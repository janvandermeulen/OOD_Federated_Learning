INFO:root:Backdoor type: single-character-attack
INFO:root: noDefense: False
INFO:root:Initialising training data for single character backdoor
INFO:root:Backdoor Train Size: 200 Backdoor Test Size: 120
INFO:root:size of test data 340
INFO:root:attack from epoch 101
INFO:root:loading global model from file ./out/baselines/baseline-no-attack/model_at_epoch_200.pt
INFO:root:Loaded global model was trained till epoch:200 
INFO:root:Test Accuracy of loaded global Model was: 80.29411764705883
INFO:root:old VocabSize 133306
INFO:root:new VocabSize 133306
INFO:root:Embedding Size of new model: Embedding(133306, 200, padding_idx=0)
INFO:root:Test Accuracy of loaded global Model is: 76.17647058823529
INFO:root:================FL round 201 Begins ===================
INFO:root:FL Epoch: 201 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 201 Workers Selected : [0, 1, 2, 595, 500, 859, 383, 1838, 1939, 1125]
INFO:root:FL Epoch: 201 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 201 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 201 Training on worker :0
INFO:root:FL Epoch: 201 Using Learning rate : 0.006700516137378225 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 1.195376
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529443
INFO:root:FL Epoch: 201 Worker: 0 Backdoor Test Loss: 0.124582273264726 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 201 Worker: 0 Backdoor Train Loss: 0.2574188679456711 Backdoor Train Accuracy: 91.0
INFO:root:FL Epoch: 201 Norm Difference for worker 0 is 0.767943
INFO:root:FL Epoch: 201 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1
INFO:root:FL Epoch: 201 Using Learning rate : 0.006700516137378225 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.956563
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195070
INFO:root:FL Epoch: 201 Worker: 1 Backdoor Test Loss: 0.13819151371717453 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 201 Worker: 1 Backdoor Train Loss: 0.2561589702963829 Backdoor Train Accuracy: 91.5
INFO:root:FL Epoch: 201 Norm Difference for worker 1 is 0.752189
INFO:root:FL Epoch: 201 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :2
INFO:root:FL Epoch: 201 Using Learning rate : 0.006700516137378225 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615697
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370157
INFO:root:FL Epoch: 201 Worker: 2 Backdoor Test Loss: 0.11945499293506145 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 201 Worker: 2 Backdoor Train Loss: 0.24906377643346786 Backdoor Train Accuracy: 89.5
INFO:root:FL Epoch: 201 Norm Difference for worker 2 is 0.793542
INFO:root:FL Epoch: 201 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :595
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515048
INFO:root:Worker: 595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308701
INFO:root:FL Epoch: 201 Norm Difference for worker 595 is 1.810959
INFO:root:FL Epoch: 201 Done on worker:595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :500
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591515
INFO:root:Worker: 500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.140526
INFO:root:FL Epoch: 201 Norm Difference for worker 500 is 1.65205
INFO:root:FL Epoch: 201 Done on worker:500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :859
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578766
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207280
INFO:root:FL Epoch: 201 Norm Difference for worker 859 is 1.767449
INFO:root:FL Epoch: 201 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :383
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 383 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579550
INFO:root:Worker: 383 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292611
INFO:root:FL Epoch: 201 Norm Difference for worker 383 is 1.816606
INFO:root:FL Epoch: 201 Done on worker:383
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1838
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543419
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253641
INFO:root:FL Epoch: 201 Norm Difference for worker 1838 is 1.797452
INFO:root:FL Epoch: 201 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1939
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687177
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235443
INFO:root:FL Epoch: 201 Norm Difference for worker 1939 is 1.86877
INFO:root:FL Epoch: 201 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1125
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421444
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333633
INFO:root:FL Epoch: 201 Norm Difference for worker 1125 is 1.847288
INFO:root:FL Epoch: 201 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 201 Ends   ===================
INFO:root:Epoch:201 Global Model Test Loss:0.5610893806990456 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:201 Global Model Backdoor Test Loss:0.13819151371717453                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 202 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 202 Workers Selected : [1016, 543, 1103, 1820, 768, 1316, 1598, 276, 207, 159]
INFO:root:FL Epoch: 202 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 202 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 202 Training on worker :1016
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807432
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390457
INFO:root:FL Epoch: 202 Norm Difference for worker 1016 is 1.856438
INFO:root:FL Epoch: 202 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :543
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372286
INFO:root:Worker: 543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403018
INFO:root:FL Epoch: 202 Norm Difference for worker 543 is 1.782382
INFO:root:FL Epoch: 202 Done on worker:543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1103
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1103 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452533
INFO:root:Worker: 1103 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325322
INFO:root:FL Epoch: 202 Norm Difference for worker 1103 is 1.865428
INFO:root:FL Epoch: 202 Done on worker:1103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1820
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451676
INFO:root:Worker: 1820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229228
INFO:root:FL Epoch: 202 Norm Difference for worker 1820 is 1.761583
INFO:root:FL Epoch: 202 Done on worker:1820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :768
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332632
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.170509
INFO:root:FL Epoch: 202 Norm Difference for worker 768 is 1.594278
INFO:root:FL Epoch: 202 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1316
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661334
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332537
INFO:root:FL Epoch: 202 Norm Difference for worker 1316 is 1.774093
INFO:root:FL Epoch: 202 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1598
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511937
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.143140
INFO:root:FL Epoch: 202 Norm Difference for worker 1598 is 1.629422
INFO:root:FL Epoch: 202 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :276
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 276 Train Epoch: 0 [0/201 (0%)]	Loss: 0.717935
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 276 Train Epoch: 1 [0/201 (0%)]	Loss: 0.188530
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 276 is 1.797992
INFO:root:FL Epoch: 202 Done on worker:276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :207
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.678734
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.345983
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 207 is 1.793179
INFO:root:FL Epoch: 202 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :159
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.448434
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.374297
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 159 is 1.851185
INFO:root:FL Epoch: 202 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 768
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 202 Ends   ===================
INFO:root:Epoch:202 Global Model Test Loss:0.5276878739104551 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:202 Global Model Backdoor Test Loss:0.27820803473393124                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 203 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 203 Workers Selected : [263, 1554, 1266, 982, 1278, 475, 1357, 684, 1506, 1238]
INFO:root:FL Epoch: 203 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 203 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 203 Training on worker :263
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 263 Train Epoch: 0 [0/201 (0%)]	Loss: 1.000238
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 263 Train Epoch: 1 [0/201 (0%)]	Loss: 0.340903
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 203 Norm Difference for worker 263 is 1.90751
INFO:root:FL Epoch: 203 Done on worker:263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1554
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492073
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264250
INFO:root:FL Epoch: 203 Norm Difference for worker 1554 is 1.737447
INFO:root:FL Epoch: 203 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1266
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1266 Train Epoch: 0 [0/200 (0%)]	Loss: 0.898213
INFO:root:Worker: 1266 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708239
INFO:root:FL Epoch: 203 Norm Difference for worker 1266 is 1.853191
INFO:root:FL Epoch: 203 Done on worker:1266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :982
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560322
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575356
INFO:root:FL Epoch: 203 Norm Difference for worker 982 is 1.921715
INFO:root:FL Epoch: 203 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1278
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624818
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305805
INFO:root:FL Epoch: 203 Norm Difference for worker 1278 is 1.728277
INFO:root:FL Epoch: 203 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :475
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305227
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229635
INFO:root:FL Epoch: 203 Norm Difference for worker 475 is 1.750694
INFO:root:FL Epoch: 203 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1357
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512001
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324389
INFO:root:FL Epoch: 203 Norm Difference for worker 1357 is 2.030561
INFO:root:FL Epoch: 203 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :684
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713603
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340082
INFO:root:FL Epoch: 203 Norm Difference for worker 684 is 1.702837
INFO:root:FL Epoch: 203 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1506
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476862
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372877
INFO:root:FL Epoch: 203 Norm Difference for worker 1506 is 1.813982
INFO:root:FL Epoch: 203 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1238
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545179
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269074
INFO:root:FL Epoch: 203 Norm Difference for worker 1238 is 1.697366
INFO:root:FL Epoch: 203 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 684
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 203 Ends   ===================
INFO:root:Epoch:203 Global Model Test Loss:0.5372879908365362 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:203 Global Model Backdoor Test Loss:0.5570499698321024                             and Backdoor Test Accuracy:70.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 204 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 204 Workers Selected : [979, 915, 1324, 1034, 360, 1751, 1025, 153, 1482, 274]
INFO:root:FL Epoch: 204 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.1003996]
INFO:root:FL Epoch: 204 Num points on workers: [200 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 204 Training on worker :979
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328872
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351965
INFO:root:FL Epoch: 204 Norm Difference for worker 979 is 1.719785
INFO:root:FL Epoch: 204 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :915
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735129
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323267
INFO:root:FL Epoch: 204 Norm Difference for worker 915 is 1.985339
INFO:root:FL Epoch: 204 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1324
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524024
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189378
INFO:root:FL Epoch: 204 Norm Difference for worker 1324 is 1.674903
INFO:root:FL Epoch: 204 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1034
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385531
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440136
INFO:root:FL Epoch: 204 Norm Difference for worker 1034 is 1.684444
INFO:root:FL Epoch: 204 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :360
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477792
INFO:root:Worker: 360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240472
INFO:root:FL Epoch: 204 Norm Difference for worker 360 is 1.710792
INFO:root:FL Epoch: 204 Done on worker:360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1751
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472453
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485031
INFO:root:FL Epoch: 204 Norm Difference for worker 1751 is 1.819193
INFO:root:FL Epoch: 204 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1025
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776920
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402267
INFO:root:FL Epoch: 204 Norm Difference for worker 1025 is 1.846989
INFO:root:FL Epoch: 204 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :153
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.280570
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.298489
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 204 Norm Difference for worker 153 is 1.647177
INFO:root:FL Epoch: 204 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1482
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349448
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303853
INFO:root:FL Epoch: 204 Norm Difference for worker 1482 is 1.639485
INFO:root:FL Epoch: 204 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :274
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.803830
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.340527
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 204 Norm Difference for worker 274 is 1.777067
INFO:root:FL Epoch: 204 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 153
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 204 Ends   ===================
INFO:root:Epoch:204 Global Model Test Loss:0.5597483042408439 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:204 Global Model Backdoor Test Loss:0.6627155145009359                             and Backdoor Test Accuracy:66.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 205 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 205 Workers Selected : [786, 115, 329, 440, 1220, 622, 1865, 1868, 1776, 1316]
INFO:root:FL Epoch: 205 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 205 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 205 Training on worker :786
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745818
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520531
INFO:root:FL Epoch: 205 Norm Difference for worker 786 is 1.533982
INFO:root:FL Epoch: 205 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :115
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.657028
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.388182
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 115 is 1.558693
INFO:root:FL Epoch: 205 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :329
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 329 Train Epoch: 0 [0/201 (0%)]	Loss: 0.426905
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 329 Train Epoch: 1 [0/201 (0%)]	Loss: 0.304080
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 329 is 1.514572
INFO:root:FL Epoch: 205 Done on worker:329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :440
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503144
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464712
INFO:root:FL Epoch: 205 Norm Difference for worker 440 is 1.439455
INFO:root:FL Epoch: 205 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1220
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435409
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411273
INFO:root:FL Epoch: 205 Norm Difference for worker 1220 is 1.536628
INFO:root:FL Epoch: 205 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :622
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411239
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430242
INFO:root:FL Epoch: 205 Norm Difference for worker 622 is 1.423422
INFO:root:FL Epoch: 205 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1865
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575440
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258863
INFO:root:FL Epoch: 205 Norm Difference for worker 1865 is 1.481818
INFO:root:FL Epoch: 205 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1868
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593725
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388814
INFO:root:FL Epoch: 205 Norm Difference for worker 1868 is 1.522565
INFO:root:FL Epoch: 205 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1776
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548726
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531159
INFO:root:FL Epoch: 205 Norm Difference for worker 1776 is 1.461823
INFO:root:FL Epoch: 205 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1316
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572580
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514373
INFO:root:FL Epoch: 205 Norm Difference for worker 1316 is 1.450628
INFO:root:FL Epoch: 205 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 440
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 205 Ends   ===================
INFO:root:Epoch:205 Global Model Test Loss:0.5598848619881798 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:205 Global Model Backdoor Test Loss:0.5636136531829834                             and Backdoor Test Accuracy:72.5 
INFO:root:=======================================================
INFO:root:================FL round 206 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 206 Workers Selected : [1197, 1507, 1435, 1040, 1420, 361, 1002, 327, 674, 1021]
INFO:root:FL Epoch: 206 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 206 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 206 Training on worker :1197
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685398
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513441
INFO:root:FL Epoch: 206 Norm Difference for worker 1197 is 1.559039
INFO:root:FL Epoch: 206 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1507
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685595
INFO:root:Worker: 1507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279479
INFO:root:FL Epoch: 206 Norm Difference for worker 1507 is 1.457533
INFO:root:FL Epoch: 206 Done on worker:1507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1435
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705752
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430479
INFO:root:FL Epoch: 206 Norm Difference for worker 1435 is 1.453264
INFO:root:FL Epoch: 206 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1040
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.258116
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331743
INFO:root:FL Epoch: 206 Norm Difference for worker 1040 is 1.518934
INFO:root:FL Epoch: 206 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1420
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537857
INFO:root:Worker: 1420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255244
INFO:root:FL Epoch: 206 Norm Difference for worker 1420 is 1.48895
INFO:root:FL Epoch: 206 Done on worker:1420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :361
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764768
INFO:root:Worker: 361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316976
INFO:root:FL Epoch: 206 Norm Difference for worker 361 is 1.512663
INFO:root:FL Epoch: 206 Done on worker:361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1002
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421846
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437471
INFO:root:FL Epoch: 206 Norm Difference for worker 1002 is 1.605359
INFO:root:FL Epoch: 206 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :327
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595351
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.407430
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 327 is 1.583854
INFO:root:FL Epoch: 206 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :674
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560821
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398984
INFO:root:FL Epoch: 206 Norm Difference for worker 674 is 1.466437
INFO:root:FL Epoch: 206 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1021
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804650
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370031
INFO:root:FL Epoch: 206 Norm Difference for worker 1021 is 1.444929
INFO:root:FL Epoch: 206 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1435
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 206 Ends   ===================
INFO:root:Epoch:206 Global Model Test Loss:0.5694964791045469 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:206 Global Model Backdoor Test Loss:0.7452341318130493                             and Backdoor Test Accuracy:56.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 207 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 207 Workers Selected : [1809, 835, 972, 1512, 1161, 1280, 1341, 243, 1257, 863]
INFO:root:FL Epoch: 207 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 207 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 207 Training on worker :1809
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660804
INFO:root:Worker: 1809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515284
INFO:root:FL Epoch: 207 Norm Difference for worker 1809 is 1.518974
INFO:root:FL Epoch: 207 Done on worker:1809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :835
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585780
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401130
INFO:root:FL Epoch: 207 Norm Difference for worker 835 is 1.483692
INFO:root:FL Epoch: 207 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :972
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 972 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662700
INFO:root:Worker: 972 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396214
INFO:root:FL Epoch: 207 Norm Difference for worker 972 is 1.53251
INFO:root:FL Epoch: 207 Done on worker:972
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1512
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471883
INFO:root:Worker: 1512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257945
INFO:root:FL Epoch: 207 Norm Difference for worker 1512 is 1.550628
INFO:root:FL Epoch: 207 Done on worker:1512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1161
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1161 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352464
INFO:root:Worker: 1161 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331398
INFO:root:FL Epoch: 207 Norm Difference for worker 1161 is 1.458179
INFO:root:FL Epoch: 207 Done on worker:1161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1280
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1280 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513766
INFO:root:Worker: 1280 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348281
INFO:root:FL Epoch: 207 Norm Difference for worker 1280 is 1.428316
INFO:root:FL Epoch: 207 Done on worker:1280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1341
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389789
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480505
INFO:root:FL Epoch: 207 Norm Difference for worker 1341 is 1.483006
INFO:root:FL Epoch: 207 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :243
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.778470
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.481368
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 243 is 1.497896
INFO:root:FL Epoch: 207 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1257
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1257 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362088
INFO:root:Worker: 1257 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411633
INFO:root:FL Epoch: 207 Norm Difference for worker 1257 is 1.418564
INFO:root:FL Epoch: 207 Done on worker:1257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :863
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.264891
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317128
INFO:root:FL Epoch: 207 Norm Difference for worker 863 is 1.512558
INFO:root:FL Epoch: 207 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1257
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 207 Ends   ===================
INFO:root:Epoch:207 Global Model Test Loss:0.5520962932530571 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:207 Global Model Backdoor Test Loss:0.7314559121926626                             and Backdoor Test Accuracy:54.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 208 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 208 Workers Selected : [1434, 721, 363, 467, 1443, 1573, 269, 475, 1216, 521]
INFO:root:FL Epoch: 208 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 208 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 208 Training on worker :1434
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508548
INFO:root:Worker: 1434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300179
INFO:root:FL Epoch: 208 Norm Difference for worker 1434 is 1.359583
INFO:root:FL Epoch: 208 Done on worker:1434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :721
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364723
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540715
INFO:root:FL Epoch: 208 Norm Difference for worker 721 is 1.54649
INFO:root:FL Epoch: 208 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :363
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778363
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365011
INFO:root:FL Epoch: 208 Norm Difference for worker 363 is 1.457953
INFO:root:FL Epoch: 208 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :467
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573123
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231381
INFO:root:FL Epoch: 208 Norm Difference for worker 467 is 1.363837
INFO:root:FL Epoch: 208 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1443
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544427
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653016
INFO:root:FL Epoch: 208 Norm Difference for worker 1443 is 1.509343
INFO:root:FL Epoch: 208 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1573
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763448
INFO:root:Worker: 1573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258591
INFO:root:FL Epoch: 208 Norm Difference for worker 1573 is 1.493891
INFO:root:FL Epoch: 208 Done on worker:1573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :269
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 269 Train Epoch: 0 [0/201 (0%)]	Loss: 0.604494
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 269 Train Epoch: 1 [0/201 (0%)]	Loss: 0.460420
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 208 Norm Difference for worker 269 is 1.46237
INFO:root:FL Epoch: 208 Done on worker:269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :475
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680103
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491679
INFO:root:FL Epoch: 208 Norm Difference for worker 475 is 1.476163
INFO:root:FL Epoch: 208 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1216
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1216 Train Epoch: 0 [0/200 (0%)]	Loss: 0.816849
INFO:root:Worker: 1216 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490722
INFO:root:FL Epoch: 208 Norm Difference for worker 1216 is 1.567484
INFO:root:FL Epoch: 208 Done on worker:1216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :521
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697842
INFO:root:Worker: 521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330999
INFO:root:FL Epoch: 208 Norm Difference for worker 521 is 1.445835
INFO:root:FL Epoch: 208 Done on worker:521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 467
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 208 Ends   ===================
INFO:root:Epoch:208 Global Model Test Loss:0.597046946778017 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:208 Global Model Backdoor Test Loss:1.115015337864558                             and Backdoor Test Accuracy:30.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 209 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 209 Workers Selected : [1154, 257, 1894, 729, 1361, 634, 632, 657, 28, 344]
INFO:root:FL Epoch: 209 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 209 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 209 Training on worker :1154
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1154 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373327
INFO:root:Worker: 1154 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631633
INFO:root:FL Epoch: 209 Norm Difference for worker 1154 is 1.438343
INFO:root:FL Epoch: 209 Done on worker:1154
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :257
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.356074
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.466947
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 257 is 1.522602
INFO:root:FL Epoch: 209 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1894
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467054
INFO:root:Worker: 1894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429477
INFO:root:FL Epoch: 209 Norm Difference for worker 1894 is 1.425664
INFO:root:FL Epoch: 209 Done on worker:1894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :729
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465474
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369280
INFO:root:FL Epoch: 209 Norm Difference for worker 729 is 1.588291
INFO:root:FL Epoch: 209 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1361
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615799
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358732
INFO:root:FL Epoch: 209 Norm Difference for worker 1361 is 1.441126
INFO:root:FL Epoch: 209 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :634
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586069
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356683
INFO:root:FL Epoch: 209 Norm Difference for worker 634 is 1.403859
INFO:root:FL Epoch: 209 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :632
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553517
INFO:root:Worker: 632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398624
INFO:root:FL Epoch: 209 Norm Difference for worker 632 is 1.471619
INFO:root:FL Epoch: 209 Done on worker:632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :657
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687537
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328032
INFO:root:FL Epoch: 209 Norm Difference for worker 657 is 1.499948
INFO:root:FL Epoch: 209 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :28
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.735401
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.382666
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 28 is 1.415143
INFO:root:FL Epoch: 209 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :344
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556155
INFO:root:Worker: 344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297678
INFO:root:FL Epoch: 209 Norm Difference for worker 344 is 1.358163
INFO:root:FL Epoch: 209 Done on worker:344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 344
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 209 Ends   ===================
INFO:root:Epoch:209 Global Model Test Loss:0.5549170059316298 and Test Accuracy:70.0 
INFO:root:Epoch:209 Global Model Backdoor Test Loss:0.9445858597755432                             and Backdoor Test Accuracy:41.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 210 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 210 Workers Selected : [322, 1069, 1454, 716, 1613, 1184, 1191, 27, 1904, 291]
INFO:root:FL Epoch: 210 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 210 Num points on workers: [201 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 210 Training on worker :322
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 322 Train Epoch: 0 [0/201 (0%)]	Loss: 0.686003
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 322 Train Epoch: 1 [0/201 (0%)]	Loss: 0.395569
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 322 is 1.441957
INFO:root:FL Epoch: 210 Done on worker:322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1069
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 0.850296
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640381
INFO:root:FL Epoch: 210 Norm Difference for worker 1069 is 1.38911
INFO:root:FL Epoch: 210 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1454
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539881
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319607
INFO:root:FL Epoch: 210 Norm Difference for worker 1454 is 1.27838
INFO:root:FL Epoch: 210 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :716
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372972
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423615
INFO:root:FL Epoch: 210 Norm Difference for worker 716 is 1.370748
INFO:root:FL Epoch: 210 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1613
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656994
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678820
INFO:root:FL Epoch: 210 Norm Difference for worker 1613 is 1.456111
INFO:root:FL Epoch: 210 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1184
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1184 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718667
INFO:root:Worker: 1184 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316203
INFO:root:FL Epoch: 210 Norm Difference for worker 1184 is 1.392552
INFO:root:FL Epoch: 210 Done on worker:1184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1191
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1191 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461885
INFO:root:Worker: 1191 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304721
INFO:root:FL Epoch: 210 Norm Difference for worker 1191 is 1.488413
INFO:root:FL Epoch: 210 Done on worker:1191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :27
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 27 Train Epoch: 0 [0/201 (0%)]	Loss: 0.508351
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 27 Train Epoch: 1 [0/201 (0%)]	Loss: 0.427687
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 27 is 1.438395
INFO:root:FL Epoch: 210 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1904
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752156
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454868
INFO:root:FL Epoch: 210 Norm Difference for worker 1904 is 1.443733
INFO:root:FL Epoch: 210 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :291
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.650020
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.542102
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 291 is 1.41029
INFO:root:FL Epoch: 210 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1454
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 210 Ends   ===================
INFO:root:Epoch:210 Global Model Test Loss:0.5523303764707902 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:210 Global Model Backdoor Test Loss:0.9800420502821604                             and Backdoor Test Accuracy:40.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 211 Begins ===================
INFO:root:FL Epoch: 211 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 211 Workers Selected : [0, 1, 2, 1409, 1122, 467, 247, 1802, 1801, 1139]
INFO:root:FL Epoch: 211 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 211 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 211 Training on worker :0
INFO:root:FL Epoch: 211 Using Learning rate : 0.006567705497499687 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447550
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337818
INFO:root:FL Epoch: 211 Worker: 0 Backdoor Test Loss: 0.2172242651383082 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 211 Worker: 0 Backdoor Train Loss: 0.34582851827144623 Backdoor Train Accuracy: 81.5
INFO:root:FL Epoch: 211 Norm Difference for worker 0 is 0.553272
INFO:root:FL Epoch: 211 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1
INFO:root:FL Epoch: 211 Using Learning rate : 0.006567705497499687 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685233
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480815
INFO:root:FL Epoch: 211 Worker: 1 Backdoor Test Loss: 0.22969182084004083 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 211 Worker: 1 Backdoor Train Loss: 0.338099779188633 Backdoor Train Accuracy: 83.5
INFO:root:FL Epoch: 211 Norm Difference for worker 1 is 0.563715
INFO:root:FL Epoch: 211 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :2
INFO:root:FL Epoch: 211 Using Learning rate : 0.006567705497499687 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602395
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597174
INFO:root:FL Epoch: 211 Worker: 2 Backdoor Test Loss: 0.2522112602988879 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 211 Worker: 2 Backdoor Train Loss: 0.3385478317737579 Backdoor Train Accuracy: 83.0
INFO:root:FL Epoch: 211 Norm Difference for worker 2 is 0.552597
INFO:root:FL Epoch: 211 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1409
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468971
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356441
INFO:root:FL Epoch: 211 Norm Difference for worker 1409 is 1.564385
INFO:root:FL Epoch: 211 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1122
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1122 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433538
INFO:root:Worker: 1122 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272035
INFO:root:FL Epoch: 211 Norm Difference for worker 1122 is 1.459913
INFO:root:FL Epoch: 211 Done on worker:1122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :467
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.186264
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297668
INFO:root:FL Epoch: 211 Norm Difference for worker 467 is 0.936443
INFO:root:FL Epoch: 211 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :247
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.873826
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.409139
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 211 Norm Difference for worker 247 is 1.643198
INFO:root:FL Epoch: 211 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1802
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380510
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282600
INFO:root:FL Epoch: 211 Norm Difference for worker 1802 is 1.555638
INFO:root:FL Epoch: 211 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1801
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609441
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321433
INFO:root:FL Epoch: 211 Norm Difference for worker 1801 is 1.494087
INFO:root:FL Epoch: 211 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1139
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430217
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483478
INFO:root:FL Epoch: 211 Norm Difference for worker 1139 is 1.45207
INFO:root:FL Epoch: 211 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 211 Ends   ===================
INFO:root:Epoch:211 Global Model Test Loss:0.5613138272481806 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:211 Global Model Backdoor Test Loss:0.2522112602988879                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 212 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 212 Workers Selected : [1405, 1244, 380, 125, 802, 840, 1334, 1733, 689, 1036]
INFO:root:FL Epoch: 212 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 212 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 212 Training on worker :1405
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579410
INFO:root:Worker: 1405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443600
INFO:root:FL Epoch: 212 Norm Difference for worker 1405 is 1.418827
INFO:root:FL Epoch: 212 Done on worker:1405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1244
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420201
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319233
INFO:root:FL Epoch: 212 Norm Difference for worker 1244 is 1.490524
INFO:root:FL Epoch: 212 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :380
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630286
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437378
INFO:root:FL Epoch: 212 Norm Difference for worker 380 is 1.659842
INFO:root:FL Epoch: 212 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :125
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.400347
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.351455
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 212 Norm Difference for worker 125 is 1.423926
INFO:root:FL Epoch: 212 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :802
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687456
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410867
INFO:root:FL Epoch: 212 Norm Difference for worker 802 is 1.546148
INFO:root:FL Epoch: 212 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :840
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666342
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440963
INFO:root:FL Epoch: 212 Norm Difference for worker 840 is 1.536464
INFO:root:FL Epoch: 212 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1334
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431256
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.717655
INFO:root:FL Epoch: 212 Norm Difference for worker 1334 is 1.507375
INFO:root:FL Epoch: 212 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1733
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640560
INFO:root:Worker: 1733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345330
INFO:root:FL Epoch: 212 Norm Difference for worker 1733 is 1.409048
INFO:root:FL Epoch: 212 Done on worker:1733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :689
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664258
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411681
INFO:root:FL Epoch: 212 Norm Difference for worker 689 is 1.580049
INFO:root:FL Epoch: 212 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1036
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520468
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387747
INFO:root:FL Epoch: 212 Norm Difference for worker 1036 is 1.453031
INFO:root:FL Epoch: 212 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1733
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 212 Ends   ===================
INFO:root:Epoch:212 Global Model Test Loss:0.6018601498183083 and Test Accuracy:70.0 
INFO:root:Epoch:212 Global Model Backdoor Test Loss:0.3848654329776764                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 213 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 213 Workers Selected : [1930, 1474, 442, 232, 116, 202, 1081, 606, 1303, 945]
INFO:root:FL Epoch: 213 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 213 Num points on workers: [200 200 200 201 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 213 Training on worker :1930
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585491
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320196
INFO:root:FL Epoch: 213 Norm Difference for worker 1930 is 1.445202
INFO:root:FL Epoch: 213 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1474
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480993
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531483
INFO:root:FL Epoch: 213 Norm Difference for worker 1474 is 1.520549
INFO:root:FL Epoch: 213 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :442
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.840562
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364921
INFO:root:FL Epoch: 213 Norm Difference for worker 442 is 1.475225
INFO:root:FL Epoch: 213 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :232
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.654223
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.444904
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 213 Norm Difference for worker 232 is 1.505379
INFO:root:FL Epoch: 213 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :116
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.437748
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.388311
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 213 Norm Difference for worker 116 is 1.568667
INFO:root:FL Epoch: 213 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :202
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.631896
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.416760
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 213 Norm Difference for worker 202 is 1.645637
INFO:root:FL Epoch: 213 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1081
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759547
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520575
INFO:root:FL Epoch: 213 Norm Difference for worker 1081 is 1.634088
INFO:root:FL Epoch: 213 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :606
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633204
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661265
INFO:root:FL Epoch: 213 Norm Difference for worker 606 is 1.48554
INFO:root:FL Epoch: 213 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1303
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.954979
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375594
INFO:root:FL Epoch: 213 Norm Difference for worker 1303 is 1.501506
INFO:root:FL Epoch: 213 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :945
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.335544
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387286
INFO:root:FL Epoch: 213 Norm Difference for worker 945 is 1.506229
INFO:root:FL Epoch: 213 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 606
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 213 Ends   ===================
INFO:root:Epoch:213 Global Model Test Loss:0.5869509507628048 and Test Accuracy:66.17647058823529 
INFO:root:Epoch:213 Global Model Backdoor Test Loss:0.47411073247591656                             and Backdoor Test Accuracy:75.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 214 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 214 Workers Selected : [1163, 1460, 409, 1123, 604, 200, 551, 1222, 1589, 746]
INFO:root:FL Epoch: 214 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 214 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 214 Training on worker :1163
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402207
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284241
INFO:root:FL Epoch: 214 Norm Difference for worker 1163 is 1.388121
INFO:root:FL Epoch: 214 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1460
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485054
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309090
INFO:root:FL Epoch: 214 Norm Difference for worker 1460 is 1.267828
INFO:root:FL Epoch: 214 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :409
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.855593
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656713
INFO:root:FL Epoch: 214 Norm Difference for worker 409 is 1.389135
INFO:root:FL Epoch: 214 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1123
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1123 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421233
INFO:root:Worker: 1123 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448387
INFO:root:FL Epoch: 214 Norm Difference for worker 1123 is 1.296078
INFO:root:FL Epoch: 214 Done on worker:1123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :604
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551099
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401062
INFO:root:FL Epoch: 214 Norm Difference for worker 604 is 1.341899
INFO:root:FL Epoch: 214 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :200
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.472547
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.592683
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 200 is 1.48472
INFO:root:FL Epoch: 214 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :551
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.832514
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329419
INFO:root:FL Epoch: 214 Norm Difference for worker 551 is 1.342805
INFO:root:FL Epoch: 214 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1222
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1222 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407913
INFO:root:Worker: 1222 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684163
INFO:root:FL Epoch: 214 Norm Difference for worker 1222 is 1.396703
INFO:root:FL Epoch: 214 Done on worker:1222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1589
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656619
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360126
INFO:root:FL Epoch: 214 Norm Difference for worker 1589 is 1.415273
INFO:root:FL Epoch: 214 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :746
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 746 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520968
INFO:root:Worker: 746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390799
INFO:root:FL Epoch: 214 Norm Difference for worker 746 is 1.388885
INFO:root:FL Epoch: 214 Done on worker:746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1460
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 214 Ends   ===================
INFO:root:Epoch:214 Global Model Test Loss:0.5823422652833602 and Test Accuracy:70.0 
INFO:root:Epoch:214 Global Model Backdoor Test Loss:0.435416504740715                             and Backdoor Test Accuracy:78.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 215 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 215 Workers Selected : [1506, 196, 1478, 1595, 1923, 91, 242, 1709, 1297, 1000]
INFO:root:FL Epoch: 215 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 215 Num points on workers: [200 201 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 215 Training on worker :1506
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443186
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308737
INFO:root:FL Epoch: 215 Norm Difference for worker 1506 is 1.319865
INFO:root:FL Epoch: 215 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :196
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.735260
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415030
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 215 Norm Difference for worker 196 is 1.409625
INFO:root:FL Epoch: 215 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1478
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406925
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414665
INFO:root:FL Epoch: 215 Norm Difference for worker 1478 is 1.330506
INFO:root:FL Epoch: 215 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1595
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474578
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350794
INFO:root:FL Epoch: 215 Norm Difference for worker 1595 is 1.261017
INFO:root:FL Epoch: 215 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1923
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.890733
INFO:root:Worker: 1923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565503
INFO:root:FL Epoch: 215 Norm Difference for worker 1923 is 1.512436
INFO:root:FL Epoch: 215 Done on worker:1923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :91
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.742645
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.408069
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 215 Norm Difference for worker 91 is 1.388425
INFO:root:FL Epoch: 215 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :242
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.413783
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.472067
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 215 Norm Difference for worker 242 is 1.457491
INFO:root:FL Epoch: 215 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1709
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733274
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651600
INFO:root:FL Epoch: 215 Norm Difference for worker 1709 is 1.519987
INFO:root:FL Epoch: 215 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1297
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1297 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450608
INFO:root:Worker: 1297 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594393
INFO:root:FL Epoch: 215 Norm Difference for worker 1297 is 1.431057
INFO:root:FL Epoch: 215 Done on worker:1297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1000
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638174
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490624
INFO:root:FL Epoch: 215 Norm Difference for worker 1000 is 1.533995
INFO:root:FL Epoch: 215 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1506
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 215 Ends   ===================
INFO:root:Epoch:215 Global Model Test Loss:0.5918473461095024 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:215 Global Model Backdoor Test Loss:0.5871157596508662                             and Backdoor Test Accuracy:71.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 216 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 216 Workers Selected : [639, 327, 503, 1110, 839, 472, 274, 481, 805, 1606]
INFO:root:FL Epoch: 216 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 216 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 216 Training on worker :639
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429000
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408300
INFO:root:FL Epoch: 216 Norm Difference for worker 639 is 1.423615
INFO:root:FL Epoch: 216 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :327
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.567151
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.557528
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 216 Norm Difference for worker 327 is 1.564457
INFO:root:FL Epoch: 216 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :503
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545831
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450866
INFO:root:FL Epoch: 216 Norm Difference for worker 503 is 1.379877
INFO:root:FL Epoch: 216 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1110
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1110 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367836
INFO:root:Worker: 1110 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417374
INFO:root:FL Epoch: 216 Norm Difference for worker 1110 is 1.521966
INFO:root:FL Epoch: 216 Done on worker:1110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :839
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642495
INFO:root:Worker: 839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385666
INFO:root:FL Epoch: 216 Norm Difference for worker 839 is 1.421967
INFO:root:FL Epoch: 216 Done on worker:839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :472
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493186
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378275
INFO:root:FL Epoch: 216 Norm Difference for worker 472 is 1.511012
INFO:root:FL Epoch: 216 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :274
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.548412
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.480525
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 216 Norm Difference for worker 274 is 1.377685
INFO:root:FL Epoch: 216 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :481
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587453
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407527
INFO:root:FL Epoch: 216 Norm Difference for worker 481 is 1.417245
INFO:root:FL Epoch: 216 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :805
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.331426
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299888
INFO:root:FL Epoch: 216 Norm Difference for worker 805 is 1.333936
INFO:root:FL Epoch: 216 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1606
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744482
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383971
INFO:root:FL Epoch: 216 Norm Difference for worker 1606 is 1.422907
INFO:root:FL Epoch: 216 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 274
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 216 Ends   ===================
INFO:root:Epoch:216 Global Model Test Loss:0.6009451729409835 and Test Accuracy:69.11764705882354 
INFO:root:Epoch:216 Global Model Backdoor Test Loss:0.5140793174505234                             and Backdoor Test Accuracy:75.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 217 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 217 Workers Selected : [116, 1658, 988, 1655, 62, 870, 955, 304, 1427, 652]
INFO:root:FL Epoch: 217 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 217 Num points on workers: [201 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 217 Training on worker :116
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.617175
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.391796
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 217 Norm Difference for worker 116 is 1.530784
INFO:root:FL Epoch: 217 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1658
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501898
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522269
INFO:root:FL Epoch: 217 Norm Difference for worker 1658 is 1.451371
INFO:root:FL Epoch: 217 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :988
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 988 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434358
INFO:root:Worker: 988 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450073
INFO:root:FL Epoch: 217 Norm Difference for worker 988 is 1.486348
INFO:root:FL Epoch: 217 Done on worker:988
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1655
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1655 Train Epoch: 0 [0/200 (0%)]	Loss: 1.011267
INFO:root:Worker: 1655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414638
INFO:root:FL Epoch: 217 Norm Difference for worker 1655 is 1.533546
INFO:root:FL Epoch: 217 Done on worker:1655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :62
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.527077
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.379415
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 217 Norm Difference for worker 62 is 1.391608
INFO:root:FL Epoch: 217 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :870
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636926
INFO:root:Worker: 870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616800
INFO:root:FL Epoch: 217 Norm Difference for worker 870 is 1.458159
INFO:root:FL Epoch: 217 Done on worker:870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :955
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 955 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304801
INFO:root:Worker: 955 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424218
INFO:root:FL Epoch: 217 Norm Difference for worker 955 is 1.458712
INFO:root:FL Epoch: 217 Done on worker:955
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :304
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.875044
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.429357
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 217 Norm Difference for worker 304 is 1.419726
INFO:root:FL Epoch: 217 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1427
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631854
INFO:root:Worker: 1427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299627
INFO:root:FL Epoch: 217 Norm Difference for worker 1427 is 1.398816
INFO:root:FL Epoch: 217 Done on worker:1427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :652
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600416
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376240
INFO:root:FL Epoch: 217 Norm Difference for worker 652 is 1.329029
INFO:root:FL Epoch: 217 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 652
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 217 Ends   ===================
INFO:root:Epoch:217 Global Model Test Loss:0.6155557702569401 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:217 Global Model Backdoor Test Loss:0.5234414140383402                             and Backdoor Test Accuracy:74.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 218 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 218 Workers Selected : [1037, 1375, 637, 293, 1435, 1294, 712, 440, 1768, 1805]
INFO:root:FL Epoch: 218 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 218 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 218 Training on worker :1037
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1037 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455842
INFO:root:Worker: 1037 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559757
INFO:root:FL Epoch: 218 Norm Difference for worker 1037 is 1.519282
INFO:root:FL Epoch: 218 Done on worker:1037
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1375
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.822191
INFO:root:Worker: 1375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630613
INFO:root:FL Epoch: 218 Norm Difference for worker 1375 is 1.646403
INFO:root:FL Epoch: 218 Done on worker:1375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :637
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390832
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434103
INFO:root:FL Epoch: 218 Norm Difference for worker 637 is 1.66078
INFO:root:FL Epoch: 218 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :293
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 293 Train Epoch: 0 [0/201 (0%)]	Loss: 0.368417
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 293 Train Epoch: 1 [0/201 (0%)]	Loss: 0.232019
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 293 is 1.363077
INFO:root:FL Epoch: 218 Done on worker:293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1435
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378449
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.165976
INFO:root:FL Epoch: 218 Norm Difference for worker 1435 is 1.295023
INFO:root:FL Epoch: 218 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1294
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528618
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471146
INFO:root:FL Epoch: 218 Norm Difference for worker 1294 is 1.524482
INFO:root:FL Epoch: 218 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :712
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325216
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540358
INFO:root:FL Epoch: 218 Norm Difference for worker 712 is 1.601583
INFO:root:FL Epoch: 218 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :440
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697412
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218875
INFO:root:FL Epoch: 218 Norm Difference for worker 440 is 1.27474
INFO:root:FL Epoch: 218 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1768
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361976
INFO:root:Worker: 1768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418936
INFO:root:FL Epoch: 218 Norm Difference for worker 1768 is 1.599632
INFO:root:FL Epoch: 218 Done on worker:1768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1805
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440374
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323988
INFO:root:FL Epoch: 218 Norm Difference for worker 1805 is 1.422822
INFO:root:FL Epoch: 218 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1435
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 218 Ends   ===================
INFO:root:Epoch:218 Global Model Test Loss:0.6298744266524035 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:218 Global Model Backdoor Test Loss:0.544479658206304                             and Backdoor Test Accuracy:75.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 219 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 219 Workers Selected : [772, 212, 407, 782, 1093, 1764, 38, 351, 1391, 334]
INFO:root:FL Epoch: 219 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 219 Num points on workers: [200 201 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 219 Training on worker :772
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.798616
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380777
INFO:root:FL Epoch: 219 Norm Difference for worker 772 is 1.550761
INFO:root:FL Epoch: 219 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :212
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.771902
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.273926
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 219 Norm Difference for worker 212 is 1.584804
INFO:root:FL Epoch: 219 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :407
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525344
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335516
INFO:root:FL Epoch: 219 Norm Difference for worker 407 is 1.463154
INFO:root:FL Epoch: 219 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :782
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674435
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334281
INFO:root:FL Epoch: 219 Norm Difference for worker 782 is 1.69564
INFO:root:FL Epoch: 219 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1093
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723359
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294564
INFO:root:FL Epoch: 219 Norm Difference for worker 1093 is 1.574204
INFO:root:FL Epoch: 219 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1764
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803238
INFO:root:Worker: 1764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597047
INFO:root:FL Epoch: 219 Norm Difference for worker 1764 is 1.759185
INFO:root:FL Epoch: 219 Done on worker:1764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :38
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.546458
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.259388
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 219 Norm Difference for worker 38 is 1.311623
INFO:root:FL Epoch: 219 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :351
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760055
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562656
INFO:root:FL Epoch: 219 Norm Difference for worker 351 is 1.615338
INFO:root:FL Epoch: 219 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1391
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.791348
INFO:root:Worker: 1391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586601
INFO:root:FL Epoch: 219 Norm Difference for worker 1391 is 1.620022
INFO:root:FL Epoch: 219 Done on worker:1391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :334
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.606291
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.453989
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 219 Norm Difference for worker 334 is 1.580766
INFO:root:FL Epoch: 219 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 38
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 219 Ends   ===================
INFO:root:Epoch:219 Global Model Test Loss:0.6113119493512547 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:219 Global Model Backdoor Test Loss:0.5709929515918096                             and Backdoor Test Accuracy:70.0 
INFO:root:=======================================================
INFO:root:================FL round 220 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 220 Workers Selected : [697, 1059, 940, 1796, 1162, 1765, 469, 1470, 442, 1373]
INFO:root:FL Epoch: 220 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 220 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 220 Training on worker :697
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807031
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591739
INFO:root:FL Epoch: 220 Norm Difference for worker 697 is 1.698059
INFO:root:FL Epoch: 220 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1059
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445851
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499260
INFO:root:FL Epoch: 220 Norm Difference for worker 1059 is 1.47015
INFO:root:FL Epoch: 220 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :940
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.867780
INFO:root:Worker: 940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277398
INFO:root:FL Epoch: 220 Norm Difference for worker 940 is 1.401563
INFO:root:FL Epoch: 220 Done on worker:940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1796
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656806
INFO:root:Worker: 1796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315429
INFO:root:FL Epoch: 220 Norm Difference for worker 1796 is 1.636138
INFO:root:FL Epoch: 220 Done on worker:1796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1162
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1162 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745454
INFO:root:Worker: 1162 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336058
INFO:root:FL Epoch: 220 Norm Difference for worker 1162 is 1.540145
INFO:root:FL Epoch: 220 Done on worker:1162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1765
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561315
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366203
INFO:root:FL Epoch: 220 Norm Difference for worker 1765 is 1.40964
INFO:root:FL Epoch: 220 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :469
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456889
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287638
INFO:root:FL Epoch: 220 Norm Difference for worker 469 is 1.522853
INFO:root:FL Epoch: 220 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1470
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.822197
INFO:root:Worker: 1470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491296
INFO:root:FL Epoch: 220 Norm Difference for worker 1470 is 1.585428
INFO:root:FL Epoch: 220 Done on worker:1470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :442
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527533
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414074
INFO:root:FL Epoch: 220 Norm Difference for worker 442 is 1.561634
INFO:root:FL Epoch: 220 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1373
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696187
INFO:root:Worker: 1373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297344
INFO:root:FL Epoch: 220 Norm Difference for worker 1373 is 1.604315
INFO:root:FL Epoch: 220 Done on worker:1373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 940
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 220 Ends   ===================
INFO:root:Epoch:220 Global Model Test Loss:0.6289042024051442 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:220 Global Model Backdoor Test Loss:0.6876637438933054                             and Backdoor Test Accuracy:63.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 221 Begins ===================
INFO:root:FL Epoch: 221 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 221 Workers Selected : [0, 1, 2, 188, 485, 797, 1233, 876, 159, 811]
INFO:root:FL Epoch: 221 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 221 Num points on workers: [200 200 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 221 Training on worker :0
INFO:root:FL Epoch: 221 Using Learning rate : 0.006437527291556583 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574821
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537965
INFO:root:FL Epoch: 221 Worker: 0 Backdoor Test Loss: 0.20860538383324942 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 221 Worker: 0 Backdoor Train Loss: 0.26673087030649184 Backdoor Train Accuracy: 89.0
INFO:root:FL Epoch: 221 Norm Difference for worker 0 is 0.494993
INFO:root:FL Epoch: 221 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1
INFO:root:FL Epoch: 221 Using Learning rate : 0.006437527291556583 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555266
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503038
INFO:root:FL Epoch: 221 Worker: 1 Backdoor Test Loss: 0.22553863128026327 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 221 Worker: 1 Backdoor Train Loss: 0.2680219627916813 Backdoor Train Accuracy: 88.5
INFO:root:FL Epoch: 221 Norm Difference for worker 1 is 0.481899
INFO:root:FL Epoch: 221 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :2
INFO:root:FL Epoch: 221 Using Learning rate : 0.006437527291556583 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308889
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337117
INFO:root:FL Epoch: 221 Worker: 2 Backdoor Test Loss: 0.20736035828789076 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 221 Worker: 2 Backdoor Train Loss: 0.27084691673517225 Backdoor Train Accuracy: 88.0
INFO:root:FL Epoch: 221 Norm Difference for worker 2 is 0.494733
INFO:root:FL Epoch: 221 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :188
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.436971
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.440054
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 221 Norm Difference for worker 188 is 1.741852
INFO:root:FL Epoch: 221 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :485
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431656
INFO:root:Worker: 485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304131
INFO:root:FL Epoch: 221 Norm Difference for worker 485 is 1.660878
INFO:root:FL Epoch: 221 Done on worker:485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :797
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630336
INFO:root:Worker: 797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431732
INFO:root:FL Epoch: 221 Norm Difference for worker 797 is 1.697022
INFO:root:FL Epoch: 221 Done on worker:797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1233
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1233 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582617
INFO:root:Worker: 1233 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240578
INFO:root:FL Epoch: 221 Norm Difference for worker 1233 is 1.737303
INFO:root:FL Epoch: 221 Done on worker:1233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :876
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393951
INFO:root:Worker: 876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327863
INFO:root:FL Epoch: 221 Norm Difference for worker 876 is 1.72209
INFO:root:FL Epoch: 221 Done on worker:876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :159
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.939654
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.374645
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 221 Norm Difference for worker 159 is 1.587425
INFO:root:FL Epoch: 221 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :811
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 811 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522673
INFO:root:Worker: 811 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403528
INFO:root:FL Epoch: 221 Norm Difference for worker 811 is 1.800478
INFO:root:FL Epoch: 221 Done on worker:811
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 221 Ends   ===================
INFO:root:Epoch:221 Global Model Test Loss:0.6274529011810527 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:221 Global Model Backdoor Test Loss:0.22553863128026327                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 222 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 222 Workers Selected : [1716, 910, 1098, 1721, 576, 104, 1834, 1178, 810, 1047]
INFO:root:FL Epoch: 222 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 222 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 222 Training on worker :1716
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729640
INFO:root:Worker: 1716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361574
INFO:root:FL Epoch: 222 Norm Difference for worker 1716 is 1.65323
INFO:root:FL Epoch: 222 Done on worker:1716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :910
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.858412
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483680
INFO:root:FL Epoch: 222 Norm Difference for worker 910 is 1.659877
INFO:root:FL Epoch: 222 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1098
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472043
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241422
INFO:root:FL Epoch: 222 Norm Difference for worker 1098 is 1.548344
INFO:root:FL Epoch: 222 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1721
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350002
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526745
INFO:root:FL Epoch: 222 Norm Difference for worker 1721 is 1.64018
INFO:root:FL Epoch: 222 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :576
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.822834
INFO:root:Worker: 576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288438
INFO:root:FL Epoch: 222 Norm Difference for worker 576 is 1.553052
INFO:root:FL Epoch: 222 Done on worker:576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :104
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.516921
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.405265
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 222 Norm Difference for worker 104 is 1.668488
INFO:root:FL Epoch: 222 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1834
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333021
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566648
INFO:root:FL Epoch: 222 Norm Difference for worker 1834 is 1.746591
INFO:root:FL Epoch: 222 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1178
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390017
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297425
INFO:root:FL Epoch: 222 Norm Difference for worker 1178 is 1.693824
INFO:root:FL Epoch: 222 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :810
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439102
INFO:root:Worker: 810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.159927
INFO:root:FL Epoch: 222 Norm Difference for worker 810 is 1.725447
INFO:root:FL Epoch: 222 Done on worker:810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1047
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1047 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562932
INFO:root:Worker: 1047 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391276
INFO:root:FL Epoch: 222 Norm Difference for worker 1047 is 1.676689
INFO:root:FL Epoch: 222 Done on worker:1047
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1098
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 222 Ends   ===================
INFO:root:Epoch:222 Global Model Test Loss:0.6327624285922331 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:222 Global Model Backdoor Test Loss:0.362502321600914                             and Backdoor Test Accuracy:82.5 
INFO:root:=======================================================
INFO:root:================FL round 223 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 223 Workers Selected : [1150, 703, 1942, 362, 1475, 742, 1557, 355, 747, 802]
INFO:root:FL Epoch: 223 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 223 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 223 Training on worker :1150
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1150 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572877
INFO:root:Worker: 1150 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258275
INFO:root:FL Epoch: 223 Norm Difference for worker 1150 is 1.509364
INFO:root:FL Epoch: 223 Done on worker:1150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :703
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558059
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320118
INFO:root:FL Epoch: 223 Norm Difference for worker 703 is 1.558058
INFO:root:FL Epoch: 223 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1942
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.880542
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254094
INFO:root:FL Epoch: 223 Norm Difference for worker 1942 is 1.50229
INFO:root:FL Epoch: 223 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :362
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.833374
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199430
INFO:root:FL Epoch: 223 Norm Difference for worker 362 is 1.541912
INFO:root:FL Epoch: 223 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1475
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686452
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.714672
INFO:root:FL Epoch: 223 Norm Difference for worker 1475 is 1.637914
INFO:root:FL Epoch: 223 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :742
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625813
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337362
INFO:root:FL Epoch: 223 Norm Difference for worker 742 is 1.516304
INFO:root:FL Epoch: 223 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1557
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402004
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504184
INFO:root:FL Epoch: 223 Norm Difference for worker 1557 is 1.546088
INFO:root:FL Epoch: 223 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :355
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667909
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414269
INFO:root:FL Epoch: 223 Norm Difference for worker 355 is 1.675157
INFO:root:FL Epoch: 223 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :747
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494983
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.757975
INFO:root:FL Epoch: 223 Norm Difference for worker 747 is 1.610114
INFO:root:FL Epoch: 223 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :802
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386368
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323285
INFO:root:FL Epoch: 223 Norm Difference for worker 802 is 1.514152
INFO:root:FL Epoch: 223 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1150
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 223 Ends   ===================
INFO:root:Epoch:223 Global Model Test Loss:0.5387276884387521 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:223 Global Model Backdoor Test Loss:0.46295351286729175                             and Backdoor Test Accuracy:77.5 
INFO:root:=======================================================
INFO:root:================FL round 224 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 224 Workers Selected : [858, 699, 206, 1820, 1414, 474, 7, 1914, 865, 249]
INFO:root:FL Epoch: 224 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 224 Num points on workers: [200 200 201 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 224 Training on worker :858
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584118
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437136
INFO:root:FL Epoch: 224 Norm Difference for worker 858 is 1.369051
INFO:root:FL Epoch: 224 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :699
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 699 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537147
INFO:root:Worker: 699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343535
INFO:root:FL Epoch: 224 Norm Difference for worker 699 is 1.356118
INFO:root:FL Epoch: 224 Done on worker:699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :206
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.465106
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.232861
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 224 Norm Difference for worker 206 is 1.285276
INFO:root:FL Epoch: 224 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1820
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.811646
INFO:root:Worker: 1820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338192
INFO:root:FL Epoch: 224 Norm Difference for worker 1820 is 1.382311
INFO:root:FL Epoch: 224 Done on worker:1820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1414
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569813
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294967
INFO:root:FL Epoch: 224 Norm Difference for worker 1414 is 1.343714
INFO:root:FL Epoch: 224 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :474
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503087
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486167
INFO:root:FL Epoch: 224 Norm Difference for worker 474 is 1.414157
INFO:root:FL Epoch: 224 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :7
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 7 Train Epoch: 0 [0/201 (0%)]	Loss: 0.654172
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 7 Train Epoch: 1 [0/201 (0%)]	Loss: 0.354352
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 224 Norm Difference for worker 7 is 1.452255
INFO:root:FL Epoch: 224 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1914
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683884
INFO:root:Worker: 1914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339143
INFO:root:FL Epoch: 224 Norm Difference for worker 1914 is 1.345962
INFO:root:FL Epoch: 224 Done on worker:1914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :865
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392443
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579735
INFO:root:FL Epoch: 224 Norm Difference for worker 865 is 1.382947
INFO:root:FL Epoch: 224 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :249
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 249 Train Epoch: 0 [0/201 (0%)]	Loss: 0.580982
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 249 Train Epoch: 1 [0/201 (0%)]	Loss: 0.445804
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 224 Norm Difference for worker 249 is 1.31592
INFO:root:FL Epoch: 224 Done on worker:249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 206
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 224 Ends   ===================
INFO:root:Epoch:224 Global Model Test Loss:0.5477368691388298 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:224 Global Model Backdoor Test Loss:0.43506498138109845                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 225 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 225 Workers Selected : [1399, 693, 1217, 70, 496, 407, 317, 98, 1286, 1251]
INFO:root:FL Epoch: 225 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 225 Num points on workers: [200 200 200 201 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 225 Training on worker :1399
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578165
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260502
INFO:root:FL Epoch: 225 Norm Difference for worker 1399 is 1.378164
INFO:root:FL Epoch: 225 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :693
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296799
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381906
INFO:root:FL Epoch: 225 Norm Difference for worker 693 is 1.329147
INFO:root:FL Epoch: 225 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1217
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636741
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513357
INFO:root:FL Epoch: 225 Norm Difference for worker 1217 is 1.379646
INFO:root:FL Epoch: 225 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :70
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.499136
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483778
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 225 Norm Difference for worker 70 is 1.321951
INFO:root:FL Epoch: 225 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :496
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727254
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496370
INFO:root:FL Epoch: 225 Norm Difference for worker 496 is 1.391299
INFO:root:FL Epoch: 225 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :407
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344320
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272989
INFO:root:FL Epoch: 225 Norm Difference for worker 407 is 1.258421
INFO:root:FL Epoch: 225 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :317
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 317 Train Epoch: 0 [0/201 (0%)]	Loss: 0.648861
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 317 Train Epoch: 1 [0/201 (0%)]	Loss: 0.311057
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 225 Norm Difference for worker 317 is 1.423812
INFO:root:FL Epoch: 225 Done on worker:317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :98
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.741487
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.438325
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 225 Norm Difference for worker 98 is 1.408533
INFO:root:FL Epoch: 225 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1286
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376898
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480112
INFO:root:FL Epoch: 225 Norm Difference for worker 1286 is 1.403715
INFO:root:FL Epoch: 225 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1251
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563526
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283101
INFO:root:FL Epoch: 225 Norm Difference for worker 1251 is 1.401513
INFO:root:FL Epoch: 225 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 407
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 225 Ends   ===================
INFO:root:Epoch:225 Global Model Test Loss:0.5455652054618386 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:225 Global Model Backdoor Test Loss:0.575372780362765                             and Backdoor Test Accuracy:70.0 
INFO:root:=======================================================
INFO:root:================FL round 226 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 226 Workers Selected : [1748, 1403, 1456, 1021, 1824, 311, 906, 1618, 900, 1277]
INFO:root:FL Epoch: 226 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 226 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 226 Training on worker :1748
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550299
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532516
INFO:root:FL Epoch: 226 Norm Difference for worker 1748 is 1.422715
INFO:root:FL Epoch: 226 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1403
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.848918
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501018
INFO:root:FL Epoch: 226 Norm Difference for worker 1403 is 1.367213
INFO:root:FL Epoch: 226 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1456
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775196
INFO:root:Worker: 1456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447447
INFO:root:FL Epoch: 226 Norm Difference for worker 1456 is 1.292009
INFO:root:FL Epoch: 226 Done on worker:1456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1021
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625349
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423834
INFO:root:FL Epoch: 226 Norm Difference for worker 1021 is 1.332556
INFO:root:FL Epoch: 226 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1824
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.941710
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512528
INFO:root:FL Epoch: 226 Norm Difference for worker 1824 is 1.375602
INFO:root:FL Epoch: 226 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :311
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.515864
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.392519
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 226 Norm Difference for worker 311 is 1.327042
INFO:root:FL Epoch: 226 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :906
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427171
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353359
INFO:root:FL Epoch: 226 Norm Difference for worker 906 is 1.252714
INFO:root:FL Epoch: 226 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1618
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.921090
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290168
INFO:root:FL Epoch: 226 Norm Difference for worker 1618 is 1.317871
INFO:root:FL Epoch: 226 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :900
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495370
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392645
INFO:root:FL Epoch: 226 Norm Difference for worker 900 is 1.338098
INFO:root:FL Epoch: 226 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1277
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523398
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193170
INFO:root:FL Epoch: 226 Norm Difference for worker 1277 is 1.339568
INFO:root:FL Epoch: 226 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 906
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 226 Ends   ===================
INFO:root:Epoch:226 Global Model Test Loss:0.5854503512382507 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:226 Global Model Backdoor Test Loss:0.7260442872842153                             and Backdoor Test Accuracy:62.5 
INFO:root:=======================================================
INFO:root:================FL round 227 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 227 Workers Selected : [1930, 1641, 786, 1944, 949, 161, 1024, 860, 79, 1497]
INFO:root:FL Epoch: 227 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 227 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 227 Training on worker :1930
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612194
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475753
INFO:root:FL Epoch: 227 Norm Difference for worker 1930 is 1.398986
INFO:root:FL Epoch: 227 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1641
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.874637
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234008
INFO:root:FL Epoch: 227 Norm Difference for worker 1641 is 1.39544
INFO:root:FL Epoch: 227 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :786
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763998
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340617
INFO:root:FL Epoch: 227 Norm Difference for worker 786 is 1.573485
INFO:root:FL Epoch: 227 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1944
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442008
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324507
INFO:root:FL Epoch: 227 Norm Difference for worker 1944 is 1.402972
INFO:root:FL Epoch: 227 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :949
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.765020
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613078
INFO:root:FL Epoch: 227 Norm Difference for worker 949 is 1.491059
INFO:root:FL Epoch: 227 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :161
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629685
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.365915
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 161 is 1.344574
INFO:root:FL Epoch: 227 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1024
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681181
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594641
INFO:root:FL Epoch: 227 Norm Difference for worker 1024 is 1.527867
INFO:root:FL Epoch: 227 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :860
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782822
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361622
INFO:root:FL Epoch: 227 Norm Difference for worker 860 is 1.437677
INFO:root:FL Epoch: 227 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :79
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.636703
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.484389
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 79 is 1.420395
INFO:root:FL Epoch: 227 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1497
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420173
INFO:root:Worker: 1497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460496
INFO:root:FL Epoch: 227 Norm Difference for worker 1497 is 1.414257
INFO:root:FL Epoch: 227 Done on worker:1497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 161
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 227 Ends   ===================
INFO:root:Epoch:227 Global Model Test Loss:0.5490745744284462 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:227 Global Model Backdoor Test Loss:0.5674492865800858                             and Backdoor Test Accuracy:70.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 228 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 228 Workers Selected : [533, 1370, 1778, 376, 1688, 1791, 744, 605, 1458, 452]
INFO:root:FL Epoch: 228 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 228 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 228 Training on worker :533
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619806
INFO:root:Worker: 533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445583
INFO:root:FL Epoch: 228 Norm Difference for worker 533 is 1.406453
INFO:root:FL Epoch: 228 Done on worker:533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1370
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.254637
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395638
INFO:root:FL Epoch: 228 Norm Difference for worker 1370 is 1.264157
INFO:root:FL Epoch: 228 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1778
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.786939
INFO:root:Worker: 1778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325064
INFO:root:FL Epoch: 228 Norm Difference for worker 1778 is 1.332209
INFO:root:FL Epoch: 228 Done on worker:1778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :376
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807257
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529836
INFO:root:FL Epoch: 228 Norm Difference for worker 376 is 1.277961
INFO:root:FL Epoch: 228 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1688
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460575
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553249
INFO:root:FL Epoch: 228 Norm Difference for worker 1688 is 1.277578
INFO:root:FL Epoch: 228 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1791
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548598
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270447
INFO:root:FL Epoch: 228 Norm Difference for worker 1791 is 1.364017
INFO:root:FL Epoch: 228 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :744
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419181
INFO:root:Worker: 744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329948
INFO:root:FL Epoch: 228 Norm Difference for worker 744 is 1.262082
INFO:root:FL Epoch: 228 Done on worker:744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :605
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526239
INFO:root:Worker: 605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311860
INFO:root:FL Epoch: 228 Norm Difference for worker 605 is 1.246869
INFO:root:FL Epoch: 228 Done on worker:605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1458
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450488
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457463
INFO:root:FL Epoch: 228 Norm Difference for worker 1458 is 1.2752
INFO:root:FL Epoch: 228 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :452
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672975
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216771
INFO:root:FL Epoch: 228 Norm Difference for worker 452 is 1.293444
INFO:root:FL Epoch: 228 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1688
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 228 Ends   ===================
INFO:root:Epoch:228 Global Model Test Loss:0.5554435375858756 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:228 Global Model Backdoor Test Loss:0.4879031876722972                             and Backdoor Test Accuracy:77.5 
INFO:root:=======================================================
INFO:root:================FL round 229 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 229 Workers Selected : [173, 1917, 1341, 789, 961, 1601, 1755, 1597, 1906, 545]
INFO:root:FL Epoch: 229 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 229 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 229 Training on worker :173
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.509920
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.441667
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 229 Norm Difference for worker 173 is 1.279565
INFO:root:FL Epoch: 229 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1917
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459783
INFO:root:Worker: 1917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456124
INFO:root:FL Epoch: 229 Norm Difference for worker 1917 is 1.281627
INFO:root:FL Epoch: 229 Done on worker:1917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1341
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689600
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568310
INFO:root:FL Epoch: 229 Norm Difference for worker 1341 is 1.306376
INFO:root:FL Epoch: 229 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :789
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422332
INFO:root:Worker: 789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379369
INFO:root:FL Epoch: 229 Norm Difference for worker 789 is 1.214745
INFO:root:FL Epoch: 229 Done on worker:789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :961
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794902
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645364
INFO:root:FL Epoch: 229 Norm Difference for worker 961 is 1.315838
INFO:root:FL Epoch: 229 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1601
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.793664
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421359
INFO:root:FL Epoch: 229 Norm Difference for worker 1601 is 1.164239
INFO:root:FL Epoch: 229 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1755
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499887
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365989
INFO:root:FL Epoch: 229 Norm Difference for worker 1755 is 1.220499
INFO:root:FL Epoch: 229 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1597
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612355
INFO:root:Worker: 1597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463500
INFO:root:FL Epoch: 229 Norm Difference for worker 1597 is 1.152214
INFO:root:FL Epoch: 229 Done on worker:1597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1906
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592301
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403989
INFO:root:FL Epoch: 229 Norm Difference for worker 1906 is 1.230184
INFO:root:FL Epoch: 229 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :545
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634880
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370630
INFO:root:FL Epoch: 229 Norm Difference for worker 545 is 1.273112
INFO:root:FL Epoch: 229 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1597
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 229 Ends   ===================
INFO:root:Epoch:229 Global Model Test Loss:0.5562029761426589 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:229 Global Model Backdoor Test Loss:0.5910740941762924                             and Backdoor Test Accuracy:73.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 230 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 230 Workers Selected : [97, 1517, 1598, 1172, 189, 1585, 1215, 439, 573, 1311]
INFO:root:FL Epoch: 230 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 230 Num points on workers: [201 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 230 Training on worker :97
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.850766
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.273171
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 97 is 1.295074
INFO:root:FL Epoch: 230 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1517
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576112
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359927
INFO:root:FL Epoch: 230 Norm Difference for worker 1517 is 1.243115
INFO:root:FL Epoch: 230 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1598
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705095
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395596
INFO:root:FL Epoch: 230 Norm Difference for worker 1598 is 1.227737
INFO:root:FL Epoch: 230 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1172
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1172 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385968
INFO:root:Worker: 1172 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313456
INFO:root:FL Epoch: 230 Norm Difference for worker 1172 is 1.360443
INFO:root:FL Epoch: 230 Done on worker:1172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :189
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.969626
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.341389
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 189 is 1.284737
INFO:root:FL Epoch: 230 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1585
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516953
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474298
INFO:root:FL Epoch: 230 Norm Difference for worker 1585 is 1.300261
INFO:root:FL Epoch: 230 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1215
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634632
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394041
INFO:root:FL Epoch: 230 Norm Difference for worker 1215 is 1.297788
INFO:root:FL Epoch: 230 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :439
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636515
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369081
INFO:root:FL Epoch: 230 Norm Difference for worker 439 is 1.212233
INFO:root:FL Epoch: 230 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :573
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724696
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453078
INFO:root:FL Epoch: 230 Norm Difference for worker 573 is 1.36868
INFO:root:FL Epoch: 230 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1311
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682538
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423408
INFO:root:FL Epoch: 230 Norm Difference for worker 1311 is 1.277407
INFO:root:FL Epoch: 230 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1598
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 230 Ends   ===================
INFO:root:Epoch:230 Global Model Test Loss:0.5285251052940593 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:230 Global Model Backdoor Test Loss:0.5404614706834158                             and Backdoor Test Accuracy:68.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 231 Begins ===================
INFO:root:FL Epoch: 231 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 231 Workers Selected : [0, 1, 2, 1693, 599, 1613, 1374, 698, 1310, 1539]
INFO:root:FL Epoch: 231 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 231 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 231 Training on worker :0
INFO:root:FL Epoch: 231 Using Learning rate : 0.006309929342189997 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373059
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286032
INFO:root:FL Epoch: 231 Worker: 0 Backdoor Test Loss: 0.2708718205491702 Backdoor Test Accuracy: 91.66666666666667
INFO:root:FL Epoch: 231 Worker: 0 Backdoor Train Loss: 0.2803961217403412 Backdoor Train Accuracy: 91.5
INFO:root:FL Epoch: 231 Norm Difference for worker 0 is 0.348621
INFO:root:FL Epoch: 231 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1
INFO:root:FL Epoch: 231 Using Learning rate : 0.006309929342189997 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500097
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301358
INFO:root:FL Epoch: 231 Worker: 1 Backdoor Test Loss: 0.2690608849128087 Backdoor Test Accuracy: 91.66666666666667
INFO:root:FL Epoch: 231 Worker: 1 Backdoor Train Loss: 0.28231020718812944 Backdoor Train Accuracy: 90.5
INFO:root:FL Epoch: 231 Norm Difference for worker 1 is 0.34451
INFO:root:FL Epoch: 231 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :2
INFO:root:FL Epoch: 231 Using Learning rate : 0.006309929342189997 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470913
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412834
INFO:root:FL Epoch: 231 Worker: 2 Backdoor Test Loss: 0.26128631085157394 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 231 Worker: 2 Backdoor Train Loss: 0.28550633788108826 Backdoor Train Accuracy: 90.5
INFO:root:FL Epoch: 231 Norm Difference for worker 2 is 0.340799
INFO:root:FL Epoch: 231 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1693
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466284
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562238
INFO:root:FL Epoch: 231 Norm Difference for worker 1693 is 1.137532
INFO:root:FL Epoch: 231 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :599
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579281
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379687
INFO:root:FL Epoch: 231 Norm Difference for worker 599 is 1.229263
INFO:root:FL Epoch: 231 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1613
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402803
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311636
INFO:root:FL Epoch: 231 Norm Difference for worker 1613 is 1.22197
INFO:root:FL Epoch: 231 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1374
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603002
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463785
INFO:root:FL Epoch: 231 Norm Difference for worker 1374 is 1.216498
INFO:root:FL Epoch: 231 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :698
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399792
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411738
INFO:root:FL Epoch: 231 Norm Difference for worker 698 is 1.219768
INFO:root:FL Epoch: 231 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1310
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1310 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610684
INFO:root:Worker: 1310 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395999
INFO:root:FL Epoch: 231 Norm Difference for worker 1310 is 1.18862
INFO:root:FL Epoch: 231 Done on worker:1310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1539
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761715
INFO:root:Worker: 1539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422897
INFO:root:FL Epoch: 231 Norm Difference for worker 1539 is 1.250501
INFO:root:FL Epoch: 231 Done on worker:1539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 231 Ends   ===================
INFO:root:Epoch:231 Global Model Test Loss:0.5296286730205312 and Test Accuracy:75.0 
INFO:root:Epoch:231 Global Model Backdoor Test Loss:0.2690608849128087                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 232 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 232 Workers Selected : [1528, 546, 1315, 41, 504, 250, 655, 1640, 1386, 46]
INFO:root:FL Epoch: 232 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 232 Num points on workers: [200 200 200 201 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 232 Training on worker :1528
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523659
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376380
INFO:root:FL Epoch: 232 Norm Difference for worker 1528 is 1.140783
INFO:root:FL Epoch: 232 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :546
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495650
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411305
INFO:root:FL Epoch: 232 Norm Difference for worker 546 is 1.30659
INFO:root:FL Epoch: 232 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1315
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399273
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304881
INFO:root:FL Epoch: 232 Norm Difference for worker 1315 is 1.26326
INFO:root:FL Epoch: 232 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :41
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 41 Train Epoch: 0 [0/201 (0%)]	Loss: 0.528635
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 41 Train Epoch: 1 [0/201 (0%)]	Loss: 0.362225
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 232 Norm Difference for worker 41 is 1.281883
INFO:root:FL Epoch: 232 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :504
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685512
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422348
INFO:root:FL Epoch: 232 Norm Difference for worker 504 is 1.274454
INFO:root:FL Epoch: 232 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :250
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.714766
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.319918
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 232 Norm Difference for worker 250 is 1.23996
INFO:root:FL Epoch: 232 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :655
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520072
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477193
INFO:root:FL Epoch: 232 Norm Difference for worker 655 is 1.280394
INFO:root:FL Epoch: 232 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1640
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763531
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439244
INFO:root:FL Epoch: 232 Norm Difference for worker 1640 is 1.328632
INFO:root:FL Epoch: 232 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1386
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522472
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461159
INFO:root:FL Epoch: 232 Norm Difference for worker 1386 is 1.292213
INFO:root:FL Epoch: 232 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :46
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676475
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.365813
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 232 Norm Difference for worker 46 is 1.247848
INFO:root:FL Epoch: 232 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1528
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 232 Ends   ===================
INFO:root:Epoch:232 Global Model Test Loss:0.5396976558601155 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:232 Global Model Backdoor Test Loss:0.527231976389885                             and Backdoor Test Accuracy:69.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 233 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 233 Workers Selected : [1149, 529, 986, 911, 260, 855, 478, 1001, 407, 1886]
INFO:root:FL Epoch: 233 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 233 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 233 Training on worker :1149
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.820900
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278367
INFO:root:FL Epoch: 233 Norm Difference for worker 1149 is 1.342741
INFO:root:FL Epoch: 233 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :529
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407299
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368864
INFO:root:FL Epoch: 233 Norm Difference for worker 529 is 1.278203
INFO:root:FL Epoch: 233 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :986
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304987
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338699
INFO:root:FL Epoch: 233 Norm Difference for worker 986 is 1.431021
INFO:root:FL Epoch: 233 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :911
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657646
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296352
INFO:root:FL Epoch: 233 Norm Difference for worker 911 is 1.325678
INFO:root:FL Epoch: 233 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :260
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.579722
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.566645
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 233 Norm Difference for worker 260 is 1.267182
INFO:root:FL Epoch: 233 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :855
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640042
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648718
INFO:root:FL Epoch: 233 Norm Difference for worker 855 is 1.419433
INFO:root:FL Epoch: 233 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :478
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.910185
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297673
INFO:root:FL Epoch: 233 Norm Difference for worker 478 is 1.35263
INFO:root:FL Epoch: 233 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1001
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1001 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507796
INFO:root:Worker: 1001 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561617
INFO:root:FL Epoch: 233 Norm Difference for worker 1001 is 1.394784
INFO:root:FL Epoch: 233 Done on worker:1001
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :407
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430756
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342256
INFO:root:FL Epoch: 233 Norm Difference for worker 407 is 0.99495
INFO:root:FL Epoch: 233 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1886
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657226
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310193
INFO:root:FL Epoch: 233 Norm Difference for worker 1886 is 1.327762
INFO:root:FL Epoch: 233 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 407
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 233 Ends   ===================
INFO:root:Epoch:233 Global Model Test Loss:0.5671314579599044 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:233 Global Model Backdoor Test Loss:0.5936626940965652                             and Backdoor Test Accuracy:64.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 234 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 234 Workers Selected : [1640, 942, 389, 907, 1081, 1797, 1890, 922, 1593, 1411]
INFO:root:FL Epoch: 234 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 234 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 234 Training on worker :1640
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526368
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521869
INFO:root:FL Epoch: 234 Norm Difference for worker 1640 is 1.550697
INFO:root:FL Epoch: 234 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :942
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352803
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372067
INFO:root:FL Epoch: 234 Norm Difference for worker 942 is 1.566463
INFO:root:FL Epoch: 234 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :389
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452031
INFO:root:Worker: 389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284369
INFO:root:FL Epoch: 234 Norm Difference for worker 389 is 1.534774
INFO:root:FL Epoch: 234 Done on worker:389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :907
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626617
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478975
INFO:root:FL Epoch: 234 Norm Difference for worker 907 is 1.655973
INFO:root:FL Epoch: 234 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1081
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583581
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468278
INFO:root:FL Epoch: 234 Norm Difference for worker 1081 is 1.669025
INFO:root:FL Epoch: 234 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1797
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.934148
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392589
INFO:root:FL Epoch: 234 Norm Difference for worker 1797 is 1.718801
INFO:root:FL Epoch: 234 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1890
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702273
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353388
INFO:root:FL Epoch: 234 Norm Difference for worker 1890 is 1.611426
INFO:root:FL Epoch: 234 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :922
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466278
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645686
INFO:root:FL Epoch: 234 Norm Difference for worker 922 is 1.672141
INFO:root:FL Epoch: 234 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1593
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366340
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282521
INFO:root:FL Epoch: 234 Norm Difference for worker 1593 is 1.520279
INFO:root:FL Epoch: 234 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1411
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745555
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463010
INFO:root:FL Epoch: 234 Norm Difference for worker 1411 is 1.557464
INFO:root:FL Epoch: 234 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1640
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 234 Ends   ===================
INFO:root:Epoch:234 Global Model Test Loss:0.5645190670209772 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:234 Global Model Backdoor Test Loss:0.6891538500785828                             and Backdoor Test Accuracy:57.5 
INFO:root:=======================================================
INFO:root:================FL round 235 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 235 Workers Selected : [1678, 1654, 1413, 547, 1443, 144, 892, 191, 340, 1558]
INFO:root:FL Epoch: 235 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 235 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 235 Training on worker :1678
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.789378
INFO:root:Worker: 1678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.714584
INFO:root:FL Epoch: 235 Norm Difference for worker 1678 is 1.224403
INFO:root:FL Epoch: 235 Done on worker:1678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1654
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476604
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597674
INFO:root:FL Epoch: 235 Norm Difference for worker 1654 is 1.400881
INFO:root:FL Epoch: 235 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1413
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538100
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408521
INFO:root:FL Epoch: 235 Norm Difference for worker 1413 is 1.339814
INFO:root:FL Epoch: 235 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :547
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547741
INFO:root:Worker: 547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376803
INFO:root:FL Epoch: 235 Norm Difference for worker 547 is 1.370485
INFO:root:FL Epoch: 235 Done on worker:547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1443
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493400
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274174
INFO:root:FL Epoch: 235 Norm Difference for worker 1443 is 1.279524
INFO:root:FL Epoch: 235 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :144
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.726000
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.435675
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 235 Norm Difference for worker 144 is 1.268218
INFO:root:FL Epoch: 235 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :892
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487074
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439641
INFO:root:FL Epoch: 235 Norm Difference for worker 892 is 1.263019
INFO:root:FL Epoch: 235 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :191
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.809495
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.417436
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 235 Norm Difference for worker 191 is 1.289694
INFO:root:FL Epoch: 235 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :340
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556546
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480001
INFO:root:FL Epoch: 235 Norm Difference for worker 340 is 1.328715
INFO:root:FL Epoch: 235 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1558
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430808
INFO:root:Worker: 1558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462360
INFO:root:FL Epoch: 235 Norm Difference for worker 1558 is 1.371857
INFO:root:FL Epoch: 235 Done on worker:1558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1678
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 235 Ends   ===================
INFO:root:Epoch:235 Global Model Test Loss:0.5189029854886672 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:235 Global Model Backdoor Test Loss:0.48681477705637616                             and Backdoor Test Accuracy:72.5 
INFO:root:=======================================================
INFO:root:================FL round 236 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 236 Workers Selected : [1323, 1216, 1937, 432, 1511, 669, 1891, 1824, 228, 447]
INFO:root:FL Epoch: 236 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 236 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 236 Training on worker :1323
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517554
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428918
INFO:root:FL Epoch: 236 Norm Difference for worker 1323 is 1.295223
INFO:root:FL Epoch: 236 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1216
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1216 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437512
INFO:root:Worker: 1216 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577936
INFO:root:FL Epoch: 236 Norm Difference for worker 1216 is 1.300039
INFO:root:FL Epoch: 236 Done on worker:1216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1937
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625473
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471660
INFO:root:FL Epoch: 236 Norm Difference for worker 1937 is 1.345078
INFO:root:FL Epoch: 236 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :432
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559518
INFO:root:Worker: 432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620396
INFO:root:FL Epoch: 236 Norm Difference for worker 432 is 1.08507
INFO:root:FL Epoch: 236 Done on worker:432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1511
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559412
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604405
INFO:root:FL Epoch: 236 Norm Difference for worker 1511 is 1.237896
INFO:root:FL Epoch: 236 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :669
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463830
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614919
INFO:root:FL Epoch: 236 Norm Difference for worker 669 is 1.269726
INFO:root:FL Epoch: 236 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1891
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775501
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299855
INFO:root:FL Epoch: 236 Norm Difference for worker 1891 is 1.118713
INFO:root:FL Epoch: 236 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1824
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602764
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566552
INFO:root:FL Epoch: 236 Norm Difference for worker 1824 is 1.304143
INFO:root:FL Epoch: 236 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :228
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.424529
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.558688
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 228 is 1.229586
INFO:root:FL Epoch: 236 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :447
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636700
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443188
INFO:root:FL Epoch: 236 Norm Difference for worker 447 is 1.260598
INFO:root:FL Epoch: 236 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 432
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 236 Ends   ===================
INFO:root:Epoch:236 Global Model Test Loss:0.5053247230894425 and Test Accuracy:75.0 
INFO:root:Epoch:236 Global Model Backdoor Test Loss:0.6544951250155767                             and Backdoor Test Accuracy:63.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 237 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 237 Workers Selected : [400, 3, 1265, 532, 1836, 270, 1792, 1318, 159, 894]
INFO:root:FL Epoch: 237 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 237 Num points on workers: [200 201 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 237 Training on worker :400
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 400 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529899
INFO:root:Worker: 400 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446678
INFO:root:FL Epoch: 237 Norm Difference for worker 400 is 1.267597
INFO:root:FL Epoch: 237 Done on worker:400
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :3
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.614270
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.522162
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 237 Norm Difference for worker 3 is 1.238965
INFO:root:FL Epoch: 237 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1265
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513672
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501573
INFO:root:FL Epoch: 237 Norm Difference for worker 1265 is 1.22697
INFO:root:FL Epoch: 237 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :532
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 1.008497
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313609
INFO:root:FL Epoch: 237 Norm Difference for worker 532 is 1.274225
INFO:root:FL Epoch: 237 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1836
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566146
INFO:root:Worker: 1836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479308
INFO:root:FL Epoch: 237 Norm Difference for worker 1836 is 1.478196
INFO:root:FL Epoch: 237 Done on worker:1836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :270
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.448108
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.377368
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 237 Norm Difference for worker 270 is 1.238679
INFO:root:FL Epoch: 237 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1792
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617230
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435455
INFO:root:FL Epoch: 237 Norm Difference for worker 1792 is 1.113955
INFO:root:FL Epoch: 237 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1318
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708797
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600570
INFO:root:FL Epoch: 237 Norm Difference for worker 1318 is 1.25317
INFO:root:FL Epoch: 237 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :159
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.594222
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.399360
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 237 Norm Difference for worker 159 is 1.185207
INFO:root:FL Epoch: 237 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :894
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363684
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420369
INFO:root:FL Epoch: 237 Norm Difference for worker 894 is 1.265738
INFO:root:FL Epoch: 237 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1792
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 237 Ends   ===================
INFO:root:Epoch:237 Global Model Test Loss:0.514192695126814 and Test Accuracy:75.0 
INFO:root:Epoch:237 Global Model Backdoor Test Loss:0.8875016470750173                             and Backdoor Test Accuracy:47.5 
INFO:root:=======================================================
INFO:root:================FL round 238 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 238 Workers Selected : [91, 406, 1341, 1142, 961, 1634, 278, 1725, 1426, 171]
INFO:root:FL Epoch: 238 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 238 Num points on workers: [201 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 238 Training on worker :91
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.807687
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.378132
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 238 Norm Difference for worker 91 is 1.523862
INFO:root:FL Epoch: 238 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :406
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.844550
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605519
INFO:root:FL Epoch: 238 Norm Difference for worker 406 is 1.282761
INFO:root:FL Epoch: 238 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1341
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565181
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281788
INFO:root:FL Epoch: 238 Norm Difference for worker 1341 is 1.234234
INFO:root:FL Epoch: 238 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1142
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 1.163492
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456286
INFO:root:FL Epoch: 238 Norm Difference for worker 1142 is 1.272584
INFO:root:FL Epoch: 238 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :961
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440850
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364565
INFO:root:FL Epoch: 238 Norm Difference for worker 961 is 1.333143
INFO:root:FL Epoch: 238 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1634
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579335
INFO:root:Worker: 1634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236163
INFO:root:FL Epoch: 238 Norm Difference for worker 1634 is 1.745079
INFO:root:FL Epoch: 238 Done on worker:1634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :278
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.787893
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.718462
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 238 Norm Difference for worker 278 is 1.414531
INFO:root:FL Epoch: 238 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1725
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704746
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522928
INFO:root:FL Epoch: 238 Norm Difference for worker 1725 is 1.564332
INFO:root:FL Epoch: 238 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1426
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775866
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403386
INFO:root:FL Epoch: 238 Norm Difference for worker 1426 is 1.398328
INFO:root:FL Epoch: 238 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :171
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692260
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.734081
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 238 Norm Difference for worker 171 is 1.303065
INFO:root:FL Epoch: 238 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1341
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 238 Ends   ===================
INFO:root:Epoch:238 Global Model Test Loss:0.5513312238104203 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:238 Global Model Backdoor Test Loss:0.5050854335228602                             and Backdoor Test Accuracy:75.0 
INFO:root:=======================================================
INFO:root:================FL round 239 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 239 Workers Selected : [793, 1430, 1259, 83, 963, 727, 1798, 1045, 795, 1544]
INFO:root:FL Epoch: 239 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 239 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 239 Training on worker :793
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595940
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472530
INFO:root:FL Epoch: 239 Norm Difference for worker 793 is 1.123327
INFO:root:FL Epoch: 239 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1430
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703496
INFO:root:Worker: 1430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377630
INFO:root:FL Epoch: 239 Norm Difference for worker 1430 is 1.138306
INFO:root:FL Epoch: 239 Done on worker:1430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1259
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480106
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413742
INFO:root:FL Epoch: 239 Norm Difference for worker 1259 is 1.095287
INFO:root:FL Epoch: 239 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :83
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 83 Train Epoch: 0 [0/201 (0%)]	Loss: 0.533452
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 83 Train Epoch: 1 [0/201 (0%)]	Loss: 0.443540
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 83 is 1.165014
INFO:root:FL Epoch: 239 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :963
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 963 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521188
INFO:root:Worker: 963 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550338
INFO:root:FL Epoch: 239 Norm Difference for worker 963 is 1.178034
INFO:root:FL Epoch: 239 Done on worker:963
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :727
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.833366
INFO:root:Worker: 727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474424
INFO:root:FL Epoch: 239 Norm Difference for worker 727 is 1.194365
INFO:root:FL Epoch: 239 Done on worker:727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1798
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544666
INFO:root:Worker: 1798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503834
INFO:root:FL Epoch: 239 Norm Difference for worker 1798 is 1.172988
INFO:root:FL Epoch: 239 Done on worker:1798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1045
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627846
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456650
INFO:root:FL Epoch: 239 Norm Difference for worker 1045 is 1.051346
INFO:root:FL Epoch: 239 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :795
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492199
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328930
INFO:root:FL Epoch: 239 Norm Difference for worker 795 is 1.076728
INFO:root:FL Epoch: 239 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1544
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706021
INFO:root:Worker: 1544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624351
INFO:root:FL Epoch: 239 Norm Difference for worker 1544 is 1.204548
INFO:root:FL Epoch: 239 Done on worker:1544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 795
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 239 Ends   ===================
INFO:root:Epoch:239 Global Model Test Loss:0.5138264368562138 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:239 Global Model Backdoor Test Loss:0.7184774478276571                             and Backdoor Test Accuracy:60.0 
INFO:root:=======================================================
INFO:root:================FL round 240 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 240 Workers Selected : [1876, 1511, 1817, 696, 514, 724, 71, 1627, 1036, 1139]
INFO:root:FL Epoch: 240 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 240 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 240 Training on worker :1876
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428532
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451732
INFO:root:FL Epoch: 240 Norm Difference for worker 1876 is 1.262362
INFO:root:FL Epoch: 240 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1511
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666183
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540853
INFO:root:FL Epoch: 240 Norm Difference for worker 1511 is 1.315264
INFO:root:FL Epoch: 240 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1817
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.828071
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576838
INFO:root:FL Epoch: 240 Norm Difference for worker 1817 is 1.568931
INFO:root:FL Epoch: 240 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :696
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749871
INFO:root:Worker: 696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524841
INFO:root:FL Epoch: 240 Norm Difference for worker 696 is 1.215816
INFO:root:FL Epoch: 240 Done on worker:696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :514
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503308
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286525
INFO:root:FL Epoch: 240 Norm Difference for worker 514 is 1.138026
INFO:root:FL Epoch: 240 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :724
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443122
INFO:root:Worker: 724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437685
INFO:root:FL Epoch: 240 Norm Difference for worker 724 is 1.143734
INFO:root:FL Epoch: 240 Done on worker:724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :71
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.564573
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.489471
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 71 is 1.154164
INFO:root:FL Epoch: 240 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1627
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577171
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321969
INFO:root:FL Epoch: 240 Norm Difference for worker 1627 is 1.135629
INFO:root:FL Epoch: 240 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1036
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.840873
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565702
INFO:root:FL Epoch: 240 Norm Difference for worker 1036 is 1.209425
INFO:root:FL Epoch: 240 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1139
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557665
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357841
INFO:root:FL Epoch: 240 Norm Difference for worker 1139 is 1.230456
INFO:root:FL Epoch: 240 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1627
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 240 Ends   ===================
INFO:root:Epoch:240 Global Model Test Loss:0.5391491283388699 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:240 Global Model Backdoor Test Loss:0.7083017826080322                             and Backdoor Test Accuracy:58.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 241 Begins ===================
INFO:root:FL Epoch: 241 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 241 Workers Selected : [0, 1, 2, 431, 1920, 659, 855, 1679, 48, 359]
INFO:root:FL Epoch: 241 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 241 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 241 Training on worker :0
INFO:root:FL Epoch: 241 Using Learning rate : 0.006184860506246187 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540971
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330471
INFO:root:FL Epoch: 241 Worker: 0 Backdoor Test Loss: 0.237325352927049 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 241 Worker: 0 Backdoor Train Loss: 0.31500970423221586 Backdoor Train Accuracy: 87.5
INFO:root:FL Epoch: 241 Norm Difference for worker 0 is 0.409481
INFO:root:FL Epoch: 241 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1
INFO:root:FL Epoch: 241 Using Learning rate : 0.006184860506246187 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586355
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485073
INFO:root:FL Epoch: 241 Worker: 1 Backdoor Test Loss: 0.2669549236694972 Backdoor Test Accuracy: 91.66666666666667
INFO:root:FL Epoch: 241 Worker: 1 Backdoor Train Loss: 0.30846049785614016 Backdoor Train Accuracy: 88.0
INFO:root:FL Epoch: 241 Norm Difference for worker 1 is 0.396556
INFO:root:FL Epoch: 241 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :2
INFO:root:FL Epoch: 241 Using Learning rate : 0.006184860506246187 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599043
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289284
INFO:root:FL Epoch: 241 Worker: 2 Backdoor Test Loss: 0.2613206207752228 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 241 Worker: 2 Backdoor Train Loss: 0.3130163803696632 Backdoor Train Accuracy: 87.5
INFO:root:FL Epoch: 241 Norm Difference for worker 2 is 0.389876
INFO:root:FL Epoch: 241 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :431
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583790
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561327
INFO:root:FL Epoch: 241 Norm Difference for worker 431 is 1.213879
INFO:root:FL Epoch: 241 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1920
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656906
INFO:root:Worker: 1920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670605
INFO:root:FL Epoch: 241 Norm Difference for worker 1920 is 1.222865
INFO:root:FL Epoch: 241 Done on worker:1920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :659
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569800
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499370
INFO:root:FL Epoch: 241 Norm Difference for worker 659 is 1.267097
INFO:root:FL Epoch: 241 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :855
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780732
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479428
INFO:root:FL Epoch: 241 Norm Difference for worker 855 is 1.214548
INFO:root:FL Epoch: 241 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1679
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770832
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401049
INFO:root:FL Epoch: 241 Norm Difference for worker 1679 is 1.280173
INFO:root:FL Epoch: 241 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :48
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500341
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.392237
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 241 Norm Difference for worker 48 is 1.235948
INFO:root:FL Epoch: 241 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :359
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538196
INFO:root:Worker: 359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602903
INFO:root:FL Epoch: 241 Norm Difference for worker 359 is 1.192338
INFO:root:FL Epoch: 241 Done on worker:359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 241 Ends   ===================
INFO:root:Epoch:241 Global Model Test Loss:0.5379103387103361 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:241 Global Model Backdoor Test Loss:0.2613206207752228                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 242 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 242 Workers Selected : [1016, 758, 1919, 1693, 1465, 882, 176, 1854, 107, 77]
INFO:root:FL Epoch: 242 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 242 Num points on workers: [200 200 200 200 200 200 201 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 242 Training on worker :1016
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607503
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396799
INFO:root:FL Epoch: 242 Norm Difference for worker 1016 is 1.296141
INFO:root:FL Epoch: 242 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :758
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473468
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409714
INFO:root:FL Epoch: 242 Norm Difference for worker 758 is 1.292294
INFO:root:FL Epoch: 242 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1919
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416276
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522554
INFO:root:FL Epoch: 242 Norm Difference for worker 1919 is 1.30635
INFO:root:FL Epoch: 242 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1693
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443164
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420423
INFO:root:FL Epoch: 242 Norm Difference for worker 1693 is 1.230192
INFO:root:FL Epoch: 242 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1465
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554555
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313843
INFO:root:FL Epoch: 242 Norm Difference for worker 1465 is 1.259341
INFO:root:FL Epoch: 242 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :882
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377070
INFO:root:Worker: 882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474467
INFO:root:FL Epoch: 242 Norm Difference for worker 882 is 1.285659
INFO:root:FL Epoch: 242 Done on worker:882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :176
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 176 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581116
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 176 Train Epoch: 1 [0/201 (0%)]	Loss: 0.387248
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 176 is 1.298779
INFO:root:FL Epoch: 242 Done on worker:176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1854
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745421
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411264
INFO:root:FL Epoch: 242 Norm Difference for worker 1854 is 1.36692
INFO:root:FL Epoch: 242 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :107
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 107 Train Epoch: 0 [0/201 (0%)]	Loss: 0.813110
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 107 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431180
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 107 is 1.297537
INFO:root:FL Epoch: 242 Done on worker:107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :77
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.558406
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.432268
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 77 is 1.25283
INFO:root:FL Epoch: 242 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1693
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 242 Ends   ===================
INFO:root:Epoch:242 Global Model Test Loss:0.533108346602496 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:242 Global Model Backdoor Test Loss:0.2711196119586627                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 243 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 243 Workers Selected : [301, 961, 1081, 165, 1765, 96, 21, 425, 1827, 1721]
INFO:root:FL Epoch: 243 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994 0.1002994
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 243 Num points on workers: [201 200 200 201 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 243 Training on worker :301
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.645438
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.417306
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 243 Norm Difference for worker 301 is 1.186437
INFO:root:FL Epoch: 243 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :961
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781664
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374997
INFO:root:FL Epoch: 243 Norm Difference for worker 961 is 1.165926
INFO:root:FL Epoch: 243 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1081
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356001
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600399
INFO:root:FL Epoch: 243 Norm Difference for worker 1081 is 1.18874
INFO:root:FL Epoch: 243 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :165
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.539832
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.259058
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 243 Norm Difference for worker 165 is 1.171041
INFO:root:FL Epoch: 243 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1765
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551022
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417047
INFO:root:FL Epoch: 243 Norm Difference for worker 1765 is 1.143157
INFO:root:FL Epoch: 243 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :96
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 96 Train Epoch: 0 [0/201 (0%)]	Loss: 0.572546
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 96 Train Epoch: 1 [0/201 (0%)]	Loss: 0.555114
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 243 Norm Difference for worker 96 is 1.148154
INFO:root:FL Epoch: 243 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :21
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.475322
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.383507
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 243 Norm Difference for worker 21 is 1.155734
INFO:root:FL Epoch: 243 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :425
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 1.075496
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683469
INFO:root:FL Epoch: 243 Norm Difference for worker 425 is 1.178754
INFO:root:FL Epoch: 243 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1827
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599657
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416966
INFO:root:FL Epoch: 243 Norm Difference for worker 1827 is 1.129486
INFO:root:FL Epoch: 243 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1721
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356964
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453032
INFO:root:FL Epoch: 243 Norm Difference for worker 1721 is 1.094984
INFO:root:FL Epoch: 243 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1721
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 243 Ends   ===================
INFO:root:Epoch:243 Global Model Test Loss:0.525925890487783 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:243 Global Model Backdoor Test Loss:0.27043789873520535                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 244 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 244 Workers Selected : [617, 842, 851, 604, 1478, 1239, 1744, 1946, 1499, 1072]
INFO:root:FL Epoch: 244 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 244 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 244 Training on worker :617
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480128
INFO:root:Worker: 617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349427
INFO:root:FL Epoch: 244 Norm Difference for worker 617 is 1.187467
INFO:root:FL Epoch: 244 Done on worker:617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :842
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 842 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533854
INFO:root:Worker: 842 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480302
INFO:root:FL Epoch: 244 Norm Difference for worker 842 is 1.175433
INFO:root:FL Epoch: 244 Done on worker:842
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :851
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611611
INFO:root:Worker: 851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425151
INFO:root:FL Epoch: 244 Norm Difference for worker 851 is 1.094523
INFO:root:FL Epoch: 244 Done on worker:851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :604
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520556
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329016
INFO:root:FL Epoch: 244 Norm Difference for worker 604 is 1.151524
INFO:root:FL Epoch: 244 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1478
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476990
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336192
INFO:root:FL Epoch: 244 Norm Difference for worker 1478 is 1.152447
INFO:root:FL Epoch: 244 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1239
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694735
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449620
INFO:root:FL Epoch: 244 Norm Difference for worker 1239 is 1.230471
INFO:root:FL Epoch: 244 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1744
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516783
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528691
INFO:root:FL Epoch: 244 Norm Difference for worker 1744 is 1.129071
INFO:root:FL Epoch: 244 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1946
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699896
INFO:root:Worker: 1946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485922
INFO:root:FL Epoch: 244 Norm Difference for worker 1946 is 1.184228
INFO:root:FL Epoch: 244 Done on worker:1946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1499
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661831
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308570
INFO:root:FL Epoch: 244 Norm Difference for worker 1499 is 1.189988
INFO:root:FL Epoch: 244 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1072
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1072 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529238
INFO:root:Worker: 1072 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576973
INFO:root:FL Epoch: 244 Norm Difference for worker 1072 is 1.089673
INFO:root:FL Epoch: 244 Done on worker:1072
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1072
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 244 Ends   ===================
INFO:root:Epoch:244 Global Model Test Loss:0.5356176881229177 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:244 Global Model Backdoor Test Loss:0.2097932050625483                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 245 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 245 Workers Selected : [284, 629, 1483, 496, 1902, 261, 1691, 309, 195, 346]
INFO:root:FL Epoch: 245 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004
 0.1002994 0.1002994 0.0998004]
INFO:root:FL Epoch: 245 Num points on workers: [201 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 245 Training on worker :284
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.700783
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.374348
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 284 is 1.217516
INFO:root:FL Epoch: 245 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :629
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443032
INFO:root:Worker: 629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532447
INFO:root:FL Epoch: 245 Norm Difference for worker 629 is 1.18506
INFO:root:FL Epoch: 245 Done on worker:629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1483
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552448
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375212
INFO:root:FL Epoch: 245 Norm Difference for worker 1483 is 1.169582
INFO:root:FL Epoch: 245 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :496
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365572
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525334
INFO:root:FL Epoch: 245 Norm Difference for worker 496 is 1.214108
INFO:root:FL Epoch: 245 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1902
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396007
INFO:root:Worker: 1902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487271
INFO:root:FL Epoch: 245 Norm Difference for worker 1902 is 1.137126
INFO:root:FL Epoch: 245 Done on worker:1902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :261
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.735369
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.583486
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 261 is 1.310302
INFO:root:FL Epoch: 245 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1691
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623596
INFO:root:Worker: 1691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425513
INFO:root:FL Epoch: 245 Norm Difference for worker 1691 is 1.223164
INFO:root:FL Epoch: 245 Done on worker:1691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :309
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 309 Train Epoch: 0 [0/201 (0%)]	Loss: 0.661477
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 309 Train Epoch: 1 [0/201 (0%)]	Loss: 0.404125
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 309 is 1.200085
INFO:root:FL Epoch: 245 Done on worker:309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :195
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.528435
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.373688
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 195 is 1.200557
INFO:root:FL Epoch: 245 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :346
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572944
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444091
INFO:root:FL Epoch: 245 Norm Difference for worker 346 is 1.222143
INFO:root:FL Epoch: 245 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1902
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 245 Ends   ===================
INFO:root:Epoch:245 Global Model Test Loss:0.5330150022226221 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:245 Global Model Backdoor Test Loss:0.2399307812253634                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 246 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 246 Workers Selected : [1012, 1287, 1772, 973, 355, 15, 1335, 859, 1060, 1175]
INFO:root:FL Epoch: 246 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 246 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 246 Training on worker :1012
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447899
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258756
INFO:root:FL Epoch: 246 Norm Difference for worker 1012 is 1.258297
INFO:root:FL Epoch: 246 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1287
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1287 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720186
INFO:root:Worker: 1287 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334558
INFO:root:FL Epoch: 246 Norm Difference for worker 1287 is 1.31162
INFO:root:FL Epoch: 246 Done on worker:1287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1772
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618147
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555076
INFO:root:FL Epoch: 246 Norm Difference for worker 1772 is 1.296133
INFO:root:FL Epoch: 246 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :973
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480253
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379196
INFO:root:FL Epoch: 246 Norm Difference for worker 973 is 1.320639
INFO:root:FL Epoch: 246 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :355
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547421
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469882
INFO:root:FL Epoch: 246 Norm Difference for worker 355 is 1.266496
INFO:root:FL Epoch: 246 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :15
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.396991
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.404849
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 246 Norm Difference for worker 15 is 1.241944
INFO:root:FL Epoch: 246 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1335
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523470
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519897
INFO:root:FL Epoch: 246 Norm Difference for worker 1335 is 1.275826
INFO:root:FL Epoch: 246 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :859
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546650
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397186
INFO:root:FL Epoch: 246 Norm Difference for worker 859 is 1.230614
INFO:root:FL Epoch: 246 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1060
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1060 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718498
INFO:root:Worker: 1060 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457340
INFO:root:FL Epoch: 246 Norm Difference for worker 1060 is 1.450096
INFO:root:FL Epoch: 246 Done on worker:1060
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1175
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599099
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423625
INFO:root:FL Epoch: 246 Norm Difference for worker 1175 is 1.341905
INFO:root:FL Epoch: 246 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 859
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 246 Ends   ===================
INFO:root:Epoch:246 Global Model Test Loss:0.5590579772696775 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:246 Global Model Backdoor Test Loss:0.264550360540549                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 247 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 247 Workers Selected : [1026, 1386, 370, 1316, 1423, 1323, 1440, 374, 641, 685]
INFO:root:FL Epoch: 247 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 247 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 247 Training on worker :1026
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1026 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704000
INFO:root:Worker: 1026 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383048
INFO:root:FL Epoch: 247 Norm Difference for worker 1026 is 1.449368
INFO:root:FL Epoch: 247 Done on worker:1026
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1386
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705439
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271121
INFO:root:FL Epoch: 247 Norm Difference for worker 1386 is 1.284979
INFO:root:FL Epoch: 247 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :370
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725747
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591714
INFO:root:FL Epoch: 247 Norm Difference for worker 370 is 1.302212
INFO:root:FL Epoch: 247 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1316
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681753
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420799
INFO:root:FL Epoch: 247 Norm Difference for worker 1316 is 1.240105
INFO:root:FL Epoch: 247 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1423
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348652
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353316
INFO:root:FL Epoch: 247 Norm Difference for worker 1423 is 1.305359
INFO:root:FL Epoch: 247 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1323
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554158
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342159
INFO:root:FL Epoch: 247 Norm Difference for worker 1323 is 1.423279
INFO:root:FL Epoch: 247 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1440
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622632
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421822
INFO:root:FL Epoch: 247 Norm Difference for worker 1440 is 1.344982
INFO:root:FL Epoch: 247 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :374
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426427
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479404
INFO:root:FL Epoch: 247 Norm Difference for worker 374 is 1.311818
INFO:root:FL Epoch: 247 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :641
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741487
INFO:root:Worker: 641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391544
INFO:root:FL Epoch: 247 Norm Difference for worker 641 is 1.331476
INFO:root:FL Epoch: 247 Done on worker:641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :685
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686961
INFO:root:Worker: 685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386447
INFO:root:FL Epoch: 247 Norm Difference for worker 685 is 1.267322
INFO:root:FL Epoch: 247 Done on worker:685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1316
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 247 Ends   ===================
INFO:root:Epoch:247 Global Model Test Loss:0.5120061723624959 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:247 Global Model Backdoor Test Loss:0.27768342693646747                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 248 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 248 Workers Selected : [742, 885, 169, 1527, 884, 1072, 458, 1623, 1318, 1808]
INFO:root:FL Epoch: 248 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 248 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 248 Training on worker :742
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489936
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364102
INFO:root:FL Epoch: 248 Norm Difference for worker 742 is 1.23521
INFO:root:FL Epoch: 248 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :885
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.828426
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437346
INFO:root:FL Epoch: 248 Norm Difference for worker 885 is 1.206222
INFO:root:FL Epoch: 248 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :169
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.726152
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.832448
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 248 Norm Difference for worker 169 is 1.143779
INFO:root:FL Epoch: 248 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1527
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473358
INFO:root:Worker: 1527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420464
INFO:root:FL Epoch: 248 Norm Difference for worker 1527 is 1.125049
INFO:root:FL Epoch: 248 Done on worker:1527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :884
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713493
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410829
INFO:root:FL Epoch: 248 Norm Difference for worker 884 is 1.184189
INFO:root:FL Epoch: 248 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1072
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1072 Train Epoch: 0 [0/200 (0%)]	Loss: 0.249119
INFO:root:Worker: 1072 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238569
INFO:root:FL Epoch: 248 Norm Difference for worker 1072 is 0.925591
INFO:root:FL Epoch: 248 Done on worker:1072
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :458
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583826
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636740
INFO:root:FL Epoch: 248 Norm Difference for worker 458 is 1.292523
INFO:root:FL Epoch: 248 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1623
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685299
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439525
INFO:root:FL Epoch: 248 Norm Difference for worker 1623 is 1.285807
INFO:root:FL Epoch: 248 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1318
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775627
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.820300
INFO:root:FL Epoch: 248 Norm Difference for worker 1318 is 1.21682
INFO:root:FL Epoch: 248 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1808
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469691
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313243
INFO:root:FL Epoch: 248 Norm Difference for worker 1808 is 1.157592
INFO:root:FL Epoch: 248 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1072
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 248 Ends   ===================
INFO:root:Epoch:248 Global Model Test Loss:0.5225958368357491 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:248 Global Model Backdoor Test Loss:0.19142389173309007                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 249 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 249 Workers Selected : [1089, 1220, 832, 348, 1483, 1709, 170, 862, 1619, 52]
INFO:root:FL Epoch: 249 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 249 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 249 Training on worker :1089
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1089 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425821
INFO:root:Worker: 1089 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316389
INFO:root:FL Epoch: 249 Norm Difference for worker 1089 is 1.446572
INFO:root:FL Epoch: 249 Done on worker:1089
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1220
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453495
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425531
INFO:root:FL Epoch: 249 Norm Difference for worker 1220 is 1.367975
INFO:root:FL Epoch: 249 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :832
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587022
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290217
INFO:root:FL Epoch: 249 Norm Difference for worker 832 is 1.543819
INFO:root:FL Epoch: 249 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :348
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482772
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260930
INFO:root:FL Epoch: 249 Norm Difference for worker 348 is 1.408841
INFO:root:FL Epoch: 249 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1483
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626998
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286421
INFO:root:FL Epoch: 249 Norm Difference for worker 1483 is 1.319143
INFO:root:FL Epoch: 249 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1709
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510595
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293419
INFO:root:FL Epoch: 249 Norm Difference for worker 1709 is 1.313881
INFO:root:FL Epoch: 249 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :170
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.840302
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.417613
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 249 Norm Difference for worker 170 is 1.395507
INFO:root:FL Epoch: 249 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :862
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540861
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327677
INFO:root:FL Epoch: 249 Norm Difference for worker 862 is 1.363725
INFO:root:FL Epoch: 249 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1619
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582982
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481292
INFO:root:FL Epoch: 249 Norm Difference for worker 1619 is 1.411697
INFO:root:FL Epoch: 249 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :52
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 52 Train Epoch: 0 [0/201 (0%)]	Loss: 0.939403
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 52 Train Epoch: 1 [0/201 (0%)]	Loss: 0.464230
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 249 Norm Difference for worker 52 is 1.428088
INFO:root:FL Epoch: 249 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1483
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 249 Ends   ===================
INFO:root:Epoch:249 Global Model Test Loss:0.5140654365806019 and Test Accuracy:75.0 
INFO:root:Epoch:249 Global Model Backdoor Test Loss:0.20097131033738455                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 250 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 250 Workers Selected : [1159, 973, 918, 978, 1454, 1102, 762, 302, 1871, 580]
INFO:root:FL Epoch: 250 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 250 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 250 Training on worker :1159
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1159 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425962
INFO:root:Worker: 1159 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409373
INFO:root:FL Epoch: 250 Norm Difference for worker 1159 is 1.294731
INFO:root:FL Epoch: 250 Done on worker:1159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :973
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625242
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391288
INFO:root:FL Epoch: 250 Norm Difference for worker 973 is 1.505602
INFO:root:FL Epoch: 250 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :918
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.255128
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403794
INFO:root:FL Epoch: 250 Norm Difference for worker 918 is 1.457912
INFO:root:FL Epoch: 250 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :978
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 978 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386429
INFO:root:Worker: 978 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391203
INFO:root:FL Epoch: 250 Norm Difference for worker 978 is 1.367684
INFO:root:FL Epoch: 250 Done on worker:978
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1454
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.303974
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341591
INFO:root:FL Epoch: 250 Norm Difference for worker 1454 is 1.186382
INFO:root:FL Epoch: 250 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1102
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483336
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.929422
INFO:root:FL Epoch: 250 Norm Difference for worker 1102 is 2.144139
INFO:root:FL Epoch: 250 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :762
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 762 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672298
INFO:root:Worker: 762 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302686
INFO:root:FL Epoch: 250 Norm Difference for worker 762 is 1.411023
INFO:root:FL Epoch: 250 Done on worker:762
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :302
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.733418
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.469000
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 302 is 1.447483
INFO:root:FL Epoch: 250 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1871
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486184
INFO:root:Worker: 1871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238530
INFO:root:FL Epoch: 250 Norm Difference for worker 1871 is 1.538082
INFO:root:FL Epoch: 250 Done on worker:1871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :580
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.872951
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308487
INFO:root:FL Epoch: 250 Norm Difference for worker 580 is 1.551065
INFO:root:FL Epoch: 250 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1454
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 250 Ends   ===================
INFO:root:Epoch:250 Global Model Test Loss:0.536847850855659 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:250 Global Model Backdoor Test Loss:0.24960257609685263                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 251 Begins ===================
INFO:root:FL Epoch: 251 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 251 Workers Selected : [0, 1, 2, 1942, 848, 888, 1807, 655, 164, 302]
INFO:root:FL Epoch: 251 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 251 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 251 Training on worker :0
INFO:root:FL Epoch: 251 Using Learning rate : 0.0060622706542776406 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.174676
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354386
INFO:root:FL Epoch: 251 Worker: 0 Backdoor Test Loss: 0.15964868292212486 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 251 Worker: 0 Backdoor Train Loss: 0.24700271859765052 Backdoor Train Accuracy: 89.5
INFO:root:FL Epoch: 251 Norm Difference for worker 0 is 0.29422
INFO:root:FL Epoch: 251 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1
INFO:root:FL Epoch: 251 Using Learning rate : 0.0060622706542776406 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.167489
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229016
INFO:root:FL Epoch: 251 Worker: 1 Backdoor Test Loss: 0.1642716278632482 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 251 Worker: 1 Backdoor Train Loss: 0.2516506165266037 Backdoor Train Accuracy: 89.0
INFO:root:FL Epoch: 251 Norm Difference for worker 1 is 0.273848
INFO:root:FL Epoch: 251 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :2
INFO:root:FL Epoch: 251 Using Learning rate : 0.0060622706542776406 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389984
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406923
INFO:root:FL Epoch: 251 Worker: 2 Backdoor Test Loss: 0.1444983147084713 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 251 Worker: 2 Backdoor Train Loss: 0.24405881762504578 Backdoor Train Accuracy: 89.5
INFO:root:FL Epoch: 251 Norm Difference for worker 2 is 0.302333
INFO:root:FL Epoch: 251 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1942
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.943297
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468161
INFO:root:FL Epoch: 251 Norm Difference for worker 1942 is 1.512643
INFO:root:FL Epoch: 251 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :848
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685402
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359045
INFO:root:FL Epoch: 251 Norm Difference for worker 848 is 1.562358
INFO:root:FL Epoch: 251 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :888
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359208
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597449
INFO:root:FL Epoch: 251 Norm Difference for worker 888 is 1.546916
INFO:root:FL Epoch: 251 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1807
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 1807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461586
INFO:root:Worker: 1807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488393
INFO:root:FL Epoch: 251 Norm Difference for worker 1807 is 1.382721
INFO:root:FL Epoch: 251 Done on worker:1807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :655
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552302
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310512
INFO:root:FL Epoch: 251 Norm Difference for worker 655 is 1.368126
INFO:root:FL Epoch: 251 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :164
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 164 Train Epoch: 0 [0/201 (0%)]	Loss: 0.650221
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 164 Train Epoch: 1 [0/201 (0%)]	Loss: 0.334255
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 251 Norm Difference for worker 164 is 1.541883
INFO:root:FL Epoch: 251 Done on worker:164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :302
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.462238
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.509210
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 251 Norm Difference for worker 302 is 1.470433
INFO:root:FL Epoch: 251 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 251 Ends   ===================
INFO:root:Epoch:251 Global Model Test Loss:0.5381491464727065 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:251 Global Model Backdoor Test Loss:0.1642716278632482                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 252 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 252 Workers Selected : [410, 710, 1013, 60, 109, 1576, 931, 407, 697, 1217]
INFO:root:FL Epoch: 252 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 252 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 252 Training on worker :410
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714266
INFO:root:Worker: 410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476440
INFO:root:FL Epoch: 252 Norm Difference for worker 410 is 1.480883
INFO:root:FL Epoch: 252 Done on worker:410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :710
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416095
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470409
INFO:root:FL Epoch: 252 Norm Difference for worker 710 is 1.469352
INFO:root:FL Epoch: 252 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1013
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.858861
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548090
INFO:root:FL Epoch: 252 Norm Difference for worker 1013 is 1.631558
INFO:root:FL Epoch: 252 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :60
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 60 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517547
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 60 Train Epoch: 1 [0/201 (0%)]	Loss: 0.184235
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 252 Norm Difference for worker 60 is 1.431278
INFO:root:FL Epoch: 252 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :109
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 109 Train Epoch: 0 [0/201 (0%)]	Loss: 0.438883
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 109 Train Epoch: 1 [0/201 (0%)]	Loss: 0.221087
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 252 Norm Difference for worker 109 is 1.339406
INFO:root:FL Epoch: 252 Done on worker:109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1576
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485920
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532649
INFO:root:FL Epoch: 252 Norm Difference for worker 1576 is 1.630398
INFO:root:FL Epoch: 252 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :931
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734517
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418830
INFO:root:FL Epoch: 252 Norm Difference for worker 931 is 1.631207
INFO:root:FL Epoch: 252 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :407
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.206557
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261606
INFO:root:FL Epoch: 252 Norm Difference for worker 407 is 1.09717
INFO:root:FL Epoch: 252 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :697
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425483
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373075
INFO:root:FL Epoch: 252 Norm Difference for worker 697 is 1.662297
INFO:root:FL Epoch: 252 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1217
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.853355
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274078
INFO:root:FL Epoch: 252 Norm Difference for worker 1217 is 1.630144
INFO:root:FL Epoch: 252 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 407
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 252 Ends   ===================
INFO:root:Epoch:252 Global Model Test Loss:0.5670750333982355 and Test Accuracy:75.0 
INFO:root:Epoch:252 Global Model Backdoor Test Loss:0.20227512965599695                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 253 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 253 Workers Selected : [1299, 593, 1438, 1891, 1705, 1052, 1474, 550, 475, 1925]
INFO:root:FL Epoch: 253 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 253 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 253 Training on worker :1299
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1299 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685553
INFO:root:Worker: 1299 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231819
INFO:root:FL Epoch: 253 Norm Difference for worker 1299 is 1.616117
INFO:root:FL Epoch: 253 Done on worker:1299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :593
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648620
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286788
INFO:root:FL Epoch: 253 Norm Difference for worker 593 is 1.696612
INFO:root:FL Epoch: 253 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1438
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.908208
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446245
INFO:root:FL Epoch: 253 Norm Difference for worker 1438 is 1.56664
INFO:root:FL Epoch: 253 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1891
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401835
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218715
INFO:root:FL Epoch: 253 Norm Difference for worker 1891 is 1.644872
INFO:root:FL Epoch: 253 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1705
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530502
INFO:root:Worker: 1705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540784
INFO:root:FL Epoch: 253 Norm Difference for worker 1705 is 1.771562
INFO:root:FL Epoch: 253 Done on worker:1705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1052
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668625
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334143
INFO:root:FL Epoch: 253 Norm Difference for worker 1052 is 1.625255
INFO:root:FL Epoch: 253 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1474
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539690
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602336
INFO:root:FL Epoch: 253 Norm Difference for worker 1474 is 1.648946
INFO:root:FL Epoch: 253 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :550
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755161
INFO:root:Worker: 550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529954
INFO:root:FL Epoch: 253 Norm Difference for worker 550 is 1.74596
INFO:root:FL Epoch: 253 Done on worker:550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :475
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629239
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418984
INFO:root:FL Epoch: 253 Norm Difference for worker 475 is 1.610315
INFO:root:FL Epoch: 253 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1925
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510935
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524193
INFO:root:FL Epoch: 253 Norm Difference for worker 1925 is 1.672353
INFO:root:FL Epoch: 253 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1925
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 253 Ends   ===================
INFO:root:Epoch:253 Global Model Test Loss:0.5096016210668227 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:253 Global Model Backdoor Test Loss:0.35912658274173737                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 254 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 254 Workers Selected : [1628, 165, 671, 216, 620, 465, 72, 559, 886, 1530]
INFO:root:FL Epoch: 254 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 254 Num points on workers: [200 201 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 254 Training on worker :1628
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550762
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414088
INFO:root:FL Epoch: 254 Norm Difference for worker 1628 is 1.17987
INFO:root:FL Epoch: 254 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :165
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.736913
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.629388
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 254 Norm Difference for worker 165 is 1.232061
INFO:root:FL Epoch: 254 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :671
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628178
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364461
INFO:root:FL Epoch: 254 Norm Difference for worker 671 is 1.172584
INFO:root:FL Epoch: 254 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :216
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 216 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500358
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 216 Train Epoch: 1 [0/201 (0%)]	Loss: 0.418009
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 254 Norm Difference for worker 216 is 1.183583
INFO:root:FL Epoch: 254 Done on worker:216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :620
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336221
INFO:root:Worker: 620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339013
INFO:root:FL Epoch: 254 Norm Difference for worker 620 is 1.070943
INFO:root:FL Epoch: 254 Done on worker:620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :465
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458066
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474184
INFO:root:FL Epoch: 254 Norm Difference for worker 465 is 1.21606
INFO:root:FL Epoch: 254 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :72
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.504870
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450662
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 254 Norm Difference for worker 72 is 1.228954
INFO:root:FL Epoch: 254 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :559
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472861
INFO:root:Worker: 559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666722
INFO:root:FL Epoch: 254 Norm Difference for worker 559 is 1.223727
INFO:root:FL Epoch: 254 Done on worker:559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :886
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380771
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557425
INFO:root:FL Epoch: 254 Norm Difference for worker 886 is 1.190333
INFO:root:FL Epoch: 254 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1530
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664255
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406475
INFO:root:FL Epoch: 254 Norm Difference for worker 1530 is 1.262477
INFO:root:FL Epoch: 254 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 620
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 254 Ends   ===================
INFO:root:Epoch:254 Global Model Test Loss:0.5205443185918471 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:254 Global Model Backdoor Test Loss:0.3176511923472087                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 255 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 255 Workers Selected : [1536, 1204, 1550, 1139, 735, 1804, 1303, 856, 1587, 124]
INFO:root:FL Epoch: 255 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 255 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 255 Training on worker :1536
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.829765
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523271
INFO:root:FL Epoch: 255 Norm Difference for worker 1536 is 1.315029
INFO:root:FL Epoch: 255 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1204
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566644
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543303
INFO:root:FL Epoch: 255 Norm Difference for worker 1204 is 1.296611
INFO:root:FL Epoch: 255 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1550
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548203
INFO:root:Worker: 1550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463999
INFO:root:FL Epoch: 255 Norm Difference for worker 1550 is 1.325948
INFO:root:FL Epoch: 255 Done on worker:1550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1139
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479882
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507417
INFO:root:FL Epoch: 255 Norm Difference for worker 1139 is 1.338132
INFO:root:FL Epoch: 255 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :735
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 735 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600589
INFO:root:Worker: 735 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562070
INFO:root:FL Epoch: 255 Norm Difference for worker 735 is 1.334791
INFO:root:FL Epoch: 255 Done on worker:735
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1804
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393925
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515552
INFO:root:FL Epoch: 255 Norm Difference for worker 1804 is 1.362866
INFO:root:FL Epoch: 255 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1303
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321844
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414261
INFO:root:FL Epoch: 255 Norm Difference for worker 1303 is 1.309058
INFO:root:FL Epoch: 255 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :856
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307262
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484893
INFO:root:FL Epoch: 255 Norm Difference for worker 856 is 1.383032
INFO:root:FL Epoch: 255 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1587
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496734
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581661
INFO:root:FL Epoch: 255 Norm Difference for worker 1587 is 1.419711
INFO:root:FL Epoch: 255 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :124
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.363917
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.275514
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 255 Norm Difference for worker 124 is 1.326587
INFO:root:FL Epoch: 255 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1204
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 255 Ends   ===================
INFO:root:Epoch:255 Global Model Test Loss:0.5116188771584455 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:255 Global Model Backdoor Test Loss:0.33430542796850204                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 256 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 256 Workers Selected : [103, 47, 1805, 1280, 1599, 1088, 1092, 1468, 962, 1742]
INFO:root:FL Epoch: 256 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 256 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 256 Training on worker :103
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.484478
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.360524
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 256 Norm Difference for worker 103 is 1.310593
INFO:root:FL Epoch: 256 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :47
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 47 Train Epoch: 0 [0/201 (0%)]	Loss: 0.418565
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 47 Train Epoch: 1 [0/201 (0%)]	Loss: 0.364728
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 256 Norm Difference for worker 47 is 1.170882
INFO:root:FL Epoch: 256 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1805
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558139
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449494
INFO:root:FL Epoch: 256 Norm Difference for worker 1805 is 1.302017
INFO:root:FL Epoch: 256 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1280
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1280 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569174
INFO:root:Worker: 1280 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536658
INFO:root:FL Epoch: 256 Norm Difference for worker 1280 is 1.234028
INFO:root:FL Epoch: 256 Done on worker:1280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1599
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461358
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483269
INFO:root:FL Epoch: 256 Norm Difference for worker 1599 is 1.241737
INFO:root:FL Epoch: 256 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1088
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328143
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337749
INFO:root:FL Epoch: 256 Norm Difference for worker 1088 is 1.194443
INFO:root:FL Epoch: 256 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1092
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385294
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493562
INFO:root:FL Epoch: 256 Norm Difference for worker 1092 is 1.271142
INFO:root:FL Epoch: 256 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1468
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472341
INFO:root:Worker: 1468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297437
INFO:root:FL Epoch: 256 Norm Difference for worker 1468 is 1.252924
INFO:root:FL Epoch: 256 Done on worker:1468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :962
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458526
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485509
INFO:root:FL Epoch: 256 Norm Difference for worker 962 is 1.311753
INFO:root:FL Epoch: 256 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1742
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685608
INFO:root:Worker: 1742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392248
INFO:root:FL Epoch: 256 Norm Difference for worker 1742 is 1.27737
INFO:root:FL Epoch: 256 Done on worker:1742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1088
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 256 Ends   ===================
INFO:root:Epoch:256 Global Model Test Loss:0.5033038135837106 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:256 Global Model Backdoor Test Loss:0.37707571188608807                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 257 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 257 Workers Selected : [1087, 51, 352, 1760, 1518, 1886, 1418, 593, 803, 1360]
INFO:root:FL Epoch: 257 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 257 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 257 Training on worker :1087
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566175
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302630
INFO:root:FL Epoch: 257 Norm Difference for worker 1087 is 1.257795
INFO:root:FL Epoch: 257 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :51
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 51 Train Epoch: 0 [0/201 (0%)]	Loss: 0.571035
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 51 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450269
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 51 is 1.237319
INFO:root:FL Epoch: 257 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :352
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364049
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552987
INFO:root:FL Epoch: 257 Norm Difference for worker 352 is 1.359807
INFO:root:FL Epoch: 257 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :1760
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436189
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379007
INFO:root:FL Epoch: 257 Norm Difference for worker 1760 is 1.290037
INFO:root:FL Epoch: 257 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :1518
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319604
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423055
INFO:root:FL Epoch: 257 Norm Difference for worker 1518 is 1.249091
INFO:root:FL Epoch: 257 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :1886
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754710
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313172
INFO:root:FL Epoch: 257 Norm Difference for worker 1886 is 1.286775
INFO:root:FL Epoch: 257 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :1418
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654991
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421256
INFO:root:FL Epoch: 257 Norm Difference for worker 1418 is 1.253058
INFO:root:FL Epoch: 257 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :593
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419630
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425184
INFO:root:FL Epoch: 257 Norm Difference for worker 593 is 1.294622
INFO:root:FL Epoch: 257 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :803
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541016
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346915
INFO:root:FL Epoch: 257 Norm Difference for worker 803 is 1.247061
INFO:root:FL Epoch: 257 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :1360
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490831
INFO:root:Worker: 1360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310825
INFO:root:FL Epoch: 257 Norm Difference for worker 1360 is 1.298728
INFO:root:FL Epoch: 257 Done on worker:1360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 51
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 257 Ends   ===================
INFO:root:Epoch:257 Global Model Test Loss:0.46872198844657226 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:257 Global Model Backdoor Test Loss:0.3246040294567744                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 258 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 258 Workers Selected : [1472, 142, 686, 1238, 610, 438, 1853, 1371, 839, 1439]
INFO:root:FL Epoch: 258 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 258 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 258 Training on worker :1472
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.895008
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636275
INFO:root:FL Epoch: 258 Norm Difference for worker 1472 is 1.542928
INFO:root:FL Epoch: 258 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :142
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 142 Train Epoch: 0 [0/201 (0%)]	Loss: 0.907023
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 142 Train Epoch: 1 [0/201 (0%)]	Loss: 0.564516
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 258 Norm Difference for worker 142 is 1.620206
INFO:root:FL Epoch: 258 Done on worker:142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :686
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782313
INFO:root:Worker: 686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631010
INFO:root:FL Epoch: 258 Norm Difference for worker 686 is 1.338894
INFO:root:FL Epoch: 258 Done on worker:686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1238
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573774
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552238
INFO:root:FL Epoch: 258 Norm Difference for worker 1238 is 1.317559
INFO:root:FL Epoch: 258 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :610
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536456
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346306
INFO:root:FL Epoch: 258 Norm Difference for worker 610 is 1.34687
INFO:root:FL Epoch: 258 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :438
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617442
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293230
INFO:root:FL Epoch: 258 Norm Difference for worker 438 is 1.301047
INFO:root:FL Epoch: 258 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1853
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458757
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414007
INFO:root:FL Epoch: 258 Norm Difference for worker 1853 is 1.390474
INFO:root:FL Epoch: 258 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1371
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529401
INFO:root:Worker: 1371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399488
INFO:root:FL Epoch: 258 Norm Difference for worker 1371 is 1.296628
INFO:root:FL Epoch: 258 Done on worker:1371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :839
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.278698
INFO:root:Worker: 839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559124
INFO:root:FL Epoch: 258 Norm Difference for worker 839 is 1.347825
INFO:root:FL Epoch: 258 Done on worker:839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1439
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584411
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.863852
INFO:root:FL Epoch: 258 Norm Difference for worker 1439 is 1.380253
INFO:root:FL Epoch: 258 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1238
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 258 Ends   ===================
INFO:root:Epoch:258 Global Model Test Loss:0.47927072293618145 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:258 Global Model Backdoor Test Loss:0.3439459999402364                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 259 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 259 Workers Selected : [1354, 228, 462, 1636, 1046, 1188, 1882, 1003, 1658, 1075]
INFO:root:FL Epoch: 259 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 259 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 259 Training on worker :1354
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564172
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467905
INFO:root:FL Epoch: 259 Norm Difference for worker 1354 is 1.193581
INFO:root:FL Epoch: 259 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :228
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.477181
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446124
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 228 is 1.139635
INFO:root:FL Epoch: 259 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :462
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381414
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568430
INFO:root:FL Epoch: 259 Norm Difference for worker 462 is 1.176968
INFO:root:FL Epoch: 259 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1636
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813320
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544596
INFO:root:FL Epoch: 259 Norm Difference for worker 1636 is 1.256692
INFO:root:FL Epoch: 259 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1046
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1046 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410535
INFO:root:Worker: 1046 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347394
INFO:root:FL Epoch: 259 Norm Difference for worker 1046 is 1.153823
INFO:root:FL Epoch: 259 Done on worker:1046
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1188
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535723
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553603
INFO:root:FL Epoch: 259 Norm Difference for worker 1188 is 1.226603
INFO:root:FL Epoch: 259 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1882
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.850851
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315927
INFO:root:FL Epoch: 259 Norm Difference for worker 1882 is 1.114357
INFO:root:FL Epoch: 259 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1003
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687584
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284285
INFO:root:FL Epoch: 259 Norm Difference for worker 1003 is 1.143398
INFO:root:FL Epoch: 259 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1658
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692198
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386117
INFO:root:FL Epoch: 259 Norm Difference for worker 1658 is 1.122368
INFO:root:FL Epoch: 259 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1075
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432671
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380854
INFO:root:FL Epoch: 259 Norm Difference for worker 1075 is 1.14385
INFO:root:FL Epoch: 259 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1658
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 259 Ends   ===================
INFO:root:Epoch:259 Global Model Test Loss:0.5066260081880233 and Test Accuracy:75.0 
INFO:root:Epoch:259 Global Model Backdoor Test Loss:0.4471311767896016                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 260 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 260 Workers Selected : [160, 1460, 1369, 1465, 920, 167, 434, 908, 1014, 1614]
INFO:root:FL Epoch: 260 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 260 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 260 Training on worker :160
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.550186
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.329698
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 260 Norm Difference for worker 160 is 1.142305
INFO:root:FL Epoch: 260 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1460
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.274242
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.179846
INFO:root:FL Epoch: 260 Norm Difference for worker 1460 is 1.030944
INFO:root:FL Epoch: 260 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1369
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637796
INFO:root:Worker: 1369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511248
INFO:root:FL Epoch: 260 Norm Difference for worker 1369 is 1.178811
INFO:root:FL Epoch: 260 Done on worker:1369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1465
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714010
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493593
INFO:root:FL Epoch: 260 Norm Difference for worker 1465 is 1.229535
INFO:root:FL Epoch: 260 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :920
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598075
INFO:root:Worker: 920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505614
INFO:root:FL Epoch: 260 Norm Difference for worker 920 is 1.257602
INFO:root:FL Epoch: 260 Done on worker:920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :167
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 167 Train Epoch: 0 [0/201 (0%)]	Loss: 0.475269
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 167 Train Epoch: 1 [0/201 (0%)]	Loss: 0.400127
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 260 Norm Difference for worker 167 is 1.110518
INFO:root:FL Epoch: 260 Done on worker:167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :434
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.894958
INFO:root:Worker: 434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475232
INFO:root:FL Epoch: 260 Norm Difference for worker 434 is 1.171662
INFO:root:FL Epoch: 260 Done on worker:434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :908
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476336
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396973
INFO:root:FL Epoch: 260 Norm Difference for worker 908 is 1.129804
INFO:root:FL Epoch: 260 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1014
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343531
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224024
INFO:root:FL Epoch: 260 Norm Difference for worker 1014 is 1.05861
INFO:root:FL Epoch: 260 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1614
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582956
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558913
INFO:root:FL Epoch: 260 Norm Difference for worker 1614 is 1.248964
INFO:root:FL Epoch: 260 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1460
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 260 Ends   ===================
INFO:root:Epoch:260 Global Model Test Loss:0.4792990754632389 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:260 Global Model Backdoor Test Loss:0.3679888720313708                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 261 Begins ===================
INFO:root:FL Epoch: 261 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 261 Workers Selected : [0, 1, 2, 1377, 126, 1194, 362, 1279, 1826, 1404]
INFO:root:FL Epoch: 261 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 261 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 261 Training on worker :0
INFO:root:FL Epoch: 261 Using Learning rate : 0.005942110650450455 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355368
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589284
INFO:root:FL Epoch: 261 Worker: 0 Backdoor Test Loss: 0.15977737928430238 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 261 Worker: 0 Backdoor Train Loss: 0.22716167867183684 Backdoor Train Accuracy: 92.5
INFO:root:FL Epoch: 261 Norm Difference for worker 0 is 0.314704
INFO:root:FL Epoch: 261 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1
INFO:root:FL Epoch: 261 Using Learning rate : 0.005942110650450455 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.268183
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324955
INFO:root:FL Epoch: 261 Worker: 1 Backdoor Test Loss: 0.04958423847953478 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 261 Worker: 1 Backdoor Train Loss: 0.5888788744807243 Backdoor Train Accuracy: 77.5
INFO:root:FL Epoch: 261 Norm Difference for worker 1 is 0.372728
INFO:root:FL Epoch: 261 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :2
INFO:root:FL Epoch: 261 Using Learning rate : 0.005942110650450455 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339913
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219416
INFO:root:FL Epoch: 261 Worker: 2 Backdoor Test Loss: 0.14971712604165077 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 261 Worker: 2 Backdoor Train Loss: 0.23311944901943207 Backdoor Train Accuracy: 91.0
INFO:root:FL Epoch: 261 Norm Difference for worker 2 is 0.306355
INFO:root:FL Epoch: 261 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1377
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509276
INFO:root:Worker: 1377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294274
INFO:root:FL Epoch: 261 Norm Difference for worker 1377 is 1.391763
INFO:root:FL Epoch: 261 Done on worker:1377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :126
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.492154
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.387349
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 261 Norm Difference for worker 126 is 1.413264
INFO:root:FL Epoch: 261 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1194
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1194 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782188
INFO:root:Worker: 1194 Train Epoch: 1 [0/200 (0%)]	Loss: 1.267164
INFO:root:FL Epoch: 261 Norm Difference for worker 1194 is 1.959712
INFO:root:FL Epoch: 261 Done on worker:1194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :362
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369845
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391473
INFO:root:FL Epoch: 261 Norm Difference for worker 362 is 1.485656
INFO:root:FL Epoch: 261 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1279
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1279 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590822
INFO:root:Worker: 1279 Train Epoch: 1 [0/200 (0%)]	Loss: 0.769920
INFO:root:FL Epoch: 261 Norm Difference for worker 1279 is 1.333714
INFO:root:FL Epoch: 261 Done on worker:1279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1826
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343010
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284308
INFO:root:FL Epoch: 261 Norm Difference for worker 1826 is 1.261859
INFO:root:FL Epoch: 261 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1404
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.281491
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198632
INFO:root:FL Epoch: 261 Norm Difference for worker 1404 is 1.230902
INFO:root:FL Epoch: 261 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 261 Ends   ===================
INFO:root:Epoch:261 Global Model Test Loss:0.4821697631303002 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:261 Global Model Backdoor Test Loss:0.15977737928430238                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 262 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 262 Workers Selected : [228, 380, 1593, 1340, 838, 117, 48, 793, 1118, 1657]
INFO:root:FL Epoch: 262 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 262 Num points on workers: [201 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 262 Training on worker :228
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.345316
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.475342
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 228 is 1.351617
INFO:root:FL Epoch: 262 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :380
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707448
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421873
INFO:root:FL Epoch: 262 Norm Difference for worker 380 is 1.647992
INFO:root:FL Epoch: 262 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1593
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442554
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365834
INFO:root:FL Epoch: 262 Norm Difference for worker 1593 is 1.357791
INFO:root:FL Epoch: 262 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1340
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623401
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301461
INFO:root:FL Epoch: 262 Norm Difference for worker 1340 is 1.425688
INFO:root:FL Epoch: 262 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :838
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469454
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666676
INFO:root:FL Epoch: 262 Norm Difference for worker 838 is 1.526211
INFO:root:FL Epoch: 262 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :117
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541927
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.442587
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 117 is 1.42309
INFO:root:FL Epoch: 262 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :48
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.456062
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.288496
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 48 is 1.349406
INFO:root:FL Epoch: 262 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :793
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570099
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293176
INFO:root:FL Epoch: 262 Norm Difference for worker 793 is 1.421257
INFO:root:FL Epoch: 262 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1118
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1118 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372279
INFO:root:Worker: 1118 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279763
INFO:root:FL Epoch: 262 Norm Difference for worker 1118 is 1.424609
INFO:root:FL Epoch: 262 Done on worker:1118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1657
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572985
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374674
INFO:root:FL Epoch: 262 Norm Difference for worker 1657 is 1.502191
INFO:root:FL Epoch: 262 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 228
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 262 Ends   ===================
INFO:root:Epoch:262 Global Model Test Loss:0.502765474950566 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:262 Global Model Backdoor Test Loss:0.3486669212579727                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 263 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 263 Workers Selected : [1234, 729, 469, 846, 1600, 157, 1182, 1061, 1408, 650]
INFO:root:FL Epoch: 263 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 263 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 263 Training on worker :1234
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562033
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482967
INFO:root:FL Epoch: 263 Norm Difference for worker 1234 is 1.232596
INFO:root:FL Epoch: 263 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :729
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530491
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311263
INFO:root:FL Epoch: 263 Norm Difference for worker 729 is 1.31395
INFO:root:FL Epoch: 263 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :469
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465107
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353009
INFO:root:FL Epoch: 263 Norm Difference for worker 469 is 1.241825
INFO:root:FL Epoch: 263 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :846
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.257341
INFO:root:Worker: 846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476245
INFO:root:FL Epoch: 263 Norm Difference for worker 846 is 1.315785
INFO:root:FL Epoch: 263 Done on worker:846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1600
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.765120
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276818
INFO:root:FL Epoch: 263 Norm Difference for worker 1600 is 1.269698
INFO:root:FL Epoch: 263 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :157
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595603
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.584925
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 157 is 1.332825
INFO:root:FL Epoch: 263 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1182
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566427
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461984
INFO:root:FL Epoch: 263 Norm Difference for worker 1182 is 1.224475
INFO:root:FL Epoch: 263 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1061
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634957
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444194
INFO:root:FL Epoch: 263 Norm Difference for worker 1061 is 1.204636
INFO:root:FL Epoch: 263 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1408
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579566
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389904
INFO:root:FL Epoch: 263 Norm Difference for worker 1408 is 1.309648
INFO:root:FL Epoch: 263 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :650
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570374
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369309
INFO:root:FL Epoch: 263 Norm Difference for worker 650 is 1.273809
INFO:root:FL Epoch: 263 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1182
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 263 Ends   ===================
INFO:root:Epoch:263 Global Model Test Loss:0.49744170553543987 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:263 Global Model Backdoor Test Loss:0.3027389993270238                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 264 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 264 Workers Selected : [207, 542, 1793, 1161, 1832, 1180, 1370, 679, 1235, 562]
INFO:root:FL Epoch: 264 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 264 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 264 Training on worker :207
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.477805
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.593894
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 207 is 1.28518
INFO:root:FL Epoch: 264 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :542
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383388
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291388
INFO:root:FL Epoch: 264 Norm Difference for worker 542 is 1.08581
INFO:root:FL Epoch: 264 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1793
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486417
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429948
INFO:root:FL Epoch: 264 Norm Difference for worker 1793 is 1.179895
INFO:root:FL Epoch: 264 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1161
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1161 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749274
INFO:root:Worker: 1161 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563115
INFO:root:FL Epoch: 264 Norm Difference for worker 1161 is 1.197
INFO:root:FL Epoch: 264 Done on worker:1161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1832
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663080
INFO:root:Worker: 1832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404457
INFO:root:FL Epoch: 264 Norm Difference for worker 1832 is 1.260709
INFO:root:FL Epoch: 264 Done on worker:1832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1180
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339079
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512904
INFO:root:FL Epoch: 264 Norm Difference for worker 1180 is 1.188552
INFO:root:FL Epoch: 264 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1370
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588858
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426936
INFO:root:FL Epoch: 264 Norm Difference for worker 1370 is 1.170862
INFO:root:FL Epoch: 264 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :679
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639570
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242187
INFO:root:FL Epoch: 264 Norm Difference for worker 679 is 1.18861
INFO:root:FL Epoch: 264 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1235
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1235 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452234
INFO:root:Worker: 1235 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305514
INFO:root:FL Epoch: 264 Norm Difference for worker 1235 is 1.201846
INFO:root:FL Epoch: 264 Done on worker:1235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :562
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405271
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360565
INFO:root:FL Epoch: 264 Norm Difference for worker 562 is 1.138828
INFO:root:FL Epoch: 264 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 542
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 264 Ends   ===================
INFO:root:Epoch:264 Global Model Test Loss:0.4897245519301471 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:264 Global Model Backdoor Test Loss:0.29199377199014026                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 265 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 265 Workers Selected : [7, 806, 172, 751, 922, 1606, 904, 1023, 451, 871]
INFO:root:FL Epoch: 265 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 265 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 265 Training on worker :7
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 7 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595453
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 7 Train Epoch: 1 [0/201 (0%)]	Loss: 0.466468
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 7 is 1.370671
INFO:root:FL Epoch: 265 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :806
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609703
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588006
INFO:root:FL Epoch: 265 Norm Difference for worker 806 is 1.356758
INFO:root:FL Epoch: 265 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :172
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 1.125766
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.548081
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 172 is 1.241825
INFO:root:FL Epoch: 265 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :751
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344386
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322051
INFO:root:FL Epoch: 265 Norm Difference for worker 751 is 1.265213
INFO:root:FL Epoch: 265 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :922
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431741
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300217
INFO:root:FL Epoch: 265 Norm Difference for worker 922 is 1.293325
INFO:root:FL Epoch: 265 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1606
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340762
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412004
INFO:root:FL Epoch: 265 Norm Difference for worker 1606 is 1.220008
INFO:root:FL Epoch: 265 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :904
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531383
INFO:root:Worker: 904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373331
INFO:root:FL Epoch: 265 Norm Difference for worker 904 is 1.204575
INFO:root:FL Epoch: 265 Done on worker:904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1023
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625512
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404867
INFO:root:FL Epoch: 265 Norm Difference for worker 1023 is 1.182437
INFO:root:FL Epoch: 265 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :451
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585836
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498471
INFO:root:FL Epoch: 265 Norm Difference for worker 451 is 1.314002
INFO:root:FL Epoch: 265 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :871
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.335611
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365185
INFO:root:FL Epoch: 265 Norm Difference for worker 871 is 1.269357
INFO:root:FL Epoch: 265 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1023
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 265 Ends   ===================
INFO:root:Epoch:265 Global Model Test Loss:0.4628046856207006 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:265 Global Model Backdoor Test Loss:0.31748610486586887                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 266 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 266 Workers Selected : [1824, 776, 679, 1263, 1658, 161, 623, 1308, 248, 692]
INFO:root:FL Epoch: 266 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 266 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 266 Training on worker :1824
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.765750
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489495
INFO:root:FL Epoch: 266 Norm Difference for worker 1824 is 1.234536
INFO:root:FL Epoch: 266 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :776
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548485
INFO:root:Worker: 776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510792
INFO:root:FL Epoch: 266 Norm Difference for worker 776 is 1.125441
INFO:root:FL Epoch: 266 Done on worker:776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :679
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454136
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397102
INFO:root:FL Epoch: 266 Norm Difference for worker 679 is 1.152283
INFO:root:FL Epoch: 266 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1263
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1263 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645584
INFO:root:Worker: 1263 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554180
INFO:root:FL Epoch: 266 Norm Difference for worker 1263 is 1.264096
INFO:root:FL Epoch: 266 Done on worker:1263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1658
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351231
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303867
INFO:root:FL Epoch: 266 Norm Difference for worker 1658 is 0.916659
INFO:root:FL Epoch: 266 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :161
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.469354
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.367619
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 266 Norm Difference for worker 161 is 1.138687
INFO:root:FL Epoch: 266 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :623
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.799482
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680817
INFO:root:FL Epoch: 266 Norm Difference for worker 623 is 1.251122
INFO:root:FL Epoch: 266 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1308
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555378
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490897
INFO:root:FL Epoch: 266 Norm Difference for worker 1308 is 1.124474
INFO:root:FL Epoch: 266 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :248
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.339702
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.414786
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 266 Norm Difference for worker 248 is 1.056553
INFO:root:FL Epoch: 266 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :692
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477178
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548206
INFO:root:FL Epoch: 266 Norm Difference for worker 692 is 1.121105
INFO:root:FL Epoch: 266 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1658
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 266 Ends   ===================
INFO:root:Epoch:266 Global Model Test Loss:0.48722945241367116 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:266 Global Model Backdoor Test Loss:0.2808629895250003                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 267 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 267 Workers Selected : [1855, 447, 860, 1575, 818, 1745, 201, 82, 907, 1068]
INFO:root:FL Epoch: 267 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 267 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 267 Training on worker :1855
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.814161
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532412
INFO:root:FL Epoch: 267 Norm Difference for worker 1855 is 1.440526
INFO:root:FL Epoch: 267 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :447
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.767926
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449251
INFO:root:FL Epoch: 267 Norm Difference for worker 447 is 1.452923
INFO:root:FL Epoch: 267 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :860
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.247764
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260958
INFO:root:FL Epoch: 267 Norm Difference for worker 860 is 1.548903
INFO:root:FL Epoch: 267 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1575
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468614
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521623
INFO:root:FL Epoch: 267 Norm Difference for worker 1575 is 1.407284
INFO:root:FL Epoch: 267 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :818
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 1.012765
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615908
INFO:root:FL Epoch: 267 Norm Difference for worker 818 is 1.389757
INFO:root:FL Epoch: 267 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1745
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337984
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567072
INFO:root:FL Epoch: 267 Norm Difference for worker 1745 is 1.413633
INFO:root:FL Epoch: 267 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :201
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.769624
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470395
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 267 Norm Difference for worker 201 is 1.384822
INFO:root:FL Epoch: 267 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :82
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 82 Train Epoch: 0 [0/201 (0%)]	Loss: 0.644946
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 82 Train Epoch: 1 [0/201 (0%)]	Loss: 0.416918
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 267 Norm Difference for worker 82 is 1.474817
INFO:root:FL Epoch: 267 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :907
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662733
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365261
INFO:root:FL Epoch: 267 Norm Difference for worker 907 is 1.560323
INFO:root:FL Epoch: 267 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1068
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1068 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564492
INFO:root:Worker: 1068 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443899
INFO:root:FL Epoch: 267 Norm Difference for worker 1068 is 1.313725
INFO:root:FL Epoch: 267 Done on worker:1068
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1068
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 267 Ends   ===================
INFO:root:Epoch:267 Global Model Test Loss:0.5075439162114087 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:267 Global Model Backdoor Test Loss:0.19982364773750305                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 268 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 268 Workers Selected : [1385, 1108, 1575, 567, 1334, 186, 589, 861, 249, 363]
INFO:root:FL Epoch: 268 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 268 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 268 Training on worker :1385
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749522
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366603
INFO:root:FL Epoch: 268 Norm Difference for worker 1385 is 1.436346
INFO:root:FL Epoch: 268 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1108
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686214
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611164
INFO:root:FL Epoch: 268 Norm Difference for worker 1108 is 1.410814
INFO:root:FL Epoch: 268 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1575
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660803
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356763
INFO:root:FL Epoch: 268 Norm Difference for worker 1575 is 1.379689
INFO:root:FL Epoch: 268 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :567
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479359
INFO:root:Worker: 567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428093
INFO:root:FL Epoch: 268 Norm Difference for worker 567 is 1.178108
INFO:root:FL Epoch: 268 Done on worker:567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1334
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686998
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614182
INFO:root:FL Epoch: 268 Norm Difference for worker 1334 is 1.451434
INFO:root:FL Epoch: 268 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :186
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 186 Train Epoch: 0 [0/201 (0%)]	Loss: 0.510634
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 186 Train Epoch: 1 [0/201 (0%)]	Loss: 0.360092
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 268 Norm Difference for worker 186 is 1.272971
INFO:root:FL Epoch: 268 Done on worker:186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :589
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598805
INFO:root:Worker: 589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367579
INFO:root:FL Epoch: 268 Norm Difference for worker 589 is 1.498572
INFO:root:FL Epoch: 268 Done on worker:589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :861
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526940
INFO:root:Worker: 861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331938
INFO:root:FL Epoch: 268 Norm Difference for worker 861 is 1.350157
INFO:root:FL Epoch: 268 Done on worker:861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :249
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 249 Train Epoch: 0 [0/201 (0%)]	Loss: 0.325582
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 249 Train Epoch: 1 [0/201 (0%)]	Loss: 0.405673
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 268 Norm Difference for worker 249 is 1.285035
INFO:root:FL Epoch: 268 Done on worker:249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :363
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627721
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274455
INFO:root:FL Epoch: 268 Norm Difference for worker 363 is 1.424185
INFO:root:FL Epoch: 268 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 567
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 268 Ends   ===================
INFO:root:Epoch:268 Global Model Test Loss:0.4795292054905611 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:268 Global Model Backdoor Test Loss:0.30438252290089923                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 269 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 269 Workers Selected : [1792, 1931, 1446, 1658, 1501, 633, 191, 365, 539, 1151]
INFO:root:FL Epoch: 269 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 269 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 269 Training on worker :1792
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434426
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507968
INFO:root:FL Epoch: 269 Norm Difference for worker 1792 is 1.131177
INFO:root:FL Epoch: 269 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1931
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.827301
INFO:root:Worker: 1931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.781865
INFO:root:FL Epoch: 269 Norm Difference for worker 1931 is 1.438409
INFO:root:FL Epoch: 269 Done on worker:1931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1446
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560848
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349408
INFO:root:FL Epoch: 269 Norm Difference for worker 1446 is 1.332896
INFO:root:FL Epoch: 269 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1658
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.174154
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.132124
INFO:root:FL Epoch: 269 Norm Difference for worker 1658 is 0.781408
INFO:root:FL Epoch: 269 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1501
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458613
INFO:root:Worker: 1501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223274
INFO:root:FL Epoch: 269 Norm Difference for worker 1501 is 1.296299
INFO:root:FL Epoch: 269 Done on worker:1501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :633
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606275
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370244
INFO:root:FL Epoch: 269 Norm Difference for worker 633 is 1.367452
INFO:root:FL Epoch: 269 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :191
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.418558
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450883
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 269 Norm Difference for worker 191 is 1.377707
INFO:root:FL Epoch: 269 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :365
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495796
INFO:root:Worker: 365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370458
INFO:root:FL Epoch: 269 Norm Difference for worker 365 is 1.32934
INFO:root:FL Epoch: 269 Done on worker:365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :539
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.285786
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653058
INFO:root:FL Epoch: 269 Norm Difference for worker 539 is 1.550761
INFO:root:FL Epoch: 269 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1151
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1151 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779969
INFO:root:Worker: 1151 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423674
INFO:root:FL Epoch: 269 Norm Difference for worker 1151 is 1.272846
INFO:root:FL Epoch: 269 Done on worker:1151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1658
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 269 Ends   ===================
INFO:root:Epoch:269 Global Model Test Loss:0.5081308115931118 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:269 Global Model Backdoor Test Loss:0.28163935740788776                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 270 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 270 Workers Selected : [1947, 708, 1032, 1835, 1097, 1636, 104, 1018, 783, 1165]
INFO:root:FL Epoch: 270 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 270 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 270 Training on worker :1947
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376925
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312226
INFO:root:FL Epoch: 270 Norm Difference for worker 1947 is 1.53675
INFO:root:FL Epoch: 270 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :708
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634244
INFO:root:Worker: 708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303907
INFO:root:FL Epoch: 270 Norm Difference for worker 708 is 2.035973
INFO:root:FL Epoch: 270 Done on worker:708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1032
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1032 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794845
INFO:root:Worker: 1032 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303770
INFO:root:FL Epoch: 270 Norm Difference for worker 1032 is 1.787546
INFO:root:FL Epoch: 270 Done on worker:1032
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1835
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586116
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449479
INFO:root:FL Epoch: 270 Norm Difference for worker 1835 is 1.709855
INFO:root:FL Epoch: 270 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1097
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1097 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489267
INFO:root:Worker: 1097 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252180
INFO:root:FL Epoch: 270 Norm Difference for worker 1097 is 1.62916
INFO:root:FL Epoch: 270 Done on worker:1097
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1636
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594478
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233360
INFO:root:FL Epoch: 270 Norm Difference for worker 1636 is 1.672583
INFO:root:FL Epoch: 270 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :104
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 1.598094
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.363991
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 270 Norm Difference for worker 104 is 1.643232
INFO:root:FL Epoch: 270 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1018
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730944
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262339
INFO:root:FL Epoch: 270 Norm Difference for worker 1018 is 1.627201
INFO:root:FL Epoch: 270 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :783
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541920
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245196
INFO:root:FL Epoch: 270 Norm Difference for worker 783 is 1.693105
INFO:root:FL Epoch: 270 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1165
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548996
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537334
INFO:root:FL Epoch: 270 Norm Difference for worker 1165 is 1.610642
INFO:root:FL Epoch: 270 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1947
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 270 Ends   ===================
INFO:root:Epoch:270 Global Model Test Loss:0.47119544183506684 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:270 Global Model Backdoor Test Loss:0.23314362143476805                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 271 Begins ===================
INFO:root:FL Epoch: 271 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 271 Workers Selected : [0, 1, 2, 62, 1637, 492, 467, 439, 1788, 1531]
INFO:root:FL Epoch: 271 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 271 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 271 Training on worker :0
INFO:root:FL Epoch: 271 Using Learning rate : 0.005824332332849957 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.219523
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420643
INFO:root:FL Epoch: 271 Worker: 0 Backdoor Test Loss: 0.1694969249268373 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 271 Worker: 0 Backdoor Train Loss: 0.22308917045593263 Backdoor Train Accuracy: 91.0
INFO:root:FL Epoch: 271 Norm Difference for worker 0 is 0.282047
INFO:root:FL Epoch: 271 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1
INFO:root:FL Epoch: 271 Using Learning rate : 0.005824332332849957 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.238612
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213596
INFO:root:FL Epoch: 271 Worker: 1 Backdoor Test Loss: 0.16008368569115797 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 271 Worker: 1 Backdoor Train Loss: 0.22048160880804063 Backdoor Train Accuracy: 91.5
INFO:root:FL Epoch: 271 Norm Difference for worker 1 is 0.288699
INFO:root:FL Epoch: 271 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :2
INFO:root:FL Epoch: 271 Using Learning rate : 0.005824332332849957 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.290209
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265829
INFO:root:FL Epoch: 271 Worker: 2 Backdoor Test Loss: 0.15365841488043466 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 271 Worker: 2 Backdoor Train Loss: 0.22281448170542717 Backdoor Train Accuracy: 91.0
INFO:root:FL Epoch: 271 Norm Difference for worker 2 is 0.279265
INFO:root:FL Epoch: 271 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :62
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.546641
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.603522
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 62 is 1.76218
INFO:root:FL Epoch: 271 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1637
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682365
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464769
INFO:root:FL Epoch: 271 Norm Difference for worker 1637 is 1.360003
INFO:root:FL Epoch: 271 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :492
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605213
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324071
INFO:root:FL Epoch: 271 Norm Difference for worker 492 is 1.331885
INFO:root:FL Epoch: 271 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :467
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454180
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281236
INFO:root:FL Epoch: 271 Norm Difference for worker 467 is 1.191907
INFO:root:FL Epoch: 271 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :439
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465942
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435769
INFO:root:FL Epoch: 271 Norm Difference for worker 439 is 1.386865
INFO:root:FL Epoch: 271 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1788
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769076
INFO:root:Worker: 1788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422172
INFO:root:FL Epoch: 271 Norm Difference for worker 1788 is 1.42999
INFO:root:FL Epoch: 271 Done on worker:1788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1531
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.874393
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331314
INFO:root:FL Epoch: 271 Norm Difference for worker 1531 is 1.442627
INFO:root:FL Epoch: 271 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 271 Ends   ===================
INFO:root:Epoch:271 Global Model Test Loss:0.47330285345806794 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:271 Global Model Backdoor Test Loss:0.1694969249268373                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 272 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 272 Workers Selected : [1808, 988, 1871, 246, 578, 1167, 1905, 161, 115, 918]
INFO:root:FL Epoch: 272 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 272 Num points on workers: [200 200 200 201 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 272 Training on worker :1808
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.263309
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426112
INFO:root:FL Epoch: 272 Norm Difference for worker 1808 is 1.383984
INFO:root:FL Epoch: 272 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :988
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 988 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753963
INFO:root:Worker: 988 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294203
INFO:root:FL Epoch: 272 Norm Difference for worker 988 is 1.358681
INFO:root:FL Epoch: 272 Done on worker:988
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1871
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336257
INFO:root:Worker: 1871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492519
INFO:root:FL Epoch: 272 Norm Difference for worker 1871 is 1.522148
INFO:root:FL Epoch: 272 Done on worker:1871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :246
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526176
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.496443
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 246 is 1.456839
INFO:root:FL Epoch: 272 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :578
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729940
INFO:root:Worker: 578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492643
INFO:root:FL Epoch: 272 Norm Difference for worker 578 is 1.431304
INFO:root:FL Epoch: 272 Done on worker:578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1167
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621646
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197470
INFO:root:FL Epoch: 272 Norm Difference for worker 1167 is 1.483786
INFO:root:FL Epoch: 272 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1905
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619017
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397526
INFO:root:FL Epoch: 272 Norm Difference for worker 1905 is 1.299437
INFO:root:FL Epoch: 272 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :161
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.671343
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.500592
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 161 is 1.313232
INFO:root:FL Epoch: 272 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :115
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.299674
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.217941
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 115 is 1.346471
INFO:root:FL Epoch: 272 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :918
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482936
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623513
INFO:root:FL Epoch: 272 Norm Difference for worker 918 is 1.437763
INFO:root:FL Epoch: 272 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1905
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 272 Ends   ===================
INFO:root:Epoch:272 Global Model Test Loss:0.47321413369739757 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:272 Global Model Backdoor Test Loss:0.18013882140318552                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 273 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 273 Workers Selected : [1190, 534, 1482, 854, 1711, 834, 816, 1421, 1353, 991]
INFO:root:FL Epoch: 273 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 273 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 273 Training on worker :1190
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390319
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311020
INFO:root:FL Epoch: 273 Norm Difference for worker 1190 is 1.181568
INFO:root:FL Epoch: 273 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :534
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.873733
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656056
INFO:root:FL Epoch: 273 Norm Difference for worker 534 is 1.386575
INFO:root:FL Epoch: 273 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1482
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353270
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373441
INFO:root:FL Epoch: 273 Norm Difference for worker 1482 is 1.314746
INFO:root:FL Epoch: 273 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :854
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730426
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469308
INFO:root:FL Epoch: 273 Norm Difference for worker 854 is 1.350751
INFO:root:FL Epoch: 273 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1711
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611644
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410751
INFO:root:FL Epoch: 273 Norm Difference for worker 1711 is 1.432943
INFO:root:FL Epoch: 273 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :834
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343622
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558242
INFO:root:FL Epoch: 273 Norm Difference for worker 834 is 1.346821
INFO:root:FL Epoch: 273 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :816
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682671
INFO:root:Worker: 816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397478
INFO:root:FL Epoch: 273 Norm Difference for worker 816 is 1.354805
INFO:root:FL Epoch: 273 Done on worker:816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1421
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763805
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291575
INFO:root:FL Epoch: 273 Norm Difference for worker 1421 is 1.191038
INFO:root:FL Epoch: 273 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1353
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773982
INFO:root:Worker: 1353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454839
INFO:root:FL Epoch: 273 Norm Difference for worker 1353 is 1.462856
INFO:root:FL Epoch: 273 Done on worker:1353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :991
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540993
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461371
INFO:root:FL Epoch: 273 Norm Difference for worker 991 is 1.433169
INFO:root:FL Epoch: 273 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1421
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 273 Ends   ===================
INFO:root:Epoch:273 Global Model Test Loss:0.4791457547860987 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:273 Global Model Backdoor Test Loss:0.17757131407658258                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 274 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 274 Workers Selected : [906, 572, 1804, 98, 1645, 583, 100, 1709, 278, 942]
INFO:root:FL Epoch: 274 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 274 Num points on workers: [200 200 200 201 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 274 Training on worker :906
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.264123
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290470
INFO:root:FL Epoch: 274 Norm Difference for worker 906 is 1.17826
INFO:root:FL Epoch: 274 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :572
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527047
INFO:root:Worker: 572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288198
INFO:root:FL Epoch: 274 Norm Difference for worker 572 is 1.450233
INFO:root:FL Epoch: 274 Done on worker:572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1804
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468334
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232713
INFO:root:FL Epoch: 274 Norm Difference for worker 1804 is 1.388979
INFO:root:FL Epoch: 274 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :98
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.672287
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.341998
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 274 Norm Difference for worker 98 is 1.399501
INFO:root:FL Epoch: 274 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1645
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720639
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309143
INFO:root:FL Epoch: 274 Norm Difference for worker 1645 is 1.317056
INFO:root:FL Epoch: 274 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :583
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.865931
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273222
INFO:root:FL Epoch: 274 Norm Difference for worker 583 is 1.37199
INFO:root:FL Epoch: 274 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :100
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 1.040933
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.486407
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 274 Norm Difference for worker 100 is 1.450915
INFO:root:FL Epoch: 274 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1709
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807908
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501275
INFO:root:FL Epoch: 274 Norm Difference for worker 1709 is 1.362002
INFO:root:FL Epoch: 274 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :278
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.652778
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.364951
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 274 Norm Difference for worker 278 is 1.503849
INFO:root:FL Epoch: 274 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :942
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755822
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490120
INFO:root:FL Epoch: 274 Norm Difference for worker 942 is 1.325918
INFO:root:FL Epoch: 274 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 906
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 274 Ends   ===================
INFO:root:Epoch:274 Global Model Test Loss:0.48091379859868216 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:274 Global Model Backdoor Test Loss:0.28503627081712085                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 275 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 275 Workers Selected : [978, 410, 848, 1023, 197, 1535, 786, 1486, 1128, 1761]
INFO:root:FL Epoch: 275 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 275 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 275 Training on worker :978
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 978 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533616
INFO:root:Worker: 978 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317536
INFO:root:FL Epoch: 275 Norm Difference for worker 978 is 1.418541
INFO:root:FL Epoch: 275 Done on worker:978
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :410
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364314
INFO:root:Worker: 410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442208
INFO:root:FL Epoch: 275 Norm Difference for worker 410 is 1.375599
INFO:root:FL Epoch: 275 Done on worker:410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :848
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639246
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572382
INFO:root:FL Epoch: 275 Norm Difference for worker 848 is 1.64922
INFO:root:FL Epoch: 275 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1023
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.239832
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344060
INFO:root:FL Epoch: 275 Norm Difference for worker 1023 is 1.385941
INFO:root:FL Epoch: 275 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :197
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 197 Train Epoch: 0 [0/201 (0%)]	Loss: 0.411695
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 197 Train Epoch: 1 [0/201 (0%)]	Loss: 0.263220
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 275 Norm Difference for worker 197 is 1.381158
INFO:root:FL Epoch: 275 Done on worker:197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1535
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566139
INFO:root:Worker: 1535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332250
INFO:root:FL Epoch: 275 Norm Difference for worker 1535 is 1.563045
INFO:root:FL Epoch: 275 Done on worker:1535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :786
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 1.001005
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496424
INFO:root:FL Epoch: 275 Norm Difference for worker 786 is 1.579689
INFO:root:FL Epoch: 275 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1486
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.272493
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294258
INFO:root:FL Epoch: 275 Norm Difference for worker 1486 is 1.526139
INFO:root:FL Epoch: 275 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1128
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377818
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267768
INFO:root:FL Epoch: 275 Norm Difference for worker 1128 is 1.497203
INFO:root:FL Epoch: 275 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1761
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622954
INFO:root:Worker: 1761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503281
INFO:root:FL Epoch: 275 Norm Difference for worker 1761 is 1.331028
INFO:root:FL Epoch: 275 Done on worker:1761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1023
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 275 Ends   ===================
INFO:root:Epoch:275 Global Model Test Loss:0.5433829891331056 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:275 Global Model Backdoor Test Loss:0.434294730424881                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 276 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 276 Workers Selected : [1548, 1417, 840, 570, 1300, 1440, 716, 1434, 1090, 170]
INFO:root:FL Epoch: 276 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 276 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 276 Training on worker :1548
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 1.017638
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393520
INFO:root:FL Epoch: 276 Norm Difference for worker 1548 is 1.528718
INFO:root:FL Epoch: 276 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1417
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644676
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369030
INFO:root:FL Epoch: 276 Norm Difference for worker 1417 is 1.41
INFO:root:FL Epoch: 276 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :840
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628651
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243490
INFO:root:FL Epoch: 276 Norm Difference for worker 840 is 1.42546
INFO:root:FL Epoch: 276 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :570
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735651
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589805
INFO:root:FL Epoch: 276 Norm Difference for worker 570 is 1.352675
INFO:root:FL Epoch: 276 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1300
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312208
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311919
INFO:root:FL Epoch: 276 Norm Difference for worker 1300 is 1.410999
INFO:root:FL Epoch: 276 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1440
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453158
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531300
INFO:root:FL Epoch: 276 Norm Difference for worker 1440 is 1.484242
INFO:root:FL Epoch: 276 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :716
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710664
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222980
INFO:root:FL Epoch: 276 Norm Difference for worker 716 is 1.395514
INFO:root:FL Epoch: 276 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1434
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714126
INFO:root:Worker: 1434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517830
INFO:root:FL Epoch: 276 Norm Difference for worker 1434 is 1.393796
INFO:root:FL Epoch: 276 Done on worker:1434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1090
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436217
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634115
INFO:root:FL Epoch: 276 Norm Difference for worker 1090 is 1.434787
INFO:root:FL Epoch: 276 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :170
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.875131
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450524
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 170 is 1.552362
INFO:root:FL Epoch: 276 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 570
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 276 Ends   ===================
INFO:root:Epoch:276 Global Model Test Loss:0.491410996984033 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:276 Global Model Backdoor Test Loss:0.29036419093608856                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 277 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 277 Workers Selected : [975, 926, 1128, 303, 1274, 483, 944, 904, 394, 1282]
INFO:root:FL Epoch: 277 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 277 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 277 Training on worker :975
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555775
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388904
INFO:root:FL Epoch: 277 Norm Difference for worker 975 is 1.158118
INFO:root:FL Epoch: 277 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :926
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471147
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344303
INFO:root:FL Epoch: 277 Norm Difference for worker 926 is 1.040226
INFO:root:FL Epoch: 277 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1128
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661918
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464397
INFO:root:FL Epoch: 277 Norm Difference for worker 1128 is 1.111493
INFO:root:FL Epoch: 277 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :303
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 303 Train Epoch: 0 [0/201 (0%)]	Loss: 0.568295
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 303 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505491
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 303 is 1.116752
INFO:root:FL Epoch: 277 Done on worker:303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1274
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607515
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612140
INFO:root:FL Epoch: 277 Norm Difference for worker 1274 is 1.132252
INFO:root:FL Epoch: 277 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :483
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699917
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301288
INFO:root:FL Epoch: 277 Norm Difference for worker 483 is 1.077679
INFO:root:FL Epoch: 277 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :944
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327286
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652957
INFO:root:FL Epoch: 277 Norm Difference for worker 944 is 1.15526
INFO:root:FL Epoch: 277 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :904
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440051
INFO:root:Worker: 904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437610
INFO:root:FL Epoch: 277 Norm Difference for worker 904 is 1.013194
INFO:root:FL Epoch: 277 Done on worker:904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :394
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646498
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498252
INFO:root:FL Epoch: 277 Norm Difference for worker 394 is 1.161437
INFO:root:FL Epoch: 277 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1282
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1282 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556150
INFO:root:Worker: 1282 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362194
INFO:root:FL Epoch: 277 Norm Difference for worker 1282 is 1.260784
INFO:root:FL Epoch: 277 Done on worker:1282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 926
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 277 Ends   ===================
INFO:root:Epoch:277 Global Model Test Loss:0.4837518036365509 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:277 Global Model Backdoor Test Loss:0.414894238114357                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 278 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 278 Workers Selected : [1205, 886, 835, 1830, 482, 1179, 1312, 1592, 45, 1934]
INFO:root:FL Epoch: 278 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 278 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 278 Training on worker :1205
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375077
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373087
INFO:root:FL Epoch: 278 Norm Difference for worker 1205 is 1.191803
INFO:root:FL Epoch: 278 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :886
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.921303
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345505
INFO:root:FL Epoch: 278 Norm Difference for worker 886 is 1.162671
INFO:root:FL Epoch: 278 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :835
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569036
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283254
INFO:root:FL Epoch: 278 Norm Difference for worker 835 is 1.205016
INFO:root:FL Epoch: 278 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1830
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561183
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460178
INFO:root:FL Epoch: 278 Norm Difference for worker 1830 is 1.169828
INFO:root:FL Epoch: 278 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :482
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457785
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493692
INFO:root:FL Epoch: 278 Norm Difference for worker 482 is 1.169657
INFO:root:FL Epoch: 278 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1179
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1179 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633044
INFO:root:Worker: 1179 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383366
INFO:root:FL Epoch: 278 Norm Difference for worker 1179 is 1.177047
INFO:root:FL Epoch: 278 Done on worker:1179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1312
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498185
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462894
INFO:root:FL Epoch: 278 Norm Difference for worker 1312 is 1.125713
INFO:root:FL Epoch: 278 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1592
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498455
INFO:root:Worker: 1592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462333
INFO:root:FL Epoch: 278 Norm Difference for worker 1592 is 1.232038
INFO:root:FL Epoch: 278 Done on worker:1592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :45
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.483378
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.460734
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 45 is 1.265386
INFO:root:FL Epoch: 278 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1934
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575231
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434313
INFO:root:FL Epoch: 278 Norm Difference for worker 1934 is 1.204873
INFO:root:FL Epoch: 278 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1312
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 278 Ends   ===================
INFO:root:Epoch:278 Global Model Test Loss:0.4896704607150134 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:278 Global Model Backdoor Test Loss:0.4831887135903041                             and Backdoor Test Accuracy:78.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 279 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 279 Workers Selected : [1712, 194, 814, 277, 1810, 235, 487, 1274, 998, 1460]
INFO:root:FL Epoch: 279 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 279 Num points on workers: [200 201 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 279 Training on worker :1712
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603215
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607143
INFO:root:FL Epoch: 279 Norm Difference for worker 1712 is 1.117472
INFO:root:FL Epoch: 279 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :194
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 194 Train Epoch: 0 [0/201 (0%)]	Loss: 0.382484
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 194 Train Epoch: 1 [0/201 (0%)]	Loss: 0.498856
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 194 is 1.07289
INFO:root:FL Epoch: 279 Done on worker:194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :814
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467508
INFO:root:Worker: 814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569032
INFO:root:FL Epoch: 279 Norm Difference for worker 814 is 1.071716
INFO:root:FL Epoch: 279 Done on worker:814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :277
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.602413
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.573258
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 277 is 1.087237
INFO:root:FL Epoch: 279 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1810
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417640
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.158821
INFO:root:FL Epoch: 279 Norm Difference for worker 1810 is 0.969329
INFO:root:FL Epoch: 279 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :235
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 235 Train Epoch: 0 [0/201 (0%)]	Loss: 0.837689
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 235 Train Epoch: 1 [0/201 (0%)]	Loss: 0.540832
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 235 is 1.09714
INFO:root:FL Epoch: 279 Done on worker:235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :487
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.331250
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579879
INFO:root:FL Epoch: 279 Norm Difference for worker 487 is 0.980333
INFO:root:FL Epoch: 279 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1274
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457142
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452789
INFO:root:FL Epoch: 279 Norm Difference for worker 1274 is 1.185599
INFO:root:FL Epoch: 279 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :998
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 998 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639014
INFO:root:Worker: 998 Train Epoch: 1 [0/200 (0%)]	Loss: 0.722309
INFO:root:FL Epoch: 279 Norm Difference for worker 998 is 1.095275
INFO:root:FL Epoch: 279 Done on worker:998
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1460
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365185
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288587
INFO:root:FL Epoch: 279 Norm Difference for worker 1460 is 0.913238
INFO:root:FL Epoch: 279 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1460
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 279 Ends   ===================
INFO:root:Epoch:279 Global Model Test Loss:0.47000301936093497 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:279 Global Model Backdoor Test Loss:0.334522508084774                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 280 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 280 Workers Selected : [951, 196, 695, 1847, 1670, 1872, 1335, 564, 683, 33]
INFO:root:FL Epoch: 280 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 280 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 280 Training on worker :951
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612442
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413599
INFO:root:FL Epoch: 280 Norm Difference for worker 951 is 1.232343
INFO:root:FL Epoch: 280 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :196
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.816868
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.383237
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 280 Norm Difference for worker 196 is 1.350748
INFO:root:FL Epoch: 280 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :695
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450022
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512127
INFO:root:FL Epoch: 280 Norm Difference for worker 695 is 1.346526
INFO:root:FL Epoch: 280 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1847
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1847 Train Epoch: 0 [0/200 (0%)]	Loss: 1.008683
INFO:root:Worker: 1847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511765
INFO:root:FL Epoch: 280 Norm Difference for worker 1847 is 1.320939
INFO:root:FL Epoch: 280 Done on worker:1847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1670
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663020
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383079
INFO:root:FL Epoch: 280 Norm Difference for worker 1670 is 1.252009
INFO:root:FL Epoch: 280 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1872
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643553
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379830
INFO:root:FL Epoch: 280 Norm Difference for worker 1872 is 1.231677
INFO:root:FL Epoch: 280 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1335
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569785
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271512
INFO:root:FL Epoch: 280 Norm Difference for worker 1335 is 1.313885
INFO:root:FL Epoch: 280 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :564
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601690
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386218
INFO:root:FL Epoch: 280 Norm Difference for worker 564 is 1.320069
INFO:root:FL Epoch: 280 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :683
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367376
INFO:root:Worker: 683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582738
INFO:root:FL Epoch: 280 Norm Difference for worker 683 is 1.348585
INFO:root:FL Epoch: 280 Done on worker:683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :33
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.621430
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.276811
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 280 Norm Difference for worker 33 is 1.375559
INFO:root:FL Epoch: 280 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1670
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 280 Ends   ===================
INFO:root:Epoch:280 Global Model Test Loss:0.5046272698570701 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:280 Global Model Backdoor Test Loss:0.41586780548095703                             and Backdoor Test Accuracy:79.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 281 Begins ===================
INFO:root:FL Epoch: 281 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 281 Workers Selected : [0, 1, 2, 1552, 722, 895, 1912, 1905, 370, 1295]
INFO:root:FL Epoch: 281 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 281 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 281 Training on worker :0
INFO:root:FL Epoch: 281 Using Learning rate : 0.005708888494176698 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505039
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239960
INFO:root:FL Epoch: 281 Worker: 0 Backdoor Test Loss: 0.19767816116412482 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 281 Worker: 0 Backdoor Train Loss: 0.23821902573108672 Backdoor Train Accuracy: 91.5
INFO:root:FL Epoch: 281 Norm Difference for worker 0 is 0.294666
INFO:root:FL Epoch: 281 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1
INFO:root:FL Epoch: 281 Using Learning rate : 0.005708888494176698 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315668
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245481
INFO:root:FL Epoch: 281 Worker: 1 Backdoor Test Loss: 0.20806515713532767 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 281 Worker: 1 Backdoor Train Loss: 0.2399897038936615 Backdoor Train Accuracy: 92.5
INFO:root:FL Epoch: 281 Norm Difference for worker 1 is 0.280377
INFO:root:FL Epoch: 281 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :2
INFO:root:FL Epoch: 281 Using Learning rate : 0.005708888494176698 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369096
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362198
INFO:root:FL Epoch: 281 Worker: 2 Backdoor Test Loss: 0.20636799186468124 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 281 Worker: 2 Backdoor Train Loss: 0.238206347823143 Backdoor Train Accuracy: 93.0
INFO:root:FL Epoch: 281 Norm Difference for worker 2 is 0.287212
INFO:root:FL Epoch: 281 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1552
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587543
INFO:root:Worker: 1552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468554
INFO:root:FL Epoch: 281 Norm Difference for worker 1552 is 1.24289
INFO:root:FL Epoch: 281 Done on worker:1552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :722
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737599
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320811
INFO:root:FL Epoch: 281 Norm Difference for worker 722 is 1.159706
INFO:root:FL Epoch: 281 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :895
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429086
INFO:root:Worker: 895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467410
INFO:root:FL Epoch: 281 Norm Difference for worker 895 is 1.210469
INFO:root:FL Epoch: 281 Done on worker:895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1912
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649886
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515432
INFO:root:FL Epoch: 281 Norm Difference for worker 1912 is 1.200015
INFO:root:FL Epoch: 281 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1905
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.264297
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359860
INFO:root:FL Epoch: 281 Norm Difference for worker 1905 is 0.906144
INFO:root:FL Epoch: 281 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :370
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391439
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513828
INFO:root:FL Epoch: 281 Norm Difference for worker 370 is 1.116213
INFO:root:FL Epoch: 281 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1295
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388967
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516837
INFO:root:FL Epoch: 281 Norm Difference for worker 1295 is 1.168538
INFO:root:FL Epoch: 281 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 281 Ends   ===================
INFO:root:Epoch:281 Global Model Test Loss:0.4953014938270344 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:281 Global Model Backdoor Test Loss:0.20806515713532767                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 282 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 282 Workers Selected : [1016, 1907, 171, 180, 1447, 316, 1107, 451, 1246, 792]
INFO:root:FL Epoch: 282 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 282 Num points on workers: [200 200 201 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 282 Training on worker :1016
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 1.107884
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354215
INFO:root:FL Epoch: 282 Norm Difference for worker 1016 is 1.310813
INFO:root:FL Epoch: 282 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1907
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723712
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381998
INFO:root:FL Epoch: 282 Norm Difference for worker 1907 is 1.226661
INFO:root:FL Epoch: 282 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :171
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.478468
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.712568
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 171 is 1.28648
INFO:root:FL Epoch: 282 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :180
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.737451
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.232020
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 180 is 1.114941
INFO:root:FL Epoch: 282 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1447
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.214399
INFO:root:Worker: 1447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266244
INFO:root:FL Epoch: 282 Norm Difference for worker 1447 is 1.256248
INFO:root:FL Epoch: 282 Done on worker:1447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :316
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.452085
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.443727
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 316 is 1.199668
INFO:root:FL Epoch: 282 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1107
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1107 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351765
INFO:root:Worker: 1107 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233057
INFO:root:FL Epoch: 282 Norm Difference for worker 1107 is 1.137341
INFO:root:FL Epoch: 282 Done on worker:1107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :451
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634526
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516600
INFO:root:FL Epoch: 282 Norm Difference for worker 451 is 1.327953
INFO:root:FL Epoch: 282 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1246
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1246 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627383
INFO:root:Worker: 1246 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589189
INFO:root:FL Epoch: 282 Norm Difference for worker 1246 is 1.22086
INFO:root:FL Epoch: 282 Done on worker:1246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :792
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608864
INFO:root:Worker: 792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381822
INFO:root:FL Epoch: 282 Norm Difference for worker 792 is 1.18981
INFO:root:FL Epoch: 282 Done on worker:792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 180
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 282 Ends   ===================
INFO:root:Epoch:282 Global Model Test Loss:0.4963313060648301 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:282 Global Model Backdoor Test Loss:0.24179319789012274                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 283 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 283 Workers Selected : [1537, 890, 1098, 872, 1229, 169, 1490, 659, 81, 873]
INFO:root:FL Epoch: 283 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 283 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 283 Training on worker :1537
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448871
INFO:root:Worker: 1537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410098
INFO:root:FL Epoch: 283 Norm Difference for worker 1537 is 1.382647
INFO:root:FL Epoch: 283 Done on worker:1537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :890
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740588
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358198
INFO:root:FL Epoch: 283 Norm Difference for worker 890 is 1.270492
INFO:root:FL Epoch: 283 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1098
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.193278
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508880
INFO:root:FL Epoch: 283 Norm Difference for worker 1098 is 1.101019
INFO:root:FL Epoch: 283 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :872
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650160
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550304
INFO:root:FL Epoch: 283 Norm Difference for worker 872 is 1.271824
INFO:root:FL Epoch: 283 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1229
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1229 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432570
INFO:root:Worker: 1229 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457044
INFO:root:FL Epoch: 283 Norm Difference for worker 1229 is 1.352444
INFO:root:FL Epoch: 283 Done on worker:1229
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :169
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494920
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.472996
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 169 is 1.26171
INFO:root:FL Epoch: 283 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1490
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340343
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402696
INFO:root:FL Epoch: 283 Norm Difference for worker 1490 is 1.147658
INFO:root:FL Epoch: 283 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :659
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461357
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295586
INFO:root:FL Epoch: 283 Norm Difference for worker 659 is 1.340315
INFO:root:FL Epoch: 283 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :81
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.456951
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.525518
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 81 is 1.328283
INFO:root:FL Epoch: 283 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :873
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683675
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258463
INFO:root:FL Epoch: 283 Norm Difference for worker 873 is 1.38101
INFO:root:FL Epoch: 283 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1490
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 283 Ends   ===================
INFO:root:Epoch:283 Global Model Test Loss:0.5471046181286082 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:283 Global Model Backdoor Test Loss:0.36752185970544815                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 284 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 284 Workers Selected : [1878, 1224, 132, 198, 140, 649, 436, 86, 1238, 1616]
INFO:root:FL Epoch: 284 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.1002994 0.1002994 0.0998004 0.0998004
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 284 Num points on workers: [200 200 201 201 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 284 Training on worker :1878
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557988
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516028
INFO:root:FL Epoch: 284 Norm Difference for worker 1878 is 1.247059
INFO:root:FL Epoch: 284 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1224
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1224 Train Epoch: 0 [0/200 (0%)]	Loss: 0.879553
INFO:root:Worker: 1224 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406646
INFO:root:FL Epoch: 284 Norm Difference for worker 1224 is 1.222331
INFO:root:FL Epoch: 284 Done on worker:1224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :132
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.473092
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.366897
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 284 Norm Difference for worker 132 is 1.27917
INFO:root:FL Epoch: 284 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :198
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.577400
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.315114
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 284 Norm Difference for worker 198 is 1.182399
INFO:root:FL Epoch: 284 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :140
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.781054
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.659191
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 284 Norm Difference for worker 140 is 1.288779
INFO:root:FL Epoch: 284 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :649
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490306
INFO:root:Worker: 649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264880
INFO:root:FL Epoch: 284 Norm Difference for worker 649 is 1.306399
INFO:root:FL Epoch: 284 Done on worker:649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :436
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611758
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609944
INFO:root:FL Epoch: 284 Norm Difference for worker 436 is 1.265753
INFO:root:FL Epoch: 284 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :86
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.791282
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.570095
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 284 Norm Difference for worker 86 is 1.239094
INFO:root:FL Epoch: 284 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1238
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405154
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285684
INFO:root:FL Epoch: 284 Norm Difference for worker 1238 is 0.99249
INFO:root:FL Epoch: 284 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1616
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557317
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476325
INFO:root:FL Epoch: 284 Norm Difference for worker 1616 is 1.181036
INFO:root:FL Epoch: 284 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1238
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 284 Ends   ===================
INFO:root:Epoch:284 Global Model Test Loss:0.5278371081632727 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:284 Global Model Backdoor Test Loss:0.2737494384249051                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 285 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 285 Workers Selected : [376, 587, 1674, 1650, 1395, 747, 841, 1713, 586, 76]
INFO:root:FL Epoch: 285 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 285 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 285 Training on worker :376
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527315
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558889
INFO:root:FL Epoch: 285 Norm Difference for worker 376 is 1.354622
INFO:root:FL Epoch: 285 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :587
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.987973
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336351
INFO:root:FL Epoch: 285 Norm Difference for worker 587 is 1.366495
INFO:root:FL Epoch: 285 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1674
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500709
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314962
INFO:root:FL Epoch: 285 Norm Difference for worker 1674 is 1.301448
INFO:root:FL Epoch: 285 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1650
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510133
INFO:root:Worker: 1650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307428
INFO:root:FL Epoch: 285 Norm Difference for worker 1650 is 1.297956
INFO:root:FL Epoch: 285 Done on worker:1650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1395
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744929
INFO:root:Worker: 1395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394042
INFO:root:FL Epoch: 285 Norm Difference for worker 1395 is 1.322331
INFO:root:FL Epoch: 285 Done on worker:1395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :747
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684207
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667444
INFO:root:FL Epoch: 285 Norm Difference for worker 747 is 1.407325
INFO:root:FL Epoch: 285 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :841
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437307
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560172
INFO:root:FL Epoch: 285 Norm Difference for worker 841 is 1.367875
INFO:root:FL Epoch: 285 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1713
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442803
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206444
INFO:root:FL Epoch: 285 Norm Difference for worker 1713 is 1.295306
INFO:root:FL Epoch: 285 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :586
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.997374
INFO:root:Worker: 586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373690
INFO:root:FL Epoch: 285 Norm Difference for worker 586 is 1.340418
INFO:root:FL Epoch: 285 Done on worker:586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :76
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.672109
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.497947
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 285 Norm Difference for worker 76 is 1.381174
INFO:root:FL Epoch: 285 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1395
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 285 Ends   ===================
INFO:root:Epoch:285 Global Model Test Loss:0.5245867336497587 and Test Accuracy:75.0 
INFO:root:Epoch:285 Global Model Backdoor Test Loss:0.2617484952012698                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 286 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 286 Workers Selected : [1588, 653, 1926, 1027, 529, 1929, 184, 1709, 74, 1001]
INFO:root:FL Epoch: 286 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 286 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 286 Training on worker :1588
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334635
INFO:root:Worker: 1588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554515
INFO:root:FL Epoch: 286 Norm Difference for worker 1588 is 1.12973
INFO:root:FL Epoch: 286 Done on worker:1588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :653
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445631
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246713
INFO:root:FL Epoch: 286 Norm Difference for worker 653 is 1.192447
INFO:root:FL Epoch: 286 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1926
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710237
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322064
INFO:root:FL Epoch: 286 Norm Difference for worker 1926 is 1.22838
INFO:root:FL Epoch: 286 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1027
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1027 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509018
INFO:root:Worker: 1027 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419402
INFO:root:FL Epoch: 286 Norm Difference for worker 1027 is 1.250919
INFO:root:FL Epoch: 286 Done on worker:1027
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :529
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518159
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513351
INFO:root:FL Epoch: 286 Norm Difference for worker 529 is 1.24342
INFO:root:FL Epoch: 286 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1929
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561673
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424066
INFO:root:FL Epoch: 286 Norm Difference for worker 1929 is 1.291482
INFO:root:FL Epoch: 286 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :184
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.481760
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.323648
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 286 Norm Difference for worker 184 is 1.103708
INFO:root:FL Epoch: 286 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1709
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478642
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557648
INFO:root:FL Epoch: 286 Norm Difference for worker 1709 is 1.192772
INFO:root:FL Epoch: 286 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :74
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.477973
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.380399
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 286 Norm Difference for worker 74 is 1.194167
INFO:root:FL Epoch: 286 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1001
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1001 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603790
INFO:root:Worker: 1001 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330826
INFO:root:FL Epoch: 286 Norm Difference for worker 1001 is 1.224425
INFO:root:FL Epoch: 286 Done on worker:1001
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1588
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 286 Ends   ===================
INFO:root:Epoch:286 Global Model Test Loss:0.5620625965735492 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:286 Global Model Backdoor Test Loss:0.38131315757830936                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 287 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 287 Workers Selected : [1919, 211, 692, 756, 452, 1940, 1274, 505, 1090, 674]
INFO:root:FL Epoch: 287 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 287 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 287 Training on worker :1919
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459992
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314546
INFO:root:FL Epoch: 287 Norm Difference for worker 1919 is 1.142295
INFO:root:FL Epoch: 287 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :211
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541812
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.435891
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 211 is 1.062346
INFO:root:FL Epoch: 287 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :692
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.811897
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598060
INFO:root:FL Epoch: 287 Norm Difference for worker 692 is 1.153333
INFO:root:FL Epoch: 287 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :756
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.901142
INFO:root:Worker: 756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398095
INFO:root:FL Epoch: 287 Norm Difference for worker 756 is 1.220501
INFO:root:FL Epoch: 287 Done on worker:756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :452
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406390
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441186
INFO:root:FL Epoch: 287 Norm Difference for worker 452 is 1.190418
INFO:root:FL Epoch: 287 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :1940
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315652
INFO:root:Worker: 1940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333961
INFO:root:FL Epoch: 287 Norm Difference for worker 1940 is 1.106375
INFO:root:FL Epoch: 287 Done on worker:1940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :1274
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.902210
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363777
INFO:root:FL Epoch: 287 Norm Difference for worker 1274 is 1.152094
INFO:root:FL Epoch: 287 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :505
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604576
INFO:root:Worker: 505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426600
INFO:root:FL Epoch: 287 Norm Difference for worker 505 is 1.206137
INFO:root:FL Epoch: 287 Done on worker:505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :1090
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526543
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481204
INFO:root:FL Epoch: 287 Norm Difference for worker 1090 is 1.167504
INFO:root:FL Epoch: 287 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :674
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614369
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407074
INFO:root:FL Epoch: 287 Norm Difference for worker 674 is 1.152301
INFO:root:FL Epoch: 287 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 211
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 287 Ends   ===================
INFO:root:Epoch:287 Global Model Test Loss:0.5388984084129333 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:287 Global Model Backdoor Test Loss:0.2676855226357778                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 288 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 288 Workers Selected : [754, 1867, 1196, 1355, 1912, 1919, 1518, 818, 1600, 1594]
INFO:root:FL Epoch: 288 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 288 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 288 Training on worker :754
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.916907
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510982
INFO:root:FL Epoch: 288 Norm Difference for worker 754 is 1.185445
INFO:root:FL Epoch: 288 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1867
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448545
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506324
INFO:root:FL Epoch: 288 Norm Difference for worker 1867 is 1.15799
INFO:root:FL Epoch: 288 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1196
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1196 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676026
INFO:root:Worker: 1196 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551851
INFO:root:FL Epoch: 288 Norm Difference for worker 1196 is 1.141369
INFO:root:FL Epoch: 288 Done on worker:1196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1355
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524650
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561045
INFO:root:FL Epoch: 288 Norm Difference for worker 1355 is 1.11254
INFO:root:FL Epoch: 288 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1912
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519077
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548685
INFO:root:FL Epoch: 288 Norm Difference for worker 1912 is 1.104241
INFO:root:FL Epoch: 288 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1919
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519476
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459420
INFO:root:FL Epoch: 288 Norm Difference for worker 1919 is 1.10537
INFO:root:FL Epoch: 288 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1518
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605799
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602860
INFO:root:FL Epoch: 288 Norm Difference for worker 1518 is 1.053067
INFO:root:FL Epoch: 288 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :818
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614968
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454979
INFO:root:FL Epoch: 288 Norm Difference for worker 818 is 1.126405
INFO:root:FL Epoch: 288 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1600
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377270
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469583
INFO:root:FL Epoch: 288 Norm Difference for worker 1600 is 1.114921
INFO:root:FL Epoch: 288 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1594
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618333
INFO:root:Worker: 1594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325282
INFO:root:FL Epoch: 288 Norm Difference for worker 1594 is 1.108245
INFO:root:FL Epoch: 288 Done on worker:1594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1594
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 288 Ends   ===================
INFO:root:Epoch:288 Global Model Test Loss:0.5250979661941528 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:288 Global Model Backdoor Test Loss:0.45071640610694885                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 289 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 289 Workers Selected : [1856, 476, 191, 401, 350, 34, 742, 1521, 1275, 107]
INFO:root:FL Epoch: 289 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 289 Num points on workers: [200 200 201 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 289 Training on worker :1856
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637777
INFO:root:Worker: 1856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512051
INFO:root:FL Epoch: 289 Norm Difference for worker 1856 is 1.039181
INFO:root:FL Epoch: 289 Done on worker:1856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :476
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562582
INFO:root:Worker: 476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293888
INFO:root:FL Epoch: 289 Norm Difference for worker 476 is 0.952044
INFO:root:FL Epoch: 289 Done on worker:476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :191
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.456994
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.482601
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 191 is 1.015033
INFO:root:FL Epoch: 289 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :401
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559282
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450410
INFO:root:FL Epoch: 289 Norm Difference for worker 401 is 1.040287
INFO:root:FL Epoch: 289 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :350
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590260
INFO:root:Worker: 350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514097
INFO:root:FL Epoch: 289 Norm Difference for worker 350 is 1.027644
INFO:root:FL Epoch: 289 Done on worker:350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :34
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 34 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526010
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 34 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419834
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 34 is 1.090965
INFO:root:FL Epoch: 289 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :742
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402269
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374589
INFO:root:FL Epoch: 289 Norm Difference for worker 742 is 1.033251
INFO:root:FL Epoch: 289 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1521
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483496
INFO:root:Worker: 1521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368866
INFO:root:FL Epoch: 289 Norm Difference for worker 1521 is 1.003991
INFO:root:FL Epoch: 289 Done on worker:1521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1275
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754474
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385669
INFO:root:FL Epoch: 289 Norm Difference for worker 1275 is 0.947443
INFO:root:FL Epoch: 289 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :107
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 107 Train Epoch: 0 [0/201 (0%)]	Loss: 0.654205
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 107 Train Epoch: 1 [0/201 (0%)]	Loss: 0.722179
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 107 is 1.046102
INFO:root:FL Epoch: 289 Done on worker:107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1275
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 289 Ends   ===================
INFO:root:Epoch:289 Global Model Test Loss:0.5257286394343657 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:289 Global Model Backdoor Test Loss:0.27237963924805325                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 290 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 290 Workers Selected : [1193, 930, 1680, 1543, 25, 1115, 1856, 687, 24, 850]
INFO:root:FL Epoch: 290 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 290 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 290 Training on worker :1193
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1193 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524418
INFO:root:Worker: 1193 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539217
INFO:root:FL Epoch: 290 Norm Difference for worker 1193 is 1.103188
INFO:root:FL Epoch: 290 Done on worker:1193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :930
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554053
INFO:root:Worker: 930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381249
INFO:root:FL Epoch: 290 Norm Difference for worker 930 is 0.975665
INFO:root:FL Epoch: 290 Done on worker:930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1680
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559033
INFO:root:Worker: 1680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564229
INFO:root:FL Epoch: 290 Norm Difference for worker 1680 is 1.048408
INFO:root:FL Epoch: 290 Done on worker:1680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1543
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542522
INFO:root:Worker: 1543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474637
INFO:root:FL Epoch: 290 Norm Difference for worker 1543 is 1.13259
INFO:root:FL Epoch: 290 Done on worker:1543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :25
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.338081
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.345794
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 290 Norm Difference for worker 25 is 0.976409
INFO:root:FL Epoch: 290 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1115
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1115 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486771
INFO:root:Worker: 1115 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507497
INFO:root:FL Epoch: 290 Norm Difference for worker 1115 is 1.093391
INFO:root:FL Epoch: 290 Done on worker:1115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1856
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738118
INFO:root:Worker: 1856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446185
INFO:root:FL Epoch: 290 Norm Difference for worker 1856 is 1.11453
INFO:root:FL Epoch: 290 Done on worker:1856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :687
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515400
INFO:root:Worker: 687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433255
INFO:root:FL Epoch: 290 Norm Difference for worker 687 is 1.090211
INFO:root:FL Epoch: 290 Done on worker:687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :24
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.540450
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.656935
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 290 Norm Difference for worker 24 is 1.206532
INFO:root:FL Epoch: 290 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :850
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813011
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416447
INFO:root:FL Epoch: 290 Norm Difference for worker 850 is 1.118775
INFO:root:FL Epoch: 290 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 930
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 290 Ends   ===================
INFO:root:Epoch:290 Global Model Test Loss:0.5160349660059985 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:290 Global Model Backdoor Test Loss:0.40285053849220276                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 291 Begins ===================
INFO:root:FL Epoch: 291 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 291 Workers Selected : [0, 1, 2, 623, 1591, 1404, 853, 1441, 944, 1326]
INFO:root:FL Epoch: 291 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 291 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 291 Training on worker :0
INFO:root:FL Epoch: 291 Using Learning rate : 0.0055957328628250666 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426444
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392228
INFO:root:FL Epoch: 291 Worker: 0 Backdoor Test Loss: 0.23666120320558548 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 291 Worker: 0 Backdoor Train Loss: 0.2671801924705505 Backdoor Train Accuracy: 90.5
INFO:root:FL Epoch: 291 Norm Difference for worker 0 is 0.255338
INFO:root:FL Epoch: 291 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1
INFO:root:FL Epoch: 291 Using Learning rate : 0.0055957328628250666 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351814
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264101
INFO:root:FL Epoch: 291 Worker: 1 Backdoor Test Loss: 0.24578135460615158 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 291 Worker: 1 Backdoor Train Loss: 0.269815132021904 Backdoor Train Accuracy: 90.5
INFO:root:FL Epoch: 291 Norm Difference for worker 1 is 0.245238
INFO:root:FL Epoch: 291 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :2
INFO:root:FL Epoch: 291 Using Learning rate : 0.0055957328628250666 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509651
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277247
INFO:root:FL Epoch: 291 Worker: 2 Backdoor Test Loss: 0.23194493353366852 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 291 Worker: 2 Backdoor Train Loss: 0.2684164732694626 Backdoor Train Accuracy: 90.5
INFO:root:FL Epoch: 291 Norm Difference for worker 2 is 0.251885
INFO:root:FL Epoch: 291 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :623
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560475
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526172
INFO:root:FL Epoch: 291 Norm Difference for worker 623 is 1.130667
INFO:root:FL Epoch: 291 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1591
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646294
INFO:root:Worker: 1591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481958
INFO:root:FL Epoch: 291 Norm Difference for worker 1591 is 1.098464
INFO:root:FL Epoch: 291 Done on worker:1591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1404
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362105
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552010
INFO:root:FL Epoch: 291 Norm Difference for worker 1404 is 0.969393
INFO:root:FL Epoch: 291 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :853
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624746
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677295
INFO:root:FL Epoch: 291 Norm Difference for worker 853 is 1.167246
INFO:root:FL Epoch: 291 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1441
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319863
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464708
INFO:root:FL Epoch: 291 Norm Difference for worker 1441 is 1.055747
INFO:root:FL Epoch: 291 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :944
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440437
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455887
INFO:root:FL Epoch: 291 Norm Difference for worker 944 is 1.048783
INFO:root:FL Epoch: 291 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1326
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402657
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565775
INFO:root:FL Epoch: 291 Norm Difference for worker 1326 is 1.114735
INFO:root:FL Epoch: 291 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 291 Ends   ===================
INFO:root:Epoch:291 Global Model Test Loss:0.5112157411435071 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:291 Global Model Backdoor Test Loss:0.24578135460615158                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 292 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 292 Workers Selected : [845, 1139, 844, 540, 872, 1177, 1685, 175, 376, 1367]
INFO:root:FL Epoch: 292 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 292 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 292 Training on worker :845
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613783
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551602
INFO:root:FL Epoch: 292 Norm Difference for worker 845 is 1.082243
INFO:root:FL Epoch: 292 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1139
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565506
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305933
INFO:root:FL Epoch: 292 Norm Difference for worker 1139 is 1.050007
INFO:root:FL Epoch: 292 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :844
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.826273
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407264
INFO:root:FL Epoch: 292 Norm Difference for worker 844 is 1.09309
INFO:root:FL Epoch: 292 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :540
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496805
INFO:root:Worker: 540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389742
INFO:root:FL Epoch: 292 Norm Difference for worker 540 is 1.170186
INFO:root:FL Epoch: 292 Done on worker:540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :872
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500405
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441875
INFO:root:FL Epoch: 292 Norm Difference for worker 872 is 1.136784
INFO:root:FL Epoch: 292 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1177
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1177 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409714
INFO:root:Worker: 1177 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433090
INFO:root:FL Epoch: 292 Norm Difference for worker 1177 is 1.055825
INFO:root:FL Epoch: 292 Done on worker:1177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1685
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531981
INFO:root:Worker: 1685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618935
INFO:root:FL Epoch: 292 Norm Difference for worker 1685 is 1.109515
INFO:root:FL Epoch: 292 Done on worker:1685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :175
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 175 Train Epoch: 0 [0/201 (0%)]	Loss: 0.390853
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 175 Train Epoch: 1 [0/201 (0%)]	Loss: 0.248986
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 292 Norm Difference for worker 175 is 1.040723
INFO:root:FL Epoch: 292 Done on worker:175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :376
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543830
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457181
INFO:root:FL Epoch: 292 Norm Difference for worker 376 is 1.064911
INFO:root:FL Epoch: 292 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1367
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450302
INFO:root:Worker: 1367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307185
INFO:root:FL Epoch: 292 Norm Difference for worker 1367 is 1.185095
INFO:root:FL Epoch: 292 Done on worker:1367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 175
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 292 Ends   ===================
INFO:root:Epoch:292 Global Model Test Loss:0.5121360578957725 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:292 Global Model Backdoor Test Loss:0.29357168078422546                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 293 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 293 Workers Selected : [48, 872, 1196, 1390, 1195, 341, 279, 241, 1160, 1421]
INFO:root:FL Epoch: 293 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 293 Num points on workers: [201 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 293 Training on worker :48
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.510458
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.542032
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 293 Norm Difference for worker 48 is 1.268378
INFO:root:FL Epoch: 293 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :872
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505603
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331035
INFO:root:FL Epoch: 293 Norm Difference for worker 872 is 1.083152
INFO:root:FL Epoch: 293 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1196
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1196 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465273
INFO:root:Worker: 1196 Train Epoch: 1 [0/200 (0%)]	Loss: 0.788009
INFO:root:FL Epoch: 293 Norm Difference for worker 1196 is 1.158222
INFO:root:FL Epoch: 293 Done on worker:1196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1390
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411172
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357915
INFO:root:FL Epoch: 293 Norm Difference for worker 1390 is 1.149403
INFO:root:FL Epoch: 293 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1195
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611636
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699655
INFO:root:FL Epoch: 293 Norm Difference for worker 1195 is 1.179686
INFO:root:FL Epoch: 293 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :341
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451561
INFO:root:Worker: 341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543126
INFO:root:FL Epoch: 293 Norm Difference for worker 341 is 1.168475
INFO:root:FL Epoch: 293 Done on worker:341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :279
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.654734
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488897
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 293 Norm Difference for worker 279 is 1.178812
INFO:root:FL Epoch: 293 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :241
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 241 Train Epoch: 0 [0/201 (0%)]	Loss: 0.648182
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 241 Train Epoch: 1 [0/201 (0%)]	Loss: 0.494542
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 293 Norm Difference for worker 241 is 1.22862
INFO:root:FL Epoch: 293 Done on worker:241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1160
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1160 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703765
INFO:root:Worker: 1160 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384049
INFO:root:FL Epoch: 293 Norm Difference for worker 1160 is 1.188396
INFO:root:FL Epoch: 293 Done on worker:1160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1421
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405717
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224763
INFO:root:FL Epoch: 293 Norm Difference for worker 1421 is 0.88302
INFO:root:FL Epoch: 293 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1421
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 293 Ends   ===================
INFO:root:Epoch:293 Global Model Test Loss:0.503912429599201 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:293 Global Model Backdoor Test Loss:0.18276947240034738                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 294 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 294 Workers Selected : [1770, 149, 1939, 1250, 809, 301, 636, 1925, 125, 1537]
INFO:root:FL Epoch: 294 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 294 Num points on workers: [200 201 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 294 Training on worker :1770
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664548
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402726
INFO:root:FL Epoch: 294 Norm Difference for worker 1770 is 1.330609
INFO:root:FL Epoch: 294 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :149
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 149 Train Epoch: 0 [0/201 (0%)]	Loss: 0.557845
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 149 Train Epoch: 1 [0/201 (0%)]	Loss: 0.324207
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 149 is 1.281434
INFO:root:FL Epoch: 294 Done on worker:149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1939
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696139
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403855
INFO:root:FL Epoch: 294 Norm Difference for worker 1939 is 1.377137
INFO:root:FL Epoch: 294 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1250
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557515
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555436
INFO:root:FL Epoch: 294 Norm Difference for worker 1250 is 1.339881
INFO:root:FL Epoch: 294 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :809
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555322
INFO:root:Worker: 809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496809
INFO:root:FL Epoch: 294 Norm Difference for worker 809 is 1.403533
INFO:root:FL Epoch: 294 Done on worker:809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :301
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.705655
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.636244
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 301 is 1.358592
INFO:root:FL Epoch: 294 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :636
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.892612
INFO:root:Worker: 636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353313
INFO:root:FL Epoch: 294 Norm Difference for worker 636 is 1.510409
INFO:root:FL Epoch: 294 Done on worker:636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1925
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452322
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443887
INFO:root:FL Epoch: 294 Norm Difference for worker 1925 is 1.177283
INFO:root:FL Epoch: 294 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :125
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500822
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.452895
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 125 is 1.242161
INFO:root:FL Epoch: 294 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1537
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706556
INFO:root:Worker: 1537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.764272
INFO:root:FL Epoch: 294 Norm Difference for worker 1537 is 1.380321
INFO:root:FL Epoch: 294 Done on worker:1537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1925
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 294 Ends   ===================
INFO:root:Epoch:294 Global Model Test Loss:0.5135208789040061 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:294 Global Model Backdoor Test Loss:0.3094217007358869                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 295 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 295 Workers Selected : [1495, 1264, 469, 1275, 734, 1533, 1555, 94, 311, 243]
INFO:root:FL Epoch: 295 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 295 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 295 Training on worker :1495
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732390
INFO:root:Worker: 1495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274312
INFO:root:FL Epoch: 295 Norm Difference for worker 1495 is 1.32616
INFO:root:FL Epoch: 295 Done on worker:1495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1264
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1264 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554212
INFO:root:Worker: 1264 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562744
INFO:root:FL Epoch: 295 Norm Difference for worker 1264 is 1.391783
INFO:root:FL Epoch: 295 Done on worker:1264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :469
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525457
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469316
INFO:root:FL Epoch: 295 Norm Difference for worker 469 is 1.2758
INFO:root:FL Epoch: 295 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1275
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.322812
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.155328
INFO:root:FL Epoch: 295 Norm Difference for worker 1275 is 0.953428
INFO:root:FL Epoch: 295 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :734
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801893
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546762
INFO:root:FL Epoch: 295 Norm Difference for worker 734 is 1.308251
INFO:root:FL Epoch: 295 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1533
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455232
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585616
INFO:root:FL Epoch: 295 Norm Difference for worker 1533 is 1.322632
INFO:root:FL Epoch: 295 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1555
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528272
INFO:root:Worker: 1555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599729
INFO:root:FL Epoch: 295 Norm Difference for worker 1555 is 1.335312
INFO:root:FL Epoch: 295 Done on worker:1555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :94
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/201 (0%)]	Loss: 0.763273
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 94 Train Epoch: 1 [0/201 (0%)]	Loss: 0.484821
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 295 Norm Difference for worker 94 is 1.431352
INFO:root:FL Epoch: 295 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :311
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.507167
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.517510
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 295 Norm Difference for worker 311 is 1.424914
INFO:root:FL Epoch: 295 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :243
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.752378
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.367363
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 295 Norm Difference for worker 243 is 1.292029
INFO:root:FL Epoch: 295 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1275
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 295 Ends   ===================
INFO:root:Epoch:295 Global Model Test Loss:0.551394415252349 and Test Accuracy:75.0 
INFO:root:Epoch:295 Global Model Backdoor Test Loss:0.2508607928951581                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 296 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 296 Workers Selected : [1199, 1172, 440, 207, 205, 542, 1428, 1348, 1135, 308]
INFO:root:FL Epoch: 296 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 296 Num points on workers: [200 200 200 201 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 296 Training on worker :1199
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464385
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410784
INFO:root:FL Epoch: 296 Norm Difference for worker 1199 is 1.505508
INFO:root:FL Epoch: 296 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1172
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1172 Train Epoch: 0 [0/200 (0%)]	Loss: 1.053919
INFO:root:Worker: 1172 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350060
INFO:root:FL Epoch: 296 Norm Difference for worker 1172 is 1.484952
INFO:root:FL Epoch: 296 Done on worker:1172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :440
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.261552
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341211
INFO:root:FL Epoch: 296 Norm Difference for worker 440 is 1.208393
INFO:root:FL Epoch: 296 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :207
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.402923
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.459444
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 207 is 1.47685
INFO:root:FL Epoch: 296 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :205
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.974073
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.339077
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 205 is 1.473062
INFO:root:FL Epoch: 296 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :542
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417493
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254416
INFO:root:FL Epoch: 296 Norm Difference for worker 542 is 1.222698
INFO:root:FL Epoch: 296 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1428
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752600
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394981
INFO:root:FL Epoch: 296 Norm Difference for worker 1428 is 1.515407
INFO:root:FL Epoch: 296 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1348
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.270815
INFO:root:Worker: 1348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282664
INFO:root:FL Epoch: 296 Norm Difference for worker 1348 is 1.338436
INFO:root:FL Epoch: 296 Done on worker:1348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1135
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1135 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769851
INFO:root:Worker: 1135 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418743
INFO:root:FL Epoch: 296 Norm Difference for worker 1135 is 1.549517
INFO:root:FL Epoch: 296 Done on worker:1135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :308
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.856031
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.625708
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 308 is 1.481621
INFO:root:FL Epoch: 296 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 542
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 296 Ends   ===================
INFO:root:Epoch:296 Global Model Test Loss:0.5653249165591072 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:296 Global Model Backdoor Test Loss:0.356147068242232                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 297 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 297 Workers Selected : [848, 769, 627, 413, 1061, 1302, 1445, 973, 110, 15]
INFO:root:FL Epoch: 297 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 297 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 297 Training on worker :848
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640034
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472951
INFO:root:FL Epoch: 297 Norm Difference for worker 848 is 1.575492
INFO:root:FL Epoch: 297 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :769
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742657
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283489
INFO:root:FL Epoch: 297 Norm Difference for worker 769 is 1.573285
INFO:root:FL Epoch: 297 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :627
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.790533
INFO:root:Worker: 627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395027
INFO:root:FL Epoch: 297 Norm Difference for worker 627 is 1.460506
INFO:root:FL Epoch: 297 Done on worker:627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :413
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654518
INFO:root:Worker: 413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379166
INFO:root:FL Epoch: 297 Norm Difference for worker 413 is 1.456955
INFO:root:FL Epoch: 297 Done on worker:413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1061
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.299976
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349191
INFO:root:FL Epoch: 297 Norm Difference for worker 1061 is 1.38568
INFO:root:FL Epoch: 297 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1302
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1302 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401651
INFO:root:Worker: 1302 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483113
INFO:root:FL Epoch: 297 Norm Difference for worker 1302 is 1.460878
INFO:root:FL Epoch: 297 Done on worker:1302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1445
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654173
INFO:root:Worker: 1445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368901
INFO:root:FL Epoch: 297 Norm Difference for worker 1445 is 1.496572
INFO:root:FL Epoch: 297 Done on worker:1445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :973
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802072
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233440
INFO:root:FL Epoch: 297 Norm Difference for worker 973 is 1.533017
INFO:root:FL Epoch: 297 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :110
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 110 Train Epoch: 0 [0/201 (0%)]	Loss: 0.661933
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 110 Train Epoch: 1 [0/201 (0%)]	Loss: 0.482090
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 297 Norm Difference for worker 110 is 1.463318
INFO:root:FL Epoch: 297 Done on worker:110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :15
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.824554
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.216390
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 297 Norm Difference for worker 15 is 1.269078
INFO:root:FL Epoch: 297 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 15
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 297 Ends   ===================
INFO:root:Epoch:297 Global Model Test Loss:0.5515504111261929 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:297 Global Model Backdoor Test Loss:0.3003636474410693                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 298 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 298 Workers Selected : [633, 77, 1548, 734, 1609, 1375, 1209, 1751, 1773, 1238]
INFO:root:FL Epoch: 298 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 298 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 298 Training on worker :633
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.235814
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618975
INFO:root:FL Epoch: 298 Norm Difference for worker 633 is 1.219889
INFO:root:FL Epoch: 298 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :77
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.472687
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.418415
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 298 Norm Difference for worker 77 is 1.217448
INFO:root:FL Epoch: 298 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1548
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664905
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459476
INFO:root:FL Epoch: 298 Norm Difference for worker 1548 is 1.350169
INFO:root:FL Epoch: 298 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :734
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466522
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465399
INFO:root:FL Epoch: 298 Norm Difference for worker 734 is 1.320223
INFO:root:FL Epoch: 298 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1609
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434661
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492725
INFO:root:FL Epoch: 298 Norm Difference for worker 1609 is 1.218686
INFO:root:FL Epoch: 298 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1375
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526867
INFO:root:Worker: 1375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330791
INFO:root:FL Epoch: 298 Norm Difference for worker 1375 is 1.397757
INFO:root:FL Epoch: 298 Done on worker:1375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1209
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1209 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693637
INFO:root:Worker: 1209 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253601
INFO:root:FL Epoch: 298 Norm Difference for worker 1209 is 1.281298
INFO:root:FL Epoch: 298 Done on worker:1209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1751
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708851
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441275
INFO:root:FL Epoch: 298 Norm Difference for worker 1751 is 1.287474
INFO:root:FL Epoch: 298 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1773
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655440
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455279
INFO:root:FL Epoch: 298 Norm Difference for worker 1773 is 1.318992
INFO:root:FL Epoch: 298 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1238
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.143802
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.148557
INFO:root:FL Epoch: 298 Norm Difference for worker 1238 is 0.980844
INFO:root:FL Epoch: 298 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1238
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 298 Ends   ===================
INFO:root:Epoch:298 Global Model Test Loss:0.5938893241040847 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:298 Global Model Backdoor Test Loss:0.36248612900575                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 299 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 299 Workers Selected : [1854, 1767, 1325, 857, 918, 86, 420, 564, 958, 800]
INFO:root:FL Epoch: 299 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 299 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 299 Training on worker :1854
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.874006
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469349
INFO:root:FL Epoch: 299 Norm Difference for worker 1854 is 1.680858
INFO:root:FL Epoch: 299 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1767
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511440
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313032
INFO:root:FL Epoch: 299 Norm Difference for worker 1767 is 1.473476
INFO:root:FL Epoch: 299 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1325
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1325 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511458
INFO:root:Worker: 1325 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490822
INFO:root:FL Epoch: 299 Norm Difference for worker 1325 is 1.557042
INFO:root:FL Epoch: 299 Done on worker:1325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :857
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564385
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387405
INFO:root:FL Epoch: 299 Norm Difference for worker 857 is 1.701804
INFO:root:FL Epoch: 299 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :918
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.790363
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558581
INFO:root:FL Epoch: 299 Norm Difference for worker 918 is 1.592296
INFO:root:FL Epoch: 299 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :86
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.620714
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.400118
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 299 Norm Difference for worker 86 is 1.478422
INFO:root:FL Epoch: 299 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :420
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.846031
INFO:root:Worker: 420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198373
INFO:root:FL Epoch: 299 Norm Difference for worker 420 is 1.61797
INFO:root:FL Epoch: 299 Done on worker:420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :564
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640494
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249877
INFO:root:FL Epoch: 299 Norm Difference for worker 564 is 1.500703
INFO:root:FL Epoch: 299 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :958
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794707
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386589
INFO:root:FL Epoch: 299 Norm Difference for worker 958 is 1.557178
INFO:root:FL Epoch: 299 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :800
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 1.370962
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380128
INFO:root:FL Epoch: 299 Norm Difference for worker 800 is 1.516787
INFO:root:FL Epoch: 299 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 86
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 299 Ends   ===================
INFO:root:Epoch:299 Global Model Test Loss:0.5312619279412663 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:299 Global Model Backdoor Test Loss:0.32844678312540054                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 300 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 300 Workers Selected : [1823, 1049, 1864, 1066, 1740, 1716, 840, 11, 1887, 845]
INFO:root:FL Epoch: 300 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 300 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 300 Training on worker :1823
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683314
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.895144
INFO:root:FL Epoch: 300 Norm Difference for worker 1823 is 1.332474
INFO:root:FL Epoch: 300 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1049
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1049 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549077
INFO:root:Worker: 1049 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490206
INFO:root:FL Epoch: 300 Norm Difference for worker 1049 is 1.193789
INFO:root:FL Epoch: 300 Done on worker:1049
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1864
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488395
INFO:root:Worker: 1864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504591
INFO:root:FL Epoch: 300 Norm Difference for worker 1864 is 1.161432
INFO:root:FL Epoch: 300 Done on worker:1864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1066
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1066 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742539
INFO:root:Worker: 1066 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461153
INFO:root:FL Epoch: 300 Norm Difference for worker 1066 is 1.282766
INFO:root:FL Epoch: 300 Done on worker:1066
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1740
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690176
INFO:root:Worker: 1740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661610
INFO:root:FL Epoch: 300 Norm Difference for worker 1740 is 1.2038
INFO:root:FL Epoch: 300 Done on worker:1740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1716
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442774
INFO:root:Worker: 1716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449168
INFO:root:FL Epoch: 300 Norm Difference for worker 1716 is 1.176295
INFO:root:FL Epoch: 300 Done on worker:1716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :840
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352545
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619013
INFO:root:FL Epoch: 300 Norm Difference for worker 840 is 1.194302
INFO:root:FL Epoch: 300 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :11
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 11 Train Epoch: 0 [0/201 (0%)]	Loss: 0.459328
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 11 Train Epoch: 1 [0/201 (0%)]	Loss: 0.544241
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 300 Norm Difference for worker 11 is 1.188346
INFO:root:FL Epoch: 300 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1887
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.902591
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.772598
INFO:root:FL Epoch: 300 Norm Difference for worker 1887 is 1.192639
INFO:root:FL Epoch: 300 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :845
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391860
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311410
INFO:root:FL Epoch: 300 Norm Difference for worker 845 is 1.181831
INFO:root:FL Epoch: 300 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1716
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 300 Ends   ===================
INFO:root:Epoch:300 Global Model Test Loss:0.5591770796214833 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:300 Global Model Backdoor Test Loss:0.43554002046585083                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 301 Begins ===================
INFO:root:FL Epoch: 301 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 301 Workers Selected : [0, 1, 2, 1526, 1322, 862, 701, 1726, 526, 1267]
INFO:root:FL Epoch: 301 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 301 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 301 Training on worker :0
INFO:root:FL Epoch: 301 Using Learning rate : 0.005484820084336939 
INFO:root:FL Epoch: 301 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.286708
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488745
INFO:root:FL Epoch: 301 Worker: 0 Backdoor Test Loss: 0.23166757076978683 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 301 Worker: 0 Backdoor Train Loss: 0.23163784593343734 Backdoor Train Accuracy: 93.0
INFO:root:FL Epoch: 301 Norm Difference for worker 0 is 0.268474
INFO:root:FL Epoch: 301 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1
INFO:root:FL Epoch: 301 Using Learning rate : 0.005484820084336939 
INFO:root:FL Epoch: 301 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436366
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323120
INFO:root:FL Epoch: 301 Worker: 1 Backdoor Test Loss: 0.23429924249649048 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 301 Worker: 1 Backdoor Train Loss: 0.23288701325654984 Backdoor Train Accuracy: 93.0
INFO:root:FL Epoch: 301 Norm Difference for worker 1 is 0.260248
INFO:root:FL Epoch: 301 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :2
INFO:root:FL Epoch: 301 Using Learning rate : 0.005484820084336939 
INFO:root:FL Epoch: 301 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314181
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227047
INFO:root:FL Epoch: 301 Worker: 2 Backdoor Test Loss: 0.2395890379945437 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 301 Worker: 2 Backdoor Train Loss: 0.23250045478343964 Backdoor Train Accuracy: 93.0
INFO:root:FL Epoch: 301 Norm Difference for worker 2 is 0.258164
INFO:root:FL Epoch: 301 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1526
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506317
INFO:root:Worker: 1526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360803
INFO:root:FL Epoch: 301 Norm Difference for worker 1526 is 1.106324
INFO:root:FL Epoch: 301 Done on worker:1526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1322
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1322 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575064
INFO:root:Worker: 1322 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420186
INFO:root:FL Epoch: 301 Norm Difference for worker 1322 is 1.202617
INFO:root:FL Epoch: 301 Done on worker:1322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :862
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694368
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326912
INFO:root:FL Epoch: 301 Norm Difference for worker 862 is 1.1356
INFO:root:FL Epoch: 301 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :701
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424646
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247286
INFO:root:FL Epoch: 301 Norm Difference for worker 701 is 1.057595
INFO:root:FL Epoch: 301 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1726
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722063
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502969
INFO:root:FL Epoch: 301 Norm Difference for worker 1726 is 1.148989
INFO:root:FL Epoch: 301 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :526
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543440
INFO:root:Worker: 526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656862
INFO:root:FL Epoch: 301 Norm Difference for worker 526 is 1.155221
INFO:root:FL Epoch: 301 Done on worker:526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1267
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1267 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312939
INFO:root:Worker: 1267 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361096
INFO:root:FL Epoch: 301 Norm Difference for worker 1267 is 1.075335
INFO:root:FL Epoch: 301 Done on worker:1267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 301 Ends   ===================
INFO:root:Epoch:301 Global Model Test Loss:0.5313000994570115 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:301 Global Model Backdoor Test Loss:0.23166757076978683                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 302 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 302 Workers Selected : [1911, 427, 1354, 10, 1326, 1947, 1506, 1248, 887, 1077]
INFO:root:FL Epoch: 302 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 302 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 302 Training on worker :1911
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625083
INFO:root:Worker: 1911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300267
INFO:root:FL Epoch: 302 Norm Difference for worker 1911 is 1.164113
INFO:root:FL Epoch: 302 Done on worker:1911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :427
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652225
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366785
INFO:root:FL Epoch: 302 Norm Difference for worker 427 is 1.180074
INFO:root:FL Epoch: 302 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1354
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769828
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347019
INFO:root:FL Epoch: 302 Norm Difference for worker 1354 is 1.169275
INFO:root:FL Epoch: 302 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :10
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 10 Train Epoch: 0 [0/201 (0%)]	Loss: 0.351004
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 10 Train Epoch: 1 [0/201 (0%)]	Loss: 0.386941
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 302 Norm Difference for worker 10 is 1.131618
INFO:root:FL Epoch: 302 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1326
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533299
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605825
INFO:root:FL Epoch: 302 Norm Difference for worker 1326 is 1.187831
INFO:root:FL Epoch: 302 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1947
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628716
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297132
INFO:root:FL Epoch: 302 Norm Difference for worker 1947 is 1.021369
INFO:root:FL Epoch: 302 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1506
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415595
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414297
INFO:root:FL Epoch: 302 Norm Difference for worker 1506 is 0.996183
INFO:root:FL Epoch: 302 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1248
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663338
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286143
INFO:root:FL Epoch: 302 Norm Difference for worker 1248 is 1.14024
INFO:root:FL Epoch: 302 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :887
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400270
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560000
INFO:root:FL Epoch: 302 Norm Difference for worker 887 is 1.193112
INFO:root:FL Epoch: 302 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1077
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1077 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308102
INFO:root:Worker: 1077 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252726
INFO:root:FL Epoch: 302 Norm Difference for worker 1077 is 1.076321
INFO:root:FL Epoch: 302 Done on worker:1077
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1947
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 302 Ends   ===================
INFO:root:Epoch:302 Global Model Test Loss:0.5108146053903243 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:302 Global Model Backdoor Test Loss:0.18060716862479845                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 303 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 303 Workers Selected : [1424, 869, 1947, 1218, 731, 391, 1873, 163, 1175, 1457]
INFO:root:FL Epoch: 303 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 303 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 303 Training on worker :1424
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441387
INFO:root:Worker: 1424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392945
INFO:root:FL Epoch: 303 Norm Difference for worker 1424 is 1.268389
INFO:root:FL Epoch: 303 Done on worker:1424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :869
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621446
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421492
INFO:root:FL Epoch: 303 Norm Difference for worker 869 is 1.331801
INFO:root:FL Epoch: 303 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1947
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.112955
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210051
INFO:root:FL Epoch: 303 Norm Difference for worker 1947 is 0.688952
INFO:root:FL Epoch: 303 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1218
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554599
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432055
INFO:root:FL Epoch: 303 Norm Difference for worker 1218 is 1.275659
INFO:root:FL Epoch: 303 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :731
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534488
INFO:root:Worker: 731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311088
INFO:root:FL Epoch: 303 Norm Difference for worker 731 is 1.279362
INFO:root:FL Epoch: 303 Done on worker:731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :391
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578526
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623859
INFO:root:FL Epoch: 303 Norm Difference for worker 391 is 1.375584
INFO:root:FL Epoch: 303 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1873
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397723
INFO:root:Worker: 1873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363344
INFO:root:FL Epoch: 303 Norm Difference for worker 1873 is 1.326203
INFO:root:FL Epoch: 303 Done on worker:1873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :163
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.520537
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.302341
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 303 Norm Difference for worker 163 is 1.33775
INFO:root:FL Epoch: 303 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1175
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.300935
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472257
INFO:root:FL Epoch: 303 Norm Difference for worker 1175 is 1.331351
INFO:root:FL Epoch: 303 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1457
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577984
INFO:root:Worker: 1457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393040
INFO:root:FL Epoch: 303 Norm Difference for worker 1457 is 1.221573
INFO:root:FL Epoch: 303 Done on worker:1457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1947
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 303 Ends   ===================
INFO:root:Epoch:303 Global Model Test Loss:0.5334658272126142 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:303 Global Model Backdoor Test Loss:0.14425223817427954                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 304 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 304 Workers Selected : [612, 1157, 1471, 128, 66, 879, 1042, 1632, 150, 1712]
INFO:root:FL Epoch: 304 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 304 Num points on workers: [200 200 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 304 Training on worker :612
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700801
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424199
INFO:root:FL Epoch: 304 Norm Difference for worker 612 is 1.59842
INFO:root:FL Epoch: 304 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1157
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770485
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422164
INFO:root:FL Epoch: 304 Norm Difference for worker 1157 is 1.608542
INFO:root:FL Epoch: 304 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1471
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325001
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355141
INFO:root:FL Epoch: 304 Norm Difference for worker 1471 is 1.62461
INFO:root:FL Epoch: 304 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :128
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.664611
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.492776
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 304 Norm Difference for worker 128 is 1.669178
INFO:root:FL Epoch: 304 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :66
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.383503
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.522361
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 304 Norm Difference for worker 66 is 1.535383
INFO:root:FL Epoch: 304 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :879
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509139
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552708
INFO:root:FL Epoch: 304 Norm Difference for worker 879 is 1.645859
INFO:root:FL Epoch: 304 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1042
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637942
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524725
INFO:root:FL Epoch: 304 Norm Difference for worker 1042 is 1.538577
INFO:root:FL Epoch: 304 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1632
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734380
INFO:root:Worker: 1632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502226
INFO:root:FL Epoch: 304 Norm Difference for worker 1632 is 1.586296
INFO:root:FL Epoch: 304 Done on worker:1632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :150
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 150 Train Epoch: 0 [0/201 (0%)]	Loss: 0.659638
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 150 Train Epoch: 1 [0/201 (0%)]	Loss: 0.344321
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 304 Norm Difference for worker 150 is 1.596951
INFO:root:FL Epoch: 304 Done on worker:150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1712
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558828
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658118
INFO:root:FL Epoch: 304 Norm Difference for worker 1712 is 1.618133
INFO:root:FL Epoch: 304 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1042
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 304 Ends   ===================
INFO:root:Epoch:304 Global Model Test Loss:0.5345748242209939 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:304 Global Model Backdoor Test Loss:0.19647872323791185                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 305 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 305 Workers Selected : [1124, 766, 284, 1589, 1409, 1883, 833, 1441, 847, 1423]
INFO:root:FL Epoch: 305 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 305 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 305 Training on worker :1124
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702207
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629245
INFO:root:FL Epoch: 305 Norm Difference for worker 1124 is 1.228439
INFO:root:FL Epoch: 305 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :766
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741601
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391110
INFO:root:FL Epoch: 305 Norm Difference for worker 766 is 1.134058
INFO:root:FL Epoch: 305 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :284
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.357143
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.619075
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 305 Norm Difference for worker 284 is 1.293637
INFO:root:FL Epoch: 305 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1589
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644374
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370465
INFO:root:FL Epoch: 305 Norm Difference for worker 1589 is 1.390832
INFO:root:FL Epoch: 305 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1409
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737610
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434633
INFO:root:FL Epoch: 305 Norm Difference for worker 1409 is 1.304676
INFO:root:FL Epoch: 305 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1883
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.913805
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666990
INFO:root:FL Epoch: 305 Norm Difference for worker 1883 is 1.312461
INFO:root:FL Epoch: 305 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :833
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433446
INFO:root:Worker: 833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511219
INFO:root:FL Epoch: 305 Norm Difference for worker 833 is 1.272923
INFO:root:FL Epoch: 305 Done on worker:833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1441
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544856
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528420
INFO:root:FL Epoch: 305 Norm Difference for worker 1441 is 1.28882
INFO:root:FL Epoch: 305 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :847
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488946
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468027
INFO:root:FL Epoch: 305 Norm Difference for worker 847 is 1.294895
INFO:root:FL Epoch: 305 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1423
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426070
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255921
INFO:root:FL Epoch: 305 Norm Difference for worker 1423 is 1.179989
INFO:root:FL Epoch: 305 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 766
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 305 Ends   ===================
INFO:root:Epoch:305 Global Model Test Loss:0.5223650984904346 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:305 Global Model Backdoor Test Loss:0.23418467988570532                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 306 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 306 Workers Selected : [534, 186, 452, 985, 1302, 1826, 274, 1833, 626, 1265]
INFO:root:FL Epoch: 306 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 306 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 306 Training on worker :534
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563697
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237003
INFO:root:FL Epoch: 306 Norm Difference for worker 534 is 1.330498
INFO:root:FL Epoch: 306 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :186
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 186 Train Epoch: 0 [0/201 (0%)]	Loss: 0.442622
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 186 Train Epoch: 1 [0/201 (0%)]	Loss: 0.270552
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 306 Norm Difference for worker 186 is 1.145972
INFO:root:FL Epoch: 306 Done on worker:186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :452
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404579
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518724
INFO:root:FL Epoch: 306 Norm Difference for worker 452 is 1.204771
INFO:root:FL Epoch: 306 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :985
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 985 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629757
INFO:root:Worker: 985 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462704
INFO:root:FL Epoch: 306 Norm Difference for worker 985 is 1.188715
INFO:root:FL Epoch: 306 Done on worker:985
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1302
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1302 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517556
INFO:root:Worker: 1302 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201510
INFO:root:FL Epoch: 306 Norm Difference for worker 1302 is 1.235584
INFO:root:FL Epoch: 306 Done on worker:1302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1826
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722178
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520739
INFO:root:FL Epoch: 306 Norm Difference for worker 1826 is 1.170571
INFO:root:FL Epoch: 306 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :274
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.531405
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.324638
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 306 Norm Difference for worker 274 is 1.107132
INFO:root:FL Epoch: 306 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1833
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561669
INFO:root:Worker: 1833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397243
INFO:root:FL Epoch: 306 Norm Difference for worker 1833 is 1.169892
INFO:root:FL Epoch: 306 Done on worker:1833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :626
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387533
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261703
INFO:root:FL Epoch: 306 Norm Difference for worker 626 is 1.190626
INFO:root:FL Epoch: 306 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1265
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456175
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277989
INFO:root:FL Epoch: 306 Norm Difference for worker 1265 is 1.122492
INFO:root:FL Epoch: 306 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 274
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 306 Ends   ===================
INFO:root:Epoch:306 Global Model Test Loss:0.5303452698623433 and Test Accuracy:75.0 
INFO:root:Epoch:306 Global Model Backdoor Test Loss:0.21967211365699768                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 307 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 307 Workers Selected : [1731, 1909, 1927, 1664, 392, 575, 1365, 308, 1329, 142]
INFO:root:FL Epoch: 307 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.1003996]
INFO:root:FL Epoch: 307 Num points on workers: [200 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 307 Training on worker :1731
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387612
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384897
INFO:root:FL Epoch: 307 Norm Difference for worker 1731 is 1.206023
INFO:root:FL Epoch: 307 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1909
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.797000
INFO:root:Worker: 1909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423921
INFO:root:FL Epoch: 307 Norm Difference for worker 1909 is 1.186223
INFO:root:FL Epoch: 307 Done on worker:1909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1927
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375452
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619851
INFO:root:FL Epoch: 307 Norm Difference for worker 1927 is 1.20542
INFO:root:FL Epoch: 307 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1664
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.877814
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424076
INFO:root:FL Epoch: 307 Norm Difference for worker 1664 is 1.140146
INFO:root:FL Epoch: 307 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :392
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430229
INFO:root:Worker: 392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397442
INFO:root:FL Epoch: 307 Norm Difference for worker 392 is 1.134206
INFO:root:FL Epoch: 307 Done on worker:392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :575
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556875
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675755
INFO:root:FL Epoch: 307 Norm Difference for worker 575 is 1.384443
INFO:root:FL Epoch: 307 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1365
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348991
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243797
INFO:root:FL Epoch: 307 Norm Difference for worker 1365 is 1.221542
INFO:root:FL Epoch: 307 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :308
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.809648
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.348029
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 307 Norm Difference for worker 308 is 1.178186
INFO:root:FL Epoch: 307 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1329
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593817
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561526
INFO:root:FL Epoch: 307 Norm Difference for worker 1329 is 1.204396
INFO:root:FL Epoch: 307 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :142
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 142 Train Epoch: 0 [0/201 (0%)]	Loss: 0.496953
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 142 Train Epoch: 1 [0/201 (0%)]	Loss: 0.292840
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 307 Norm Difference for worker 142 is 1.158806
INFO:root:FL Epoch: 307 Done on worker:142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 142
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 307 Ends   ===================
INFO:root:Epoch:307 Global Model Test Loss:0.5363993101260242 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:307 Global Model Backdoor Test Loss:0.22393275052309036                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 308 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 308 Workers Selected : [65, 163, 504, 120, 1859, 1651, 1272, 595, 487, 1181]
INFO:root:FL Epoch: 308 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 308 Num points on workers: [201 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 308 Training on worker :65
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.421746
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483966
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 308 Norm Difference for worker 65 is 1.074736
INFO:root:FL Epoch: 308 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :163
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694239
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.562473
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 308 Norm Difference for worker 163 is 1.096053
INFO:root:FL Epoch: 308 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :504
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494019
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382465
INFO:root:FL Epoch: 308 Norm Difference for worker 504 is 1.022527
INFO:root:FL Epoch: 308 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :120
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 120 Train Epoch: 0 [0/201 (0%)]	Loss: 0.428556
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 120 Train Epoch: 1 [0/201 (0%)]	Loss: 0.256840
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 308 Norm Difference for worker 120 is 1.002715
INFO:root:FL Epoch: 308 Done on worker:120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1859
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584816
INFO:root:Worker: 1859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433481
INFO:root:FL Epoch: 308 Norm Difference for worker 1859 is 1.108849
INFO:root:FL Epoch: 308 Done on worker:1859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1651
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518873
INFO:root:Worker: 1651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369167
INFO:root:FL Epoch: 308 Norm Difference for worker 1651 is 1.090608
INFO:root:FL Epoch: 308 Done on worker:1651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1272
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1272 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696944
INFO:root:Worker: 1272 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603704
INFO:root:FL Epoch: 308 Norm Difference for worker 1272 is 1.031712
INFO:root:FL Epoch: 308 Done on worker:1272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :595
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572146
INFO:root:Worker: 595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294590
INFO:root:FL Epoch: 308 Norm Difference for worker 595 is 1.055208
INFO:root:FL Epoch: 308 Done on worker:595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :487
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499869
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430333
INFO:root:FL Epoch: 308 Norm Difference for worker 487 is 0.988343
INFO:root:FL Epoch: 308 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1181
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647943
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380704
INFO:root:FL Epoch: 308 Norm Difference for worker 1181 is 1.006013
INFO:root:FL Epoch: 308 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 487
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 308 Ends   ===================
INFO:root:Epoch:308 Global Model Test Loss:0.537492070127936 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:308 Global Model Backdoor Test Loss:0.29178163160880405                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 309 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 309 Workers Selected : [659, 1630, 147, 1704, 1338, 376, 790, 1004, 1131, 172]
INFO:root:FL Epoch: 309 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 309 Num points on workers: [200 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 309 Training on worker :659
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753419
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548105
INFO:root:FL Epoch: 309 Norm Difference for worker 659 is 1.142402
INFO:root:FL Epoch: 309 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1630
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458914
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363403
INFO:root:FL Epoch: 309 Norm Difference for worker 1630 is 1.100571
INFO:root:FL Epoch: 309 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :147
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.569945
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450107
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 309 Norm Difference for worker 147 is 1.011341
INFO:root:FL Epoch: 309 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1704
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650403
INFO:root:Worker: 1704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546402
INFO:root:FL Epoch: 309 Norm Difference for worker 1704 is 1.018005
INFO:root:FL Epoch: 309 Done on worker:1704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1338
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521924
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476393
INFO:root:FL Epoch: 309 Norm Difference for worker 1338 is 0.978183
INFO:root:FL Epoch: 309 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :376
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412828
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531265
INFO:root:FL Epoch: 309 Norm Difference for worker 376 is 1.021863
INFO:root:FL Epoch: 309 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :790
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621589
INFO:root:Worker: 790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506528
INFO:root:FL Epoch: 309 Norm Difference for worker 790 is 1.133831
INFO:root:FL Epoch: 309 Done on worker:790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1004
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1004 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575903
INFO:root:Worker: 1004 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511774
INFO:root:FL Epoch: 309 Norm Difference for worker 1004 is 1.060701
INFO:root:FL Epoch: 309 Done on worker:1004
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1131
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370341
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412817
INFO:root:FL Epoch: 309 Norm Difference for worker 1131 is 1.089692
INFO:root:FL Epoch: 309 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :172
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.557106
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.402225
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 309 Norm Difference for worker 172 is 0.979332
INFO:root:FL Epoch: 309 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1338
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 309 Ends   ===================
INFO:root:Epoch:309 Global Model Test Loss:0.5316947049954358 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:309 Global Model Backdoor Test Loss:0.24039353678623834                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 310 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 310 Workers Selected : [191, 844, 1062, 1182, 1038, 791, 1015, 160, 803, 902]
INFO:root:FL Epoch: 310 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 310 Num points on workers: [201 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 310 Training on worker :191
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.353847
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.661144
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 310 Norm Difference for worker 191 is 1.09524
INFO:root:FL Epoch: 310 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :844
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406210
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432020
INFO:root:FL Epoch: 310 Norm Difference for worker 844 is 0.992848
INFO:root:FL Epoch: 310 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1062
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1062 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650791
INFO:root:Worker: 1062 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623948
INFO:root:FL Epoch: 310 Norm Difference for worker 1062 is 1.031744
INFO:root:FL Epoch: 310 Done on worker:1062
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1182
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353841
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322800
INFO:root:FL Epoch: 310 Norm Difference for worker 1182 is 0.945246
INFO:root:FL Epoch: 310 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1038
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1038 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595276
INFO:root:Worker: 1038 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444113
INFO:root:FL Epoch: 310 Norm Difference for worker 1038 is 1.105988
INFO:root:FL Epoch: 310 Done on worker:1038
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :791
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608923
INFO:root:Worker: 791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336098
INFO:root:FL Epoch: 310 Norm Difference for worker 791 is 1.073252
INFO:root:FL Epoch: 310 Done on worker:791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1015
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558420
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454427
INFO:root:FL Epoch: 310 Norm Difference for worker 1015 is 1.030561
INFO:root:FL Epoch: 310 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :160
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.401727
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.346453
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 310 Norm Difference for worker 160 is 1.078705
INFO:root:FL Epoch: 310 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :803
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496127
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398271
INFO:root:FL Epoch: 310 Norm Difference for worker 803 is 1.001657
INFO:root:FL Epoch: 310 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :902
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408284
INFO:root:Worker: 902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416102
INFO:root:FL Epoch: 310 Norm Difference for worker 902 is 0.963232
INFO:root:FL Epoch: 310 Done on worker:902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1182
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 310 Ends   ===================
INFO:root:Epoch:310 Global Model Test Loss:0.5430162671734305 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:310 Global Model Backdoor Test Loss:0.304610716799895                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 311 Begins ===================
INFO:root:FL Epoch: 311 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 311 Workers Selected : [0, 1, 2, 212, 603, 1485, 1334, 260, 1352, 1619]
INFO:root:FL Epoch: 311 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 311 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 311 Training on worker :0
INFO:root:FL Epoch: 311 Using Learning rate : 0.00537610570322294 
INFO:root:FL Epoch: 311 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.322852
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330106
INFO:root:FL Epoch: 311 Worker: 0 Backdoor Test Loss: 0.20287611708045006 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 311 Worker: 0 Backdoor Train Loss: 0.21179731115698813 Backdoor Train Accuracy: 94.0
INFO:root:FL Epoch: 311 Norm Difference for worker 0 is 0.210417
INFO:root:FL Epoch: 311 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1
INFO:root:FL Epoch: 311 Using Learning rate : 0.00537610570322294 
INFO:root:FL Epoch: 311 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.123051
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282378
INFO:root:FL Epoch: 311 Worker: 1 Backdoor Test Loss: 0.2012121764322122 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 311 Worker: 1 Backdoor Train Loss: 0.212160924077034 Backdoor Train Accuracy: 94.0
INFO:root:FL Epoch: 311 Norm Difference for worker 1 is 0.208798
INFO:root:FL Epoch: 311 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :2
INFO:root:FL Epoch: 311 Using Learning rate : 0.00537610570322294 
INFO:root:FL Epoch: 311 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.298781
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.155629
INFO:root:FL Epoch: 311 Worker: 2 Backdoor Test Loss: 0.1927336777249972 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 311 Worker: 2 Backdoor Train Loss: 0.21295364424586297 Backdoor Train Accuracy: 94.0
INFO:root:FL Epoch: 311 Norm Difference for worker 2 is 0.21036
INFO:root:FL Epoch: 311 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :212
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.807054
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.544529
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 311 Norm Difference for worker 212 is 1.141869
INFO:root:FL Epoch: 311 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :603
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738828
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554163
INFO:root:FL Epoch: 311 Norm Difference for worker 603 is 1.113557
INFO:root:FL Epoch: 311 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1485
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632477
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476462
INFO:root:FL Epoch: 311 Norm Difference for worker 1485 is 1.162352
INFO:root:FL Epoch: 311 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1334
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472186
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587608
INFO:root:FL Epoch: 311 Norm Difference for worker 1334 is 1.12682
INFO:root:FL Epoch: 311 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :260
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.408862
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.556132
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 311 Norm Difference for worker 260 is 1.118122
INFO:root:FL Epoch: 311 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1352
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412534
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505766
INFO:root:FL Epoch: 311 Norm Difference for worker 1352 is 1.189959
INFO:root:FL Epoch: 311 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1619
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577807
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583659
INFO:root:FL Epoch: 311 Norm Difference for worker 1619 is 1.155241
INFO:root:FL Epoch: 311 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 311 Ends   ===================
INFO:root:Epoch:311 Global Model Test Loss:0.5376113390221315 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:311 Global Model Backdoor Test Loss:0.1927336777249972                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 312 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 312 Workers Selected : [254, 253, 267, 1281, 552, 1889, 1555, 1475, 334, 202]
INFO:root:FL Epoch: 312 Fraction of points on each worker in this round: [0.10024938 0.10024938 0.10024938 0.09975062 0.09975062 0.09975062
 0.09975062 0.09975062 0.10024938 0.10024938]
INFO:root:FL Epoch: 312 Num points on workers: [201 201 201 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 312 Training on worker :254
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 254 Train Epoch: 0 [0/201 (0%)]	Loss: 0.684621
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 254 Train Epoch: 1 [0/201 (0%)]	Loss: 0.218492
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 312 Norm Difference for worker 254 is 1.10122
INFO:root:FL Epoch: 312 Done on worker:254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :253
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.556306
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.295938
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 312 Norm Difference for worker 253 is 1.117185
INFO:root:FL Epoch: 312 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :267
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 267 Train Epoch: 0 [0/201 (0%)]	Loss: 0.499106
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 267 Train Epoch: 1 [0/201 (0%)]	Loss: 0.376319
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 312 Norm Difference for worker 267 is 1.200445
INFO:root:FL Epoch: 312 Done on worker:267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1281
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1281 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561112
INFO:root:Worker: 1281 Train Epoch: 1 [0/200 (0%)]	Loss: 0.756502
INFO:root:FL Epoch: 312 Norm Difference for worker 1281 is 1.172101
INFO:root:FL Epoch: 312 Done on worker:1281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :552
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613920
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.720834
INFO:root:FL Epoch: 312 Norm Difference for worker 552 is 1.2074
INFO:root:FL Epoch: 312 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1889
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.286004
INFO:root:Worker: 1889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561013
INFO:root:FL Epoch: 312 Norm Difference for worker 1889 is 1.14148
INFO:root:FL Epoch: 312 Done on worker:1889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1555
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1555 Train Epoch: 0 [0/200 (0%)]	Loss: 1.043486
INFO:root:Worker: 1555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293795
INFO:root:FL Epoch: 312 Norm Difference for worker 1555 is 1.173001
INFO:root:FL Epoch: 312 Done on worker:1555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1475
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375134
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425994
INFO:root:FL Epoch: 312 Norm Difference for worker 1475 is 1.196286
INFO:root:FL Epoch: 312 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :334
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.681998
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.300249
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 312 Norm Difference for worker 334 is 1.155636
INFO:root:FL Epoch: 312 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :202
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.771414
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.297886
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 312 Norm Difference for worker 202 is 1.221024
INFO:root:FL Epoch: 312 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 254
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 312 Ends   ===================
INFO:root:Epoch:312 Global Model Test Loss:0.5476054759586558 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:312 Global Model Backdoor Test Loss:0.20532591144243875                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 313 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 313 Workers Selected : [173, 1677, 1063, 828, 1243, 1645, 701, 511, 1769, 539]
INFO:root:FL Epoch: 313 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 313 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 313 Training on worker :173
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.486554
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.404336
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 313 Norm Difference for worker 173 is 1.129343
INFO:root:FL Epoch: 313 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1677
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.861147
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484383
INFO:root:FL Epoch: 313 Norm Difference for worker 1677 is 1.084654
INFO:root:FL Epoch: 313 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1063
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380881
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302056
INFO:root:FL Epoch: 313 Norm Difference for worker 1063 is 1.031726
INFO:root:FL Epoch: 313 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :828
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547396
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590071
INFO:root:FL Epoch: 313 Norm Difference for worker 828 is 1.292498
INFO:root:FL Epoch: 313 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1243
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736767
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634015
INFO:root:FL Epoch: 313 Norm Difference for worker 1243 is 1.151593
INFO:root:FL Epoch: 313 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1645
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475797
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394311
INFO:root:FL Epoch: 313 Norm Difference for worker 1645 is 1.115908
INFO:root:FL Epoch: 313 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :701
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449899
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555645
INFO:root:FL Epoch: 313 Norm Difference for worker 701 is 1.090997
INFO:root:FL Epoch: 313 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :511
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587771
INFO:root:Worker: 511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222052
INFO:root:FL Epoch: 313 Norm Difference for worker 511 is 1.027175
INFO:root:FL Epoch: 313 Done on worker:511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1769
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499608
INFO:root:Worker: 1769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362589
INFO:root:FL Epoch: 313 Norm Difference for worker 1769 is 1.116749
INFO:root:FL Epoch: 313 Done on worker:1769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :539
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645517
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505034
INFO:root:FL Epoch: 313 Norm Difference for worker 539 is 1.101459
INFO:root:FL Epoch: 313 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 511
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 313 Ends   ===================
INFO:root:Epoch:313 Global Model Test Loss:0.5305192943881539 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:313 Global Model Backdoor Test Loss:0.2438183774550756                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 314 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 314 Workers Selected : [1682, 817, 747, 1065, 615, 439, 501, 1941, 729, 1621]
INFO:root:FL Epoch: 314 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 314 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 314 Training on worker :1682
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490824
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357943
INFO:root:FL Epoch: 314 Norm Difference for worker 1682 is 0.998815
INFO:root:FL Epoch: 314 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :817
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600485
INFO:root:Worker: 817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364172
INFO:root:FL Epoch: 314 Norm Difference for worker 817 is 1.038351
INFO:root:FL Epoch: 314 Done on worker:817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :747
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539702
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593903
INFO:root:FL Epoch: 314 Norm Difference for worker 747 is 1.025167
INFO:root:FL Epoch: 314 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1065
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463845
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420177
INFO:root:FL Epoch: 314 Norm Difference for worker 1065 is 1.110969
INFO:root:FL Epoch: 314 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :615
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 615 Train Epoch: 0 [0/200 (0%)]	Loss: 0.283412
INFO:root:Worker: 615 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388298
INFO:root:FL Epoch: 314 Norm Difference for worker 615 is 1.078573
INFO:root:FL Epoch: 314 Done on worker:615
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :439
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418628
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318548
INFO:root:FL Epoch: 314 Norm Difference for worker 439 is 1.047475
INFO:root:FL Epoch: 314 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :501
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356520
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435892
INFO:root:FL Epoch: 314 Norm Difference for worker 501 is 1.010789
INFO:root:FL Epoch: 314 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1941
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.841189
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345826
INFO:root:FL Epoch: 314 Norm Difference for worker 1941 is 0.983654
INFO:root:FL Epoch: 314 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :729
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638977
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435882
INFO:root:FL Epoch: 314 Norm Difference for worker 729 is 1.01755
INFO:root:FL Epoch: 314 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1621
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542128
INFO:root:Worker: 1621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492939
INFO:root:FL Epoch: 314 Norm Difference for worker 1621 is 1.078335
INFO:root:FL Epoch: 314 Done on worker:1621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1941
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 314 Ends   ===================
INFO:root:Epoch:314 Global Model Test Loss:0.5253976004965165 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:314 Global Model Backdoor Test Loss:0.2748675321539243                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 315 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 315 Workers Selected : [1247, 1891, 1092, 1160, 1542, 1248, 1758, 206, 881, 1311]
INFO:root:FL Epoch: 315 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 315 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 315 Training on worker :1247
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403256
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389247
INFO:root:FL Epoch: 315 Norm Difference for worker 1247 is 0.92989
INFO:root:FL Epoch: 315 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1891
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.313190
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477285
INFO:root:FL Epoch: 315 Norm Difference for worker 1891 is 0.995695
INFO:root:FL Epoch: 315 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1092
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639527
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568096
INFO:root:FL Epoch: 315 Norm Difference for worker 1092 is 1.03274
INFO:root:FL Epoch: 315 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1160
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1160 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384028
INFO:root:Worker: 1160 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505887
INFO:root:FL Epoch: 315 Norm Difference for worker 1160 is 1.004124
INFO:root:FL Epoch: 315 Done on worker:1160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1542
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455907
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361599
INFO:root:FL Epoch: 315 Norm Difference for worker 1542 is 0.936745
INFO:root:FL Epoch: 315 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1248
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514316
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475520
INFO:root:FL Epoch: 315 Norm Difference for worker 1248 is 0.928707
INFO:root:FL Epoch: 315 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1758
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523342
INFO:root:Worker: 1758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482155
INFO:root:FL Epoch: 315 Norm Difference for worker 1758 is 1.001113
INFO:root:FL Epoch: 315 Done on worker:1758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :206
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.501084
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.387036
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 315 Norm Difference for worker 206 is 0.90709
INFO:root:FL Epoch: 315 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :881
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503699
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357442
INFO:root:FL Epoch: 315 Norm Difference for worker 881 is 0.925732
INFO:root:FL Epoch: 315 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1311
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590185
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566687
INFO:root:FL Epoch: 315 Norm Difference for worker 1311 is 1.012947
INFO:root:FL Epoch: 315 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 881
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 315 Ends   ===================
INFO:root:Epoch:315 Global Model Test Loss:0.48692723582772646 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:315 Global Model Backdoor Test Loss:0.1937765454252561                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 316 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 316 Workers Selected : [670, 77, 14, 831, 557, 1196, 1519, 237, 1512, 592]
INFO:root:FL Epoch: 316 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 316 Num points on workers: [200 201 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 316 Training on worker :670
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766004
INFO:root:Worker: 670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486847
INFO:root:FL Epoch: 316 Norm Difference for worker 670 is 1.115988
INFO:root:FL Epoch: 316 Done on worker:670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :77
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.601948
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.498082
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 316 Norm Difference for worker 77 is 0.995094
INFO:root:FL Epoch: 316 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :14
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.947361
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.426660
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 316 Norm Difference for worker 14 is 1.068314
INFO:root:FL Epoch: 316 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :831
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498066
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350649
INFO:root:FL Epoch: 316 Norm Difference for worker 831 is 0.999228
INFO:root:FL Epoch: 316 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :557
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584316
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394173
INFO:root:FL Epoch: 316 Norm Difference for worker 557 is 0.985916
INFO:root:FL Epoch: 316 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1196
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1196 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637956
INFO:root:Worker: 1196 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440298
INFO:root:FL Epoch: 316 Norm Difference for worker 1196 is 1.108464
INFO:root:FL Epoch: 316 Done on worker:1196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1519
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441880
INFO:root:Worker: 1519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580603
INFO:root:FL Epoch: 316 Norm Difference for worker 1519 is 1.012385
INFO:root:FL Epoch: 316 Done on worker:1519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :237
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 237 Train Epoch: 0 [0/201 (0%)]	Loss: 0.359174
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 237 Train Epoch: 1 [0/201 (0%)]	Loss: 0.509027
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 316 Norm Difference for worker 237 is 1.100821
INFO:root:FL Epoch: 316 Done on worker:237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1512
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542369
INFO:root:Worker: 1512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414841
INFO:root:FL Epoch: 316 Norm Difference for worker 1512 is 1.052961
INFO:root:FL Epoch: 316 Done on worker:1512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :592
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460578
INFO:root:Worker: 592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344695
INFO:root:FL Epoch: 316 Norm Difference for worker 592 is 1.053179
INFO:root:FL Epoch: 316 Done on worker:592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 557
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 316 Ends   ===================
INFO:root:Epoch:316 Global Model Test Loss:0.492831990999334 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:316 Global Model Backdoor Test Loss:0.21467490990956625                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 317 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 317 Workers Selected : [300, 251, 562, 1356, 204, 809, 968, 1645, 1482, 844]
INFO:root:FL Epoch: 317 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 317 Num points on workers: [201 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 317 Training on worker :300
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.417783
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.535999
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 300 is 0.955364
INFO:root:FL Epoch: 317 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :251
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 251 Train Epoch: 0 [0/201 (0%)]	Loss: 0.463464
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 251 Train Epoch: 1 [0/201 (0%)]	Loss: 0.413690
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 251 is 0.966558
INFO:root:FL Epoch: 317 Done on worker:251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :562
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461381
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480593
INFO:root:FL Epoch: 317 Norm Difference for worker 562 is 1.024462
INFO:root:FL Epoch: 317 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :1356
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.938483
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672083
INFO:root:FL Epoch: 317 Norm Difference for worker 1356 is 1.061268
INFO:root:FL Epoch: 317 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :204
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.748022
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.481075
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 204 is 1.010507
INFO:root:FL Epoch: 317 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :809
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644645
INFO:root:Worker: 809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552390
INFO:root:FL Epoch: 317 Norm Difference for worker 809 is 1.000527
INFO:root:FL Epoch: 317 Done on worker:809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :968
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413175
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.861914
INFO:root:FL Epoch: 317 Norm Difference for worker 968 is 1.053937
INFO:root:FL Epoch: 317 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :1645
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.286291
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469764
INFO:root:FL Epoch: 317 Norm Difference for worker 1645 is 0.966844
INFO:root:FL Epoch: 317 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :1482
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499729
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314762
INFO:root:FL Epoch: 317 Norm Difference for worker 1482 is 0.946644
INFO:root:FL Epoch: 317 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :844
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367572
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387978
INFO:root:FL Epoch: 317 Norm Difference for worker 844 is 0.930859
INFO:root:FL Epoch: 317 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 844
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 317 Ends   ===================
INFO:root:Epoch:317 Global Model Test Loss:0.5059452144538655 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:317 Global Model Backdoor Test Loss:0.2503243312239647                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 318 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 318 Workers Selected : [191, 1890, 999, 1404, 725, 1853, 1315, 1082, 862, 84]
INFO:root:FL Epoch: 318 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 318 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 318 Training on worker :191
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.453426
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.392254
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 318 Norm Difference for worker 191 is 0.991227
INFO:root:FL Epoch: 318 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1890
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666197
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377361
INFO:root:FL Epoch: 318 Norm Difference for worker 1890 is 0.992705
INFO:root:FL Epoch: 318 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :999
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.814075
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511608
INFO:root:FL Epoch: 318 Norm Difference for worker 999 is 0.962661
INFO:root:FL Epoch: 318 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1404
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382821
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352946
INFO:root:FL Epoch: 318 Norm Difference for worker 1404 is 0.917175
INFO:root:FL Epoch: 318 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :725
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448423
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417281
INFO:root:FL Epoch: 318 Norm Difference for worker 725 is 0.950458
INFO:root:FL Epoch: 318 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1853
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758688
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584360
INFO:root:FL Epoch: 318 Norm Difference for worker 1853 is 1.042517
INFO:root:FL Epoch: 318 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1315
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381393
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593471
INFO:root:FL Epoch: 318 Norm Difference for worker 1315 is 1.0467
INFO:root:FL Epoch: 318 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1082
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400589
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475728
INFO:root:FL Epoch: 318 Norm Difference for worker 1082 is 0.926407
INFO:root:FL Epoch: 318 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :862
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480458
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601479
INFO:root:FL Epoch: 318 Norm Difference for worker 862 is 1.021078
INFO:root:FL Epoch: 318 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :84
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 84 Train Epoch: 0 [0/201 (0%)]	Loss: 0.447801
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 84 Train Epoch: 1 [0/201 (0%)]	Loss: 0.352046
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 318 Norm Difference for worker 84 is 0.948014
INFO:root:FL Epoch: 318 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1404
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 318 Ends   ===================
INFO:root:Epoch:318 Global Model Test Loss:0.5182748542112463 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:318 Global Model Backdoor Test Loss:0.22626252472400665                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 319 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 319 Workers Selected : [917, 474, 748, 1071, 436, 1413, 141, 439, 281, 1415]
INFO:root:FL Epoch: 319 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 319 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 319 Training on worker :917
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.855501
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457044
INFO:root:FL Epoch: 319 Norm Difference for worker 917 is 1.093845
INFO:root:FL Epoch: 319 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :474
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606249
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626133
INFO:root:FL Epoch: 319 Norm Difference for worker 474 is 1.092309
INFO:root:FL Epoch: 319 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :748
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667238
INFO:root:Worker: 748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423282
INFO:root:FL Epoch: 319 Norm Difference for worker 748 is 1.12163
INFO:root:FL Epoch: 319 Done on worker:748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1071
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1071 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468916
INFO:root:Worker: 1071 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582604
INFO:root:FL Epoch: 319 Norm Difference for worker 1071 is 1.04185
INFO:root:FL Epoch: 319 Done on worker:1071
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :436
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579946
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.833360
INFO:root:FL Epoch: 319 Norm Difference for worker 436 is 1.072317
INFO:root:FL Epoch: 319 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1413
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740152
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309492
INFO:root:FL Epoch: 319 Norm Difference for worker 1413 is 1.010301
INFO:root:FL Epoch: 319 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :141
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.599919
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.354837
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 319 Norm Difference for worker 141 is 1.040181
INFO:root:FL Epoch: 319 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :439
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549041
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473500
INFO:root:FL Epoch: 319 Norm Difference for worker 439 is 1.016617
INFO:root:FL Epoch: 319 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :281
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 281 Train Epoch: 0 [0/201 (0%)]	Loss: 0.493938
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 281 Train Epoch: 1 [0/201 (0%)]	Loss: 0.342847
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 319 Norm Difference for worker 281 is 0.977739
INFO:root:FL Epoch: 319 Done on worker:281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1415
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.890518
INFO:root:Worker: 1415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680709
INFO:root:FL Epoch: 319 Norm Difference for worker 1415 is 1.053859
INFO:root:FL Epoch: 319 Done on worker:1415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 281
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 319 Ends   ===================
INFO:root:Epoch:319 Global Model Test Loss:0.5172320376424229 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:319 Global Model Backdoor Test Loss:0.1930660493671894                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 320 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 320 Workers Selected : [672, 1130, 89, 766, 604, 1934, 1085, 1785, 799, 394]
INFO:root:FL Epoch: 320 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 320 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 320 Training on worker :672
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.811420
INFO:root:Worker: 672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457858
INFO:root:FL Epoch: 320 Norm Difference for worker 672 is 0.932821
INFO:root:FL Epoch: 320 Done on worker:672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1130
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1130 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643408
INFO:root:Worker: 1130 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438792
INFO:root:FL Epoch: 320 Norm Difference for worker 1130 is 1.04542
INFO:root:FL Epoch: 320 Done on worker:1130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :89
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 89 Train Epoch: 0 [0/201 (0%)]	Loss: 0.448943
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 89 Train Epoch: 1 [0/201 (0%)]	Loss: 0.566389
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 89 is 0.959746
INFO:root:FL Epoch: 320 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :766
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391203
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217430
INFO:root:FL Epoch: 320 Norm Difference for worker 766 is 0.813726
INFO:root:FL Epoch: 320 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :604
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589768
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551774
INFO:root:FL Epoch: 320 Norm Difference for worker 604 is 0.966726
INFO:root:FL Epoch: 320 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1934
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.818310
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522017
INFO:root:FL Epoch: 320 Norm Difference for worker 1934 is 0.993988
INFO:root:FL Epoch: 320 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1085
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592706
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371552
INFO:root:FL Epoch: 320 Norm Difference for worker 1085 is 0.938327
INFO:root:FL Epoch: 320 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1785
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.858667
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374418
INFO:root:FL Epoch: 320 Norm Difference for worker 1785 is 0.951201
INFO:root:FL Epoch: 320 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :799
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559636
INFO:root:Worker: 799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384968
INFO:root:FL Epoch: 320 Norm Difference for worker 799 is 0.9468
INFO:root:FL Epoch: 320 Done on worker:799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :394
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675858
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669002
INFO:root:FL Epoch: 320 Norm Difference for worker 394 is 1.011119
INFO:root:FL Epoch: 320 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 766
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 320 Ends   ===================
INFO:root:Epoch:320 Global Model Test Loss:0.5230870597502765 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:320 Global Model Backdoor Test Loss:0.21838976442813873                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 321 Begins ===================
INFO:root:FL Epoch: 321 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 321 Workers Selected : [0, 1, 2, 1516, 1691, 1534, 1245, 1693, 520, 996]
INFO:root:FL Epoch: 321 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 321 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 321 Training on worker :0
INFO:root:FL Epoch: 321 Using Learning rate : 0.005269546145144021 
INFO:root:FL Epoch: 321 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.130398
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248827
INFO:root:FL Epoch: 321 Worker: 0 Backdoor Test Loss: 0.1466545636455218 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 321 Worker: 0 Backdoor Train Loss: 0.18365805447101594 Backdoor Train Accuracy: 94.5
INFO:root:FL Epoch: 321 Norm Difference for worker 0 is 0.202304
INFO:root:FL Epoch: 321 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1
INFO:root:FL Epoch: 321 Using Learning rate : 0.005269546145144021 
INFO:root:FL Epoch: 321 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354724
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.148911
INFO:root:FL Epoch: 321 Worker: 1 Backdoor Test Loss: 0.1565012807647387 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 321 Worker: 1 Backdoor Train Loss: 0.18493270725011826 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 321 Norm Difference for worker 1 is 0.198227
INFO:root:FL Epoch: 321 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :2
INFO:root:FL Epoch: 321 Using Learning rate : 0.005269546145144021 
INFO:root:FL Epoch: 321 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.251953
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247038
INFO:root:FL Epoch: 321 Worker: 2 Backdoor Test Loss: 0.1521386963625749 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 321 Worker: 2 Backdoor Train Loss: 0.1828199714422226 Backdoor Train Accuracy: 94.5
INFO:root:FL Epoch: 321 Norm Difference for worker 2 is 0.205295
INFO:root:FL Epoch: 321 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1516
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533800
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493849
INFO:root:FL Epoch: 321 Norm Difference for worker 1516 is 1.153428
INFO:root:FL Epoch: 321 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1691
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632322
INFO:root:Worker: 1691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391485
INFO:root:FL Epoch: 321 Norm Difference for worker 1691 is 1.216047
INFO:root:FL Epoch: 321 Done on worker:1691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1534
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469941
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449939
INFO:root:FL Epoch: 321 Norm Difference for worker 1534 is 1.0986
INFO:root:FL Epoch: 321 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1245
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1245 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690108
INFO:root:Worker: 1245 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523622
INFO:root:FL Epoch: 321 Norm Difference for worker 1245 is 1.280458
INFO:root:FL Epoch: 321 Done on worker:1245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1693
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455691
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425341
INFO:root:FL Epoch: 321 Norm Difference for worker 1693 is 1.063741
INFO:root:FL Epoch: 321 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :520
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464759
INFO:root:Worker: 520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686635
INFO:root:FL Epoch: 321 Norm Difference for worker 520 is 1.143977
INFO:root:FL Epoch: 321 Done on worker:520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :996
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352994
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365493
INFO:root:FL Epoch: 321 Norm Difference for worker 996 is 1.171435
INFO:root:FL Epoch: 321 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 321 Ends   ===================
INFO:root:Epoch:321 Global Model Test Loss:0.5307724300552817 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:321 Global Model Backdoor Test Loss:0.1565012807647387                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 322 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 322 Workers Selected : [847, 302, 1156, 1187, 252, 460, 1246, 151, 556, 1367]
INFO:root:FL Epoch: 322 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 322 Num points on workers: [200 201 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 322 Training on worker :847
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.302471
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296083
INFO:root:FL Epoch: 322 Norm Difference for worker 847 is 1.180205
INFO:root:FL Epoch: 322 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :302
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.599686
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.336697
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 322 Norm Difference for worker 302 is 1.189799
INFO:root:FL Epoch: 322 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1156
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516947
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679286
INFO:root:FL Epoch: 322 Norm Difference for worker 1156 is 1.25398
INFO:root:FL Epoch: 322 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1187
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1187 Train Epoch: 0 [0/200 (0%)]	Loss: 0.916532
INFO:root:Worker: 1187 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544002
INFO:root:FL Epoch: 322 Norm Difference for worker 1187 is 1.124148
INFO:root:FL Epoch: 322 Done on worker:1187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :252
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581078
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.230501
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 322 Norm Difference for worker 252 is 1.168683
INFO:root:FL Epoch: 322 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :460
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 1.000708
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414714
INFO:root:FL Epoch: 322 Norm Difference for worker 460 is 1.327968
INFO:root:FL Epoch: 322 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1246
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1246 Train Epoch: 0 [0/200 (0%)]	Loss: 0.862767
INFO:root:Worker: 1246 Train Epoch: 1 [0/200 (0%)]	Loss: 0.706889
INFO:root:FL Epoch: 322 Norm Difference for worker 1246 is 1.282001
INFO:root:FL Epoch: 322 Done on worker:1246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :151
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.765481
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.380170
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 322 Norm Difference for worker 151 is 1.236492
INFO:root:FL Epoch: 322 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :556
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561012
INFO:root:Worker: 556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393066
INFO:root:FL Epoch: 322 Norm Difference for worker 556 is 1.227376
INFO:root:FL Epoch: 322 Done on worker:556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1367
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1367 Train Epoch: 0 [0/200 (0%)]	Loss: 1.012982
INFO:root:Worker: 1367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307568
INFO:root:FL Epoch: 322 Norm Difference for worker 1367 is 1.280114
INFO:root:FL Epoch: 322 Done on worker:1367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1187
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 322 Ends   ===================
INFO:root:Epoch:322 Global Model Test Loss:0.5277393109658185 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:322 Global Model Backdoor Test Loss:0.2477845922112465                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 323 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 323 Workers Selected : [900, 614, 1916, 1149, 1225, 315, 66, 959, 938, 1349]
INFO:root:FL Epoch: 323 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 323 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 323 Training on worker :900
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.836256
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445190
INFO:root:FL Epoch: 323 Norm Difference for worker 900 is 1.162852
INFO:root:FL Epoch: 323 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :614
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542841
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634778
INFO:root:FL Epoch: 323 Norm Difference for worker 614 is 1.129394
INFO:root:FL Epoch: 323 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1916
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394675
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362124
INFO:root:FL Epoch: 323 Norm Difference for worker 1916 is 1.089724
INFO:root:FL Epoch: 323 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1149
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555235
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533656
INFO:root:FL Epoch: 323 Norm Difference for worker 1149 is 1.160054
INFO:root:FL Epoch: 323 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1225
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1225 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375822
INFO:root:Worker: 1225 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618340
INFO:root:FL Epoch: 323 Norm Difference for worker 1225 is 1.235562
INFO:root:FL Epoch: 323 Done on worker:1225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :315
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.655755
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.410056
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 323 Norm Difference for worker 315 is 1.122616
INFO:root:FL Epoch: 323 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :66
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.554624
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.265032
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 323 Norm Difference for worker 66 is 1.190677
INFO:root:FL Epoch: 323 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :959
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.950229
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529129
INFO:root:FL Epoch: 323 Norm Difference for worker 959 is 1.281247
INFO:root:FL Epoch: 323 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :938
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691480
INFO:root:Worker: 938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382734
INFO:root:FL Epoch: 323 Norm Difference for worker 938 is 1.255787
INFO:root:FL Epoch: 323 Done on worker:938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1349
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687363
INFO:root:Worker: 1349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419537
INFO:root:FL Epoch: 323 Norm Difference for worker 1349 is 1.24176
INFO:root:FL Epoch: 323 Done on worker:1349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 315
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 323 Ends   ===================
INFO:root:Epoch:323 Global Model Test Loss:0.5078419604722191 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:323 Global Model Backdoor Test Loss:0.1449577920138836                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 324 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 324 Workers Selected : [1329, 1737, 570, 1802, 1438, 725, 394, 456, 1801, 1221]
INFO:root:FL Epoch: 324 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 324 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 324 Training on worker :1329
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434576
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427294
INFO:root:FL Epoch: 324 Norm Difference for worker 1329 is 1.038617
INFO:root:FL Epoch: 324 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1737
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532416
INFO:root:Worker: 1737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393347
INFO:root:FL Epoch: 324 Norm Difference for worker 1737 is 1.039704
INFO:root:FL Epoch: 324 Done on worker:1737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :570
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703617
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210202
INFO:root:FL Epoch: 324 Norm Difference for worker 570 is 0.886683
INFO:root:FL Epoch: 324 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1802
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361629
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436135
INFO:root:FL Epoch: 324 Norm Difference for worker 1802 is 1.074201
INFO:root:FL Epoch: 324 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1438
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595910
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258242
INFO:root:FL Epoch: 324 Norm Difference for worker 1438 is 1.021228
INFO:root:FL Epoch: 324 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :725
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477331
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257078
INFO:root:FL Epoch: 324 Norm Difference for worker 725 is 1.008716
INFO:root:FL Epoch: 324 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :394
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606523
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370584
INFO:root:FL Epoch: 324 Norm Difference for worker 394 is 1.131307
INFO:root:FL Epoch: 324 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :456
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442457
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415412
INFO:root:FL Epoch: 324 Norm Difference for worker 456 is 1.099793
INFO:root:FL Epoch: 324 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1801
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446951
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539351
INFO:root:FL Epoch: 324 Norm Difference for worker 1801 is 1.049433
INFO:root:FL Epoch: 324 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1221
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1221 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466704
INFO:root:Worker: 1221 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459649
INFO:root:FL Epoch: 324 Norm Difference for worker 1221 is 1.114838
INFO:root:FL Epoch: 324 Done on worker:1221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 570
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 324 Ends   ===================
INFO:root:Epoch:324 Global Model Test Loss:0.4960724097840926 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:324 Global Model Backdoor Test Loss:0.12489186475674312                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 325 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 325 Workers Selected : [371, 455, 747, 106, 1722, 631, 374, 1617, 513, 1270]
INFO:root:FL Epoch: 325 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 325 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 325 Training on worker :371
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443660
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439643
INFO:root:FL Epoch: 325 Norm Difference for worker 371 is 1.123232
INFO:root:FL Epoch: 325 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :455
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515703
INFO:root:Worker: 455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668084
INFO:root:FL Epoch: 325 Norm Difference for worker 455 is 1.29004
INFO:root:FL Epoch: 325 Done on worker:455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :747
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493828
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354536
INFO:root:FL Epoch: 325 Norm Difference for worker 747 is 1.178108
INFO:root:FL Epoch: 325 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :106
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.561077
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.626854
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 325 Norm Difference for worker 106 is 1.141509
INFO:root:FL Epoch: 325 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1722
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544797
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572157
INFO:root:FL Epoch: 325 Norm Difference for worker 1722 is 1.104252
INFO:root:FL Epoch: 325 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :631
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.767419
INFO:root:Worker: 631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449321
INFO:root:FL Epoch: 325 Norm Difference for worker 631 is 1.11484
INFO:root:FL Epoch: 325 Done on worker:631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :374
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661826
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456579
INFO:root:FL Epoch: 325 Norm Difference for worker 374 is 1.087306
INFO:root:FL Epoch: 325 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1617
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750922
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430471
INFO:root:FL Epoch: 325 Norm Difference for worker 1617 is 1.119112
INFO:root:FL Epoch: 325 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :513
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 1.029526
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447216
INFO:root:FL Epoch: 325 Norm Difference for worker 513 is 1.173556
INFO:root:FL Epoch: 325 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1270
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518803
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688106
INFO:root:FL Epoch: 325 Norm Difference for worker 1270 is 1.058587
INFO:root:FL Epoch: 325 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1270
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 325 Ends   ===================
INFO:root:Epoch:325 Global Model Test Loss:0.5090866018744076 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:325 Global Model Backdoor Test Loss:0.16359922165671983                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 326 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 326 Workers Selected : [1262, 808, 93, 1323, 1090, 844, 915, 433, 605, 416]
INFO:root:FL Epoch: 326 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 326 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 326 Training on worker :1262
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1262 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527490
INFO:root:Worker: 1262 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540377
INFO:root:FL Epoch: 326 Norm Difference for worker 1262 is 1.049608
INFO:root:FL Epoch: 326 Done on worker:1262
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :808
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561066
INFO:root:Worker: 808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514783
INFO:root:FL Epoch: 326 Norm Difference for worker 808 is 0.988048
INFO:root:FL Epoch: 326 Done on worker:808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :93
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 93 Train Epoch: 0 [0/201 (0%)]	Loss: 0.422049
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 93 Train Epoch: 1 [0/201 (0%)]	Loss: 0.206009
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 326 Norm Difference for worker 93 is 0.994454
INFO:root:FL Epoch: 326 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1323
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576005
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447667
INFO:root:FL Epoch: 326 Norm Difference for worker 1323 is 1.062166
INFO:root:FL Epoch: 326 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1090
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326618
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396369
INFO:root:FL Epoch: 326 Norm Difference for worker 1090 is 0.951764
INFO:root:FL Epoch: 326 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :844
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476591
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314371
INFO:root:FL Epoch: 326 Norm Difference for worker 844 is 0.783593
INFO:root:FL Epoch: 326 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :915
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674026
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665772
INFO:root:FL Epoch: 326 Norm Difference for worker 915 is 1.014243
INFO:root:FL Epoch: 326 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :433
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481342
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418077
INFO:root:FL Epoch: 326 Norm Difference for worker 433 is 0.977845
INFO:root:FL Epoch: 326 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :605
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559041
INFO:root:Worker: 605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482740
INFO:root:FL Epoch: 326 Norm Difference for worker 605 is 0.961172
INFO:root:FL Epoch: 326 Done on worker:605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :416
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722335
INFO:root:Worker: 416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538494
INFO:root:FL Epoch: 326 Norm Difference for worker 416 is 1.029848
INFO:root:FL Epoch: 326 Done on worker:416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 844
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 326 Ends   ===================
INFO:root:Epoch:326 Global Model Test Loss:0.5274033774347866 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:326 Global Model Backdoor Test Loss:0.17014343415697417                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 327 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 327 Workers Selected : [857, 1514, 267, 1586, 889, 1059, 1388, 1617, 1454, 1616]
INFO:root:FL Epoch: 327 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 327 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 327 Training on worker :857
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764189
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419235
INFO:root:FL Epoch: 327 Norm Difference for worker 857 is 1.321477
INFO:root:FL Epoch: 327 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1514
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332677
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.737229
INFO:root:FL Epoch: 327 Norm Difference for worker 1514 is 1.22192
INFO:root:FL Epoch: 327 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :267
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 267 Train Epoch: 0 [0/201 (0%)]	Loss: 0.549499
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 267 Train Epoch: 1 [0/201 (0%)]	Loss: 0.273028
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 327 Norm Difference for worker 267 is 1.19174
INFO:root:FL Epoch: 327 Done on worker:267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1586
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651075
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363780
INFO:root:FL Epoch: 327 Norm Difference for worker 1586 is 1.170116
INFO:root:FL Epoch: 327 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :889
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505798
INFO:root:Worker: 889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614165
INFO:root:FL Epoch: 327 Norm Difference for worker 889 is 1.212967
INFO:root:FL Epoch: 327 Done on worker:889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1059
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.265722
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391860
INFO:root:FL Epoch: 327 Norm Difference for worker 1059 is 1.12168
INFO:root:FL Epoch: 327 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1388
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770674
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376619
INFO:root:FL Epoch: 327 Norm Difference for worker 1388 is 1.189135
INFO:root:FL Epoch: 327 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1617
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554109
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451110
INFO:root:FL Epoch: 327 Norm Difference for worker 1617 is 1.223592
INFO:root:FL Epoch: 327 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1454
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346527
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.164264
INFO:root:FL Epoch: 327 Norm Difference for worker 1454 is 0.980192
INFO:root:FL Epoch: 327 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1616
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571887
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495681
INFO:root:FL Epoch: 327 Norm Difference for worker 1616 is 1.217274
INFO:root:FL Epoch: 327 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1454
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 327 Ends   ===================
INFO:root:Epoch:327 Global Model Test Loss:0.5066926794893601 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:327 Global Model Backdoor Test Loss:0.15563201159238815                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 328 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 328 Workers Selected : [310, 104, 160, 498, 577, 1023, 911, 823, 1667, 754]
INFO:root:FL Epoch: 328 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 328 Num points on workers: [201 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 328 Training on worker :310
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 310 Train Epoch: 0 [0/201 (0%)]	Loss: 0.733872
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 310 Train Epoch: 1 [0/201 (0%)]	Loss: 0.461734
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 328 Norm Difference for worker 310 is 1.291534
INFO:root:FL Epoch: 328 Done on worker:310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :104
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490034
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.282612
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 328 Norm Difference for worker 104 is 1.266823
INFO:root:FL Epoch: 328 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :160
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.342773
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.418857
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 328 Norm Difference for worker 160 is 1.296912
INFO:root:FL Epoch: 328 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :498
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.969074
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333313
INFO:root:FL Epoch: 328 Norm Difference for worker 498 is 1.307629
INFO:root:FL Epoch: 328 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :577
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675470
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475338
INFO:root:FL Epoch: 328 Norm Difference for worker 577 is 1.275629
INFO:root:FL Epoch: 328 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1023
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467984
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344728
INFO:root:FL Epoch: 328 Norm Difference for worker 1023 is 0.977345
INFO:root:FL Epoch: 328 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :911
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542778
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617741
INFO:root:FL Epoch: 328 Norm Difference for worker 911 is 1.238503
INFO:root:FL Epoch: 328 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :823
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414229
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240770
INFO:root:FL Epoch: 328 Norm Difference for worker 823 is 1.228968
INFO:root:FL Epoch: 328 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1667
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357050
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412620
INFO:root:FL Epoch: 328 Norm Difference for worker 1667 is 1.314005
INFO:root:FL Epoch: 328 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :754
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551132
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.772820
INFO:root:FL Epoch: 328 Norm Difference for worker 754 is 1.356705
INFO:root:FL Epoch: 328 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1023
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 328 Ends   ===================
INFO:root:Epoch:328 Global Model Test Loss:0.5068292460020851 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:328 Global Model Backdoor Test Loss:0.14718797554572424                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 329 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 329 Workers Selected : [1492, 354, 33, 1440, 773, 1028, 863, 755, 1307, 1724]
INFO:root:FL Epoch: 329 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 329 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 329 Training on worker :1492
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801289
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.970553
INFO:root:FL Epoch: 329 Norm Difference for worker 1492 is 1.41565
INFO:root:FL Epoch: 329 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :354
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.892813
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433460
INFO:root:FL Epoch: 329 Norm Difference for worker 354 is 1.377022
INFO:root:FL Epoch: 329 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :33
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.408690
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.296104
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 329 Norm Difference for worker 33 is 1.335554
INFO:root:FL Epoch: 329 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1440
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663859
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549661
INFO:root:FL Epoch: 329 Norm Difference for worker 1440 is 1.324492
INFO:root:FL Epoch: 329 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :773
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676535
INFO:root:Worker: 773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296132
INFO:root:FL Epoch: 329 Norm Difference for worker 773 is 1.311165
INFO:root:FL Epoch: 329 Done on worker:773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1028
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.979279
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503703
INFO:root:FL Epoch: 329 Norm Difference for worker 1028 is 1.340001
INFO:root:FL Epoch: 329 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :863
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804739
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297028
INFO:root:FL Epoch: 329 Norm Difference for worker 863 is 1.315324
INFO:root:FL Epoch: 329 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :755
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654559
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510510
INFO:root:FL Epoch: 329 Norm Difference for worker 755 is 1.33859
INFO:root:FL Epoch: 329 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1307
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636701
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510070
INFO:root:FL Epoch: 329 Norm Difference for worker 1307 is 1.334282
INFO:root:FL Epoch: 329 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1724
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.838875
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617677
INFO:root:FL Epoch: 329 Norm Difference for worker 1724 is 1.3635
INFO:root:FL Epoch: 329 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 773
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 329 Ends   ===================
INFO:root:Epoch:329 Global Model Test Loss:0.5102993688162636 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:329 Global Model Backdoor Test Loss:0.2084995855887731                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 330 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 330 Workers Selected : [324, 145, 544, 970, 1423, 1402, 689, 1486, 765, 11]
INFO:root:FL Epoch: 330 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 330 Num points on workers: [201 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 330 Training on worker :324
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.519588
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.306724
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 324 is 1.121961
INFO:root:FL Epoch: 330 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :145
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.402824
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.282798
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 145 is 1.055358
INFO:root:FL Epoch: 330 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :544
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529205
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.709190
INFO:root:FL Epoch: 330 Norm Difference for worker 544 is 1.120788
INFO:root:FL Epoch: 330 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :970
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 970 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491175
INFO:root:Worker: 970 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444817
INFO:root:FL Epoch: 330 Norm Difference for worker 970 is 1.164415
INFO:root:FL Epoch: 330 Done on worker:970
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1423
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.294829
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474517
INFO:root:FL Epoch: 330 Norm Difference for worker 1423 is 1.047505
INFO:root:FL Epoch: 330 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1402
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1402 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405475
INFO:root:Worker: 1402 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610279
INFO:root:FL Epoch: 330 Norm Difference for worker 1402 is 1.195207
INFO:root:FL Epoch: 330 Done on worker:1402
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :689
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501675
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440106
INFO:root:FL Epoch: 330 Norm Difference for worker 689 is 1.206999
INFO:root:FL Epoch: 330 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1486
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667988
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241601
INFO:root:FL Epoch: 330 Norm Difference for worker 1486 is 1.126248
INFO:root:FL Epoch: 330 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :765
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555217
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403252
INFO:root:FL Epoch: 330 Norm Difference for worker 765 is 1.183249
INFO:root:FL Epoch: 330 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :11
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 11 Train Epoch: 0 [0/201 (0%)]	Loss: 0.616404
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 11 Train Epoch: 1 [0/201 (0%)]	Loss: 0.292748
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 11 is 1.096055
INFO:root:FL Epoch: 330 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 145
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 330 Ends   ===================
INFO:root:Epoch:330 Global Model Test Loss:0.49085456132888794 and Test Accuracy:75.0 
INFO:root:Epoch:330 Global Model Backdoor Test Loss:0.21416429181893668                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 331 Begins ===================
INFO:root:FL Epoch: 331 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 331 Workers Selected : [0, 1, 2, 1513, 1131, 516, 950, 910, 386, 240]
INFO:root:FL Epoch: 331 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 331 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 331 Training on worker :0
INFO:root:FL Epoch: 331 Using Learning rate : 0.005165098699446219 
INFO:root:FL Epoch: 331 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.252820
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195213
INFO:root:FL Epoch: 331 Worker: 0 Backdoor Test Loss: 0.16750112548470497 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 331 Worker: 0 Backdoor Train Loss: 0.2110967218875885 Backdoor Train Accuracy: 94.0
INFO:root:FL Epoch: 331 Norm Difference for worker 0 is 0.180112
INFO:root:FL Epoch: 331 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :1
INFO:root:FL Epoch: 331 Using Learning rate : 0.005165098699446219 
INFO:root:FL Epoch: 331 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.238520
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202052
INFO:root:FL Epoch: 331 Worker: 1 Backdoor Test Loss: 0.15285226330161095 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 331 Worker: 1 Backdoor Train Loss: 0.21164191961288453 Backdoor Train Accuracy: 94.5
INFO:root:FL Epoch: 331 Norm Difference for worker 1 is 0.187753
INFO:root:FL Epoch: 331 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :2
INFO:root:FL Epoch: 331 Using Learning rate : 0.005165098699446219 
INFO:root:FL Epoch: 331 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.203246
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306183
INFO:root:FL Epoch: 331 Worker: 2 Backdoor Test Loss: 0.16679192334413528 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 331 Worker: 2 Backdoor Train Loss: 0.21191759705543517 Backdoor Train Accuracy: 94.0
INFO:root:FL Epoch: 331 Norm Difference for worker 2 is 0.181161
INFO:root:FL Epoch: 331 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :1513
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647308
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244310
INFO:root:FL Epoch: 331 Norm Difference for worker 1513 is 1.015211
INFO:root:FL Epoch: 331 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :1131
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737342
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416458
INFO:root:FL Epoch: 331 Norm Difference for worker 1131 is 1.171923
INFO:root:FL Epoch: 331 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :516
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674157
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393278
INFO:root:FL Epoch: 331 Norm Difference for worker 516 is 1.042589
INFO:root:FL Epoch: 331 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :950
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626256
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342758
INFO:root:FL Epoch: 331 Norm Difference for worker 950 is 1.086316
INFO:root:FL Epoch: 331 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :910
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746299
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520129
INFO:root:FL Epoch: 331 Norm Difference for worker 910 is 1.084665
INFO:root:FL Epoch: 331 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :386
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556269
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469364
INFO:root:FL Epoch: 331 Norm Difference for worker 386 is 1.091104
INFO:root:FL Epoch: 331 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :240
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 240 Train Epoch: 0 [0/201 (0%)]	Loss: 0.738576
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 240 Train Epoch: 1 [0/201 (0%)]	Loss: 0.457981
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 331 Norm Difference for worker 240 is 1.018845
INFO:root:FL Epoch: 331 Done on worker:240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 331 Ends   ===================
INFO:root:Epoch:331 Global Model Test Loss:0.4929449102457832 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:331 Global Model Backdoor Test Loss:0.16679192334413528                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 332 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 332 Workers Selected : [1511, 1912, 355, 961, 352, 366, 136, 335, 1156, 1522]
INFO:root:FL Epoch: 332 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 332 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 332 Training on worker :1511
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414491
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299315
INFO:root:FL Epoch: 332 Norm Difference for worker 1511 is 1.1407
INFO:root:FL Epoch: 332 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1912
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567282
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412328
INFO:root:FL Epoch: 332 Norm Difference for worker 1912 is 1.035719
INFO:root:FL Epoch: 332 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :355
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744037
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367787
INFO:root:FL Epoch: 332 Norm Difference for worker 355 is 1.089502
INFO:root:FL Epoch: 332 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :961
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343519
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409676
INFO:root:FL Epoch: 332 Norm Difference for worker 961 is 1.120113
INFO:root:FL Epoch: 332 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :352
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622037
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421860
INFO:root:FL Epoch: 332 Norm Difference for worker 352 is 1.166243
INFO:root:FL Epoch: 332 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :366
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652427
INFO:root:Worker: 366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574421
INFO:root:FL Epoch: 332 Norm Difference for worker 366 is 1.13665
INFO:root:FL Epoch: 332 Done on worker:366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :136
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 136 Train Epoch: 0 [0/201 (0%)]	Loss: 0.507340
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 136 Train Epoch: 1 [0/201 (0%)]	Loss: 0.277450
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 332 Norm Difference for worker 136 is 1.054665
INFO:root:FL Epoch: 332 Done on worker:136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :335
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.358365
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.490689
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 332 Norm Difference for worker 335 is 1.100558
INFO:root:FL Epoch: 332 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1156
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521632
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447052
INFO:root:FL Epoch: 332 Norm Difference for worker 1156 is 1.075616
INFO:root:FL Epoch: 332 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1522
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557326
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360892
INFO:root:FL Epoch: 332 Norm Difference for worker 1522 is 1.167647
INFO:root:FL Epoch: 332 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1912
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 332 Ends   ===================
INFO:root:Epoch:332 Global Model Test Loss:0.5253293794744155 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:332 Global Model Backdoor Test Loss:0.131612046311299                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 333 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 333 Workers Selected : [1447, 1313, 1892, 700, 1180, 208, 1366, 1174, 968, 869]
INFO:root:FL Epoch: 333 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 333 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 333 Training on worker :1447
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595268
INFO:root:Worker: 1447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379957
INFO:root:FL Epoch: 333 Norm Difference for worker 1447 is 1.073704
INFO:root:FL Epoch: 333 Done on worker:1447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1313
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606557
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390307
INFO:root:FL Epoch: 333 Norm Difference for worker 1313 is 1.062069
INFO:root:FL Epoch: 333 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1892
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497281
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326648
INFO:root:FL Epoch: 333 Norm Difference for worker 1892 is 1.201102
INFO:root:FL Epoch: 333 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :700
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630552
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346927
INFO:root:FL Epoch: 333 Norm Difference for worker 700 is 1.068032
INFO:root:FL Epoch: 333 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1180
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632677
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545041
INFO:root:FL Epoch: 333 Norm Difference for worker 1180 is 1.104981
INFO:root:FL Epoch: 333 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :208
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.463054
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686876
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 333 Norm Difference for worker 208 is 1.103091
INFO:root:FL Epoch: 333 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1366
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354317
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473834
INFO:root:FL Epoch: 333 Norm Difference for worker 1366 is 1.054888
INFO:root:FL Epoch: 333 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1174
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538203
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555973
INFO:root:FL Epoch: 333 Norm Difference for worker 1174 is 1.156643
INFO:root:FL Epoch: 333 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :968
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472710
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588999
INFO:root:FL Epoch: 333 Norm Difference for worker 968 is 1.1438
INFO:root:FL Epoch: 333 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :869
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449643
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362603
INFO:root:FL Epoch: 333 Norm Difference for worker 869 is 1.140774
INFO:root:FL Epoch: 333 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1313
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 333 Ends   ===================
INFO:root:Epoch:333 Global Model Test Loss:0.5056212859995225 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:333 Global Model Backdoor Test Loss:0.1340032604833444                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 334 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 334 Workers Selected : [1137, 1389, 158, 892, 314, 737, 1206, 362, 1354, 650]
INFO:root:FL Epoch: 334 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 334 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 334 Training on worker :1137
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552665
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692752
INFO:root:FL Epoch: 334 Norm Difference for worker 1137 is 1.1467
INFO:root:FL Epoch: 334 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1389
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663619
INFO:root:Worker: 1389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362276
INFO:root:FL Epoch: 334 Norm Difference for worker 1389 is 1.082917
INFO:root:FL Epoch: 334 Done on worker:1389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :158
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.535469
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.605631
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 158 is 1.23459
INFO:root:FL Epoch: 334 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :892
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417170
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398704
INFO:root:FL Epoch: 334 Norm Difference for worker 892 is 1.103243
INFO:root:FL Epoch: 334 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :314
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 314 Train Epoch: 0 [0/201 (0%)]	Loss: 0.710304
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 314 Train Epoch: 1 [0/201 (0%)]	Loss: 0.275052
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 314 is 1.168461
INFO:root:FL Epoch: 334 Done on worker:314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :737
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492402
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639426
INFO:root:FL Epoch: 334 Norm Difference for worker 737 is 1.061453
INFO:root:FL Epoch: 334 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1206
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1206 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480856
INFO:root:Worker: 1206 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703630
INFO:root:FL Epoch: 334 Norm Difference for worker 1206 is 1.177351
INFO:root:FL Epoch: 334 Done on worker:1206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :362
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516471
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500940
INFO:root:FL Epoch: 334 Norm Difference for worker 362 is 1.130113
INFO:root:FL Epoch: 334 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1354
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688787
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427626
INFO:root:FL Epoch: 334 Norm Difference for worker 1354 is 1.10361
INFO:root:FL Epoch: 334 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :650
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379951
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646074
INFO:root:FL Epoch: 334 Norm Difference for worker 650 is 1.123143
INFO:root:FL Epoch: 334 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 737
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 334 Ends   ===================
INFO:root:Epoch:334 Global Model Test Loss:0.5231510611141429 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:334 Global Model Backdoor Test Loss:0.13126573835810026                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 335 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 335 Workers Selected : [1702, 19, 779, 1874, 153, 751, 1409, 1891, 1327, 312]
INFO:root:FL Epoch: 335 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 335 Num points on workers: [200 201 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 335 Training on worker :1702
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367043
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430228
INFO:root:FL Epoch: 335 Norm Difference for worker 1702 is 1.032251
INFO:root:FL Epoch: 335 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :19
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.458015
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.329010
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 19 is 1.024932
INFO:root:FL Epoch: 335 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :779
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548946
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362597
INFO:root:FL Epoch: 335 Norm Difference for worker 779 is 1.056127
INFO:root:FL Epoch: 335 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :1874
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487366
INFO:root:Worker: 1874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333831
INFO:root:FL Epoch: 335 Norm Difference for worker 1874 is 0.99217
INFO:root:FL Epoch: 335 Done on worker:1874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :153
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.373530
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.367220
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 153 is 1.014858
INFO:root:FL Epoch: 335 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :751
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755325
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337297
INFO:root:FL Epoch: 335 Norm Difference for worker 751 is 1.019624
INFO:root:FL Epoch: 335 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :1409
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445634
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467495
INFO:root:FL Epoch: 335 Norm Difference for worker 1409 is 1.076042
INFO:root:FL Epoch: 335 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :1891
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631041
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629574
INFO:root:FL Epoch: 335 Norm Difference for worker 1891 is 1.016547
INFO:root:FL Epoch: 335 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :1327
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519660
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399009
INFO:root:FL Epoch: 335 Norm Difference for worker 1327 is 1.02336
INFO:root:FL Epoch: 335 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :312
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.519669
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.248852
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 312 is 1.01324
INFO:root:FL Epoch: 335 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1874
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 335 Ends   ===================
INFO:root:Epoch:335 Global Model Test Loss:0.5012692265650806 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:335 Global Model Backdoor Test Loss:0.20276260872681937                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 336 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 336 Workers Selected : [950, 1614, 1069, 1082, 755, 211, 626, 1801, 592, 113]
INFO:root:FL Epoch: 336 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 336 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 336 Training on worker :950
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385632
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481131
INFO:root:FL Epoch: 336 Norm Difference for worker 950 is 1.034372
INFO:root:FL Epoch: 336 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :1614
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737355
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527258
INFO:root:FL Epoch: 336 Norm Difference for worker 1614 is 1.079009
INFO:root:FL Epoch: 336 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :1069
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763780
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496435
INFO:root:FL Epoch: 336 Norm Difference for worker 1069 is 1.054994
INFO:root:FL Epoch: 336 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :1082
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479766
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228760
INFO:root:FL Epoch: 336 Norm Difference for worker 1082 is 0.94668
INFO:root:FL Epoch: 336 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :755
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434471
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513078
INFO:root:FL Epoch: 336 Norm Difference for worker 755 is 1.060188
INFO:root:FL Epoch: 336 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :211
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.530101
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.303714
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 336 Norm Difference for worker 211 is 0.938095
INFO:root:FL Epoch: 336 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :626
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525451
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318911
INFO:root:FL Epoch: 336 Norm Difference for worker 626 is 0.947096
INFO:root:FL Epoch: 336 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :1801
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465928
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320325
INFO:root:FL Epoch: 336 Norm Difference for worker 1801 is 0.941903
INFO:root:FL Epoch: 336 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :592
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738782
INFO:root:Worker: 592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408698
INFO:root:FL Epoch: 336 Norm Difference for worker 592 is 1.001276
INFO:root:FL Epoch: 336 Done on worker:592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :113
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 113 Train Epoch: 0 [0/201 (0%)]	Loss: 0.430540
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 113 Train Epoch: 1 [0/201 (0%)]	Loss: 0.285555
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 336 Norm Difference for worker 113 is 0.925549
INFO:root:FL Epoch: 336 Done on worker:113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 113
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 336 Ends   ===================
INFO:root:Epoch:336 Global Model Test Loss:0.4824752737494076 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:336 Global Model Backdoor Test Loss:0.22873271256685257                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 337 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 337 Workers Selected : [935, 1785, 769, 514, 59, 1601, 1554, 1492, 393, 1921]
INFO:root:FL Epoch: 337 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 337 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 337 Training on worker :935
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692932
INFO:root:Worker: 935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318915
INFO:root:FL Epoch: 337 Norm Difference for worker 935 is 1.002114
INFO:root:FL Epoch: 337 Done on worker:935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1785
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537989
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344946
INFO:root:FL Epoch: 337 Norm Difference for worker 1785 is 1.027183
INFO:root:FL Epoch: 337 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :769
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720752
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307924
INFO:root:FL Epoch: 337 Norm Difference for worker 769 is 1.105292
INFO:root:FL Epoch: 337 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :514
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355486
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241170
INFO:root:FL Epoch: 337 Norm Difference for worker 514 is 0.933613
INFO:root:FL Epoch: 337 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :59
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.592227
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.343042
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 59 is 1.051137
INFO:root:FL Epoch: 337 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1601
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595221
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327528
INFO:root:FL Epoch: 337 Norm Difference for worker 1601 is 0.941697
INFO:root:FL Epoch: 337 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1554
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401279
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376027
INFO:root:FL Epoch: 337 Norm Difference for worker 1554 is 0.892329
INFO:root:FL Epoch: 337 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1492
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560874
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543643
INFO:root:FL Epoch: 337 Norm Difference for worker 1492 is 1.031428
INFO:root:FL Epoch: 337 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :393
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545569
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.738156
INFO:root:FL Epoch: 337 Norm Difference for worker 393 is 1.054781
INFO:root:FL Epoch: 337 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1921
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489273
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513313
INFO:root:FL Epoch: 337 Norm Difference for worker 1921 is 1.154683
INFO:root:FL Epoch: 337 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1554
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 337 Ends   ===================
INFO:root:Epoch:337 Global Model Test Loss:0.4912911618457121 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:337 Global Model Backdoor Test Loss:0.18935227394104004                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 338 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 338 Workers Selected : [589, 1143, 1020, 1022, 730, 346, 92, 139, 1469, 1364]
INFO:root:FL Epoch: 338 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 338 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 338 Training on worker :589
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450594
INFO:root:Worker: 589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499576
INFO:root:FL Epoch: 338 Norm Difference for worker 589 is 1.110062
INFO:root:FL Epoch: 338 Done on worker:589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1143
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1143 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744658
INFO:root:Worker: 1143 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488090
INFO:root:FL Epoch: 338 Norm Difference for worker 1143 is 1.046117
INFO:root:FL Epoch: 338 Done on worker:1143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1020
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1020 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779238
INFO:root:Worker: 1020 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547325
INFO:root:FL Epoch: 338 Norm Difference for worker 1020 is 1.01623
INFO:root:FL Epoch: 338 Done on worker:1020
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1022
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357897
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500015
INFO:root:FL Epoch: 338 Norm Difference for worker 1022 is 0.909116
INFO:root:FL Epoch: 338 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :730
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359723
INFO:root:Worker: 730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522265
INFO:root:FL Epoch: 338 Norm Difference for worker 730 is 1.028515
INFO:root:FL Epoch: 338 Done on worker:730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :346
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.800303
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421750
INFO:root:FL Epoch: 338 Norm Difference for worker 346 is 1.027399
INFO:root:FL Epoch: 338 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :92
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.389376
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.420226
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 338 Norm Difference for worker 92 is 1.02021
INFO:root:FL Epoch: 338 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :139
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 139 Train Epoch: 0 [0/201 (0%)]	Loss: 0.564020
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 139 Train Epoch: 1 [0/201 (0%)]	Loss: 0.461550
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 338 Norm Difference for worker 139 is 1.03865
INFO:root:FL Epoch: 338 Done on worker:139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1469
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416867
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662784
INFO:root:FL Epoch: 338 Norm Difference for worker 1469 is 1.047859
INFO:root:FL Epoch: 338 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1364
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638260
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457871
INFO:root:FL Epoch: 338 Norm Difference for worker 1364 is 1.05424
INFO:root:FL Epoch: 338 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1022
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 338 Ends   ===================
INFO:root:Epoch:338 Global Model Test Loss:0.48534122810644265 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:338 Global Model Backdoor Test Loss:0.2411274934808413                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 339 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 339 Workers Selected : [545, 55, 702, 1861, 1745, 524, 900, 492, 1013, 1556]
INFO:root:FL Epoch: 339 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 339 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 339 Training on worker :545
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530136
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411876
INFO:root:FL Epoch: 339 Norm Difference for worker 545 is 1.021018
INFO:root:FL Epoch: 339 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :55
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.539071
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.500647
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 339 Norm Difference for worker 55 is 1.01435
INFO:root:FL Epoch: 339 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :702
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545149
INFO:root:Worker: 702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528848
INFO:root:FL Epoch: 339 Norm Difference for worker 702 is 1.013201
INFO:root:FL Epoch: 339 Done on worker:702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1861
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602221
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433794
INFO:root:FL Epoch: 339 Norm Difference for worker 1861 is 1.043539
INFO:root:FL Epoch: 339 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1745
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675572
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420232
INFO:root:FL Epoch: 339 Norm Difference for worker 1745 is 0.998718
INFO:root:FL Epoch: 339 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :524
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514296
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336857
INFO:root:FL Epoch: 339 Norm Difference for worker 524 is 0.979898
INFO:root:FL Epoch: 339 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :900
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412564
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348994
INFO:root:FL Epoch: 339 Norm Difference for worker 900 is 1.081686
INFO:root:FL Epoch: 339 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :492
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581425
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351971
INFO:root:FL Epoch: 339 Norm Difference for worker 492 is 1.014815
INFO:root:FL Epoch: 339 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1013
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794235
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396069
INFO:root:FL Epoch: 339 Norm Difference for worker 1013 is 1.091174
INFO:root:FL Epoch: 339 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1556
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.255605
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332392
INFO:root:FL Epoch: 339 Norm Difference for worker 1556 is 0.964338
INFO:root:FL Epoch: 339 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1556
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 339 Ends   ===================
INFO:root:Epoch:339 Global Model Test Loss:0.5143772083170274 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:339 Global Model Backdoor Test Loss:0.2803822010755539                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 340 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 340 Workers Selected : [1834, 946, 646, 1428, 50, 1198, 1355, 222, 1642, 1223]
INFO:root:FL Epoch: 340 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 340 Num points on workers: [200 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 340 Training on worker :1834
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782661
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535604
INFO:root:FL Epoch: 340 Norm Difference for worker 1834 is 1.117012
INFO:root:FL Epoch: 340 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :946
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.933541
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447699
INFO:root:FL Epoch: 340 Norm Difference for worker 946 is 1.063177
INFO:root:FL Epoch: 340 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :646
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443886
INFO:root:Worker: 646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338210
INFO:root:FL Epoch: 340 Norm Difference for worker 646 is 0.953427
INFO:root:FL Epoch: 340 Done on worker:646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1428
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453106
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401242
INFO:root:FL Epoch: 340 Norm Difference for worker 1428 is 1.019746
INFO:root:FL Epoch: 340 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :50
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.402656
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.432659
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 50 is 0.973675
INFO:root:FL Epoch: 340 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1198
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546192
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248818
INFO:root:FL Epoch: 340 Norm Difference for worker 1198 is 0.93419
INFO:root:FL Epoch: 340 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1355
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600367
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500014
INFO:root:FL Epoch: 340 Norm Difference for worker 1355 is 0.996273
INFO:root:FL Epoch: 340 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :222
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.642218
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.405411
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 222 is 0.947057
INFO:root:FL Epoch: 340 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1642
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.966270
INFO:root:Worker: 1642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.719382
INFO:root:FL Epoch: 340 Norm Difference for worker 1642 is 1.002001
INFO:root:FL Epoch: 340 Done on worker:1642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1223
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1223 Train Epoch: 0 [0/200 (0%)]	Loss: 0.934989
INFO:root:Worker: 1223 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326695
INFO:root:FL Epoch: 340 Norm Difference for worker 1223 is 0.997733
INFO:root:FL Epoch: 340 Done on worker:1223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 222
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 340 Ends   ===================
INFO:root:Epoch:340 Global Model Test Loss:0.5163026066387401 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:340 Global Model Backdoor Test Loss:0.21816765516996384                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 341 Begins ===================
INFO:root:FL Epoch: 341 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 341 Workers Selected : [0, 1, 2, 1878, 962, 549, 976, 769, 465, 1750]
INFO:root:FL Epoch: 341 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 341 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 341 Training on worker :0
INFO:root:FL Epoch: 341 Using Learning rate : 0.005062721502041593 
INFO:root:FL Epoch: 341 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.150657
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.139272
INFO:root:FL Epoch: 341 Worker: 0 Backdoor Test Loss: 0.16868562748034796 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 341 Worker: 0 Backdoor Train Loss: 0.20884835943579674 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 341 Norm Difference for worker 0 is 0.168787
INFO:root:FL Epoch: 341 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1
INFO:root:FL Epoch: 341 Using Learning rate : 0.005062721502041593 
INFO:root:FL Epoch: 341 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.274934
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371200
INFO:root:FL Epoch: 341 Worker: 1 Backdoor Test Loss: 0.16550502553582191 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 341 Worker: 1 Backdoor Train Loss: 0.20808314383029938 Backdoor Train Accuracy: 94.0
INFO:root:FL Epoch: 341 Norm Difference for worker 1 is 0.173298
INFO:root:FL Epoch: 341 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :2
INFO:root:FL Epoch: 341 Using Learning rate : 0.005062721502041593 
INFO:root:FL Epoch: 341 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.226780
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265078
INFO:root:FL Epoch: 341 Worker: 2 Backdoor Test Loss: 0.1733411786456903 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 341 Worker: 2 Backdoor Train Loss: 0.206375153362751 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 341 Norm Difference for worker 2 is 0.177734
INFO:root:FL Epoch: 341 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1878
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.835299
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470575
INFO:root:FL Epoch: 341 Norm Difference for worker 1878 is 1.021331
INFO:root:FL Epoch: 341 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :962
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603773
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565327
INFO:root:FL Epoch: 341 Norm Difference for worker 962 is 1.038914
INFO:root:FL Epoch: 341 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :549
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547867
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465972
INFO:root:FL Epoch: 341 Norm Difference for worker 549 is 1.016041
INFO:root:FL Epoch: 341 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :976
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 976 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446241
INFO:root:Worker: 976 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353136
INFO:root:FL Epoch: 341 Norm Difference for worker 976 is 0.989386
INFO:root:FL Epoch: 341 Done on worker:976
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :769
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728448
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631132
INFO:root:FL Epoch: 341 Norm Difference for worker 769 is 1.097761
INFO:root:FL Epoch: 341 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :465
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723407
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428750
INFO:root:FL Epoch: 341 Norm Difference for worker 465 is 1.034112
INFO:root:FL Epoch: 341 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1750
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654591
INFO:root:Worker: 1750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208171
INFO:root:FL Epoch: 341 Norm Difference for worker 1750 is 1.046977
INFO:root:FL Epoch: 341 Done on worker:1750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 341 Ends   ===================
INFO:root:Epoch:341 Global Model Test Loss:0.5205950596753288 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:341 Global Model Backdoor Test Loss:0.1733411786456903                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 342 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 342 Workers Selected : [1841, 1522, 23, 1157, 56, 1269, 442, 577, 219, 1614]
INFO:root:FL Epoch: 342 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 342 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 342 Training on worker :1841
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444399
INFO:root:Worker: 1841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512269
INFO:root:FL Epoch: 342 Norm Difference for worker 1841 is 1.13253
INFO:root:FL Epoch: 342 Done on worker:1841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1522
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544116
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286277
INFO:root:FL Epoch: 342 Norm Difference for worker 1522 is 1.098713
INFO:root:FL Epoch: 342 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :23
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 23 Train Epoch: 0 [0/201 (0%)]	Loss: 0.785324
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 23 Train Epoch: 1 [0/201 (0%)]	Loss: 0.430562
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 342 Norm Difference for worker 23 is 1.129611
INFO:root:FL Epoch: 342 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1157
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719562
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464461
INFO:root:FL Epoch: 342 Norm Difference for worker 1157 is 1.03912
INFO:root:FL Epoch: 342 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :56
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587732
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.288232
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 342 Norm Difference for worker 56 is 1.028084
INFO:root:FL Epoch: 342 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1269
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1269 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704119
INFO:root:Worker: 1269 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374554
INFO:root:FL Epoch: 342 Norm Difference for worker 1269 is 1.063663
INFO:root:FL Epoch: 342 Done on worker:1269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :442
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.201761
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351816
INFO:root:FL Epoch: 342 Norm Difference for worker 442 is 1.099861
INFO:root:FL Epoch: 342 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :577
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593371
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490698
INFO:root:FL Epoch: 342 Norm Difference for worker 577 is 1.096364
INFO:root:FL Epoch: 342 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :219
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 219 Train Epoch: 0 [0/201 (0%)]	Loss: 0.731800
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 219 Train Epoch: 1 [0/201 (0%)]	Loss: 0.372378
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 342 Norm Difference for worker 219 is 1.095006
INFO:root:FL Epoch: 342 Done on worker:219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1614
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630035
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445977
INFO:root:FL Epoch: 342 Norm Difference for worker 1614 is 1.109615
INFO:root:FL Epoch: 342 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1157
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 342 Ends   ===================
INFO:root:Epoch:342 Global Model Test Loss:0.5281503130407894 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:342 Global Model Backdoor Test Loss:0.18307319904367128                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 343 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 343 Workers Selected : [1520, 1151, 182, 755, 86, 1828, 1417, 504, 250, 634]
INFO:root:FL Epoch: 343 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 343 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 343 Training on worker :1520
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494877
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400117
INFO:root:FL Epoch: 343 Norm Difference for worker 1520 is 1.018102
INFO:root:FL Epoch: 343 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1151
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1151 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422137
INFO:root:Worker: 1151 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458194
INFO:root:FL Epoch: 343 Norm Difference for worker 1151 is 0.949617
INFO:root:FL Epoch: 343 Done on worker:1151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :182
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.508693
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.372588
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 343 Norm Difference for worker 182 is 1.014779
INFO:root:FL Epoch: 343 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :755
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618491
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642339
INFO:root:FL Epoch: 343 Norm Difference for worker 755 is 1.026569
INFO:root:FL Epoch: 343 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :86
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.498648
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.340966
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 343 Norm Difference for worker 86 is 0.862443
INFO:root:FL Epoch: 343 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1828
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.916788
INFO:root:Worker: 1828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476625
INFO:root:FL Epoch: 343 Norm Difference for worker 1828 is 0.971192
INFO:root:FL Epoch: 343 Done on worker:1828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1417
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383139
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491758
INFO:root:FL Epoch: 343 Norm Difference for worker 1417 is 0.914821
INFO:root:FL Epoch: 343 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :504
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571332
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410940
INFO:root:FL Epoch: 343 Norm Difference for worker 504 is 0.965569
INFO:root:FL Epoch: 343 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :250
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.621446
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431111
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 343 Norm Difference for worker 250 is 0.911338
INFO:root:FL Epoch: 343 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :634
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370478
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298634
INFO:root:FL Epoch: 343 Norm Difference for worker 634 is 0.894331
INFO:root:FL Epoch: 343 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 86
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 343 Ends   ===================
INFO:root:Epoch:343 Global Model Test Loss:0.5279095821520862 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:343 Global Model Backdoor Test Loss:0.15686107178529105                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 344 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 344 Workers Selected : [1753, 1838, 71, 711, 960, 665, 1500, 1467, 800, 787]
INFO:root:FL Epoch: 344 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 344 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 344 Training on worker :1753
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412160
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317752
INFO:root:FL Epoch: 344 Norm Difference for worker 1753 is 1.024962
INFO:root:FL Epoch: 344 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1838
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709591
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578895
INFO:root:FL Epoch: 344 Norm Difference for worker 1838 is 1.087475
INFO:root:FL Epoch: 344 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :71
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.752041
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.641624
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 344 Norm Difference for worker 71 is 1.08656
INFO:root:FL Epoch: 344 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :711
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699827
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499054
INFO:root:FL Epoch: 344 Norm Difference for worker 711 is 1.099137
INFO:root:FL Epoch: 344 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :960
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 960 Train Epoch: 0 [0/200 (0%)]	Loss: 0.273900
INFO:root:Worker: 960 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527848
INFO:root:FL Epoch: 344 Norm Difference for worker 960 is 1.031366
INFO:root:FL Epoch: 344 Done on worker:960
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :665
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.292247
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351885
INFO:root:FL Epoch: 344 Norm Difference for worker 665 is 1.007672
INFO:root:FL Epoch: 344 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1500
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646663
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560327
INFO:root:FL Epoch: 344 Norm Difference for worker 1500 is 1.096694
INFO:root:FL Epoch: 344 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1467
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505192
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545002
INFO:root:FL Epoch: 344 Norm Difference for worker 1467 is 1.112067
INFO:root:FL Epoch: 344 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :800
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.217216
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324210
INFO:root:FL Epoch: 344 Norm Difference for worker 800 is 1.107502
INFO:root:FL Epoch: 344 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :787
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520902
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372782
INFO:root:FL Epoch: 344 Norm Difference for worker 787 is 1.117607
INFO:root:FL Epoch: 344 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1753
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 344 Ends   ===================
INFO:root:Epoch:344 Global Model Test Loss:0.5291938623961281 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:344 Global Model Backdoor Test Loss:0.1789977364242077                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 345 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 345 Workers Selected : [380, 95, 818, 1766, 1585, 1927, 1721, 478, 1393, 1170]
INFO:root:FL Epoch: 345 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 345 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 345 Training on worker :380
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486404
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311684
INFO:root:FL Epoch: 345 Norm Difference for worker 380 is 0.972497
INFO:root:FL Epoch: 345 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :95
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 95 Train Epoch: 0 [0/201 (0%)]	Loss: 0.401981
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 95 Train Epoch: 1 [0/201 (0%)]	Loss: 0.422225
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 345 Norm Difference for worker 95 is 1.053734
INFO:root:FL Epoch: 345 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :818
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.969056
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489236
INFO:root:FL Epoch: 345 Norm Difference for worker 818 is 0.949883
INFO:root:FL Epoch: 345 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1766
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567885
INFO:root:Worker: 1766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527844
INFO:root:FL Epoch: 345 Norm Difference for worker 1766 is 1.064593
INFO:root:FL Epoch: 345 Done on worker:1766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1585
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333950
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698301
INFO:root:FL Epoch: 345 Norm Difference for worker 1585 is 1.006636
INFO:root:FL Epoch: 345 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1927
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605161
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503011
INFO:root:FL Epoch: 345 Norm Difference for worker 1927 is 0.97847
INFO:root:FL Epoch: 345 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1721
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.827020
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387961
INFO:root:FL Epoch: 345 Norm Difference for worker 1721 is 0.85639
INFO:root:FL Epoch: 345 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :478
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.791415
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482792
INFO:root:FL Epoch: 345 Norm Difference for worker 478 is 1.006326
INFO:root:FL Epoch: 345 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1393
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635285
INFO:root:Worker: 1393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463873
INFO:root:FL Epoch: 345 Norm Difference for worker 1393 is 0.998019
INFO:root:FL Epoch: 345 Done on worker:1393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1170
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1170 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664873
INFO:root:Worker: 1170 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568770
INFO:root:FL Epoch: 345 Norm Difference for worker 1170 is 1.008508
INFO:root:FL Epoch: 345 Done on worker:1170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1721
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 345 Ends   ===================
INFO:root:Epoch:345 Global Model Test Loss:0.5450245475067812 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:345 Global Model Backdoor Test Loss:0.19291895627975464                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 346 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 346 Workers Selected : [968, 715, 798, 1158, 1312, 656, 911, 391, 42, 800]
INFO:root:FL Epoch: 346 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 346 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 346 Training on worker :968
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647305
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385760
INFO:root:FL Epoch: 346 Norm Difference for worker 968 is 1.052229
INFO:root:FL Epoch: 346 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :715
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411148
INFO:root:Worker: 715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552125
INFO:root:FL Epoch: 346 Norm Difference for worker 715 is 1.022537
INFO:root:FL Epoch: 346 Done on worker:715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :798
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369900
INFO:root:Worker: 798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694625
INFO:root:FL Epoch: 346 Norm Difference for worker 798 is 1.016514
INFO:root:FL Epoch: 346 Done on worker:798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1158
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623259
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233358
INFO:root:FL Epoch: 346 Norm Difference for worker 1158 is 0.954085
INFO:root:FL Epoch: 346 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1312
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347639
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520256
INFO:root:FL Epoch: 346 Norm Difference for worker 1312 is 0.981391
INFO:root:FL Epoch: 346 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :656
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630152
INFO:root:Worker: 656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418253
INFO:root:FL Epoch: 346 Norm Difference for worker 656 is 1.06189
INFO:root:FL Epoch: 346 Done on worker:656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :911
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451652
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487806
INFO:root:FL Epoch: 346 Norm Difference for worker 911 is 1.063238
INFO:root:FL Epoch: 346 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :391
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490308
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395073
INFO:root:FL Epoch: 346 Norm Difference for worker 391 is 1.03959
INFO:root:FL Epoch: 346 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :42
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.514514
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.555931
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 346 Norm Difference for worker 42 is 0.950191
INFO:root:FL Epoch: 346 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :800
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.825189
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462155
INFO:root:FL Epoch: 346 Norm Difference for worker 800 is 1.078399
INFO:root:FL Epoch: 346 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1158
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 346 Ends   ===================
INFO:root:Epoch:346 Global Model Test Loss:0.523723395431743 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:346 Global Model Backdoor Test Loss:0.1400381289422512                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 347 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 347 Workers Selected : [1230, 1810, 202, 692, 1869, 1931, 1058, 783, 536, 950]
INFO:root:FL Epoch: 347 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 347 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 347 Training on worker :1230
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1230 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332685
INFO:root:Worker: 1230 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396628
INFO:root:FL Epoch: 347 Norm Difference for worker 1230 is 0.956103
INFO:root:FL Epoch: 347 Done on worker:1230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1810
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590904
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508769
INFO:root:FL Epoch: 347 Norm Difference for worker 1810 is 0.913117
INFO:root:FL Epoch: 347 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :202
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.582530
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.360213
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 347 Norm Difference for worker 202 is 1.023522
INFO:root:FL Epoch: 347 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :692
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401962
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631085
INFO:root:FL Epoch: 347 Norm Difference for worker 692 is 0.966039
INFO:root:FL Epoch: 347 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1869
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.920194
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575800
INFO:root:FL Epoch: 347 Norm Difference for worker 1869 is 1.048068
INFO:root:FL Epoch: 347 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1931
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645613
INFO:root:Worker: 1931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524938
INFO:root:FL Epoch: 347 Norm Difference for worker 1931 is 0.962098
INFO:root:FL Epoch: 347 Done on worker:1931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1058
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1058 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391568
INFO:root:Worker: 1058 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609296
INFO:root:FL Epoch: 347 Norm Difference for worker 1058 is 1.07517
INFO:root:FL Epoch: 347 Done on worker:1058
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :783
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607266
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375440
INFO:root:FL Epoch: 347 Norm Difference for worker 783 is 0.978982
INFO:root:FL Epoch: 347 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :536
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531177
INFO:root:Worker: 536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540280
INFO:root:FL Epoch: 347 Norm Difference for worker 536 is 0.916837
INFO:root:FL Epoch: 347 Done on worker:536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :950
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570963
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465256
INFO:root:FL Epoch: 347 Norm Difference for worker 950 is 1.024516
INFO:root:FL Epoch: 347 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1810
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 347 Ends   ===================
INFO:root:Epoch:347 Global Model Test Loss:0.5327196384177488 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:347 Global Model Backdoor Test Loss:0.22471912453571954                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 348 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 348 Workers Selected : [376, 932, 206, 532, 1088, 339, 1682, 436, 1295, 1789]
INFO:root:FL Epoch: 348 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 348 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 348 Training on worker :376
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519463
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547796
INFO:root:FL Epoch: 348 Norm Difference for worker 376 is 0.965092
INFO:root:FL Epoch: 348 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :932
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323547
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518075
INFO:root:FL Epoch: 348 Norm Difference for worker 932 is 0.99098
INFO:root:FL Epoch: 348 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :206
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.577805
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.292604
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 348 Norm Difference for worker 206 is 0.895485
INFO:root:FL Epoch: 348 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :532
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449964
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350033
INFO:root:FL Epoch: 348 Norm Difference for worker 532 is 0.982241
INFO:root:FL Epoch: 348 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1088
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387751
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285848
INFO:root:FL Epoch: 348 Norm Difference for worker 1088 is 0.89817
INFO:root:FL Epoch: 348 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :339
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 339 Train Epoch: 0 [0/201 (0%)]	Loss: 0.453939
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 339 Train Epoch: 1 [0/201 (0%)]	Loss: 0.614474
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 348 Norm Difference for worker 339 is 0.994121
INFO:root:FL Epoch: 348 Done on worker:339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1682
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743698
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306428
INFO:root:FL Epoch: 348 Norm Difference for worker 1682 is 0.90058
INFO:root:FL Epoch: 348 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :436
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775730
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569085
INFO:root:FL Epoch: 348 Norm Difference for worker 436 is 1.000643
INFO:root:FL Epoch: 348 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1295
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508875
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505932
INFO:root:FL Epoch: 348 Norm Difference for worker 1295 is 0.942811
INFO:root:FL Epoch: 348 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1789
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428174
INFO:root:Worker: 1789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405396
INFO:root:FL Epoch: 348 Norm Difference for worker 1789 is 0.884338
INFO:root:FL Epoch: 348 Done on worker:1789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1789
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 348 Ends   ===================
INFO:root:Epoch:348 Global Model Test Loss:0.5317687129273134 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:348 Global Model Backdoor Test Loss:0.219843290746212                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 349 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 349 Workers Selected : [648, 1268, 337, 1086, 1112, 725, 610, 1600, 335, 996]
INFO:root:FL Epoch: 349 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 349 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 349 Training on worker :648
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350328
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401003
INFO:root:FL Epoch: 349 Norm Difference for worker 648 is 0.955394
INFO:root:FL Epoch: 349 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1268
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319869
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505115
INFO:root:FL Epoch: 349 Norm Difference for worker 1268 is 0.981742
INFO:root:FL Epoch: 349 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :337
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.586034
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.325629
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 349 Norm Difference for worker 337 is 0.951212
INFO:root:FL Epoch: 349 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1086
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371006
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.736931
INFO:root:FL Epoch: 349 Norm Difference for worker 1086 is 0.941687
INFO:root:FL Epoch: 349 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1112
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1112 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487637
INFO:root:Worker: 1112 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610789
INFO:root:FL Epoch: 349 Norm Difference for worker 1112 is 0.940139
INFO:root:FL Epoch: 349 Done on worker:1112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :725
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703008
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465957
INFO:root:FL Epoch: 349 Norm Difference for worker 725 is 0.978405
INFO:root:FL Epoch: 349 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :610
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319148
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586651
INFO:root:FL Epoch: 349 Norm Difference for worker 610 is 0.966904
INFO:root:FL Epoch: 349 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1600
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417486
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291147
INFO:root:FL Epoch: 349 Norm Difference for worker 1600 is 1.028537
INFO:root:FL Epoch: 349 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :335
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.497744
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.441683
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 349 Norm Difference for worker 335 is 0.94778
INFO:root:FL Epoch: 349 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :996
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618380
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566518
INFO:root:FL Epoch: 349 Norm Difference for worker 996 is 0.975254
INFO:root:FL Epoch: 349 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 335
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 349 Ends   ===================
INFO:root:Epoch:349 Global Model Test Loss:0.5073677353999194 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:349 Global Model Backdoor Test Loss:0.1927615317205588                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 350 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 350 Workers Selected : [969, 73, 1089, 1428, 306, 424, 1357, 441, 62, 459]
INFO:root:FL Epoch: 350 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 350 Num points on workers: [200 201 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 350 Training on worker :969
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 969 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580422
INFO:root:Worker: 969 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396214
INFO:root:FL Epoch: 350 Norm Difference for worker 969 is 0.950234
INFO:root:FL Epoch: 350 Done on worker:969
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :73
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.820408
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.573230
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 73 is 1.118554
INFO:root:FL Epoch: 350 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1089
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1089 Train Epoch: 0 [0/200 (0%)]	Loss: 0.793278
INFO:root:Worker: 1089 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372187
INFO:root:FL Epoch: 350 Norm Difference for worker 1089 is 0.900151
INFO:root:FL Epoch: 350 Done on worker:1089
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1428
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517706
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450892
INFO:root:FL Epoch: 350 Norm Difference for worker 1428 is 1.000494
INFO:root:FL Epoch: 350 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :306
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.307526
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.393616
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 306 is 1.001179
INFO:root:FL Epoch: 350 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :424
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430850
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273561
INFO:root:FL Epoch: 350 Norm Difference for worker 424 is 0.943673
INFO:root:FL Epoch: 350 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1357
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341867
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488528
INFO:root:FL Epoch: 350 Norm Difference for worker 1357 is 0.952868
INFO:root:FL Epoch: 350 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :441
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539366
INFO:root:Worker: 441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.705346
INFO:root:FL Epoch: 350 Norm Difference for worker 441 is 1.169182
INFO:root:FL Epoch: 350 Done on worker:441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :62
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.513657
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.401162
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 62 is 0.963862
INFO:root:FL Epoch: 350 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :459
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560030
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297655
INFO:root:FL Epoch: 350 Norm Difference for worker 459 is 0.965857
INFO:root:FL Epoch: 350 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1089
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 350 Ends   ===================
INFO:root:Epoch:350 Global Model Test Loss:0.5073837182101082 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:350 Global Model Backdoor Test Loss:0.22829358279705048                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 351 Begins ===================
INFO:root:FL Epoch: 351 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 351 Workers Selected : [0, 1, 2, 954, 1013, 183, 593, 1646, 153, 653]
INFO:root:FL Epoch: 351 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 351 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 351 Training on worker :0
INFO:root:FL Epoch: 351 Using Learning rate : 0.004962373518628473 
INFO:root:FL Epoch: 351 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.258371
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212711
INFO:root:FL Epoch: 351 Worker: 0 Backdoor Test Loss: 0.17972629144787788 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 351 Worker: 0 Backdoor Train Loss: 0.22549656331539153 Backdoor Train Accuracy: 93.5
INFO:root:FL Epoch: 351 Norm Difference for worker 0 is 0.167182
INFO:root:FL Epoch: 351 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1
INFO:root:FL Epoch: 351 Using Learning rate : 0.004962373518628473 
INFO:root:FL Epoch: 351 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422812
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264219
INFO:root:FL Epoch: 351 Worker: 1 Backdoor Test Loss: 0.17183915028969446 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 351 Worker: 1 Backdoor Train Loss: 0.22553963512182235 Backdoor Train Accuracy: 94.0
INFO:root:FL Epoch: 351 Norm Difference for worker 1 is 0.168412
INFO:root:FL Epoch: 351 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :2
INFO:root:FL Epoch: 351 Using Learning rate : 0.004962373518628473 
INFO:root:FL Epoch: 351 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.274722
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274867
INFO:root:FL Epoch: 351 Worker: 2 Backdoor Test Loss: 0.1753848654528459 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 351 Worker: 2 Backdoor Train Loss: 0.22480326741933823 Backdoor Train Accuracy: 94.0
INFO:root:FL Epoch: 351 Norm Difference for worker 2 is 0.170748
INFO:root:FL Epoch: 351 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :954
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 954 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597929
INFO:root:Worker: 954 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386211
INFO:root:FL Epoch: 351 Norm Difference for worker 954 is 0.859827
INFO:root:FL Epoch: 351 Done on worker:954
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1013
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502596
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438866
INFO:root:FL Epoch: 351 Norm Difference for worker 1013 is 0.969771
INFO:root:FL Epoch: 351 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :183
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 183 Train Epoch: 0 [0/201 (0%)]	Loss: 0.619700
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 183 Train Epoch: 1 [0/201 (0%)]	Loss: 0.605204
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 351 Norm Difference for worker 183 is 0.919164
INFO:root:FL Epoch: 351 Done on worker:183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :593
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652150
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512166
INFO:root:FL Epoch: 351 Norm Difference for worker 593 is 0.918141
INFO:root:FL Epoch: 351 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1646
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446649
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548518
INFO:root:FL Epoch: 351 Norm Difference for worker 1646 is 0.893748
INFO:root:FL Epoch: 351 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :153
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.433607
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.328729
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 351 Norm Difference for worker 153 is 0.85335
INFO:root:FL Epoch: 351 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :653
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530383
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370183
INFO:root:FL Epoch: 351 Norm Difference for worker 653 is 0.833774
INFO:root:FL Epoch: 351 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 351 Ends   ===================
INFO:root:Epoch:351 Global Model Test Loss:0.5074129525352927 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:351 Global Model Backdoor Test Loss:0.17972629144787788                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 352 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 352 Workers Selected : [1082, 949, 1688, 734, 277, 966, 748, 886, 918, 418]
INFO:root:FL Epoch: 352 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 352 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 352 Training on worker :1082
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319182
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454982
INFO:root:FL Epoch: 352 Norm Difference for worker 1082 is 0.883204
INFO:root:FL Epoch: 352 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :949
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687011
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464078
INFO:root:FL Epoch: 352 Norm Difference for worker 949 is 1.00526
INFO:root:FL Epoch: 352 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1688
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451484
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521273
INFO:root:FL Epoch: 352 Norm Difference for worker 1688 is 0.857214
INFO:root:FL Epoch: 352 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :734
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345776
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503473
INFO:root:FL Epoch: 352 Norm Difference for worker 734 is 0.908323
INFO:root:FL Epoch: 352 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :277
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.469251
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.581967
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 352 Norm Difference for worker 277 is 0.964482
INFO:root:FL Epoch: 352 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :966
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651463
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412141
INFO:root:FL Epoch: 352 Norm Difference for worker 966 is 0.915667
INFO:root:FL Epoch: 352 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :748
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438542
INFO:root:Worker: 748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353108
INFO:root:FL Epoch: 352 Norm Difference for worker 748 is 1.016125
INFO:root:FL Epoch: 352 Done on worker:748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :886
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644236
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530097
INFO:root:FL Epoch: 352 Norm Difference for worker 886 is 0.936778
INFO:root:FL Epoch: 352 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :918
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606273
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403453
INFO:root:FL Epoch: 352 Norm Difference for worker 918 is 0.96299
INFO:root:FL Epoch: 352 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :418
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.849967
INFO:root:Worker: 418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431231
INFO:root:FL Epoch: 352 Norm Difference for worker 418 is 0.991183
INFO:root:FL Epoch: 352 Done on worker:418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1688
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 352 Ends   ===================
INFO:root:Epoch:352 Global Model Test Loss:0.5064712990732754 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:352 Global Model Backdoor Test Loss:0.1801596904794375                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 353 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 353 Workers Selected : [115, 899, 1476, 185, 482, 1640, 1042, 354, 626, 922]
INFO:root:FL Epoch: 353 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 353 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 353 Training on worker :115
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.645837
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.434589
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 353 Norm Difference for worker 115 is 0.956015
INFO:root:FL Epoch: 353 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :899
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545241
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438079
INFO:root:FL Epoch: 353 Norm Difference for worker 899 is 1.007374
INFO:root:FL Epoch: 353 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1476
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349895
INFO:root:Worker: 1476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344617
INFO:root:FL Epoch: 353 Norm Difference for worker 1476 is 0.9934
INFO:root:FL Epoch: 353 Done on worker:1476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :185
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.433970
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.474401
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 353 Norm Difference for worker 185 is 0.985293
INFO:root:FL Epoch: 353 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :482
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346025
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412741
INFO:root:FL Epoch: 353 Norm Difference for worker 482 is 1.051616
INFO:root:FL Epoch: 353 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1640
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399924
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394915
INFO:root:FL Epoch: 353 Norm Difference for worker 1640 is 0.930812
INFO:root:FL Epoch: 353 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1042
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482529
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276285
INFO:root:FL Epoch: 353 Norm Difference for worker 1042 is 0.835957
INFO:root:FL Epoch: 353 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :354
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497445
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504128
INFO:root:FL Epoch: 353 Norm Difference for worker 354 is 1.004002
INFO:root:FL Epoch: 353 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :626
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304785
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409688
INFO:root:FL Epoch: 353 Norm Difference for worker 626 is 0.94317
INFO:root:FL Epoch: 353 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :922
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742714
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468509
INFO:root:FL Epoch: 353 Norm Difference for worker 922 is 1.005228
INFO:root:FL Epoch: 353 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1042
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 353 Ends   ===================
INFO:root:Epoch:353 Global Model Test Loss:0.5449388675829944 and Test Accuracy:75.0 
INFO:root:Epoch:353 Global Model Backdoor Test Loss:0.2188203471402327                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 354 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 354 Workers Selected : [1534, 1285, 791, 829, 1852, 1002, 160, 1586, 1575, 545]
INFO:root:FL Epoch: 354 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 354 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 354 Training on worker :1534
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.313424
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381036
INFO:root:FL Epoch: 354 Norm Difference for worker 1534 is 1.078672
INFO:root:FL Epoch: 354 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1285
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332346
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332370
INFO:root:FL Epoch: 354 Norm Difference for worker 1285 is 1.05461
INFO:root:FL Epoch: 354 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :791
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393341
INFO:root:Worker: 791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358466
INFO:root:FL Epoch: 354 Norm Difference for worker 791 is 1.070628
INFO:root:FL Epoch: 354 Done on worker:791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :829
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669895
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421111
INFO:root:FL Epoch: 354 Norm Difference for worker 829 is 1.140106
INFO:root:FL Epoch: 354 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1852
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404247
INFO:root:Worker: 1852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519178
INFO:root:FL Epoch: 354 Norm Difference for worker 1852 is 1.071151
INFO:root:FL Epoch: 354 Done on worker:1852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1002
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483828
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414692
INFO:root:FL Epoch: 354 Norm Difference for worker 1002 is 1.089089
INFO:root:FL Epoch: 354 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :160
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.505864
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470503
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 160 is 1.122282
INFO:root:FL Epoch: 354 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1586
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653413
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572871
INFO:root:FL Epoch: 354 Norm Difference for worker 1586 is 1.135289
INFO:root:FL Epoch: 354 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1575
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653053
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307517
INFO:root:FL Epoch: 354 Norm Difference for worker 1575 is 1.081976
INFO:root:FL Epoch: 354 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :545
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492731
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369035
INFO:root:FL Epoch: 354 Norm Difference for worker 545 is 1.056229
INFO:root:FL Epoch: 354 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1285
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 354 Ends   ===================
INFO:root:Epoch:354 Global Model Test Loss:0.5132753217921537 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:354 Global Model Backdoor Test Loss:0.21852665642897287                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 355 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 355 Workers Selected : [1219, 334, 82, 426, 457, 687, 836, 1157, 845, 422]
INFO:root:FL Epoch: 355 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 355 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 355 Training on worker :1219
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428558
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220851
INFO:root:FL Epoch: 355 Norm Difference for worker 1219 is 1.008472
INFO:root:FL Epoch: 355 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :334
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.540695
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.244651
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 355 Norm Difference for worker 334 is 0.974279
INFO:root:FL Epoch: 355 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :82
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 82 Train Epoch: 0 [0/201 (0%)]	Loss: 0.445330
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 82 Train Epoch: 1 [0/201 (0%)]	Loss: 0.476886
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 355 Norm Difference for worker 82 is 1.012381
INFO:root:FL Epoch: 355 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :426
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463450
INFO:root:Worker: 426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313716
INFO:root:FL Epoch: 355 Norm Difference for worker 426 is 0.946174
INFO:root:FL Epoch: 355 Done on worker:426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :457
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542083
INFO:root:Worker: 457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482066
INFO:root:FL Epoch: 355 Norm Difference for worker 457 is 0.997348
INFO:root:FL Epoch: 355 Done on worker:457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :687
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419138
INFO:root:Worker: 687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306698
INFO:root:FL Epoch: 355 Norm Difference for worker 687 is 0.939317
INFO:root:FL Epoch: 355 Done on worker:687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :836
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357530
INFO:root:Worker: 836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470724
INFO:root:FL Epoch: 355 Norm Difference for worker 836 is 0.958939
INFO:root:FL Epoch: 355 Done on worker:836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1157
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354556
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313224
INFO:root:FL Epoch: 355 Norm Difference for worker 1157 is 0.802095
INFO:root:FL Epoch: 355 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :845
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464594
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487824
INFO:root:FL Epoch: 355 Norm Difference for worker 845 is 1.008093
INFO:root:FL Epoch: 355 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :422
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549569
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516378
INFO:root:FL Epoch: 355 Norm Difference for worker 422 is 0.98911
INFO:root:FL Epoch: 355 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1157
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 355 Ends   ===================
INFO:root:Epoch:355 Global Model Test Loss:0.5266972587389105 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:355 Global Model Backdoor Test Loss:0.14580857381224632                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 356 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 356 Workers Selected : [1330, 1035, 774, 1736, 1439, 824, 957, 80, 952, 703]
INFO:root:FL Epoch: 356 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 356 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 356 Training on worker :1330
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414422
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459008
INFO:root:FL Epoch: 356 Norm Difference for worker 1330 is 1.193013
INFO:root:FL Epoch: 356 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1035
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1035 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516917
INFO:root:Worker: 1035 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462031
INFO:root:FL Epoch: 356 Norm Difference for worker 1035 is 1.449192
INFO:root:FL Epoch: 356 Done on worker:1035
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :774
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402734
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521578
INFO:root:FL Epoch: 356 Norm Difference for worker 774 is 1.008395
INFO:root:FL Epoch: 356 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1736
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672432
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468271
INFO:root:FL Epoch: 356 Norm Difference for worker 1736 is 1.120504
INFO:root:FL Epoch: 356 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1439
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520660
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613232
INFO:root:FL Epoch: 356 Norm Difference for worker 1439 is 1.17419
INFO:root:FL Epoch: 356 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :824
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599979
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504812
INFO:root:FL Epoch: 356 Norm Difference for worker 824 is 1.060194
INFO:root:FL Epoch: 356 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :957
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 957 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532513
INFO:root:Worker: 957 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305166
INFO:root:FL Epoch: 356 Norm Difference for worker 957 is 1.036099
INFO:root:FL Epoch: 356 Done on worker:957
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :80
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.342779
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.400087
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 80 is 0.971161
INFO:root:FL Epoch: 356 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :952
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491294
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590949
INFO:root:FL Epoch: 356 Norm Difference for worker 952 is 1.087114
INFO:root:FL Epoch: 356 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :703
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347322
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473288
INFO:root:FL Epoch: 356 Norm Difference for worker 703 is 1.06712
INFO:root:FL Epoch: 356 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 774
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 356 Ends   ===================
INFO:root:Epoch:356 Global Model Test Loss:0.5502354765639585 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:356 Global Model Backdoor Test Loss:0.19636997083822885                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 357 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 357 Workers Selected : [1090, 1884, 1139, 349, 877, 538, 147, 1085, 1142, 98]
INFO:root:FL Epoch: 357 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 357 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 357 Training on worker :1090
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676392
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535778
INFO:root:FL Epoch: 357 Norm Difference for worker 1090 is 1.014438
INFO:root:FL Epoch: 357 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1884
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653086
INFO:root:Worker: 1884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459950
INFO:root:FL Epoch: 357 Norm Difference for worker 1884 is 1.05701
INFO:root:FL Epoch: 357 Done on worker:1884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1139
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546429
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429414
INFO:root:FL Epoch: 357 Norm Difference for worker 1139 is 1.020056
INFO:root:FL Epoch: 357 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :349
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554947
INFO:root:Worker: 349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531540
INFO:root:FL Epoch: 357 Norm Difference for worker 349 is 0.988594
INFO:root:FL Epoch: 357 Done on worker:349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :877
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430782
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499191
INFO:root:FL Epoch: 357 Norm Difference for worker 877 is 1.012709
INFO:root:FL Epoch: 357 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :538
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470677
INFO:root:Worker: 538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678035
INFO:root:FL Epoch: 357 Norm Difference for worker 538 is 1.027039
INFO:root:FL Epoch: 357 Done on worker:538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :147
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.641777
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.537603
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 357 Norm Difference for worker 147 is 1.089649
INFO:root:FL Epoch: 357 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1085
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493753
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493262
INFO:root:FL Epoch: 357 Norm Difference for worker 1085 is 1.046504
INFO:root:FL Epoch: 357 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1142
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.863904
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328544
INFO:root:FL Epoch: 357 Norm Difference for worker 1142 is 1.04246
INFO:root:FL Epoch: 357 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :98
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.525507
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.468995
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 357 Norm Difference for worker 98 is 1.039078
INFO:root:FL Epoch: 357 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 349
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 357 Ends   ===================
INFO:root:Epoch:357 Global Model Test Loss:0.5213856679551742 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:357 Global Model Backdoor Test Loss:0.10763711606462796                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 358 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 358 Workers Selected : [527, 126, 1253, 917, 1316, 1311, 311, 779, 1872, 900]
INFO:root:FL Epoch: 358 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 358 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 358 Training on worker :527
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439632
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474533
INFO:root:FL Epoch: 358 Norm Difference for worker 527 is 1.059582
INFO:root:FL Epoch: 358 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :126
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.625865
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.482814
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 126 is 1.039583
INFO:root:FL Epoch: 358 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :1253
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1253 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782587
INFO:root:Worker: 1253 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503263
INFO:root:FL Epoch: 358 Norm Difference for worker 1253 is 1.015748
INFO:root:FL Epoch: 358 Done on worker:1253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :917
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496865
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499820
INFO:root:FL Epoch: 358 Norm Difference for worker 917 is 1.073032
INFO:root:FL Epoch: 358 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :1316
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.196654
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368163
INFO:root:FL Epoch: 358 Norm Difference for worker 1316 is 0.920341
INFO:root:FL Epoch: 358 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :1311
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485194
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528974
INFO:root:FL Epoch: 358 Norm Difference for worker 1311 is 1.023309
INFO:root:FL Epoch: 358 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :311
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.643018
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.607514
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 311 is 1.015407
INFO:root:FL Epoch: 358 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :779
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403015
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516814
INFO:root:FL Epoch: 358 Norm Difference for worker 779 is 1.050039
INFO:root:FL Epoch: 358 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :1872
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497859
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348389
INFO:root:FL Epoch: 358 Norm Difference for worker 1872 is 0.971174
INFO:root:FL Epoch: 358 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :900
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605320
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283924
INFO:root:FL Epoch: 358 Norm Difference for worker 900 is 0.966244
INFO:root:FL Epoch: 358 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1316
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 358 Ends   ===================
INFO:root:Epoch:358 Global Model Test Loss:0.5251421998528873 and Test Accuracy:75.0 
INFO:root:Epoch:358 Global Model Backdoor Test Loss:0.1092855545381705                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 359 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 359 Workers Selected : [757, 1832, 439, 689, 232, 1446, 1516, 603, 1899, 1913]
INFO:root:FL Epoch: 359 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 359 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 359 Training on worker :757
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502599
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413150
INFO:root:FL Epoch: 359 Norm Difference for worker 757 is 1.044424
INFO:root:FL Epoch: 359 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1832
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612233
INFO:root:Worker: 1832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395786
INFO:root:FL Epoch: 359 Norm Difference for worker 1832 is 1.080728
INFO:root:FL Epoch: 359 Done on worker:1832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :439
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.792278
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582288
INFO:root:FL Epoch: 359 Norm Difference for worker 439 is 1.027288
INFO:root:FL Epoch: 359 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :689
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512110
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532329
INFO:root:FL Epoch: 359 Norm Difference for worker 689 is 1.019772
INFO:root:FL Epoch: 359 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :232
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.828972
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446320
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 359 Norm Difference for worker 232 is 1.02716
INFO:root:FL Epoch: 359 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1446
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516843
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415610
INFO:root:FL Epoch: 359 Norm Difference for worker 1446 is 1.048269
INFO:root:FL Epoch: 359 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1516
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511342
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595669
INFO:root:FL Epoch: 359 Norm Difference for worker 1516 is 1.009958
INFO:root:FL Epoch: 359 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :603
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516950
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568139
INFO:root:FL Epoch: 359 Norm Difference for worker 603 is 1.075397
INFO:root:FL Epoch: 359 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1899
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354413
INFO:root:Worker: 1899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473631
INFO:root:FL Epoch: 359 Norm Difference for worker 1899 is 0.892928
INFO:root:FL Epoch: 359 Done on worker:1899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1913
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405384
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544825
INFO:root:FL Epoch: 359 Norm Difference for worker 1913 is 1.079253
INFO:root:FL Epoch: 359 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1899
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 359 Ends   ===================
INFO:root:Epoch:359 Global Model Test Loss:0.5304643494241378 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:359 Global Model Backdoor Test Loss:0.16586301972468695                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 360 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 360 Workers Selected : [492, 665, 1803, 1792, 1299, 384, 1039, 603, 159, 209]
INFO:root:FL Epoch: 360 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 360 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 360 Training on worker :492
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630845
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396727
INFO:root:FL Epoch: 360 Norm Difference for worker 492 is 1.081381
INFO:root:FL Epoch: 360 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :665
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637255
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396959
INFO:root:FL Epoch: 360 Norm Difference for worker 665 is 1.03545
INFO:root:FL Epoch: 360 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1803
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638533
INFO:root:Worker: 1803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590560
INFO:root:FL Epoch: 360 Norm Difference for worker 1803 is 1.171182
INFO:root:FL Epoch: 360 Done on worker:1803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1792
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462319
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477754
INFO:root:FL Epoch: 360 Norm Difference for worker 1792 is 1.00388
INFO:root:FL Epoch: 360 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1299
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1299 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703731
INFO:root:Worker: 1299 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431406
INFO:root:FL Epoch: 360 Norm Difference for worker 1299 is 1.037155
INFO:root:FL Epoch: 360 Done on worker:1299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :384
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533760
INFO:root:Worker: 384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422129
INFO:root:FL Epoch: 360 Norm Difference for worker 384 is 1.083469
INFO:root:FL Epoch: 360 Done on worker:384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1039
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1039 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550946
INFO:root:Worker: 1039 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379546
INFO:root:FL Epoch: 360 Norm Difference for worker 1039 is 1.139106
INFO:root:FL Epoch: 360 Done on worker:1039
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :603
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589999
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403955
INFO:root:FL Epoch: 360 Norm Difference for worker 603 is 1.161763
INFO:root:FL Epoch: 360 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :159
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500664
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.351168
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 159 is 1.138266
INFO:root:FL Epoch: 360 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :209
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 209 Train Epoch: 0 [0/201 (0%)]	Loss: 0.719517
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 209 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415693
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 209 is 1.050267
INFO:root:FL Epoch: 360 Done on worker:209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1792
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 360 Ends   ===================
INFO:root:Epoch:360 Global Model Test Loss:0.5307624690672931 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:360 Global Model Backdoor Test Loss:0.20721788704395294                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 361 Begins ===================
INFO:root:FL Epoch: 361 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 361 Workers Selected : [0, 1, 2, 906, 1144, 1064, 596, 1021, 234, 1844]
INFO:root:FL Epoch: 361 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 361 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 361 Training on worker :0
INFO:root:FL Epoch: 361 Using Learning rate : 0.004864014528244303 
INFO:root:FL Epoch: 361 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.129494
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.180041
INFO:root:FL Epoch: 361 Worker: 0 Backdoor Test Loss: 0.12627007688085237 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 361 Worker: 0 Backdoor Train Loss: 0.1765895292162895 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 361 Norm Difference for worker 0 is 0.176871
INFO:root:FL Epoch: 361 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1
INFO:root:FL Epoch: 361 Using Learning rate : 0.004864014528244303 
INFO:root:FL Epoch: 361 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.140656
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242435
INFO:root:FL Epoch: 361 Worker: 1 Backdoor Test Loss: 0.129360547910134 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 361 Worker: 1 Backdoor Train Loss: 0.17364229261875153 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 361 Norm Difference for worker 1 is 0.184099
INFO:root:FL Epoch: 361 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :2
INFO:root:FL Epoch: 361 Using Learning rate : 0.004864014528244303 
INFO:root:FL Epoch: 361 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.258913
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326310
INFO:root:FL Epoch: 361 Worker: 2 Backdoor Test Loss: 0.12430477763215701 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 361 Worker: 2 Backdoor Train Loss: 0.17568051889538766 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 361 Norm Difference for worker 2 is 0.181778
INFO:root:FL Epoch: 361 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :906
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716999
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268824
INFO:root:FL Epoch: 361 Norm Difference for worker 906 is 0.86602
INFO:root:FL Epoch: 361 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1144
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1144 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595075
INFO:root:Worker: 1144 Train Epoch: 1 [0/200 (0%)]	Loss: 0.750104
INFO:root:FL Epoch: 361 Norm Difference for worker 1144 is 0.99962
INFO:root:FL Epoch: 361 Done on worker:1144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1064
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1064 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627282
INFO:root:Worker: 1064 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364547
INFO:root:FL Epoch: 361 Norm Difference for worker 1064 is 1.12843
INFO:root:FL Epoch: 361 Done on worker:1064
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :596
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762212
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694776
INFO:root:FL Epoch: 361 Norm Difference for worker 596 is 1.044553
INFO:root:FL Epoch: 361 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1021
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657186
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526440
INFO:root:FL Epoch: 361 Norm Difference for worker 1021 is 1.051559
INFO:root:FL Epoch: 361 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :234
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 234 Train Epoch: 0 [0/201 (0%)]	Loss: 0.519114
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 234 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381942
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 361 Norm Difference for worker 234 is 1.218348
INFO:root:FL Epoch: 361 Done on worker:234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1844
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490191
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357867
INFO:root:FL Epoch: 361 Norm Difference for worker 1844 is 0.983631
INFO:root:FL Epoch: 361 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 361 Ends   ===================
INFO:root:Epoch:361 Global Model Test Loss:0.5333882657920613 and Test Accuracy:75.0 
INFO:root:Epoch:361 Global Model Backdoor Test Loss:0.12627007688085237                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 362 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 362 Workers Selected : [941, 1390, 1941, 884, 44, 1585, 1081, 1024, 1886, 1439]
INFO:root:FL Epoch: 362 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 362 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 362 Training on worker :941
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400561
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277928
INFO:root:FL Epoch: 362 Norm Difference for worker 941 is 1.026237
INFO:root:FL Epoch: 362 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1390
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393802
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.729843
INFO:root:FL Epoch: 362 Norm Difference for worker 1390 is 1.167986
INFO:root:FL Epoch: 362 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1941
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333029
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370551
INFO:root:FL Epoch: 362 Norm Difference for worker 1941 is 1.073525
INFO:root:FL Epoch: 362 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :884
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694547
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404186
INFO:root:FL Epoch: 362 Norm Difference for worker 884 is 1.122424
INFO:root:FL Epoch: 362 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :44
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 44 Train Epoch: 0 [0/201 (0%)]	Loss: 0.584042
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 44 Train Epoch: 1 [0/201 (0%)]	Loss: 0.597694
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 362 Norm Difference for worker 44 is 1.10629
INFO:root:FL Epoch: 362 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1585
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475169
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278175
INFO:root:FL Epoch: 362 Norm Difference for worker 1585 is 1.094965
INFO:root:FL Epoch: 362 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1081
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.884122
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629844
INFO:root:FL Epoch: 362 Norm Difference for worker 1081 is 1.287043
INFO:root:FL Epoch: 362 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1024
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710633
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.797235
INFO:root:FL Epoch: 362 Norm Difference for worker 1024 is 1.181361
INFO:root:FL Epoch: 362 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1886
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565846
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455793
INFO:root:FL Epoch: 362 Norm Difference for worker 1886 is 1.125807
INFO:root:FL Epoch: 362 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1439
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711657
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405663
INFO:root:FL Epoch: 362 Norm Difference for worker 1439 is 1.179227
INFO:root:FL Epoch: 362 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 941
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 362 Ends   ===================
INFO:root:Epoch:362 Global Model Test Loss:0.5104374517412746 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:362 Global Model Backdoor Test Loss:0.14636484533548355                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 363 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 363 Workers Selected : [1559, 1487, 359, 1586, 1338, 1840, 901, 711, 1413, 431]
INFO:root:FL Epoch: 363 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 363 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 363 Training on worker :1559
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745048
INFO:root:Worker: 1559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287347
INFO:root:FL Epoch: 363 Norm Difference for worker 1559 is 1.02487
INFO:root:FL Epoch: 363 Done on worker:1559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1487
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.816452
INFO:root:Worker: 1487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511192
INFO:root:FL Epoch: 363 Norm Difference for worker 1487 is 1.096232
INFO:root:FL Epoch: 363 Done on worker:1487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :359
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308702
INFO:root:Worker: 359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398607
INFO:root:FL Epoch: 363 Norm Difference for worker 359 is 1.012434
INFO:root:FL Epoch: 363 Done on worker:359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1586
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585713
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634030
INFO:root:FL Epoch: 363 Norm Difference for worker 1586 is 1.120772
INFO:root:FL Epoch: 363 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1338
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.299246
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360814
INFO:root:FL Epoch: 363 Norm Difference for worker 1338 is 0.881084
INFO:root:FL Epoch: 363 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1840
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670203
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363822
INFO:root:FL Epoch: 363 Norm Difference for worker 1840 is 1.100248
INFO:root:FL Epoch: 363 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :901
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 901 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449144
INFO:root:Worker: 901 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192090
INFO:root:FL Epoch: 363 Norm Difference for worker 901 is 0.976724
INFO:root:FL Epoch: 363 Done on worker:901
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :711
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530582
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467182
INFO:root:FL Epoch: 363 Norm Difference for worker 711 is 1.075713
INFO:root:FL Epoch: 363 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1413
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377483
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417765
INFO:root:FL Epoch: 363 Norm Difference for worker 1413 is 1.078141
INFO:root:FL Epoch: 363 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :431
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540668
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633779
INFO:root:FL Epoch: 363 Norm Difference for worker 431 is 1.051056
INFO:root:FL Epoch: 363 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1338
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 363 Ends   ===================
INFO:root:Epoch:363 Global Model Test Loss:0.5068964414736804 and Test Accuracy:75.0 
INFO:root:Epoch:363 Global Model Backdoor Test Loss:0.12661689519882202                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 364 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 364 Workers Selected : [1316, 898, 465, 599, 1822, 1634, 1455, 250, 791, 1388]
INFO:root:FL Epoch: 364 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 364 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 364 Training on worker :1316
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.329779
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332618
INFO:root:FL Epoch: 364 Norm Difference for worker 1316 is 0.781101
INFO:root:FL Epoch: 364 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :898
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703634
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356914
INFO:root:FL Epoch: 364 Norm Difference for worker 898 is 1.014589
INFO:root:FL Epoch: 364 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :465
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442597
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695133
INFO:root:FL Epoch: 364 Norm Difference for worker 465 is 1.087261
INFO:root:FL Epoch: 364 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :599
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651443
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364415
INFO:root:FL Epoch: 364 Norm Difference for worker 599 is 1.033145
INFO:root:FL Epoch: 364 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :1822
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696510
INFO:root:Worker: 1822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315929
INFO:root:FL Epoch: 364 Norm Difference for worker 1822 is 1.100576
INFO:root:FL Epoch: 364 Done on worker:1822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :1634
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498178
INFO:root:Worker: 1634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.705327
INFO:root:FL Epoch: 364 Norm Difference for worker 1634 is 1.052075
INFO:root:FL Epoch: 364 Done on worker:1634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :1455
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679824
INFO:root:Worker: 1455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563845
INFO:root:FL Epoch: 364 Norm Difference for worker 1455 is 1.008683
INFO:root:FL Epoch: 364 Done on worker:1455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :250
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.445361
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.575913
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 250 is 1.007045
INFO:root:FL Epoch: 364 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :791
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407433
INFO:root:Worker: 791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387107
INFO:root:FL Epoch: 364 Norm Difference for worker 791 is 1.02879
INFO:root:FL Epoch: 364 Done on worker:791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :1388
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620549
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363279
INFO:root:FL Epoch: 364 Norm Difference for worker 1388 is 1.0704
INFO:root:FL Epoch: 364 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1316
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 364 Ends   ===================
INFO:root:Epoch:364 Global Model Test Loss:0.5255969201817232 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:364 Global Model Backdoor Test Loss:0.10780469266076882                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 365 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 365 Workers Selected : [1295, 1294, 1754, 782, 108, 1018, 832, 133, 12, 34]
INFO:root:FL Epoch: 365 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004
 0.1002994 0.1002994 0.1002994]
INFO:root:FL Epoch: 365 Num points on workers: [200 200 200 200 201 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 365 Training on worker :1295
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.311549
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348876
INFO:root:FL Epoch: 365 Norm Difference for worker 1295 is 1.153903
INFO:root:FL Epoch: 365 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1294
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801476
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251421
INFO:root:FL Epoch: 365 Norm Difference for worker 1294 is 1.220602
INFO:root:FL Epoch: 365 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1754
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664963
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.815848
INFO:root:FL Epoch: 365 Norm Difference for worker 1754 is 1.183398
INFO:root:FL Epoch: 365 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :782
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426992
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616849
INFO:root:FL Epoch: 365 Norm Difference for worker 782 is 1.308541
INFO:root:FL Epoch: 365 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :108
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 108 Train Epoch: 0 [0/201 (0%)]	Loss: 0.574600
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 108 Train Epoch: 1 [0/201 (0%)]	Loss: 0.654136
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 365 Norm Difference for worker 108 is 1.242127
INFO:root:FL Epoch: 365 Done on worker:108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1018
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411866
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460431
INFO:root:FL Epoch: 365 Norm Difference for worker 1018 is 1.180751
INFO:root:FL Epoch: 365 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :832
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565310
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528081
INFO:root:FL Epoch: 365 Norm Difference for worker 832 is 1.358996
INFO:root:FL Epoch: 365 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :133
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.296837
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.383070
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 365 Norm Difference for worker 133 is 1.200254
INFO:root:FL Epoch: 365 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :12
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 12 Train Epoch: 0 [0/201 (0%)]	Loss: 0.422765
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 12 Train Epoch: 1 [0/201 (0%)]	Loss: 0.475891
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 365 Norm Difference for worker 12 is 1.277482
INFO:root:FL Epoch: 365 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :34
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 34 Train Epoch: 0 [0/201 (0%)]	Loss: 0.322156
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 34 Train Epoch: 1 [0/201 (0%)]	Loss: 0.349176
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 365 Norm Difference for worker 34 is 1.17355
INFO:root:FL Epoch: 365 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1295
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 365 Ends   ===================
INFO:root:Epoch:365 Global Model Test Loss:0.5238158510011786 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:365 Global Model Backdoor Test Loss:0.17689983795086542                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 366 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 366 Workers Selected : [319, 958, 1164, 515, 688, 1693, 1070, 1237, 1365, 936]
INFO:root:FL Epoch: 366 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 366 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 366 Training on worker :319
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.482584
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.439135
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 366 Norm Difference for worker 319 is 1.075485
INFO:root:FL Epoch: 366 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :958
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535938
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408725
INFO:root:FL Epoch: 366 Norm Difference for worker 958 is 1.096468
INFO:root:FL Epoch: 366 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1164
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1164 Train Epoch: 0 [0/200 (0%)]	Loss: 1.110695
INFO:root:Worker: 1164 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659351
INFO:root:FL Epoch: 366 Norm Difference for worker 1164 is 1.218891
INFO:root:FL Epoch: 366 Done on worker:1164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :515
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324056
INFO:root:Worker: 515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529795
INFO:root:FL Epoch: 366 Norm Difference for worker 515 is 1.046396
INFO:root:FL Epoch: 366 Done on worker:515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :688
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330699
INFO:root:Worker: 688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480710
INFO:root:FL Epoch: 366 Norm Difference for worker 688 is 1.084537
INFO:root:FL Epoch: 366 Done on worker:688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1693
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448381
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.149179
INFO:root:FL Epoch: 366 Norm Difference for worker 1693 is 0.999117
INFO:root:FL Epoch: 366 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1070
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439326
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512261
INFO:root:FL Epoch: 366 Norm Difference for worker 1070 is 1.189121
INFO:root:FL Epoch: 366 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1237
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.252981
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380189
INFO:root:FL Epoch: 366 Norm Difference for worker 1237 is 1.124806
INFO:root:FL Epoch: 366 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1365
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.852652
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335172
INFO:root:FL Epoch: 366 Norm Difference for worker 1365 is 1.0345
INFO:root:FL Epoch: 366 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :936
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721327
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568539
INFO:root:FL Epoch: 366 Norm Difference for worker 936 is 1.079552
INFO:root:FL Epoch: 366 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1693
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 366 Ends   ===================
INFO:root:Epoch:366 Global Model Test Loss:0.5170377720804775 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:366 Global Model Backdoor Test Loss:0.1275919390221437                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 367 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 367 Workers Selected : [106, 755, 81, 1241, 665, 1244, 1755, 1189, 785, 1463]
INFO:root:FL Epoch: 367 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 367 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 367 Training on worker :106
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.712981
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.775929
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 367 Norm Difference for worker 106 is 1.118954
INFO:root:FL Epoch: 367 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :755
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424899
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336780
INFO:root:FL Epoch: 367 Norm Difference for worker 755 is 1.073671
INFO:root:FL Epoch: 367 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :81
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.601466
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.602418
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 367 Norm Difference for worker 81 is 1.134106
INFO:root:FL Epoch: 367 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1241
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1241 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758625
INFO:root:Worker: 1241 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321828
INFO:root:FL Epoch: 367 Norm Difference for worker 1241 is 1.004785
INFO:root:FL Epoch: 367 Done on worker:1241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :665
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736969
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257934
INFO:root:FL Epoch: 367 Norm Difference for worker 665 is 1.022997
INFO:root:FL Epoch: 367 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1244
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306439
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528338
INFO:root:FL Epoch: 367 Norm Difference for worker 1244 is 1.088136
INFO:root:FL Epoch: 367 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1755
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684545
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374166
INFO:root:FL Epoch: 367 Norm Difference for worker 1755 is 1.004786
INFO:root:FL Epoch: 367 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1189
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1189 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465503
INFO:root:Worker: 1189 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527913
INFO:root:FL Epoch: 367 Norm Difference for worker 1189 is 1.078063
INFO:root:FL Epoch: 367 Done on worker:1189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :785
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414937
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199774
INFO:root:FL Epoch: 367 Norm Difference for worker 785 is 1.068511
INFO:root:FL Epoch: 367 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1463
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788072
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635365
INFO:root:FL Epoch: 367 Norm Difference for worker 1463 is 1.138567
INFO:root:FL Epoch: 367 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1241
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 367 Ends   ===================
INFO:root:Epoch:367 Global Model Test Loss:0.5180786637698903 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:367 Global Model Backdoor Test Loss:0.19146189093589783                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 368 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 368 Workers Selected : [1872, 1711, 18, 202, 30, 1782, 1869, 1830, 1197, 1476]
INFO:root:FL Epoch: 368 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 368 Num points on workers: [200 200 201 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 368 Training on worker :1872
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634368
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419324
INFO:root:FL Epoch: 368 Norm Difference for worker 1872 is 0.996036
INFO:root:FL Epoch: 368 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1711
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590266
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497380
INFO:root:FL Epoch: 368 Norm Difference for worker 1711 is 0.993849
INFO:root:FL Epoch: 368 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :18
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 18 Train Epoch: 0 [0/201 (0%)]	Loss: 0.532166
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 18 Train Epoch: 1 [0/201 (0%)]	Loss: 0.353813
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 18 is 0.919528
INFO:root:FL Epoch: 368 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :202
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.551418
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.462641
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 202 is 0.967611
INFO:root:FL Epoch: 368 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :30
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 30 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517577
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 30 Train Epoch: 1 [0/201 (0%)]	Loss: 0.350228
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 30 is 0.950302
INFO:root:FL Epoch: 368 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1782
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.262891
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487586
INFO:root:FL Epoch: 368 Norm Difference for worker 1782 is 0.961061
INFO:root:FL Epoch: 368 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1869
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652975
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492192
INFO:root:FL Epoch: 368 Norm Difference for worker 1869 is 0.975776
INFO:root:FL Epoch: 368 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1830
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552561
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606919
INFO:root:FL Epoch: 368 Norm Difference for worker 1830 is 0.987656
INFO:root:FL Epoch: 368 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1197
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.789848
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378916
INFO:root:FL Epoch: 368 Norm Difference for worker 1197 is 1.065442
INFO:root:FL Epoch: 368 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1476
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550343
INFO:root:Worker: 1476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397132
INFO:root:FL Epoch: 368 Norm Difference for worker 1476 is 1.030526
INFO:root:FL Epoch: 368 Done on worker:1476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 18
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 368 Ends   ===================
INFO:root:Epoch:368 Global Model Test Loss:0.5147481508114758 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:368 Global Model Backdoor Test Loss:0.1414799802005291                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 369 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 369 Workers Selected : [945, 273, 1442, 952, 1360, 854, 821, 1782, 807, 24]
INFO:root:FL Epoch: 369 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 369 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 369 Training on worker :945
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423353
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472795
INFO:root:FL Epoch: 369 Norm Difference for worker 945 is 0.868857
INFO:root:FL Epoch: 369 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :273
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 273 Train Epoch: 0 [0/201 (0%)]	Loss: 0.467032
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 273 Train Epoch: 1 [0/201 (0%)]	Loss: 0.380244
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 369 Norm Difference for worker 273 is 0.907264
INFO:root:FL Epoch: 369 Done on worker:273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :1442
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506606
INFO:root:Worker: 1442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514765
INFO:root:FL Epoch: 369 Norm Difference for worker 1442 is 0.98562
INFO:root:FL Epoch: 369 Done on worker:1442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :952
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384714
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315845
INFO:root:FL Epoch: 369 Norm Difference for worker 952 is 0.922095
INFO:root:FL Epoch: 369 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :1360
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752828
INFO:root:Worker: 1360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489948
INFO:root:FL Epoch: 369 Norm Difference for worker 1360 is 1.019087
INFO:root:FL Epoch: 369 Done on worker:1360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :854
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348482
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368417
INFO:root:FL Epoch: 369 Norm Difference for worker 854 is 0.968854
INFO:root:FL Epoch: 369 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :821
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658069
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294103
INFO:root:FL Epoch: 369 Norm Difference for worker 821 is 0.987159
INFO:root:FL Epoch: 369 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :1782
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485070
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377910
INFO:root:FL Epoch: 369 Norm Difference for worker 1782 is 0.945927
INFO:root:FL Epoch: 369 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :807
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337562
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425476
INFO:root:FL Epoch: 369 Norm Difference for worker 807 is 0.963577
INFO:root:FL Epoch: 369 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :24
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.448889
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.347003
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 369 Norm Difference for worker 24 is 1.032682
INFO:root:FL Epoch: 369 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 945
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 369 Ends   ===================
INFO:root:Epoch:369 Global Model Test Loss:0.5305086234036613 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:369 Global Model Backdoor Test Loss:0.1757019187013308                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 370 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 370 Workers Selected : [603, 40, 1838, 467, 350, 263, 1301, 833, 465, 863]
INFO:root:FL Epoch: 370 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 370 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 370 Training on worker :603
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628627
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437086
INFO:root:FL Epoch: 370 Norm Difference for worker 603 is 1.0601
INFO:root:FL Epoch: 370 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :40
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 40 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494614
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 40 Train Epoch: 1 [0/201 (0%)]	Loss: 0.460291
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 40 is 0.991403
INFO:root:FL Epoch: 370 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :1838
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720037
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374761
INFO:root:FL Epoch: 370 Norm Difference for worker 1838 is 1.067842
INFO:root:FL Epoch: 370 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :467
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.180588
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321883
INFO:root:FL Epoch: 370 Norm Difference for worker 467 is 0.86726
INFO:root:FL Epoch: 370 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :350
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686121
INFO:root:Worker: 350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515712
INFO:root:FL Epoch: 370 Norm Difference for worker 350 is 1.122317
INFO:root:FL Epoch: 370 Done on worker:350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :263
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 263 Train Epoch: 0 [0/201 (0%)]	Loss: 0.437124
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 263 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447608
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 370 Norm Difference for worker 263 is 1.006279
INFO:root:FL Epoch: 370 Done on worker:263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :1301
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 1301 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715777
INFO:root:Worker: 1301 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677777
INFO:root:FL Epoch: 370 Norm Difference for worker 1301 is 1.090225
INFO:root:FL Epoch: 370 Done on worker:1301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :833
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450053
INFO:root:Worker: 833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342127
INFO:root:FL Epoch: 370 Norm Difference for worker 833 is 0.943825
INFO:root:FL Epoch: 370 Done on worker:833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :465
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525522
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559218
INFO:root:FL Epoch: 370 Norm Difference for worker 465 is 1.015643
INFO:root:FL Epoch: 370 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :863
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554927
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574098
INFO:root:FL Epoch: 370 Norm Difference for worker 863 is 1.030262
INFO:root:FL Epoch: 370 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 467
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 370 Ends   ===================
INFO:root:Epoch:370 Global Model Test Loss:0.5486727269256816 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:370 Global Model Backdoor Test Loss:0.1711899141470591                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 371 Begins ===================
INFO:root:FL Epoch: 371 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 371 Workers Selected : [0, 1, 2, 694, 1305, 1063, 1767, 318, 760, 1876]
INFO:root:FL Epoch: 371 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 371 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 371 Training on worker :0
INFO:root:FL Epoch: 371 Using Learning rate : 0.0047676051071444845 
INFO:root:FL Epoch: 371 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.213002
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260402
INFO:root:FL Epoch: 371 Worker: 0 Backdoor Test Loss: 0.11604524652163188 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 371 Worker: 0 Backdoor Train Loss: 0.17705857381224632 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 371 Norm Difference for worker 0 is 0.162714
INFO:root:FL Epoch: 371 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1
INFO:root:FL Epoch: 371 Using Learning rate : 0.0047676051071444845 
INFO:root:FL Epoch: 371 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.140477
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192208
INFO:root:FL Epoch: 371 Worker: 1 Backdoor Test Loss: 0.11484465996424358 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 371 Worker: 1 Backdoor Train Loss: 0.1746114082634449 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 371 Norm Difference for worker 1 is 0.173385
INFO:root:FL Epoch: 371 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :2
INFO:root:FL Epoch: 371 Using Learning rate : 0.0047676051071444845 
INFO:root:FL Epoch: 371 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.204678
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203519
INFO:root:FL Epoch: 371 Worker: 2 Backdoor Test Loss: 0.11424687628944714 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 371 Worker: 2 Backdoor Train Loss: 0.17513269633054734 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 371 Norm Difference for worker 2 is 0.174112
INFO:root:FL Epoch: 371 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :694
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542850
INFO:root:Worker: 694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462241
INFO:root:FL Epoch: 371 Norm Difference for worker 694 is 1.048433
INFO:root:FL Epoch: 371 Done on worker:694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1305
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1305 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593481
INFO:root:Worker: 1305 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213043
INFO:root:FL Epoch: 371 Norm Difference for worker 1305 is 1.094178
INFO:root:FL Epoch: 371 Done on worker:1305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1063
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383596
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327474
INFO:root:FL Epoch: 371 Norm Difference for worker 1063 is 1.058669
INFO:root:FL Epoch: 371 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1767
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.282914
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352176
INFO:root:FL Epoch: 371 Norm Difference for worker 1767 is 1.122504
INFO:root:FL Epoch: 371 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :318
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.721807
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.494352
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 371 Norm Difference for worker 318 is 1.082555
INFO:root:FL Epoch: 371 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :760
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745433
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588025
INFO:root:FL Epoch: 371 Norm Difference for worker 760 is 1.087351
INFO:root:FL Epoch: 371 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1876
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473045
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325661
INFO:root:FL Epoch: 371 Norm Difference for worker 1876 is 1.091175
INFO:root:FL Epoch: 371 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 371 Ends   ===================
INFO:root:Epoch:371 Global Model Test Loss:0.5411416958360111 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:371 Global Model Backdoor Test Loss:0.11604524652163188                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 372 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 372 Workers Selected : [1003, 375, 966, 334, 312, 1747, 1294, 737, 1064, 1392]
INFO:root:FL Epoch: 372 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 372 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 372 Training on worker :1003
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524800
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299334
INFO:root:FL Epoch: 372 Norm Difference for worker 1003 is 1.093074
INFO:root:FL Epoch: 372 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :375
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673391
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307267
INFO:root:FL Epoch: 372 Norm Difference for worker 375 is 1.077921
INFO:root:FL Epoch: 372 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :966
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545845
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238284
INFO:root:FL Epoch: 372 Norm Difference for worker 966 is 1.106087
INFO:root:FL Epoch: 372 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :334
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.926817
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.677222
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 372 Norm Difference for worker 334 is 1.130362
INFO:root:FL Epoch: 372 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :312
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.579669
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.412292
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 372 Norm Difference for worker 312 is 1.070534
INFO:root:FL Epoch: 372 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1747
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.284412
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308300
INFO:root:FL Epoch: 372 Norm Difference for worker 1747 is 1.231392
INFO:root:FL Epoch: 372 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1294
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402538
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419789
INFO:root:FL Epoch: 372 Norm Difference for worker 1294 is 1.206788
INFO:root:FL Epoch: 372 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :737
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347488
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356606
INFO:root:FL Epoch: 372 Norm Difference for worker 737 is 0.987755
INFO:root:FL Epoch: 372 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1064
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1064 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371346
INFO:root:Worker: 1064 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609485
INFO:root:FL Epoch: 372 Norm Difference for worker 1064 is 1.207803
INFO:root:FL Epoch: 372 Done on worker:1064
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1392
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.248286
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343165
INFO:root:FL Epoch: 372 Norm Difference for worker 1392 is 1.156812
INFO:root:FL Epoch: 372 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 737
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 372 Ends   ===================
INFO:root:Epoch:372 Global Model Test Loss:0.5250747028519126 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:372 Global Model Backdoor Test Loss:0.08705496042966843                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 373 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 373 Workers Selected : [1721, 1093, 1173, 968, 270, 894, 594, 1009, 1378, 906]
INFO:root:FL Epoch: 373 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 373 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 373 Training on worker :1721
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.189428
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342120
INFO:root:FL Epoch: 373 Norm Difference for worker 1721 is 0.887546
INFO:root:FL Epoch: 373 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1093
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749559
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526416
INFO:root:FL Epoch: 373 Norm Difference for worker 1093 is 1.151194
INFO:root:FL Epoch: 373 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1173
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482714
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332950
INFO:root:FL Epoch: 373 Norm Difference for worker 1173 is 1.056309
INFO:root:FL Epoch: 373 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :968
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599576
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439252
INFO:root:FL Epoch: 373 Norm Difference for worker 968 is 1.254064
INFO:root:FL Epoch: 373 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :270
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.644967
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.367379
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 373 Norm Difference for worker 270 is 1.13512
INFO:root:FL Epoch: 373 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :894
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.286823
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420304
INFO:root:FL Epoch: 373 Norm Difference for worker 894 is 1.12511
INFO:root:FL Epoch: 373 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :594
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341907
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700304
INFO:root:FL Epoch: 373 Norm Difference for worker 594 is 1.241292
INFO:root:FL Epoch: 373 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1009
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738403
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453171
INFO:root:FL Epoch: 373 Norm Difference for worker 1009 is 1.193294
INFO:root:FL Epoch: 373 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1378
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710494
INFO:root:Worker: 1378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413727
INFO:root:FL Epoch: 373 Norm Difference for worker 1378 is 1.233764
INFO:root:FL Epoch: 373 Done on worker:1378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :906
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.282327
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329625
INFO:root:FL Epoch: 373 Norm Difference for worker 906 is 0.933508
INFO:root:FL Epoch: 373 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1721
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 373 Ends   ===================
INFO:root:Epoch:373 Global Model Test Loss:0.5422049848472371 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:373 Global Model Backdoor Test Loss:0.08393439091742039                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 374 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 374 Workers Selected : [1667, 907, 1313, 522, 913, 1260, 1683, 925, 1459, 1264]
INFO:root:FL Epoch: 374 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 374 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 374 Training on worker :1667
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618054
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649158
INFO:root:FL Epoch: 374 Norm Difference for worker 1667 is 1.232476
INFO:root:FL Epoch: 374 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :907
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596193
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488849
INFO:root:FL Epoch: 374 Norm Difference for worker 907 is 1.253705
INFO:root:FL Epoch: 374 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1313
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408763
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329649
INFO:root:FL Epoch: 374 Norm Difference for worker 1313 is 0.915455
INFO:root:FL Epoch: 374 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :522
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401506
INFO:root:Worker: 522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358412
INFO:root:FL Epoch: 374 Norm Difference for worker 522 is 1.226287
INFO:root:FL Epoch: 374 Done on worker:522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :913
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749489
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372861
INFO:root:FL Epoch: 374 Norm Difference for worker 913 is 1.240176
INFO:root:FL Epoch: 374 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1260
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.966910
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345588
INFO:root:FL Epoch: 374 Norm Difference for worker 1260 is 1.16114
INFO:root:FL Epoch: 374 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1683
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729763
INFO:root:Worker: 1683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444614
INFO:root:FL Epoch: 374 Norm Difference for worker 1683 is 1.269811
INFO:root:FL Epoch: 374 Done on worker:1683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :925
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374772
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389987
INFO:root:FL Epoch: 374 Norm Difference for worker 925 is 1.11252
INFO:root:FL Epoch: 374 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1459
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734101
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293460
INFO:root:FL Epoch: 374 Norm Difference for worker 1459 is 1.308699
INFO:root:FL Epoch: 374 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1264
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1264 Train Epoch: 0 [0/200 (0%)]	Loss: 0.850737
INFO:root:Worker: 1264 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302983
INFO:root:FL Epoch: 374 Norm Difference for worker 1264 is 1.205497
INFO:root:FL Epoch: 374 Done on worker:1264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1313
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 374 Ends   ===================
INFO:root:Epoch:374 Global Model Test Loss:0.5550907289280611 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:374 Global Model Backdoor Test Loss:0.04681123637904724                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 375 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 375 Workers Selected : [850, 914, 1212, 1570, 305, 1197, 1169, 1057, 1584, 1528]
INFO:root:FL Epoch: 375 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 375 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 375 Training on worker :850
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687039
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635128
INFO:root:FL Epoch: 375 Norm Difference for worker 850 is 1.418972
INFO:root:FL Epoch: 375 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :914
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601466
INFO:root:Worker: 914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603592
INFO:root:FL Epoch: 375 Norm Difference for worker 914 is 1.378722
INFO:root:FL Epoch: 375 Done on worker:914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1212
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618041
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323240
INFO:root:FL Epoch: 375 Norm Difference for worker 1212 is 1.394718
INFO:root:FL Epoch: 375 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1570
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 1.101862
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365764
INFO:root:FL Epoch: 375 Norm Difference for worker 1570 is 1.478193
INFO:root:FL Epoch: 375 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :305
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.585268
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.278964
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 305 is 1.241497
INFO:root:FL Epoch: 375 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1197
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536934
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183953
INFO:root:FL Epoch: 375 Norm Difference for worker 1197 is 1.391729
INFO:root:FL Epoch: 375 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1169
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474906
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420224
INFO:root:FL Epoch: 375 Norm Difference for worker 1169 is 1.398703
INFO:root:FL Epoch: 375 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1057
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1057 Train Epoch: 0 [0/200 (0%)]	Loss: 0.864956
INFO:root:Worker: 1057 Train Epoch: 1 [0/200 (0%)]	Loss: 0.726738
INFO:root:FL Epoch: 375 Norm Difference for worker 1057 is 1.390252
INFO:root:FL Epoch: 375 Done on worker:1057
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1584
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612882
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574453
INFO:root:FL Epoch: 375 Norm Difference for worker 1584 is 1.248407
INFO:root:FL Epoch: 375 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1528
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598660
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251682
INFO:root:FL Epoch: 375 Norm Difference for worker 1528 is 1.110117
INFO:root:FL Epoch: 375 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1528
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 375 Ends   ===================
INFO:root:Epoch:375 Global Model Test Loss:0.5135428379563725 and Test Accuracy:80.0 
INFO:root:Epoch:375 Global Model Backdoor Test Loss:0.09679325421651204                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 376 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 376 Workers Selected : [637, 1889, 528, 1101, 1673, 974, 1233, 787, 977, 516]
INFO:root:FL Epoch: 376 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 376 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 376 Training on worker :637
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473229
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463617
INFO:root:FL Epoch: 376 Norm Difference for worker 637 is 1.276669
INFO:root:FL Epoch: 376 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1889
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738643
INFO:root:Worker: 1889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572084
INFO:root:FL Epoch: 376 Norm Difference for worker 1889 is 1.258394
INFO:root:FL Epoch: 376 Done on worker:1889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :528
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.943524
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332163
INFO:root:FL Epoch: 376 Norm Difference for worker 528 is 1.253707
INFO:root:FL Epoch: 376 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1101
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1101 Train Epoch: 0 [0/200 (0%)]	Loss: 1.092783
INFO:root:Worker: 1101 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371528
INFO:root:FL Epoch: 376 Norm Difference for worker 1101 is 1.148056
INFO:root:FL Epoch: 376 Done on worker:1101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1673
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731580
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260927
INFO:root:FL Epoch: 376 Norm Difference for worker 1673 is 1.165296
INFO:root:FL Epoch: 376 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :974
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 974 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603726
INFO:root:Worker: 974 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184678
INFO:root:FL Epoch: 376 Norm Difference for worker 974 is 1.197275
INFO:root:FL Epoch: 376 Done on worker:974
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1233
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1233 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361427
INFO:root:Worker: 1233 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226736
INFO:root:FL Epoch: 376 Norm Difference for worker 1233 is 1.318906
INFO:root:FL Epoch: 376 Done on worker:1233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :787
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651752
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355295
INFO:root:FL Epoch: 376 Norm Difference for worker 787 is 1.186532
INFO:root:FL Epoch: 376 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :977
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700398
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415850
INFO:root:FL Epoch: 376 Norm Difference for worker 977 is 1.258924
INFO:root:FL Epoch: 376 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :516
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636716
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454163
INFO:root:FL Epoch: 376 Norm Difference for worker 516 is 1.222061
INFO:root:FL Epoch: 376 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1101
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 376 Ends   ===================
INFO:root:Epoch:376 Global Model Test Loss:0.4835880433811861 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:376 Global Model Backdoor Test Loss:0.11175282547871272                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 377 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 377 Workers Selected : [313, 908, 557, 881, 1256, 539, 8, 220, 342, 1936]
INFO:root:FL Epoch: 377 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 377 Num points on workers: [201 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 377 Training on worker :313
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.514054
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.408629
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 313 is 0.985514
INFO:root:FL Epoch: 377 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :908
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682911
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480879
INFO:root:FL Epoch: 377 Norm Difference for worker 908 is 1.015032
INFO:root:FL Epoch: 377 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :557
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395946
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524827
INFO:root:FL Epoch: 377 Norm Difference for worker 557 is 0.860747
INFO:root:FL Epoch: 377 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :881
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452301
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273572
INFO:root:FL Epoch: 377 Norm Difference for worker 881 is 0.879462
INFO:root:FL Epoch: 377 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1256
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324378
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488200
INFO:root:FL Epoch: 377 Norm Difference for worker 1256 is 1.030712
INFO:root:FL Epoch: 377 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :539
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708610
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512733
INFO:root:FL Epoch: 377 Norm Difference for worker 539 is 1.079501
INFO:root:FL Epoch: 377 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :8
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.448950
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.589436
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 8 is 0.960257
INFO:root:FL Epoch: 377 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :220
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 220 Train Epoch: 0 [0/201 (0%)]	Loss: 0.404777
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 220 Train Epoch: 1 [0/201 (0%)]	Loss: 0.265626
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 220 is 0.882542
INFO:root:FL Epoch: 377 Done on worker:220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :342
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745273
INFO:root:Worker: 342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209997
INFO:root:FL Epoch: 377 Norm Difference for worker 342 is 1.061105
INFO:root:FL Epoch: 377 Done on worker:342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1936
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616761
INFO:root:Worker: 1936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380150
INFO:root:FL Epoch: 377 Norm Difference for worker 1936 is 1.001623
INFO:root:FL Epoch: 377 Done on worker:1936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 557
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 377 Ends   ===================
INFO:root:Epoch:377 Global Model Test Loss:0.4913596405702479 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:377 Global Model Backdoor Test Loss:0.10394742215673129                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 378 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 378 Workers Selected : [1855, 418, 1550, 1800, 1189, 611, 325, 983, 666, 70]
INFO:root:FL Epoch: 378 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 378 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 378 Training on worker :1855
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598330
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337466
INFO:root:FL Epoch: 378 Norm Difference for worker 1855 is 1.042547
INFO:root:FL Epoch: 378 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :418
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742751
INFO:root:Worker: 418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433012
INFO:root:FL Epoch: 378 Norm Difference for worker 418 is 1.149014
INFO:root:FL Epoch: 378 Done on worker:418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1550
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650906
INFO:root:Worker: 1550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457313
INFO:root:FL Epoch: 378 Norm Difference for worker 1550 is 1.098212
INFO:root:FL Epoch: 378 Done on worker:1550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1800
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477839
INFO:root:Worker: 1800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442823
INFO:root:FL Epoch: 378 Norm Difference for worker 1800 is 1.040644
INFO:root:FL Epoch: 378 Done on worker:1800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1189
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1189 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500797
INFO:root:Worker: 1189 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394593
INFO:root:FL Epoch: 378 Norm Difference for worker 1189 is 1.128077
INFO:root:FL Epoch: 378 Done on worker:1189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :611
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496126
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472117
INFO:root:FL Epoch: 378 Norm Difference for worker 611 is 1.089765
INFO:root:FL Epoch: 378 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :325
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.475031
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.394022
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 378 Norm Difference for worker 325 is 1.072914
INFO:root:FL Epoch: 378 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :983
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629932
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421184
INFO:root:FL Epoch: 378 Norm Difference for worker 983 is 1.106223
INFO:root:FL Epoch: 378 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :666
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418092
INFO:root:Worker: 666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393272
INFO:root:FL Epoch: 378 Norm Difference for worker 666 is 1.099043
INFO:root:FL Epoch: 378 Done on worker:666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :70
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.383146
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.466965
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 378 Norm Difference for worker 70 is 1.030763
INFO:root:FL Epoch: 378 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 70
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 378 Ends   ===================
INFO:root:Epoch:378 Global Model Test Loss:0.4912439269178054 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:378 Global Model Backdoor Test Loss:0.17192868143320084                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 379 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 379 Workers Selected : [1226, 1285, 972, 393, 977, 59, 575, 472, 1689, 565]
INFO:root:FL Epoch: 379 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 379 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 379 Training on worker :1226
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429885
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301096
INFO:root:FL Epoch: 379 Norm Difference for worker 1226 is 0.868464
INFO:root:FL Epoch: 379 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :1285
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580527
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429979
INFO:root:FL Epoch: 379 Norm Difference for worker 1285 is 0.819066
INFO:root:FL Epoch: 379 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :972
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 972 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530097
INFO:root:Worker: 972 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498087
INFO:root:FL Epoch: 379 Norm Difference for worker 972 is 0.983015
INFO:root:FL Epoch: 379 Done on worker:972
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :393
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558959
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451626
INFO:root:FL Epoch: 379 Norm Difference for worker 393 is 0.912671
INFO:root:FL Epoch: 379 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :977
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562716
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459060
INFO:root:FL Epoch: 379 Norm Difference for worker 977 is 0.878942
INFO:root:FL Epoch: 379 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :59
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.444939
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.440363
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 379 Norm Difference for worker 59 is 0.916168
INFO:root:FL Epoch: 379 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :575
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391732
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260237
INFO:root:FL Epoch: 379 Norm Difference for worker 575 is 0.928762
INFO:root:FL Epoch: 379 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :472
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505221
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314462
INFO:root:FL Epoch: 379 Norm Difference for worker 472 is 1.036906
INFO:root:FL Epoch: 379 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :1689
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448499
INFO:root:Worker: 1689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597343
INFO:root:FL Epoch: 379 Norm Difference for worker 1689 is 0.900909
INFO:root:FL Epoch: 379 Done on worker:1689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :565
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578734
INFO:root:Worker: 565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310744
INFO:root:FL Epoch: 379 Norm Difference for worker 565 is 0.975329
INFO:root:FL Epoch: 379 Done on worker:565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1285
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 379 Ends   ===================
INFO:root:Epoch:379 Global Model Test Loss:0.4914785816388972 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:379 Global Model Backdoor Test Loss:0.14499322697520256                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 380 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 380 Workers Selected : [1850, 989, 611, 637, 1690, 1250, 844, 1444, 120, 134]
INFO:root:FL Epoch: 380 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 380 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 380 Training on worker :1850
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.288756
INFO:root:Worker: 1850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355108
INFO:root:FL Epoch: 380 Norm Difference for worker 1850 is 0.982217
INFO:root:FL Epoch: 380 Done on worker:1850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :989
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 989 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618684
INFO:root:Worker: 989 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708337
INFO:root:FL Epoch: 380 Norm Difference for worker 989 is 1.003202
INFO:root:FL Epoch: 380 Done on worker:989
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :611
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418540
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404363
INFO:root:FL Epoch: 380 Norm Difference for worker 611 is 1.01987
INFO:root:FL Epoch: 380 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :637
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545913
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446483
INFO:root:FL Epoch: 380 Norm Difference for worker 637 is 1.062878
INFO:root:FL Epoch: 380 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1690
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553516
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510550
INFO:root:FL Epoch: 380 Norm Difference for worker 1690 is 1.006695
INFO:root:FL Epoch: 380 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1250
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605892
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.833403
INFO:root:FL Epoch: 380 Norm Difference for worker 1250 is 1.016719
INFO:root:FL Epoch: 380 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :844
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418732
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517217
INFO:root:FL Epoch: 380 Norm Difference for worker 844 is 0.815237
INFO:root:FL Epoch: 380 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1444
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461938
INFO:root:Worker: 1444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286423
INFO:root:FL Epoch: 380 Norm Difference for worker 1444 is 0.9498
INFO:root:FL Epoch: 380 Done on worker:1444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :120
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 120 Train Epoch: 0 [0/201 (0%)]	Loss: 0.550748
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 120 Train Epoch: 1 [0/201 (0%)]	Loss: 0.374956
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 380 Norm Difference for worker 120 is 0.913625
INFO:root:FL Epoch: 380 Done on worker:120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :134
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.794313
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.442564
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 380 Norm Difference for worker 134 is 0.955667
INFO:root:FL Epoch: 380 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 844
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 380 Ends   ===================
INFO:root:Epoch:380 Global Model Test Loss:0.5112152380101821 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:380 Global Model Backdoor Test Loss:0.14410018175840378                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 381 Begins ===================
INFO:root:FL Epoch: 381 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 381 Workers Selected : [0, 1, 2, 869, 716, 1560, 623, 1018, 195, 1034]
INFO:root:FL Epoch: 381 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 381 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 381 Training on worker :0
INFO:root:FL Epoch: 381 Using Learning rate : 0.00467310661300075 
INFO:root:FL Epoch: 381 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.168673
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.136954
INFO:root:FL Epoch: 381 Worker: 0 Backdoor Test Loss: 0.12201133867104848 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 381 Worker: 0 Backdoor Train Loss: 0.17918727323412895 Backdoor Train Accuracy: 94.5
INFO:root:FL Epoch: 381 Norm Difference for worker 0 is 0.142308
INFO:root:FL Epoch: 381 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1
INFO:root:FL Epoch: 381 Using Learning rate : 0.00467310661300075 
INFO:root:FL Epoch: 381 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.233243
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336605
INFO:root:FL Epoch: 381 Worker: 1 Backdoor Test Loss: 0.1220379260679086 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 381 Worker: 1 Backdoor Train Loss: 0.176497433334589 Backdoor Train Accuracy: 94.5
INFO:root:FL Epoch: 381 Norm Difference for worker 1 is 0.156265
INFO:root:FL Epoch: 381 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :2
INFO:root:FL Epoch: 381 Using Learning rate : 0.00467310661300075 
INFO:root:FL Epoch: 381 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.258751
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.158809
INFO:root:FL Epoch: 381 Worker: 2 Backdoor Test Loss: 0.12621683130661646 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 381 Worker: 2 Backdoor Train Loss: 0.17660756707191466 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 381 Norm Difference for worker 2 is 0.152624
INFO:root:FL Epoch: 381 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :869
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523385
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547491
INFO:root:FL Epoch: 381 Norm Difference for worker 869 is 1.019761
INFO:root:FL Epoch: 381 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :716
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507549
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197627
INFO:root:FL Epoch: 381 Norm Difference for worker 716 is 1.006723
INFO:root:FL Epoch: 381 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1560
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559362
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417845
INFO:root:FL Epoch: 381 Norm Difference for worker 1560 is 1.02675
INFO:root:FL Epoch: 381 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :623
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545253
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544442
INFO:root:FL Epoch: 381 Norm Difference for worker 623 is 1.072095
INFO:root:FL Epoch: 381 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1018
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 1.045895
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493577
INFO:root:FL Epoch: 381 Norm Difference for worker 1018 is 1.01783
INFO:root:FL Epoch: 381 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :195
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.462165
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.395425
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 381 Norm Difference for worker 195 is 1.093546
INFO:root:FL Epoch: 381 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1034
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454091
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313985
INFO:root:FL Epoch: 381 Norm Difference for worker 1034 is 1.127377
INFO:root:FL Epoch: 381 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 381 Ends   ===================
INFO:root:Epoch:381 Global Model Test Loss:0.5148307251579621 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:381 Global Model Backdoor Test Loss:0.12201133867104848                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 382 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 382 Workers Selected : [1201, 1052, 959, 1624, 825, 1782, 488, 507, 1078, 1849]
INFO:root:FL Epoch: 382 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 382 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 382 Training on worker :1201
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1201 Train Epoch: 0 [0/200 (0%)]	Loss: 0.825064
INFO:root:Worker: 1201 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523578
INFO:root:FL Epoch: 382 Norm Difference for worker 1201 is 1.127737
INFO:root:FL Epoch: 382 Done on worker:1201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1052
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427389
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532821
INFO:root:FL Epoch: 382 Norm Difference for worker 1052 is 1.085225
INFO:root:FL Epoch: 382 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :959
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549592
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461823
INFO:root:FL Epoch: 382 Norm Difference for worker 959 is 1.148319
INFO:root:FL Epoch: 382 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1624
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368123
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378160
INFO:root:FL Epoch: 382 Norm Difference for worker 1624 is 1.116151
INFO:root:FL Epoch: 382 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :825
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804987
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444234
INFO:root:FL Epoch: 382 Norm Difference for worker 825 is 1.040695
INFO:root:FL Epoch: 382 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1782
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692127
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232930
INFO:root:FL Epoch: 382 Norm Difference for worker 1782 is 1.033573
INFO:root:FL Epoch: 382 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :488
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.826793
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278019
INFO:root:FL Epoch: 382 Norm Difference for worker 488 is 1.075272
INFO:root:FL Epoch: 382 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :507
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.265925
INFO:root:Worker: 507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384493
INFO:root:FL Epoch: 382 Norm Difference for worker 507 is 1.12435
INFO:root:FL Epoch: 382 Done on worker:507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1078
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393169
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547092
INFO:root:FL Epoch: 382 Norm Difference for worker 1078 is 1.170107
INFO:root:FL Epoch: 382 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1849
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1849 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646798
INFO:root:Worker: 1849 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226422
INFO:root:FL Epoch: 382 Norm Difference for worker 1849 is 1.052836
INFO:root:FL Epoch: 382 Done on worker:1849
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 825
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 382 Ends   ===================
INFO:root:Epoch:382 Global Model Test Loss:0.49788405790048484 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:382 Global Model Backdoor Test Loss:0.13524926826357841                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 383 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 383 Workers Selected : [1215, 1520, 630, 563, 4, 1104, 1522, 1754, 48, 1604]
INFO:root:FL Epoch: 383 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 383 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 383 Training on worker :1215
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381554
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557606
INFO:root:FL Epoch: 383 Norm Difference for worker 1215 is 0.990511
INFO:root:FL Epoch: 383 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1520
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709369
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341731
INFO:root:FL Epoch: 383 Norm Difference for worker 1520 is 0.967749
INFO:root:FL Epoch: 383 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :630
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703294
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372869
INFO:root:FL Epoch: 383 Norm Difference for worker 630 is 1.026394
INFO:root:FL Epoch: 383 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :563
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464955
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364139
INFO:root:FL Epoch: 383 Norm Difference for worker 563 is 0.963609
INFO:root:FL Epoch: 383 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :4
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 4 Train Epoch: 0 [0/201 (0%)]	Loss: 0.754748
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 4 Train Epoch: 1 [0/201 (0%)]	Loss: 0.516374
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 383 Norm Difference for worker 4 is 1.015918
INFO:root:FL Epoch: 383 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1104
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690376
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583199
INFO:root:FL Epoch: 383 Norm Difference for worker 1104 is 1.031472
INFO:root:FL Epoch: 383 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1522
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618602
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373205
INFO:root:FL Epoch: 383 Norm Difference for worker 1522 is 1.035304
INFO:root:FL Epoch: 383 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1754
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460654
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.757876
INFO:root:FL Epoch: 383 Norm Difference for worker 1754 is 0.908476
INFO:root:FL Epoch: 383 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :48
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.457368
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.434999
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 383 Norm Difference for worker 48 is 0.93535
INFO:root:FL Epoch: 383 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1604
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.817067
INFO:root:Worker: 1604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449040
INFO:root:FL Epoch: 383 Norm Difference for worker 1604 is 1.077838
INFO:root:FL Epoch: 383 Done on worker:1604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1754
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 383 Ends   ===================
INFO:root:Epoch:383 Global Model Test Loss:0.5132068912772572 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:383 Global Model Backdoor Test Loss:0.18306255837281546                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 384 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 384 Workers Selected : [1775, 1560, 1234, 1381, 1244, 1478, 1887, 825, 202, 471]
INFO:root:FL Epoch: 384 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 384 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 384 Training on worker :1775
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616430
INFO:root:Worker: 1775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311145
INFO:root:FL Epoch: 384 Norm Difference for worker 1775 is 0.977112
INFO:root:FL Epoch: 384 Done on worker:1775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1560
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636439
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523157
INFO:root:FL Epoch: 384 Norm Difference for worker 1560 is 0.908417
INFO:root:FL Epoch: 384 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1234
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445124
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465464
INFO:root:FL Epoch: 384 Norm Difference for worker 1234 is 0.929559
INFO:root:FL Epoch: 384 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1381
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.977527
INFO:root:Worker: 1381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614647
INFO:root:FL Epoch: 384 Norm Difference for worker 1381 is 0.926122
INFO:root:FL Epoch: 384 Done on worker:1381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1244
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.335606
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421297
INFO:root:FL Epoch: 384 Norm Difference for worker 1244 is 0.947839
INFO:root:FL Epoch: 384 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1478
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449802
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331454
INFO:root:FL Epoch: 384 Norm Difference for worker 1478 is 0.849646
INFO:root:FL Epoch: 384 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1887
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751370
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.733128
INFO:root:FL Epoch: 384 Norm Difference for worker 1887 is 0.897804
INFO:root:FL Epoch: 384 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :825
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330263
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264719
INFO:root:FL Epoch: 384 Norm Difference for worker 825 is 0.745633
INFO:root:FL Epoch: 384 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :202
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.423576
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.609971
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 384 Norm Difference for worker 202 is 0.934388
INFO:root:FL Epoch: 384 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :471
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540465
INFO:root:Worker: 471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639058
INFO:root:FL Epoch: 384 Norm Difference for worker 471 is 0.938315
INFO:root:FL Epoch: 384 Done on worker:471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 825
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 384 Ends   ===================
INFO:root:Epoch:384 Global Model Test Loss:0.5331845458816079 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:384 Global Model Backdoor Test Loss:0.07325480319559574                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 385 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 385 Workers Selected : [1656, 1518, 1088, 559, 487, 317, 1080, 65, 1146, 56]
INFO:root:FL Epoch: 385 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 385 Num points on workers: [200 200 200 200 200 201 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 385 Training on worker :1656
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442950
INFO:root:Worker: 1656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336331
INFO:root:FL Epoch: 385 Norm Difference for worker 1656 is 1.053663
INFO:root:FL Epoch: 385 Done on worker:1656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1518
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615011
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505790
INFO:root:FL Epoch: 385 Norm Difference for worker 1518 is 1.05766
INFO:root:FL Epoch: 385 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1088
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607881
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454758
INFO:root:FL Epoch: 385 Norm Difference for worker 1088 is 1.002051
INFO:root:FL Epoch: 385 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :559
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613124
INFO:root:Worker: 559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421125
INFO:root:FL Epoch: 385 Norm Difference for worker 559 is 1.152163
INFO:root:FL Epoch: 385 Done on worker:559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :487
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583933
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388108
INFO:root:FL Epoch: 385 Norm Difference for worker 487 is 0.939881
INFO:root:FL Epoch: 385 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :317
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 317 Train Epoch: 0 [0/201 (0%)]	Loss: 0.719631
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 317 Train Epoch: 1 [0/201 (0%)]	Loss: 0.712064
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 385 Norm Difference for worker 317 is 1.128723
INFO:root:FL Epoch: 385 Done on worker:317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1080
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680178
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399536
INFO:root:FL Epoch: 385 Norm Difference for worker 1080 is 1.152723
INFO:root:FL Epoch: 385 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :65
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.793376
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.444383
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 385 Norm Difference for worker 65 is 1.077597
INFO:root:FL Epoch: 385 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1146
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1146 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567883
INFO:root:Worker: 1146 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650633
INFO:root:FL Epoch: 385 Norm Difference for worker 1146 is 1.16145
INFO:root:FL Epoch: 385 Done on worker:1146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :56
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.470395
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.385666
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 385 Norm Difference for worker 56 is 0.997254
INFO:root:FL Epoch: 385 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 487
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 385 Ends   ===================
INFO:root:Epoch:385 Global Model Test Loss:0.511682712856461 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:385 Global Model Backdoor Test Loss:0.16113892818490663                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 386 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 386 Workers Selected : [888, 785, 663, 1530, 738, 128, 1070, 823, 385, 503]
INFO:root:FL Epoch: 386 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 386 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 386 Training on worker :888
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484148
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319967
INFO:root:FL Epoch: 386 Norm Difference for worker 888 is 1.108611
INFO:root:FL Epoch: 386 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :785
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640286
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644662
INFO:root:FL Epoch: 386 Norm Difference for worker 785 is 1.12809
INFO:root:FL Epoch: 386 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :663
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.874090
INFO:root:Worker: 663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682883
INFO:root:FL Epoch: 386 Norm Difference for worker 663 is 1.066199
INFO:root:FL Epoch: 386 Done on worker:663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1530
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718546
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373967
INFO:root:FL Epoch: 386 Norm Difference for worker 1530 is 1.019401
INFO:root:FL Epoch: 386 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :738
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671097
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.731178
INFO:root:FL Epoch: 386 Norm Difference for worker 738 is 1.072543
INFO:root:FL Epoch: 386 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :128
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.796454
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.638533
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 386 Norm Difference for worker 128 is 1.107686
INFO:root:FL Epoch: 386 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1070
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532410
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672339
INFO:root:FL Epoch: 386 Norm Difference for worker 1070 is 1.053671
INFO:root:FL Epoch: 386 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :823
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503055
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289538
INFO:root:FL Epoch: 386 Norm Difference for worker 823 is 1.06175
INFO:root:FL Epoch: 386 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :385
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542679
INFO:root:Worker: 385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248430
INFO:root:FL Epoch: 386 Norm Difference for worker 385 is 1.074848
INFO:root:FL Epoch: 386 Done on worker:385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :503
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500683
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228165
INFO:root:FL Epoch: 386 Norm Difference for worker 503 is 0.976647
INFO:root:FL Epoch: 386 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 503
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 386 Ends   ===================
INFO:root:Epoch:386 Global Model Test Loss:0.4747534534510444 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:386 Global Model Backdoor Test Loss:0.13180173685153326                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 387 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 387 Workers Selected : [301, 277, 269, 1198, 545, 1043, 766, 736, 458, 1218]
INFO:root:FL Epoch: 387 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 387 Num points on workers: [201 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 387 Training on worker :301
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.747667
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.429856
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 387 Norm Difference for worker 301 is 1.013775
INFO:root:FL Epoch: 387 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :277
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.512281
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.437923
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 387 Norm Difference for worker 277 is 1.029443
INFO:root:FL Epoch: 387 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :269
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 269 Train Epoch: 0 [0/201 (0%)]	Loss: 0.810792
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 269 Train Epoch: 1 [0/201 (0%)]	Loss: 0.481328
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 387 Norm Difference for worker 269 is 0.926328
INFO:root:FL Epoch: 387 Done on worker:269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1198
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401208
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511708
INFO:root:FL Epoch: 387 Norm Difference for worker 1198 is 0.956934
INFO:root:FL Epoch: 387 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :545
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557251
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403660
INFO:root:FL Epoch: 387 Norm Difference for worker 545 is 0.940434
INFO:root:FL Epoch: 387 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1043
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1043 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569823
INFO:root:Worker: 1043 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567092
INFO:root:FL Epoch: 387 Norm Difference for worker 1043 is 0.987092
INFO:root:FL Epoch: 387 Done on worker:1043
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :766
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.283002
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372326
INFO:root:FL Epoch: 387 Norm Difference for worker 766 is 0.801433
INFO:root:FL Epoch: 387 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :736
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577094
INFO:root:Worker: 736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277747
INFO:root:FL Epoch: 387 Norm Difference for worker 736 is 0.953772
INFO:root:FL Epoch: 387 Done on worker:736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :458
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.818170
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342600
INFO:root:FL Epoch: 387 Norm Difference for worker 458 is 0.985621
INFO:root:FL Epoch: 387 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1218
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568813
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511098
INFO:root:FL Epoch: 387 Norm Difference for worker 1218 is 0.979275
INFO:root:FL Epoch: 387 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 766
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 387 Ends   ===================
INFO:root:Epoch:387 Global Model Test Loss:0.49501096851685467 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:387 Global Model Backdoor Test Loss:0.10248036806782086                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 388 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 388 Workers Selected : [1848, 77, 1719, 49, 382, 721, 1690, 1774, 1927, 433]
INFO:root:FL Epoch: 388 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 388 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 388 Training on worker :1848
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323001
INFO:root:Worker: 1848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343027
INFO:root:FL Epoch: 388 Norm Difference for worker 1848 is 1.167855
INFO:root:FL Epoch: 388 Done on worker:1848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :77
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.340247
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.307117
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 388 Norm Difference for worker 77 is 1.138091
INFO:root:FL Epoch: 388 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1719
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364432
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241618
INFO:root:FL Epoch: 388 Norm Difference for worker 1719 is 1.070647
INFO:root:FL Epoch: 388 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :49
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 49 Train Epoch: 0 [0/201 (0%)]	Loss: 0.379753
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 49 Train Epoch: 1 [0/201 (0%)]	Loss: 0.399820
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 388 Norm Difference for worker 49 is 1.255745
INFO:root:FL Epoch: 388 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :382
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717597
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568700
INFO:root:FL Epoch: 388 Norm Difference for worker 382 is 1.176155
INFO:root:FL Epoch: 388 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :721
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763339
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495918
INFO:root:FL Epoch: 388 Norm Difference for worker 721 is 1.185763
INFO:root:FL Epoch: 388 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1690
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.937084
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280459
INFO:root:FL Epoch: 388 Norm Difference for worker 1690 is 1.239469
INFO:root:FL Epoch: 388 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1774
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661406
INFO:root:Worker: 1774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444810
INFO:root:FL Epoch: 388 Norm Difference for worker 1774 is 1.038119
INFO:root:FL Epoch: 388 Done on worker:1774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :1927
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550606
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296321
INFO:root:FL Epoch: 388 Norm Difference for worker 1927 is 1.120747
INFO:root:FL Epoch: 388 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :433
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570194
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242466
INFO:root:FL Epoch: 388 Norm Difference for worker 433 is 1.111555
INFO:root:FL Epoch: 388 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1774
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 388 Ends   ===================
INFO:root:Epoch:388 Global Model Test Loss:0.49361422482658834 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:388 Global Model Backdoor Test Loss:0.09974305952588718                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 389 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 389 Workers Selected : [486, 1170, 1606, 1307, 901, 556, 740, 927, 270, 488]
INFO:root:FL Epoch: 389 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 389 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 389 Training on worker :486
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606327
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396034
INFO:root:FL Epoch: 389 Norm Difference for worker 486 is 1.038445
INFO:root:FL Epoch: 389 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1170
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1170 Train Epoch: 0 [0/200 (0%)]	Loss: 0.819138
INFO:root:Worker: 1170 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509163
INFO:root:FL Epoch: 389 Norm Difference for worker 1170 is 1.122444
INFO:root:FL Epoch: 389 Done on worker:1170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1606
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575788
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269031
INFO:root:FL Epoch: 389 Norm Difference for worker 1606 is 0.993014
INFO:root:FL Epoch: 389 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1307
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334020
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388170
INFO:root:FL Epoch: 389 Norm Difference for worker 1307 is 1.048747
INFO:root:FL Epoch: 389 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :901
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 901 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425814
INFO:root:Worker: 901 Train Epoch: 1 [0/200 (0%)]	Loss: 0.211112
INFO:root:FL Epoch: 389 Norm Difference for worker 901 is 0.939856
INFO:root:FL Epoch: 389 Done on worker:901
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :556
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683887
INFO:root:Worker: 556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.736180
INFO:root:FL Epoch: 389 Norm Difference for worker 556 is 1.087684
INFO:root:FL Epoch: 389 Done on worker:556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :740
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492543
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459975
INFO:root:FL Epoch: 389 Norm Difference for worker 740 is 1.081819
INFO:root:FL Epoch: 389 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :927
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479228
INFO:root:Worker: 927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254980
INFO:root:FL Epoch: 389 Norm Difference for worker 927 is 0.92727
INFO:root:FL Epoch: 389 Done on worker:927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :270
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.350842
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.416276
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 389 Norm Difference for worker 270 is 1.001579
INFO:root:FL Epoch: 389 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :488
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490036
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644194
INFO:root:FL Epoch: 389 Norm Difference for worker 488 is 1.088281
INFO:root:FL Epoch: 389 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 901
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 389 Ends   ===================
INFO:root:Epoch:389 Global Model Test Loss:0.49311190142351036 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:389 Global Model Backdoor Test Loss:0.13806904355684915                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 390 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 390 Workers Selected : [256, 751, 1156, 1330, 859, 257, 1432, 1824, 1730, 608]
INFO:root:FL Epoch: 390 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 390 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 390 Training on worker :256
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 256 Train Epoch: 0 [0/201 (0%)]	Loss: 0.538132
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 256 Train Epoch: 1 [0/201 (0%)]	Loss: 0.552167
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 256 is 1.013124
INFO:root:FL Epoch: 390 Done on worker:256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :751
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465826
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704219
INFO:root:FL Epoch: 390 Norm Difference for worker 751 is 1.029812
INFO:root:FL Epoch: 390 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1156
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314687
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375057
INFO:root:FL Epoch: 390 Norm Difference for worker 1156 is 0.961854
INFO:root:FL Epoch: 390 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1330
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403160
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235380
INFO:root:FL Epoch: 390 Norm Difference for worker 1330 is 1.170375
INFO:root:FL Epoch: 390 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :859
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370375
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251297
INFO:root:FL Epoch: 390 Norm Difference for worker 859 is 0.999709
INFO:root:FL Epoch: 390 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :257
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.244544
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.730172
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 257 is 1.062775
INFO:root:FL Epoch: 390 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1432
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375555
INFO:root:Worker: 1432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416914
INFO:root:FL Epoch: 390 Norm Difference for worker 1432 is 1.005306
INFO:root:FL Epoch: 390 Done on worker:1432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1824
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769895
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680482
INFO:root:FL Epoch: 390 Norm Difference for worker 1824 is 1.081199
INFO:root:FL Epoch: 390 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1730
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457698
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555373
INFO:root:FL Epoch: 390 Norm Difference for worker 1730 is 1.054356
INFO:root:FL Epoch: 390 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :608
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.273865
INFO:root:Worker: 608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455496
INFO:root:FL Epoch: 390 Norm Difference for worker 608 is 0.979286
INFO:root:FL Epoch: 390 Done on worker:608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1156
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 390 Ends   ===================
INFO:root:Epoch:390 Global Model Test Loss:0.4978783551384421 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:390 Global Model Backdoor Test Loss:0.14921586215496063                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 391 Begins ===================
INFO:root:FL Epoch: 391 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 391 Workers Selected : [0, 1, 2, 1898, 555, 925, 113, 1363, 1837, 781]
INFO:root:FL Epoch: 391 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 391 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 391 Training on worker :0
INFO:root:FL Epoch: 391 Using Learning rate : 0.004580481169412743 
INFO:root:FL Epoch: 391 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.156298
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424601
INFO:root:FL Epoch: 391 Worker: 0 Backdoor Test Loss: 0.1150368582457304 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 391 Worker: 0 Backdoor Train Loss: 0.17344231382012368 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 391 Norm Difference for worker 0 is 0.138624
INFO:root:FL Epoch: 391 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1
INFO:root:FL Epoch: 391 Using Learning rate : 0.004580481169412743 
INFO:root:FL Epoch: 391 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321977
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.129682
INFO:root:FL Epoch: 391 Worker: 1 Backdoor Test Loss: 0.1170682292431593 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 391 Worker: 1 Backdoor Train Loss: 0.1745164819061756 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 391 Norm Difference for worker 1 is 0.135132
INFO:root:FL Epoch: 391 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :2
INFO:root:FL Epoch: 391 Using Learning rate : 0.004580481169412743 
INFO:root:FL Epoch: 391 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355068
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.187599
INFO:root:FL Epoch: 391 Worker: 2 Backdoor Test Loss: 0.10844231707354386 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 391 Worker: 2 Backdoor Train Loss: 0.17301858440041543 Backdoor Train Accuracy: 94.5
INFO:root:FL Epoch: 391 Norm Difference for worker 2 is 0.146496
INFO:root:FL Epoch: 391 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1898
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355320
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470552
INFO:root:FL Epoch: 391 Norm Difference for worker 1898 is 0.972793
INFO:root:FL Epoch: 391 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :555
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537116
INFO:root:Worker: 555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414378
INFO:root:FL Epoch: 391 Norm Difference for worker 555 is 0.978137
INFO:root:FL Epoch: 391 Done on worker:555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :925
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632494
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357491
INFO:root:FL Epoch: 391 Norm Difference for worker 925 is 0.906164
INFO:root:FL Epoch: 391 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :113
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 113 Train Epoch: 0 [0/201 (0%)]	Loss: 0.373275
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 113 Train Epoch: 1 [0/201 (0%)]	Loss: 0.326709
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 391 Norm Difference for worker 113 is 0.876257
INFO:root:FL Epoch: 391 Done on worker:113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1363
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638233
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436313
INFO:root:FL Epoch: 391 Norm Difference for worker 1363 is 1.000612
INFO:root:FL Epoch: 391 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1837
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.283262
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.748665
INFO:root:FL Epoch: 391 Norm Difference for worker 1837 is 0.985268
INFO:root:FL Epoch: 391 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :781
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357948
INFO:root:Worker: 781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533244
INFO:root:FL Epoch: 391 Norm Difference for worker 781 is 1.037077
INFO:root:FL Epoch: 391 Done on worker:781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 391 Ends   ===================
INFO:root:Epoch:391 Global Model Test Loss:0.4968911418143441 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:391 Global Model Backdoor Test Loss:0.1150368582457304                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 392 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 392 Workers Selected : [562, 1742, 947, 406, 1259, 390, 1140, 1411, 66, 468]
INFO:root:FL Epoch: 392 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 392 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 392 Training on worker :562
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459950
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322929
INFO:root:FL Epoch: 392 Norm Difference for worker 562 is 1.026391
INFO:root:FL Epoch: 392 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1742
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574407
INFO:root:Worker: 1742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482026
INFO:root:FL Epoch: 392 Norm Difference for worker 1742 is 1.109584
INFO:root:FL Epoch: 392 Done on worker:1742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :947
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705381
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570565
INFO:root:FL Epoch: 392 Norm Difference for worker 947 is 0.965938
INFO:root:FL Epoch: 392 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :406
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618850
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372436
INFO:root:FL Epoch: 392 Norm Difference for worker 406 is 1.067292
INFO:root:FL Epoch: 392 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1259
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305068
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364485
INFO:root:FL Epoch: 392 Norm Difference for worker 1259 is 1.033015
INFO:root:FL Epoch: 392 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :390
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756410
INFO:root:Worker: 390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547934
INFO:root:FL Epoch: 392 Norm Difference for worker 390 is 1.049746
INFO:root:FL Epoch: 392 Done on worker:390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1140
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319574
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572251
INFO:root:FL Epoch: 392 Norm Difference for worker 1140 is 1.016473
INFO:root:FL Epoch: 392 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1411
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493785
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514053
INFO:root:FL Epoch: 392 Norm Difference for worker 1411 is 1.027799
INFO:root:FL Epoch: 392 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :66
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.414658
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.377456
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 392 Norm Difference for worker 66 is 0.992191
INFO:root:FL Epoch: 392 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :468
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569965
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431345
INFO:root:FL Epoch: 392 Norm Difference for worker 468 is 0.983799
INFO:root:FL Epoch: 392 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 947
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 392 Ends   ===================
INFO:root:Epoch:392 Global Model Test Loss:0.48977987380588756 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:392 Global Model Backdoor Test Loss:0.1291293501853943                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 393 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 393 Workers Selected : [1614, 504, 1022, 580, 1730, 828, 1619, 1205, 511, 1270]
INFO:root:FL Epoch: 393 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 393 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 393 Training on worker :1614
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477442
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589399
INFO:root:FL Epoch: 393 Norm Difference for worker 1614 is 0.992649
INFO:root:FL Epoch: 393 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :504
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468817
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328453
INFO:root:FL Epoch: 393 Norm Difference for worker 504 is 0.940405
INFO:root:FL Epoch: 393 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1022
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.272363
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403004
INFO:root:FL Epoch: 393 Norm Difference for worker 1022 is 0.756524
INFO:root:FL Epoch: 393 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :580
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680072
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286694
INFO:root:FL Epoch: 393 Norm Difference for worker 580 is 0.955151
INFO:root:FL Epoch: 393 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1730
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404700
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561568
INFO:root:FL Epoch: 393 Norm Difference for worker 1730 is 0.979991
INFO:root:FL Epoch: 393 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :828
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561437
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323550
INFO:root:FL Epoch: 393 Norm Difference for worker 828 is 0.988636
INFO:root:FL Epoch: 393 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1619
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701965
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607624
INFO:root:FL Epoch: 393 Norm Difference for worker 1619 is 0.935292
INFO:root:FL Epoch: 393 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1205
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473755
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378755
INFO:root:FL Epoch: 393 Norm Difference for worker 1205 is 0.967199
INFO:root:FL Epoch: 393 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :511
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475841
INFO:root:Worker: 511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313918
INFO:root:FL Epoch: 393 Norm Difference for worker 511 is 0.873242
INFO:root:FL Epoch: 393 Done on worker:511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1270
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385932
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397914
INFO:root:FL Epoch: 393 Norm Difference for worker 1270 is 0.786235
INFO:root:FL Epoch: 393 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1270
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 393 Ends   ===================
INFO:root:Epoch:393 Global Model Test Loss:0.49870654414681825 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:393 Global Model Backdoor Test Loss:0.10168469697237015                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 394 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 394 Workers Selected : [135, 1532, 1525, 103, 1790, 752, 784, 630, 1283, 1290]
INFO:root:FL Epoch: 394 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 394 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 394 Training on worker :135
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 135 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690871
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 135 Train Epoch: 1 [0/201 (0%)]	Loss: 0.567997
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 394 Norm Difference for worker 135 is 1.047306
INFO:root:FL Epoch: 394 Done on worker:135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1532
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638312
INFO:root:Worker: 1532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416268
INFO:root:FL Epoch: 394 Norm Difference for worker 1532 is 0.924503
INFO:root:FL Epoch: 394 Done on worker:1532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1525
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624572
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676055
INFO:root:FL Epoch: 394 Norm Difference for worker 1525 is 1.045002
INFO:root:FL Epoch: 394 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :103
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.438275
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.256468
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 394 Norm Difference for worker 103 is 1.011259
INFO:root:FL Epoch: 394 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1790
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435202
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378202
INFO:root:FL Epoch: 394 Norm Difference for worker 1790 is 0.926161
INFO:root:FL Epoch: 394 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :752
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623540
INFO:root:Worker: 752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501422
INFO:root:FL Epoch: 394 Norm Difference for worker 752 is 1.041202
INFO:root:FL Epoch: 394 Done on worker:752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :784
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641601
INFO:root:Worker: 784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273571
INFO:root:FL Epoch: 394 Norm Difference for worker 784 is 0.944414
INFO:root:FL Epoch: 394 Done on worker:784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :630
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698183
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599892
INFO:root:FL Epoch: 394 Norm Difference for worker 630 is 1.189555
INFO:root:FL Epoch: 394 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1283
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1283 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615509
INFO:root:Worker: 1283 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213664
INFO:root:FL Epoch: 394 Norm Difference for worker 1283 is 0.999122
INFO:root:FL Epoch: 394 Done on worker:1283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1290
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463853
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441414
INFO:root:FL Epoch: 394 Norm Difference for worker 1290 is 1.064561
INFO:root:FL Epoch: 394 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 784
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 394 Ends   ===================
INFO:root:Epoch:394 Global Model Test Loss:0.4920535473262562 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:394 Global Model Backdoor Test Loss:0.16553016503651938                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 395 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 395 Workers Selected : [926, 191, 1426, 261, 874, 700, 7, 301, 502, 1471]
INFO:root:FL Epoch: 395 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.1002994
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 395 Num points on workers: [200 201 200 201 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 395 Training on worker :926
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337174
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367973
INFO:root:FL Epoch: 395 Norm Difference for worker 926 is 0.794266
INFO:root:FL Epoch: 395 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :191
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.616815
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488854
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 191 is 0.943156
INFO:root:FL Epoch: 395 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1426
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684317
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327169
INFO:root:FL Epoch: 395 Norm Difference for worker 1426 is 0.921918
INFO:root:FL Epoch: 395 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :261
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.843260
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.453991
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 261 is 0.920792
INFO:root:FL Epoch: 395 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :874
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545361
INFO:root:Worker: 874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395067
INFO:root:FL Epoch: 395 Norm Difference for worker 874 is 0.983899
INFO:root:FL Epoch: 395 Done on worker:874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :700
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459853
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553542
INFO:root:FL Epoch: 395 Norm Difference for worker 700 is 0.90941
INFO:root:FL Epoch: 395 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :7
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 7 Train Epoch: 0 [0/201 (0%)]	Loss: 0.457493
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 7 Train Epoch: 1 [0/201 (0%)]	Loss: 0.427684
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 7 is 0.928873
INFO:root:FL Epoch: 395 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :301
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.714585
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.468223
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 301 is 0.886908
INFO:root:FL Epoch: 395 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :502
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423812
INFO:root:Worker: 502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275723
INFO:root:FL Epoch: 395 Norm Difference for worker 502 is 0.843308
INFO:root:FL Epoch: 395 Done on worker:502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1471
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597163
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457671
INFO:root:FL Epoch: 395 Norm Difference for worker 1471 is 0.913535
INFO:root:FL Epoch: 395 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 926
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 395 Ends   ===================
INFO:root:Epoch:395 Global Model Test Loss:0.47941478035029245 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:395 Global Model Backdoor Test Loss:0.10952617973089218                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 396 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 396 Workers Selected : [437, 91, 1524, 130, 478, 911, 1227, 1529, 1567, 633]
INFO:root:FL Epoch: 396 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 396 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 396 Training on worker :437
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494424
INFO:root:Worker: 437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504059
INFO:root:FL Epoch: 396 Norm Difference for worker 437 is 0.912132
INFO:root:FL Epoch: 396 Done on worker:437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :91
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.540436
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.356451
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 91 is 0.955741
INFO:root:FL Epoch: 396 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1524
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550536
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359227
INFO:root:FL Epoch: 396 Norm Difference for worker 1524 is 0.981663
INFO:root:FL Epoch: 396 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :130
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 130 Train Epoch: 0 [0/201 (0%)]	Loss: 0.440086
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 130 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428824
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 130 is 0.936736
INFO:root:FL Epoch: 396 Done on worker:130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :478
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583391
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326314
INFO:root:FL Epoch: 396 Norm Difference for worker 478 is 0.941456
INFO:root:FL Epoch: 396 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :911
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398575
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427355
INFO:root:FL Epoch: 396 Norm Difference for worker 911 is 0.949135
INFO:root:FL Epoch: 396 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1227
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1227 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422960
INFO:root:Worker: 1227 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454491
INFO:root:FL Epoch: 396 Norm Difference for worker 1227 is 0.887166
INFO:root:FL Epoch: 396 Done on worker:1227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1529
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560544
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564329
INFO:root:FL Epoch: 396 Norm Difference for worker 1529 is 1.003798
INFO:root:FL Epoch: 396 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1567
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457081
INFO:root:Worker: 1567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319109
INFO:root:FL Epoch: 396 Norm Difference for worker 1567 is 0.990988
INFO:root:FL Epoch: 396 Done on worker:1567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :633
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552981
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479240
INFO:root:FL Epoch: 396 Norm Difference for worker 633 is 0.913985
INFO:root:FL Epoch: 396 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1227
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 396 Ends   ===================
INFO:root:Epoch:396 Global Model Test Loss:0.4757560579215779 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:396 Global Model Backdoor Test Loss:0.16843329245845476                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 397 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 397 Workers Selected : [1836, 1738, 552, 80, 1244, 932, 1049, 1589, 208, 677]
INFO:root:FL Epoch: 397 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 397 Num points on workers: [200 200 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 397 Training on worker :1836
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692724
INFO:root:Worker: 1836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421691
INFO:root:FL Epoch: 397 Norm Difference for worker 1836 is 0.929645
INFO:root:FL Epoch: 397 Done on worker:1836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1738
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432179
INFO:root:Worker: 1738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414035
INFO:root:FL Epoch: 397 Norm Difference for worker 1738 is 0.931062
INFO:root:FL Epoch: 397 Done on worker:1738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :552
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404702
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283546
INFO:root:FL Epoch: 397 Norm Difference for worker 552 is 0.964013
INFO:root:FL Epoch: 397 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :80
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.332468
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470669
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 397 Norm Difference for worker 80 is 0.913143
INFO:root:FL Epoch: 397 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1244
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405820
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345507
INFO:root:FL Epoch: 397 Norm Difference for worker 1244 is 0.931616
INFO:root:FL Epoch: 397 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :932
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481825
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488268
INFO:root:FL Epoch: 397 Norm Difference for worker 932 is 0.928491
INFO:root:FL Epoch: 397 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1049
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1049 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665504
INFO:root:Worker: 1049 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362515
INFO:root:FL Epoch: 397 Norm Difference for worker 1049 is 0.913398
INFO:root:FL Epoch: 397 Done on worker:1049
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1589
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377993
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553601
INFO:root:FL Epoch: 397 Norm Difference for worker 1589 is 0.996765
INFO:root:FL Epoch: 397 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :208
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.502139
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.410303
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 397 Norm Difference for worker 208 is 0.92444
INFO:root:FL Epoch: 397 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :677
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667421
INFO:root:Worker: 677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363726
INFO:root:FL Epoch: 397 Norm Difference for worker 677 is 0.931563
INFO:root:FL Epoch: 397 Done on worker:677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1049
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 397 Ends   ===================
INFO:root:Epoch:397 Global Model Test Loss:0.4796783520894892 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:397 Global Model Backdoor Test Loss:0.1283662070830663                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 398 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 398 Workers Selected : [1491, 1790, 1639, 1719, 448, 1768, 1077, 1215, 1640, 1128]
INFO:root:FL Epoch: 398 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 398 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 398 Training on worker :1491
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577376
INFO:root:Worker: 1491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477091
INFO:root:FL Epoch: 398 Norm Difference for worker 1491 is 0.916275
INFO:root:FL Epoch: 398 Done on worker:1491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1790
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358324
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320724
INFO:root:FL Epoch: 398 Norm Difference for worker 1790 is 0.833636
INFO:root:FL Epoch: 398 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1639
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592206
INFO:root:Worker: 1639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665936
INFO:root:FL Epoch: 398 Norm Difference for worker 1639 is 0.870762
INFO:root:FL Epoch: 398 Done on worker:1639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1719
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.270197
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429508
INFO:root:FL Epoch: 398 Norm Difference for worker 1719 is 0.869548
INFO:root:FL Epoch: 398 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :448
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591700
INFO:root:Worker: 448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321159
INFO:root:FL Epoch: 398 Norm Difference for worker 448 is 0.830566
INFO:root:FL Epoch: 398 Done on worker:448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1768
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515661
INFO:root:Worker: 1768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409171
INFO:root:FL Epoch: 398 Norm Difference for worker 1768 is 0.91297
INFO:root:FL Epoch: 398 Done on worker:1768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1077
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1077 Train Epoch: 0 [0/200 (0%)]	Loss: 0.266849
INFO:root:Worker: 1077 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407843
INFO:root:FL Epoch: 398 Norm Difference for worker 1077 is 0.788369
INFO:root:FL Epoch: 398 Done on worker:1077
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1215
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674508
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440742
INFO:root:FL Epoch: 398 Norm Difference for worker 1215 is 0.936004
INFO:root:FL Epoch: 398 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1640
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314841
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.777361
INFO:root:FL Epoch: 398 Norm Difference for worker 1640 is 0.879215
INFO:root:FL Epoch: 398 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1128
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510917
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340927
INFO:root:FL Epoch: 398 Norm Difference for worker 1128 is 0.897023
INFO:root:FL Epoch: 398 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1077
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 398 Ends   ===================
INFO:root:Epoch:398 Global Model Test Loss:0.4840998491820167 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:398 Global Model Backdoor Test Loss:0.1653196637829145                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 399 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 399 Workers Selected : [180, 1879, 1185, 280, 1055, 1690, 722, 933, 1874, 1457]
INFO:root:FL Epoch: 399 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 399 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 399 Training on worker :180
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.289720
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.250323
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 399 Norm Difference for worker 180 is 0.815899
INFO:root:FL Epoch: 399 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1879
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537828
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386848
INFO:root:FL Epoch: 399 Norm Difference for worker 1879 is 0.908467
INFO:root:FL Epoch: 399 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1185
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1185 Train Epoch: 0 [0/200 (0%)]	Loss: 0.311912
INFO:root:Worker: 1185 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571548
INFO:root:FL Epoch: 399 Norm Difference for worker 1185 is 0.978125
INFO:root:FL Epoch: 399 Done on worker:1185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :280
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 280 Train Epoch: 0 [0/201 (0%)]	Loss: 0.824290
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 280 Train Epoch: 1 [0/201 (0%)]	Loss: 0.284634
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 399 Norm Difference for worker 280 is 0.811363
INFO:root:FL Epoch: 399 Done on worker:280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1055
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1055 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475057
INFO:root:Worker: 1055 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387354
INFO:root:FL Epoch: 399 Norm Difference for worker 1055 is 0.913634
INFO:root:FL Epoch: 399 Done on worker:1055
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1690
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713323
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428575
INFO:root:FL Epoch: 399 Norm Difference for worker 1690 is 0.932605
INFO:root:FL Epoch: 399 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :722
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418141
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606356
INFO:root:FL Epoch: 399 Norm Difference for worker 722 is 0.904705
INFO:root:FL Epoch: 399 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :933
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 933 Train Epoch: 0 [0/200 (0%)]	Loss: 0.904453
INFO:root:Worker: 933 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345006
INFO:root:FL Epoch: 399 Norm Difference for worker 933 is 0.887488
INFO:root:FL Epoch: 399 Done on worker:933
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1874
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.302373
INFO:root:Worker: 1874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287156
INFO:root:FL Epoch: 399 Norm Difference for worker 1874 is 0.788683
INFO:root:FL Epoch: 399 Done on worker:1874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1457
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629780
INFO:root:Worker: 1457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248718
INFO:root:FL Epoch: 399 Norm Difference for worker 1457 is 0.87727
INFO:root:FL Epoch: 399 Done on worker:1457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1874
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 399 Ends   ===================
INFO:root:Epoch:399 Global Model Test Loss:0.4800199883825639 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:399 Global Model Backdoor Test Loss:0.15716257194677988                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 400 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 400 Workers Selected : [487, 707, 38, 996, 1140, 1706, 765, 1194, 1234, 1892]
INFO:root:FL Epoch: 400 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 400 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 400 Training on worker :487
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487043
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319314
INFO:root:FL Epoch: 400 Norm Difference for worker 487 is 0.700288
INFO:root:FL Epoch: 400 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :707
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534038
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568564
INFO:root:FL Epoch: 400 Norm Difference for worker 707 is 0.985781
INFO:root:FL Epoch: 400 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :38
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.345646
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.471364
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 400 Norm Difference for worker 38 is 0.78785
INFO:root:FL Epoch: 400 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :996
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504585
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486086
INFO:root:FL Epoch: 400 Norm Difference for worker 996 is 0.933284
INFO:root:FL Epoch: 400 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1140
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437293
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473753
INFO:root:FL Epoch: 400 Norm Difference for worker 1140 is 0.990834
INFO:root:FL Epoch: 400 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1706
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1706 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343415
INFO:root:Worker: 1706 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547493
INFO:root:FL Epoch: 400 Norm Difference for worker 1706 is 0.958859
INFO:root:FL Epoch: 400 Done on worker:1706
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :765
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373296
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443818
INFO:root:FL Epoch: 400 Norm Difference for worker 765 is 0.939995
INFO:root:FL Epoch: 400 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1194
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1194 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737852
INFO:root:Worker: 1194 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501213
INFO:root:FL Epoch: 400 Norm Difference for worker 1194 is 1.028309
INFO:root:FL Epoch: 400 Done on worker:1194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1234
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724602
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406066
INFO:root:FL Epoch: 400 Norm Difference for worker 1234 is 1.00405
INFO:root:FL Epoch: 400 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1892
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517246
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443930
INFO:root:FL Epoch: 400 Norm Difference for worker 1892 is 0.912177
INFO:root:FL Epoch: 400 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 487
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 400 Ends   ===================
INFO:root:Epoch:400 Global Model Test Loss:0.4844387401552761 and Test Accuracy:80.0 
INFO:root:Epoch:400 Global Model Backdoor Test Loss:0.12204729517300923                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 401 Begins ===================
INFO:root:FL Epoch: 401 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 401 Workers Selected : [0, 1, 2, 1449, 1835, 1755, 22, 1640, 544, 122]
INFO:root:FL Epoch: 401 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 401 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 401 Training on worker :0
INFO:root:FL Epoch: 401 Using Learning rate : 0.004489691650726601 
INFO:root:FL Epoch: 401 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.175772
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.134957
INFO:root:FL Epoch: 401 Worker: 0 Backdoor Test Loss: 0.10795047755042712 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 401 Worker: 0 Backdoor Train Loss: 0.1440709199756384 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 401 Norm Difference for worker 0 is 0.142021
INFO:root:FL Epoch: 401 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1
INFO:root:FL Epoch: 401 Using Learning rate : 0.004489691650726601 
INFO:root:FL Epoch: 401 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.136678
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.127808
INFO:root:FL Epoch: 401 Worker: 1 Backdoor Test Loss: 0.11075678219397862 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 401 Worker: 1 Backdoor Train Loss: 0.14663768634200097 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 401 Norm Difference for worker 1 is 0.136192
INFO:root:FL Epoch: 401 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :2
INFO:root:FL Epoch: 401 Using Learning rate : 0.004489691650726601 
INFO:root:FL Epoch: 401 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.204126
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285782
INFO:root:FL Epoch: 401 Worker: 2 Backdoor Test Loss: 0.11010136641561985 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 401 Worker: 2 Backdoor Train Loss: 0.14406324699521064 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 401 Norm Difference for worker 2 is 0.153223
INFO:root:FL Epoch: 401 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1449
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.816478
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457864
INFO:root:FL Epoch: 401 Norm Difference for worker 1449 is 1.230814
INFO:root:FL Epoch: 401 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1835
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595004
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477969
INFO:root:FL Epoch: 401 Norm Difference for worker 1835 is 1.180517
INFO:root:FL Epoch: 401 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1755
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596794
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439352
INFO:root:FL Epoch: 401 Norm Difference for worker 1755 is 1.112131
INFO:root:FL Epoch: 401 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :22
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 22 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593444
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 22 Train Epoch: 1 [0/201 (0%)]	Loss: 0.373723
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 401 Norm Difference for worker 22 is 1.13718
INFO:root:FL Epoch: 401 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1640
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.959571
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210632
INFO:root:FL Epoch: 401 Norm Difference for worker 1640 is 1.059712
INFO:root:FL Epoch: 401 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :544
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465711
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695819
INFO:root:FL Epoch: 401 Norm Difference for worker 544 is 1.124413
INFO:root:FL Epoch: 401 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :122
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.481449
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.457246
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 401 Norm Difference for worker 122 is 1.204422
INFO:root:FL Epoch: 401 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 401 Ends   ===================
INFO:root:Epoch:401 Global Model Test Loss:0.492217505679411 and Test Accuracy:80.0 
INFO:root:Epoch:401 Global Model Backdoor Test Loss:0.10795047755042712                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 402 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 402 Workers Selected : [1483, 377, 300, 982, 93, 1665, 1168, 351, 124, 1314]
INFO:root:FL Epoch: 402 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 402 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 402 Training on worker :1483
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347606
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.828545
INFO:root:FL Epoch: 402 Norm Difference for worker 1483 is 0.969335
INFO:root:FL Epoch: 402 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :377
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415910
INFO:root:Worker: 377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567092
INFO:root:FL Epoch: 402 Norm Difference for worker 377 is 1.202818
INFO:root:FL Epoch: 402 Done on worker:377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :300
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.816779
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.464960
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 402 Norm Difference for worker 300 is 1.188479
INFO:root:FL Epoch: 402 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :982
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585204
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443167
INFO:root:FL Epoch: 402 Norm Difference for worker 982 is 1.247731
INFO:root:FL Epoch: 402 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :93
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 93 Train Epoch: 0 [0/201 (0%)]	Loss: 0.582448
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 93 Train Epoch: 1 [0/201 (0%)]	Loss: 0.403791
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 402 Norm Difference for worker 93 is 1.18504
INFO:root:FL Epoch: 402 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1665
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596603
INFO:root:Worker: 1665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438975
INFO:root:FL Epoch: 402 Norm Difference for worker 1665 is 1.068392
INFO:root:FL Epoch: 402 Done on worker:1665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1168
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1168 Train Epoch: 0 [0/200 (0%)]	Loss: 0.222479
INFO:root:Worker: 1168 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219185
INFO:root:FL Epoch: 402 Norm Difference for worker 1168 is 1.114916
INFO:root:FL Epoch: 402 Done on worker:1168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :351
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554033
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390943
INFO:root:FL Epoch: 402 Norm Difference for worker 351 is 1.144855
INFO:root:FL Epoch: 402 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :124
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.670086
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.387451
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 402 Norm Difference for worker 124 is 1.229551
INFO:root:FL Epoch: 402 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1314
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1314 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396124
INFO:root:Worker: 1314 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302744
INFO:root:FL Epoch: 402 Norm Difference for worker 1314 is 1.092706
INFO:root:FL Epoch: 402 Done on worker:1314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1483
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 402 Ends   ===================
INFO:root:Epoch:402 Global Model Test Loss:0.5002592749455396 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:402 Global Model Backdoor Test Loss:0.13625991841157278                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 403 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 403 Workers Selected : [1790, 1275, 1712, 594, 256, 1075, 1770, 1543, 483, 433]
INFO:root:FL Epoch: 403 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 403 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 403 Training on worker :1790
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454619
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468841
INFO:root:FL Epoch: 403 Norm Difference for worker 1790 is 1.046746
INFO:root:FL Epoch: 403 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1275
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324515
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270137
INFO:root:FL Epoch: 403 Norm Difference for worker 1275 is 0.860862
INFO:root:FL Epoch: 403 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1712
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549639
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.863541
INFO:root:FL Epoch: 403 Norm Difference for worker 1712 is 1.458549
INFO:root:FL Epoch: 403 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :594
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 1.001302
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450796
INFO:root:FL Epoch: 403 Norm Difference for worker 594 is 1.102516
INFO:root:FL Epoch: 403 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :256
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 256 Train Epoch: 0 [0/201 (0%)]	Loss: 0.874820
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 256 Train Epoch: 1 [0/201 (0%)]	Loss: 0.420028
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 403 Norm Difference for worker 256 is 1.054502
INFO:root:FL Epoch: 403 Done on worker:256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1075
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505461
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247576
INFO:root:FL Epoch: 403 Norm Difference for worker 1075 is 0.997068
INFO:root:FL Epoch: 403 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1770
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444870
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457575
INFO:root:FL Epoch: 403 Norm Difference for worker 1770 is 1.028956
INFO:root:FL Epoch: 403 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1543
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694398
INFO:root:Worker: 1543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381975
INFO:root:FL Epoch: 403 Norm Difference for worker 1543 is 1.093973
INFO:root:FL Epoch: 403 Done on worker:1543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :483
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435421
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336115
INFO:root:FL Epoch: 403 Norm Difference for worker 483 is 1.027861
INFO:root:FL Epoch: 403 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :433
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742190
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481247
INFO:root:FL Epoch: 403 Norm Difference for worker 433 is 1.040066
INFO:root:FL Epoch: 403 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1275
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 403 Ends   ===================
INFO:root:Epoch:403 Global Model Test Loss:0.518296933349441 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:403 Global Model Backdoor Test Loss:0.09727538252870242                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 404 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 404 Workers Selected : [643, 796, 1743, 1572, 644, 893, 307, 1460, 1890, 179]
INFO:root:FL Epoch: 404 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 404 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 404 Training on worker :643
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464034
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195043
INFO:root:FL Epoch: 404 Norm Difference for worker 643 is 1.196247
INFO:root:FL Epoch: 404 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :796
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.922917
INFO:root:Worker: 796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398230
INFO:root:FL Epoch: 404 Norm Difference for worker 796 is 1.115848
INFO:root:FL Epoch: 404 Done on worker:796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1743
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676589
INFO:root:Worker: 1743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259074
INFO:root:FL Epoch: 404 Norm Difference for worker 1743 is 1.181626
INFO:root:FL Epoch: 404 Done on worker:1743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1572
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.234905
INFO:root:Worker: 1572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248741
INFO:root:FL Epoch: 404 Norm Difference for worker 1572 is 1.077979
INFO:root:FL Epoch: 404 Done on worker:1572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :644
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422455
INFO:root:Worker: 644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538707
INFO:root:FL Epoch: 404 Norm Difference for worker 644 is 1.131447
INFO:root:FL Epoch: 404 Done on worker:644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :893
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321017
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583787
INFO:root:FL Epoch: 404 Norm Difference for worker 893 is 1.184098
INFO:root:FL Epoch: 404 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :307
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 307 Train Epoch: 0 [0/201 (0%)]	Loss: 0.734794
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 307 Train Epoch: 1 [0/201 (0%)]	Loss: 0.716390
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 404 Norm Difference for worker 307 is 1.202739
INFO:root:FL Epoch: 404 Done on worker:307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1460
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314813
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245043
INFO:root:FL Epoch: 404 Norm Difference for worker 1460 is 0.898578
INFO:root:FL Epoch: 404 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1890
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691267
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561028
INFO:root:FL Epoch: 404 Norm Difference for worker 1890 is 1.213887
INFO:root:FL Epoch: 404 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :179
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 179 Train Epoch: 0 [0/201 (0%)]	Loss: 0.609234
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 179 Train Epoch: 1 [0/201 (0%)]	Loss: 0.266551
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 404 Norm Difference for worker 179 is 1.2051
INFO:root:FL Epoch: 404 Done on worker:179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1460
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 404 Ends   ===================
INFO:root:Epoch:404 Global Model Test Loss:0.5168205517179826 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:404 Global Model Backdoor Test Loss:0.09976022007564704                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 405 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 405 Workers Selected : [1646, 45, 498, 132, 1171, 587, 1921, 1482, 230, 1399]
INFO:root:FL Epoch: 405 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 405 Num points on workers: [200 201 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 405 Training on worker :1646
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501626
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279861
INFO:root:FL Epoch: 405 Norm Difference for worker 1646 is 1.417105
INFO:root:FL Epoch: 405 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :45
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611064
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.545896
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 405 Norm Difference for worker 45 is 1.312525
INFO:root:FL Epoch: 405 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :498
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488627
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521980
INFO:root:FL Epoch: 405 Norm Difference for worker 498 is 1.241661
INFO:root:FL Epoch: 405 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :132
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.817833
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.712965
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 405 Norm Difference for worker 132 is 1.179898
INFO:root:FL Epoch: 405 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1171
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1171 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699241
INFO:root:Worker: 1171 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500104
INFO:root:FL Epoch: 405 Norm Difference for worker 1171 is 1.120554
INFO:root:FL Epoch: 405 Done on worker:1171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :587
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436855
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485885
INFO:root:FL Epoch: 405 Norm Difference for worker 587 is 1.259078
INFO:root:FL Epoch: 405 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1921
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520652
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.734711
INFO:root:FL Epoch: 405 Norm Difference for worker 1921 is 1.325012
INFO:root:FL Epoch: 405 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1482
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774617
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363447
INFO:root:FL Epoch: 405 Norm Difference for worker 1482 is 1.106548
INFO:root:FL Epoch: 405 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :230
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 230 Train Epoch: 0 [0/201 (0%)]	Loss: 0.662307
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 230 Train Epoch: 1 [0/201 (0%)]	Loss: 0.189042
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 405 Norm Difference for worker 230 is 1.250617
INFO:root:FL Epoch: 405 Done on worker:230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1399
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540184
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325766
INFO:root:FL Epoch: 405 Norm Difference for worker 1399 is 1.185908
INFO:root:FL Epoch: 405 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1482
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 405 Ends   ===================
INFO:root:Epoch:405 Global Model Test Loss:0.5143921305151546 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:405 Global Model Backdoor Test Loss:0.25699685017267865                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 406 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 406 Workers Selected : [118, 1272, 1114, 236, 1838, 1835, 460, 1482, 289, 329]
INFO:root:FL Epoch: 406 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 406 Num points on workers: [201 200 200 201 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 406 Training on worker :118
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 118 Train Epoch: 0 [0/201 (0%)]	Loss: 0.218205
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 118 Train Epoch: 1 [0/201 (0%)]	Loss: 0.730738
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 406 Norm Difference for worker 118 is 1.11693
INFO:root:FL Epoch: 406 Done on worker:118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1272
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1272 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617242
INFO:root:Worker: 1272 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637636
INFO:root:FL Epoch: 406 Norm Difference for worker 1272 is 1.164837
INFO:root:FL Epoch: 406 Done on worker:1272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1114
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.806160
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438999
INFO:root:FL Epoch: 406 Norm Difference for worker 1114 is 1.123892
INFO:root:FL Epoch: 406 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :236
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 236 Train Epoch: 0 [0/201 (0%)]	Loss: 0.427088
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 236 Train Epoch: 1 [0/201 (0%)]	Loss: 0.467892
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 406 Norm Difference for worker 236 is 1.151477
INFO:root:FL Epoch: 406 Done on worker:236
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1838
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.830146
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564373
INFO:root:FL Epoch: 406 Norm Difference for worker 1838 is 1.176084
INFO:root:FL Epoch: 406 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1835
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.916732
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666142
INFO:root:FL Epoch: 406 Norm Difference for worker 1835 is 1.173523
INFO:root:FL Epoch: 406 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :460
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.294513
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610373
INFO:root:FL Epoch: 406 Norm Difference for worker 460 is 1.144137
INFO:root:FL Epoch: 406 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1482
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334973
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.144097
INFO:root:FL Epoch: 406 Norm Difference for worker 1482 is 0.702233
INFO:root:FL Epoch: 406 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :289
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.390126
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.401441
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 406 Norm Difference for worker 289 is 1.07671
INFO:root:FL Epoch: 406 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :329
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 329 Train Epoch: 0 [0/201 (0%)]	Loss: 0.350640
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 329 Train Epoch: 1 [0/201 (0%)]	Loss: 0.361504
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 406 Norm Difference for worker 329 is 1.080752
INFO:root:FL Epoch: 406 Done on worker:329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1482
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 406 Ends   ===================
INFO:root:Epoch:406 Global Model Test Loss:0.5130058789954466 and Test Accuracy:80.0 
INFO:root:Epoch:406 Global Model Backdoor Test Loss:0.18861469253897667                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 407 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 407 Workers Selected : [1442, 1664, 483, 754, 166, 1570, 541, 1604, 800, 277]
INFO:root:FL Epoch: 407 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 407 Num points on workers: [200 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 407 Training on worker :1442
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416997
INFO:root:Worker: 1442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500267
INFO:root:FL Epoch: 407 Norm Difference for worker 1442 is 1.23532
INFO:root:FL Epoch: 407 Done on worker:1442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1664
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467729
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350691
INFO:root:FL Epoch: 407 Norm Difference for worker 1664 is 1.173355
INFO:root:FL Epoch: 407 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :483
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.245453
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553315
INFO:root:FL Epoch: 407 Norm Difference for worker 483 is 1.2308
INFO:root:FL Epoch: 407 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :754
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661037
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622514
INFO:root:FL Epoch: 407 Norm Difference for worker 754 is 1.295683
INFO:root:FL Epoch: 407 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :166
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 166 Train Epoch: 0 [0/201 (0%)]	Loss: 0.444578
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 166 Train Epoch: 1 [0/201 (0%)]	Loss: 0.536473
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 407 Norm Difference for worker 166 is 1.116439
INFO:root:FL Epoch: 407 Done on worker:166
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1570
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526115
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210372
INFO:root:FL Epoch: 407 Norm Difference for worker 1570 is 1.327539
INFO:root:FL Epoch: 407 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :541
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549875
INFO:root:Worker: 541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515624
INFO:root:FL Epoch: 407 Norm Difference for worker 541 is 1.381395
INFO:root:FL Epoch: 407 Done on worker:541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1604
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662338
INFO:root:Worker: 1604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257640
INFO:root:FL Epoch: 407 Norm Difference for worker 1604 is 1.409677
INFO:root:FL Epoch: 407 Done on worker:1604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :800
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518338
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481473
INFO:root:FL Epoch: 407 Norm Difference for worker 800 is 1.2258
INFO:root:FL Epoch: 407 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :277
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.991861
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.293401
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 407 Norm Difference for worker 277 is 1.367719
INFO:root:FL Epoch: 407 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 166
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 407 Ends   ===================
INFO:root:Epoch:407 Global Model Test Loss:0.49800000646535086 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:407 Global Model Backdoor Test Loss:0.25321096926927567                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 408 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 408 Workers Selected : [1406, 774, 854, 1449, 741, 740, 1869, 1080, 1637, 1546]
INFO:root:FL Epoch: 408 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 408 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 408 Training on worker :1406
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727324
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390819
INFO:root:FL Epoch: 408 Norm Difference for worker 1406 is 1.132334
INFO:root:FL Epoch: 408 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :774
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535417
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419081
INFO:root:FL Epoch: 408 Norm Difference for worker 774 is 0.950727
INFO:root:FL Epoch: 408 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :854
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684847
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566785
INFO:root:FL Epoch: 408 Norm Difference for worker 854 is 1.127563
INFO:root:FL Epoch: 408 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1449
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388608
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443923
INFO:root:FL Epoch: 408 Norm Difference for worker 1449 is 1.294943
INFO:root:FL Epoch: 408 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :741
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442786
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464956
INFO:root:FL Epoch: 408 Norm Difference for worker 741 is 1.09592
INFO:root:FL Epoch: 408 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :740
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.787666
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298849
INFO:root:FL Epoch: 408 Norm Difference for worker 740 is 1.118511
INFO:root:FL Epoch: 408 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1869
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551441
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457341
INFO:root:FL Epoch: 408 Norm Difference for worker 1869 is 1.15619
INFO:root:FL Epoch: 408 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1080
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568641
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377710
INFO:root:FL Epoch: 408 Norm Difference for worker 1080 is 1.1219
INFO:root:FL Epoch: 408 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1637
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626007
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503289
INFO:root:FL Epoch: 408 Norm Difference for worker 1637 is 1.201287
INFO:root:FL Epoch: 408 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1546
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698301
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317639
INFO:root:FL Epoch: 408 Norm Difference for worker 1546 is 1.20265
INFO:root:FL Epoch: 408 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 774
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 408 Ends   ===================
INFO:root:Epoch:408 Global Model Test Loss:0.5389918790144079 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:408 Global Model Backdoor Test Loss:0.3762122169137001                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 409 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 409 Workers Selected : [1904, 1753, 1821, 1207, 9, 1378, 211, 883, 876, 812]
INFO:root:FL Epoch: 409 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 409 Num points on workers: [200 200 200 200 201 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 409 Training on worker :1904
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379295
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386382
INFO:root:FL Epoch: 409 Norm Difference for worker 1904 is 1.138401
INFO:root:FL Epoch: 409 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1753
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.250113
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256437
INFO:root:FL Epoch: 409 Norm Difference for worker 1753 is 0.908936
INFO:root:FL Epoch: 409 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1821
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507269
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647953
INFO:root:FL Epoch: 409 Norm Difference for worker 1821 is 1.116136
INFO:root:FL Epoch: 409 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1207
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1207 Train Epoch: 0 [0/200 (0%)]	Loss: 0.959722
INFO:root:Worker: 1207 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319442
INFO:root:FL Epoch: 409 Norm Difference for worker 1207 is 1.168229
INFO:root:FL Epoch: 409 Done on worker:1207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :9
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.543094
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.427374
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 409 Norm Difference for worker 9 is 1.047756
INFO:root:FL Epoch: 409 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1378
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663666
INFO:root:Worker: 1378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520655
INFO:root:FL Epoch: 409 Norm Difference for worker 1378 is 1.123015
INFO:root:FL Epoch: 409 Done on worker:1378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :211
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 1.003226
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.416120
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 409 Norm Difference for worker 211 is 0.989144
INFO:root:FL Epoch: 409 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :883
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635266
INFO:root:Worker: 883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476391
INFO:root:FL Epoch: 409 Norm Difference for worker 883 is 1.16531
INFO:root:FL Epoch: 409 Done on worker:883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :876
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680557
INFO:root:Worker: 876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367566
INFO:root:FL Epoch: 409 Norm Difference for worker 876 is 1.21567
INFO:root:FL Epoch: 409 Done on worker:876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :812
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616540
INFO:root:Worker: 812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344866
INFO:root:FL Epoch: 409 Norm Difference for worker 812 is 1.019812
INFO:root:FL Epoch: 409 Done on worker:812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1753
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 409 Ends   ===================
INFO:root:Epoch:409 Global Model Test Loss:0.5004541944054997 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:409 Global Model Backdoor Test Loss:0.23206372310717902                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 410 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 410 Workers Selected : [321, 758, 550, 1387, 1806, 760, 316, 1694, 937, 1178]
INFO:root:FL Epoch: 410 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 410 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 410 Training on worker :321
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.570665
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.305271
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 410 Norm Difference for worker 321 is 1.021085
INFO:root:FL Epoch: 410 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :758
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.841400
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682316
INFO:root:FL Epoch: 410 Norm Difference for worker 758 is 0.982951
INFO:root:FL Epoch: 410 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :550
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423706
INFO:root:Worker: 550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426058
INFO:root:FL Epoch: 410 Norm Difference for worker 550 is 0.96855
INFO:root:FL Epoch: 410 Done on worker:550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1387
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1387 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593252
INFO:root:Worker: 1387 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266991
INFO:root:FL Epoch: 410 Norm Difference for worker 1387 is 0.946127
INFO:root:FL Epoch: 410 Done on worker:1387
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1806
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509453
INFO:root:Worker: 1806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430705
INFO:root:FL Epoch: 410 Norm Difference for worker 1806 is 0.956748
INFO:root:FL Epoch: 410 Done on worker:1806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :760
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559910
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488249
INFO:root:FL Epoch: 410 Norm Difference for worker 760 is 1.023597
INFO:root:FL Epoch: 410 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :316
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.717076
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.556050
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 410 Norm Difference for worker 316 is 1.068268
INFO:root:FL Epoch: 410 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1694
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563490
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430792
INFO:root:FL Epoch: 410 Norm Difference for worker 1694 is 0.991458
INFO:root:FL Epoch: 410 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :937
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550247
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487930
INFO:root:FL Epoch: 410 Norm Difference for worker 937 is 0.94912
INFO:root:FL Epoch: 410 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1178
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471002
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396450
INFO:root:FL Epoch: 410 Norm Difference for worker 1178 is 0.92742
INFO:root:FL Epoch: 410 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1178
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 410 Ends   ===================
INFO:root:Epoch:410 Global Model Test Loss:0.509250176303527 and Test Accuracy:75.0 
INFO:root:Epoch:410 Global Model Backdoor Test Loss:0.1588317131002744                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 411 Begins ===================
INFO:root:FL Epoch: 411 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 411 Workers Selected : [0, 1, 2, 1428, 391, 1560, 1489, 106, 729, 1080]
INFO:root:FL Epoch: 411 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 411 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 411 Training on worker :0
INFO:root:FL Epoch: 411 Using Learning rate : 0.004400701667154434 
INFO:root:FL Epoch: 411 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399760
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358948
INFO:root:FL Epoch: 411 Worker: 0 Backdoor Test Loss: 0.15295284365614256 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 411 Worker: 0 Backdoor Train Loss: 0.19409810081124307 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 411 Norm Difference for worker 0 is 0.161925
INFO:root:FL Epoch: 411 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1
INFO:root:FL Epoch: 411 Using Learning rate : 0.004400701667154434 
INFO:root:FL Epoch: 411 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.218284
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265159
INFO:root:FL Epoch: 411 Worker: 1 Backdoor Test Loss: 0.15645597005883852 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 411 Worker: 1 Backdoor Train Loss: 0.19512020349502562 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 411 Norm Difference for worker 1 is 0.161596
INFO:root:FL Epoch: 411 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :2
INFO:root:FL Epoch: 411 Using Learning rate : 0.004400701667154434 
INFO:root:FL Epoch: 411 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.172907
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388753
INFO:root:FL Epoch: 411 Worker: 2 Backdoor Test Loss: 0.15972197304169336 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 411 Worker: 2 Backdoor Train Loss: 0.1943485200405121 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 411 Norm Difference for worker 2 is 0.159865
INFO:root:FL Epoch: 411 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1428
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.809116
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474604
INFO:root:FL Epoch: 411 Norm Difference for worker 1428 is 0.953818
INFO:root:FL Epoch: 411 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :391
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 1.033089
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366611
INFO:root:FL Epoch: 411 Norm Difference for worker 391 is 0.944966
INFO:root:FL Epoch: 411 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1560
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615251
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414509
INFO:root:FL Epoch: 411 Norm Difference for worker 1560 is 0.88029
INFO:root:FL Epoch: 411 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1489
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1489 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608449
INFO:root:Worker: 1489 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496584
INFO:root:FL Epoch: 411 Norm Difference for worker 1489 is 0.969577
INFO:root:FL Epoch: 411 Done on worker:1489
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :106
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.502432
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.285602
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 411 Norm Difference for worker 106 is 0.839653
INFO:root:FL Epoch: 411 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :729
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612435
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326962
INFO:root:FL Epoch: 411 Norm Difference for worker 729 is 0.890158
INFO:root:FL Epoch: 411 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1080
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618448
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304008
INFO:root:FL Epoch: 411 Norm Difference for worker 1080 is 0.910071
INFO:root:FL Epoch: 411 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 411 Ends   ===================
INFO:root:Epoch:411 Global Model Test Loss:0.5008396032978507 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:411 Global Model Backdoor Test Loss:0.15972197304169336                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 412 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 412 Workers Selected : [850, 1190, 991, 137, 1175, 1765, 1107, 415, 1168, 123]
INFO:root:FL Epoch: 412 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 412 Num points on workers: [200 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 412 Training on worker :850
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755393
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279712
INFO:root:FL Epoch: 412 Norm Difference for worker 850 is 0.960777
INFO:root:FL Epoch: 412 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1190
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617230
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587468
INFO:root:FL Epoch: 412 Norm Difference for worker 1190 is 0.832882
INFO:root:FL Epoch: 412 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :991
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473873
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540932
INFO:root:FL Epoch: 412 Norm Difference for worker 991 is 0.955074
INFO:root:FL Epoch: 412 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :137
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 137 Train Epoch: 0 [0/201 (0%)]	Loss: 0.575454
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 137 Train Epoch: 1 [0/201 (0%)]	Loss: 0.526855
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 412 Norm Difference for worker 137 is 1.017122
INFO:root:FL Epoch: 412 Done on worker:137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1175
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582486
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451735
INFO:root:FL Epoch: 412 Norm Difference for worker 1175 is 0.963115
INFO:root:FL Epoch: 412 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1765
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564610
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235196
INFO:root:FL Epoch: 412 Norm Difference for worker 1765 is 0.831307
INFO:root:FL Epoch: 412 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1107
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1107 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479141
INFO:root:Worker: 1107 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417058
INFO:root:FL Epoch: 412 Norm Difference for worker 1107 is 0.888763
INFO:root:FL Epoch: 412 Done on worker:1107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :415
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325173
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405445
INFO:root:FL Epoch: 412 Norm Difference for worker 415 is 0.859624
INFO:root:FL Epoch: 412 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1168
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1168 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565024
INFO:root:Worker: 1168 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482170
INFO:root:FL Epoch: 412 Norm Difference for worker 1168 is 0.860776
INFO:root:FL Epoch: 412 Done on worker:1168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :123
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.735747
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.426166
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 412 Norm Difference for worker 123 is 0.973718
INFO:root:FL Epoch: 412 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1190
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 412 Ends   ===================
INFO:root:Epoch:412 Global Model Test Loss:0.5063605606555939 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:412 Global Model Backdoor Test Loss:0.1344456747174263                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 413 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 413 Workers Selected : [1125, 873, 1501, 1370, 1513, 744, 533, 1237, 1929, 1117]
INFO:root:FL Epoch: 413 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 413 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 413 Training on worker :1125
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540580
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332007
INFO:root:FL Epoch: 413 Norm Difference for worker 1125 is 0.984806
INFO:root:FL Epoch: 413 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :873
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642372
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.763462
INFO:root:FL Epoch: 413 Norm Difference for worker 873 is 1.033229
INFO:root:FL Epoch: 413 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1501
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482147
INFO:root:Worker: 1501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365941
INFO:root:FL Epoch: 413 Norm Difference for worker 1501 is 1.009313
INFO:root:FL Epoch: 413 Done on worker:1501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1370
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398355
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233748
INFO:root:FL Epoch: 413 Norm Difference for worker 1370 is 0.95628
INFO:root:FL Epoch: 413 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1513
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576042
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523790
INFO:root:FL Epoch: 413 Norm Difference for worker 1513 is 0.948624
INFO:root:FL Epoch: 413 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :744
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.270009
INFO:root:Worker: 744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325922
INFO:root:FL Epoch: 413 Norm Difference for worker 744 is 0.960441
INFO:root:FL Epoch: 413 Done on worker:744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :533
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.818086
INFO:root:Worker: 533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695772
INFO:root:FL Epoch: 413 Norm Difference for worker 533 is 1.045345
INFO:root:FL Epoch: 413 Done on worker:533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1237
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463591
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500914
INFO:root:FL Epoch: 413 Norm Difference for worker 1237 is 1.029884
INFO:root:FL Epoch: 413 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1929
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546724
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479243
INFO:root:FL Epoch: 413 Norm Difference for worker 1929 is 0.938549
INFO:root:FL Epoch: 413 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1117
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1117 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675925
INFO:root:Worker: 1117 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260668
INFO:root:FL Epoch: 413 Norm Difference for worker 1117 is 0.932871
INFO:root:FL Epoch: 413 Done on worker:1117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1117
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 413 Ends   ===================
INFO:root:Epoch:413 Global Model Test Loss:0.5331335628733915 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:413 Global Model Backdoor Test Loss:0.25236166020234424                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 414 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 414 Workers Selected : [1192, 1056, 257, 852, 1024, 1453, 1392, 1700, 203, 661]
INFO:root:FL Epoch: 414 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 414 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 414 Training on worker :1192
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320949
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355744
INFO:root:FL Epoch: 414 Norm Difference for worker 1192 is 0.922807
INFO:root:FL Epoch: 414 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1056
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525460
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452793
INFO:root:FL Epoch: 414 Norm Difference for worker 1056 is 0.87522
INFO:root:FL Epoch: 414 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :257
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490541
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.406341
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 414 Norm Difference for worker 257 is 0.95834
INFO:root:FL Epoch: 414 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :852
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623347
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420735
INFO:root:FL Epoch: 414 Norm Difference for worker 852 is 0.914463
INFO:root:FL Epoch: 414 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1024
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594605
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466586
INFO:root:FL Epoch: 414 Norm Difference for worker 1024 is 0.97218
INFO:root:FL Epoch: 414 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1453
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334163
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624026
INFO:root:FL Epoch: 414 Norm Difference for worker 1453 is 0.915204
INFO:root:FL Epoch: 414 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1392
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490623
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358001
INFO:root:FL Epoch: 414 Norm Difference for worker 1392 is 0.953156
INFO:root:FL Epoch: 414 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1700
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547016
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259831
INFO:root:FL Epoch: 414 Norm Difference for worker 1700 is 0.919439
INFO:root:FL Epoch: 414 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :203
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.765712
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.377366
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 414 Norm Difference for worker 203 is 0.943626
INFO:root:FL Epoch: 414 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :661
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.974170
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403751
INFO:root:FL Epoch: 414 Norm Difference for worker 661 is 0.865385
INFO:root:FL Epoch: 414 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 661
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 414 Ends   ===================
INFO:root:Epoch:414 Global Model Test Loss:0.5304767016102286 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:414 Global Model Backdoor Test Loss:0.20281055818001428                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 415 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 415 Workers Selected : [408, 1362, 158, 368, 468, 1463, 341, 1793, 609, 594]
INFO:root:FL Epoch: 415 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 415 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 415 Training on worker :408
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364743
INFO:root:Worker: 408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437905
INFO:root:FL Epoch: 415 Norm Difference for worker 408 is 0.809085
INFO:root:FL Epoch: 415 Done on worker:408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1362
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482481
INFO:root:Worker: 1362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511451
INFO:root:FL Epoch: 415 Norm Difference for worker 1362 is 0.848273
INFO:root:FL Epoch: 415 Done on worker:1362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :158
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581969
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.537551
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 415 Norm Difference for worker 158 is 0.848227
INFO:root:FL Epoch: 415 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :368
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714011
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391291
INFO:root:FL Epoch: 415 Norm Difference for worker 368 is 0.869684
INFO:root:FL Epoch: 415 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :468
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603363
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386656
INFO:root:FL Epoch: 415 Norm Difference for worker 468 is 0.846533
INFO:root:FL Epoch: 415 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1463
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458910
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560917
INFO:root:FL Epoch: 415 Norm Difference for worker 1463 is 0.828758
INFO:root:FL Epoch: 415 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :341
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545760
INFO:root:Worker: 341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428109
INFO:root:FL Epoch: 415 Norm Difference for worker 341 is 0.845363
INFO:root:FL Epoch: 415 Done on worker:341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1793
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707800
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596164
INFO:root:FL Epoch: 415 Norm Difference for worker 1793 is 0.858554
INFO:root:FL Epoch: 415 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :609
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492738
INFO:root:Worker: 609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500584
INFO:root:FL Epoch: 415 Norm Difference for worker 609 is 0.895494
INFO:root:FL Epoch: 415 Done on worker:609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :594
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780539
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467797
INFO:root:FL Epoch: 415 Norm Difference for worker 594 is 0.855516
INFO:root:FL Epoch: 415 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 341
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 415 Ends   ===================
INFO:root:Epoch:415 Global Model Test Loss:0.5259518500636605 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:415 Global Model Backdoor Test Loss:0.2760917966564496                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 416 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 416 Workers Selected : [1256, 1698, 318, 1075, 427, 895, 1686, 939, 1008, 1785]
INFO:root:FL Epoch: 416 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 416 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 416 Training on worker :1256
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530937
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508805
INFO:root:FL Epoch: 416 Norm Difference for worker 1256 is 0.76569
INFO:root:FL Epoch: 416 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1698
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524811
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476606
INFO:root:FL Epoch: 416 Norm Difference for worker 1698 is 0.736435
INFO:root:FL Epoch: 416 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :318
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.527683
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.637958
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 416 Norm Difference for worker 318 is 0.709975
INFO:root:FL Epoch: 416 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1075
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509604
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406902
INFO:root:FL Epoch: 416 Norm Difference for worker 1075 is 0.769014
INFO:root:FL Epoch: 416 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :427
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385240
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432391
INFO:root:FL Epoch: 416 Norm Difference for worker 427 is 0.757696
INFO:root:FL Epoch: 416 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :895
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442514
INFO:root:Worker: 895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631173
INFO:root:FL Epoch: 416 Norm Difference for worker 895 is 0.773454
INFO:root:FL Epoch: 416 Done on worker:895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1686
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581049
INFO:root:Worker: 1686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463242
INFO:root:FL Epoch: 416 Norm Difference for worker 1686 is 0.775805
INFO:root:FL Epoch: 416 Done on worker:1686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :939
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516860
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556100
INFO:root:FL Epoch: 416 Norm Difference for worker 939 is 0.741419
INFO:root:FL Epoch: 416 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1008
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1008 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567330
INFO:root:Worker: 1008 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405361
INFO:root:FL Epoch: 416 Norm Difference for worker 1008 is 0.772098
INFO:root:FL Epoch: 416 Done on worker:1008
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1785
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614110
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602667
INFO:root:FL Epoch: 416 Norm Difference for worker 1785 is 0.751189
INFO:root:FL Epoch: 416 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 318
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 416 Ends   ===================
INFO:root:Epoch:416 Global Model Test Loss:0.557288317119374 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:416 Global Model Backdoor Test Loss:0.387138232588768                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 417 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 417 Workers Selected : [795, 1488, 830, 1412, 1025, 1652, 631, 1898, 872, 698]
INFO:root:FL Epoch: 417 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 417 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 417 Training on worker :795
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541896
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297521
INFO:root:FL Epoch: 417 Norm Difference for worker 795 is 0.676071
INFO:root:FL Epoch: 417 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1488
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386626
INFO:root:Worker: 1488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452893
INFO:root:FL Epoch: 417 Norm Difference for worker 1488 is 0.737712
INFO:root:FL Epoch: 417 Done on worker:1488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :830
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509430
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288406
INFO:root:FL Epoch: 417 Norm Difference for worker 830 is 0.831789
INFO:root:FL Epoch: 417 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1412
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1412 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472602
INFO:root:Worker: 1412 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401418
INFO:root:FL Epoch: 417 Norm Difference for worker 1412 is 0.804722
INFO:root:FL Epoch: 417 Done on worker:1412
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1025
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397397
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367673
INFO:root:FL Epoch: 417 Norm Difference for worker 1025 is 0.713002
INFO:root:FL Epoch: 417 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1652
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604422
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498218
INFO:root:FL Epoch: 417 Norm Difference for worker 1652 is 0.732499
INFO:root:FL Epoch: 417 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :631
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616738
INFO:root:Worker: 631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406776
INFO:root:FL Epoch: 417 Norm Difference for worker 631 is 0.699086
INFO:root:FL Epoch: 417 Done on worker:631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1898
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431451
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531982
INFO:root:FL Epoch: 417 Norm Difference for worker 1898 is 0.758648
INFO:root:FL Epoch: 417 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :872
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557873
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389321
INFO:root:FL Epoch: 417 Norm Difference for worker 872 is 0.786262
INFO:root:FL Epoch: 417 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :698
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511797
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438389
INFO:root:FL Epoch: 417 Norm Difference for worker 698 is 0.753005
INFO:root:FL Epoch: 417 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 795
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 417 Ends   ===================
INFO:root:Epoch:417 Global Model Test Loss:0.54628205649993 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:417 Global Model Backdoor Test Loss:0.3266260325908661                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 418 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 418 Workers Selected : [1823, 16, 1683, 1802, 663, 1406, 1358, 240, 101, 1363]
INFO:root:FL Epoch: 418 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 418 Num points on workers: [200 201 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 418 Training on worker :1823
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566191
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476647
INFO:root:FL Epoch: 418 Norm Difference for worker 1823 is 0.834928
INFO:root:FL Epoch: 418 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :16
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 16 Train Epoch: 0 [0/201 (0%)]	Loss: 0.703669
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 16 Train Epoch: 1 [0/201 (0%)]	Loss: 0.422517
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 16 is 0.824337
INFO:root:FL Epoch: 418 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1683
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611436
INFO:root:Worker: 1683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572274
INFO:root:FL Epoch: 418 Norm Difference for worker 1683 is 0.840021
INFO:root:FL Epoch: 418 Done on worker:1683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1802
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305956
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383644
INFO:root:FL Epoch: 418 Norm Difference for worker 1802 is 0.778211
INFO:root:FL Epoch: 418 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :663
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527386
INFO:root:Worker: 663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366961
INFO:root:FL Epoch: 418 Norm Difference for worker 663 is 0.810507
INFO:root:FL Epoch: 418 Done on worker:663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1406
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393039
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404818
INFO:root:FL Epoch: 418 Norm Difference for worker 1406 is 0.783641
INFO:root:FL Epoch: 418 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1358
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377089
INFO:root:Worker: 1358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511366
INFO:root:FL Epoch: 418 Norm Difference for worker 1358 is 0.83641
INFO:root:FL Epoch: 418 Done on worker:1358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :240
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 240 Train Epoch: 0 [0/201 (0%)]	Loss: 0.395272
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 240 Train Epoch: 1 [0/201 (0%)]	Loss: 0.578679
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 240 is 0.750689
INFO:root:FL Epoch: 418 Done on worker:240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :101
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.497166
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.539153
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 101 is 0.830464
INFO:root:FL Epoch: 418 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1363
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408146
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316591
INFO:root:FL Epoch: 418 Norm Difference for worker 1363 is 0.812621
INFO:root:FL Epoch: 418 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 240
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 418 Ends   ===================
INFO:root:Epoch:418 Global Model Test Loss:0.5283334483118618 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:418 Global Model Backdoor Test Loss:0.25473060210545856                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 419 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 419 Workers Selected : [185, 1693, 737, 1553, 560, 1190, 926, 912, 1477, 173]
INFO:root:FL Epoch: 419 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 419 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 419 Training on worker :185
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.478818
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.280084
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 419 Norm Difference for worker 185 is 0.771905
INFO:root:FL Epoch: 419 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1693
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395139
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386221
INFO:root:FL Epoch: 419 Norm Difference for worker 1693 is 0.716232
INFO:root:FL Epoch: 419 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :737
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389105
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361901
INFO:root:FL Epoch: 419 Norm Difference for worker 737 is 0.713397
INFO:root:FL Epoch: 419 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1553
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629501
INFO:root:Worker: 1553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622230
INFO:root:FL Epoch: 419 Norm Difference for worker 1553 is 0.760274
INFO:root:FL Epoch: 419 Done on worker:1553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :560
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468261
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635033
INFO:root:FL Epoch: 419 Norm Difference for worker 560 is 0.796749
INFO:root:FL Epoch: 419 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1190
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553247
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224272
INFO:root:FL Epoch: 419 Norm Difference for worker 1190 is 0.713202
INFO:root:FL Epoch: 419 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :926
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355358
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285859
INFO:root:FL Epoch: 419 Norm Difference for worker 926 is 0.674706
INFO:root:FL Epoch: 419 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :912
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540853
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512249
INFO:root:FL Epoch: 419 Norm Difference for worker 912 is 0.731427
INFO:root:FL Epoch: 419 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1477
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537909
INFO:root:Worker: 1477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412679
INFO:root:FL Epoch: 419 Norm Difference for worker 1477 is 0.776567
INFO:root:FL Epoch: 419 Done on worker:1477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :173
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.446989
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.300336
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 419 Norm Difference for worker 173 is 0.792369
INFO:root:FL Epoch: 419 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 926
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 419 Ends   ===================
INFO:root:Epoch:419 Global Model Test Loss:0.5348535951446084 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:419 Global Model Backdoor Test Loss:0.19247292230526605                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 420 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 420 Workers Selected : [1326, 919, 1829, 1536, 1533, 1562, 524, 652, 1778, 59]
INFO:root:FL Epoch: 420 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 420 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 420 Training on worker :1326
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423895
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515472
INFO:root:FL Epoch: 420 Norm Difference for worker 1326 is 0.937335
INFO:root:FL Epoch: 420 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :919
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555631
INFO:root:Worker: 919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639493
INFO:root:FL Epoch: 420 Norm Difference for worker 919 is 0.972803
INFO:root:FL Epoch: 420 Done on worker:919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1829
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741938
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450905
INFO:root:FL Epoch: 420 Norm Difference for worker 1829 is 0.975583
INFO:root:FL Epoch: 420 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1536
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370823
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531640
INFO:root:FL Epoch: 420 Norm Difference for worker 1536 is 0.977116
INFO:root:FL Epoch: 420 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1533
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616205
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515894
INFO:root:FL Epoch: 420 Norm Difference for worker 1533 is 1.004824
INFO:root:FL Epoch: 420 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1562
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.289458
INFO:root:Worker: 1562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536668
INFO:root:FL Epoch: 420 Norm Difference for worker 1562 is 0.961633
INFO:root:FL Epoch: 420 Done on worker:1562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :524
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649470
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339644
INFO:root:FL Epoch: 420 Norm Difference for worker 524 is 0.931275
INFO:root:FL Epoch: 420 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :652
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.297623
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330640
INFO:root:FL Epoch: 420 Norm Difference for worker 652 is 0.84798
INFO:root:FL Epoch: 420 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1778
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425912
INFO:root:Worker: 1778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400227
INFO:root:FL Epoch: 420 Norm Difference for worker 1778 is 0.918187
INFO:root:FL Epoch: 420 Done on worker:1778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :59
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.546804
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.378340
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 420 Norm Difference for worker 59 is 0.960971
INFO:root:FL Epoch: 420 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 652
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 420 Ends   ===================
INFO:root:Epoch:420 Global Model Test Loss:0.5373491644859314 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:420 Global Model Backdoor Test Loss:0.17129503563046455                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 421 Begins ===================
INFO:root:FL Epoch: 421 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 421 Workers Selected : [0, 1, 2, 316, 1143, 39, 451, 1522, 1199, 1403]
INFO:root:FL Epoch: 421 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 421 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 421 Training on worker :0
INFO:root:FL Epoch: 421 Using Learning rate : 0.004313475550188762 
INFO:root:FL Epoch: 421 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.217641
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213197
INFO:root:FL Epoch: 421 Worker: 0 Backdoor Test Loss: 0.14386786272128424 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 421 Worker: 0 Backdoor Train Loss: 0.16797605082392691 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 421 Norm Difference for worker 0 is 0.1437
INFO:root:FL Epoch: 421 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1
INFO:root:FL Epoch: 421 Using Learning rate : 0.004313475550188762 
INFO:root:FL Epoch: 421 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.216853
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260961
INFO:root:FL Epoch: 421 Worker: 1 Backdoor Test Loss: 0.1475409579773744 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 421 Worker: 1 Backdoor Train Loss: 0.16981028988957406 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 421 Norm Difference for worker 1 is 0.139229
INFO:root:FL Epoch: 421 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :2
INFO:root:FL Epoch: 421 Using Learning rate : 0.004313475550188762 
INFO:root:FL Epoch: 421 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.217197
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.138759
INFO:root:FL Epoch: 421 Worker: 2 Backdoor Test Loss: 0.1476354698340098 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 421 Worker: 2 Backdoor Train Loss: 0.17103051394224167 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 421 Norm Difference for worker 2 is 0.139126
INFO:root:FL Epoch: 421 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :316
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.411935
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.358927
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 421 Norm Difference for worker 316 is 0.903747
INFO:root:FL Epoch: 421 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1143
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1143 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563152
INFO:root:Worker: 1143 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572369
INFO:root:FL Epoch: 421 Norm Difference for worker 1143 is 1.039133
INFO:root:FL Epoch: 421 Done on worker:1143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :39
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 39 Train Epoch: 0 [0/201 (0%)]	Loss: 0.508919
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 39 Train Epoch: 1 [0/201 (0%)]	Loss: 0.354691
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 421 Norm Difference for worker 39 is 0.960565
INFO:root:FL Epoch: 421 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :451
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635817
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241768
INFO:root:FL Epoch: 421 Norm Difference for worker 451 is 0.988964
INFO:root:FL Epoch: 421 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1522
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547999
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497457
INFO:root:FL Epoch: 421 Norm Difference for worker 1522 is 0.997969
INFO:root:FL Epoch: 421 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1199
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771211
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626880
INFO:root:FL Epoch: 421 Norm Difference for worker 1199 is 0.995475
INFO:root:FL Epoch: 421 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1403
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330770
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372236
INFO:root:FL Epoch: 421 Norm Difference for worker 1403 is 1.363047
INFO:root:FL Epoch: 421 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 421 Ends   ===================
INFO:root:Epoch:421 Global Model Test Loss:0.5397452554282021 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:421 Global Model Backdoor Test Loss:0.1476354698340098                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 422 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 422 Workers Selected : [1432, 1879, 1374, 138, 1818, 1897, 1713, 1190, 804, 1704]
INFO:root:FL Epoch: 422 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 422 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 422 Training on worker :1432
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403263
INFO:root:Worker: 1432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406367
INFO:root:FL Epoch: 422 Norm Difference for worker 1432 is 0.939344
INFO:root:FL Epoch: 422 Done on worker:1432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1879
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304707
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389805
INFO:root:FL Epoch: 422 Norm Difference for worker 1879 is 1.068725
INFO:root:FL Epoch: 422 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1374
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467030
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281313
INFO:root:FL Epoch: 422 Norm Difference for worker 1374 is 0.954593
INFO:root:FL Epoch: 422 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :138
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.574636
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.600961
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 422 Norm Difference for worker 138 is 1.045502
INFO:root:FL Epoch: 422 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1818
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668468
INFO:root:Worker: 1818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460982
INFO:root:FL Epoch: 422 Norm Difference for worker 1818 is 1.001984
INFO:root:FL Epoch: 422 Done on worker:1818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1897
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622245
INFO:root:Worker: 1897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484611
INFO:root:FL Epoch: 422 Norm Difference for worker 1897 is 1.002214
INFO:root:FL Epoch: 422 Done on worker:1897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1713
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556224
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.763418
INFO:root:FL Epoch: 422 Norm Difference for worker 1713 is 0.926583
INFO:root:FL Epoch: 422 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1190
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.244186
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218053
INFO:root:FL Epoch: 422 Norm Difference for worker 1190 is 0.809878
INFO:root:FL Epoch: 422 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :804
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516249
INFO:root:Worker: 804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.728949
INFO:root:FL Epoch: 422 Norm Difference for worker 804 is 1.096132
INFO:root:FL Epoch: 422 Done on worker:804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1704
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435401
INFO:root:Worker: 1704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383040
INFO:root:FL Epoch: 422 Norm Difference for worker 1704 is 1.002057
INFO:root:FL Epoch: 422 Done on worker:1704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1190
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 422 Ends   ===================
INFO:root:Epoch:422 Global Model Test Loss:0.5647386961123523 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:422 Global Model Backdoor Test Loss:0.07202231884002686                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 423 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 423 Workers Selected : [270, 754, 153, 729, 1270, 198, 422, 357, 1197, 1215]
INFO:root:FL Epoch: 423 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 423 Num points on workers: [201 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 423 Training on worker :270
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.349828
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.413278
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 423 Norm Difference for worker 270 is 1.034256
INFO:root:FL Epoch: 423 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :754
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439883
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424277
INFO:root:FL Epoch: 423 Norm Difference for worker 754 is 1.214176
INFO:root:FL Epoch: 423 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :153
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576014
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.278571
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 423 Norm Difference for worker 153 is 1.160123
INFO:root:FL Epoch: 423 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :729
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508625
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355665
INFO:root:FL Epoch: 423 Norm Difference for worker 729 is 1.133575
INFO:root:FL Epoch: 423 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1270
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395027
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.117857
INFO:root:FL Epoch: 423 Norm Difference for worker 1270 is 0.881015
INFO:root:FL Epoch: 423 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :198
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.931612
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.527598
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 423 Norm Difference for worker 198 is 1.181542
INFO:root:FL Epoch: 423 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :422
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760721
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581472
INFO:root:FL Epoch: 423 Norm Difference for worker 422 is 1.251939
INFO:root:FL Epoch: 423 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :357
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393331
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332026
INFO:root:FL Epoch: 423 Norm Difference for worker 357 is 1.081246
INFO:root:FL Epoch: 423 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1197
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528844
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 1.166715
INFO:root:FL Epoch: 423 Norm Difference for worker 1197 is 1.94477
INFO:root:FL Epoch: 423 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1215
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735552
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339389
INFO:root:FL Epoch: 423 Norm Difference for worker 1215 is 1.191268
INFO:root:FL Epoch: 423 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1270
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 423 Ends   ===================
INFO:root:Epoch:423 Global Model Test Loss:0.5685549553702859 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:423 Global Model Backdoor Test Loss:0.09754229336977005                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 424 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 424 Workers Selected : [1695, 1865, 1713, 297, 1928, 1649, 866, 1522, 950, 1672]
INFO:root:FL Epoch: 424 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 424 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 424 Training on worker :1695
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540622
INFO:root:Worker: 1695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543072
INFO:root:FL Epoch: 424 Norm Difference for worker 1695 is 1.214807
INFO:root:FL Epoch: 424 Done on worker:1695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1865
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664821
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548826
INFO:root:FL Epoch: 424 Norm Difference for worker 1865 is 1.214883
INFO:root:FL Epoch: 424 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1713
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555008
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296776
INFO:root:FL Epoch: 424 Norm Difference for worker 1713 is 1.118928
INFO:root:FL Epoch: 424 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :297
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 297 Train Epoch: 0 [0/201 (0%)]	Loss: 0.628441
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 297 Train Epoch: 1 [0/201 (0%)]	Loss: 0.378478
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 297 is 1.162398
INFO:root:FL Epoch: 424 Done on worker:297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1928
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754058
INFO:root:Worker: 1928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276164
INFO:root:FL Epoch: 424 Norm Difference for worker 1928 is 1.153374
INFO:root:FL Epoch: 424 Done on worker:1928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1649
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731592
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372434
INFO:root:FL Epoch: 424 Norm Difference for worker 1649 is 1.173129
INFO:root:FL Epoch: 424 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :866
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773941
INFO:root:Worker: 866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260555
INFO:root:FL Epoch: 424 Norm Difference for worker 866 is 1.202881
INFO:root:FL Epoch: 424 Done on worker:866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1522
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.834247
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311406
INFO:root:FL Epoch: 424 Norm Difference for worker 1522 is 1.189281
INFO:root:FL Epoch: 424 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :950
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453564
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292296
INFO:root:FL Epoch: 424 Norm Difference for worker 950 is 1.12615
INFO:root:FL Epoch: 424 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1672
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641193
INFO:root:Worker: 1672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262899
INFO:root:FL Epoch: 424 Norm Difference for worker 1672 is 1.145297
INFO:root:FL Epoch: 424 Done on worker:1672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1713
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 424 Ends   ===================
INFO:root:Epoch:424 Global Model Test Loss:0.5536220757400289 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:424 Global Model Backdoor Test Loss:0.08573465421795845                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 425 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 425 Workers Selected : [772, 146, 483, 630, 1459, 1607, 1636, 1906, 1540, 320]
INFO:root:FL Epoch: 425 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 425 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 425 Training on worker :772
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733233
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384974
INFO:root:FL Epoch: 425 Norm Difference for worker 772 is 1.313985
INFO:root:FL Epoch: 425 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :146
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 146 Train Epoch: 0 [0/201 (0%)]	Loss: 0.647396
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 146 Train Epoch: 1 [0/201 (0%)]	Loss: 0.409429
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 146 is 1.140133
INFO:root:FL Epoch: 425 Done on worker:146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :483
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779873
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530589
INFO:root:FL Epoch: 425 Norm Difference for worker 483 is 1.485705
INFO:root:FL Epoch: 425 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :630
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497783
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690029
INFO:root:FL Epoch: 425 Norm Difference for worker 630 is 1.218973
INFO:root:FL Epoch: 425 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1459
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.840014
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524014
INFO:root:FL Epoch: 425 Norm Difference for worker 1459 is 1.279406
INFO:root:FL Epoch: 425 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1607
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546430
INFO:root:Worker: 1607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376018
INFO:root:FL Epoch: 425 Norm Difference for worker 1607 is 1.646198
INFO:root:FL Epoch: 425 Done on worker:1607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1636
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556019
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626472
INFO:root:FL Epoch: 425 Norm Difference for worker 1636 is 1.155644
INFO:root:FL Epoch: 425 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1906
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.259774
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597034
INFO:root:FL Epoch: 425 Norm Difference for worker 1906 is 1.269256
INFO:root:FL Epoch: 425 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1540
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726918
INFO:root:Worker: 1540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429154
INFO:root:FL Epoch: 425 Norm Difference for worker 1540 is 1.025312
INFO:root:FL Epoch: 425 Done on worker:1540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :320
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.556509
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.532241
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 320 is 1.080992
INFO:root:FL Epoch: 425 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1636
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 425 Ends   ===================
INFO:root:Epoch:425 Global Model Test Loss:0.5866327916874605 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:425 Global Model Backdoor Test Loss:0.392350638906161                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 426 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 426 Workers Selected : [607, 1256, 305, 1249, 1338, 942, 1340, 822, 41, 1770]
INFO:root:FL Epoch: 426 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 426 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 426 Training on worker :607
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.266789
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313997
INFO:root:FL Epoch: 426 Norm Difference for worker 607 is 0.82404
INFO:root:FL Epoch: 426 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :1256
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502662
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415073
INFO:root:FL Epoch: 426 Norm Difference for worker 1256 is 0.898229
INFO:root:FL Epoch: 426 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :305
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.462344
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.516326
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 426 Norm Difference for worker 305 is 0.930061
INFO:root:FL Epoch: 426 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :1249
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 0.853206
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579552
INFO:root:FL Epoch: 426 Norm Difference for worker 1249 is 0.941591
INFO:root:FL Epoch: 426 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :1338
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447202
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381735
INFO:root:FL Epoch: 426 Norm Difference for worker 1338 is 0.831137
INFO:root:FL Epoch: 426 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :942
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546635
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478244
INFO:root:FL Epoch: 426 Norm Difference for worker 942 is 0.884009
INFO:root:FL Epoch: 426 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :1340
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679730
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.772914
INFO:root:FL Epoch: 426 Norm Difference for worker 1340 is 0.950667
INFO:root:FL Epoch: 426 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :822
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401978
INFO:root:Worker: 822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338003
INFO:root:FL Epoch: 426 Norm Difference for worker 822 is 0.957225
INFO:root:FL Epoch: 426 Done on worker:822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :41
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 41 Train Epoch: 0 [0/201 (0%)]	Loss: 0.458179
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 41 Train Epoch: 1 [0/201 (0%)]	Loss: 0.522982
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 426 Norm Difference for worker 41 is 0.835455
INFO:root:FL Epoch: 426 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :1770
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639275
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401149
INFO:root:FL Epoch: 426 Norm Difference for worker 1770 is 0.84141
INFO:root:FL Epoch: 426 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1338
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 426 Ends   ===================
INFO:root:Epoch:426 Global Model Test Loss:0.5146537037456737 and Test Accuracy:75.0 
INFO:root:Epoch:426 Global Model Backdoor Test Loss:0.15605870385964712                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 427 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 427 Workers Selected : [77, 907, 431, 1546, 1892, 70, 1513, 959, 274, 157]
INFO:root:FL Epoch: 427 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 427 Num points on workers: [201 200 200 200 200 201 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 427 Training on worker :77
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.617869
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.421027
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 427 Norm Difference for worker 77 is 0.857517
INFO:root:FL Epoch: 427 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :907
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604947
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.721621
INFO:root:FL Epoch: 427 Norm Difference for worker 907 is 0.909159
INFO:root:FL Epoch: 427 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :431
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626329
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579297
INFO:root:FL Epoch: 427 Norm Difference for worker 431 is 0.88386
INFO:root:FL Epoch: 427 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1546
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497534
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364645
INFO:root:FL Epoch: 427 Norm Difference for worker 1546 is 0.878467
INFO:root:FL Epoch: 427 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1892
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369178
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373961
INFO:root:FL Epoch: 427 Norm Difference for worker 1892 is 0.841276
INFO:root:FL Epoch: 427 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :70
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.609357
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.493500
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 427 Norm Difference for worker 70 is 0.785025
INFO:root:FL Epoch: 427 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1513
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402247
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260997
INFO:root:FL Epoch: 427 Norm Difference for worker 1513 is 0.859676
INFO:root:FL Epoch: 427 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :959
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429203
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472250
INFO:root:FL Epoch: 427 Norm Difference for worker 959 is 0.939727
INFO:root:FL Epoch: 427 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :274
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.653724
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.509590
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 427 Norm Difference for worker 274 is 0.781201
INFO:root:FL Epoch: 427 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :157
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.307662
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.393510
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 427 Norm Difference for worker 157 is 0.918469
INFO:root:FL Epoch: 427 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 274
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 427 Ends   ===================
INFO:root:Epoch:427 Global Model Test Loss:0.5266638117678025 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:427 Global Model Backdoor Test Loss:0.24643516540527344                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 428 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 428 Workers Selected : [683, 1670, 1846, 949, 1749, 1722, 993, 1085, 948, 1414]
INFO:root:FL Epoch: 428 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 428 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 428 Training on worker :683
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507910
INFO:root:Worker: 683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384101
INFO:root:FL Epoch: 428 Norm Difference for worker 683 is 0.924628
INFO:root:FL Epoch: 428 Done on worker:683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1670
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.239072
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393269
INFO:root:FL Epoch: 428 Norm Difference for worker 1670 is 0.842945
INFO:root:FL Epoch: 428 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1846
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472063
INFO:root:Worker: 1846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268956
INFO:root:FL Epoch: 428 Norm Difference for worker 1846 is 0.917887
INFO:root:FL Epoch: 428 Done on worker:1846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :949
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389824
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502712
INFO:root:FL Epoch: 428 Norm Difference for worker 949 is 0.954792
INFO:root:FL Epoch: 428 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1749
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1749 Train Epoch: 0 [0/200 (0%)]	Loss: 0.996008
INFO:root:Worker: 1749 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560801
INFO:root:FL Epoch: 428 Norm Difference for worker 1749 is 0.926988
INFO:root:FL Epoch: 428 Done on worker:1749
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1722
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.209276
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338320
INFO:root:FL Epoch: 428 Norm Difference for worker 1722 is 0.949137
INFO:root:FL Epoch: 428 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :993
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 993 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477328
INFO:root:Worker: 993 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477274
INFO:root:FL Epoch: 428 Norm Difference for worker 993 is 1.019379
INFO:root:FL Epoch: 428 Done on worker:993
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1085
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667572
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464061
INFO:root:FL Epoch: 428 Norm Difference for worker 1085 is 0.945226
INFO:root:FL Epoch: 428 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :948
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 948 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542350
INFO:root:Worker: 948 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564153
INFO:root:FL Epoch: 428 Norm Difference for worker 948 is 0.978444
INFO:root:FL Epoch: 428 Done on worker:948
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1414
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681328
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569217
INFO:root:FL Epoch: 428 Norm Difference for worker 1414 is 1.020021
INFO:root:FL Epoch: 428 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1670
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 428 Ends   ===================
INFO:root:Epoch:428 Global Model Test Loss:0.5346491880276624 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:428 Global Model Backdoor Test Loss:0.19599662721157074                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 429 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 429 Workers Selected : [958, 924, 923, 170, 1886, 71, 912, 1134, 1808, 1870]
INFO:root:FL Epoch: 429 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 429 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 429 Training on worker :958
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714666
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436838
INFO:root:FL Epoch: 429 Norm Difference for worker 958 is 0.923103
INFO:root:FL Epoch: 429 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :924
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478941
INFO:root:Worker: 924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366043
INFO:root:FL Epoch: 429 Norm Difference for worker 924 is 0.935295
INFO:root:FL Epoch: 429 Done on worker:924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :923
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560236
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530501
INFO:root:FL Epoch: 429 Norm Difference for worker 923 is 0.920889
INFO:root:FL Epoch: 429 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :170
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596667
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.541729
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 429 Norm Difference for worker 170 is 0.955315
INFO:root:FL Epoch: 429 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1886
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707973
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355386
INFO:root:FL Epoch: 429 Norm Difference for worker 1886 is 0.892499
INFO:root:FL Epoch: 429 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :71
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576150
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.312816
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 429 Norm Difference for worker 71 is 0.934556
INFO:root:FL Epoch: 429 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :912
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593175
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580089
INFO:root:FL Epoch: 429 Norm Difference for worker 912 is 0.925065
INFO:root:FL Epoch: 429 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1134
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1134 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530570
INFO:root:Worker: 1134 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634285
INFO:root:FL Epoch: 429 Norm Difference for worker 1134 is 0.912635
INFO:root:FL Epoch: 429 Done on worker:1134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1808
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550218
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363660
INFO:root:FL Epoch: 429 Norm Difference for worker 1808 is 0.901012
INFO:root:FL Epoch: 429 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1870
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338127
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390296
INFO:root:FL Epoch: 429 Norm Difference for worker 1870 is 0.961657
INFO:root:FL Epoch: 429 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1886
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 429 Ends   ===================
INFO:root:Epoch:429 Global Model Test Loss:0.5262426383355084 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:429 Global Model Backdoor Test Loss:0.1871388852596283                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 430 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 430 Workers Selected : [1469, 582, 963, 936, 1610, 1285, 954, 660, 200, 238]
INFO:root:FL Epoch: 430 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 430 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 430 Training on worker :1469
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559141
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370943
INFO:root:FL Epoch: 430 Norm Difference for worker 1469 is 0.992339
INFO:root:FL Epoch: 430 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :582
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783202
INFO:root:Worker: 582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415621
INFO:root:FL Epoch: 430 Norm Difference for worker 582 is 1.014866
INFO:root:FL Epoch: 430 Done on worker:582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :963
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 963 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475451
INFO:root:Worker: 963 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507676
INFO:root:FL Epoch: 430 Norm Difference for worker 963 is 0.979749
INFO:root:FL Epoch: 430 Done on worker:963
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :936
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471383
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592586
INFO:root:FL Epoch: 430 Norm Difference for worker 936 is 0.992371
INFO:root:FL Epoch: 430 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1610
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718554
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389931
INFO:root:FL Epoch: 430 Norm Difference for worker 1610 is 0.937651
INFO:root:FL Epoch: 430 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1285
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387389
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.169003
INFO:root:FL Epoch: 430 Norm Difference for worker 1285 is 0.792823
INFO:root:FL Epoch: 430 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :954
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 954 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420629
INFO:root:Worker: 954 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612764
INFO:root:FL Epoch: 430 Norm Difference for worker 954 is 0.95474
INFO:root:FL Epoch: 430 Done on worker:954
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :660
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571935
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371021
INFO:root:FL Epoch: 430 Norm Difference for worker 660 is 0.89554
INFO:root:FL Epoch: 430 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :200
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.469930
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.295741
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 430 Norm Difference for worker 200 is 0.954084
INFO:root:FL Epoch: 430 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :238
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 238 Train Epoch: 0 [0/201 (0%)]	Loss: 0.557509
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 238 Train Epoch: 1 [0/201 (0%)]	Loss: 0.549211
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 430 Norm Difference for worker 238 is 0.996476
INFO:root:FL Epoch: 430 Done on worker:238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1285
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 430 Ends   ===================
INFO:root:Epoch:430 Global Model Test Loss:0.5302795487291673 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:430 Global Model Backdoor Test Loss:0.1740030845006307                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 431 Begins ===================
INFO:root:FL Epoch: 431 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 431 Workers Selected : [0, 1, 2, 182, 207, 1332, 956, 1616, 1364, 648]
INFO:root:FL Epoch: 431 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 431 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 431 Training on worker :0
INFO:root:FL Epoch: 431 Using Learning rate : 0.004227978338306044 
INFO:root:FL Epoch: 431 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.160875
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207654
INFO:root:FL Epoch: 431 Worker: 0 Backdoor Test Loss: 0.12985082467397055 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 431 Worker: 0 Backdoor Train Loss: 0.15270958989858627 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 431 Norm Difference for worker 0 is 0.152074
INFO:root:FL Epoch: 431 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1
INFO:root:FL Epoch: 431 Using Learning rate : 0.004227978338306044 
INFO:root:FL Epoch: 431 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.190727
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.128537
INFO:root:FL Epoch: 431 Worker: 1 Backdoor Test Loss: 0.12426099305351575 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 431 Worker: 1 Backdoor Train Loss: 0.15398333668708802 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 431 Norm Difference for worker 1 is 0.146059
INFO:root:FL Epoch: 431 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :2
INFO:root:FL Epoch: 431 Using Learning rate : 0.004227978338306044 
INFO:root:FL Epoch: 431 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.243372
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.110390
INFO:root:FL Epoch: 431 Worker: 2 Backdoor Test Loss: 0.1263598402341207 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 431 Worker: 2 Backdoor Train Loss: 0.15461571216583253 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 431 Norm Difference for worker 2 is 0.141091
INFO:root:FL Epoch: 431 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :182
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.650310
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450078
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 431 Norm Difference for worker 182 is 1.01527
INFO:root:FL Epoch: 431 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :207
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.623670
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.528828
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 431 Norm Difference for worker 207 is 1.131055
INFO:root:FL Epoch: 431 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1332
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593396
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212419
INFO:root:FL Epoch: 431 Norm Difference for worker 1332 is 1.043386
INFO:root:FL Epoch: 431 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :956
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 956 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709364
INFO:root:Worker: 956 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519060
INFO:root:FL Epoch: 431 Norm Difference for worker 956 is 1.053402
INFO:root:FL Epoch: 431 Done on worker:956
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1616
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418387
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419409
INFO:root:FL Epoch: 431 Norm Difference for worker 1616 is 1.044434
INFO:root:FL Epoch: 431 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1364
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483483
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350562
INFO:root:FL Epoch: 431 Norm Difference for worker 1364 is 0.967631
INFO:root:FL Epoch: 431 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :648
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621797
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420979
INFO:root:FL Epoch: 431 Norm Difference for worker 648 is 1.023118
INFO:root:FL Epoch: 431 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 431 Ends   ===================
INFO:root:Epoch:431 Global Model Test Loss:0.5343479829676011 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:431 Global Model Backdoor Test Loss:0.1263598402341207                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 432 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 432 Workers Selected : [1755, 1533, 1003, 1514, 482, 38, 1305, 806, 1291, 1342]
INFO:root:FL Epoch: 432 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 432 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 432 Training on worker :1755
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328243
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412419
INFO:root:FL Epoch: 432 Norm Difference for worker 1755 is 1.013681
INFO:root:FL Epoch: 432 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1533
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681768
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637605
INFO:root:FL Epoch: 432 Norm Difference for worker 1533 is 1.137058
INFO:root:FL Epoch: 432 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1003
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769342
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556454
INFO:root:FL Epoch: 432 Norm Difference for worker 1003 is 1.047188
INFO:root:FL Epoch: 432 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1514
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717081
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370680
INFO:root:FL Epoch: 432 Norm Difference for worker 1514 is 1.049594
INFO:root:FL Epoch: 432 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :482
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680057
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288103
INFO:root:FL Epoch: 432 Norm Difference for worker 482 is 1.109006
INFO:root:FL Epoch: 432 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :38
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.706226
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.252694
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 432 Norm Difference for worker 38 is 0.849617
INFO:root:FL Epoch: 432 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1305
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1305 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656123
INFO:root:Worker: 1305 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239413
INFO:root:FL Epoch: 432 Norm Difference for worker 1305 is 1.039226
INFO:root:FL Epoch: 432 Done on worker:1305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :806
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515951
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412723
INFO:root:FL Epoch: 432 Norm Difference for worker 806 is 1.169136
INFO:root:FL Epoch: 432 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1291
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1291 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478253
INFO:root:Worker: 1291 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391617
INFO:root:FL Epoch: 432 Norm Difference for worker 1291 is 0.885069
INFO:root:FL Epoch: 432 Done on worker:1291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1342
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617704
INFO:root:Worker: 1342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531807
INFO:root:FL Epoch: 432 Norm Difference for worker 1342 is 1.01028
INFO:root:FL Epoch: 432 Done on worker:1342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 38
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 432 Ends   ===================
INFO:root:Epoch:432 Global Model Test Loss:0.5459334201672498 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:432 Global Model Backdoor Test Loss:0.10122190788388252                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 433 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 433 Workers Selected : [1736, 1347, 965, 1370, 121, 1393, 456, 1814, 1922, 825]
INFO:root:FL Epoch: 433 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 433 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 433 Training on worker :1736
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546363
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459613
INFO:root:FL Epoch: 433 Norm Difference for worker 1736 is 1.175734
INFO:root:FL Epoch: 433 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1347
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569427
INFO:root:Worker: 1347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500693
INFO:root:FL Epoch: 433 Norm Difference for worker 1347 is 1.111618
INFO:root:FL Epoch: 433 Done on worker:1347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :965
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 965 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558274
INFO:root:Worker: 965 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409759
INFO:root:FL Epoch: 433 Norm Difference for worker 965 is 1.007262
INFO:root:FL Epoch: 433 Done on worker:965
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1370
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572520
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.209293
INFO:root:FL Epoch: 433 Norm Difference for worker 1370 is 1.064641
INFO:root:FL Epoch: 433 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :121
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 121 Train Epoch: 0 [0/201 (0%)]	Loss: 0.686898
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 121 Train Epoch: 1 [0/201 (0%)]	Loss: 0.317606
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 433 Norm Difference for worker 121 is 1.299729
INFO:root:FL Epoch: 433 Done on worker:121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1393
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485492
INFO:root:Worker: 1393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.856157
INFO:root:FL Epoch: 433 Norm Difference for worker 1393 is 1.153824
INFO:root:FL Epoch: 433 Done on worker:1393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :456
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384229
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441407
INFO:root:FL Epoch: 433 Norm Difference for worker 456 is 1.099062
INFO:root:FL Epoch: 433 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1814
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.837463
INFO:root:Worker: 1814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405952
INFO:root:FL Epoch: 433 Norm Difference for worker 1814 is 1.179554
INFO:root:FL Epoch: 433 Done on worker:1814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1922
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319679
INFO:root:Worker: 1922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600714
INFO:root:FL Epoch: 433 Norm Difference for worker 1922 is 1.038578
INFO:root:FL Epoch: 433 Done on worker:1922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :825
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391276
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338810
INFO:root:FL Epoch: 433 Norm Difference for worker 825 is 0.870807
INFO:root:FL Epoch: 433 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 825
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 433 Ends   ===================
INFO:root:Epoch:433 Global Model Test Loss:0.555855195311939 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:433 Global Model Backdoor Test Loss:0.07518911734223366                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 434 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 434 Workers Selected : [1426, 1515, 1029, 1283, 292, 988, 434, 1197, 1772, 1338]
INFO:root:FL Epoch: 434 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 434 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 434 Training on worker :1426
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478162
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.767072
INFO:root:FL Epoch: 434 Norm Difference for worker 1426 is 1.746505
INFO:root:FL Epoch: 434 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1515
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.871219
INFO:root:Worker: 1515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354120
INFO:root:FL Epoch: 434 Norm Difference for worker 1515 is 1.274958
INFO:root:FL Epoch: 434 Done on worker:1515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1029
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1029 Train Epoch: 0 [0/200 (0%)]	Loss: 0.842219
INFO:root:Worker: 1029 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446632
INFO:root:FL Epoch: 434 Norm Difference for worker 1029 is 1.16248
INFO:root:FL Epoch: 434 Done on worker:1029
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1283
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1283 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433944
INFO:root:Worker: 1283 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378648
INFO:root:FL Epoch: 434 Norm Difference for worker 1283 is 1.242089
INFO:root:FL Epoch: 434 Done on worker:1283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :292
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 292 Train Epoch: 0 [0/201 (0%)]	Loss: 0.337283
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 292 Train Epoch: 1 [0/201 (0%)]	Loss: 0.358845
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 292 is 1.280434
INFO:root:FL Epoch: 434 Done on worker:292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :988
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 988 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443277
INFO:root:Worker: 988 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393310
INFO:root:FL Epoch: 434 Norm Difference for worker 988 is 1.040587
INFO:root:FL Epoch: 434 Done on worker:988
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :434
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713907
INFO:root:Worker: 434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489617
INFO:root:FL Epoch: 434 Norm Difference for worker 434 is 1.301685
INFO:root:FL Epoch: 434 Done on worker:434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1197
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.806838
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.766513
INFO:root:FL Epoch: 434 Norm Difference for worker 1197 is 1.304197
INFO:root:FL Epoch: 434 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1772
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683558
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418738
INFO:root:FL Epoch: 434 Norm Difference for worker 1772 is 1.205441
INFO:root:FL Epoch: 434 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1338
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341074
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323840
INFO:root:FL Epoch: 434 Norm Difference for worker 1338 is 0.738614
INFO:root:FL Epoch: 434 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1338
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 434 Ends   ===================
INFO:root:Epoch:434 Global Model Test Loss:0.5621766062343821 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:434 Global Model Backdoor Test Loss:0.07186966544638078                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 435 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 435 Workers Selected : [522, 1084, 794, 1467, 1794, 1935, 1180, 1316, 1029, 1087]
INFO:root:FL Epoch: 435 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 435 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 435 Training on worker :522
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.931772
INFO:root:Worker: 522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437035
INFO:root:FL Epoch: 435 Norm Difference for worker 522 is 1.200392
INFO:root:FL Epoch: 435 Done on worker:522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1084
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661778
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506264
INFO:root:FL Epoch: 435 Norm Difference for worker 1084 is 1.374206
INFO:root:FL Epoch: 435 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :794
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 794 Train Epoch: 0 [0/200 (0%)]	Loss: 1.053441
INFO:root:Worker: 794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282958
INFO:root:FL Epoch: 435 Norm Difference for worker 794 is 1.229641
INFO:root:FL Epoch: 435 Done on worker:794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1467
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808026
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685326
INFO:root:FL Epoch: 435 Norm Difference for worker 1467 is 1.317835
INFO:root:FL Epoch: 435 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1794
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374512
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308409
INFO:root:FL Epoch: 435 Norm Difference for worker 1794 is 1.188146
INFO:root:FL Epoch: 435 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1935
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655394
INFO:root:Worker: 1935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365978
INFO:root:FL Epoch: 435 Norm Difference for worker 1935 is 1.221411
INFO:root:FL Epoch: 435 Done on worker:1935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1180
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481843
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643218
INFO:root:FL Epoch: 435 Norm Difference for worker 1180 is 1.253261
INFO:root:FL Epoch: 435 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1316
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.142782
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322470
INFO:root:FL Epoch: 435 Norm Difference for worker 1316 is 0.992792
INFO:root:FL Epoch: 435 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1029
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1029 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568144
INFO:root:Worker: 1029 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478004
INFO:root:FL Epoch: 435 Norm Difference for worker 1029 is 1.285533
INFO:root:FL Epoch: 435 Done on worker:1029
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1087
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.862907
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336169
INFO:root:FL Epoch: 435 Norm Difference for worker 1087 is 1.211985
INFO:root:FL Epoch: 435 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1316
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 435 Ends   ===================
INFO:root:Epoch:435 Global Model Test Loss:0.5713176306556252 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:435 Global Model Backdoor Test Loss:0.06304122569660346                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 436 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 436 Workers Selected : [1500, 1518, 1356, 1009, 923, 1137, 1947, 1178, 44, 161]
INFO:root:FL Epoch: 436 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 436 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 436 Training on worker :1500
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702562
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662038
INFO:root:FL Epoch: 436 Norm Difference for worker 1500 is 1.277606
INFO:root:FL Epoch: 436 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1518
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458441
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364362
INFO:root:FL Epoch: 436 Norm Difference for worker 1518 is 1.280453
INFO:root:FL Epoch: 436 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1356
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748970
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679463
INFO:root:FL Epoch: 436 Norm Difference for worker 1356 is 1.395475
INFO:root:FL Epoch: 436 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1009
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420295
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338354
INFO:root:FL Epoch: 436 Norm Difference for worker 1009 is 1.237665
INFO:root:FL Epoch: 436 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :923
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.999789
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514292
INFO:root:FL Epoch: 436 Norm Difference for worker 923 is 1.244424
INFO:root:FL Epoch: 436 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1137
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.817369
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498354
INFO:root:FL Epoch: 436 Norm Difference for worker 1137 is 1.373256
INFO:root:FL Epoch: 436 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1947
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461834
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.161851
INFO:root:FL Epoch: 436 Norm Difference for worker 1947 is 0.879403
INFO:root:FL Epoch: 436 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1178
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654732
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.148390
INFO:root:FL Epoch: 436 Norm Difference for worker 1178 is 1.025299
INFO:root:FL Epoch: 436 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :44
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 44 Train Epoch: 0 [0/201 (0%)]	Loss: 0.578831
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 44 Train Epoch: 1 [0/201 (0%)]	Loss: 0.238773
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 44 is 1.229882
INFO:root:FL Epoch: 436 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :161
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.589161
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.225805
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 161 is 1.083089
INFO:root:FL Epoch: 436 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1947
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 436 Ends   ===================
INFO:root:Epoch:436 Global Model Test Loss:0.5498903288560755 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:436 Global Model Backdoor Test Loss:0.06916798402865727                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 437 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 437 Workers Selected : [312, 1612, 1685, 582, 797, 600, 237, 1308, 534, 844]
INFO:root:FL Epoch: 437 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 437 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 437 Training on worker :312
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 1.162575
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.493498
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 312 is 1.293599
INFO:root:FL Epoch: 437 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1612
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591726
INFO:root:Worker: 1612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302226
INFO:root:FL Epoch: 437 Norm Difference for worker 1612 is 1.139033
INFO:root:FL Epoch: 437 Done on worker:1612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1685
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530706
INFO:root:Worker: 1685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503791
INFO:root:FL Epoch: 437 Norm Difference for worker 1685 is 1.166822
INFO:root:FL Epoch: 437 Done on worker:1685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :582
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426541
INFO:root:Worker: 582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310038
INFO:root:FL Epoch: 437 Norm Difference for worker 582 is 1.30406
INFO:root:FL Epoch: 437 Done on worker:582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :797
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504393
INFO:root:Worker: 797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576693
INFO:root:FL Epoch: 437 Norm Difference for worker 797 is 1.33028
INFO:root:FL Epoch: 437 Done on worker:797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :600
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489753
INFO:root:Worker: 600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303247
INFO:root:FL Epoch: 437 Norm Difference for worker 600 is 1.160475
INFO:root:FL Epoch: 437 Done on worker:600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :237
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 237 Train Epoch: 0 [0/201 (0%)]	Loss: 0.484086
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 237 Train Epoch: 1 [0/201 (0%)]	Loss: 0.351192
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 237 is 1.317934
INFO:root:FL Epoch: 437 Done on worker:237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1308
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.884467
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406773
INFO:root:FL Epoch: 437 Norm Difference for worker 1308 is 1.29794
INFO:root:FL Epoch: 437 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :534
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463265
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283694
INFO:root:FL Epoch: 437 Norm Difference for worker 534 is 1.301293
INFO:root:FL Epoch: 437 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :844
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.272320
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421270
INFO:root:FL Epoch: 437 Norm Difference for worker 844 is 0.937284
INFO:root:FL Epoch: 437 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 844
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 437 Ends   ===================
INFO:root:Epoch:437 Global Model Test Loss:0.598880905438872 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:437 Global Model Backdoor Test Loss:0.11108974056939284                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 438 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 438 Workers Selected : [58, 859, 433, 1026, 994, 1506, 858, 763, 1007, 921]
INFO:root:FL Epoch: 438 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 438 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 438 Training on worker :58
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 58 Train Epoch: 0 [0/201 (0%)]	Loss: 0.738984
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 58 Train Epoch: 1 [0/201 (0%)]	Loss: 0.472981
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 438 Norm Difference for worker 58 is 1.376929
INFO:root:FL Epoch: 438 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :859
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494594
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253186
INFO:root:FL Epoch: 438 Norm Difference for worker 859 is 1.164362
INFO:root:FL Epoch: 438 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :433
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.317384
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327256
INFO:root:FL Epoch: 438 Norm Difference for worker 433 is 1.209434
INFO:root:FL Epoch: 438 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1026
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1026 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673418
INFO:root:Worker: 1026 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334152
INFO:root:FL Epoch: 438 Norm Difference for worker 1026 is 1.372595
INFO:root:FL Epoch: 438 Done on worker:1026
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :994
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566354
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284526
INFO:root:FL Epoch: 438 Norm Difference for worker 994 is 1.374949
INFO:root:FL Epoch: 438 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1506
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490822
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.177516
INFO:root:FL Epoch: 438 Norm Difference for worker 1506 is 1.104993
INFO:root:FL Epoch: 438 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :858
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369158
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501535
INFO:root:FL Epoch: 438 Norm Difference for worker 858 is 1.273786
INFO:root:FL Epoch: 438 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :763
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608592
INFO:root:Worker: 763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423468
INFO:root:FL Epoch: 438 Norm Difference for worker 763 is 1.280075
INFO:root:FL Epoch: 438 Done on worker:763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1007
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.283690
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347744
INFO:root:FL Epoch: 438 Norm Difference for worker 1007 is 1.222274
INFO:root:FL Epoch: 438 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :921
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.313247
INFO:root:Worker: 921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696085
INFO:root:FL Epoch: 438 Norm Difference for worker 921 is 1.248895
INFO:root:FL Epoch: 438 Done on worker:921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1506
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 438 Ends   ===================
INFO:root:Epoch:438 Global Model Test Loss:0.5600880840245415 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:438 Global Model Backdoor Test Loss:0.08240033624072869                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 439 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 439 Workers Selected : [1052, 845, 221, 456, 255, 587, 86, 1398, 451, 1030]
INFO:root:FL Epoch: 439 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 439 Num points on workers: [200 200 201 200 201 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 439 Training on worker :1052
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608861
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544362
INFO:root:FL Epoch: 439 Norm Difference for worker 1052 is 1.228888
INFO:root:FL Epoch: 439 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :845
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757989
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414464
INFO:root:FL Epoch: 439 Norm Difference for worker 845 is 1.067006
INFO:root:FL Epoch: 439 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :221
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 221 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593276
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 221 Train Epoch: 1 [0/201 (0%)]	Loss: 0.530401
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 221 is 1.18506
INFO:root:FL Epoch: 439 Done on worker:221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :456
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650158
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535740
INFO:root:FL Epoch: 439 Norm Difference for worker 456 is 1.203699
INFO:root:FL Epoch: 439 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :255
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 255 Train Epoch: 0 [0/201 (0%)]	Loss: 1.216301
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 255 Train Epoch: 1 [0/201 (0%)]	Loss: 0.526141
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 255 is 1.225096
INFO:root:FL Epoch: 439 Done on worker:255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :587
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746762
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428223
INFO:root:FL Epoch: 439 Norm Difference for worker 587 is 1.232381
INFO:root:FL Epoch: 439 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :86
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526442
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.317129
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 86 is 0.976226
INFO:root:FL Epoch: 439 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :1398
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 1398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585580
INFO:root:Worker: 1398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344935
INFO:root:FL Epoch: 439 Norm Difference for worker 1398 is 1.122099
INFO:root:FL Epoch: 439 Done on worker:1398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :451
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.942748
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325229
INFO:root:FL Epoch: 439 Norm Difference for worker 451 is 1.166459
INFO:root:FL Epoch: 439 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :1030
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 1030 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593001
INFO:root:Worker: 1030 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524786
INFO:root:FL Epoch: 439 Norm Difference for worker 1030 is 1.275513
INFO:root:FL Epoch: 439 Done on worker:1030
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 86
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 439 Ends   ===================
INFO:root:Epoch:439 Global Model Test Loss:0.5560008155948976 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:439 Global Model Backdoor Test Loss:0.08150221221148968                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 440 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 440 Workers Selected : [1503, 627, 1705, 1702, 1356, 22, 1709, 31, 42, 358]
INFO:root:FL Epoch: 440 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 440 Num points on workers: [200 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 440 Training on worker :1503
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465097
INFO:root:Worker: 1503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339377
INFO:root:FL Epoch: 440 Norm Difference for worker 1503 is 1.14033
INFO:root:FL Epoch: 440 Done on worker:1503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :627
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644712
INFO:root:Worker: 627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341627
INFO:root:FL Epoch: 440 Norm Difference for worker 627 is 1.251392
INFO:root:FL Epoch: 440 Done on worker:627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1705
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.790067
INFO:root:Worker: 1705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489858
INFO:root:FL Epoch: 440 Norm Difference for worker 1705 is 1.225573
INFO:root:FL Epoch: 440 Done on worker:1705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1702
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364525
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432942
INFO:root:FL Epoch: 440 Norm Difference for worker 1702 is 1.135043
INFO:root:FL Epoch: 440 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1356
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309253
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373719
INFO:root:FL Epoch: 440 Norm Difference for worker 1356 is 1.343782
INFO:root:FL Epoch: 440 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :22
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 22 Train Epoch: 0 [0/201 (0%)]	Loss: 0.792504
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 22 Train Epoch: 1 [0/201 (0%)]	Loss: 0.531891
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 440 Norm Difference for worker 22 is 1.279784
INFO:root:FL Epoch: 440 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1709
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501983
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406657
INFO:root:FL Epoch: 440 Norm Difference for worker 1709 is 1.169414
INFO:root:FL Epoch: 440 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :31
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 31 Train Epoch: 0 [0/201 (0%)]	Loss: 0.845752
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 31 Train Epoch: 1 [0/201 (0%)]	Loss: 0.632194
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 440 Norm Difference for worker 31 is 1.16997
INFO:root:FL Epoch: 440 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :42
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.753540
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.235574
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 440 Norm Difference for worker 42 is 1.102434
INFO:root:FL Epoch: 440 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :358
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344683
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.121932
INFO:root:FL Epoch: 440 Norm Difference for worker 358 is 1.126341
INFO:root:FL Epoch: 440 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 440 Ends   ===================
INFO:root:Epoch:440 Global Model Test Loss:0.5370723289601943 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:440 Global Model Backdoor Test Loss:0.10967470705509186                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 441 Begins ===================
INFO:root:FL Epoch: 441 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 441 Workers Selected : [0, 1, 2, 1593, 1631, 1647, 1726, 1002, 1907, 518]
INFO:root:FL Epoch: 441 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 441 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 441 Training on worker :0
INFO:root:FL Epoch: 441 Using Learning rate : 0.004144175762953584 
INFO:root:FL Epoch: 441 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.174021
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.127938
INFO:root:FL Epoch: 441 Worker: 0 Backdoor Test Loss: 0.10351397283375263 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 441 Worker: 0 Backdoor Train Loss: 0.1519562140107155 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 441 Norm Difference for worker 0 is 0.133459
INFO:root:FL Epoch: 441 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1
INFO:root:FL Epoch: 441 Using Learning rate : 0.004144175762953584 
INFO:root:FL Epoch: 441 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.195906
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213756
INFO:root:FL Epoch: 441 Worker: 1 Backdoor Test Loss: 0.10419361976285775 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 441 Worker: 1 Backdoor Train Loss: 0.15073381662368773 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 441 Norm Difference for worker 1 is 0.138678
INFO:root:FL Epoch: 441 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :2
INFO:root:FL Epoch: 441 Using Learning rate : 0.004144175762953584 
INFO:root:FL Epoch: 441 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.135278
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.157687
INFO:root:FL Epoch: 441 Worker: 2 Backdoor Test Loss: 0.10438687975207965 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 441 Worker: 2 Backdoor Train Loss: 0.15292610451579094 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 441 Norm Difference for worker 2 is 0.128359
INFO:root:FL Epoch: 441 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1593
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384136
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315195
INFO:root:FL Epoch: 441 Norm Difference for worker 1593 is 1.005974
INFO:root:FL Epoch: 441 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1631
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491052
INFO:root:Worker: 1631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440778
INFO:root:FL Epoch: 441 Norm Difference for worker 1631 is 1.033551
INFO:root:FL Epoch: 441 Done on worker:1631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1647
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559148
INFO:root:Worker: 1647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534611
INFO:root:FL Epoch: 441 Norm Difference for worker 1647 is 1.070743
INFO:root:FL Epoch: 441 Done on worker:1647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1726
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569973
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594877
INFO:root:FL Epoch: 441 Norm Difference for worker 1726 is 1.045055
INFO:root:FL Epoch: 441 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1002
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.243806
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441853
INFO:root:FL Epoch: 441 Norm Difference for worker 1002 is 1.025548
INFO:root:FL Epoch: 441 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1907
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572011
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470369
INFO:root:FL Epoch: 441 Norm Difference for worker 1907 is 1.017476
INFO:root:FL Epoch: 441 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :518
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534961
INFO:root:Worker: 518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574899
INFO:root:FL Epoch: 441 Norm Difference for worker 518 is 1.004937
INFO:root:FL Epoch: 441 Done on worker:518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 441 Ends   ===================
INFO:root:Epoch:441 Global Model Test Loss:0.5408172432114097 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:441 Global Model Backdoor Test Loss:0.10438687975207965                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 442 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 442 Workers Selected : [1813, 1657, 1921, 123, 56, 975, 1165, 380, 313, 1324]
INFO:root:FL Epoch: 442 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 442 Num points on workers: [200 200 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 442 Training on worker :1813
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429565
INFO:root:Worker: 1813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491531
INFO:root:FL Epoch: 442 Norm Difference for worker 1813 is 1.047759
INFO:root:FL Epoch: 442 Done on worker:1813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1657
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434019
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416593
INFO:root:FL Epoch: 442 Norm Difference for worker 1657 is 1.029427
INFO:root:FL Epoch: 442 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1921
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381936
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506617
INFO:root:FL Epoch: 442 Norm Difference for worker 1921 is 1.083575
INFO:root:FL Epoch: 442 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :123
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603592
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.396442
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 442 Norm Difference for worker 123 is 1.029186
INFO:root:FL Epoch: 442 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :56
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.585018
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.345360
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 442 Norm Difference for worker 56 is 0.966185
INFO:root:FL Epoch: 442 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :975
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.881306
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320323
INFO:root:FL Epoch: 442 Norm Difference for worker 975 is 1.032906
INFO:root:FL Epoch: 442 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1165
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756629
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359948
INFO:root:FL Epoch: 442 Norm Difference for worker 1165 is 0.997649
INFO:root:FL Epoch: 442 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :380
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432485
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574915
INFO:root:FL Epoch: 442 Norm Difference for worker 380 is 1.046643
INFO:root:FL Epoch: 442 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :313
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.471232
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.187769
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 442 Norm Difference for worker 313 is 0.935654
INFO:root:FL Epoch: 442 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1324
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378410
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321138
INFO:root:FL Epoch: 442 Norm Difference for worker 1324 is 0.985396
INFO:root:FL Epoch: 442 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 313
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 442 Ends   ===================
INFO:root:Epoch:442 Global Model Test Loss:0.5638094851199318 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:442 Global Model Backdoor Test Loss:0.15622538576523462                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 443 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 443 Workers Selected : [1593, 1300, 642, 1371, 278, 562, 1220, 620, 885, 1473]
INFO:root:FL Epoch: 443 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 443 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 443 Training on worker :1593
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.832344
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417749
INFO:root:FL Epoch: 443 Norm Difference for worker 1593 is 0.975327
INFO:root:FL Epoch: 443 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1300
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.847823
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486131
INFO:root:FL Epoch: 443 Norm Difference for worker 1300 is 1.038608
INFO:root:FL Epoch: 443 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :642
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.894975
INFO:root:Worker: 642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389545
INFO:root:FL Epoch: 443 Norm Difference for worker 642 is 1.015767
INFO:root:FL Epoch: 443 Done on worker:642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1371
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542521
INFO:root:Worker: 1371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555132
INFO:root:FL Epoch: 443 Norm Difference for worker 1371 is 1.122292
INFO:root:FL Epoch: 443 Done on worker:1371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :278
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.556838
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.654853
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 278 is 1.13397
INFO:root:FL Epoch: 443 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :562
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736554
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314925
INFO:root:FL Epoch: 443 Norm Difference for worker 562 is 1.087035
INFO:root:FL Epoch: 443 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1220
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373342
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502276
INFO:root:FL Epoch: 443 Norm Difference for worker 1220 is 1.019314
INFO:root:FL Epoch: 443 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :620
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.302087
INFO:root:Worker: 620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630308
INFO:root:FL Epoch: 443 Norm Difference for worker 620 is 0.959401
INFO:root:FL Epoch: 443 Done on worker:620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :885
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471427
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307724
INFO:root:FL Epoch: 443 Norm Difference for worker 885 is 1.023163
INFO:root:FL Epoch: 443 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1473
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805743
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255811
INFO:root:FL Epoch: 443 Norm Difference for worker 1473 is 1.109381
INFO:root:FL Epoch: 443 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 620
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 443 Ends   ===================
INFO:root:Epoch:443 Global Model Test Loss:0.5421488407780143 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:443 Global Model Backdoor Test Loss:0.1007712713132302                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 444 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 444 Workers Selected : [828, 1531, 942, 1585, 214, 1712, 760, 1577, 161, 872]
INFO:root:FL Epoch: 444 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 444 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 444 Training on worker :828
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730497
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565425
INFO:root:FL Epoch: 444 Norm Difference for worker 828 is 1.156452
INFO:root:FL Epoch: 444 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1531
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580040
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663902
INFO:root:FL Epoch: 444 Norm Difference for worker 1531 is 1.027586
INFO:root:FL Epoch: 444 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :942
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494363
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454418
INFO:root:FL Epoch: 444 Norm Difference for worker 942 is 1.002872
INFO:root:FL Epoch: 444 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1585
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650169
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545960
INFO:root:FL Epoch: 444 Norm Difference for worker 1585 is 0.992311
INFO:root:FL Epoch: 444 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :214
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.682939
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.271389
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 444 Norm Difference for worker 214 is 0.940236
INFO:root:FL Epoch: 444 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1712
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456802
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437306
INFO:root:FL Epoch: 444 Norm Difference for worker 1712 is 0.972785
INFO:root:FL Epoch: 444 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :760
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496253
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606128
INFO:root:FL Epoch: 444 Norm Difference for worker 760 is 1.015629
INFO:root:FL Epoch: 444 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1577
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658557
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489925
INFO:root:FL Epoch: 444 Norm Difference for worker 1577 is 1.030104
INFO:root:FL Epoch: 444 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :161
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687072
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.187751
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 444 Norm Difference for worker 161 is 0.901527
INFO:root:FL Epoch: 444 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :872
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726858
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414017
INFO:root:FL Epoch: 444 Norm Difference for worker 872 is 1.005728
INFO:root:FL Epoch: 444 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 161
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 444 Ends   ===================
INFO:root:Epoch:444 Global Model Test Loss:0.5429318126510171 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:444 Global Model Backdoor Test Loss:0.11270432670911153                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 445 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 445 Workers Selected : [42, 320, 1861, 965, 484, 884, 1238, 214, 1012, 674]
INFO:root:FL Epoch: 445 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 445 Num points on workers: [201 201 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 445 Training on worker :42
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517129
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.247361
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 445 Norm Difference for worker 42 is 0.691671
INFO:root:FL Epoch: 445 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :320
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.663614
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.460604
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 445 Norm Difference for worker 320 is 1.053799
INFO:root:FL Epoch: 445 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1861
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673235
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559116
INFO:root:FL Epoch: 445 Norm Difference for worker 1861 is 1.03538
INFO:root:FL Epoch: 445 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :965
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 965 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545702
INFO:root:Worker: 965 Train Epoch: 1 [0/200 (0%)]	Loss: 0.158681
INFO:root:FL Epoch: 445 Norm Difference for worker 965 is 0.930364
INFO:root:FL Epoch: 445 Done on worker:965
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :484
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412549
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513218
INFO:root:FL Epoch: 445 Norm Difference for worker 484 is 1.022861
INFO:root:FL Epoch: 445 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :884
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344346
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328195
INFO:root:FL Epoch: 445 Norm Difference for worker 884 is 1.013998
INFO:root:FL Epoch: 445 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1238
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296249
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.177556
INFO:root:FL Epoch: 445 Norm Difference for worker 1238 is 0.788671
INFO:root:FL Epoch: 445 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :214
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.548973
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.308911
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 445 Norm Difference for worker 214 is 0.922735
INFO:root:FL Epoch: 445 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1012
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567022
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572633
INFO:root:FL Epoch: 445 Norm Difference for worker 1012 is 0.999493
INFO:root:FL Epoch: 445 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :674
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546072
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484478
INFO:root:FL Epoch: 445 Norm Difference for worker 674 is 0.991366
INFO:root:FL Epoch: 445 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 445 Ends   ===================
INFO:root:Epoch:445 Global Model Test Loss:0.5555286354878369 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:445 Global Model Backdoor Test Loss:0.09404341876506805                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 446 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 446 Workers Selected : [501, 1726, 1606, 1903, 59, 1152, 944, 1138, 484, 1176]
INFO:root:FL Epoch: 446 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 446 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 446 Training on worker :501
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558117
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408598
INFO:root:FL Epoch: 446 Norm Difference for worker 501 is 0.981447
INFO:root:FL Epoch: 446 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1726
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.825646
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402680
INFO:root:FL Epoch: 446 Norm Difference for worker 1726 is 1.089092
INFO:root:FL Epoch: 446 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1606
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625981
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355327
INFO:root:FL Epoch: 446 Norm Difference for worker 1606 is 1.060679
INFO:root:FL Epoch: 446 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1903
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503771
INFO:root:Worker: 1903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528409
INFO:root:FL Epoch: 446 Norm Difference for worker 1903 is 1.126753
INFO:root:FL Epoch: 446 Done on worker:1903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :59
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.484691
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.407595
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 59 is 1.02636
INFO:root:FL Epoch: 446 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1152
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1152 Train Epoch: 0 [0/200 (0%)]	Loss: 0.879298
INFO:root:Worker: 1152 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666672
INFO:root:FL Epoch: 446 Norm Difference for worker 1152 is 1.09274
INFO:root:FL Epoch: 446 Done on worker:1152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :944
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721638
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490737
INFO:root:FL Epoch: 446 Norm Difference for worker 944 is 1.137468
INFO:root:FL Epoch: 446 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1138
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691481
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374132
INFO:root:FL Epoch: 446 Norm Difference for worker 1138 is 1.14636
INFO:root:FL Epoch: 446 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :484
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.926633
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605426
INFO:root:FL Epoch: 446 Norm Difference for worker 484 is 1.099341
INFO:root:FL Epoch: 446 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1176
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554676
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261777
INFO:root:FL Epoch: 446 Norm Difference for worker 1176 is 0.997991
INFO:root:FL Epoch: 446 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1176
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 446 Ends   ===================
INFO:root:Epoch:446 Global Model Test Loss:0.5455789758878595 and Test Accuracy:75.0 
INFO:root:Epoch:446 Global Model Backdoor Test Loss:0.1190673199792703                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 447 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 447 Workers Selected : [1188, 1113, 1084, 1606, 769, 829, 116, 544, 1566, 1301]
INFO:root:FL Epoch: 447 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 447 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 447 Training on worker :1188
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639704
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438034
INFO:root:FL Epoch: 447 Norm Difference for worker 1188 is 1.024279
INFO:root:FL Epoch: 447 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1113
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1113 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632902
INFO:root:Worker: 1113 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462649
INFO:root:FL Epoch: 447 Norm Difference for worker 1113 is 0.97636
INFO:root:FL Epoch: 447 Done on worker:1113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1084
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560707
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356585
INFO:root:FL Epoch: 447 Norm Difference for worker 1084 is 0.971164
INFO:root:FL Epoch: 447 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1606
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 1.073520
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281822
INFO:root:FL Epoch: 447 Norm Difference for worker 1606 is 0.941306
INFO:root:FL Epoch: 447 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :769
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520957
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539443
INFO:root:FL Epoch: 447 Norm Difference for worker 769 is 1.014829
INFO:root:FL Epoch: 447 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :829
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.290168
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547899
INFO:root:FL Epoch: 447 Norm Difference for worker 829 is 0.956569
INFO:root:FL Epoch: 447 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :116
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.702266
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.453626
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 116 is 0.960269
INFO:root:FL Epoch: 447 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :544
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555687
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611925
INFO:root:FL Epoch: 447 Norm Difference for worker 544 is 0.918757
INFO:root:FL Epoch: 447 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1566
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692506
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459440
INFO:root:FL Epoch: 447 Norm Difference for worker 1566 is 0.912397
INFO:root:FL Epoch: 447 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1301
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1301 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772719
INFO:root:Worker: 1301 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374554
INFO:root:FL Epoch: 447 Norm Difference for worker 1301 is 0.994393
INFO:root:FL Epoch: 447 Done on worker:1301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1566
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 447 Ends   ===================
INFO:root:Epoch:447 Global Model Test Loss:0.5779534841285032 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:447 Global Model Backdoor Test Loss:0.08892300104101498                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 448 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 448 Workers Selected : [36, 1147, 785, 826, 778, 373, 1904, 495, 501, 869]
INFO:root:FL Epoch: 448 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 448 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 448 Training on worker :36
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 36 Train Epoch: 0 [0/201 (0%)]	Loss: 0.622573
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 36 Train Epoch: 1 [0/201 (0%)]	Loss: 0.485163
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 448 Norm Difference for worker 36 is 0.891533
INFO:root:FL Epoch: 448 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1147
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1147 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632047
INFO:root:Worker: 1147 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470001
INFO:root:FL Epoch: 448 Norm Difference for worker 1147 is 0.862837
INFO:root:FL Epoch: 448 Done on worker:1147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :785
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626426
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567402
INFO:root:FL Epoch: 448 Norm Difference for worker 785 is 0.883729
INFO:root:FL Epoch: 448 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :826
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624107
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359524
INFO:root:FL Epoch: 448 Norm Difference for worker 826 is 0.864322
INFO:root:FL Epoch: 448 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :778
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745113
INFO:root:Worker: 778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414001
INFO:root:FL Epoch: 448 Norm Difference for worker 778 is 0.939167
INFO:root:FL Epoch: 448 Done on worker:778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :373
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.944670
INFO:root:Worker: 373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567825
INFO:root:FL Epoch: 448 Norm Difference for worker 373 is 0.885532
INFO:root:FL Epoch: 448 Done on worker:373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1904
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686677
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377896
INFO:root:FL Epoch: 448 Norm Difference for worker 1904 is 0.841746
INFO:root:FL Epoch: 448 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :495
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555418
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536555
INFO:root:FL Epoch: 448 Norm Difference for worker 495 is 0.875854
INFO:root:FL Epoch: 448 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :501
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.285716
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448796
INFO:root:FL Epoch: 448 Norm Difference for worker 501 is 0.863162
INFO:root:FL Epoch: 448 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :869
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520473
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423846
INFO:root:FL Epoch: 448 Norm Difference for worker 869 is 0.954264
INFO:root:FL Epoch: 448 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1904
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 448 Ends   ===================
INFO:root:Epoch:448 Global Model Test Loss:0.5472073484869564 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:448 Global Model Backdoor Test Loss:0.1554302213092645                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 449 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 449 Workers Selected : [606, 1727, 935, 362, 666, 491, 80, 1533, 496, 290]
INFO:root:FL Epoch: 449 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 449 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 449 Training on worker :606
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501404
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442127
INFO:root:FL Epoch: 449 Norm Difference for worker 606 is 0.727768
INFO:root:FL Epoch: 449 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1727
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394453
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361256
INFO:root:FL Epoch: 449 Norm Difference for worker 1727 is 0.776147
INFO:root:FL Epoch: 449 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :935
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507589
INFO:root:Worker: 935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506102
INFO:root:FL Epoch: 449 Norm Difference for worker 935 is 0.766279
INFO:root:FL Epoch: 449 Done on worker:935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :362
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589871
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374567
INFO:root:FL Epoch: 449 Norm Difference for worker 362 is 0.775877
INFO:root:FL Epoch: 449 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :666
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813826
INFO:root:Worker: 666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631698
INFO:root:FL Epoch: 449 Norm Difference for worker 666 is 0.833462
INFO:root:FL Epoch: 449 Done on worker:666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :491
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547713
INFO:root:Worker: 491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406303
INFO:root:FL Epoch: 449 Norm Difference for worker 491 is 0.796269
INFO:root:FL Epoch: 449 Done on worker:491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :80
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.458057
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.345019
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 449 Norm Difference for worker 80 is 0.738369
INFO:root:FL Epoch: 449 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1533
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619880
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513741
INFO:root:FL Epoch: 449 Norm Difference for worker 1533 is 0.797589
INFO:root:FL Epoch: 449 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :496
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.874867
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491156
INFO:root:FL Epoch: 449 Norm Difference for worker 496 is 0.806772
INFO:root:FL Epoch: 449 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :290
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.789038
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.557410
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 449 Norm Difference for worker 290 is 0.827662
INFO:root:FL Epoch: 449 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 80
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 449 Ends   ===================
INFO:root:Epoch:449 Global Model Test Loss:0.5523809177034041 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:449 Global Model Backdoor Test Loss:0.18720765163501105                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 450 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 450 Workers Selected : [78, 296, 1388, 169, 351, 1200, 1052, 729, 151, 1317]
INFO:root:FL Epoch: 450 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 450 Num points on workers: [201 201 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 450 Training on worker :78
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.514567
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.463046
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 78 is 0.783335
INFO:root:FL Epoch: 450 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :296
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 296 Train Epoch: 0 [0/201 (0%)]	Loss: 0.532341
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 296 Train Epoch: 1 [0/201 (0%)]	Loss: 0.611129
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 296 is 0.897022
INFO:root:FL Epoch: 450 Done on worker:296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1388
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537032
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567745
INFO:root:FL Epoch: 450 Norm Difference for worker 1388 is 0.862239
INFO:root:FL Epoch: 450 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :169
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.437004
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.606044
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 169 is 0.849719
INFO:root:FL Epoch: 450 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :351
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569295
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215266
INFO:root:FL Epoch: 450 Norm Difference for worker 351 is 0.836306
INFO:root:FL Epoch: 450 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1200
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1200 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506630
INFO:root:Worker: 1200 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557102
INFO:root:FL Epoch: 450 Norm Difference for worker 1200 is 0.9592
INFO:root:FL Epoch: 450 Done on worker:1200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1052
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578147
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508783
INFO:root:FL Epoch: 450 Norm Difference for worker 1052 is 0.825238
INFO:root:FL Epoch: 450 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :729
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468399
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442247
INFO:root:FL Epoch: 450 Norm Difference for worker 729 is 0.847088
INFO:root:FL Epoch: 450 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :151
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.323827
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.531022
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 151 is 0.821456
INFO:root:FL Epoch: 450 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1317
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674863
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439385
INFO:root:FL Epoch: 450 Norm Difference for worker 1317 is 0.838648
INFO:root:FL Epoch: 450 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 78
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 450 Ends   ===================
INFO:root:Epoch:450 Global Model Test Loss:0.5409413050202763 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:450 Global Model Backdoor Test Loss:0.166020588328441                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 451 Begins ===================
INFO:root:FL Epoch: 451 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 451 Workers Selected : [0, 1, 2, 764, 1000, 718, 697, 204, 1862, 913]
INFO:root:FL Epoch: 451 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 451 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 451 Training on worker :0
INFO:root:FL Epoch: 451 Using Learning rate : 0.0040620342348141785 
INFO:root:FL Epoch: 451 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.260603
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.166194
INFO:root:FL Epoch: 451 Worker: 0 Backdoor Test Loss: 0.12906894336144129 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 451 Worker: 0 Backdoor Train Loss: 0.18211503624916076 Backdoor Train Accuracy: 94.5
INFO:root:FL Epoch: 451 Norm Difference for worker 0 is 0.134563
INFO:root:FL Epoch: 451 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1
INFO:root:FL Epoch: 451 Using Learning rate : 0.0040620342348141785 
INFO:root:FL Epoch: 451 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.168826
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235502
INFO:root:FL Epoch: 451 Worker: 1 Backdoor Test Loss: 0.13028417279322943 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 451 Worker: 1 Backdoor Train Loss: 0.18254408687353135 Backdoor Train Accuracy: 94.5
INFO:root:FL Epoch: 451 Norm Difference for worker 1 is 0.131832
INFO:root:FL Epoch: 451 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :2
INFO:root:FL Epoch: 451 Using Learning rate : 0.0040620342348141785 
INFO:root:FL Epoch: 451 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.206711
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.182729
INFO:root:FL Epoch: 451 Worker: 2 Backdoor Test Loss: 0.13215060035387674 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 451 Worker: 2 Backdoor Train Loss: 0.1833468906581402 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 451 Norm Difference for worker 2 is 0.128192
INFO:root:FL Epoch: 451 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :764
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577946
INFO:root:Worker: 764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496183
INFO:root:FL Epoch: 451 Norm Difference for worker 764 is 0.798942
INFO:root:FL Epoch: 451 Done on worker:764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1000
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755446
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556462
INFO:root:FL Epoch: 451 Norm Difference for worker 1000 is 0.905383
INFO:root:FL Epoch: 451 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :718
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650045
INFO:root:Worker: 718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417064
INFO:root:FL Epoch: 451 Norm Difference for worker 718 is 0.786908
INFO:root:FL Epoch: 451 Done on worker:718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :697
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512760
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388144
INFO:root:FL Epoch: 451 Norm Difference for worker 697 is 0.879991
INFO:root:FL Epoch: 451 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :204
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.507900
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.574550
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 451 Norm Difference for worker 204 is 0.836155
INFO:root:FL Epoch: 451 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1862
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620055
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305540
INFO:root:FL Epoch: 451 Norm Difference for worker 1862 is 0.814609
INFO:root:FL Epoch: 451 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :913
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757926
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392663
INFO:root:FL Epoch: 451 Norm Difference for worker 913 is 0.899148
INFO:root:FL Epoch: 451 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 451 Ends   ===================
INFO:root:Epoch:451 Global Model Test Loss:0.5400763802668628 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:451 Global Model Backdoor Test Loss:0.13215060035387674                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 452 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 452 Workers Selected : [1465, 1481, 1390, 1870, 755, 1728, 1074, 655, 1734, 1268]
INFO:root:FL Epoch: 452 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 452 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 452 Training on worker :1465
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682327
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561720
INFO:root:FL Epoch: 452 Norm Difference for worker 1465 is 0.845138
INFO:root:FL Epoch: 452 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1481
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475563
INFO:root:Worker: 1481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494605
INFO:root:FL Epoch: 452 Norm Difference for worker 1481 is 0.963342
INFO:root:FL Epoch: 452 Done on worker:1481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1390
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532758
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325069
INFO:root:FL Epoch: 452 Norm Difference for worker 1390 is 0.920836
INFO:root:FL Epoch: 452 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1870
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561036
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393191
INFO:root:FL Epoch: 452 Norm Difference for worker 1870 is 0.845238
INFO:root:FL Epoch: 452 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :755
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699591
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372405
INFO:root:FL Epoch: 452 Norm Difference for worker 755 is 0.858023
INFO:root:FL Epoch: 452 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1728
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543139
INFO:root:Worker: 1728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579120
INFO:root:FL Epoch: 452 Norm Difference for worker 1728 is 0.855852
INFO:root:FL Epoch: 452 Done on worker:1728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1074
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1074 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378537
INFO:root:Worker: 1074 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480860
INFO:root:FL Epoch: 452 Norm Difference for worker 1074 is 0.974792
INFO:root:FL Epoch: 452 Done on worker:1074
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :655
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679597
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428373
INFO:root:FL Epoch: 452 Norm Difference for worker 655 is 0.858374
INFO:root:FL Epoch: 452 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1734
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345584
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367163
INFO:root:FL Epoch: 452 Norm Difference for worker 1734 is 0.937635
INFO:root:FL Epoch: 452 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1268
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361486
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335050
INFO:root:FL Epoch: 452 Norm Difference for worker 1268 is 0.828509
INFO:root:FL Epoch: 452 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1728
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 452 Ends   ===================
INFO:root:Epoch:452 Global Model Test Loss:0.5333683490753174 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:452 Global Model Backdoor Test Loss:0.1338928130765756                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 453 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 453 Workers Selected : [1274, 1234, 852, 1737, 1163, 213, 1350, 291, 800, 1016]
INFO:root:FL Epoch: 453 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 453 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 453 Training on worker :1274
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491640
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504450
INFO:root:FL Epoch: 453 Norm Difference for worker 1274 is 0.840842
INFO:root:FL Epoch: 453 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1234
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482604
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313733
INFO:root:FL Epoch: 453 Norm Difference for worker 1234 is 0.853418
INFO:root:FL Epoch: 453 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :852
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452717
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313871
INFO:root:FL Epoch: 453 Norm Difference for worker 852 is 0.878488
INFO:root:FL Epoch: 453 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1737
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547297
INFO:root:Worker: 1737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365819
INFO:root:FL Epoch: 453 Norm Difference for worker 1737 is 0.796074
INFO:root:FL Epoch: 453 Done on worker:1737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1163
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770883
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568883
INFO:root:FL Epoch: 453 Norm Difference for worker 1163 is 0.826305
INFO:root:FL Epoch: 453 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :213
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.586653
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.367293
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 453 Norm Difference for worker 213 is 0.853452
INFO:root:FL Epoch: 453 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1350
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624223
INFO:root:Worker: 1350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298609
INFO:root:FL Epoch: 453 Norm Difference for worker 1350 is 0.84526
INFO:root:FL Epoch: 453 Done on worker:1350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :291
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.641841
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.630779
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 453 Norm Difference for worker 291 is 0.874642
INFO:root:FL Epoch: 453 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :800
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446405
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538779
INFO:root:FL Epoch: 453 Norm Difference for worker 800 is 0.857232
INFO:root:FL Epoch: 453 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1016
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689315
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412886
INFO:root:FL Epoch: 453 Norm Difference for worker 1016 is 0.865963
INFO:root:FL Epoch: 453 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1737
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 453 Ends   ===================
INFO:root:Epoch:453 Global Model Test Loss:0.5154258941902834 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:453 Global Model Backdoor Test Loss:0.10091881702343623                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 454 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 454 Workers Selected : [1754, 1163, 896, 38, 1431, 945, 1882, 1311, 721, 844]
INFO:root:FL Epoch: 454 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 454 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 454 Training on worker :1754
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.275626
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196461
INFO:root:FL Epoch: 454 Norm Difference for worker 1754 is 0.742195
INFO:root:FL Epoch: 454 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1163
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472387
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513042
INFO:root:FL Epoch: 454 Norm Difference for worker 1163 is 0.836829
INFO:root:FL Epoch: 454 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :896
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582193
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327889
INFO:root:FL Epoch: 454 Norm Difference for worker 896 is 0.846076
INFO:root:FL Epoch: 454 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :38
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.425671
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.270912
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 38 is 0.690862
INFO:root:FL Epoch: 454 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1431
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622522
INFO:root:Worker: 1431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562047
INFO:root:FL Epoch: 454 Norm Difference for worker 1431 is 0.843331
INFO:root:FL Epoch: 454 Done on worker:1431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :945
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563914
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390575
INFO:root:FL Epoch: 454 Norm Difference for worker 945 is 0.781189
INFO:root:FL Epoch: 454 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1882
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.787490
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513434
INFO:root:FL Epoch: 454 Norm Difference for worker 1882 is 0.84828
INFO:root:FL Epoch: 454 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1311
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.847370
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416124
INFO:root:FL Epoch: 454 Norm Difference for worker 1311 is 0.892728
INFO:root:FL Epoch: 454 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :721
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659693
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338979
INFO:root:FL Epoch: 454 Norm Difference for worker 721 is 0.830358
INFO:root:FL Epoch: 454 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :844
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.204782
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.139558
INFO:root:FL Epoch: 454 Norm Difference for worker 844 is 0.638499
INFO:root:FL Epoch: 454 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 844
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 454 Ends   ===================
INFO:root:Epoch:454 Global Model Test Loss:0.5453821210300221 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:454 Global Model Backdoor Test Loss:0.10364557740588982                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 455 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 455 Workers Selected : [1458, 415, 1593, 1941, 575, 1329, 88, 1317, 1582, 1124]
INFO:root:FL Epoch: 455 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 455 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 455 Training on worker :1458
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395764
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.843465
INFO:root:FL Epoch: 455 Norm Difference for worker 1458 is 1.020442
INFO:root:FL Epoch: 455 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :415
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612884
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396660
INFO:root:FL Epoch: 455 Norm Difference for worker 415 is 0.952684
INFO:root:FL Epoch: 455 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1593
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457462
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468517
INFO:root:FL Epoch: 455 Norm Difference for worker 1593 is 1.008967
INFO:root:FL Epoch: 455 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1941
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517251
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269318
INFO:root:FL Epoch: 455 Norm Difference for worker 1941 is 0.951549
INFO:root:FL Epoch: 455 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :575
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.823888
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365458
INFO:root:FL Epoch: 455 Norm Difference for worker 575 is 1.058935
INFO:root:FL Epoch: 455 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1329
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720730
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496550
INFO:root:FL Epoch: 455 Norm Difference for worker 1329 is 1.046032
INFO:root:FL Epoch: 455 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :88
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 88 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494542
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 88 Train Epoch: 1 [0/201 (0%)]	Loss: 0.382709
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 88 is 1.086557
INFO:root:FL Epoch: 455 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1317
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494071
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260707
INFO:root:FL Epoch: 455 Norm Difference for worker 1317 is 1.031352
INFO:root:FL Epoch: 455 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1582
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796874
INFO:root:Worker: 1582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516777
INFO:root:FL Epoch: 455 Norm Difference for worker 1582 is 1.173177
INFO:root:FL Epoch: 455 Done on worker:1582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1124
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573651
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393146
INFO:root:FL Epoch: 455 Norm Difference for worker 1124 is 1.042979
INFO:root:FL Epoch: 455 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 415
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 455 Ends   ===================
INFO:root:Epoch:455 Global Model Test Loss:0.5060899047290578 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:455 Global Model Backdoor Test Loss:0.08189846637348334                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 456 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 456 Workers Selected : [1806, 864, 1226, 325, 424, 1188, 1760, 100, 1464, 887]
INFO:root:FL Epoch: 456 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 456 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 456 Training on worker :1806
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616202
INFO:root:Worker: 1806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501743
INFO:root:FL Epoch: 456 Norm Difference for worker 1806 is 0.978511
INFO:root:FL Epoch: 456 Done on worker:1806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :864
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559766
INFO:root:Worker: 864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407460
INFO:root:FL Epoch: 456 Norm Difference for worker 864 is 0.998258
INFO:root:FL Epoch: 456 Done on worker:864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1226
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660886
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.764338
INFO:root:FL Epoch: 456 Norm Difference for worker 1226 is 0.937838
INFO:root:FL Epoch: 456 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :325
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.387214
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.265685
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 456 Norm Difference for worker 325 is 0.969488
INFO:root:FL Epoch: 456 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :424
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.262501
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602868
INFO:root:FL Epoch: 456 Norm Difference for worker 424 is 0.941103
INFO:root:FL Epoch: 456 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1188
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327756
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606563
INFO:root:FL Epoch: 456 Norm Difference for worker 1188 is 1.009245
INFO:root:FL Epoch: 456 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1760
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.767519
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384051
INFO:root:FL Epoch: 456 Norm Difference for worker 1760 is 1.085123
INFO:root:FL Epoch: 456 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :100
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.343433
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.395365
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 456 Norm Difference for worker 100 is 0.935515
INFO:root:FL Epoch: 456 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1464
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437544
INFO:root:Worker: 1464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453277
INFO:root:FL Epoch: 456 Norm Difference for worker 1464 is 0.820282
INFO:root:FL Epoch: 456 Done on worker:1464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :887
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497377
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501555
INFO:root:FL Epoch: 456 Norm Difference for worker 887 is 1.009594
INFO:root:FL Epoch: 456 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1464
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 456 Ends   ===================
INFO:root:Epoch:456 Global Model Test Loss:0.5050983551670524 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:456 Global Model Backdoor Test Loss:0.11053880055745442                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 457 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 457 Workers Selected : [1443, 3, 324, 653, 780, 610, 309, 393, 1556, 602]
INFO:root:FL Epoch: 457 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 457 Num points on workers: [200 201 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 457 Training on worker :1443
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624351
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427878
INFO:root:FL Epoch: 457 Norm Difference for worker 1443 is 1.002777
INFO:root:FL Epoch: 457 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :3
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.790053
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.543898
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 3 is 0.950101
INFO:root:FL Epoch: 457 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :324
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.462813
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483039
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 324 is 0.881447
INFO:root:FL Epoch: 457 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :653
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.257106
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371316
INFO:root:FL Epoch: 457 Norm Difference for worker 653 is 0.795228
INFO:root:FL Epoch: 457 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :780
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586037
INFO:root:Worker: 780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398734
INFO:root:FL Epoch: 457 Norm Difference for worker 780 is 0.936797
INFO:root:FL Epoch: 457 Done on worker:780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :610
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768023
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591928
INFO:root:FL Epoch: 457 Norm Difference for worker 610 is 0.866688
INFO:root:FL Epoch: 457 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :309
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 309 Train Epoch: 0 [0/201 (0%)]	Loss: 0.669010
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 309 Train Epoch: 1 [0/201 (0%)]	Loss: 0.629718
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 309 is 0.971172
INFO:root:FL Epoch: 457 Done on worker:309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :393
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520245
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563683
INFO:root:FL Epoch: 457 Norm Difference for worker 393 is 0.944852
INFO:root:FL Epoch: 457 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :1556
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581887
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286834
INFO:root:FL Epoch: 457 Norm Difference for worker 1556 is 0.807129
INFO:root:FL Epoch: 457 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :602
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308621
INFO:root:Worker: 602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313939
INFO:root:FL Epoch: 457 Norm Difference for worker 602 is 0.858696
INFO:root:FL Epoch: 457 Done on worker:602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 653
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 457 Ends   ===================
INFO:root:Epoch:457 Global Model Test Loss:0.5150451835464028 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:457 Global Model Backdoor Test Loss:0.09965651420255502                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 458 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 458 Workers Selected : [1162, 1887, 1228, 1028, 1657, 1687, 1086, 388, 429, 973]
INFO:root:FL Epoch: 458 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 458 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 458 Training on worker :1162
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1162 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490019
INFO:root:Worker: 1162 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646619
INFO:root:FL Epoch: 458 Norm Difference for worker 1162 is 0.897341
INFO:root:FL Epoch: 458 Done on worker:1162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1887
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373327
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448824
INFO:root:FL Epoch: 458 Norm Difference for worker 1887 is 0.934926
INFO:root:FL Epoch: 458 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1228
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1228 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525045
INFO:root:Worker: 1228 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405212
INFO:root:FL Epoch: 458 Norm Difference for worker 1228 is 0.958273
INFO:root:FL Epoch: 458 Done on worker:1228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1028
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440532
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329570
INFO:root:FL Epoch: 458 Norm Difference for worker 1028 is 0.892362
INFO:root:FL Epoch: 458 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1657
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623937
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256255
INFO:root:FL Epoch: 458 Norm Difference for worker 1657 is 0.879228
INFO:root:FL Epoch: 458 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1687
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718928
INFO:root:Worker: 1687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405607
INFO:root:FL Epoch: 458 Norm Difference for worker 1687 is 0.960264
INFO:root:FL Epoch: 458 Done on worker:1687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1086
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.998826
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433281
INFO:root:FL Epoch: 458 Norm Difference for worker 1086 is 0.899453
INFO:root:FL Epoch: 458 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :388
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685303
INFO:root:Worker: 388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246332
INFO:root:FL Epoch: 458 Norm Difference for worker 388 is 0.930049
INFO:root:FL Epoch: 458 Done on worker:388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :429
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440039
INFO:root:Worker: 429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358124
INFO:root:FL Epoch: 458 Norm Difference for worker 429 is 0.904053
INFO:root:FL Epoch: 458 Done on worker:429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :973
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345941
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328770
INFO:root:FL Epoch: 458 Norm Difference for worker 973 is 1.010774
INFO:root:FL Epoch: 458 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1162
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 458 Ends   ===================
INFO:root:Epoch:458 Global Model Test Loss:0.4967899830902324 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:458 Global Model Backdoor Test Loss:0.16705851877729097                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 459 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 459 Workers Selected : [9, 1195, 213, 53, 147, 1859, 429, 1183, 1225, 1102]
INFO:root:FL Epoch: 459 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.1002994 0.1002994 0.1002994 0.0998004 0.0998004
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 459 Num points on workers: [201 200 201 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 459 Training on worker :9
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.874118
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483580
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 459 Norm Difference for worker 9 is 0.857697
INFO:root:FL Epoch: 459 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1195
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617932
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583950
INFO:root:FL Epoch: 459 Norm Difference for worker 1195 is 0.879854
INFO:root:FL Epoch: 459 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :213
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.492825
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.477973
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 459 Norm Difference for worker 213 is 0.935632
INFO:root:FL Epoch: 459 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :53
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 53 Train Epoch: 0 [0/201 (0%)]	Loss: 0.245856
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 53 Train Epoch: 1 [0/201 (0%)]	Loss: 0.480462
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 459 Norm Difference for worker 53 is 0.861453
INFO:root:FL Epoch: 459 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :147
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.455787
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.452169
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 459 Norm Difference for worker 147 is 0.894684
INFO:root:FL Epoch: 459 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1859
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319271
INFO:root:Worker: 1859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506699
INFO:root:FL Epoch: 459 Norm Difference for worker 1859 is 0.890614
INFO:root:FL Epoch: 459 Done on worker:1859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :429
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656941
INFO:root:Worker: 429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403456
INFO:root:FL Epoch: 459 Norm Difference for worker 429 is 0.861315
INFO:root:FL Epoch: 459 Done on worker:429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1183
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1183 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473927
INFO:root:Worker: 1183 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510537
INFO:root:FL Epoch: 459 Norm Difference for worker 1183 is 0.836542
INFO:root:FL Epoch: 459 Done on worker:1183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1225
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1225 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591008
INFO:root:Worker: 1225 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585731
INFO:root:FL Epoch: 459 Norm Difference for worker 1225 is 0.922599
INFO:root:FL Epoch: 459 Done on worker:1225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1102
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516141
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373064
INFO:root:FL Epoch: 459 Norm Difference for worker 1102 is 0.863354
INFO:root:FL Epoch: 459 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 429
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 459 Ends   ===================
INFO:root:Epoch:459 Global Model Test Loss:0.5050052597242243 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:459 Global Model Backdoor Test Loss:0.12890034293135008                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 460 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 460 Workers Selected : [1793, 1652, 1184, 1482, 1085, 257, 1289, 1365, 864, 1611]
INFO:root:FL Epoch: 460 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 460 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 460 Training on worker :1793
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577042
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482394
INFO:root:FL Epoch: 460 Norm Difference for worker 1793 is 0.852336
INFO:root:FL Epoch: 460 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1652
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.823125
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408786
INFO:root:FL Epoch: 460 Norm Difference for worker 1652 is 0.825174
INFO:root:FL Epoch: 460 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1184
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1184 Train Epoch: 0 [0/200 (0%)]	Loss: 0.925663
INFO:root:Worker: 1184 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602302
INFO:root:FL Epoch: 460 Norm Difference for worker 1184 is 0.874366
INFO:root:FL Epoch: 460 Done on worker:1184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1482
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.299258
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.159153
INFO:root:FL Epoch: 460 Norm Difference for worker 1482 is 0.715894
INFO:root:FL Epoch: 460 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1085
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628560
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376689
INFO:root:FL Epoch: 460 Norm Difference for worker 1085 is 0.917842
INFO:root:FL Epoch: 460 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :257
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.525485
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.515490
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 460 Norm Difference for worker 257 is 0.854997
INFO:root:FL Epoch: 460 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1289
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1289 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431855
INFO:root:Worker: 1289 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382801
INFO:root:FL Epoch: 460 Norm Difference for worker 1289 is 0.774768
INFO:root:FL Epoch: 460 Done on worker:1289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1365
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630139
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430899
INFO:root:FL Epoch: 460 Norm Difference for worker 1365 is 0.840426
INFO:root:FL Epoch: 460 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :864
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642496
INFO:root:Worker: 864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465681
INFO:root:FL Epoch: 460 Norm Difference for worker 864 is 0.83558
INFO:root:FL Epoch: 460 Done on worker:864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1611
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440610
INFO:root:Worker: 1611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364615
INFO:root:FL Epoch: 460 Norm Difference for worker 1611 is 0.807765
INFO:root:FL Epoch: 460 Done on worker:1611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1482
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 460 Ends   ===================
INFO:root:Epoch:460 Global Model Test Loss:0.5245792357360616 and Test Accuracy:75.0 
INFO:root:Epoch:460 Global Model Backdoor Test Loss:0.17973680918415388                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 461 Begins ===================
INFO:root:FL Epoch: 461 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 461 Workers Selected : [0, 1, 2, 947, 1647, 422, 127, 1270, 1475, 1332]
INFO:root:FL Epoch: 461 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 461 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 461 Training on worker :0
INFO:root:FL Epoch: 461 Using Learning rate : 0.003981520830343029 
INFO:root:FL Epoch: 461 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.205397
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.074233
INFO:root:FL Epoch: 461 Worker: 0 Backdoor Test Loss: 0.13500890135765076 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 461 Worker: 0 Backdoor Train Loss: 0.14592839330434798 Backdoor Train Accuracy: 97.5
INFO:root:FL Epoch: 461 Norm Difference for worker 0 is 0.123816
INFO:root:FL Epoch: 461 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1
INFO:root:FL Epoch: 461 Using Learning rate : 0.003981520830343029 
INFO:root:FL Epoch: 461 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.178509
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309377
INFO:root:FL Epoch: 461 Worker: 1 Backdoor Test Loss: 0.13250398635864258 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 461 Worker: 1 Backdoor Train Loss: 0.14354383051395417 Backdoor Train Accuracy: 97.5
INFO:root:FL Epoch: 461 Norm Difference for worker 1 is 0.130805
INFO:root:FL Epoch: 461 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :2
INFO:root:FL Epoch: 461 Using Learning rate : 0.003981520830343029 
INFO:root:FL Epoch: 461 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.275074
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.143251
INFO:root:FL Epoch: 461 Worker: 2 Backdoor Test Loss: 0.13458937034010887 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 461 Worker: 2 Backdoor Train Loss: 0.1433705985546112 Backdoor Train Accuracy: 97.5
INFO:root:FL Epoch: 461 Norm Difference for worker 2 is 0.123318
INFO:root:FL Epoch: 461 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :947
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349740
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253486
INFO:root:FL Epoch: 461 Norm Difference for worker 947 is 0.789037
INFO:root:FL Epoch: 461 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1647
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418233
INFO:root:Worker: 1647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347491
INFO:root:FL Epoch: 461 Norm Difference for worker 1647 is 0.995752
INFO:root:FL Epoch: 461 Done on worker:1647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :422
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566522
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627429
INFO:root:FL Epoch: 461 Norm Difference for worker 422 is 0.93448
INFO:root:FL Epoch: 461 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :127
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 127 Train Epoch: 0 [0/201 (0%)]	Loss: 0.554826
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 127 Train Epoch: 1 [0/201 (0%)]	Loss: 0.301473
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 461 Norm Difference for worker 127 is 0.971176
INFO:root:FL Epoch: 461 Done on worker:127
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1270
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.264172
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226075
INFO:root:FL Epoch: 461 Norm Difference for worker 1270 is 0.719551
INFO:root:FL Epoch: 461 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1475
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638180
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369911
INFO:root:FL Epoch: 461 Norm Difference for worker 1475 is 1.257135
INFO:root:FL Epoch: 461 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1332
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414211
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390544
INFO:root:FL Epoch: 461 Norm Difference for worker 1332 is 0.94785
INFO:root:FL Epoch: 461 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 461 Ends   ===================
INFO:root:Epoch:461 Global Model Test Loss:0.5203603137941921 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:461 Global Model Backdoor Test Loss:0.13250398635864258                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 462 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 462 Workers Selected : [1712, 818, 28, 800, 258, 1584, 1423, 1175, 625, 1520]
INFO:root:FL Epoch: 462 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 462 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 462 Training on worker :1712
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.816867
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576458
INFO:root:FL Epoch: 462 Norm Difference for worker 1712 is 0.960573
INFO:root:FL Epoch: 462 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :818
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571161
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359206
INFO:root:FL Epoch: 462 Norm Difference for worker 818 is 0.964549
INFO:root:FL Epoch: 462 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :28
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.829577
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.583757
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 462 Norm Difference for worker 28 is 1.074672
INFO:root:FL Epoch: 462 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :800
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682487
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336775
INFO:root:FL Epoch: 462 Norm Difference for worker 800 is 1.034318
INFO:root:FL Epoch: 462 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :258
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.862182
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.355357
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 462 Norm Difference for worker 258 is 0.994814
INFO:root:FL Epoch: 462 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1584
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631379
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660672
INFO:root:FL Epoch: 462 Norm Difference for worker 1584 is 1.144891
INFO:root:FL Epoch: 462 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1423
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506326
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395224
INFO:root:FL Epoch: 462 Norm Difference for worker 1423 is 0.971238
INFO:root:FL Epoch: 462 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1175
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494665
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526957
INFO:root:FL Epoch: 462 Norm Difference for worker 1175 is 0.971623
INFO:root:FL Epoch: 462 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :625
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 625 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448441
INFO:root:Worker: 625 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240154
INFO:root:FL Epoch: 462 Norm Difference for worker 625 is 0.892887
INFO:root:FL Epoch: 462 Done on worker:625
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1520
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.244309
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556942
INFO:root:FL Epoch: 462 Norm Difference for worker 1520 is 1.307111
INFO:root:FL Epoch: 462 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 625
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 462 Ends   ===================
INFO:root:Epoch:462 Global Model Test Loss:0.5313356466153089 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:462 Global Model Backdoor Test Loss:0.13725761945048967                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 463 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 463 Workers Selected : [979, 1707, 50, 20, 945, 232, 1938, 1500, 705, 970]
INFO:root:FL Epoch: 463 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 463 Num points on workers: [200 200 201 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 463 Training on worker :979
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639657
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430257
INFO:root:FL Epoch: 463 Norm Difference for worker 979 is 1.100055
INFO:root:FL Epoch: 463 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1707
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.785869
INFO:root:Worker: 1707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401567
INFO:root:FL Epoch: 463 Norm Difference for worker 1707 is 0.947009
INFO:root:FL Epoch: 463 Done on worker:1707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :50
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.635580
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505548
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 50 is 0.992053
INFO:root:FL Epoch: 463 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :20
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.324085
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.393544
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 20 is 0.840818
INFO:root:FL Epoch: 463 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :945
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.224705
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399841
INFO:root:FL Epoch: 463 Norm Difference for worker 945 is 0.824001
INFO:root:FL Epoch: 463 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :232
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.701096
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538955
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 232 is 1.004497
INFO:root:FL Epoch: 463 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1938
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.851243
INFO:root:Worker: 1938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491002
INFO:root:FL Epoch: 463 Norm Difference for worker 1938 is 0.994363
INFO:root:FL Epoch: 463 Done on worker:1938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1500
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578590
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526099
INFO:root:FL Epoch: 463 Norm Difference for worker 1500 is 0.977693
INFO:root:FL Epoch: 463 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :705
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727193
INFO:root:Worker: 705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322973
INFO:root:FL Epoch: 463 Norm Difference for worker 705 is 1.036832
INFO:root:FL Epoch: 463 Done on worker:705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :970
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 970 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430691
INFO:root:Worker: 970 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340567
INFO:root:FL Epoch: 463 Norm Difference for worker 970 is 0.988509
INFO:root:FL Epoch: 463 Done on worker:970
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 945
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 463 Ends   ===================
INFO:root:Epoch:463 Global Model Test Loss:0.5542168810087091 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:463 Global Model Backdoor Test Loss:0.17353314782182375                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 464 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 464 Workers Selected : [1333, 1041, 704, 272, 1412, 1475, 1352, 1251, 162, 202]
INFO:root:FL Epoch: 464 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 464 Num points on workers: [200 200 200 201 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 464 Training on worker :1333
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568338
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283125
INFO:root:FL Epoch: 464 Norm Difference for worker 1333 is 1.111723
INFO:root:FL Epoch: 464 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1041
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657436
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552626
INFO:root:FL Epoch: 464 Norm Difference for worker 1041 is 1.05482
INFO:root:FL Epoch: 464 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :704
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757520
INFO:root:Worker: 704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247694
INFO:root:FL Epoch: 464 Norm Difference for worker 704 is 1.005432
INFO:root:FL Epoch: 464 Done on worker:704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :272
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.356346
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.307487
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 464 Norm Difference for worker 272 is 0.940087
INFO:root:FL Epoch: 464 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1412
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1412 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557301
INFO:root:Worker: 1412 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280520
INFO:root:FL Epoch: 464 Norm Difference for worker 1412 is 1.074693
INFO:root:FL Epoch: 464 Done on worker:1412
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1475
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506697
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229038
INFO:root:FL Epoch: 464 Norm Difference for worker 1475 is 1.05094
INFO:root:FL Epoch: 464 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1352
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.962697
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320739
INFO:root:FL Epoch: 464 Norm Difference for worker 1352 is 1.051098
INFO:root:FL Epoch: 464 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1251
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363548
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362998
INFO:root:FL Epoch: 464 Norm Difference for worker 1251 is 1.077109
INFO:root:FL Epoch: 464 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :162
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 162 Train Epoch: 0 [0/201 (0%)]	Loss: 0.479966
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 162 Train Epoch: 1 [0/201 (0%)]	Loss: 0.449132
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 464 Norm Difference for worker 162 is 1.101433
INFO:root:FL Epoch: 464 Done on worker:162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :202
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.802746
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.593690
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 464 Norm Difference for worker 202 is 1.106928
INFO:root:FL Epoch: 464 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 272
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 464 Ends   ===================
INFO:root:Epoch:464 Global Model Test Loss:0.5455011252094718 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:464 Global Model Backdoor Test Loss:0.16563241432110468                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 465 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 465 Workers Selected : [1078, 339, 1327, 1482, 1713, 1622, 1408, 1865, 1421, 325]
INFO:root:FL Epoch: 465 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 465 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 465 Training on worker :1078
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796524
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582069
INFO:root:FL Epoch: 465 Norm Difference for worker 1078 is 1.029861
INFO:root:FL Epoch: 465 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :339
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 339 Train Epoch: 0 [0/201 (0%)]	Loss: 0.756722
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 339 Train Epoch: 1 [0/201 (0%)]	Loss: 0.454388
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 465 Norm Difference for worker 339 is 0.987128
INFO:root:FL Epoch: 465 Done on worker:339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1327
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479937
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319131
INFO:root:FL Epoch: 465 Norm Difference for worker 1327 is 0.893422
INFO:root:FL Epoch: 465 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1482
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.142860
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.131363
INFO:root:FL Epoch: 465 Norm Difference for worker 1482 is 0.628559
INFO:root:FL Epoch: 465 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1713
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499767
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196795
INFO:root:FL Epoch: 465 Norm Difference for worker 1713 is 0.880554
INFO:root:FL Epoch: 465 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1622
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571492
INFO:root:Worker: 1622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660013
INFO:root:FL Epoch: 465 Norm Difference for worker 1622 is 0.838089
INFO:root:FL Epoch: 465 Done on worker:1622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1408
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522912
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350299
INFO:root:FL Epoch: 465 Norm Difference for worker 1408 is 0.899784
INFO:root:FL Epoch: 465 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1865
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530311
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390792
INFO:root:FL Epoch: 465 Norm Difference for worker 1865 is 0.953894
INFO:root:FL Epoch: 465 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1421
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.230117
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261071
INFO:root:FL Epoch: 465 Norm Difference for worker 1421 is 0.731728
INFO:root:FL Epoch: 465 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :325
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.377449
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.215465
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 465 Norm Difference for worker 325 is 0.951333
INFO:root:FL Epoch: 465 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1482
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 465 Ends   ===================
INFO:root:Epoch:465 Global Model Test Loss:0.5482426180559046 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:465 Global Model Backdoor Test Loss:0.09571913629770279                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 466 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 466 Workers Selected : [1494, 857, 104, 1713, 1448, 21, 596, 894, 1708, 1086]
INFO:root:FL Epoch: 466 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 466 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 466 Training on worker :1494
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428489
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372690
INFO:root:FL Epoch: 466 Norm Difference for worker 1494 is 1.118242
INFO:root:FL Epoch: 466 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :857
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 1.050100
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618213
INFO:root:FL Epoch: 466 Norm Difference for worker 857 is 1.358936
INFO:root:FL Epoch: 466 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :104
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.332292
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.198081
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 466 Norm Difference for worker 104 is 1.208342
INFO:root:FL Epoch: 466 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1713
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.247943
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321902
INFO:root:FL Epoch: 466 Norm Difference for worker 1713 is 1.033593
INFO:root:FL Epoch: 466 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1448
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.985240
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499179
INFO:root:FL Epoch: 466 Norm Difference for worker 1448 is 1.066812
INFO:root:FL Epoch: 466 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :21
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.717316
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.353520
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 466 Norm Difference for worker 21 is 1.022953
INFO:root:FL Epoch: 466 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :596
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652767
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494876
INFO:root:FL Epoch: 466 Norm Difference for worker 596 is 1.198847
INFO:root:FL Epoch: 466 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :894
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406110
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186815
INFO:root:FL Epoch: 466 Norm Difference for worker 894 is 1.188437
INFO:root:FL Epoch: 466 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1708
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440370
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490466
INFO:root:FL Epoch: 466 Norm Difference for worker 1708 is 1.165494
INFO:root:FL Epoch: 466 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1086
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416866
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251012
INFO:root:FL Epoch: 466 Norm Difference for worker 1086 is 1.133477
INFO:root:FL Epoch: 466 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1448
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 466 Ends   ===================
INFO:root:Epoch:466 Global Model Test Loss:0.5153493776040918 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:466 Global Model Backdoor Test Loss:0.1335065687696139                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 467 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 467 Workers Selected : [684, 1281, 462, 1092, 606, 1605, 925, 434, 484, 348]
INFO:root:FL Epoch: 467 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 467 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 467 Training on worker :684
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380492
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617608
INFO:root:FL Epoch: 467 Norm Difference for worker 684 is 0.833149
INFO:root:FL Epoch: 467 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1281
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1281 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475860
INFO:root:Worker: 1281 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316738
INFO:root:FL Epoch: 467 Norm Difference for worker 1281 is 0.970086
INFO:root:FL Epoch: 467 Done on worker:1281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :462
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441909
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368192
INFO:root:FL Epoch: 467 Norm Difference for worker 462 is 0.924783
INFO:root:FL Epoch: 467 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1092
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477625
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422103
INFO:root:FL Epoch: 467 Norm Difference for worker 1092 is 0.895464
INFO:root:FL Epoch: 467 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :606
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500190
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171467
INFO:root:FL Epoch: 467 Norm Difference for worker 606 is 0.804521
INFO:root:FL Epoch: 467 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1605
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745206
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490789
INFO:root:FL Epoch: 467 Norm Difference for worker 1605 is 1.007427
INFO:root:FL Epoch: 467 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :925
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740215
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314293
INFO:root:FL Epoch: 467 Norm Difference for worker 925 is 0.844938
INFO:root:FL Epoch: 467 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :434
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692996
INFO:root:Worker: 434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348280
INFO:root:FL Epoch: 467 Norm Difference for worker 434 is 0.8957
INFO:root:FL Epoch: 467 Done on worker:434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :484
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633875
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.722750
INFO:root:FL Epoch: 467 Norm Difference for worker 484 is 0.985191
INFO:root:FL Epoch: 467 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :348
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479073
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395179
INFO:root:FL Epoch: 467 Norm Difference for worker 348 is 0.911401
INFO:root:FL Epoch: 467 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 606
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 467 Ends   ===================
INFO:root:Epoch:467 Global Model Test Loss:0.51267551148639 and Test Accuracy:75.0 
INFO:root:Epoch:467 Global Model Backdoor Test Loss:0.14843032757441202                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 468 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 468 Workers Selected : [1881, 711, 1677, 664, 661, 1595, 304, 1712, 1175, 1844]
INFO:root:FL Epoch: 468 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 468 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 468 Training on worker :1881
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.271586
INFO:root:Worker: 1881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454392
INFO:root:FL Epoch: 468 Norm Difference for worker 1881 is 0.853336
INFO:root:FL Epoch: 468 Done on worker:1881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :711
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603595
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349153
INFO:root:FL Epoch: 468 Norm Difference for worker 711 is 0.868142
INFO:root:FL Epoch: 468 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1677
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365810
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491151
INFO:root:FL Epoch: 468 Norm Difference for worker 1677 is 0.816583
INFO:root:FL Epoch: 468 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :664
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681609
INFO:root:Worker: 664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676785
INFO:root:FL Epoch: 468 Norm Difference for worker 664 is 0.874684
INFO:root:FL Epoch: 468 Done on worker:664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :661
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619560
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433679
INFO:root:FL Epoch: 468 Norm Difference for worker 661 is 0.791885
INFO:root:FL Epoch: 468 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1595
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449148
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611884
INFO:root:FL Epoch: 468 Norm Difference for worker 1595 is 0.763224
INFO:root:FL Epoch: 468 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :304
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.447797
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.224276
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 468 Norm Difference for worker 304 is 0.8898
INFO:root:FL Epoch: 468 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1712
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.810230
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461891
INFO:root:FL Epoch: 468 Norm Difference for worker 1712 is 0.886522
INFO:root:FL Epoch: 468 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1175
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502593
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267121
INFO:root:FL Epoch: 468 Norm Difference for worker 1175 is 0.871272
INFO:root:FL Epoch: 468 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1844
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542462
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639824
INFO:root:FL Epoch: 468 Norm Difference for worker 1844 is 0.844938
INFO:root:FL Epoch: 468 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1595
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 468 Ends   ===================
INFO:root:Epoch:468 Global Model Test Loss:0.5204949273782618 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:468 Global Model Backdoor Test Loss:0.13496863345305124                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 469 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 469 Workers Selected : [1376, 336, 1276, 1589, 673, 525, 278, 1929, 883, 602]
INFO:root:FL Epoch: 469 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 469 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 469 Training on worker :1376
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557033
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326196
INFO:root:FL Epoch: 469 Norm Difference for worker 1376 is 0.855705
INFO:root:FL Epoch: 469 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :336
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 336 Train Epoch: 0 [0/201 (0%)]	Loss: 0.422558
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 336 Train Epoch: 1 [0/201 (0%)]	Loss: 0.461693
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 469 Norm Difference for worker 336 is 0.84775
INFO:root:FL Epoch: 469 Done on worker:336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1276
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1276 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596700
INFO:root:Worker: 1276 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469060
INFO:root:FL Epoch: 469 Norm Difference for worker 1276 is 0.883955
INFO:root:FL Epoch: 469 Done on worker:1276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1589
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681736
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346016
INFO:root:FL Epoch: 469 Norm Difference for worker 1589 is 0.868027
INFO:root:FL Epoch: 469 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :673
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513322
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439914
INFO:root:FL Epoch: 469 Norm Difference for worker 673 is 0.924745
INFO:root:FL Epoch: 469 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :525
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459156
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442652
INFO:root:FL Epoch: 469 Norm Difference for worker 525 is 0.970324
INFO:root:FL Epoch: 469 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :278
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.419677
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.532849
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 469 Norm Difference for worker 278 is 0.964786
INFO:root:FL Epoch: 469 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1929
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386319
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256421
INFO:root:FL Epoch: 469 Norm Difference for worker 1929 is 0.816597
INFO:root:FL Epoch: 469 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :883
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 883 Train Epoch: 0 [0/200 (0%)]	Loss: 1.026172
INFO:root:Worker: 883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362987
INFO:root:FL Epoch: 469 Norm Difference for worker 883 is 0.929597
INFO:root:FL Epoch: 469 Done on worker:883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :602
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674678
INFO:root:Worker: 602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456377
INFO:root:FL Epoch: 469 Norm Difference for worker 602 is 0.863459
INFO:root:FL Epoch: 469 Done on worker:602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1929
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 469 Ends   ===================
INFO:root:Epoch:469 Global Model Test Loss:0.5357093460419599 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:469 Global Model Backdoor Test Loss:0.12318583329518636                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 470 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 470 Workers Selected : [642, 292, 1822, 896, 733, 899, 640, 1499, 203, 906]
INFO:root:FL Epoch: 470 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 470 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 470 Training on worker :642
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558067
INFO:root:Worker: 642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440340
INFO:root:FL Epoch: 470 Norm Difference for worker 642 is 0.891394
INFO:root:FL Epoch: 470 Done on worker:642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :292
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 292 Train Epoch: 0 [0/201 (0%)]	Loss: 0.480564
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 292 Train Epoch: 1 [0/201 (0%)]	Loss: 0.502661
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 470 Norm Difference for worker 292 is 0.889375
INFO:root:FL Epoch: 470 Done on worker:292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1822
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567476
INFO:root:Worker: 1822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420640
INFO:root:FL Epoch: 470 Norm Difference for worker 1822 is 0.914706
INFO:root:FL Epoch: 470 Done on worker:1822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :896
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473448
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365575
INFO:root:FL Epoch: 470 Norm Difference for worker 896 is 0.873825
INFO:root:FL Epoch: 470 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :733
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747866
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309497
INFO:root:FL Epoch: 470 Norm Difference for worker 733 is 0.913822
INFO:root:FL Epoch: 470 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :899
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.243210
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625991
INFO:root:FL Epoch: 470 Norm Difference for worker 899 is 0.94384
INFO:root:FL Epoch: 470 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :640
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463432
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477315
INFO:root:FL Epoch: 470 Norm Difference for worker 640 is 0.828314
INFO:root:FL Epoch: 470 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1499
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666974
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566932
INFO:root:FL Epoch: 470 Norm Difference for worker 1499 is 0.884966
INFO:root:FL Epoch: 470 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :203
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.610579
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.569925
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 470 Norm Difference for worker 203 is 0.876473
INFO:root:FL Epoch: 470 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :906
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477064
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352433
INFO:root:FL Epoch: 470 Norm Difference for worker 906 is 0.831613
INFO:root:FL Epoch: 470 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 906
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 470 Ends   ===================
INFO:root:Epoch:470 Global Model Test Loss:0.5943435781142291 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:470 Global Model Backdoor Test Loss:0.22018489241600037                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 471 Begins ===================
INFO:root:FL Epoch: 471 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 471 Workers Selected : [0, 1, 2, 1386, 312, 273, 324, 868, 587, 1406]
INFO:root:FL Epoch: 471 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 471 Num points on workers: [200 200 200 200 201 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 471 Training on worker :0
INFO:root:FL Epoch: 471 Using Learning rate : 0.00390260327857149 
INFO:root:FL Epoch: 471 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.158890
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.182817
INFO:root:FL Epoch: 471 Worker: 0 Backdoor Test Loss: 0.14158969124158224 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 471 Worker: 0 Backdoor Train Loss: 0.14079221710562706 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 471 Norm Difference for worker 0 is 0.15481
INFO:root:FL Epoch: 471 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1
INFO:root:FL Epoch: 471 Using Learning rate : 0.00390260327857149 
INFO:root:FL Epoch: 471 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.174587
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.218568
INFO:root:FL Epoch: 471 Worker: 1 Backdoor Test Loss: 0.1418020837008953 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 471 Worker: 1 Backdoor Train Loss: 0.14046836718916894 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 471 Norm Difference for worker 1 is 0.155264
INFO:root:FL Epoch: 471 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :2
INFO:root:FL Epoch: 471 Using Learning rate : 0.00390260327857149 
INFO:root:FL Epoch: 471 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.149274
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.182130
INFO:root:FL Epoch: 471 Worker: 2 Backdoor Test Loss: 0.13829033076763153 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 471 Worker: 2 Backdoor Train Loss: 0.1396150156855583 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 471 Norm Difference for worker 2 is 0.157124
INFO:root:FL Epoch: 471 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1386
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319889
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396377
INFO:root:FL Epoch: 471 Norm Difference for worker 1386 is 0.973263
INFO:root:FL Epoch: 471 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :312
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.428504
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.406195
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 471 Norm Difference for worker 312 is 1.068579
INFO:root:FL Epoch: 471 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :273
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 273 Train Epoch: 0 [0/201 (0%)]	Loss: 0.177930
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 273 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431798
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 471 Norm Difference for worker 273 is 0.894931
INFO:root:FL Epoch: 471 Done on worker:273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :324
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.615415
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.358955
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 471 Norm Difference for worker 324 is 0.970521
INFO:root:FL Epoch: 471 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :868
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 868 Train Epoch: 0 [0/200 (0%)]	Loss: 1.036489
INFO:root:Worker: 868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436458
INFO:root:FL Epoch: 471 Norm Difference for worker 868 is 0.996061
INFO:root:FL Epoch: 471 Done on worker:868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :587
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462427
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474532
INFO:root:FL Epoch: 471 Norm Difference for worker 587 is 0.984599
INFO:root:FL Epoch: 471 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1406
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.950634
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583726
INFO:root:FL Epoch: 471 Norm Difference for worker 1406 is 1.011577
INFO:root:FL Epoch: 471 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 471 Ends   ===================
INFO:root:Epoch:471 Global Model Test Loss:0.569021621171166 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:471 Global Model Backdoor Test Loss:0.1418020837008953                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 472 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 472 Workers Selected : [1369, 1078, 946, 1596, 1754, 1893, 76, 35, 1514, 134]
INFO:root:FL Epoch: 472 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 472 Num points on workers: [200 200 200 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 472 Training on worker :1369
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.897080
INFO:root:Worker: 1369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611482
INFO:root:FL Epoch: 472 Norm Difference for worker 1369 is 1.061156
INFO:root:FL Epoch: 472 Done on worker:1369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1078
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663941
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362396
INFO:root:FL Epoch: 472 Norm Difference for worker 1078 is 1.037259
INFO:root:FL Epoch: 472 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :946
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.817834
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326530
INFO:root:FL Epoch: 472 Norm Difference for worker 946 is 1.008065
INFO:root:FL Epoch: 472 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1596
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760565
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521991
INFO:root:FL Epoch: 472 Norm Difference for worker 1596 is 0.964768
INFO:root:FL Epoch: 472 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1754
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780423
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421496
INFO:root:FL Epoch: 472 Norm Difference for worker 1754 is 0.90551
INFO:root:FL Epoch: 472 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1893
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578968
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532095
INFO:root:FL Epoch: 472 Norm Difference for worker 1893 is 1.074522
INFO:root:FL Epoch: 472 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :76
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.558276
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.353227
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 472 Norm Difference for worker 76 is 1.027099
INFO:root:FL Epoch: 472 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :35
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.580167
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.437863
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 472 Norm Difference for worker 35 is 0.996384
INFO:root:FL Epoch: 472 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1514
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 1.024121
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326013
INFO:root:FL Epoch: 472 Norm Difference for worker 1514 is 0.964131
INFO:root:FL Epoch: 472 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :134
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.505011
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.274328
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 472 Norm Difference for worker 134 is 0.954034
INFO:root:FL Epoch: 472 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1754
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 472 Ends   ===================
INFO:root:Epoch:472 Global Model Test Loss:0.5507102573619169 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:472 Global Model Backdoor Test Loss:0.11120723684628804                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 473 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 473 Workers Selected : [1624, 1303, 1603, 789, 1461, 1439, 566, 614, 747, 1857]
INFO:root:FL Epoch: 473 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 473 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 473 Training on worker :1624
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365551
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325017
INFO:root:FL Epoch: 473 Norm Difference for worker 1624 is 0.873861
INFO:root:FL Epoch: 473 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1303
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372882
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475846
INFO:root:FL Epoch: 473 Norm Difference for worker 1303 is 0.917951
INFO:root:FL Epoch: 473 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1603
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414234
INFO:root:Worker: 1603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515957
INFO:root:FL Epoch: 473 Norm Difference for worker 1603 is 0.869831
INFO:root:FL Epoch: 473 Done on worker:1603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :789
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503964
INFO:root:Worker: 789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304969
INFO:root:FL Epoch: 473 Norm Difference for worker 789 is 0.91915
INFO:root:FL Epoch: 473 Done on worker:789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1461
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474245
INFO:root:Worker: 1461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268492
INFO:root:FL Epoch: 473 Norm Difference for worker 1461 is 0.839863
INFO:root:FL Epoch: 473 Done on worker:1461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1439
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445466
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399837
INFO:root:FL Epoch: 473 Norm Difference for worker 1439 is 0.932729
INFO:root:FL Epoch: 473 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :566
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602512
INFO:root:Worker: 566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477541
INFO:root:FL Epoch: 473 Norm Difference for worker 566 is 0.949232
INFO:root:FL Epoch: 473 Done on worker:566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :614
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518164
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422304
INFO:root:FL Epoch: 473 Norm Difference for worker 614 is 0.917881
INFO:root:FL Epoch: 473 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :747
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487952
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.951069
INFO:root:FL Epoch: 473 Norm Difference for worker 747 is 0.932965
INFO:root:FL Epoch: 473 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1857
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423247
INFO:root:Worker: 1857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257755
INFO:root:FL Epoch: 473 Norm Difference for worker 1857 is 0.940363
INFO:root:FL Epoch: 473 Done on worker:1857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1461
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 473 Ends   ===================
INFO:root:Epoch:473 Global Model Test Loss:0.5497849495971904 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:473 Global Model Backdoor Test Loss:0.14164203157027563                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 474 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 474 Workers Selected : [722, 1292, 200, 1745, 1317, 888, 600, 1582, 122, 1276]
INFO:root:FL Epoch: 474 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 474 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 474 Training on worker :722
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703779
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.746992
INFO:root:FL Epoch: 474 Norm Difference for worker 722 is 0.915827
INFO:root:FL Epoch: 474 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1292
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1292 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547067
INFO:root:Worker: 1292 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357375
INFO:root:FL Epoch: 474 Norm Difference for worker 1292 is 0.901076
INFO:root:FL Epoch: 474 Done on worker:1292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :200
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.516714
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.556433
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 474 Norm Difference for worker 200 is 0.883658
INFO:root:FL Epoch: 474 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1745
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588643
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485310
INFO:root:FL Epoch: 474 Norm Difference for worker 1745 is 0.887529
INFO:root:FL Epoch: 474 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1317
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.273937
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587230
INFO:root:FL Epoch: 474 Norm Difference for worker 1317 is 0.882657
INFO:root:FL Epoch: 474 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :888
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704906
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.787351
INFO:root:FL Epoch: 474 Norm Difference for worker 888 is 0.920736
INFO:root:FL Epoch: 474 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :600
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.244158
INFO:root:Worker: 600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278502
INFO:root:FL Epoch: 474 Norm Difference for worker 600 is 0.81013
INFO:root:FL Epoch: 474 Done on worker:600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1582
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732195
INFO:root:Worker: 1582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607010
INFO:root:FL Epoch: 474 Norm Difference for worker 1582 is 0.974072
INFO:root:FL Epoch: 474 Done on worker:1582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :122
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.381921
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.360487
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 474 Norm Difference for worker 122 is 0.808721
INFO:root:FL Epoch: 474 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1276
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1276 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512429
INFO:root:Worker: 1276 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352598
INFO:root:FL Epoch: 474 Norm Difference for worker 1276 is 0.898172
INFO:root:FL Epoch: 474 Done on worker:1276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 600
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 474 Ends   ===================
INFO:root:Epoch:474 Global Model Test Loss:0.5363009992767783 and Test Accuracy:75.0 
INFO:root:Epoch:474 Global Model Backdoor Test Loss:0.11951464290420215                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 475 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 475 Workers Selected : [1037, 1924, 1138, 939, 622, 1818, 213, 1662, 829, 968]
INFO:root:FL Epoch: 475 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 475 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 475 Training on worker :1037
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1037 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638501
INFO:root:Worker: 1037 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357643
INFO:root:FL Epoch: 475 Norm Difference for worker 1037 is 0.909381
INFO:root:FL Epoch: 475 Done on worker:1037
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1924
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401756
INFO:root:Worker: 1924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360274
INFO:root:FL Epoch: 475 Norm Difference for worker 1924 is 0.820276
INFO:root:FL Epoch: 475 Done on worker:1924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1138
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762607
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477783
INFO:root:FL Epoch: 475 Norm Difference for worker 1138 is 0.918879
INFO:root:FL Epoch: 475 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :939
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757701
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500799
INFO:root:FL Epoch: 475 Norm Difference for worker 939 is 0.892331
INFO:root:FL Epoch: 475 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :622
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518521
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491322
INFO:root:FL Epoch: 475 Norm Difference for worker 622 is 0.904485
INFO:root:FL Epoch: 475 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1818
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473685
INFO:root:Worker: 1818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655727
INFO:root:FL Epoch: 475 Norm Difference for worker 1818 is 0.877107
INFO:root:FL Epoch: 475 Done on worker:1818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :213
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694350
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.429215
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 475 Norm Difference for worker 213 is 0.906728
INFO:root:FL Epoch: 475 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1662
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.787887
INFO:root:Worker: 1662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314768
INFO:root:FL Epoch: 475 Norm Difference for worker 1662 is 0.793646
INFO:root:FL Epoch: 475 Done on worker:1662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :829
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425269
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413730
INFO:root:FL Epoch: 475 Norm Difference for worker 829 is 0.906615
INFO:root:FL Epoch: 475 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :968
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479647
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376189
INFO:root:FL Epoch: 475 Norm Difference for worker 968 is 0.915525
INFO:root:FL Epoch: 475 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1662
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 475 Ends   ===================
INFO:root:Epoch:475 Global Model Test Loss:0.5472423592034508 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:475 Global Model Backdoor Test Loss:0.16943069671591124                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 476 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 476 Workers Selected : [20, 1906, 168, 97, 947, 950, 1018, 477, 1388, 1776]
INFO:root:FL Epoch: 476 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 476 Num points on workers: [201 200 201 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 476 Training on worker :20
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 1.016608
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.782439
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 476 Norm Difference for worker 20 is 0.877408
INFO:root:FL Epoch: 476 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1906
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552971
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336607
INFO:root:FL Epoch: 476 Norm Difference for worker 1906 is 0.856877
INFO:root:FL Epoch: 476 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :168
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 168 Train Epoch: 0 [0/201 (0%)]	Loss: 0.380813
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 168 Train Epoch: 1 [0/201 (0%)]	Loss: 0.423978
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 476 Norm Difference for worker 168 is 0.865664
INFO:root:FL Epoch: 476 Done on worker:168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :97
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.618018
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.501175
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 476 Norm Difference for worker 97 is 0.836596
INFO:root:FL Epoch: 476 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :947
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413875
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272964
INFO:root:FL Epoch: 476 Norm Difference for worker 947 is 0.734658
INFO:root:FL Epoch: 476 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :950
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692616
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351526
INFO:root:FL Epoch: 476 Norm Difference for worker 950 is 0.902922
INFO:root:FL Epoch: 476 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1018
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586928
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405610
INFO:root:FL Epoch: 476 Norm Difference for worker 1018 is 0.848343
INFO:root:FL Epoch: 476 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :477
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452761
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388527
INFO:root:FL Epoch: 476 Norm Difference for worker 477 is 0.830346
INFO:root:FL Epoch: 476 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1388
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433988
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492213
INFO:root:FL Epoch: 476 Norm Difference for worker 1388 is 0.872181
INFO:root:FL Epoch: 476 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1776
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513423
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.878569
INFO:root:FL Epoch: 476 Norm Difference for worker 1776 is 0.822055
INFO:root:FL Epoch: 476 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 947
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 476 Ends   ===================
INFO:root:Epoch:476 Global Model Test Loss:0.5212513909620398 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:476 Global Model Backdoor Test Loss:0.12721723690629005                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 477 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 477 Workers Selected : [140, 1142, 362, 200, 503, 1050, 405, 1577, 1490, 1483]
INFO:root:FL Epoch: 477 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 477 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 477 Training on worker :140
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.705416
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446665
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 477 Norm Difference for worker 140 is 0.917582
INFO:root:FL Epoch: 477 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1142
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700428
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387744
INFO:root:FL Epoch: 477 Norm Difference for worker 1142 is 0.923993
INFO:root:FL Epoch: 477 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :362
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530908
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590612
INFO:root:FL Epoch: 477 Norm Difference for worker 362 is 0.876328
INFO:root:FL Epoch: 477 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :200
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.444428
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.504426
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 477 Norm Difference for worker 200 is 0.901836
INFO:root:FL Epoch: 477 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :503
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.287506
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439366
INFO:root:FL Epoch: 477 Norm Difference for worker 503 is 0.792334
INFO:root:FL Epoch: 477 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1050
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1050 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778318
INFO:root:Worker: 1050 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387108
INFO:root:FL Epoch: 477 Norm Difference for worker 1050 is 0.91562
INFO:root:FL Epoch: 477 Done on worker:1050
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :405
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721966
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670692
INFO:root:FL Epoch: 477 Norm Difference for worker 405 is 0.868916
INFO:root:FL Epoch: 477 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1577
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548451
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574407
INFO:root:FL Epoch: 477 Norm Difference for worker 1577 is 0.878942
INFO:root:FL Epoch: 477 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1490
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647709
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535015
INFO:root:FL Epoch: 477 Norm Difference for worker 1490 is 0.820353
INFO:root:FL Epoch: 477 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1483
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.283719
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.160553
INFO:root:FL Epoch: 477 Norm Difference for worker 1483 is 0.673223
INFO:root:FL Epoch: 477 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1483
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 477 Ends   ===================
INFO:root:Epoch:477 Global Model Test Loss:0.515172632301555 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:477 Global Model Backdoor Test Loss:0.09465621908505757                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 478 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 478 Workers Selected : [103, 304, 1032, 468, 1597, 227, 380, 825, 1670, 1007]
INFO:root:FL Epoch: 478 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 478 Num points on workers: [201 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 478 Training on worker :103
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.460737
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.468051
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 478 Norm Difference for worker 103 is 0.932344
INFO:root:FL Epoch: 478 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :304
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.410457
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415448
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 478 Norm Difference for worker 304 is 0.981277
INFO:root:FL Epoch: 478 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1032
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1032 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398040
INFO:root:Worker: 1032 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298121
INFO:root:FL Epoch: 478 Norm Difference for worker 1032 is 0.848691
INFO:root:FL Epoch: 478 Done on worker:1032
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :468
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469294
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395482
INFO:root:FL Epoch: 478 Norm Difference for worker 468 is 0.938978
INFO:root:FL Epoch: 478 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1597
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637203
INFO:root:Worker: 1597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311125
INFO:root:FL Epoch: 478 Norm Difference for worker 1597 is 0.871816
INFO:root:FL Epoch: 478 Done on worker:1597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :227
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.652905
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.681274
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 478 Norm Difference for worker 227 is 0.956667
INFO:root:FL Epoch: 478 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :380
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410702
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539723
INFO:root:FL Epoch: 478 Norm Difference for worker 380 is 0.999974
INFO:root:FL Epoch: 478 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :825
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.223887
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203291
INFO:root:FL Epoch: 478 Norm Difference for worker 825 is 0.707418
INFO:root:FL Epoch: 478 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1670
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406276
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324190
INFO:root:FL Epoch: 478 Norm Difference for worker 1670 is 0.770159
INFO:root:FL Epoch: 478 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1007
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668464
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306905
INFO:root:FL Epoch: 478 Norm Difference for worker 1007 is 0.933837
INFO:root:FL Epoch: 478 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 825
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 478 Ends   ===================
INFO:root:Epoch:478 Global Model Test Loss:0.5179321152322433 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:478 Global Model Backdoor Test Loss:0.061688449854652085                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 479 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 479 Workers Selected : [1013, 873, 1343, 1746, 499, 1131, 310, 223, 1692, 1352]
INFO:root:FL Epoch: 479 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 479 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 479 Training on worker :1013
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.838590
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390563
INFO:root:FL Epoch: 479 Norm Difference for worker 1013 is 1.099331
INFO:root:FL Epoch: 479 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :873
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697905
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.182937
INFO:root:FL Epoch: 479 Norm Difference for worker 873 is 1.166658
INFO:root:FL Epoch: 479 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :1343
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393766
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373449
INFO:root:FL Epoch: 479 Norm Difference for worker 1343 is 1.094193
INFO:root:FL Epoch: 479 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :1746
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1746 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615035
INFO:root:Worker: 1746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335227
INFO:root:FL Epoch: 479 Norm Difference for worker 1746 is 1.082858
INFO:root:FL Epoch: 479 Done on worker:1746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :499
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401163
INFO:root:Worker: 499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258211
INFO:root:FL Epoch: 479 Norm Difference for worker 499 is 0.973484
INFO:root:FL Epoch: 479 Done on worker:499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :1131
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 0.821785
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443303
INFO:root:FL Epoch: 479 Norm Difference for worker 1131 is 1.197438
INFO:root:FL Epoch: 479 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :310
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 310 Train Epoch: 0 [0/201 (0%)]	Loss: 0.648345
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 310 Train Epoch: 1 [0/201 (0%)]	Loss: 0.498133
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 479 Norm Difference for worker 310 is 1.017909
INFO:root:FL Epoch: 479 Done on worker:310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :223
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 223 Train Epoch: 0 [0/201 (0%)]	Loss: 0.513360
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 223 Train Epoch: 1 [0/201 (0%)]	Loss: 0.454207
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 479 Norm Difference for worker 223 is 1.072928
INFO:root:FL Epoch: 479 Done on worker:223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :1692
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568332
INFO:root:Worker: 1692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565113
INFO:root:FL Epoch: 479 Norm Difference for worker 1692 is 1.436753
INFO:root:FL Epoch: 479 Done on worker:1692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :1352
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571433
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492992
INFO:root:FL Epoch: 479 Norm Difference for worker 1352 is 1.133175
INFO:root:FL Epoch: 479 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 499
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 479 Ends   ===================
INFO:root:Epoch:479 Global Model Test Loss:0.6798052787780762 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:479 Global Model Backdoor Test Loss:0.07920114323496819                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 480 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 480 Workers Selected : [1925, 1145, 636, 1906, 1542, 348, 704, 1809, 1212, 1390]
INFO:root:FL Epoch: 480 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 480 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 480 Training on worker :1925
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328661
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 1.038662
INFO:root:FL Epoch: 480 Norm Difference for worker 1925 is 2.111243
INFO:root:FL Epoch: 480 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1145
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1145 Train Epoch: 0 [0/200 (0%)]	Loss: 0.279712
INFO:root:Worker: 1145 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536428
INFO:root:FL Epoch: 480 Norm Difference for worker 1145 is 1.986616
INFO:root:FL Epoch: 480 Done on worker:1145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :636
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764600
INFO:root:Worker: 636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.731532
INFO:root:FL Epoch: 480 Norm Difference for worker 636 is 1.703717
INFO:root:FL Epoch: 480 Done on worker:636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1906
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551883
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.866484
INFO:root:FL Epoch: 480 Norm Difference for worker 1906 is 1.656194
INFO:root:FL Epoch: 480 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1542
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728251
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519996
INFO:root:FL Epoch: 480 Norm Difference for worker 1542 is 1.248433
INFO:root:FL Epoch: 480 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :348
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644692
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431218
INFO:root:FL Epoch: 480 Norm Difference for worker 348 is 1.49878
INFO:root:FL Epoch: 480 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :704
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401361
INFO:root:Worker: 704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626410
INFO:root:FL Epoch: 480 Norm Difference for worker 704 is 1.426946
INFO:root:FL Epoch: 480 Done on worker:704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1809
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587821
INFO:root:Worker: 1809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.834272
INFO:root:FL Epoch: 480 Norm Difference for worker 1809 is 1.934769
INFO:root:FL Epoch: 480 Done on worker:1809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1212
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489090
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423038
INFO:root:FL Epoch: 480 Norm Difference for worker 1212 is 1.502869
INFO:root:FL Epoch: 480 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1390
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522581
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612699
INFO:root:FL Epoch: 480 Norm Difference for worker 1390 is 1.79249
INFO:root:FL Epoch: 480 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 704
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 480 Ends   ===================
INFO:root:Epoch:480 Global Model Test Loss:0.521356487975401 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:480 Global Model Backdoor Test Loss:0.17507185290257135                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 481 Begins ===================
INFO:root:FL Epoch: 481 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 481 Workers Selected : [0, 1, 2, 907, 330, 1916, 1435, 1385, 1108, 449]
INFO:root:FL Epoch: 481 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 481 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 481 Training on worker :0
INFO:root:FL Epoch: 481 Using Learning rate : 0.003825249948172384 
INFO:root:FL Epoch: 481 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.147412
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.168392
INFO:root:FL Epoch: 481 Worker: 0 Backdoor Test Loss: 0.14444550623496374 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 481 Worker: 0 Backdoor Train Loss: 0.1874655082821846 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 481 Norm Difference for worker 0 is 0.122197
INFO:root:FL Epoch: 481 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :1
INFO:root:FL Epoch: 481 Using Learning rate : 0.003825249948172384 
INFO:root:FL Epoch: 481 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.280144
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244325
INFO:root:FL Epoch: 481 Worker: 1 Backdoor Test Loss: 0.14538298547267914 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 481 Worker: 1 Backdoor Train Loss: 0.1862291194498539 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 481 Norm Difference for worker 1 is 0.12595
INFO:root:FL Epoch: 481 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :2
INFO:root:FL Epoch: 481 Using Learning rate : 0.003825249948172384 
INFO:root:FL Epoch: 481 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.181032
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.183121
INFO:root:FL Epoch: 481 Worker: 2 Backdoor Test Loss: 0.14670001342892647 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 481 Worker: 2 Backdoor Train Loss: 0.18667279183864594 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 481 Norm Difference for worker 2 is 0.125356
INFO:root:FL Epoch: 481 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :907
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487395
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453083
INFO:root:FL Epoch: 481 Norm Difference for worker 907 is 0.776745
INFO:root:FL Epoch: 481 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :330
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 330 Train Epoch: 0 [0/201 (0%)]	Loss: 0.432144
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 330 Train Epoch: 1 [0/201 (0%)]	Loss: 0.420320
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 330 is 0.737158
INFO:root:FL Epoch: 481 Done on worker:330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :1916
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645762
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554946
INFO:root:FL Epoch: 481 Norm Difference for worker 1916 is 0.780006
INFO:root:FL Epoch: 481 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :1435
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534434
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558900
INFO:root:FL Epoch: 481 Norm Difference for worker 1435 is 0.68537
INFO:root:FL Epoch: 481 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :1385
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385517
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374922
INFO:root:FL Epoch: 481 Norm Difference for worker 1385 is 0.715548
INFO:root:FL Epoch: 481 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :1108
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467893
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401089
INFO:root:FL Epoch: 481 Norm Difference for worker 1108 is 0.81388
INFO:root:FL Epoch: 481 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :449
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439354
INFO:root:Worker: 449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408087
INFO:root:FL Epoch: 481 Norm Difference for worker 449 is 0.803362
INFO:root:FL Epoch: 481 Done on worker:449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 481 Ends   ===================
INFO:root:Epoch:481 Global Model Test Loss:0.5211677919415867 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:481 Global Model Backdoor Test Loss:0.14444550623496374                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 482 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 482 Workers Selected : [194, 1670, 368, 1195, 1701, 24, 1893, 1109, 1734, 324]
INFO:root:FL Epoch: 482 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 482 Num points on workers: [201 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 482 Training on worker :194
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 194 Train Epoch: 0 [0/201 (0%)]	Loss: 0.680496
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 194 Train Epoch: 1 [0/201 (0%)]	Loss: 0.440394
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 482 Norm Difference for worker 194 is 0.810778
INFO:root:FL Epoch: 482 Done on worker:194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1670
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.335411
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348166
INFO:root:FL Epoch: 482 Norm Difference for worker 1670 is 0.676199
INFO:root:FL Epoch: 482 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :368
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580824
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631500
INFO:root:FL Epoch: 482 Norm Difference for worker 368 is 0.7783
INFO:root:FL Epoch: 482 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1195
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520984
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443501
INFO:root:FL Epoch: 482 Norm Difference for worker 1195 is 0.82735
INFO:root:FL Epoch: 482 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1701
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396976
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392470
INFO:root:FL Epoch: 482 Norm Difference for worker 1701 is 0.778011
INFO:root:FL Epoch: 482 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :24
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.462979
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.278271
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 482 Norm Difference for worker 24 is 0.8513
INFO:root:FL Epoch: 482 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1893
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.836452
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443459
INFO:root:FL Epoch: 482 Norm Difference for worker 1893 is 0.849149
INFO:root:FL Epoch: 482 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1109
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1109 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516110
INFO:root:Worker: 1109 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522768
INFO:root:FL Epoch: 482 Norm Difference for worker 1109 is 0.808979
INFO:root:FL Epoch: 482 Done on worker:1109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1734
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416971
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355265
INFO:root:FL Epoch: 482 Norm Difference for worker 1734 is 0.869877
INFO:root:FL Epoch: 482 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :324
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.482454
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.425559
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 482 Norm Difference for worker 324 is 0.779502
INFO:root:FL Epoch: 482 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1670
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 482 Ends   ===================
INFO:root:Epoch:482 Global Model Test Loss:0.5550984705195707 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:482 Global Model Backdoor Test Loss:0.1591511977215608                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 483 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 483 Workers Selected : [177, 4, 1015, 346, 215, 938, 1805, 495, 999, 1886]
INFO:root:FL Epoch: 483 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 483 Num points on workers: [201 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 483 Training on worker :177
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 177 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518753
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 177 Train Epoch: 1 [0/201 (0%)]	Loss: 0.401918
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 483 Norm Difference for worker 177 is 0.873382
INFO:root:FL Epoch: 483 Done on worker:177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :4
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 4 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587848
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 4 Train Epoch: 1 [0/201 (0%)]	Loss: 0.463502
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 483 Norm Difference for worker 4 is 0.903065
INFO:root:FL Epoch: 483 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1015
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643908
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403276
INFO:root:FL Epoch: 483 Norm Difference for worker 1015 is 0.883722
INFO:root:FL Epoch: 483 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :346
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416287
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451495
INFO:root:FL Epoch: 483 Norm Difference for worker 346 is 0.803642
INFO:root:FL Epoch: 483 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :215
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 215 Train Epoch: 0 [0/201 (0%)]	Loss: 0.554774
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 215 Train Epoch: 1 [0/201 (0%)]	Loss: 0.476513
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 483 Norm Difference for worker 215 is 0.873256
INFO:root:FL Epoch: 483 Done on worker:215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :938
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.847962
INFO:root:Worker: 938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352714
INFO:root:FL Epoch: 483 Norm Difference for worker 938 is 0.927249
INFO:root:FL Epoch: 483 Done on worker:938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1805
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525103
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350129
INFO:root:FL Epoch: 483 Norm Difference for worker 1805 is 0.893807
INFO:root:FL Epoch: 483 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :495
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679872
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445763
INFO:root:FL Epoch: 483 Norm Difference for worker 495 is 0.909441
INFO:root:FL Epoch: 483 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :999
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760330
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451757
INFO:root:FL Epoch: 483 Norm Difference for worker 999 is 0.905178
INFO:root:FL Epoch: 483 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1886
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346507
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320561
INFO:root:FL Epoch: 483 Norm Difference for worker 1886 is 0.764059
INFO:root:FL Epoch: 483 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1886
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 483 Ends   ===================
INFO:root:Epoch:483 Global Model Test Loss:0.5521649507915273 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:483 Global Model Backdoor Test Loss:0.10151525338490804                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 484 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 484 Workers Selected : [386, 1503, 1701, 862, 1169, 346, 852, 1492, 1401, 424]
INFO:root:FL Epoch: 484 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 484 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 484 Training on worker :386
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321752
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278460
INFO:root:FL Epoch: 484 Norm Difference for worker 386 is 0.859582
INFO:root:FL Epoch: 484 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1503
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340390
INFO:root:Worker: 1503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325395
INFO:root:FL Epoch: 484 Norm Difference for worker 1503 is 0.913642
INFO:root:FL Epoch: 484 Done on worker:1503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1701
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578919
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577488
INFO:root:FL Epoch: 484 Norm Difference for worker 1701 is 0.889182
INFO:root:FL Epoch: 484 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :862
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737439
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519400
INFO:root:FL Epoch: 484 Norm Difference for worker 862 is 0.92974
INFO:root:FL Epoch: 484 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1169
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681495
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307186
INFO:root:FL Epoch: 484 Norm Difference for worker 1169 is 0.966717
INFO:root:FL Epoch: 484 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :346
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450901
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280030
INFO:root:FL Epoch: 484 Norm Difference for worker 346 is 0.864735
INFO:root:FL Epoch: 484 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :852
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.301535
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466395
INFO:root:FL Epoch: 484 Norm Difference for worker 852 is 1.004009
INFO:root:FL Epoch: 484 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1492
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.823146
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601266
INFO:root:FL Epoch: 484 Norm Difference for worker 1492 is 1.046637
INFO:root:FL Epoch: 484 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1401
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651473
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489462
INFO:root:FL Epoch: 484 Norm Difference for worker 1401 is 0.926807
INFO:root:FL Epoch: 484 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :424
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495015
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473416
INFO:root:FL Epoch: 484 Norm Difference for worker 424 is 0.903409
INFO:root:FL Epoch: 484 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 386
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 484 Ends   ===================
INFO:root:Epoch:484 Global Model Test Loss:0.537310309269849 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:484 Global Model Backdoor Test Loss:0.12216576188802719                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 485 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 485 Workers Selected : [1837, 824, 1007, 253, 1875, 985, 1657, 468, 1548, 1947]
INFO:root:FL Epoch: 485 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 485 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 485 Training on worker :1837
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537720
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465077
INFO:root:FL Epoch: 485 Norm Difference for worker 1837 is 0.919891
INFO:root:FL Epoch: 485 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :824
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660156
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479239
INFO:root:FL Epoch: 485 Norm Difference for worker 824 is 0.825354
INFO:root:FL Epoch: 485 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :1007
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.829798
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509499
INFO:root:FL Epoch: 485 Norm Difference for worker 1007 is 0.958318
INFO:root:FL Epoch: 485 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :253
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.671760
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.413871
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 253 is 0.928659
INFO:root:FL Epoch: 485 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :1875
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1875 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761776
INFO:root:Worker: 1875 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421333
INFO:root:FL Epoch: 485 Norm Difference for worker 1875 is 0.914991
INFO:root:FL Epoch: 485 Done on worker:1875
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :985
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 985 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650089
INFO:root:Worker: 985 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434888
INFO:root:FL Epoch: 485 Norm Difference for worker 985 is 0.919002
INFO:root:FL Epoch: 485 Done on worker:985
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :1657
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523712
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295978
INFO:root:FL Epoch: 485 Norm Difference for worker 1657 is 0.976582
INFO:root:FL Epoch: 485 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :468
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623736
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.751519
INFO:root:FL Epoch: 485 Norm Difference for worker 468 is 0.900192
INFO:root:FL Epoch: 485 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :1548
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606798
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572827
INFO:root:FL Epoch: 485 Norm Difference for worker 1548 is 0.953294
INFO:root:FL Epoch: 485 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :1947
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.164126
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244543
INFO:root:FL Epoch: 485 Norm Difference for worker 1947 is 0.658195
INFO:root:FL Epoch: 485 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1947
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 485 Ends   ===================
INFO:root:Epoch:485 Global Model Test Loss:0.5255744913045097 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:485 Global Model Backdoor Test Loss:0.07652081487079461                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 486 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 486 Workers Selected : [1275, 1599, 419, 900, 474, 471, 1727, 881, 697, 483]
INFO:root:FL Epoch: 486 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 486 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 486 Training on worker :1275
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.248561
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193431
INFO:root:FL Epoch: 486 Norm Difference for worker 1275 is 0.703079
INFO:root:FL Epoch: 486 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1599
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529203
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257047
INFO:root:FL Epoch: 486 Norm Difference for worker 1599 is 0.976225
INFO:root:FL Epoch: 486 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :419
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354591
INFO:root:Worker: 419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287283
INFO:root:FL Epoch: 486 Norm Difference for worker 419 is 0.913684
INFO:root:FL Epoch: 486 Done on worker:419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :900
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496108
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468607
INFO:root:FL Epoch: 486 Norm Difference for worker 900 is 0.991388
INFO:root:FL Epoch: 486 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :474
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.942135
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570130
INFO:root:FL Epoch: 486 Norm Difference for worker 474 is 1.028416
INFO:root:FL Epoch: 486 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :471
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413181
INFO:root:Worker: 471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346893
INFO:root:FL Epoch: 486 Norm Difference for worker 471 is 1.049252
INFO:root:FL Epoch: 486 Done on worker:471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1727
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736574
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.839486
INFO:root:FL Epoch: 486 Norm Difference for worker 1727 is 1.023336
INFO:root:FL Epoch: 486 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :881
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487470
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355432
INFO:root:FL Epoch: 486 Norm Difference for worker 881 is 0.891323
INFO:root:FL Epoch: 486 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :697
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755825
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483894
INFO:root:FL Epoch: 486 Norm Difference for worker 697 is 1.146858
INFO:root:FL Epoch: 486 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :483
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642973
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427911
INFO:root:FL Epoch: 486 Norm Difference for worker 483 is 1.005438
INFO:root:FL Epoch: 486 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1275
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 486 Ends   ===================
INFO:root:Epoch:486 Global Model Test Loss:0.5572271119145786 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:486 Global Model Backdoor Test Loss:0.055163513869047165                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 487 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 487 Workers Selected : [1262, 690, 59, 1825, 509, 444, 246, 841, 417, 1509]
INFO:root:FL Epoch: 487 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 487 Num points on workers: [200 200 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 487 Training on worker :1262
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1262 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741566
INFO:root:Worker: 1262 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553166
INFO:root:FL Epoch: 487 Norm Difference for worker 1262 is 1.190045
INFO:root:FL Epoch: 487 Done on worker:1262
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :690
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398363
INFO:root:Worker: 690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580639
INFO:root:FL Epoch: 487 Norm Difference for worker 690 is 1.170088
INFO:root:FL Epoch: 487 Done on worker:690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :59
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.288204
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.238303
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 487 Norm Difference for worker 59 is 1.142918
INFO:root:FL Epoch: 487 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1825
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659782
INFO:root:Worker: 1825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387198
INFO:root:FL Epoch: 487 Norm Difference for worker 1825 is 1.074384
INFO:root:FL Epoch: 487 Done on worker:1825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :509
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783025
INFO:root:Worker: 509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473371
INFO:root:FL Epoch: 487 Norm Difference for worker 509 is 1.213159
INFO:root:FL Epoch: 487 Done on worker:509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :444
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307692
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423911
INFO:root:FL Epoch: 487 Norm Difference for worker 444 is 1.185862
INFO:root:FL Epoch: 487 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :246
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.549199
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.250962
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 487 Norm Difference for worker 246 is 1.037255
INFO:root:FL Epoch: 487 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :841
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647500
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494112
INFO:root:FL Epoch: 487 Norm Difference for worker 841 is 1.170707
INFO:root:FL Epoch: 487 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :417
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550162
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541933
INFO:root:FL Epoch: 487 Norm Difference for worker 417 is 1.066714
INFO:root:FL Epoch: 487 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1509
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569882
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523181
INFO:root:FL Epoch: 487 Norm Difference for worker 1509 is 1.190069
INFO:root:FL Epoch: 487 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 246
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 487 Ends   ===================
INFO:root:Epoch:487 Global Model Test Loss:0.5329939793137943 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:487 Global Model Backdoor Test Loss:0.11385380228360494                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 488 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 488 Workers Selected : [893, 133, 732, 912, 831, 1258, 1406, 510, 75, 1065]
INFO:root:FL Epoch: 488 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 488 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 488 Training on worker :893
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530437
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437151
INFO:root:FL Epoch: 488 Norm Difference for worker 893 is 0.978117
INFO:root:FL Epoch: 488 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :133
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.545574
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.368359
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 488 Norm Difference for worker 133 is 0.943822
INFO:root:FL Epoch: 488 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :732
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540197
INFO:root:Worker: 732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689817
INFO:root:FL Epoch: 488 Norm Difference for worker 732 is 0.943241
INFO:root:FL Epoch: 488 Done on worker:732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :912
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426603
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.857823
INFO:root:FL Epoch: 488 Norm Difference for worker 912 is 0.958659
INFO:root:FL Epoch: 488 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :831
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546757
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384763
INFO:root:FL Epoch: 488 Norm Difference for worker 831 is 0.932331
INFO:root:FL Epoch: 488 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1258
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1258 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551229
INFO:root:Worker: 1258 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381464
INFO:root:FL Epoch: 488 Norm Difference for worker 1258 is 1.002948
INFO:root:FL Epoch: 488 Done on worker:1258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1406
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.331342
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684130
INFO:root:FL Epoch: 488 Norm Difference for worker 1406 is 1.041231
INFO:root:FL Epoch: 488 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :510
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392612
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232675
INFO:root:FL Epoch: 488 Norm Difference for worker 510 is 0.901375
INFO:root:FL Epoch: 488 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :75
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 75 Train Epoch: 0 [0/201 (0%)]	Loss: 0.515710
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 75 Train Epoch: 1 [0/201 (0%)]	Loss: 0.475355
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 488 Norm Difference for worker 75 is 1.022781
INFO:root:FL Epoch: 488 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1065
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630733
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432059
INFO:root:FL Epoch: 488 Norm Difference for worker 1065 is 1.015665
INFO:root:FL Epoch: 488 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 831
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 488 Ends   ===================
INFO:root:Epoch:488 Global Model Test Loss:0.5397890981505898 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:488 Global Model Backdoor Test Loss:0.10385390867789586                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 489 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 489 Workers Selected : [444, 1645, 199, 500, 917, 1421, 1485, 306, 638, 1471]
INFO:root:FL Epoch: 489 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 489 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 489 Training on worker :444
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575575
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703301
INFO:root:FL Epoch: 489 Norm Difference for worker 444 is 0.979837
INFO:root:FL Epoch: 489 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1645
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405331
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394681
INFO:root:FL Epoch: 489 Norm Difference for worker 1645 is 0.961223
INFO:root:FL Epoch: 489 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :199
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 199 Train Epoch: 0 [0/201 (0%)]	Loss: 1.013259
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 199 Train Epoch: 1 [0/201 (0%)]	Loss: 0.325516
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 489 Norm Difference for worker 199 is 1.109451
INFO:root:FL Epoch: 489 Done on worker:199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :500
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420113
INFO:root:Worker: 500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.767971
INFO:root:FL Epoch: 489 Norm Difference for worker 500 is 0.892393
INFO:root:FL Epoch: 489 Done on worker:500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :917
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676864
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576112
INFO:root:FL Epoch: 489 Norm Difference for worker 917 is 0.995948
INFO:root:FL Epoch: 489 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1421
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402731
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288574
INFO:root:FL Epoch: 489 Norm Difference for worker 1421 is 0.727072
INFO:root:FL Epoch: 489 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1485
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.169371
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434726
INFO:root:FL Epoch: 489 Norm Difference for worker 1485 is 0.905235
INFO:root:FL Epoch: 489 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :306
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.203332
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450951
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 489 Norm Difference for worker 306 is 0.907584
INFO:root:FL Epoch: 489 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :638
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453465
INFO:root:Worker: 638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381203
INFO:root:FL Epoch: 489 Norm Difference for worker 638 is 0.866463
INFO:root:FL Epoch: 489 Done on worker:638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1471
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.331134
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555991
INFO:root:FL Epoch: 489 Norm Difference for worker 1471 is 0.986962
INFO:root:FL Epoch: 489 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1421
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 489 Ends   ===================
INFO:root:Epoch:489 Global Model Test Loss:0.5465216180857491 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:489 Global Model Backdoor Test Loss:0.08576159613827865                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 490 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 490 Workers Selected : [1328, 498, 1566, 1908, 1688, 885, 907, 1256, 1058, 1876]
INFO:root:FL Epoch: 490 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 490 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 490 Training on worker :1328
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1328 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535814
INFO:root:Worker: 1328 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286611
INFO:root:FL Epoch: 490 Norm Difference for worker 1328 is 0.942624
INFO:root:FL Epoch: 490 Done on worker:1328
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :498
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504124
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441180
INFO:root:FL Epoch: 490 Norm Difference for worker 498 is 1.041643
INFO:root:FL Epoch: 490 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1566
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463565
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260863
INFO:root:FL Epoch: 490 Norm Difference for worker 1566 is 0.834905
INFO:root:FL Epoch: 490 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1908
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537483
INFO:root:Worker: 1908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313097
INFO:root:FL Epoch: 490 Norm Difference for worker 1908 is 0.984734
INFO:root:FL Epoch: 490 Done on worker:1908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1688
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333817
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274298
INFO:root:FL Epoch: 490 Norm Difference for worker 1688 is 0.87899
INFO:root:FL Epoch: 490 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :885
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648052
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418769
INFO:root:FL Epoch: 490 Norm Difference for worker 885 is 1.024801
INFO:root:FL Epoch: 490 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :907
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483191
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601719
INFO:root:FL Epoch: 490 Norm Difference for worker 907 is 1.046571
INFO:root:FL Epoch: 490 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1256
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387461
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495954
INFO:root:FL Epoch: 490 Norm Difference for worker 1256 is 1.027623
INFO:root:FL Epoch: 490 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1058
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1058 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448466
INFO:root:Worker: 1058 Train Epoch: 1 [0/200 (0%)]	Loss: 0.809645
INFO:root:FL Epoch: 490 Norm Difference for worker 1058 is 1.0948
INFO:root:FL Epoch: 490 Done on worker:1058
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1876
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529525
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.849892
INFO:root:FL Epoch: 490 Norm Difference for worker 1876 is 1.061532
INFO:root:FL Epoch: 490 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1566
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 490 Ends   ===================
INFO:root:Epoch:490 Global Model Test Loss:0.5457159596330979 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:490 Global Model Backdoor Test Loss:0.0853355893244346                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 491 Begins ===================
INFO:root:FL Epoch: 491 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 491 Workers Selected : [0, 1, 2, 1366, 1025, 1801, 1023, 476, 769, 1114]
INFO:root:FL Epoch: 491 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 491 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 491 Training on worker :0
INFO:root:FL Epoch: 491 Using Learning rate : 0.003749429834781701 
INFO:root:FL Epoch: 491 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.246073
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298131
INFO:root:FL Epoch: 491 Worker: 0 Backdoor Test Loss: 0.0951875876635313 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 491 Worker: 0 Backdoor Train Loss: 0.16325245276093484 Backdoor Train Accuracy: 94.5
INFO:root:FL Epoch: 491 Norm Difference for worker 0 is 0.151245
INFO:root:FL Epoch: 491 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1
INFO:root:FL Epoch: 491 Using Learning rate : 0.003749429834781701 
INFO:root:FL Epoch: 491 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.210950
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.157658
INFO:root:FL Epoch: 491 Worker: 1 Backdoor Test Loss: 0.09310817966858546 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 491 Worker: 1 Backdoor Train Loss: 0.16616180390119553 Backdoor Train Accuracy: 94.5
INFO:root:FL Epoch: 491 Norm Difference for worker 1 is 0.138721
INFO:root:FL Epoch: 491 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :2
INFO:root:FL Epoch: 491 Using Learning rate : 0.003749429834781701 
INFO:root:FL Epoch: 491 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.079409
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.177471
INFO:root:FL Epoch: 491 Worker: 2 Backdoor Test Loss: 0.09675597151120503 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 491 Worker: 2 Backdoor Train Loss: 0.1620263785123825 Backdoor Train Accuracy: 94.5
INFO:root:FL Epoch: 491 Norm Difference for worker 2 is 0.158684
INFO:root:FL Epoch: 491 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1366
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404222
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228497
INFO:root:FL Epoch: 491 Norm Difference for worker 1366 is 0.795125
INFO:root:FL Epoch: 491 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1025
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.924392
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329425
INFO:root:FL Epoch: 491 Norm Difference for worker 1025 is 0.928223
INFO:root:FL Epoch: 491 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1801
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653699
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521334
INFO:root:FL Epoch: 491 Norm Difference for worker 1801 is 0.922171
INFO:root:FL Epoch: 491 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1023
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443086
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248296
INFO:root:FL Epoch: 491 Norm Difference for worker 1023 is 0.763198
INFO:root:FL Epoch: 491 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :476
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715027
INFO:root:Worker: 476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355902
INFO:root:FL Epoch: 491 Norm Difference for worker 476 is 0.921899
INFO:root:FL Epoch: 491 Done on worker:476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :769
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661296
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.790161
INFO:root:FL Epoch: 491 Norm Difference for worker 769 is 0.95638
INFO:root:FL Epoch: 491 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1114
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534766
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617528
INFO:root:FL Epoch: 491 Norm Difference for worker 1114 is 1.004884
INFO:root:FL Epoch: 491 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 491 Ends   ===================
INFO:root:Epoch:491 Global Model Test Loss:0.5391937844893512 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:491 Global Model Backdoor Test Loss:0.09675597151120503                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 492 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 492 Workers Selected : [1472, 1744, 373, 1755, 1251, 364, 894, 1005, 388, 1242]
INFO:root:FL Epoch: 492 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 492 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 492 Training on worker :1472
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513964
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311675
INFO:root:FL Epoch: 492 Norm Difference for worker 1472 is 0.893536
INFO:root:FL Epoch: 492 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1744
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771526
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434550
INFO:root:FL Epoch: 492 Norm Difference for worker 1744 is 0.870233
INFO:root:FL Epoch: 492 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :373
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502879
INFO:root:Worker: 373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482141
INFO:root:FL Epoch: 492 Norm Difference for worker 373 is 0.959236
INFO:root:FL Epoch: 492 Done on worker:373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1755
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417685
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592220
INFO:root:FL Epoch: 492 Norm Difference for worker 1755 is 0.894312
INFO:root:FL Epoch: 492 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1251
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528881
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613421
INFO:root:FL Epoch: 492 Norm Difference for worker 1251 is 0.997702
INFO:root:FL Epoch: 492 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :364
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360407
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.733906
INFO:root:FL Epoch: 492 Norm Difference for worker 364 is 0.853896
INFO:root:FL Epoch: 492 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :894
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.317508
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.182539
INFO:root:FL Epoch: 492 Norm Difference for worker 894 is 0.882364
INFO:root:FL Epoch: 492 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1005
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1005 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631087
INFO:root:Worker: 1005 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465145
INFO:root:FL Epoch: 492 Norm Difference for worker 1005 is 0.855742
INFO:root:FL Epoch: 492 Done on worker:1005
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :388
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586005
INFO:root:Worker: 388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484279
INFO:root:FL Epoch: 492 Norm Difference for worker 388 is 0.900551
INFO:root:FL Epoch: 492 Done on worker:388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1242
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392292
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575647
INFO:root:FL Epoch: 492 Norm Difference for worker 1242 is 0.927415
INFO:root:FL Epoch: 492 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1005
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 492 Ends   ===================
INFO:root:Epoch:492 Global Model Test Loss:0.5161096664036021 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:492 Global Model Backdoor Test Loss:0.12953370437026024                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 493 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 493 Workers Selected : [1224, 983, 1414, 1763, 305, 650, 1660, 1700, 1483, 860]
INFO:root:FL Epoch: 493 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 493 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 493 Training on worker :1224
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1224 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541155
INFO:root:Worker: 1224 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670310
INFO:root:FL Epoch: 493 Norm Difference for worker 1224 is 0.773174
INFO:root:FL Epoch: 493 Done on worker:1224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :983
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741730
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554168
INFO:root:FL Epoch: 493 Norm Difference for worker 983 is 0.870943
INFO:root:FL Epoch: 493 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1414
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309080
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587765
INFO:root:FL Epoch: 493 Norm Difference for worker 1414 is 0.810257
INFO:root:FL Epoch: 493 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1763
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451018
INFO:root:Worker: 1763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382038
INFO:root:FL Epoch: 493 Norm Difference for worker 1763 is 0.814565
INFO:root:FL Epoch: 493 Done on worker:1763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :305
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.448760
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.367728
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 493 Norm Difference for worker 305 is 0.820463
INFO:root:FL Epoch: 493 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :650
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390066
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433648
INFO:root:FL Epoch: 493 Norm Difference for worker 650 is 0.8033
INFO:root:FL Epoch: 493 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1660
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413120
INFO:root:Worker: 1660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629810
INFO:root:FL Epoch: 493 Norm Difference for worker 1660 is 0.790309
INFO:root:FL Epoch: 493 Done on worker:1660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1700
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496522
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592486
INFO:root:FL Epoch: 493 Norm Difference for worker 1700 is 0.784826
INFO:root:FL Epoch: 493 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1483
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308073
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.208867
INFO:root:FL Epoch: 493 Norm Difference for worker 1483 is 0.543732
INFO:root:FL Epoch: 493 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :860
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.809568
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694715
INFO:root:FL Epoch: 493 Norm Difference for worker 860 is 0.866433
INFO:root:FL Epoch: 493 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1483
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 493 Ends   ===================
INFO:root:Epoch:493 Global Model Test Loss:0.5289505089030546 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:493 Global Model Backdoor Test Loss:0.10408648972709973                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 494 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 494 Workers Selected : [318, 1700, 951, 1022, 1087, 931, 653, 272, 1459, 1399]
INFO:root:FL Epoch: 494 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 494 Num points on workers: [201 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 494 Training on worker :318
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503001
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.243687
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 318 is 0.902048
INFO:root:FL Epoch: 494 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1700
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545281
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428331
INFO:root:FL Epoch: 494 Norm Difference for worker 1700 is 0.926889
INFO:root:FL Epoch: 494 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :951
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700647
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316723
INFO:root:FL Epoch: 494 Norm Difference for worker 951 is 0.901114
INFO:root:FL Epoch: 494 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1022
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418872
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459419
INFO:root:FL Epoch: 494 Norm Difference for worker 1022 is 0.803345
INFO:root:FL Epoch: 494 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1087
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697630
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561658
INFO:root:FL Epoch: 494 Norm Difference for worker 1087 is 0.941357
INFO:root:FL Epoch: 494 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :931
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432817
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483456
INFO:root:FL Epoch: 494 Norm Difference for worker 931 is 0.914629
INFO:root:FL Epoch: 494 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :653
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457837
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275209
INFO:root:FL Epoch: 494 Norm Difference for worker 653 is 0.698889
INFO:root:FL Epoch: 494 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :272
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.601767
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.159884
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 272 is 0.703542
INFO:root:FL Epoch: 494 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1459
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499970
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417275
INFO:root:FL Epoch: 494 Norm Difference for worker 1459 is 0.993039
INFO:root:FL Epoch: 494 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1399
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.814655
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335726
INFO:root:FL Epoch: 494 Norm Difference for worker 1399 is 0.917541
INFO:root:FL Epoch: 494 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 272
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 494 Ends   ===================
INFO:root:Epoch:494 Global Model Test Loss:0.5598781932802761 and Test Accuracy:75.0 
INFO:root:Epoch:494 Global Model Backdoor Test Loss:0.12601948405305544                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 495 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 495 Workers Selected : [675, 1942, 1406, 1321, 443, 427, 1883, 918, 638, 1630]
INFO:root:FL Epoch: 495 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 495 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 495 Training on worker :675
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 675 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408051
INFO:root:Worker: 675 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527672
INFO:root:FL Epoch: 495 Norm Difference for worker 675 is 1.047355
INFO:root:FL Epoch: 495 Done on worker:675
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1942
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.236244
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436283
INFO:root:FL Epoch: 495 Norm Difference for worker 1942 is 0.989934
INFO:root:FL Epoch: 495 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1406
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682338
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.724847
INFO:root:FL Epoch: 495 Norm Difference for worker 1406 is 1.035621
INFO:root:FL Epoch: 495 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1321
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1321 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662837
INFO:root:Worker: 1321 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550843
INFO:root:FL Epoch: 495 Norm Difference for worker 1321 is 1.049559
INFO:root:FL Epoch: 495 Done on worker:1321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :443
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731448
INFO:root:Worker: 443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415965
INFO:root:FL Epoch: 495 Norm Difference for worker 443 is 0.94137
INFO:root:FL Epoch: 495 Done on worker:443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :427
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593639
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291332
INFO:root:FL Epoch: 495 Norm Difference for worker 427 is 0.971358
INFO:root:FL Epoch: 495 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1883
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670732
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543332
INFO:root:FL Epoch: 495 Norm Difference for worker 1883 is 0.960921
INFO:root:FL Epoch: 495 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :918
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726468
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447704
INFO:root:FL Epoch: 495 Norm Difference for worker 918 is 1.044909
INFO:root:FL Epoch: 495 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :638
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685769
INFO:root:Worker: 638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241193
INFO:root:FL Epoch: 495 Norm Difference for worker 638 is 0.899914
INFO:root:FL Epoch: 495 Done on worker:638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1630
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539017
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414401
INFO:root:FL Epoch: 495 Norm Difference for worker 1630 is 1.052244
INFO:root:FL Epoch: 495 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 638
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 495 Ends   ===================
INFO:root:Epoch:495 Global Model Test Loss:0.5483165190500372 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:495 Global Model Backdoor Test Loss:0.09244351461529732                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 496 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 496 Workers Selected : [1480, 79, 1343, 1312, 198, 1941, 975, 496, 1075, 1032]
INFO:root:FL Epoch: 496 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 496 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 496 Training on worker :1480
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.960295
INFO:root:Worker: 1480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418686
INFO:root:FL Epoch: 496 Norm Difference for worker 1480 is 1.051147
INFO:root:FL Epoch: 496 Done on worker:1480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :79
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.761696
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.241679
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 79 is 0.873777
INFO:root:FL Epoch: 496 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1343
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570468
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477957
INFO:root:FL Epoch: 496 Norm Difference for worker 1343 is 0.971861
INFO:root:FL Epoch: 496 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1312
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436731
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592587
INFO:root:FL Epoch: 496 Norm Difference for worker 1312 is 0.941321
INFO:root:FL Epoch: 496 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :198
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.406494
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.328879
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 496 Norm Difference for worker 198 is 0.910093
INFO:root:FL Epoch: 496 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1941
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.322320
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539510
INFO:root:FL Epoch: 496 Norm Difference for worker 1941 is 0.902728
INFO:root:FL Epoch: 496 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :975
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 1.075432
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364324
INFO:root:FL Epoch: 496 Norm Difference for worker 975 is 1.003229
INFO:root:FL Epoch: 496 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :496
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 1.055822
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459916
INFO:root:FL Epoch: 496 Norm Difference for worker 496 is 0.965977
INFO:root:FL Epoch: 496 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1075
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512639
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434049
INFO:root:FL Epoch: 496 Norm Difference for worker 1075 is 0.948573
INFO:root:FL Epoch: 496 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1032
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1032 Train Epoch: 0 [0/200 (0%)]	Loss: 0.301125
INFO:root:Worker: 1032 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266537
INFO:root:FL Epoch: 496 Norm Difference for worker 1032 is 0.760264
INFO:root:FL Epoch: 496 Done on worker:1032
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1032
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 496 Ends   ===================
INFO:root:Epoch:496 Global Model Test Loss:0.5402007681481978 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:496 Global Model Backdoor Test Loss:0.08747371037801106                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 497 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 497 Workers Selected : [1570, 1715, 1205, 1159, 1186, 734, 1461, 100, 989, 1614]
INFO:root:FL Epoch: 497 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 497 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 497 Training on worker :1570
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618531
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230884
INFO:root:FL Epoch: 497 Norm Difference for worker 1570 is 0.971606
INFO:root:FL Epoch: 497 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :1715
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679796
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499639
INFO:root:FL Epoch: 497 Norm Difference for worker 1715 is 0.947401
INFO:root:FL Epoch: 497 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :1205
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544082
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338544
INFO:root:FL Epoch: 497 Norm Difference for worker 1205 is 0.921348
INFO:root:FL Epoch: 497 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :1159
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1159 Train Epoch: 0 [0/200 (0%)]	Loss: 0.937973
INFO:root:Worker: 1159 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487938
INFO:root:FL Epoch: 497 Norm Difference for worker 1159 is 0.933055
INFO:root:FL Epoch: 497 Done on worker:1159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :1186
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.913021
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239745
INFO:root:FL Epoch: 497 Norm Difference for worker 1186 is 1.019245
INFO:root:FL Epoch: 497 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :734
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427072
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420681
INFO:root:FL Epoch: 497 Norm Difference for worker 734 is 0.90166
INFO:root:FL Epoch: 497 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :1461
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.277986
INFO:root:Worker: 1461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383681
INFO:root:FL Epoch: 497 Norm Difference for worker 1461 is 0.746305
INFO:root:FL Epoch: 497 Done on worker:1461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :100
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688573
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.706069
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 497 Norm Difference for worker 100 is 0.948873
INFO:root:FL Epoch: 497 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :989
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 989 Train Epoch: 0 [0/200 (0%)]	Loss: 1.029945
INFO:root:Worker: 989 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496599
INFO:root:FL Epoch: 497 Norm Difference for worker 989 is 0.972635
INFO:root:FL Epoch: 497 Done on worker:989
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :1614
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388457
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.729393
INFO:root:FL Epoch: 497 Norm Difference for worker 1614 is 1.191213
INFO:root:FL Epoch: 497 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1461
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 497 Ends   ===================
INFO:root:Epoch:497 Global Model Test Loss:0.5515894504154429 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:497 Global Model Backdoor Test Loss:0.1563235024611155                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 498 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 498 Workers Selected : [535, 268, 968, 728, 188, 1851, 1892, 580, 1226, 1003]
INFO:root:FL Epoch: 498 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 498 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 498 Training on worker :535
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481838
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561487
INFO:root:FL Epoch: 498 Norm Difference for worker 535 is 0.872609
INFO:root:FL Epoch: 498 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :268
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 268 Train Epoch: 0 [0/201 (0%)]	Loss: 0.642342
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 268 Train Epoch: 1 [0/201 (0%)]	Loss: 0.923432
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 498 Norm Difference for worker 268 is 1.09104
INFO:root:FL Epoch: 498 Done on worker:268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :968
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 1.106473
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.785056
INFO:root:FL Epoch: 498 Norm Difference for worker 968 is 0.968574
INFO:root:FL Epoch: 498 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :728
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582383
INFO:root:Worker: 728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282510
INFO:root:FL Epoch: 498 Norm Difference for worker 728 is 0.931044
INFO:root:FL Epoch: 498 Done on worker:728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :188
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.498942
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.489397
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 498 Norm Difference for worker 188 is 0.895882
INFO:root:FL Epoch: 498 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1851
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656802
INFO:root:Worker: 1851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249444
INFO:root:FL Epoch: 498 Norm Difference for worker 1851 is 0.929976
INFO:root:FL Epoch: 498 Done on worker:1851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1892
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525753
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326888
INFO:root:FL Epoch: 498 Norm Difference for worker 1892 is 0.891026
INFO:root:FL Epoch: 498 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :580
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603666
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507566
INFO:root:FL Epoch: 498 Norm Difference for worker 580 is 0.903985
INFO:root:FL Epoch: 498 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1226
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495300
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459032
INFO:root:FL Epoch: 498 Norm Difference for worker 1226 is 0.951126
INFO:root:FL Epoch: 498 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1003
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581800
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424534
INFO:root:FL Epoch: 498 Norm Difference for worker 1003 is 0.89615
INFO:root:FL Epoch: 498 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 535
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 498 Ends   ===================
INFO:root:Epoch:498 Global Model Test Loss:0.5176789147012374 and Test Accuracy:75.0 
INFO:root:Epoch:498 Global Model Backdoor Test Loss:0.09933163846532504                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 499 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 499 Workers Selected : [1318, 1648, 781, 1817, 648, 144, 1139, 1156, 598, 650]
INFO:root:FL Epoch: 499 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 499 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 499 Training on worker :1318
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631433
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399104
INFO:root:FL Epoch: 499 Norm Difference for worker 1318 is 0.893508
INFO:root:FL Epoch: 499 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1648
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618277
INFO:root:Worker: 1648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205528
INFO:root:FL Epoch: 499 Norm Difference for worker 1648 is 0.867394
INFO:root:FL Epoch: 499 Done on worker:1648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :781
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741357
INFO:root:Worker: 781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586718
INFO:root:FL Epoch: 499 Norm Difference for worker 781 is 0.853534
INFO:root:FL Epoch: 499 Done on worker:781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1817
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631775
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.788292
INFO:root:FL Epoch: 499 Norm Difference for worker 1817 is 0.875499
INFO:root:FL Epoch: 499 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :648
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538680
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414198
INFO:root:FL Epoch: 499 Norm Difference for worker 648 is 0.863381
INFO:root:FL Epoch: 499 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :144
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.607100
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.668149
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 499 Norm Difference for worker 144 is 0.911644
INFO:root:FL Epoch: 499 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1139
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.849909
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321566
INFO:root:FL Epoch: 499 Norm Difference for worker 1139 is 0.818333
INFO:root:FL Epoch: 499 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1156
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617466
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289796
INFO:root:FL Epoch: 499 Norm Difference for worker 1156 is 0.834241
INFO:root:FL Epoch: 499 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :598
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.335397
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343822
INFO:root:FL Epoch: 499 Norm Difference for worker 598 is 0.82504
INFO:root:FL Epoch: 499 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :650
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358762
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369778
INFO:root:FL Epoch: 499 Norm Difference for worker 650 is 0.880973
INFO:root:FL Epoch: 499 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1139
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 499 Ends   ===================
INFO:root:Epoch:499 Global Model Test Loss:0.5175278765313766 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:499 Global Model Backdoor Test Loss:0.10983379433552425                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 500 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 500 Workers Selected : [1467, 1937, 1312, 1780, 228, 852, 941, 1896, 414, 1088]
INFO:root:FL Epoch: 500 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 500 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 500 Training on worker :1467
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696276
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452703
INFO:root:FL Epoch: 500 Norm Difference for worker 1467 is 0.871147
INFO:root:FL Epoch: 500 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1937
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454106
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311207
INFO:root:FL Epoch: 500 Norm Difference for worker 1937 is 0.888147
INFO:root:FL Epoch: 500 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1312
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437982
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415451
INFO:root:FL Epoch: 500 Norm Difference for worker 1312 is 0.890029
INFO:root:FL Epoch: 500 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1780
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515348
INFO:root:Worker: 1780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440538
INFO:root:FL Epoch: 500 Norm Difference for worker 1780 is 0.781193
INFO:root:FL Epoch: 500 Done on worker:1780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :228
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.351392
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.346336
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 500 Norm Difference for worker 228 is 0.770612
INFO:root:FL Epoch: 500 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :852
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361979
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404337
INFO:root:FL Epoch: 500 Norm Difference for worker 852 is 0.890826
INFO:root:FL Epoch: 500 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :941
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309009
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322237
INFO:root:FL Epoch: 500 Norm Difference for worker 941 is 0.68603
INFO:root:FL Epoch: 500 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1896
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451736
INFO:root:Worker: 1896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.136911
INFO:root:FL Epoch: 500 Norm Difference for worker 1896 is 0.838573
INFO:root:FL Epoch: 500 Done on worker:1896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :414
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691957
INFO:root:Worker: 414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517187
INFO:root:FL Epoch: 500 Norm Difference for worker 414 is 0.793278
INFO:root:FL Epoch: 500 Done on worker:414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1088
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657240
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302914
INFO:root:FL Epoch: 500 Norm Difference for worker 1088 is 0.752661
INFO:root:FL Epoch: 500 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 941
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 500 Ends   ===================
INFO:root:Epoch:500 Global Model Test Loss:0.5234431501697091 and Test Accuracy:75.0 
INFO:root:Epoch:500 Global Model Backdoor Test Loss:0.11234275996685028                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 501 Begins ===================
INFO:root:FL Epoch: 501 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 501 Workers Selected : [0, 1, 2, 1443, 486, 588, 551, 1025, 195, 320]
INFO:root:FL Epoch: 501 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 501 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 501 Training on worker :0
INFO:root:FL Epoch: 501 Using Learning rate : 0.0036751125485715856 
INFO:root:FL Epoch: 501 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.106585
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249307
INFO:root:FL Epoch: 501 Worker: 0 Backdoor Test Loss: 0.10642233490943909 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 501 Worker: 0 Backdoor Train Loss: 0.142714574187994 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 501 Norm Difference for worker 0 is 0.120376
INFO:root:FL Epoch: 501 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 501 Training on worker :1
INFO:root:FL Epoch: 501 Using Learning rate : 0.0036751125485715856 
INFO:root:FL Epoch: 501 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.167045
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.115135
INFO:root:FL Epoch: 501 Worker: 1 Backdoor Test Loss: 0.10686235626538594 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 501 Worker: 1 Backdoor Train Loss: 0.14392315447330475 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 501 Norm Difference for worker 1 is 0.116422
INFO:root:FL Epoch: 501 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 501 Training on worker :2
INFO:root:FL Epoch: 501 Using Learning rate : 0.0036751125485715856 
INFO:root:FL Epoch: 501 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.077924
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214483
INFO:root:FL Epoch: 501 Worker: 2 Backdoor Test Loss: 0.107178279509147 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 501 Worker: 2 Backdoor Train Loss: 0.1452559232711792 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 501 Norm Difference for worker 2 is 0.112298
INFO:root:FL Epoch: 501 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 501 Training on worker :1443
INFO:root:FL Epoch: 501 Using Learning rate : 0.01837556274285793 
INFO:root:FL Epoch: 501 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776424
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382933
INFO:root:FL Epoch: 501 Norm Difference for worker 1443 is 0.980098
INFO:root:FL Epoch: 501 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 501 Training on worker :486
INFO:root:FL Epoch: 501 Using Learning rate : 0.01837556274285793 
INFO:root:FL Epoch: 501 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568340
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625070
INFO:root:FL Epoch: 501 Norm Difference for worker 486 is 0.934489
INFO:root:FL Epoch: 501 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 501 Training on worker :588
INFO:root:FL Epoch: 501 Using Learning rate : 0.01837556274285793 
INFO:root:FL Epoch: 501 Normal Training
INFO:root:Worker: 588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530050
INFO:root:Worker: 588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659750
INFO:root:FL Epoch: 501 Norm Difference for worker 588 is 0.990264
INFO:root:FL Epoch: 501 Done on worker:588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 501 Training on worker :551
INFO:root:FL Epoch: 501 Using Learning rate : 0.01837556274285793 
INFO:root:FL Epoch: 501 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.231639
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.705195
INFO:root:FL Epoch: 501 Norm Difference for worker 551 is 0.960214
INFO:root:FL Epoch: 501 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 501 Training on worker :1025
INFO:root:FL Epoch: 501 Using Learning rate : 0.01837556274285793 
INFO:root:FL Epoch: 501 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551412
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417750
INFO:root:FL Epoch: 501 Norm Difference for worker 1025 is 0.996318
INFO:root:FL Epoch: 501 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 501 Training on worker :195
INFO:root:FL Epoch: 501 Using Learning rate : 0.01837556274285793 
INFO:root:FL Epoch: 501 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.605243
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.396405
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 501 Norm Difference for worker 195 is 0.910926
INFO:root:FL Epoch: 501 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 501 Training on worker :320
INFO:root:FL Epoch: 501 Using Learning rate : 0.01837556274285793 
INFO:root:FL Epoch: 501 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.415060
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.463348
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 501 Norm Difference for worker 320 is 0.933786
INFO:root:FL Epoch: 501 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 501 Ends   ===================
INFO:root:Epoch:501 Global Model Test Loss:0.5297262773794287 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:501 Global Model Backdoor Test Loss:0.107178279509147                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 502 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 502 Workers Selected : [905, 877, 1238, 1840, 1610, 287, 910, 204, 609, 1756]
INFO:root:FL Epoch: 502 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 502 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 502 Training on worker :905
INFO:root:FL Epoch: 502 Using Learning rate : 0.018338811617372216 
INFO:root:FL Epoch: 502 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628567
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291799
INFO:root:FL Epoch: 502 Norm Difference for worker 905 is 0.971985
INFO:root:FL Epoch: 502 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 502 Training on worker :877
INFO:root:FL Epoch: 502 Using Learning rate : 0.018338811617372216 
INFO:root:FL Epoch: 502 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.951635
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300707
INFO:root:FL Epoch: 502 Norm Difference for worker 877 is 0.946998
INFO:root:FL Epoch: 502 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 502 Training on worker :1238
INFO:root:FL Epoch: 502 Using Learning rate : 0.018338811617372216 
INFO:root:FL Epoch: 502 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418859
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331186
INFO:root:FL Epoch: 502 Norm Difference for worker 1238 is 0.737087
INFO:root:FL Epoch: 502 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 502 Training on worker :1840
INFO:root:FL Epoch: 502 Using Learning rate : 0.018338811617372216 
INFO:root:FL Epoch: 502 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460277
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352455
INFO:root:FL Epoch: 502 Norm Difference for worker 1840 is 0.979602
INFO:root:FL Epoch: 502 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 502 Training on worker :1610
INFO:root:FL Epoch: 502 Using Learning rate : 0.018338811617372216 
INFO:root:FL Epoch: 502 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666304
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562606
INFO:root:FL Epoch: 502 Norm Difference for worker 1610 is 0.983907
INFO:root:FL Epoch: 502 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 502 Training on worker :287
INFO:root:FL Epoch: 502 Using Learning rate : 0.018338811617372216 
INFO:root:FL Epoch: 502 Normal Training
INFO:root:Worker: 287 Train Epoch: 0 [0/201 (0%)]	Loss: 0.802277
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 287 Train Epoch: 1 [0/201 (0%)]	Loss: 0.462129
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 502 Norm Difference for worker 287 is 0.9207
INFO:root:FL Epoch: 502 Done on worker:287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 502 Training on worker :910
INFO:root:FL Epoch: 502 Using Learning rate : 0.018338811617372216 
INFO:root:FL Epoch: 502 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397617
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516026
INFO:root:FL Epoch: 502 Norm Difference for worker 910 is 0.92789
INFO:root:FL Epoch: 502 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 502 Training on worker :204
INFO:root:FL Epoch: 502 Using Learning rate : 0.018338811617372216 
INFO:root:FL Epoch: 502 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.773482
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.279063
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 502 Norm Difference for worker 204 is 0.91772
INFO:root:FL Epoch: 502 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 502 Training on worker :609
INFO:root:FL Epoch: 502 Using Learning rate : 0.018338811617372216 
INFO:root:FL Epoch: 502 Normal Training
INFO:root:Worker: 609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606087
INFO:root:Worker: 609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416777
INFO:root:FL Epoch: 502 Norm Difference for worker 609 is 1.064536
INFO:root:FL Epoch: 502 Done on worker:609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 502 Training on worker :1756
INFO:root:FL Epoch: 502 Using Learning rate : 0.018338811617372216 
INFO:root:FL Epoch: 502 Normal Training
INFO:root:Worker: 1756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490656
INFO:root:Worker: 1756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322852
INFO:root:FL Epoch: 502 Norm Difference for worker 1756 is 1.138753
INFO:root:FL Epoch: 502 Done on worker:1756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1238
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 502 Ends   ===================
INFO:root:Epoch:502 Global Model Test Loss:0.5297491883530336 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:502 Global Model Backdoor Test Loss:0.09604306270678838                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 503 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 503 Workers Selected : [1753, 1756, 1355, 139, 584, 1564, 174, 1418, 1113, 648]
INFO:root:FL Epoch: 503 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 503 Num points on workers: [200 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 503 Training on worker :1753
INFO:root:FL Epoch: 503 Using Learning rate : 0.01830213399413747 
INFO:root:FL Epoch: 503 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.243483
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482648
INFO:root:FL Epoch: 503 Norm Difference for worker 1753 is 0.797024
INFO:root:FL Epoch: 503 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 503 Training on worker :1756
INFO:root:FL Epoch: 503 Using Learning rate : 0.01830213399413747 
INFO:root:FL Epoch: 503 Normal Training
INFO:root:Worker: 1756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642535
INFO:root:Worker: 1756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474626
INFO:root:FL Epoch: 503 Norm Difference for worker 1756 is 1.068744
INFO:root:FL Epoch: 503 Done on worker:1756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 503 Training on worker :1355
INFO:root:FL Epoch: 503 Using Learning rate : 0.01830213399413747 
INFO:root:FL Epoch: 503 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622666
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423354
INFO:root:FL Epoch: 503 Norm Difference for worker 1355 is 1.041116
INFO:root:FL Epoch: 503 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 503 Training on worker :139
INFO:root:FL Epoch: 503 Using Learning rate : 0.01830213399413747 
INFO:root:FL Epoch: 503 Normal Training
INFO:root:Worker: 139 Train Epoch: 0 [0/201 (0%)]	Loss: 0.283977
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 139 Train Epoch: 1 [0/201 (0%)]	Loss: 0.558953
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 503 Norm Difference for worker 139 is 0.90245
INFO:root:FL Epoch: 503 Done on worker:139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 503 Training on worker :584
INFO:root:FL Epoch: 503 Using Learning rate : 0.01830213399413747 
INFO:root:FL Epoch: 503 Normal Training
INFO:root:Worker: 584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478862
INFO:root:Worker: 584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426197
INFO:root:FL Epoch: 503 Norm Difference for worker 584 is 1.046821
INFO:root:FL Epoch: 503 Done on worker:584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 503 Training on worker :1564
INFO:root:FL Epoch: 503 Using Learning rate : 0.01830213399413747 
INFO:root:FL Epoch: 503 Normal Training
INFO:root:Worker: 1564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437225
INFO:root:Worker: 1564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468959
INFO:root:FL Epoch: 503 Norm Difference for worker 1564 is 1.058931
INFO:root:FL Epoch: 503 Done on worker:1564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 503 Training on worker :174
INFO:root:FL Epoch: 503 Using Learning rate : 0.01830213399413747 
INFO:root:FL Epoch: 503 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 1.116998
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.599739
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 503 Norm Difference for worker 174 is 1.039659
INFO:root:FL Epoch: 503 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 503 Training on worker :1418
INFO:root:FL Epoch: 503 Using Learning rate : 0.01830213399413747 
INFO:root:FL Epoch: 503 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585968
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406357
INFO:root:FL Epoch: 503 Norm Difference for worker 1418 is 1.081659
INFO:root:FL Epoch: 503 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 503 Training on worker :1113
INFO:root:FL Epoch: 503 Using Learning rate : 0.01830213399413747 
INFO:root:FL Epoch: 503 Normal Training
INFO:root:Worker: 1113 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709963
INFO:root:Worker: 1113 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312726
INFO:root:FL Epoch: 503 Norm Difference for worker 1113 is 1.030424
INFO:root:FL Epoch: 503 Done on worker:1113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 503 Training on worker :648
INFO:root:FL Epoch: 503 Using Learning rate : 0.01830213399413747 
INFO:root:FL Epoch: 503 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606310
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361311
INFO:root:FL Epoch: 503 Norm Difference for worker 648 is 0.997667
INFO:root:FL Epoch: 503 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1753
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 503 Ends   ===================
INFO:root:Epoch:503 Global Model Test Loss:0.5359218576375175 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:503 Global Model Backdoor Test Loss:0.11744475737214088                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 504 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 504 Workers Selected : [315, 691, 657, 599, 1341, 285, 1303, 1544, 468, 755]
INFO:root:FL Epoch: 504 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 504 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 504 Training on worker :315
INFO:root:FL Epoch: 504 Using Learning rate : 0.018265529726149195 
INFO:root:FL Epoch: 504 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.649601
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.407739
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 504 Norm Difference for worker 315 is 0.87136
INFO:root:FL Epoch: 504 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 504 Training on worker :691
INFO:root:FL Epoch: 504 Using Learning rate : 0.018265529726149195 
INFO:root:FL Epoch: 504 Normal Training
INFO:root:Worker: 691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.217974
INFO:root:Worker: 691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471906
INFO:root:FL Epoch: 504 Norm Difference for worker 691 is 0.936046
INFO:root:FL Epoch: 504 Done on worker:691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 504 Training on worker :657
INFO:root:FL Epoch: 504 Using Learning rate : 0.018265529726149195 
INFO:root:FL Epoch: 504 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788988
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425973
INFO:root:FL Epoch: 504 Norm Difference for worker 657 is 1.062807
INFO:root:FL Epoch: 504 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 504 Training on worker :599
INFO:root:FL Epoch: 504 Using Learning rate : 0.018265529726149195 
INFO:root:FL Epoch: 504 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.786095
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315448
INFO:root:FL Epoch: 504 Norm Difference for worker 599 is 0.979643
INFO:root:FL Epoch: 504 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 504 Training on worker :1341
INFO:root:FL Epoch: 504 Using Learning rate : 0.018265529726149195 
INFO:root:FL Epoch: 504 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.279737
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225615
INFO:root:FL Epoch: 504 Norm Difference for worker 1341 is 0.985142
INFO:root:FL Epoch: 504 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 504 Training on worker :285
INFO:root:FL Epoch: 504 Using Learning rate : 0.018265529726149195 
INFO:root:FL Epoch: 504 Normal Training
INFO:root:Worker: 285 Train Epoch: 0 [0/201 (0%)]	Loss: 0.881306
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 285 Train Epoch: 1 [0/201 (0%)]	Loss: 0.287854
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 504 Norm Difference for worker 285 is 0.974534
INFO:root:FL Epoch: 504 Done on worker:285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 504 Training on worker :1303
INFO:root:FL Epoch: 504 Using Learning rate : 0.018265529726149195 
INFO:root:FL Epoch: 504 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619920
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516515
INFO:root:FL Epoch: 504 Norm Difference for worker 1303 is 0.98112
INFO:root:FL Epoch: 504 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 504 Training on worker :1544
INFO:root:FL Epoch: 504 Using Learning rate : 0.018265529726149195 
INFO:root:FL Epoch: 504 Normal Training
INFO:root:Worker: 1544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741336
INFO:root:Worker: 1544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655201
INFO:root:FL Epoch: 504 Norm Difference for worker 1544 is 1.127629
INFO:root:FL Epoch: 504 Done on worker:1544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 504 Training on worker :468
INFO:root:FL Epoch: 504 Using Learning rate : 0.018265529726149195 
INFO:root:FL Epoch: 504 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.806212
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241721
INFO:root:FL Epoch: 504 Norm Difference for worker 468 is 0.983616
INFO:root:FL Epoch: 504 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 504 Training on worker :755
INFO:root:FL Epoch: 504 Using Learning rate : 0.018265529726149195 
INFO:root:FL Epoch: 504 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572013
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.203922
INFO:root:FL Epoch: 504 Norm Difference for worker 755 is 1.017572
INFO:root:FL Epoch: 504 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 315
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 504 Ends   ===================
INFO:root:Epoch:504 Global Model Test Loss:0.5218395292758942 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:504 Global Model Backdoor Test Loss:0.06904611798624198                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 505 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 505 Workers Selected : [28, 1394, 832, 101, 1000, 1708, 385, 352, 1307, 941]
INFO:root:FL Epoch: 505 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 505 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 505 Training on worker :28
INFO:root:FL Epoch: 505 Using Learning rate : 0.018228998666696895 
INFO:root:FL Epoch: 505 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.323110
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.399494
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 505 Norm Difference for worker 28 is 0.943497
INFO:root:FL Epoch: 505 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 505 Training on worker :1394
INFO:root:FL Epoch: 505 Using Learning rate : 0.018228998666696895 
INFO:root:FL Epoch: 505 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704094
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289124
INFO:root:FL Epoch: 505 Norm Difference for worker 1394 is 1.041613
INFO:root:FL Epoch: 505 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 505 Training on worker :832
INFO:root:FL Epoch: 505 Using Learning rate : 0.018228998666696895 
INFO:root:FL Epoch: 505 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556595
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321164
INFO:root:FL Epoch: 505 Norm Difference for worker 832 is 1.035731
INFO:root:FL Epoch: 505 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 505 Training on worker :101
INFO:root:FL Epoch: 505 Using Learning rate : 0.018228998666696895 
INFO:root:FL Epoch: 505 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.846342
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.374457
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 505 Norm Difference for worker 101 is 0.91508
INFO:root:FL Epoch: 505 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 505 Training on worker :1000
INFO:root:FL Epoch: 505 Using Learning rate : 0.018228998666696895 
INFO:root:FL Epoch: 505 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442632
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380804
INFO:root:FL Epoch: 505 Norm Difference for worker 1000 is 0.94596
INFO:root:FL Epoch: 505 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 505 Training on worker :1708
INFO:root:FL Epoch: 505 Using Learning rate : 0.018228998666696895 
INFO:root:FL Epoch: 505 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705688
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.926555
INFO:root:FL Epoch: 505 Norm Difference for worker 1708 is 0.987738
INFO:root:FL Epoch: 505 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 505 Training on worker :385
INFO:root:FL Epoch: 505 Using Learning rate : 0.018228998666696895 
INFO:root:FL Epoch: 505 Normal Training
INFO:root:Worker: 385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653319
INFO:root:Worker: 385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465786
INFO:root:FL Epoch: 505 Norm Difference for worker 385 is 1.008667
INFO:root:FL Epoch: 505 Done on worker:385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 505 Training on worker :352
INFO:root:FL Epoch: 505 Using Learning rate : 0.018228998666696895 
INFO:root:FL Epoch: 505 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675389
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432752
INFO:root:FL Epoch: 505 Norm Difference for worker 352 is 1.002006
INFO:root:FL Epoch: 505 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 505 Training on worker :1307
INFO:root:FL Epoch: 505 Using Learning rate : 0.018228998666696895 
INFO:root:FL Epoch: 505 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690146
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657026
INFO:root:FL Epoch: 505 Norm Difference for worker 1307 is 0.955003
INFO:root:FL Epoch: 505 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 505 Training on worker :941
INFO:root:FL Epoch: 505 Using Learning rate : 0.018228998666696895 
INFO:root:FL Epoch: 505 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.164645
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390904
INFO:root:FL Epoch: 505 Norm Difference for worker 941 is 0.542437
INFO:root:FL Epoch: 505 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 941
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 505 Ends   ===================
INFO:root:Epoch:505 Global Model Test Loss:0.5337816038552452 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:505 Global Model Backdoor Test Loss:0.06564571832617123                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 506 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 506 Workers Selected : [1489, 606, 1775, 681, 834, 643, 1374, 711, 1459, 538]
INFO:root:FL Epoch: 506 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 506 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 506 Training on worker :1489
INFO:root:FL Epoch: 506 Using Learning rate : 0.018192540669363502 
INFO:root:FL Epoch: 506 Normal Training
INFO:root:Worker: 1489 Train Epoch: 0 [0/200 (0%)]	Loss: 0.876040
INFO:root:Worker: 1489 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499135
INFO:root:FL Epoch: 506 Norm Difference for worker 1489 is 1.158808
INFO:root:FL Epoch: 506 Done on worker:1489
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 506 Training on worker :606
INFO:root:FL Epoch: 506 Using Learning rate : 0.018192540669363502 
INFO:root:FL Epoch: 506 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530267
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173468
INFO:root:FL Epoch: 506 Norm Difference for worker 606 is 0.751262
INFO:root:FL Epoch: 506 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 506 Training on worker :1775
INFO:root:FL Epoch: 506 Using Learning rate : 0.018192540669363502 
INFO:root:FL Epoch: 506 Normal Training
INFO:root:Worker: 1775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.968740
INFO:root:Worker: 1775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279989
INFO:root:FL Epoch: 506 Norm Difference for worker 1775 is 1.112004
INFO:root:FL Epoch: 506 Done on worker:1775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 506 Training on worker :681
INFO:root:FL Epoch: 506 Using Learning rate : 0.018192540669363502 
INFO:root:FL Epoch: 506 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593848
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552213
INFO:root:FL Epoch: 506 Norm Difference for worker 681 is 1.101476
INFO:root:FL Epoch: 506 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 506 Training on worker :834
INFO:root:FL Epoch: 506 Using Learning rate : 0.018192540669363502 
INFO:root:FL Epoch: 506 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661738
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333865
INFO:root:FL Epoch: 506 Norm Difference for worker 834 is 0.990544
INFO:root:FL Epoch: 506 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 506 Training on worker :643
INFO:root:FL Epoch: 506 Using Learning rate : 0.018192540669363502 
INFO:root:FL Epoch: 506 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525869
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508325
INFO:root:FL Epoch: 506 Norm Difference for worker 643 is 1.137593
INFO:root:FL Epoch: 506 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 506 Training on worker :1374
INFO:root:FL Epoch: 506 Using Learning rate : 0.018192540669363502 
INFO:root:FL Epoch: 506 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618210
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548179
INFO:root:FL Epoch: 506 Norm Difference for worker 1374 is 1.016421
INFO:root:FL Epoch: 506 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 506 Training on worker :711
INFO:root:FL Epoch: 506 Using Learning rate : 0.018192540669363502 
INFO:root:FL Epoch: 506 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.810126
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412402
INFO:root:FL Epoch: 506 Norm Difference for worker 711 is 1.071746
INFO:root:FL Epoch: 506 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 506 Training on worker :1459
INFO:root:FL Epoch: 506 Using Learning rate : 0.018192540669363502 
INFO:root:FL Epoch: 506 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.994419
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235797
INFO:root:FL Epoch: 506 Norm Difference for worker 1459 is 1.054413
INFO:root:FL Epoch: 506 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 506 Training on worker :538
INFO:root:FL Epoch: 506 Using Learning rate : 0.018192540669363502 
INFO:root:FL Epoch: 506 Normal Training
INFO:root:Worker: 538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515170
INFO:root:Worker: 538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195461
INFO:root:FL Epoch: 506 Norm Difference for worker 538 is 0.99456
INFO:root:FL Epoch: 506 Done on worker:538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 606
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 506 Ends   ===================
INFO:root:Epoch:506 Global Model Test Loss:0.5321653923567604 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:506 Global Model Backdoor Test Loss:0.08938056230545044                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 507 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 507 Workers Selected : [906, 614, 1894, 1327, 596, 1690, 1186, 1923, 510, 784]
INFO:root:FL Epoch: 507 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 507 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 507 Training on worker :906
INFO:root:FL Epoch: 507 Using Learning rate : 0.018156155588024775 
INFO:root:FL Epoch: 507 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.252248
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.116843
INFO:root:FL Epoch: 507 Norm Difference for worker 906 is 0.674358
INFO:root:FL Epoch: 507 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 507 Training on worker :614
INFO:root:FL Epoch: 507 Using Learning rate : 0.018156155588024775 
INFO:root:FL Epoch: 507 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510912
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679216
INFO:root:FL Epoch: 507 Norm Difference for worker 614 is 1.04356
INFO:root:FL Epoch: 507 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 507 Training on worker :1894
INFO:root:FL Epoch: 507 Using Learning rate : 0.018156155588024775 
INFO:root:FL Epoch: 507 Normal Training
INFO:root:Worker: 1894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.894719
INFO:root:Worker: 1894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558455
INFO:root:FL Epoch: 507 Norm Difference for worker 1894 is 0.990224
INFO:root:FL Epoch: 507 Done on worker:1894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 507 Training on worker :1327
INFO:root:FL Epoch: 507 Using Learning rate : 0.018156155588024775 
INFO:root:FL Epoch: 507 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482157
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276044
INFO:root:FL Epoch: 507 Norm Difference for worker 1327 is 0.953472
INFO:root:FL Epoch: 507 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 507 Training on worker :596
INFO:root:FL Epoch: 507 Using Learning rate : 0.018156155588024775 
INFO:root:FL Epoch: 507 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760665
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420794
INFO:root:FL Epoch: 507 Norm Difference for worker 596 is 0.964323
INFO:root:FL Epoch: 507 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 507 Training on worker :1690
INFO:root:FL Epoch: 507 Using Learning rate : 0.018156155588024775 
INFO:root:FL Epoch: 507 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.828936
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466587
INFO:root:FL Epoch: 507 Norm Difference for worker 1690 is 1.001759
INFO:root:FL Epoch: 507 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 507 Training on worker :1186
INFO:root:FL Epoch: 507 Using Learning rate : 0.018156155588024775 
INFO:root:FL Epoch: 507 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.895264
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465054
INFO:root:FL Epoch: 507 Norm Difference for worker 1186 is 1.044802
INFO:root:FL Epoch: 507 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 507 Training on worker :1923
INFO:root:FL Epoch: 507 Using Learning rate : 0.018156155588024775 
INFO:root:FL Epoch: 507 Normal Training
INFO:root:Worker: 1923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554445
INFO:root:Worker: 1923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289858
INFO:root:FL Epoch: 507 Norm Difference for worker 1923 is 1.003028
INFO:root:FL Epoch: 507 Done on worker:1923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 507 Training on worker :510
INFO:root:FL Epoch: 507 Using Learning rate : 0.018156155588024775 
INFO:root:FL Epoch: 507 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507332
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440825
INFO:root:FL Epoch: 507 Norm Difference for worker 510 is 1.048461
INFO:root:FL Epoch: 507 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 507 Training on worker :784
INFO:root:FL Epoch: 507 Using Learning rate : 0.018156155588024775 
INFO:root:FL Epoch: 507 Normal Training
INFO:root:Worker: 784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334596
INFO:root:Worker: 784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309508
INFO:root:FL Epoch: 507 Norm Difference for worker 784 is 0.830185
INFO:root:FL Epoch: 507 Done on worker:784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 906
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 507 Ends   ===================
INFO:root:Epoch:507 Global Model Test Loss:0.5816336335504756 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:507 Global Model Backdoor Test Loss:0.10722710316379865                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 508 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 508 Workers Selected : [1266, 207, 1584, 252, 1605, 1486, 1617, 525, 1340, 1914]
INFO:root:FL Epoch: 508 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 508 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 508 Training on worker :1266
INFO:root:FL Epoch: 508 Using Learning rate : 0.018119843276848725 
INFO:root:FL Epoch: 508 Normal Training
INFO:root:Worker: 1266 Train Epoch: 0 [0/200 (0%)]	Loss: 1.007868
INFO:root:Worker: 1266 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342996
INFO:root:FL Epoch: 508 Norm Difference for worker 1266 is 1.158394
INFO:root:FL Epoch: 508 Done on worker:1266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 508 Training on worker :207
INFO:root:FL Epoch: 508 Using Learning rate : 0.018119843276848725 
INFO:root:FL Epoch: 508 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.857619
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.592981
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 508 Norm Difference for worker 207 is 1.284777
INFO:root:FL Epoch: 508 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 508 Training on worker :1584
INFO:root:FL Epoch: 508 Using Learning rate : 0.018119843276848725 
INFO:root:FL Epoch: 508 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636356
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494855
INFO:root:FL Epoch: 508 Norm Difference for worker 1584 is 1.162045
INFO:root:FL Epoch: 508 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 508 Training on worker :252
INFO:root:FL Epoch: 508 Using Learning rate : 0.018119843276848725 
INFO:root:FL Epoch: 508 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.349172
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.337073
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 508 Norm Difference for worker 252 is 1.064072
INFO:root:FL Epoch: 508 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 508 Training on worker :1605
INFO:root:FL Epoch: 508 Using Learning rate : 0.018119843276848725 
INFO:root:FL Epoch: 508 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.875113
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297546
INFO:root:FL Epoch: 508 Norm Difference for worker 1605 is 1.21621
INFO:root:FL Epoch: 508 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 508 Training on worker :1486
INFO:root:FL Epoch: 508 Using Learning rate : 0.018119843276848725 
INFO:root:FL Epoch: 508 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.832150
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593697
INFO:root:FL Epoch: 508 Norm Difference for worker 1486 is 1.206792
INFO:root:FL Epoch: 508 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 508 Training on worker :1617
INFO:root:FL Epoch: 508 Using Learning rate : 0.018119843276848725 
INFO:root:FL Epoch: 508 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354192
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653506
INFO:root:FL Epoch: 508 Norm Difference for worker 1617 is 1.173408
INFO:root:FL Epoch: 508 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 508 Training on worker :525
INFO:root:FL Epoch: 508 Using Learning rate : 0.018119843276848725 
INFO:root:FL Epoch: 508 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607195
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214794
INFO:root:FL Epoch: 508 Norm Difference for worker 525 is 1.153271
INFO:root:FL Epoch: 508 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 508 Training on worker :1340
INFO:root:FL Epoch: 508 Using Learning rate : 0.018119843276848725 
INFO:root:FL Epoch: 508 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673451
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405579
INFO:root:FL Epoch: 508 Norm Difference for worker 1340 is 1.215966
INFO:root:FL Epoch: 508 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 508 Training on worker :1914
INFO:root:FL Epoch: 508 Using Learning rate : 0.018119843276848725 
INFO:root:FL Epoch: 508 Normal Training
INFO:root:Worker: 1914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526392
INFO:root:Worker: 1914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519821
INFO:root:FL Epoch: 508 Norm Difference for worker 1914 is 1.099766
INFO:root:FL Epoch: 508 Done on worker:1914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1914
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 508 Ends   ===================
INFO:root:Epoch:508 Global Model Test Loss:0.4941224420771879 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:508 Global Model Backdoor Test Loss:0.06770430256923039                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 509 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 509 Workers Selected : [21, 1041, 1494, 370, 1006, 19, 1204, 583, 1772, 502]
INFO:root:FL Epoch: 509 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 509 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 509 Training on worker :21
INFO:root:FL Epoch: 509 Using Learning rate : 0.01808360359029503 
INFO:root:FL Epoch: 509 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.608423
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.489760
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 509 Norm Difference for worker 21 is 0.901882
INFO:root:FL Epoch: 509 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 509 Training on worker :1041
INFO:root:FL Epoch: 509 Using Learning rate : 0.01808360359029503 
INFO:root:FL Epoch: 509 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754805
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533604
INFO:root:FL Epoch: 509 Norm Difference for worker 1041 is 0.978808
INFO:root:FL Epoch: 509 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 509 Training on worker :1494
INFO:root:FL Epoch: 509 Using Learning rate : 0.01808360359029503 
INFO:root:FL Epoch: 509 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696683
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658575
INFO:root:FL Epoch: 509 Norm Difference for worker 1494 is 0.959392
INFO:root:FL Epoch: 509 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 509 Training on worker :370
INFO:root:FL Epoch: 509 Using Learning rate : 0.01808360359029503 
INFO:root:FL Epoch: 509 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474706
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.738164
INFO:root:FL Epoch: 509 Norm Difference for worker 370 is 0.846852
INFO:root:FL Epoch: 509 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 509 Training on worker :1006
INFO:root:FL Epoch: 509 Using Learning rate : 0.01808360359029503 
INFO:root:FL Epoch: 509 Normal Training
INFO:root:Worker: 1006 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581365
INFO:root:Worker: 1006 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524600
INFO:root:FL Epoch: 509 Norm Difference for worker 1006 is 0.898905
INFO:root:FL Epoch: 509 Done on worker:1006
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 509 Training on worker :19
INFO:root:FL Epoch: 509 Using Learning rate : 0.01808360359029503 
INFO:root:FL Epoch: 509 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.531765
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.509357
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 509 Norm Difference for worker 19 is 0.840485
INFO:root:FL Epoch: 509 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 509 Training on worker :1204
INFO:root:FL Epoch: 509 Using Learning rate : 0.01808360359029503 
INFO:root:FL Epoch: 509 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349188
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191598
INFO:root:FL Epoch: 509 Norm Difference for worker 1204 is 0.861792
INFO:root:FL Epoch: 509 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 509 Training on worker :583
INFO:root:FL Epoch: 509 Using Learning rate : 0.01808360359029503 
INFO:root:FL Epoch: 509 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699518
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429587
INFO:root:FL Epoch: 509 Norm Difference for worker 583 is 0.93274
INFO:root:FL Epoch: 509 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 509 Training on worker :1772
INFO:root:FL Epoch: 509 Using Learning rate : 0.01808360359029503 
INFO:root:FL Epoch: 509 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463966
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476568
INFO:root:FL Epoch: 509 Norm Difference for worker 1772 is 1.023485
INFO:root:FL Epoch: 509 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 509 Training on worker :502
INFO:root:FL Epoch: 509 Using Learning rate : 0.01808360359029503 
INFO:root:FL Epoch: 509 Normal Training
INFO:root:Worker: 502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685635
INFO:root:Worker: 502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310649
INFO:root:FL Epoch: 509 Norm Difference for worker 502 is 0.908392
INFO:root:FL Epoch: 509 Done on worker:502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 19
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 509 Ends   ===================
INFO:root:Epoch:509 Global Model Test Loss:0.4865894492934732 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:509 Global Model Backdoor Test Loss:0.11145199959476788                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 510 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 510 Workers Selected : [167, 201, 537, 1676, 1913, 909, 1534, 585, 658, 1332]
INFO:root:FL Epoch: 510 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 510 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 510 Training on worker :167
INFO:root:FL Epoch: 510 Using Learning rate : 0.01804743638311444 
INFO:root:FL Epoch: 510 Normal Training
INFO:root:Worker: 167 Train Epoch: 0 [0/201 (0%)]	Loss: 0.640269
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 167 Train Epoch: 1 [0/201 (0%)]	Loss: 0.418165
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 510 Norm Difference for worker 167 is 0.92658
INFO:root:FL Epoch: 510 Done on worker:167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 510 Training on worker :201
INFO:root:FL Epoch: 510 Using Learning rate : 0.01804743638311444 
INFO:root:FL Epoch: 510 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.878820
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.620959
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 510 Norm Difference for worker 201 is 0.912502
INFO:root:FL Epoch: 510 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 510 Training on worker :537
INFO:root:FL Epoch: 510 Using Learning rate : 0.01804743638311444 
INFO:root:FL Epoch: 510 Normal Training
INFO:root:Worker: 537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580943
INFO:root:Worker: 537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416594
INFO:root:FL Epoch: 510 Norm Difference for worker 537 is 1.014859
INFO:root:FL Epoch: 510 Done on worker:537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 510 Training on worker :1676
INFO:root:FL Epoch: 510 Using Learning rate : 0.01804743638311444 
INFO:root:FL Epoch: 510 Normal Training
INFO:root:Worker: 1676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.988649
INFO:root:Worker: 1676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478275
INFO:root:FL Epoch: 510 Norm Difference for worker 1676 is 1.032891
INFO:root:FL Epoch: 510 Done on worker:1676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 510 Training on worker :1913
INFO:root:FL Epoch: 510 Using Learning rate : 0.01804743638311444 
INFO:root:FL Epoch: 510 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.322698
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246798
INFO:root:FL Epoch: 510 Norm Difference for worker 1913 is 0.896715
INFO:root:FL Epoch: 510 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 510 Training on worker :909
INFO:root:FL Epoch: 510 Using Learning rate : 0.01804743638311444 
INFO:root:FL Epoch: 510 Normal Training
INFO:root:Worker: 909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692096
INFO:root:Worker: 909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.736443
INFO:root:FL Epoch: 510 Norm Difference for worker 909 is 0.890223
INFO:root:FL Epoch: 510 Done on worker:909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 510 Training on worker :1534
INFO:root:FL Epoch: 510 Using Learning rate : 0.01804743638311444 
INFO:root:FL Epoch: 510 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720109
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362177
INFO:root:FL Epoch: 510 Norm Difference for worker 1534 is 0.984404
INFO:root:FL Epoch: 510 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 510 Training on worker :585
INFO:root:FL Epoch: 510 Using Learning rate : 0.01804743638311444 
INFO:root:FL Epoch: 510 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516140
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338160
INFO:root:FL Epoch: 510 Norm Difference for worker 585 is 0.964732
INFO:root:FL Epoch: 510 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 510 Training on worker :658
INFO:root:FL Epoch: 510 Using Learning rate : 0.01804743638311444 
INFO:root:FL Epoch: 510 Normal Training
INFO:root:Worker: 658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296123
INFO:root:Worker: 658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293128
INFO:root:FL Epoch: 510 Norm Difference for worker 658 is 0.972652
INFO:root:FL Epoch: 510 Done on worker:658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 510 Training on worker :1332
INFO:root:FL Epoch: 510 Using Learning rate : 0.01804743638311444 
INFO:root:FL Epoch: 510 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426329
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424435
INFO:root:FL Epoch: 510 Norm Difference for worker 1332 is 0.960157
INFO:root:FL Epoch: 510 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 909
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 510 Ends   ===================
INFO:root:Epoch:510 Global Model Test Loss:0.49265432182480307 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:510 Global Model Backdoor Test Loss:0.10883904745181401                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 511 Begins ===================
INFO:root:FL Epoch: 511 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 511 Workers Selected : [0, 1, 2, 1910, 621, 208, 1255, 860, 680, 1770]
INFO:root:FL Epoch: 511 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 511 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 511 Training on worker :0
INFO:root:FL Epoch: 511 Using Learning rate : 0.003602268302069642 
INFO:root:FL Epoch: 511 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.149603
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184180
INFO:root:FL Epoch: 511 Worker: 0 Backdoor Test Loss: 0.10344030832250913 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 511 Worker: 0 Backdoor Train Loss: 0.1526603400707245 Backdoor Train Accuracy: 97.5
INFO:root:FL Epoch: 511 Norm Difference for worker 0 is 0.113285
INFO:root:FL Epoch: 511 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 511 Training on worker :1
INFO:root:FL Epoch: 511 Using Learning rate : 0.003602268302069642 
INFO:root:FL Epoch: 511 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.120371
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.125103
INFO:root:FL Epoch: 511 Worker: 1 Backdoor Test Loss: 0.10247712582349777 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 511 Worker: 1 Backdoor Train Loss: 0.15295065939426422 Backdoor Train Accuracy: 97.5
INFO:root:FL Epoch: 511 Norm Difference for worker 1 is 0.115513
INFO:root:FL Epoch: 511 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 511 Training on worker :2
INFO:root:FL Epoch: 511 Using Learning rate : 0.003602268302069642 
INFO:root:FL Epoch: 511 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.212476
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.129639
INFO:root:FL Epoch: 511 Worker: 2 Backdoor Test Loss: 0.10096685712536176 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 511 Worker: 2 Backdoor Train Loss: 0.15260933265089988 Backdoor Train Accuracy: 97.5
INFO:root:FL Epoch: 511 Norm Difference for worker 2 is 0.11718
INFO:root:FL Epoch: 511 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 511 Training on worker :1910
INFO:root:FL Epoch: 511 Using Learning rate : 0.01801134151034821 
INFO:root:FL Epoch: 511 Normal Training
INFO:root:Worker: 1910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409930
INFO:root:Worker: 1910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404839
INFO:root:FL Epoch: 511 Norm Difference for worker 1910 is 0.859912
INFO:root:FL Epoch: 511 Done on worker:1910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 511 Training on worker :621
INFO:root:FL Epoch: 511 Using Learning rate : 0.01801134151034821 
INFO:root:FL Epoch: 511 Normal Training
INFO:root:Worker: 621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.767741
INFO:root:Worker: 621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507555
INFO:root:FL Epoch: 511 Norm Difference for worker 621 is 0.790086
INFO:root:FL Epoch: 511 Done on worker:621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 511 Training on worker :208
INFO:root:FL Epoch: 511 Using Learning rate : 0.01801134151034821 
INFO:root:FL Epoch: 511 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.349563
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.382901
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 511 Norm Difference for worker 208 is 0.794062
INFO:root:FL Epoch: 511 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 511 Training on worker :1255
INFO:root:FL Epoch: 511 Using Learning rate : 0.01801134151034821 
INFO:root:FL Epoch: 511 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542881
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524739
INFO:root:FL Epoch: 511 Norm Difference for worker 1255 is 0.85156
INFO:root:FL Epoch: 511 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 511 Training on worker :860
INFO:root:FL Epoch: 511 Using Learning rate : 0.01801134151034821 
INFO:root:FL Epoch: 511 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698786
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429650
INFO:root:FL Epoch: 511 Norm Difference for worker 860 is 0.877672
INFO:root:FL Epoch: 511 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 511 Training on worker :680
INFO:root:FL Epoch: 511 Using Learning rate : 0.01801134151034821 
INFO:root:FL Epoch: 511 Normal Training
INFO:root:Worker: 680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304154
INFO:root:Worker: 680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495330
INFO:root:FL Epoch: 511 Norm Difference for worker 680 is 0.771507
INFO:root:FL Epoch: 511 Done on worker:680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 511 Training on worker :1770
INFO:root:FL Epoch: 511 Using Learning rate : 0.01801134151034821 
INFO:root:FL Epoch: 511 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690216
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352922
INFO:root:FL Epoch: 511 Norm Difference for worker 1770 is 0.803667
INFO:root:FL Epoch: 511 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 511 Ends   ===================
INFO:root:Epoch:511 Global Model Test Loss:0.4941856528029722 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:511 Global Model Backdoor Test Loss:0.10096685712536176                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 512 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 512 Workers Selected : [682, 445, 1687, 664, 651, 289, 709, 742, 1093, 800]
INFO:root:FL Epoch: 512 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 512 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 512 Training on worker :682
INFO:root:FL Epoch: 512 Using Learning rate : 0.017975318827327513 
INFO:root:FL Epoch: 512 Normal Training
INFO:root:Worker: 682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626321
INFO:root:Worker: 682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.744603
INFO:root:FL Epoch: 512 Norm Difference for worker 682 is 0.933699
INFO:root:FL Epoch: 512 Done on worker:682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 512 Training on worker :445
INFO:root:FL Epoch: 512 Using Learning rate : 0.017975318827327513 
INFO:root:FL Epoch: 512 Normal Training
INFO:root:Worker: 445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462407
INFO:root:Worker: 445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481221
INFO:root:FL Epoch: 512 Norm Difference for worker 445 is 0.832875
INFO:root:FL Epoch: 512 Done on worker:445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 512 Training on worker :1687
INFO:root:FL Epoch: 512 Using Learning rate : 0.017975318827327513 
INFO:root:FL Epoch: 512 Normal Training
INFO:root:Worker: 1687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774125
INFO:root:Worker: 1687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565307
INFO:root:FL Epoch: 512 Norm Difference for worker 1687 is 0.90246
INFO:root:FL Epoch: 512 Done on worker:1687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 512 Training on worker :664
INFO:root:FL Epoch: 512 Using Learning rate : 0.017975318827327513 
INFO:root:FL Epoch: 512 Normal Training
INFO:root:Worker: 664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529468
INFO:root:Worker: 664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387668
INFO:root:FL Epoch: 512 Norm Difference for worker 664 is 0.897183
INFO:root:FL Epoch: 512 Done on worker:664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 512 Training on worker :651
INFO:root:FL Epoch: 512 Using Learning rate : 0.017975318827327513 
INFO:root:FL Epoch: 512 Normal Training
INFO:root:Worker: 651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394116
INFO:root:Worker: 651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424620
INFO:root:FL Epoch: 512 Norm Difference for worker 651 is 0.881267
INFO:root:FL Epoch: 512 Done on worker:651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 512 Training on worker :289
INFO:root:FL Epoch: 512 Using Learning rate : 0.017975318827327513 
INFO:root:FL Epoch: 512 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.735190
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.361966
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 512 Norm Difference for worker 289 is 0.751068
INFO:root:FL Epoch: 512 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 512 Training on worker :709
INFO:root:FL Epoch: 512 Using Learning rate : 0.017975318827327513 
INFO:root:FL Epoch: 512 Normal Training
INFO:root:Worker: 709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677653
INFO:root:Worker: 709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439856
INFO:root:FL Epoch: 512 Norm Difference for worker 709 is 0.821964
INFO:root:FL Epoch: 512 Done on worker:709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 512 Training on worker :742
INFO:root:FL Epoch: 512 Using Learning rate : 0.017975318827327513 
INFO:root:FL Epoch: 512 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424181
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386415
INFO:root:FL Epoch: 512 Norm Difference for worker 742 is 0.842648
INFO:root:FL Epoch: 512 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 512 Training on worker :1093
INFO:root:FL Epoch: 512 Using Learning rate : 0.017975318827327513 
INFO:root:FL Epoch: 512 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624829
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298556
INFO:root:FL Epoch: 512 Norm Difference for worker 1093 is 0.82647
INFO:root:FL Epoch: 512 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 512 Training on worker :800
INFO:root:FL Epoch: 512 Using Learning rate : 0.017975318827327513 
INFO:root:FL Epoch: 512 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470560
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245109
INFO:root:FL Epoch: 512 Norm Difference for worker 800 is 0.84879
INFO:root:FL Epoch: 512 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 289
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 512 Ends   ===================
INFO:root:Epoch:512 Global Model Test Loss:0.49804484318284425 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:512 Global Model Backdoor Test Loss:0.11374154190222423                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 513 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 513 Workers Selected : [1508, 834, 1190, 29, 1700, 246, 1120, 1788, 578, 729]
INFO:root:FL Epoch: 513 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 513 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 513 Training on worker :1508
INFO:root:FL Epoch: 513 Using Learning rate : 0.017939368189672858 
INFO:root:FL Epoch: 513 Normal Training
INFO:root:Worker: 1508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534615
INFO:root:Worker: 1508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520491
INFO:root:FL Epoch: 513 Norm Difference for worker 1508 is 0.790888
INFO:root:FL Epoch: 513 Done on worker:1508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 513 Training on worker :834
INFO:root:FL Epoch: 513 Using Learning rate : 0.017939368189672858 
INFO:root:FL Epoch: 513 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445947
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470612
INFO:root:FL Epoch: 513 Norm Difference for worker 834 is 0.865204
INFO:root:FL Epoch: 513 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 513 Training on worker :1190
INFO:root:FL Epoch: 513 Using Learning rate : 0.017939368189672858 
INFO:root:FL Epoch: 513 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424174
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423974
INFO:root:FL Epoch: 513 Norm Difference for worker 1190 is 0.720529
INFO:root:FL Epoch: 513 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 513 Training on worker :29
INFO:root:FL Epoch: 513 Using Learning rate : 0.017939368189672858 
INFO:root:FL Epoch: 513 Normal Training
INFO:root:Worker: 29 Train Epoch: 0 [0/201 (0%)]	Loss: 0.482346
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 29 Train Epoch: 1 [0/201 (0%)]	Loss: 0.420118
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 513 Norm Difference for worker 29 is 0.872839
INFO:root:FL Epoch: 513 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 513 Training on worker :1700
INFO:root:FL Epoch: 513 Using Learning rate : 0.017939368189672858 
INFO:root:FL Epoch: 513 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614936
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360779
INFO:root:FL Epoch: 513 Norm Difference for worker 1700 is 0.826805
INFO:root:FL Epoch: 513 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 513 Training on worker :246
INFO:root:FL Epoch: 513 Using Learning rate : 0.017939368189672858 
INFO:root:FL Epoch: 513 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593384
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.635387
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 513 Norm Difference for worker 246 is 0.753352
INFO:root:FL Epoch: 513 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 513 Training on worker :1120
INFO:root:FL Epoch: 513 Using Learning rate : 0.017939368189672858 
INFO:root:FL Epoch: 513 Normal Training
INFO:root:Worker: 1120 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321158
INFO:root:Worker: 1120 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362859
INFO:root:FL Epoch: 513 Norm Difference for worker 1120 is 0.788271
INFO:root:FL Epoch: 513 Done on worker:1120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 513 Training on worker :1788
INFO:root:FL Epoch: 513 Using Learning rate : 0.017939368189672858 
INFO:root:FL Epoch: 513 Normal Training
INFO:root:Worker: 1788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664537
INFO:root:Worker: 1788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506221
INFO:root:FL Epoch: 513 Norm Difference for worker 1788 is 0.81312
INFO:root:FL Epoch: 513 Done on worker:1788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 513 Training on worker :578
INFO:root:FL Epoch: 513 Using Learning rate : 0.017939368189672858 
INFO:root:FL Epoch: 513 Normal Training
INFO:root:Worker: 578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632338
INFO:root:Worker: 578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462650
INFO:root:FL Epoch: 513 Norm Difference for worker 578 is 0.885069
INFO:root:FL Epoch: 513 Done on worker:578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 513 Training on worker :729
INFO:root:FL Epoch: 513 Using Learning rate : 0.017939368189672858 
INFO:root:FL Epoch: 513 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.331316
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506369
INFO:root:FL Epoch: 513 Norm Difference for worker 729 is 0.825928
INFO:root:FL Epoch: 513 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1190
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 513 Ends   ===================
INFO:root:Epoch:513 Global Model Test Loss:0.49407121889731465 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:513 Global Model Backdoor Test Loss:0.06735033417741458                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 514 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 514 Workers Selected : [1599, 1102, 743, 1678, 1810, 800, 1839, 750, 1145, 1449]
INFO:root:FL Epoch: 514 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 514 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 514 Training on worker :1599
INFO:root:FL Epoch: 514 Using Learning rate : 0.017903489453293512 
INFO:root:FL Epoch: 514 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.895448
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390883
INFO:root:FL Epoch: 514 Norm Difference for worker 1599 is 0.926094
INFO:root:FL Epoch: 514 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 514 Training on worker :1102
INFO:root:FL Epoch: 514 Using Learning rate : 0.017903489453293512 
INFO:root:FL Epoch: 514 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772615
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437725
INFO:root:FL Epoch: 514 Norm Difference for worker 1102 is 0.931048
INFO:root:FL Epoch: 514 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 514 Training on worker :743
INFO:root:FL Epoch: 514 Using Learning rate : 0.017903489453293512 
INFO:root:FL Epoch: 514 Normal Training
INFO:root:Worker: 743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.914085
INFO:root:Worker: 743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376558
INFO:root:FL Epoch: 514 Norm Difference for worker 743 is 0.899553
INFO:root:FL Epoch: 514 Done on worker:743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 514 Training on worker :1678
INFO:root:FL Epoch: 514 Using Learning rate : 0.017903489453293512 
INFO:root:FL Epoch: 514 Normal Training
INFO:root:Worker: 1678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592043
INFO:root:Worker: 1678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217458
INFO:root:FL Epoch: 514 Norm Difference for worker 1678 is 0.803055
INFO:root:FL Epoch: 514 Done on worker:1678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 514 Training on worker :1810
INFO:root:FL Epoch: 514 Using Learning rate : 0.017903489453293512 
INFO:root:FL Epoch: 514 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374228
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286592
INFO:root:FL Epoch: 514 Norm Difference for worker 1810 is 0.748563
INFO:root:FL Epoch: 514 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 514 Training on worker :800
INFO:root:FL Epoch: 514 Using Learning rate : 0.017903489453293512 
INFO:root:FL Epoch: 514 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.311135
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545399
INFO:root:FL Epoch: 514 Norm Difference for worker 800 is 0.933299
INFO:root:FL Epoch: 514 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 514 Training on worker :1839
INFO:root:FL Epoch: 514 Using Learning rate : 0.017903489453293512 
INFO:root:FL Epoch: 514 Normal Training
INFO:root:Worker: 1839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308086
INFO:root:Worker: 1839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365994
INFO:root:FL Epoch: 514 Norm Difference for worker 1839 is 0.946868
INFO:root:FL Epoch: 514 Done on worker:1839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 514 Training on worker :750
INFO:root:FL Epoch: 514 Using Learning rate : 0.017903489453293512 
INFO:root:FL Epoch: 514 Normal Training
INFO:root:Worker: 750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735233
INFO:root:Worker: 750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283090
INFO:root:FL Epoch: 514 Norm Difference for worker 750 is 0.957351
INFO:root:FL Epoch: 514 Done on worker:750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 514 Training on worker :1145
INFO:root:FL Epoch: 514 Using Learning rate : 0.017903489453293512 
INFO:root:FL Epoch: 514 Normal Training
INFO:root:Worker: 1145 Train Epoch: 0 [0/200 (0%)]	Loss: 0.834194
INFO:root:Worker: 1145 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401281
INFO:root:FL Epoch: 514 Norm Difference for worker 1145 is 0.948975
INFO:root:FL Epoch: 514 Done on worker:1145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 514 Training on worker :1449
INFO:root:FL Epoch: 514 Using Learning rate : 0.017903489453293512 
INFO:root:FL Epoch: 514 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499480
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695990
INFO:root:FL Epoch: 514 Norm Difference for worker 1449 is 1.018094
INFO:root:FL Epoch: 514 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1810
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 514 Ends   ===================
INFO:root:Epoch:514 Global Model Test Loss:0.510058557285982 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:514 Global Model Backdoor Test Loss:0.09383631187180679                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 515 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 515 Workers Selected : [984, 720, 1397, 1394, 1003, 1673, 1271, 1114, 1740, 185]
INFO:root:FL Epoch: 515 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 515 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 515 Training on worker :984
INFO:root:FL Epoch: 515 Using Learning rate : 0.017867682474386925 
INFO:root:FL Epoch: 515 Normal Training
INFO:root:Worker: 984 Train Epoch: 0 [0/200 (0%)]	Loss: 0.318088
INFO:root:Worker: 984 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550064
INFO:root:FL Epoch: 515 Norm Difference for worker 984 is 0.908239
INFO:root:FL Epoch: 515 Done on worker:984
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 515 Training on worker :720
INFO:root:FL Epoch: 515 Using Learning rate : 0.017867682474386925 
INFO:root:FL Epoch: 515 Normal Training
INFO:root:Worker: 720 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371549
INFO:root:Worker: 720 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451216
INFO:root:FL Epoch: 515 Norm Difference for worker 720 is 0.933788
INFO:root:FL Epoch: 515 Done on worker:720
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 515 Training on worker :1397
INFO:root:FL Epoch: 515 Using Learning rate : 0.017867682474386925 
INFO:root:FL Epoch: 515 Normal Training
INFO:root:Worker: 1397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700571
INFO:root:Worker: 1397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308979
INFO:root:FL Epoch: 515 Norm Difference for worker 1397 is 0.854841
INFO:root:FL Epoch: 515 Done on worker:1397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 515 Training on worker :1394
INFO:root:FL Epoch: 515 Using Learning rate : 0.017867682474386925 
INFO:root:FL Epoch: 515 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610521
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324781
INFO:root:FL Epoch: 515 Norm Difference for worker 1394 is 1.027054
INFO:root:FL Epoch: 515 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 515 Training on worker :1003
INFO:root:FL Epoch: 515 Using Learning rate : 0.017867682474386925 
INFO:root:FL Epoch: 515 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572291
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542894
INFO:root:FL Epoch: 515 Norm Difference for worker 1003 is 0.814242
INFO:root:FL Epoch: 515 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 515 Training on worker :1673
INFO:root:FL Epoch: 515 Using Learning rate : 0.017867682474386925 
INFO:root:FL Epoch: 515 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708535
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533393
INFO:root:FL Epoch: 515 Norm Difference for worker 1673 is 0.871482
INFO:root:FL Epoch: 515 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 515 Training on worker :1271
INFO:root:FL Epoch: 515 Using Learning rate : 0.017867682474386925 
INFO:root:FL Epoch: 515 Normal Training
INFO:root:Worker: 1271 Train Epoch: 0 [0/200 (0%)]	Loss: 0.864557
INFO:root:Worker: 1271 Train Epoch: 1 [0/200 (0%)]	Loss: 0.756365
INFO:root:FL Epoch: 515 Norm Difference for worker 1271 is 0.917579
INFO:root:FL Epoch: 515 Done on worker:1271
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 515 Training on worker :1114
INFO:root:FL Epoch: 515 Using Learning rate : 0.017867682474386925 
INFO:root:FL Epoch: 515 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.916625
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459823
INFO:root:FL Epoch: 515 Norm Difference for worker 1114 is 0.985637
INFO:root:FL Epoch: 515 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 515 Training on worker :1740
INFO:root:FL Epoch: 515 Using Learning rate : 0.017867682474386925 
INFO:root:FL Epoch: 515 Normal Training
INFO:root:Worker: 1740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560984
INFO:root:Worker: 1740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652867
INFO:root:FL Epoch: 515 Norm Difference for worker 1740 is 0.914641
INFO:root:FL Epoch: 515 Done on worker:1740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 515 Training on worker :185
INFO:root:FL Epoch: 515 Using Learning rate : 0.017867682474386925 
INFO:root:FL Epoch: 515 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.469381
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.350812
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 515 Norm Difference for worker 185 is 0.891904
INFO:root:FL Epoch: 515 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1003
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 515 Ends   ===================
INFO:root:Epoch:515 Global Model Test Loss:0.4995737075805664 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:515 Global Model Backdoor Test Loss:0.1217936562995116                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 516 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 516 Workers Selected : [1324, 1278, 397, 409, 691, 951, 145, 665, 1649, 1550]
INFO:root:FL Epoch: 516 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 516 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 516 Training on worker :1324
INFO:root:FL Epoch: 516 Using Learning rate : 0.01783194710943815 
INFO:root:FL Epoch: 516 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592040
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447324
INFO:root:FL Epoch: 516 Norm Difference for worker 1324 is 0.858602
INFO:root:FL Epoch: 516 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 516 Training on worker :1278
INFO:root:FL Epoch: 516 Using Learning rate : 0.01783194710943815 
INFO:root:FL Epoch: 516 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387571
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296763
INFO:root:FL Epoch: 516 Norm Difference for worker 1278 is 0.841942
INFO:root:FL Epoch: 516 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 516 Training on worker :397
INFO:root:FL Epoch: 516 Using Learning rate : 0.01783194710943815 
INFO:root:FL Epoch: 516 Normal Training
INFO:root:Worker: 397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524289
INFO:root:Worker: 397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240623
INFO:root:FL Epoch: 516 Norm Difference for worker 397 is 0.846443
INFO:root:FL Epoch: 516 Done on worker:397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 516 Training on worker :409
INFO:root:FL Epoch: 516 Using Learning rate : 0.01783194710943815 
INFO:root:FL Epoch: 516 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622725
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244534
INFO:root:FL Epoch: 516 Norm Difference for worker 409 is 0.839675
INFO:root:FL Epoch: 516 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 516 Training on worker :691
INFO:root:FL Epoch: 516 Using Learning rate : 0.01783194710943815 
INFO:root:FL Epoch: 516 Normal Training
INFO:root:Worker: 691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336526
INFO:root:Worker: 691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369549
INFO:root:FL Epoch: 516 Norm Difference for worker 691 is 0.815527
INFO:root:FL Epoch: 516 Done on worker:691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 516 Training on worker :951
INFO:root:FL Epoch: 516 Using Learning rate : 0.01783194710943815 
INFO:root:FL Epoch: 516 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667937
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427042
INFO:root:FL Epoch: 516 Norm Difference for worker 951 is 0.82836
INFO:root:FL Epoch: 516 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 516 Training on worker :145
INFO:root:FL Epoch: 516 Using Learning rate : 0.01783194710943815 
INFO:root:FL Epoch: 516 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.294967
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.235658
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 516 Norm Difference for worker 145 is 0.740392
INFO:root:FL Epoch: 516 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 516 Training on worker :665
INFO:root:FL Epoch: 516 Using Learning rate : 0.01783194710943815 
INFO:root:FL Epoch: 516 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388056
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469479
INFO:root:FL Epoch: 516 Norm Difference for worker 665 is 0.821473
INFO:root:FL Epoch: 516 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 516 Training on worker :1649
INFO:root:FL Epoch: 516 Using Learning rate : 0.01783194710943815 
INFO:root:FL Epoch: 516 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602581
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446670
INFO:root:FL Epoch: 516 Norm Difference for worker 1649 is 0.843228
INFO:root:FL Epoch: 516 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 516 Training on worker :1550
INFO:root:FL Epoch: 516 Using Learning rate : 0.01783194710943815 
INFO:root:FL Epoch: 516 Normal Training
INFO:root:Worker: 1550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560703
INFO:root:Worker: 1550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464358
INFO:root:FL Epoch: 516 Norm Difference for worker 1550 is 0.971465
INFO:root:FL Epoch: 516 Done on worker:1550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 145
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 516 Ends   ===================
INFO:root:Epoch:516 Global Model Test Loss:0.49651504614773917 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:516 Global Model Backdoor Test Loss:0.09795739501714706                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 517 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 517 Workers Selected : [596, 425, 327, 614, 1586, 1405, 196, 226, 526, 243]
INFO:root:FL Epoch: 517 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 517 Num points on workers: [200 200 201 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 517 Training on worker :596
INFO:root:FL Epoch: 517 Using Learning rate : 0.017796283215219276 
INFO:root:FL Epoch: 517 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472719
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415723
INFO:root:FL Epoch: 517 Norm Difference for worker 596 is 0.817233
INFO:root:FL Epoch: 517 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 517 Training on worker :425
INFO:root:FL Epoch: 517 Using Learning rate : 0.017796283215219276 
INFO:root:FL Epoch: 517 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519676
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427437
INFO:root:FL Epoch: 517 Norm Difference for worker 425 is 0.955131
INFO:root:FL Epoch: 517 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 517 Training on worker :327
INFO:root:FL Epoch: 517 Using Learning rate : 0.017796283215219276 
INFO:root:FL Epoch: 517 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.499421
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.495671
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 517 Norm Difference for worker 327 is 0.893006
INFO:root:FL Epoch: 517 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 517 Training on worker :614
INFO:root:FL Epoch: 517 Using Learning rate : 0.017796283215219276 
INFO:root:FL Epoch: 517 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.239640
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470685
INFO:root:FL Epoch: 517 Norm Difference for worker 614 is 0.850823
INFO:root:FL Epoch: 517 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 517 Training on worker :1586
INFO:root:FL Epoch: 517 Using Learning rate : 0.017796283215219276 
INFO:root:FL Epoch: 517 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309348
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500442
INFO:root:FL Epoch: 517 Norm Difference for worker 1586 is 0.891633
INFO:root:FL Epoch: 517 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 517 Training on worker :1405
INFO:root:FL Epoch: 517 Using Learning rate : 0.017796283215219276 
INFO:root:FL Epoch: 517 Normal Training
INFO:root:Worker: 1405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580149
INFO:root:Worker: 1405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393004
INFO:root:FL Epoch: 517 Norm Difference for worker 1405 is 0.840751
INFO:root:FL Epoch: 517 Done on worker:1405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 517 Training on worker :196
INFO:root:FL Epoch: 517 Using Learning rate : 0.017796283215219276 
INFO:root:FL Epoch: 517 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.383732
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.650355
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 517 Norm Difference for worker 196 is 0.814673
INFO:root:FL Epoch: 517 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 517 Training on worker :226
INFO:root:FL Epoch: 517 Using Learning rate : 0.017796283215219276 
INFO:root:FL Epoch: 517 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.543261
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.493176
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 517 Norm Difference for worker 226 is 0.880397
INFO:root:FL Epoch: 517 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 517 Training on worker :526
INFO:root:FL Epoch: 517 Using Learning rate : 0.017796283215219276 
INFO:root:FL Epoch: 517 Normal Training
INFO:root:Worker: 526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.799254
INFO:root:Worker: 526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313198
INFO:root:FL Epoch: 517 Norm Difference for worker 526 is 0.870903
INFO:root:FL Epoch: 517 Done on worker:526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 517 Training on worker :243
INFO:root:FL Epoch: 517 Using Learning rate : 0.017796283215219276 
INFO:root:FL Epoch: 517 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.360802
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.356528
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 517 Norm Difference for worker 243 is 0.824349
INFO:root:FL Epoch: 517 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 243
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 517 Ends   ===================
INFO:root:Epoch:517 Global Model Test Loss:0.5224762190790737 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:517 Global Model Backdoor Test Loss:0.17082852000991502                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 518 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 518 Workers Selected : [253, 748, 1265, 1438, 1466, 1310, 171, 1495, 820, 920]
INFO:root:FL Epoch: 518 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 518 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 518 Training on worker :253
INFO:root:FL Epoch: 518 Using Learning rate : 0.017760690648788834 
INFO:root:FL Epoch: 518 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541818
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.421377
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 518 Norm Difference for worker 253 is 0.802196
INFO:root:FL Epoch: 518 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 518 Training on worker :748
INFO:root:FL Epoch: 518 Using Learning rate : 0.017760690648788834 
INFO:root:FL Epoch: 518 Normal Training
INFO:root:Worker: 748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624213
INFO:root:Worker: 748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577384
INFO:root:FL Epoch: 518 Norm Difference for worker 748 is 0.919113
INFO:root:FL Epoch: 518 Done on worker:748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 518 Training on worker :1265
INFO:root:FL Epoch: 518 Using Learning rate : 0.017760690648788834 
INFO:root:FL Epoch: 518 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479722
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293361
INFO:root:FL Epoch: 518 Norm Difference for worker 1265 is 0.784604
INFO:root:FL Epoch: 518 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 518 Training on worker :1438
INFO:root:FL Epoch: 518 Using Learning rate : 0.017760690648788834 
INFO:root:FL Epoch: 518 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638195
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458403
INFO:root:FL Epoch: 518 Norm Difference for worker 1438 is 0.770427
INFO:root:FL Epoch: 518 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 518 Training on worker :1466
INFO:root:FL Epoch: 518 Using Learning rate : 0.017760690648788834 
INFO:root:FL Epoch: 518 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714742
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322084
INFO:root:FL Epoch: 518 Norm Difference for worker 1466 is 0.917317
INFO:root:FL Epoch: 518 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 518 Training on worker :1310
INFO:root:FL Epoch: 518 Using Learning rate : 0.017760690648788834 
INFO:root:FL Epoch: 518 Normal Training
INFO:root:Worker: 1310 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413454
INFO:root:Worker: 1310 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455505
INFO:root:FL Epoch: 518 Norm Difference for worker 1310 is 0.787263
INFO:root:FL Epoch: 518 Done on worker:1310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 518 Training on worker :171
INFO:root:FL Epoch: 518 Using Learning rate : 0.017760690648788834 
INFO:root:FL Epoch: 518 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.820058
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.606487
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 518 Norm Difference for worker 171 is 0.819061
INFO:root:FL Epoch: 518 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 518 Training on worker :1495
INFO:root:FL Epoch: 518 Using Learning rate : 0.017760690648788834 
INFO:root:FL Epoch: 518 Normal Training
INFO:root:Worker: 1495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519219
INFO:root:Worker: 1495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376799
INFO:root:FL Epoch: 518 Norm Difference for worker 1495 is 0.799219
INFO:root:FL Epoch: 518 Done on worker:1495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 518 Training on worker :820
INFO:root:FL Epoch: 518 Using Learning rate : 0.017760690648788834 
INFO:root:FL Epoch: 518 Normal Training
INFO:root:Worker: 820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623520
INFO:root:Worker: 820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457481
INFO:root:FL Epoch: 518 Norm Difference for worker 820 is 0.792707
INFO:root:FL Epoch: 518 Done on worker:820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 518 Training on worker :920
INFO:root:FL Epoch: 518 Using Learning rate : 0.017760690648788834 
INFO:root:FL Epoch: 518 Normal Training
INFO:root:Worker: 920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.913729
INFO:root:Worker: 920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545881
INFO:root:FL Epoch: 518 Norm Difference for worker 920 is 0.866068
INFO:root:FL Epoch: 518 Done on worker:920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1438
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 518 Ends   ===================
INFO:root:Epoch:518 Global Model Test Loss:0.5058362185955048 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:518 Global Model Backdoor Test Loss:0.11458314831058185                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 519 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 519 Workers Selected : [1365, 504, 564, 1732, 1905, 1719, 1514, 629, 929, 1382]
INFO:root:FL Epoch: 519 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 519 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 519 Training on worker :1365
INFO:root:FL Epoch: 519 Using Learning rate : 0.01772516926749126 
INFO:root:FL Epoch: 519 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.265028
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368063
INFO:root:FL Epoch: 519 Norm Difference for worker 1365 is 0.784245
INFO:root:FL Epoch: 519 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 519 Training on worker :504
INFO:root:FL Epoch: 519 Using Learning rate : 0.01772516926749126 
INFO:root:FL Epoch: 519 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626730
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611144
INFO:root:FL Epoch: 519 Norm Difference for worker 504 is 0.742363
INFO:root:FL Epoch: 519 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 519 Training on worker :564
INFO:root:FL Epoch: 519 Using Learning rate : 0.01772516926749126 
INFO:root:FL Epoch: 519 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.272703
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480399
INFO:root:FL Epoch: 519 Norm Difference for worker 564 is 0.756918
INFO:root:FL Epoch: 519 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 519 Training on worker :1732
INFO:root:FL Epoch: 519 Using Learning rate : 0.01772516926749126 
INFO:root:FL Epoch: 519 Normal Training
INFO:root:Worker: 1732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422332
INFO:root:Worker: 1732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357396
INFO:root:FL Epoch: 519 Norm Difference for worker 1732 is 0.767486
INFO:root:FL Epoch: 519 Done on worker:1732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 519 Training on worker :1905
INFO:root:FL Epoch: 519 Using Learning rate : 0.01772516926749126 
INFO:root:FL Epoch: 519 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410035
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343679
INFO:root:FL Epoch: 519 Norm Difference for worker 1905 is 0.63079
INFO:root:FL Epoch: 519 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 519 Training on worker :1719
INFO:root:FL Epoch: 519 Using Learning rate : 0.01772516926749126 
INFO:root:FL Epoch: 519 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448635
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404569
INFO:root:FL Epoch: 519 Norm Difference for worker 1719 is 0.760561
INFO:root:FL Epoch: 519 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 519 Training on worker :1514
INFO:root:FL Epoch: 519 Using Learning rate : 0.01772516926749126 
INFO:root:FL Epoch: 519 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533527
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380966
INFO:root:FL Epoch: 519 Norm Difference for worker 1514 is 0.754833
INFO:root:FL Epoch: 519 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 519 Training on worker :629
INFO:root:FL Epoch: 519 Using Learning rate : 0.01772516926749126 
INFO:root:FL Epoch: 519 Normal Training
INFO:root:Worker: 629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564156
INFO:root:Worker: 629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440845
INFO:root:FL Epoch: 519 Norm Difference for worker 629 is 0.756934
INFO:root:FL Epoch: 519 Done on worker:629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 519 Training on worker :929
INFO:root:FL Epoch: 519 Using Learning rate : 0.01772516926749126 
INFO:root:FL Epoch: 519 Normal Training
INFO:root:Worker: 929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.960234
INFO:root:Worker: 929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451332
INFO:root:FL Epoch: 519 Norm Difference for worker 929 is 0.783974
INFO:root:FL Epoch: 519 Done on worker:929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 519 Training on worker :1382
INFO:root:FL Epoch: 519 Using Learning rate : 0.01772516926749126 
INFO:root:FL Epoch: 519 Normal Training
INFO:root:Worker: 1382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493048
INFO:root:Worker: 1382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574122
INFO:root:FL Epoch: 519 Norm Difference for worker 1382 is 0.764087
INFO:root:FL Epoch: 519 Done on worker:1382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1905
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 519 Ends   ===================
INFO:root:Epoch:519 Global Model Test Loss:0.5203740719486686 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:519 Global Model Backdoor Test Loss:0.14481673017144203                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 520 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 520 Workers Selected : [64, 124, 326, 1653, 535, 1504, 1731, 1934, 1210, 1637]
INFO:root:FL Epoch: 520 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 520 Num points on workers: [201 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 520 Training on worker :64
INFO:root:FL Epoch: 520 Using Learning rate : 0.017689718928956277 
INFO:root:FL Epoch: 520 Normal Training
INFO:root:Worker: 64 Train Epoch: 0 [0/201 (0%)]	Loss: 0.522772
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 64 Train Epoch: 1 [0/201 (0%)]	Loss: 0.548113
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 520 Norm Difference for worker 64 is 0.848272
INFO:root:FL Epoch: 520 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 520 Training on worker :124
INFO:root:FL Epoch: 520 Using Learning rate : 0.017689718928956277 
INFO:root:FL Epoch: 520 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.705630
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697530
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 520 Norm Difference for worker 124 is 0.934492
INFO:root:FL Epoch: 520 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 520 Training on worker :326
INFO:root:FL Epoch: 520 Using Learning rate : 0.017689718928956277 
INFO:root:FL Epoch: 520 Normal Training
INFO:root:Worker: 326 Train Epoch: 0 [0/201 (0%)]	Loss: 0.390008
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 326 Train Epoch: 1 [0/201 (0%)]	Loss: 0.516633
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 520 Norm Difference for worker 326 is 0.759881
INFO:root:FL Epoch: 520 Done on worker:326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 520 Training on worker :1653
INFO:root:FL Epoch: 520 Using Learning rate : 0.017689718928956277 
INFO:root:FL Epoch: 520 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372656
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359368
INFO:root:FL Epoch: 520 Norm Difference for worker 1653 is 0.764183
INFO:root:FL Epoch: 520 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 520 Training on worker :535
INFO:root:FL Epoch: 520 Using Learning rate : 0.017689718928956277 
INFO:root:FL Epoch: 520 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445853
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356019
INFO:root:FL Epoch: 520 Norm Difference for worker 535 is 0.711201
INFO:root:FL Epoch: 520 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 520 Training on worker :1504
INFO:root:FL Epoch: 520 Using Learning rate : 0.017689718928956277 
INFO:root:FL Epoch: 520 Normal Training
INFO:root:Worker: 1504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572729
INFO:root:Worker: 1504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409898
INFO:root:FL Epoch: 520 Norm Difference for worker 1504 is 0.814448
INFO:root:FL Epoch: 520 Done on worker:1504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 520 Training on worker :1731
INFO:root:FL Epoch: 520 Using Learning rate : 0.017689718928956277 
INFO:root:FL Epoch: 520 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594567
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311040
INFO:root:FL Epoch: 520 Norm Difference for worker 1731 is 0.804569
INFO:root:FL Epoch: 520 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 520 Training on worker :1934
INFO:root:FL Epoch: 520 Using Learning rate : 0.017689718928956277 
INFO:root:FL Epoch: 520 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699797
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201690
INFO:root:FL Epoch: 520 Norm Difference for worker 1934 is 0.845704
INFO:root:FL Epoch: 520 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 520 Training on worker :1210
INFO:root:FL Epoch: 520 Using Learning rate : 0.017689718928956277 
INFO:root:FL Epoch: 520 Normal Training
INFO:root:Worker: 1210 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663425
INFO:root:Worker: 1210 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345112
INFO:root:FL Epoch: 520 Norm Difference for worker 1210 is 0.846711
INFO:root:FL Epoch: 520 Done on worker:1210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 520 Training on worker :1637
INFO:root:FL Epoch: 520 Using Learning rate : 0.017689718928956277 
INFO:root:FL Epoch: 520 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.799011
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449156
INFO:root:FL Epoch: 520 Norm Difference for worker 1637 is 0.817103
INFO:root:FL Epoch: 520 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 535
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 520 Ends   ===================
INFO:root:Epoch:520 Global Model Test Loss:0.5048388908891117 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:520 Global Model Backdoor Test Loss:0.11999794219930966                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 521 Begins ===================
INFO:root:FL Epoch: 521 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 521 Workers Selected : [0, 1, 2, 1219, 1730, 471, 792, 1830, 1466, 619]
INFO:root:FL Epoch: 521 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 521 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 521 Training on worker :0
INFO:root:FL Epoch: 521 Using Learning rate : 0.0035308678982196723 
INFO:root:FL Epoch: 521 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.148334
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.123894
INFO:root:FL Epoch: 521 Worker: 0 Backdoor Test Loss: 0.10375622535745303 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 521 Worker: 0 Backdoor Train Loss: 0.13104058429598808 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 521 Norm Difference for worker 0 is 0.092636
INFO:root:FL Epoch: 521 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 521 Training on worker :1
INFO:root:FL Epoch: 521 Using Learning rate : 0.0035308678982196723 
INFO:root:FL Epoch: 521 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.160549
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.151391
INFO:root:FL Epoch: 521 Worker: 1 Backdoor Test Loss: 0.10073938965797424 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 521 Worker: 1 Backdoor Train Loss: 0.13020087778568268 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 521 Norm Difference for worker 1 is 0.0973
INFO:root:FL Epoch: 521 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 521 Training on worker :2
INFO:root:FL Epoch: 521 Using Learning rate : 0.0035308678982196723 
INFO:root:FL Epoch: 521 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.128530
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.169108
INFO:root:FL Epoch: 521 Worker: 2 Backdoor Test Loss: 0.10171348974108696 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 521 Worker: 2 Backdoor Train Loss: 0.12974571511149408 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 521 Norm Difference for worker 2 is 0.102401
INFO:root:FL Epoch: 521 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 521 Training on worker :1219
INFO:root:FL Epoch: 521 Using Learning rate : 0.01765433949109836 
INFO:root:FL Epoch: 521 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646464
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615951
INFO:root:FL Epoch: 521 Norm Difference for worker 1219 is 0.856041
INFO:root:FL Epoch: 521 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 521 Training on worker :1730
INFO:root:FL Epoch: 521 Using Learning rate : 0.01765433949109836 
INFO:root:FL Epoch: 521 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519962
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557508
INFO:root:FL Epoch: 521 Norm Difference for worker 1730 is 0.863918
INFO:root:FL Epoch: 521 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 521 Training on worker :471
INFO:root:FL Epoch: 521 Using Learning rate : 0.01765433949109836 
INFO:root:FL Epoch: 521 Normal Training
INFO:root:Worker: 471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.944816
INFO:root:Worker: 471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512167
INFO:root:FL Epoch: 521 Norm Difference for worker 471 is 0.84275
INFO:root:FL Epoch: 521 Done on worker:471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 521 Training on worker :792
INFO:root:FL Epoch: 521 Using Learning rate : 0.01765433949109836 
INFO:root:FL Epoch: 521 Normal Training
INFO:root:Worker: 792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550529
INFO:root:Worker: 792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324713
INFO:root:FL Epoch: 521 Norm Difference for worker 792 is 0.772704
INFO:root:FL Epoch: 521 Done on worker:792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 521 Training on worker :1830
INFO:root:FL Epoch: 521 Using Learning rate : 0.01765433949109836 
INFO:root:FL Epoch: 521 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 1.131649
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457937
INFO:root:FL Epoch: 521 Norm Difference for worker 1830 is 0.874855
INFO:root:FL Epoch: 521 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 521 Training on worker :1466
INFO:root:FL Epoch: 521 Using Learning rate : 0.01765433949109836 
INFO:root:FL Epoch: 521 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.885844
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298491
INFO:root:FL Epoch: 521 Norm Difference for worker 1466 is 0.935774
INFO:root:FL Epoch: 521 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 521 Training on worker :619
INFO:root:FL Epoch: 521 Using Learning rate : 0.01765433949109836 
INFO:root:FL Epoch: 521 Normal Training
INFO:root:Worker: 619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564621
INFO:root:Worker: 619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342503
INFO:root:FL Epoch: 521 Norm Difference for worker 619 is 0.883846
INFO:root:FL Epoch: 521 Done on worker:619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 521 Ends   ===================
INFO:root:Epoch:521 Global Model Test Loss:0.5066416333703434 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:521 Global Model Backdoor Test Loss:0.10375622535745303                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 522 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 522 Workers Selected : [832, 612, 600, 982, 1725, 1224, 539, 3, 1510, 673]
INFO:root:FL Epoch: 522 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 522 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 522 Training on worker :832
INFO:root:FL Epoch: 522 Using Learning rate : 0.017619030812116167 
INFO:root:FL Epoch: 522 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601346
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.757697
INFO:root:FL Epoch: 522 Norm Difference for worker 832 is 0.913335
INFO:root:FL Epoch: 522 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 522 Training on worker :612
INFO:root:FL Epoch: 522 Using Learning rate : 0.017619030812116167 
INFO:root:FL Epoch: 522 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720417
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307815
INFO:root:FL Epoch: 522 Norm Difference for worker 612 is 0.843665
INFO:root:FL Epoch: 522 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 522 Training on worker :600
INFO:root:FL Epoch: 522 Using Learning rate : 0.017619030812116167 
INFO:root:FL Epoch: 522 Normal Training
INFO:root:Worker: 600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325993
INFO:root:Worker: 600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431573
INFO:root:FL Epoch: 522 Norm Difference for worker 600 is 0.701897
INFO:root:FL Epoch: 522 Done on worker:600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 522 Training on worker :982
INFO:root:FL Epoch: 522 Using Learning rate : 0.017619030812116167 
INFO:root:FL Epoch: 522 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382767
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500606
INFO:root:FL Epoch: 522 Norm Difference for worker 982 is 0.894388
INFO:root:FL Epoch: 522 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 522 Training on worker :1725
INFO:root:FL Epoch: 522 Using Learning rate : 0.017619030812116167 
INFO:root:FL Epoch: 522 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462242
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270386
INFO:root:FL Epoch: 522 Norm Difference for worker 1725 is 0.89523
INFO:root:FL Epoch: 522 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 522 Training on worker :1224
INFO:root:FL Epoch: 522 Using Learning rate : 0.017619030812116167 
INFO:root:FL Epoch: 522 Normal Training
INFO:root:Worker: 1224 Train Epoch: 0 [0/200 (0%)]	Loss: 1.008980
INFO:root:Worker: 1224 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331634
INFO:root:FL Epoch: 522 Norm Difference for worker 1224 is 0.82781
INFO:root:FL Epoch: 522 Done on worker:1224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 522 Training on worker :539
INFO:root:FL Epoch: 522 Using Learning rate : 0.017619030812116167 
INFO:root:FL Epoch: 522 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529538
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522371
INFO:root:FL Epoch: 522 Norm Difference for worker 539 is 0.887086
INFO:root:FL Epoch: 522 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 522 Training on worker :3
INFO:root:FL Epoch: 522 Using Learning rate : 0.017619030812116167 
INFO:root:FL Epoch: 522 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.344995
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.418153
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 522 Norm Difference for worker 3 is 0.884427
INFO:root:FL Epoch: 522 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 522 Training on worker :1510
INFO:root:FL Epoch: 522 Using Learning rate : 0.017619030812116167 
INFO:root:FL Epoch: 522 Normal Training
INFO:root:Worker: 1510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469016
INFO:root:Worker: 1510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378146
INFO:root:FL Epoch: 522 Norm Difference for worker 1510 is 0.849318
INFO:root:FL Epoch: 522 Done on worker:1510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 522 Training on worker :673
INFO:root:FL Epoch: 522 Using Learning rate : 0.017619030812116167 
INFO:root:FL Epoch: 522 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592332
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305392
INFO:root:FL Epoch: 522 Norm Difference for worker 673 is 0.84024
INFO:root:FL Epoch: 522 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 600
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 522 Ends   ===================
INFO:root:Epoch:522 Global Model Test Loss:0.514027336064507 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:522 Global Model Backdoor Test Loss:0.06636103801429272                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 523 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 523 Workers Selected : [888, 344, 814, 1493, 639, 1448, 256, 461, 1908, 337]
INFO:root:FL Epoch: 523 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 523 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 523 Training on worker :888
INFO:root:FL Epoch: 523 Using Learning rate : 0.017583792750491933 
INFO:root:FL Epoch: 523 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501284
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381397
INFO:root:FL Epoch: 523 Norm Difference for worker 888 is 0.930457
INFO:root:FL Epoch: 523 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 523 Training on worker :344
INFO:root:FL Epoch: 523 Using Learning rate : 0.017583792750491933 
INFO:root:FL Epoch: 523 Normal Training
INFO:root:Worker: 344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368445
INFO:root:Worker: 344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415630
INFO:root:FL Epoch: 523 Norm Difference for worker 344 is 0.929868
INFO:root:FL Epoch: 523 Done on worker:344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 523 Training on worker :814
INFO:root:FL Epoch: 523 Using Learning rate : 0.017583792750491933 
INFO:root:FL Epoch: 523 Normal Training
INFO:root:Worker: 814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485736
INFO:root:Worker: 814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220732
INFO:root:FL Epoch: 523 Norm Difference for worker 814 is 0.877976
INFO:root:FL Epoch: 523 Done on worker:814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 523 Training on worker :1493
INFO:root:FL Epoch: 523 Using Learning rate : 0.017583792750491933 
INFO:root:FL Epoch: 523 Normal Training
INFO:root:Worker: 1493 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381320
INFO:root:Worker: 1493 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592304
INFO:root:FL Epoch: 523 Norm Difference for worker 1493 is 0.897884
INFO:root:FL Epoch: 523 Done on worker:1493
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 523 Training on worker :639
INFO:root:FL Epoch: 523 Using Learning rate : 0.017583792750491933 
INFO:root:FL Epoch: 523 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654187
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.772652
INFO:root:FL Epoch: 523 Norm Difference for worker 639 is 0.832087
INFO:root:FL Epoch: 523 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 523 Training on worker :1448
INFO:root:FL Epoch: 523 Using Learning rate : 0.017583792750491933 
INFO:root:FL Epoch: 523 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591455
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408525
INFO:root:FL Epoch: 523 Norm Difference for worker 1448 is 0.83542
INFO:root:FL Epoch: 523 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 523 Training on worker :256
INFO:root:FL Epoch: 523 Using Learning rate : 0.017583792750491933 
INFO:root:FL Epoch: 523 Normal Training
INFO:root:Worker: 256 Train Epoch: 0 [0/201 (0%)]	Loss: 0.881931
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 256 Train Epoch: 1 [0/201 (0%)]	Loss: 0.568806
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 523 Norm Difference for worker 256 is 0.946048
INFO:root:FL Epoch: 523 Done on worker:256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 523 Training on worker :461
INFO:root:FL Epoch: 523 Using Learning rate : 0.017583792750491933 
INFO:root:FL Epoch: 523 Normal Training
INFO:root:Worker: 461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.255278
INFO:root:Worker: 461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259353
INFO:root:FL Epoch: 523 Norm Difference for worker 461 is 0.857837
INFO:root:FL Epoch: 523 Done on worker:461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 523 Training on worker :1908
INFO:root:FL Epoch: 523 Using Learning rate : 0.017583792750491933 
INFO:root:FL Epoch: 523 Normal Training
INFO:root:Worker: 1908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574449
INFO:root:Worker: 1908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291218
INFO:root:FL Epoch: 523 Norm Difference for worker 1908 is 1.032634
INFO:root:FL Epoch: 523 Done on worker:1908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 523 Training on worker :337
INFO:root:FL Epoch: 523 Using Learning rate : 0.017583792750491933 
INFO:root:FL Epoch: 523 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.723983
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.310860
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 523 Norm Difference for worker 337 is 0.959972
INFO:root:FL Epoch: 523 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 461
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 523 Ends   ===================
INFO:root:Epoch:523 Global Model Test Loss:0.5224687492146212 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:523 Global Model Backdoor Test Loss:0.1560886154572169                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 524 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 524 Workers Selected : [1471, 1574, 1571, 563, 1944, 1599, 1205, 843, 1897, 1775]
INFO:root:FL Epoch: 524 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 524 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 524 Training on worker :1471
INFO:root:FL Epoch: 524 Using Learning rate : 0.01754862516499095 
INFO:root:FL Epoch: 524 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426926
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436007
INFO:root:FL Epoch: 524 Norm Difference for worker 1471 is 0.831108
INFO:root:FL Epoch: 524 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 524 Training on worker :1574
INFO:root:FL Epoch: 524 Using Learning rate : 0.01754862516499095 
INFO:root:FL Epoch: 524 Normal Training
INFO:root:Worker: 1574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371662
INFO:root:Worker: 1574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266609
INFO:root:FL Epoch: 524 Norm Difference for worker 1574 is 0.877672
INFO:root:FL Epoch: 524 Done on worker:1574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 524 Training on worker :1571
INFO:root:FL Epoch: 524 Using Learning rate : 0.01754862516499095 
INFO:root:FL Epoch: 524 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623637
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422004
INFO:root:FL Epoch: 524 Norm Difference for worker 1571 is 0.808703
INFO:root:FL Epoch: 524 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 524 Training on worker :563
INFO:root:FL Epoch: 524 Using Learning rate : 0.01754862516499095 
INFO:root:FL Epoch: 524 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327988
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372301
INFO:root:FL Epoch: 524 Norm Difference for worker 563 is 0.794094
INFO:root:FL Epoch: 524 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 524 Training on worker :1944
INFO:root:FL Epoch: 524 Using Learning rate : 0.01754862516499095 
INFO:root:FL Epoch: 524 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559923
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407986
INFO:root:FL Epoch: 524 Norm Difference for worker 1944 is 0.816918
INFO:root:FL Epoch: 524 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 524 Training on worker :1599
INFO:root:FL Epoch: 524 Using Learning rate : 0.01754862516499095 
INFO:root:FL Epoch: 524 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471535
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505157
INFO:root:FL Epoch: 524 Norm Difference for worker 1599 is 0.852459
INFO:root:FL Epoch: 524 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 524 Training on worker :1205
INFO:root:FL Epoch: 524 Using Learning rate : 0.01754862516499095 
INFO:root:FL Epoch: 524 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709637
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456906
INFO:root:FL Epoch: 524 Norm Difference for worker 1205 is 0.819805
INFO:root:FL Epoch: 524 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 524 Training on worker :843
INFO:root:FL Epoch: 524 Using Learning rate : 0.01754862516499095 
INFO:root:FL Epoch: 524 Normal Training
INFO:root:Worker: 843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484614
INFO:root:Worker: 843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336789
INFO:root:FL Epoch: 524 Norm Difference for worker 843 is 0.817891
INFO:root:FL Epoch: 524 Done on worker:843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 524 Training on worker :1897
INFO:root:FL Epoch: 524 Using Learning rate : 0.01754862516499095 
INFO:root:FL Epoch: 524 Normal Training
INFO:root:Worker: 1897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477999
INFO:root:Worker: 1897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516121
INFO:root:FL Epoch: 524 Norm Difference for worker 1897 is 0.839036
INFO:root:FL Epoch: 524 Done on worker:1897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 524 Training on worker :1775
INFO:root:FL Epoch: 524 Using Learning rate : 0.01754862516499095 
INFO:root:FL Epoch: 524 Normal Training
INFO:root:Worker: 1775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669364
INFO:root:Worker: 1775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427031
INFO:root:FL Epoch: 524 Norm Difference for worker 1775 is 0.913314
INFO:root:FL Epoch: 524 Done on worker:1775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 563
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 524 Ends   ===================
INFO:root:Epoch:524 Global Model Test Loss:0.49998964632258697 and Test Accuracy:75.0 
INFO:root:Epoch:524 Global Model Backdoor Test Loss:0.10597091913223267                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 525 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 525 Workers Selected : [1096, 570, 779, 298, 1125, 1322, 856, 1417, 826, 661]
INFO:root:FL Epoch: 525 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 525 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 525 Training on worker :1096
INFO:root:FL Epoch: 525 Using Learning rate : 0.01751352791466097 
INFO:root:FL Epoch: 525 Normal Training
INFO:root:Worker: 1096 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337430
INFO:root:Worker: 1096 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599112
INFO:root:FL Epoch: 525 Norm Difference for worker 1096 is 0.744778
INFO:root:FL Epoch: 525 Done on worker:1096
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 525 Training on worker :570
INFO:root:FL Epoch: 525 Using Learning rate : 0.01751352791466097 
INFO:root:FL Epoch: 525 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.211534
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558981
INFO:root:FL Epoch: 525 Norm Difference for worker 570 is 0.698616
INFO:root:FL Epoch: 525 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 525 Training on worker :779
INFO:root:FL Epoch: 525 Using Learning rate : 0.01751352791466097 
INFO:root:FL Epoch: 525 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417314
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593175
INFO:root:FL Epoch: 525 Norm Difference for worker 779 is 0.827478
INFO:root:FL Epoch: 525 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 525 Training on worker :298
INFO:root:FL Epoch: 525 Using Learning rate : 0.01751352791466097 
INFO:root:FL Epoch: 525 Normal Training
INFO:root:Worker: 298 Train Epoch: 0 [0/201 (0%)]	Loss: 0.655957
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 298 Train Epoch: 1 [0/201 (0%)]	Loss: 0.721088
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 525 Norm Difference for worker 298 is 0.835156
INFO:root:FL Epoch: 525 Done on worker:298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 525 Training on worker :1125
INFO:root:FL Epoch: 525 Using Learning rate : 0.01751352791466097 
INFO:root:FL Epoch: 525 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699080
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564288
INFO:root:FL Epoch: 525 Norm Difference for worker 1125 is 0.801076
INFO:root:FL Epoch: 525 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 525 Training on worker :1322
INFO:root:FL Epoch: 525 Using Learning rate : 0.01751352791466097 
INFO:root:FL Epoch: 525 Normal Training
INFO:root:Worker: 1322 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483455
INFO:root:Worker: 1322 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488610
INFO:root:FL Epoch: 525 Norm Difference for worker 1322 is 0.820824
INFO:root:FL Epoch: 525 Done on worker:1322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 525 Training on worker :856
INFO:root:FL Epoch: 525 Using Learning rate : 0.01751352791466097 
INFO:root:FL Epoch: 525 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602595
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.795608
INFO:root:FL Epoch: 525 Norm Difference for worker 856 is 0.902686
INFO:root:FL Epoch: 525 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 525 Training on worker :1417
INFO:root:FL Epoch: 525 Using Learning rate : 0.01751352791466097 
INFO:root:FL Epoch: 525 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563502
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479899
INFO:root:FL Epoch: 525 Norm Difference for worker 1417 is 0.735691
INFO:root:FL Epoch: 525 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 525 Training on worker :826
INFO:root:FL Epoch: 525 Using Learning rate : 0.01751352791466097 
INFO:root:FL Epoch: 525 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418487
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426824
INFO:root:FL Epoch: 525 Norm Difference for worker 826 is 0.784524
INFO:root:FL Epoch: 525 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 525 Training on worker :661
INFO:root:FL Epoch: 525 Using Learning rate : 0.01751352791466097 
INFO:root:FL Epoch: 525 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480242
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382607
INFO:root:FL Epoch: 525 Norm Difference for worker 661 is 0.718287
INFO:root:FL Epoch: 525 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 570
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 525 Ends   ===================
INFO:root:Epoch:525 Global Model Test Loss:0.4957308927003075 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:525 Global Model Backdoor Test Loss:0.08202269983788331                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 526 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 526 Workers Selected : [354, 951, 1777, 867, 1140, 1467, 525, 13, 1011, 386]
INFO:root:FL Epoch: 526 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 526 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 526 Training on worker :354
INFO:root:FL Epoch: 526 Using Learning rate : 0.017478500858831646 
INFO:root:FL Epoch: 526 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455596
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315353
INFO:root:FL Epoch: 526 Norm Difference for worker 354 is 0.855047
INFO:root:FL Epoch: 526 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 526 Training on worker :951
INFO:root:FL Epoch: 526 Using Learning rate : 0.017478500858831646 
INFO:root:FL Epoch: 526 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387531
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492948
INFO:root:FL Epoch: 526 Norm Difference for worker 951 is 0.725471
INFO:root:FL Epoch: 526 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 526 Training on worker :1777
INFO:root:FL Epoch: 526 Using Learning rate : 0.017478500858831646 
INFO:root:FL Epoch: 526 Normal Training
INFO:root:Worker: 1777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.317107
INFO:root:Worker: 1777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521124
INFO:root:FL Epoch: 526 Norm Difference for worker 1777 is 0.848267
INFO:root:FL Epoch: 526 Done on worker:1777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 526 Training on worker :867
INFO:root:FL Epoch: 526 Using Learning rate : 0.017478500858831646 
INFO:root:FL Epoch: 526 Normal Training
INFO:root:Worker: 867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391394
INFO:root:Worker: 867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255454
INFO:root:FL Epoch: 526 Norm Difference for worker 867 is 0.880725
INFO:root:FL Epoch: 526 Done on worker:867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 526 Training on worker :1140
INFO:root:FL Epoch: 526 Using Learning rate : 0.017478500858831646 
INFO:root:FL Epoch: 526 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475669
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477238
INFO:root:FL Epoch: 526 Norm Difference for worker 1140 is 0.858849
INFO:root:FL Epoch: 526 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 526 Training on worker :1467
INFO:root:FL Epoch: 526 Using Learning rate : 0.017478500858831646 
INFO:root:FL Epoch: 526 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305799
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573634
INFO:root:FL Epoch: 526 Norm Difference for worker 1467 is 0.894206
INFO:root:FL Epoch: 526 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 526 Training on worker :525
INFO:root:FL Epoch: 526 Using Learning rate : 0.017478500858831646 
INFO:root:FL Epoch: 526 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.271770
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320612
INFO:root:FL Epoch: 526 Norm Difference for worker 525 is 0.888962
INFO:root:FL Epoch: 526 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 526 Training on worker :13
INFO:root:FL Epoch: 526 Using Learning rate : 0.017478500858831646 
INFO:root:FL Epoch: 526 Normal Training
INFO:root:Worker: 13 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494316
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 13 Train Epoch: 1 [0/201 (0%)]	Loss: 0.248290
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 526 Norm Difference for worker 13 is 0.814314
INFO:root:FL Epoch: 526 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 526 Training on worker :1011
INFO:root:FL Epoch: 526 Using Learning rate : 0.017478500858831646 
INFO:root:FL Epoch: 526 Normal Training
INFO:root:Worker: 1011 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567411
INFO:root:Worker: 1011 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620557
INFO:root:FL Epoch: 526 Norm Difference for worker 1011 is 0.814997
INFO:root:FL Epoch: 526 Done on worker:1011
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 526 Training on worker :386
INFO:root:FL Epoch: 526 Using Learning rate : 0.017478500858831646 
INFO:root:FL Epoch: 526 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362637
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303872
INFO:root:FL Epoch: 526 Norm Difference for worker 386 is 0.737078
INFO:root:FL Epoch: 526 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 386
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 526 Ends   ===================
INFO:root:Epoch:526 Global Model Test Loss:0.5280357862220091 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:526 Global Model Backdoor Test Loss:0.132284385462602                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 527 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 527 Workers Selected : [394, 43, 1946, 202, 357, 879, 365, 105, 548, 1176]
INFO:root:FL Epoch: 527 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 527 Num points on workers: [200 201 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 527 Training on worker :394
INFO:root:FL Epoch: 527 Using Learning rate : 0.017443543857113983 
INFO:root:FL Epoch: 527 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663166
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525879
INFO:root:FL Epoch: 527 Norm Difference for worker 394 is 0.88374
INFO:root:FL Epoch: 527 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 527 Training on worker :43
INFO:root:FL Epoch: 527 Using Learning rate : 0.017443543857113983 
INFO:root:FL Epoch: 527 Normal Training
INFO:root:Worker: 43 Train Epoch: 0 [0/201 (0%)]	Loss: 0.997641
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 43 Train Epoch: 1 [0/201 (0%)]	Loss: 0.567753
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 527 Norm Difference for worker 43 is 0.935876
INFO:root:FL Epoch: 527 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 527 Training on worker :1946
INFO:root:FL Epoch: 527 Using Learning rate : 0.017443543857113983 
INFO:root:FL Epoch: 527 Normal Training
INFO:root:Worker: 1946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.245563
INFO:root:Worker: 1946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236854
INFO:root:FL Epoch: 527 Norm Difference for worker 1946 is 0.944292
INFO:root:FL Epoch: 527 Done on worker:1946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 527 Training on worker :202
INFO:root:FL Epoch: 527 Using Learning rate : 0.017443543857113983 
INFO:root:FL Epoch: 527 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595503
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415703
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 527 Norm Difference for worker 202 is 0.960834
INFO:root:FL Epoch: 527 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 527 Training on worker :357
INFO:root:FL Epoch: 527 Using Learning rate : 0.017443543857113983 
INFO:root:FL Epoch: 527 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.331310
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485661
INFO:root:FL Epoch: 527 Norm Difference for worker 357 is 0.804515
INFO:root:FL Epoch: 527 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 527 Training on worker :879
INFO:root:FL Epoch: 527 Using Learning rate : 0.017443543857113983 
INFO:root:FL Epoch: 527 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.792245
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357598
INFO:root:FL Epoch: 527 Norm Difference for worker 879 is 0.939999
INFO:root:FL Epoch: 527 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 527 Training on worker :365
INFO:root:FL Epoch: 527 Using Learning rate : 0.017443543857113983 
INFO:root:FL Epoch: 527 Normal Training
INFO:root:Worker: 365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587925
INFO:root:Worker: 365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.935234
INFO:root:FL Epoch: 527 Norm Difference for worker 365 is 0.894812
INFO:root:FL Epoch: 527 Done on worker:365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 527 Training on worker :105
INFO:root:FL Epoch: 527 Using Learning rate : 0.017443543857113983 
INFO:root:FL Epoch: 527 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.569718
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.417515
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 527 Norm Difference for worker 105 is 1.022217
INFO:root:FL Epoch: 527 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 527 Training on worker :548
INFO:root:FL Epoch: 527 Using Learning rate : 0.017443543857113983 
INFO:root:FL Epoch: 527 Normal Training
INFO:root:Worker: 548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638113
INFO:root:Worker: 548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481353
INFO:root:FL Epoch: 527 Norm Difference for worker 548 is 0.903955
INFO:root:FL Epoch: 527 Done on worker:548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 527 Training on worker :1176
INFO:root:FL Epoch: 527 Using Learning rate : 0.017443543857113983 
INFO:root:FL Epoch: 527 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390461
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491029
INFO:root:FL Epoch: 527 Norm Difference for worker 1176 is 0.811601
INFO:root:FL Epoch: 527 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1176
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 527 Ends   ===================
INFO:root:Epoch:527 Global Model Test Loss:0.49402020433369803 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:527 Global Model Backdoor Test Loss:0.10107377419869105                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 528 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 528 Workers Selected : [1232, 710, 1540, 1486, 1881, 795, 1174, 1718, 1621, 1011]
INFO:root:FL Epoch: 528 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 528 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 528 Training on worker :1232
INFO:root:FL Epoch: 528 Using Learning rate : 0.017408656769399757 
INFO:root:FL Epoch: 528 Normal Training
INFO:root:Worker: 1232 Train Epoch: 0 [0/200 (0%)]	Loss: 0.789296
INFO:root:Worker: 1232 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571509
INFO:root:FL Epoch: 528 Norm Difference for worker 1232 is 0.85838
INFO:root:FL Epoch: 528 Done on worker:1232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 528 Training on worker :710
INFO:root:FL Epoch: 528 Using Learning rate : 0.017408656769399757 
INFO:root:FL Epoch: 528 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412839
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339210
INFO:root:FL Epoch: 528 Norm Difference for worker 710 is 0.805629
INFO:root:FL Epoch: 528 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 528 Training on worker :1540
INFO:root:FL Epoch: 528 Using Learning rate : 0.017408656769399757 
INFO:root:FL Epoch: 528 Normal Training
INFO:root:Worker: 1540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.294294
INFO:root:Worker: 1540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423750
INFO:root:FL Epoch: 528 Norm Difference for worker 1540 is 0.868391
INFO:root:FL Epoch: 528 Done on worker:1540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 528 Training on worker :1486
INFO:root:FL Epoch: 528 Using Learning rate : 0.017408656769399757 
INFO:root:FL Epoch: 528 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624711
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489909
INFO:root:FL Epoch: 528 Norm Difference for worker 1486 is 0.880396
INFO:root:FL Epoch: 528 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 528 Training on worker :1881
INFO:root:FL Epoch: 528 Using Learning rate : 0.017408656769399757 
INFO:root:FL Epoch: 528 Normal Training
INFO:root:Worker: 1881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701465
INFO:root:Worker: 1881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316610
INFO:root:FL Epoch: 528 Norm Difference for worker 1881 is 0.725131
INFO:root:FL Epoch: 528 Done on worker:1881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 528 Training on worker :795
INFO:root:FL Epoch: 528 Using Learning rate : 0.017408656769399757 
INFO:root:FL Epoch: 528 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405134
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486175
INFO:root:FL Epoch: 528 Norm Difference for worker 795 is 0.700923
INFO:root:FL Epoch: 528 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 528 Training on worker :1174
INFO:root:FL Epoch: 528 Using Learning rate : 0.017408656769399757 
INFO:root:FL Epoch: 528 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805721
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526093
INFO:root:FL Epoch: 528 Norm Difference for worker 1174 is 0.864332
INFO:root:FL Epoch: 528 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 528 Training on worker :1718
INFO:root:FL Epoch: 528 Using Learning rate : 0.017408656769399757 
INFO:root:FL Epoch: 528 Normal Training
INFO:root:Worker: 1718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545805
INFO:root:Worker: 1718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521989
INFO:root:FL Epoch: 528 Norm Difference for worker 1718 is 0.836361
INFO:root:FL Epoch: 528 Done on worker:1718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 528 Training on worker :1621
INFO:root:FL Epoch: 528 Using Learning rate : 0.017408656769399757 
INFO:root:FL Epoch: 528 Normal Training
INFO:root:Worker: 1621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.885795
INFO:root:Worker: 1621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352954
INFO:root:FL Epoch: 528 Norm Difference for worker 1621 is 0.841749
INFO:root:FL Epoch: 528 Done on worker:1621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 528 Training on worker :1011
INFO:root:FL Epoch: 528 Using Learning rate : 0.017408656769399757 
INFO:root:FL Epoch: 528 Normal Training
INFO:root:Worker: 1011 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653695
INFO:root:Worker: 1011 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326592
INFO:root:FL Epoch: 528 Norm Difference for worker 1011 is 0.837453
INFO:root:FL Epoch: 528 Done on worker:1011
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 795
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 528 Ends   ===================
INFO:root:Epoch:528 Global Model Test Loss:0.5116795932545382 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:528 Global Model Backdoor Test Loss:0.11575520535310109                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 529 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 529 Workers Selected : [991, 1293, 318, 707, 1256, 1006, 474, 1060, 1599, 1142]
INFO:root:FL Epoch: 529 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 529 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 529 Training on worker :991
INFO:root:FL Epoch: 529 Using Learning rate : 0.017373839455860955 
INFO:root:FL Epoch: 529 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392014
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676165
INFO:root:FL Epoch: 529 Norm Difference for worker 991 is 0.913958
INFO:root:FL Epoch: 529 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 529 Training on worker :1293
INFO:root:FL Epoch: 529 Using Learning rate : 0.017373839455860955 
INFO:root:FL Epoch: 529 Normal Training
INFO:root:Worker: 1293 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508616
INFO:root:Worker: 1293 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509435
INFO:root:FL Epoch: 529 Norm Difference for worker 1293 is 0.78748
INFO:root:FL Epoch: 529 Done on worker:1293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 529 Training on worker :318
INFO:root:FL Epoch: 529 Using Learning rate : 0.017373839455860955 
INFO:root:FL Epoch: 529 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.711196
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.365224
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 529 Norm Difference for worker 318 is 0.78227
INFO:root:FL Epoch: 529 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 529 Training on worker :707
INFO:root:FL Epoch: 529 Using Learning rate : 0.017373839455860955 
INFO:root:FL Epoch: 529 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413667
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442026
INFO:root:FL Epoch: 529 Norm Difference for worker 707 is 0.805363
INFO:root:FL Epoch: 529 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 529 Training on worker :1256
INFO:root:FL Epoch: 529 Using Learning rate : 0.017373839455860955 
INFO:root:FL Epoch: 529 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451647
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360645
INFO:root:FL Epoch: 529 Norm Difference for worker 1256 is 0.8495
INFO:root:FL Epoch: 529 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 529 Training on worker :1006
INFO:root:FL Epoch: 529 Using Learning rate : 0.017373839455860955 
INFO:root:FL Epoch: 529 Normal Training
INFO:root:Worker: 1006 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474317
INFO:root:Worker: 1006 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427111
INFO:root:FL Epoch: 529 Norm Difference for worker 1006 is 0.843005
INFO:root:FL Epoch: 529 Done on worker:1006
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 529 Training on worker :474
INFO:root:FL Epoch: 529 Using Learning rate : 0.017373839455860955 
INFO:root:FL Epoch: 529 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351365
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375370
INFO:root:FL Epoch: 529 Norm Difference for worker 474 is 0.907381
INFO:root:FL Epoch: 529 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 529 Training on worker :1060
INFO:root:FL Epoch: 529 Using Learning rate : 0.017373839455860955 
INFO:root:FL Epoch: 529 Normal Training
INFO:root:Worker: 1060 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465736
INFO:root:Worker: 1060 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411886
INFO:root:FL Epoch: 529 Norm Difference for worker 1060 is 0.885479
INFO:root:FL Epoch: 529 Done on worker:1060
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 529 Training on worker :1599
INFO:root:FL Epoch: 529 Using Learning rate : 0.017373839455860955 
INFO:root:FL Epoch: 529 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670377
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524353
INFO:root:FL Epoch: 529 Norm Difference for worker 1599 is 0.906901
INFO:root:FL Epoch: 529 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 529 Training on worker :1142
INFO:root:FL Epoch: 529 Using Learning rate : 0.017373839455860955 
INFO:root:FL Epoch: 529 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700681
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488191
INFO:root:FL Epoch: 529 Norm Difference for worker 1142 is 0.833237
INFO:root:FL Epoch: 529 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 318
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 529 Ends   ===================
INFO:root:Epoch:529 Global Model Test Loss:0.5215480345136979 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:529 Global Model Backdoor Test Loss:0.1523872216542562                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 530 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 530 Workers Selected : [824, 956, 806, 259, 128, 1910, 388, 1464, 189, 1100]
INFO:root:FL Epoch: 530 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 530 Num points on workers: [200 200 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 530 Training on worker :824
INFO:root:FL Epoch: 530 Using Learning rate : 0.017339091776949235 
INFO:root:FL Epoch: 530 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.827969
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404646
INFO:root:FL Epoch: 530 Norm Difference for worker 824 is 0.747214
INFO:root:FL Epoch: 530 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 530 Training on worker :956
INFO:root:FL Epoch: 530 Using Learning rate : 0.017339091776949235 
INFO:root:FL Epoch: 530 Normal Training
INFO:root:Worker: 956 Train Epoch: 0 [0/200 (0%)]	Loss: 0.848177
INFO:root:Worker: 956 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515744
INFO:root:FL Epoch: 530 Norm Difference for worker 956 is 0.798423
INFO:root:FL Epoch: 530 Done on worker:956
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 530 Training on worker :806
INFO:root:FL Epoch: 530 Using Learning rate : 0.017339091776949235 
INFO:root:FL Epoch: 530 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695835
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468346
INFO:root:FL Epoch: 530 Norm Difference for worker 806 is 0.91149
INFO:root:FL Epoch: 530 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 530 Training on worker :259
INFO:root:FL Epoch: 530 Using Learning rate : 0.017339091776949235 
INFO:root:FL Epoch: 530 Normal Training
INFO:root:Worker: 259 Train Epoch: 0 [0/201 (0%)]	Loss: 0.350970
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 259 Train Epoch: 1 [0/201 (0%)]	Loss: 0.489120
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 530 Norm Difference for worker 259 is 0.875214
INFO:root:FL Epoch: 530 Done on worker:259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 530 Training on worker :128
INFO:root:FL Epoch: 530 Using Learning rate : 0.017339091776949235 
INFO:root:FL Epoch: 530 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.750737
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.533330
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 530 Norm Difference for worker 128 is 0.882348
INFO:root:FL Epoch: 530 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 530 Training on worker :1910
INFO:root:FL Epoch: 530 Using Learning rate : 0.017339091776949235 
INFO:root:FL Epoch: 530 Normal Training
INFO:root:Worker: 1910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309600
INFO:root:Worker: 1910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354136
INFO:root:FL Epoch: 530 Norm Difference for worker 1910 is 0.898829
INFO:root:FL Epoch: 530 Done on worker:1910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 530 Training on worker :388
INFO:root:FL Epoch: 530 Using Learning rate : 0.017339091776949235 
INFO:root:FL Epoch: 530 Normal Training
INFO:root:Worker: 388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533252
INFO:root:Worker: 388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234762
INFO:root:FL Epoch: 530 Norm Difference for worker 388 is 0.817908
INFO:root:FL Epoch: 530 Done on worker:388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 530 Training on worker :1464
INFO:root:FL Epoch: 530 Using Learning rate : 0.017339091776949235 
INFO:root:FL Epoch: 530 Normal Training
INFO:root:Worker: 1464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.271101
INFO:root:Worker: 1464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283533
INFO:root:FL Epoch: 530 Norm Difference for worker 1464 is 0.712664
INFO:root:FL Epoch: 530 Done on worker:1464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 530 Training on worker :189
INFO:root:FL Epoch: 530 Using Learning rate : 0.017339091776949235 
INFO:root:FL Epoch: 530 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.671092
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.517117
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 530 Norm Difference for worker 189 is 0.797879
INFO:root:FL Epoch: 530 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 530 Training on worker :1100
INFO:root:FL Epoch: 530 Using Learning rate : 0.017339091776949235 
INFO:root:FL Epoch: 530 Normal Training
INFO:root:Worker: 1100 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773406
INFO:root:Worker: 1100 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478325
INFO:root:FL Epoch: 530 Norm Difference for worker 1100 is 0.77028
INFO:root:FL Epoch: 530 Done on worker:1100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1464
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 530 Ends   ===================
INFO:root:Epoch:530 Global Model Test Loss:0.5142439726520988 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:530 Global Model Backdoor Test Loss:0.06353415921330452                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 531 Begins ===================
INFO:root:FL Epoch: 531 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 531 Workers Selected : [0, 1, 2, 218, 858, 782, 846, 1181, 420, 726]
INFO:root:FL Epoch: 531 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 531 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 531 Training on worker :0
INFO:root:FL Epoch: 531 Using Learning rate : 0.003460882718679067 
INFO:root:FL Epoch: 531 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.219689
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.082056
INFO:root:FL Epoch: 531 Worker: 0 Backdoor Test Loss: 0.06617067505915959 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 531 Worker: 0 Backdoor Train Loss: 0.13436292633414268 Backdoor Train Accuracy: 97.5
INFO:root:FL Epoch: 531 Norm Difference for worker 0 is 0.115283
INFO:root:FL Epoch: 531 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 531 Training on worker :1
INFO:root:FL Epoch: 531 Using Learning rate : 0.003460882718679067 
INFO:root:FL Epoch: 531 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.145448
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210359
INFO:root:FL Epoch: 531 Worker: 1 Backdoor Test Loss: 0.06875504491229852 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 531 Worker: 1 Backdoor Train Loss: 0.134512697160244 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 531 Norm Difference for worker 1 is 0.124855
INFO:root:FL Epoch: 531 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 531 Training on worker :2
INFO:root:FL Epoch: 531 Using Learning rate : 0.003460882718679067 
INFO:root:FL Epoch: 531 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.150718
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.169110
INFO:root:FL Epoch: 531 Worker: 2 Backdoor Test Loss: 0.06821014732122421 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 531 Worker: 2 Backdoor Train Loss: 0.13171325623989105 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 531 Norm Difference for worker 2 is 0.127405
INFO:root:FL Epoch: 531 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 531 Training on worker :218
INFO:root:FL Epoch: 531 Using Learning rate : 0.017304413593395334 
INFO:root:FL Epoch: 531 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.673721
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.386204
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 531 Norm Difference for worker 218 is 0.894814
INFO:root:FL Epoch: 531 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 531 Training on worker :858
INFO:root:FL Epoch: 531 Using Learning rate : 0.017304413593395334 
INFO:root:FL Epoch: 531 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686997
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488119
INFO:root:FL Epoch: 531 Norm Difference for worker 858 is 0.859748
INFO:root:FL Epoch: 531 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 531 Training on worker :782
INFO:root:FL Epoch: 531 Using Learning rate : 0.017304413593395334 
INFO:root:FL Epoch: 531 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479546
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644615
INFO:root:FL Epoch: 531 Norm Difference for worker 782 is 0.954555
INFO:root:FL Epoch: 531 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 531 Training on worker :846
INFO:root:FL Epoch: 531 Using Learning rate : 0.017304413593395334 
INFO:root:FL Epoch: 531 Normal Training
INFO:root:Worker: 846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773581
INFO:root:Worker: 846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529570
INFO:root:FL Epoch: 531 Norm Difference for worker 846 is 1.028273
INFO:root:FL Epoch: 531 Done on worker:846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 531 Training on worker :1181
INFO:root:FL Epoch: 531 Using Learning rate : 0.017304413593395334 
INFO:root:FL Epoch: 531 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.861383
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631627
INFO:root:FL Epoch: 531 Norm Difference for worker 1181 is 0.822995
INFO:root:FL Epoch: 531 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 531 Training on worker :420
INFO:root:FL Epoch: 531 Using Learning rate : 0.017304413593395334 
INFO:root:FL Epoch: 531 Normal Training
INFO:root:Worker: 420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.830465
INFO:root:Worker: 420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488863
INFO:root:FL Epoch: 531 Norm Difference for worker 420 is 0.952561
INFO:root:FL Epoch: 531 Done on worker:420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 531 Training on worker :726
INFO:root:FL Epoch: 531 Using Learning rate : 0.017304413593395334 
INFO:root:FL Epoch: 531 Normal Training
INFO:root:Worker: 726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344555
INFO:root:Worker: 726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283542
INFO:root:FL Epoch: 531 Norm Difference for worker 726 is 0.952325
INFO:root:FL Epoch: 531 Done on worker:726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 531 Ends   ===================
INFO:root:Epoch:531 Global Model Test Loss:0.5074161185937769 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:531 Global Model Backdoor Test Loss:0.06875504491229852                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 532 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 532 Workers Selected : [1137, 943, 1384, 478, 1853, 836, 1335, 1385, 333, 848]
INFO:root:FL Epoch: 532 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 532 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 532 Training on worker :1137
INFO:root:FL Epoch: 532 Using Learning rate : 0.017269804766208544 
INFO:root:FL Epoch: 532 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685070
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530745
INFO:root:FL Epoch: 532 Norm Difference for worker 1137 is 0.91885
INFO:root:FL Epoch: 532 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 532 Training on worker :943
INFO:root:FL Epoch: 532 Using Learning rate : 0.017269804766208544 
INFO:root:FL Epoch: 532 Normal Training
INFO:root:Worker: 943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.836159
INFO:root:Worker: 943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.743136
INFO:root:FL Epoch: 532 Norm Difference for worker 943 is 1.016132
INFO:root:FL Epoch: 532 Done on worker:943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 532 Training on worker :1384
INFO:root:FL Epoch: 532 Using Learning rate : 0.017269804766208544 
INFO:root:FL Epoch: 532 Normal Training
INFO:root:Worker: 1384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449268
INFO:root:Worker: 1384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375484
INFO:root:FL Epoch: 532 Norm Difference for worker 1384 is 0.878305
INFO:root:FL Epoch: 532 Done on worker:1384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 532 Training on worker :478
INFO:root:FL Epoch: 532 Using Learning rate : 0.017269804766208544 
INFO:root:FL Epoch: 532 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419006
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.729136
INFO:root:FL Epoch: 532 Norm Difference for worker 478 is 0.886423
INFO:root:FL Epoch: 532 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 532 Training on worker :1853
INFO:root:FL Epoch: 532 Using Learning rate : 0.017269804766208544 
INFO:root:FL Epoch: 532 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778255
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662969
INFO:root:FL Epoch: 532 Norm Difference for worker 1853 is 1.044804
INFO:root:FL Epoch: 532 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 532 Training on worker :836
INFO:root:FL Epoch: 532 Using Learning rate : 0.017269804766208544 
INFO:root:FL Epoch: 532 Normal Training
INFO:root:Worker: 836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397020
INFO:root:Worker: 836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453407
INFO:root:FL Epoch: 532 Norm Difference for worker 836 is 0.80031
INFO:root:FL Epoch: 532 Done on worker:836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 532 Training on worker :1335
INFO:root:FL Epoch: 532 Using Learning rate : 0.017269804766208544 
INFO:root:FL Epoch: 532 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465349
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507371
INFO:root:FL Epoch: 532 Norm Difference for worker 1335 is 0.860189
INFO:root:FL Epoch: 532 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 532 Training on worker :1385
INFO:root:FL Epoch: 532 Using Learning rate : 0.017269804766208544 
INFO:root:FL Epoch: 532 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771934
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352295
INFO:root:FL Epoch: 532 Norm Difference for worker 1385 is 0.835148
INFO:root:FL Epoch: 532 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 532 Training on worker :333
INFO:root:FL Epoch: 532 Using Learning rate : 0.017269804766208544 
INFO:root:FL Epoch: 532 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.841273
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.306203
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 532 Norm Difference for worker 333 is 0.862329
INFO:root:FL Epoch: 532 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 532 Training on worker :848
INFO:root:FL Epoch: 532 Using Learning rate : 0.017269804766208544 
INFO:root:FL Epoch: 532 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.832803
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667577
INFO:root:FL Epoch: 532 Norm Difference for worker 848 is 0.896374
INFO:root:FL Epoch: 532 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 333
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 532 Ends   ===================
INFO:root:Epoch:532 Global Model Test Loss:0.4975269156343797 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:532 Global Model Backdoor Test Loss:0.2098242218295733                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 533 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 533 Workers Selected : [754, 1821, 539, 906, 684, 557, 1509, 1785, 340, 645]
INFO:root:FL Epoch: 533 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 533 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 533 Training on worker :754
INFO:root:FL Epoch: 533 Using Learning rate : 0.017235265156676127 
INFO:root:FL Epoch: 533 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656149
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598199
INFO:root:FL Epoch: 533 Norm Difference for worker 754 is 0.744781
INFO:root:FL Epoch: 533 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 533 Training on worker :1821
INFO:root:FL Epoch: 533 Using Learning rate : 0.017235265156676127 
INFO:root:FL Epoch: 533 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.820165
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642525
INFO:root:FL Epoch: 533 Norm Difference for worker 1821 is 0.717088
INFO:root:FL Epoch: 533 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 533 Training on worker :539
INFO:root:FL Epoch: 533 Using Learning rate : 0.017235265156676127 
INFO:root:FL Epoch: 533 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531203
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661697
INFO:root:FL Epoch: 533 Norm Difference for worker 539 is 0.709925
INFO:root:FL Epoch: 533 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 533 Training on worker :906
INFO:root:FL Epoch: 533 Using Learning rate : 0.017235265156676127 
INFO:root:FL Epoch: 533 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.235099
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292181
INFO:root:FL Epoch: 533 Norm Difference for worker 906 is 0.544558
INFO:root:FL Epoch: 533 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 533 Training on worker :684
INFO:root:FL Epoch: 533 Using Learning rate : 0.017235265156676127 
INFO:root:FL Epoch: 533 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484346
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325434
INFO:root:FL Epoch: 533 Norm Difference for worker 684 is 0.632748
INFO:root:FL Epoch: 533 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 533 Training on worker :557
INFO:root:FL Epoch: 533 Using Learning rate : 0.017235265156676127 
INFO:root:FL Epoch: 533 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463110
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362535
INFO:root:FL Epoch: 533 Norm Difference for worker 557 is 0.624305
INFO:root:FL Epoch: 533 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 533 Training on worker :1509
INFO:root:FL Epoch: 533 Using Learning rate : 0.017235265156676127 
INFO:root:FL Epoch: 533 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458132
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228902
INFO:root:FL Epoch: 533 Norm Difference for worker 1509 is 0.757932
INFO:root:FL Epoch: 533 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 533 Training on worker :1785
INFO:root:FL Epoch: 533 Using Learning rate : 0.017235265156676127 
INFO:root:FL Epoch: 533 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501525
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610112
INFO:root:FL Epoch: 533 Norm Difference for worker 1785 is 0.768201
INFO:root:FL Epoch: 533 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 533 Training on worker :340
INFO:root:FL Epoch: 533 Using Learning rate : 0.017235265156676127 
INFO:root:FL Epoch: 533 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560707
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370722
INFO:root:FL Epoch: 533 Norm Difference for worker 340 is 0.728192
INFO:root:FL Epoch: 533 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 533 Training on worker :645
INFO:root:FL Epoch: 533 Using Learning rate : 0.017235265156676127 
INFO:root:FL Epoch: 533 Normal Training
INFO:root:Worker: 645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596668
INFO:root:Worker: 645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473593
INFO:root:FL Epoch: 533 Norm Difference for worker 645 is 0.716286
INFO:root:FL Epoch: 533 Done on worker:645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 906
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 533 Ends   ===================
INFO:root:Epoch:533 Global Model Test Loss:0.5415784891913918 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:533 Global Model Backdoor Test Loss:0.20583671579758325                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 534 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 534 Workers Selected : [1885, 480, 103, 583, 1552, 1728, 265, 35, 1513, 218]
INFO:root:FL Epoch: 534 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 534 Num points on workers: [200 200 201 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 534 Training on worker :1885
INFO:root:FL Epoch: 534 Using Learning rate : 0.017200794626362776 
INFO:root:FL Epoch: 534 Normal Training
INFO:root:Worker: 1885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357671
INFO:root:Worker: 1885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380225
INFO:root:FL Epoch: 534 Norm Difference for worker 1885 is 0.835904
INFO:root:FL Epoch: 534 Done on worker:1885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 534 Training on worker :480
INFO:root:FL Epoch: 534 Using Learning rate : 0.017200794626362776 
INFO:root:FL Epoch: 534 Normal Training
INFO:root:Worker: 480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510653
INFO:root:Worker: 480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377300
INFO:root:FL Epoch: 534 Norm Difference for worker 480 is 0.913812
INFO:root:FL Epoch: 534 Done on worker:480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 534 Training on worker :103
INFO:root:FL Epoch: 534 Using Learning rate : 0.017200794626362776 
INFO:root:FL Epoch: 534 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.641101
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.398270
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 534 Norm Difference for worker 103 is 0.973507
INFO:root:FL Epoch: 534 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 534 Training on worker :583
INFO:root:FL Epoch: 534 Using Learning rate : 0.017200794626362776 
INFO:root:FL Epoch: 534 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354825
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287265
INFO:root:FL Epoch: 534 Norm Difference for worker 583 is 0.872319
INFO:root:FL Epoch: 534 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 534 Training on worker :1552
INFO:root:FL Epoch: 534 Using Learning rate : 0.017200794626362776 
INFO:root:FL Epoch: 534 Normal Training
INFO:root:Worker: 1552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738544
INFO:root:Worker: 1552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479461
INFO:root:FL Epoch: 534 Norm Difference for worker 1552 is 0.939925
INFO:root:FL Epoch: 534 Done on worker:1552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 534 Training on worker :1728
INFO:root:FL Epoch: 534 Using Learning rate : 0.017200794626362776 
INFO:root:FL Epoch: 534 Normal Training
INFO:root:Worker: 1728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494632
INFO:root:Worker: 1728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435899
INFO:root:FL Epoch: 534 Norm Difference for worker 1728 is 0.845484
INFO:root:FL Epoch: 534 Done on worker:1728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 534 Training on worker :265
INFO:root:FL Epoch: 534 Using Learning rate : 0.017200794626362776 
INFO:root:FL Epoch: 534 Normal Training
INFO:root:Worker: 265 Train Epoch: 0 [0/201 (0%)]	Loss: 0.736977
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 265 Train Epoch: 1 [0/201 (0%)]	Loss: 0.558436
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 534 Norm Difference for worker 265 is 1.040771
INFO:root:FL Epoch: 534 Done on worker:265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 534 Training on worker :35
INFO:root:FL Epoch: 534 Using Learning rate : 0.017200794626362776 
INFO:root:FL Epoch: 534 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.506292
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.519340
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 534 Norm Difference for worker 35 is 0.902956
INFO:root:FL Epoch: 534 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 534 Training on worker :1513
INFO:root:FL Epoch: 534 Using Learning rate : 0.017200794626362776 
INFO:root:FL Epoch: 534 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342915
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291453
INFO:root:FL Epoch: 534 Norm Difference for worker 1513 is 0.841623
INFO:root:FL Epoch: 534 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 534 Training on worker :218
INFO:root:FL Epoch: 534 Using Learning rate : 0.017200794626362776 
INFO:root:FL Epoch: 534 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.316167
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.485411
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 534 Norm Difference for worker 218 is 0.863015
INFO:root:FL Epoch: 534 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1728
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 534 Ends   ===================
INFO:root:Epoch:534 Global Model Test Loss:0.4889143512529485 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:534 Global Model Backdoor Test Loss:0.11519706373413403                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 535 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 535 Workers Selected : [1862, 981, 783, 483, 92, 332, 409, 1407, 210, 1936]
INFO:root:FL Epoch: 535 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 535 Num points on workers: [200 200 200 200 201 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 535 Training on worker :1862
INFO:root:FL Epoch: 535 Using Learning rate : 0.01716639303711005 
INFO:root:FL Epoch: 535 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557000
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422673
INFO:root:FL Epoch: 535 Norm Difference for worker 1862 is 0.841564
INFO:root:FL Epoch: 535 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 535 Training on worker :981
INFO:root:FL Epoch: 535 Using Learning rate : 0.01716639303711005 
INFO:root:FL Epoch: 535 Normal Training
INFO:root:Worker: 981 Train Epoch: 0 [0/200 (0%)]	Loss: 0.818142
INFO:root:Worker: 981 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386469
INFO:root:FL Epoch: 535 Norm Difference for worker 981 is 0.861369
INFO:root:FL Epoch: 535 Done on worker:981
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 535 Training on worker :783
INFO:root:FL Epoch: 535 Using Learning rate : 0.01716639303711005 
INFO:root:FL Epoch: 535 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551479
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510304
INFO:root:FL Epoch: 535 Norm Difference for worker 783 is 0.904453
INFO:root:FL Epoch: 535 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 535 Training on worker :483
INFO:root:FL Epoch: 535 Using Learning rate : 0.01716639303711005 
INFO:root:FL Epoch: 535 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.945673
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410646
INFO:root:FL Epoch: 535 Norm Difference for worker 483 is 0.841478
INFO:root:FL Epoch: 535 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 535 Training on worker :92
INFO:root:FL Epoch: 535 Using Learning rate : 0.01716639303711005 
INFO:root:FL Epoch: 535 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.681577
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.432084
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 535 Norm Difference for worker 92 is 0.853463
INFO:root:FL Epoch: 535 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 535 Training on worker :332
INFO:root:FL Epoch: 535 Using Learning rate : 0.01716639303711005 
INFO:root:FL Epoch: 535 Normal Training
INFO:root:Worker: 332 Train Epoch: 0 [0/201 (0%)]	Loss: 0.748201
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 332 Train Epoch: 1 [0/201 (0%)]	Loss: 0.413692
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 535 Norm Difference for worker 332 is 0.882238
INFO:root:FL Epoch: 535 Done on worker:332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 535 Training on worker :409
INFO:root:FL Epoch: 535 Using Learning rate : 0.01716639303711005 
INFO:root:FL Epoch: 535 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421330
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664354
INFO:root:FL Epoch: 535 Norm Difference for worker 409 is 0.876766
INFO:root:FL Epoch: 535 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 535 Training on worker :1407
INFO:root:FL Epoch: 535 Using Learning rate : 0.01716639303711005 
INFO:root:FL Epoch: 535 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631987
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377295
INFO:root:FL Epoch: 535 Norm Difference for worker 1407 is 0.846014
INFO:root:FL Epoch: 535 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 535 Training on worker :210
INFO:root:FL Epoch: 535 Using Learning rate : 0.01716639303711005 
INFO:root:FL Epoch: 535 Normal Training
INFO:root:Worker: 210 Train Epoch: 0 [0/201 (0%)]	Loss: 0.702346
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 210 Train Epoch: 1 [0/201 (0%)]	Loss: 0.542635
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 535 Norm Difference for worker 210 is 0.80763
INFO:root:FL Epoch: 535 Done on worker:210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 535 Training on worker :1936
INFO:root:FL Epoch: 535 Using Learning rate : 0.01716639303711005 
INFO:root:FL Epoch: 535 Normal Training
INFO:root:Worker: 1936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545878
INFO:root:Worker: 1936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341489
INFO:root:FL Epoch: 535 Norm Difference for worker 1936 is 0.832474
INFO:root:FL Epoch: 535 Done on worker:1936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 210
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 535 Ends   ===================
INFO:root:Epoch:535 Global Model Test Loss:0.48027804669211893 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:535 Global Model Backdoor Test Loss:0.12841462468107542                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 536 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 536 Workers Selected : [1219, 607, 222, 931, 772, 1596, 769, 484, 896, 852]
INFO:root:FL Epoch: 536 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 536 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 536 Training on worker :1219
INFO:root:FL Epoch: 536 Using Learning rate : 0.01713206025103583 
INFO:root:FL Epoch: 536 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430625
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498695
INFO:root:FL Epoch: 536 Norm Difference for worker 1219 is 0.812177
INFO:root:FL Epoch: 536 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 536 Training on worker :607
INFO:root:FL Epoch: 536 Using Learning rate : 0.01713206025103583 
INFO:root:FL Epoch: 536 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.299161
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359683
INFO:root:FL Epoch: 536 Norm Difference for worker 607 is 0.776712
INFO:root:FL Epoch: 536 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 536 Training on worker :222
INFO:root:FL Epoch: 536 Using Learning rate : 0.01713206025103583 
INFO:root:FL Epoch: 536 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.425932
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.517926
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 536 Norm Difference for worker 222 is 0.702991
INFO:root:FL Epoch: 536 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 536 Training on worker :931
INFO:root:FL Epoch: 536 Using Learning rate : 0.01713206025103583 
INFO:root:FL Epoch: 536 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570674
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567869
INFO:root:FL Epoch: 536 Norm Difference for worker 931 is 0.761066
INFO:root:FL Epoch: 536 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 536 Training on worker :772
INFO:root:FL Epoch: 536 Using Learning rate : 0.01713206025103583 
INFO:root:FL Epoch: 536 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572101
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365540
INFO:root:FL Epoch: 536 Norm Difference for worker 772 is 0.756153
INFO:root:FL Epoch: 536 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 536 Training on worker :1596
INFO:root:FL Epoch: 536 Using Learning rate : 0.01713206025103583 
INFO:root:FL Epoch: 536 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642293
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455003
INFO:root:FL Epoch: 536 Norm Difference for worker 1596 is 0.785921
INFO:root:FL Epoch: 536 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 536 Training on worker :769
INFO:root:FL Epoch: 536 Using Learning rate : 0.01713206025103583 
INFO:root:FL Epoch: 536 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690228
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585092
INFO:root:FL Epoch: 536 Norm Difference for worker 769 is 0.817613
INFO:root:FL Epoch: 536 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 536 Training on worker :484
INFO:root:FL Epoch: 536 Using Learning rate : 0.01713206025103583 
INFO:root:FL Epoch: 536 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418115
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594226
INFO:root:FL Epoch: 536 Norm Difference for worker 484 is 0.780345
INFO:root:FL Epoch: 536 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 536 Training on worker :896
INFO:root:FL Epoch: 536 Using Learning rate : 0.01713206025103583 
INFO:root:FL Epoch: 536 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436201
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270346
INFO:root:FL Epoch: 536 Norm Difference for worker 896 is 0.736317
INFO:root:FL Epoch: 536 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 536 Training on worker :852
INFO:root:FL Epoch: 536 Using Learning rate : 0.01713206025103583 
INFO:root:FL Epoch: 536 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472068
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308969
INFO:root:FL Epoch: 536 Norm Difference for worker 852 is 0.800779
INFO:root:FL Epoch: 536 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 222
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 536 Ends   ===================
INFO:root:Epoch:536 Global Model Test Loss:0.49217674136161804 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:536 Global Model Backdoor Test Loss:0.11139598488807678                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 537 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 537 Workers Selected : [1915, 136, 1458, 1617, 113, 225, 258, 144, 640, 920]
INFO:root:FL Epoch: 537 Fraction of points on each worker in this round: [0.09975062 0.10024938 0.09975062 0.09975062 0.10024938 0.10024938
 0.10024938 0.10024938 0.09975062 0.09975062]
INFO:root:FL Epoch: 537 Num points on workers: [200 201 200 200 201 201 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 537 Training on worker :1915
INFO:root:FL Epoch: 537 Using Learning rate : 0.01709779613053376 
INFO:root:FL Epoch: 537 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667324
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534600
INFO:root:FL Epoch: 537 Norm Difference for worker 1915 is 0.836656
INFO:root:FL Epoch: 537 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 537 Training on worker :136
INFO:root:FL Epoch: 537 Using Learning rate : 0.01709779613053376 
INFO:root:FL Epoch: 537 Normal Training
INFO:root:Worker: 136 Train Epoch: 0 [0/201 (0%)]	Loss: 0.430157
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 136 Train Epoch: 1 [0/201 (0%)]	Loss: 0.367741
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 537 Norm Difference for worker 136 is 0.772393
INFO:root:FL Epoch: 537 Done on worker:136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 537 Training on worker :1458
INFO:root:FL Epoch: 537 Using Learning rate : 0.01709779613053376 
INFO:root:FL Epoch: 537 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347433
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449032
INFO:root:FL Epoch: 537 Norm Difference for worker 1458 is 0.800657
INFO:root:FL Epoch: 537 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 537 Training on worker :1617
INFO:root:FL Epoch: 537 Using Learning rate : 0.01709779613053376 
INFO:root:FL Epoch: 537 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.847346
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585070
INFO:root:FL Epoch: 537 Norm Difference for worker 1617 is 0.784061
INFO:root:FL Epoch: 537 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 537 Training on worker :113
INFO:root:FL Epoch: 537 Using Learning rate : 0.01709779613053376 
INFO:root:FL Epoch: 537 Normal Training
INFO:root:Worker: 113 Train Epoch: 0 [0/201 (0%)]	Loss: 0.567576
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 113 Train Epoch: 1 [0/201 (0%)]	Loss: 0.383897
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 537 Norm Difference for worker 113 is 0.75882
INFO:root:FL Epoch: 537 Done on worker:113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 537 Training on worker :225
INFO:root:FL Epoch: 537 Using Learning rate : 0.01709779613053376 
INFO:root:FL Epoch: 537 Normal Training
INFO:root:Worker: 225 Train Epoch: 0 [0/201 (0%)]	Loss: 0.464781
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 225 Train Epoch: 1 [0/201 (0%)]	Loss: 0.629969
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 537 Norm Difference for worker 225 is 0.904484
INFO:root:FL Epoch: 537 Done on worker:225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 537 Training on worker :258
INFO:root:FL Epoch: 537 Using Learning rate : 0.01709779613053376 
INFO:root:FL Epoch: 537 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 1.151821
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.676099
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 537 Norm Difference for worker 258 is 0.834902
INFO:root:FL Epoch: 537 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 537 Training on worker :144
INFO:root:FL Epoch: 537 Using Learning rate : 0.01709779613053376 
INFO:root:FL Epoch: 537 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.427214
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.222341
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 537 Norm Difference for worker 144 is 0.787931
INFO:root:FL Epoch: 537 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 537 Training on worker :640
INFO:root:FL Epoch: 537 Using Learning rate : 0.01709779613053376 
INFO:root:FL Epoch: 537 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416614
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617990
INFO:root:FL Epoch: 537 Norm Difference for worker 640 is 0.802238
INFO:root:FL Epoch: 537 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 537 Training on worker :920
INFO:root:FL Epoch: 537 Using Learning rate : 0.01709779613053376 
INFO:root:FL Epoch: 537 Normal Training
INFO:root:Worker: 920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411876
INFO:root:Worker: 920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511776
INFO:root:FL Epoch: 537 Norm Difference for worker 920 is 0.847154
INFO:root:FL Epoch: 537 Done on worker:920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1617
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 537 Ends   ===================
INFO:root:Epoch:537 Global Model Test Loss:0.48830238159965067 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:537 Global Model Backdoor Test Loss:0.1534475845595201                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 538 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 538 Workers Selected : [483, 1773, 692, 125, 896, 1694, 899, 1396, 1318, 1791]
INFO:root:FL Epoch: 538 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 538 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 538 Training on worker :483
INFO:root:FL Epoch: 538 Using Learning rate : 0.01706360053827269 
INFO:root:FL Epoch: 538 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459628
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277040
INFO:root:FL Epoch: 538 Norm Difference for worker 483 is 0.674061
INFO:root:FL Epoch: 538 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 538 Training on worker :1773
INFO:root:FL Epoch: 538 Using Learning rate : 0.01706360053827269 
INFO:root:FL Epoch: 538 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656661
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375886
INFO:root:FL Epoch: 538 Norm Difference for worker 1773 is 0.667386
INFO:root:FL Epoch: 538 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 538 Training on worker :692
INFO:root:FL Epoch: 538 Using Learning rate : 0.01706360053827269 
INFO:root:FL Epoch: 538 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543919
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365020
INFO:root:FL Epoch: 538 Norm Difference for worker 692 is 0.622057
INFO:root:FL Epoch: 538 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 538 Training on worker :125
INFO:root:FL Epoch: 538 Using Learning rate : 0.01706360053827269 
INFO:root:FL Epoch: 538 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.473683
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.443282
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 538 Norm Difference for worker 125 is 0.678397
INFO:root:FL Epoch: 538 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 538 Training on worker :896
INFO:root:FL Epoch: 538 Using Learning rate : 0.01706360053827269 
INFO:root:FL Epoch: 538 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336440
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288950
INFO:root:FL Epoch: 538 Norm Difference for worker 896 is 0.662538
INFO:root:FL Epoch: 538 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 538 Training on worker :1694
INFO:root:FL Epoch: 538 Using Learning rate : 0.01706360053827269 
INFO:root:FL Epoch: 538 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423145
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424358
INFO:root:FL Epoch: 538 Norm Difference for worker 1694 is 0.672346
INFO:root:FL Epoch: 538 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 538 Training on worker :899
INFO:root:FL Epoch: 538 Using Learning rate : 0.01706360053827269 
INFO:root:FL Epoch: 538 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569098
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278147
INFO:root:FL Epoch: 538 Norm Difference for worker 899 is 0.683643
INFO:root:FL Epoch: 538 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 538 Training on worker :1396
INFO:root:FL Epoch: 538 Using Learning rate : 0.01706360053827269 
INFO:root:FL Epoch: 538 Normal Training
INFO:root:Worker: 1396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704465
INFO:root:Worker: 1396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470120
INFO:root:FL Epoch: 538 Norm Difference for worker 1396 is 0.668786
INFO:root:FL Epoch: 538 Done on worker:1396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 538 Training on worker :1318
INFO:root:FL Epoch: 538 Using Learning rate : 0.01706360053827269 
INFO:root:FL Epoch: 538 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624629
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499014
INFO:root:FL Epoch: 538 Norm Difference for worker 1318 is 0.673153
INFO:root:FL Epoch: 538 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 538 Training on worker :1791
INFO:root:FL Epoch: 538 Using Learning rate : 0.01706360053827269 
INFO:root:FL Epoch: 538 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662411
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589540
INFO:root:FL Epoch: 538 Norm Difference for worker 1791 is 0.69416
INFO:root:FL Epoch: 538 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 692
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 538 Ends   ===================
INFO:root:Epoch:538 Global Model Test Loss:0.48182716790367575 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:538 Global Model Backdoor Test Loss:0.14671933030088743                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 539 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 539 Workers Selected : [1629, 745, 1002, 1359, 619, 1907, 21, 1557, 205, 802]
INFO:root:FL Epoch: 539 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 539 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 539 Training on worker :1629
INFO:root:FL Epoch: 539 Using Learning rate : 0.017029473337196146 
INFO:root:FL Epoch: 539 Normal Training
INFO:root:Worker: 1629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515831
INFO:root:Worker: 1629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464414
INFO:root:FL Epoch: 539 Norm Difference for worker 1629 is 0.67025
INFO:root:FL Epoch: 539 Done on worker:1629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 539 Training on worker :745
INFO:root:FL Epoch: 539 Using Learning rate : 0.017029473337196146 
INFO:root:FL Epoch: 539 Normal Training
INFO:root:Worker: 745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501426
INFO:root:Worker: 745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563908
INFO:root:FL Epoch: 539 Norm Difference for worker 745 is 0.718731
INFO:root:FL Epoch: 539 Done on worker:745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 539 Training on worker :1002
INFO:root:FL Epoch: 539 Using Learning rate : 0.017029473337196146 
INFO:root:FL Epoch: 539 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525354
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390636
INFO:root:FL Epoch: 539 Norm Difference for worker 1002 is 0.643042
INFO:root:FL Epoch: 539 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 539 Training on worker :1359
INFO:root:FL Epoch: 539 Using Learning rate : 0.017029473337196146 
INFO:root:FL Epoch: 539 Normal Training
INFO:root:Worker: 1359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520297
INFO:root:Worker: 1359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517957
INFO:root:FL Epoch: 539 Norm Difference for worker 1359 is 0.677021
INFO:root:FL Epoch: 539 Done on worker:1359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 539 Training on worker :619
INFO:root:FL Epoch: 539 Using Learning rate : 0.017029473337196146 
INFO:root:FL Epoch: 539 Normal Training
INFO:root:Worker: 619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744172
INFO:root:Worker: 619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487732
INFO:root:FL Epoch: 539 Norm Difference for worker 619 is 0.670948
INFO:root:FL Epoch: 539 Done on worker:619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 539 Training on worker :1907
INFO:root:FL Epoch: 539 Using Learning rate : 0.017029473337196146 
INFO:root:FL Epoch: 539 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515063
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531918
INFO:root:FL Epoch: 539 Norm Difference for worker 1907 is 0.660343
INFO:root:FL Epoch: 539 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 539 Training on worker :21
INFO:root:FL Epoch: 539 Using Learning rate : 0.017029473337196146 
INFO:root:FL Epoch: 539 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.474819
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.472706
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 539 Norm Difference for worker 21 is 0.646686
INFO:root:FL Epoch: 539 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 539 Training on worker :1557
INFO:root:FL Epoch: 539 Using Learning rate : 0.017029473337196146 
INFO:root:FL Epoch: 539 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498053
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399543
INFO:root:FL Epoch: 539 Norm Difference for worker 1557 is 0.636316
INFO:root:FL Epoch: 539 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 539 Training on worker :205
INFO:root:FL Epoch: 539 Using Learning rate : 0.017029473337196146 
INFO:root:FL Epoch: 539 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.448822
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.626825
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 539 Norm Difference for worker 205 is 0.691775
INFO:root:FL Epoch: 539 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 539 Training on worker :802
INFO:root:FL Epoch: 539 Using Learning rate : 0.017029473337196146 
INFO:root:FL Epoch: 539 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402613
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439774
INFO:root:FL Epoch: 539 Norm Difference for worker 802 is 0.699728
INFO:root:FL Epoch: 539 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 21
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 539 Ends   ===================
INFO:root:Epoch:539 Global Model Test Loss:0.4745052754878998 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:539 Global Model Backdoor Test Loss:0.1871982105076313                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 540 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 540 Workers Selected : [871, 60, 930, 1124, 733, 1016, 689, 214, 319, 1111]
INFO:root:FL Epoch: 540 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 540 Num points on workers: [200 201 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 540 Training on worker :871
INFO:root:FL Epoch: 540 Using Learning rate : 0.01699541439052175 
INFO:root:FL Epoch: 540 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662867
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422719
INFO:root:FL Epoch: 540 Norm Difference for worker 871 is 0.680243
INFO:root:FL Epoch: 540 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 540 Training on worker :60
INFO:root:FL Epoch: 540 Using Learning rate : 0.01699541439052175 
INFO:root:FL Epoch: 540 Normal Training
INFO:root:Worker: 60 Train Epoch: 0 [0/201 (0%)]	Loss: 0.377176
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 60 Train Epoch: 1 [0/201 (0%)]	Loss: 0.615937
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 540 Norm Difference for worker 60 is 0.675112
INFO:root:FL Epoch: 540 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 540 Training on worker :930
INFO:root:FL Epoch: 540 Using Learning rate : 0.01699541439052175 
INFO:root:FL Epoch: 540 Normal Training
INFO:root:Worker: 930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378231
INFO:root:Worker: 930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327744
INFO:root:FL Epoch: 540 Norm Difference for worker 930 is 0.650309
INFO:root:FL Epoch: 540 Done on worker:930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 540 Training on worker :1124
INFO:root:FL Epoch: 540 Using Learning rate : 0.01699541439052175 
INFO:root:FL Epoch: 540 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579595
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495336
INFO:root:FL Epoch: 540 Norm Difference for worker 1124 is 0.656572
INFO:root:FL Epoch: 540 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 540 Training on worker :733
INFO:root:FL Epoch: 540 Using Learning rate : 0.01699541439052175 
INFO:root:FL Epoch: 540 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.852292
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568867
INFO:root:FL Epoch: 540 Norm Difference for worker 733 is 0.709068
INFO:root:FL Epoch: 540 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 540 Training on worker :1016
INFO:root:FL Epoch: 540 Using Learning rate : 0.01699541439052175 
INFO:root:FL Epoch: 540 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659087
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411438
INFO:root:FL Epoch: 540 Norm Difference for worker 1016 is 0.714256
INFO:root:FL Epoch: 540 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 540 Training on worker :689
INFO:root:FL Epoch: 540 Using Learning rate : 0.01699541439052175 
INFO:root:FL Epoch: 540 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481148
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555025
INFO:root:FL Epoch: 540 Norm Difference for worker 689 is 0.698688
INFO:root:FL Epoch: 540 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 540 Training on worker :214
INFO:root:FL Epoch: 540 Using Learning rate : 0.01699541439052175 
INFO:root:FL Epoch: 540 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.438829
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.416432
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 540 Norm Difference for worker 214 is 0.681128
INFO:root:FL Epoch: 540 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 540 Training on worker :319
INFO:root:FL Epoch: 540 Using Learning rate : 0.01699541439052175 
INFO:root:FL Epoch: 540 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.423878
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.286698
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 540 Norm Difference for worker 319 is 0.723781
INFO:root:FL Epoch: 540 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 540 Training on worker :1111
INFO:root:FL Epoch: 540 Using Learning rate : 0.01699541439052175 
INFO:root:FL Epoch: 540 Normal Training
INFO:root:Worker: 1111 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769770
INFO:root:Worker: 1111 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298151
INFO:root:FL Epoch: 540 Norm Difference for worker 1111 is 0.637673
INFO:root:FL Epoch: 540 Done on worker:1111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1111
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 540 Ends   ===================
INFO:root:Epoch:540 Global Model Test Loss:0.4687879979610443 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:540 Global Model Backdoor Test Loss:0.16478798538446426                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 541 Begins ===================
INFO:root:FL Epoch: 541 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 541 Workers Selected : [0, 1, 2, 472, 1059, 560, 655, 898, 1664, 1277]
INFO:root:FL Epoch: 541 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 541 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 541 Training on worker :0
INFO:root:FL Epoch: 541 Using Learning rate : 0.0033922847123481416 
INFO:root:FL Epoch: 541 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.120966
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197310
INFO:root:FL Epoch: 541 Worker: 0 Backdoor Test Loss: 0.14069530367851257 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 541 Worker: 0 Backdoor Train Loss: 0.16246261671185494 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 541 Norm Difference for worker 0 is 0.100121
INFO:root:FL Epoch: 541 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 541 Training on worker :1
INFO:root:FL Epoch: 541 Using Learning rate : 0.0033922847123481416 
INFO:root:FL Epoch: 541 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.257510
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.173738
INFO:root:FL Epoch: 541 Worker: 1 Backdoor Test Loss: 0.1400764063000679 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 541 Worker: 1 Backdoor Train Loss: 0.16209367364645005 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 541 Norm Difference for worker 1 is 0.101231
INFO:root:FL Epoch: 541 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 541 Training on worker :2
INFO:root:FL Epoch: 541 Using Learning rate : 0.0033922847123481416 
INFO:root:FL Epoch: 541 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.180458
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175231
INFO:root:FL Epoch: 541 Worker: 2 Backdoor Test Loss: 0.13980528463919958 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 541 Worker: 2 Backdoor Train Loss: 0.16298503875732423 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 541 Norm Difference for worker 2 is 0.097633
INFO:root:FL Epoch: 541 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 541 Training on worker :472
INFO:root:FL Epoch: 541 Using Learning rate : 0.01696142356174071 
INFO:root:FL Epoch: 541 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405622
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432627
INFO:root:FL Epoch: 541 Norm Difference for worker 472 is 0.656315
INFO:root:FL Epoch: 541 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 541 Training on worker :1059
INFO:root:FL Epoch: 541 Using Learning rate : 0.01696142356174071 
INFO:root:FL Epoch: 541 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625415
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545627
INFO:root:FL Epoch: 541 Norm Difference for worker 1059 is 0.657906
INFO:root:FL Epoch: 541 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 541 Training on worker :560
INFO:root:FL Epoch: 541 Using Learning rate : 0.01696142356174071 
INFO:root:FL Epoch: 541 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560432
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409342
INFO:root:FL Epoch: 541 Norm Difference for worker 560 is 0.648893
INFO:root:FL Epoch: 541 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 541 Training on worker :655
INFO:root:FL Epoch: 541 Using Learning rate : 0.01696142356174071 
INFO:root:FL Epoch: 541 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548307
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420328
INFO:root:FL Epoch: 541 Norm Difference for worker 655 is 0.657073
INFO:root:FL Epoch: 541 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 541 Training on worker :898
INFO:root:FL Epoch: 541 Using Learning rate : 0.01696142356174071 
INFO:root:FL Epoch: 541 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357488
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336610
INFO:root:FL Epoch: 541 Norm Difference for worker 898 is 0.670259
INFO:root:FL Epoch: 541 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 541 Training on worker :1664
INFO:root:FL Epoch: 541 Using Learning rate : 0.01696142356174071 
INFO:root:FL Epoch: 541 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623652
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668105
INFO:root:FL Epoch: 541 Norm Difference for worker 1664 is 0.69433
INFO:root:FL Epoch: 541 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 541 Training on worker :1277
INFO:root:FL Epoch: 541 Using Learning rate : 0.01696142356174071 
INFO:root:FL Epoch: 541 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.181827
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364150
INFO:root:FL Epoch: 541 Norm Difference for worker 1277 is 0.633829
INFO:root:FL Epoch: 541 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 541 Ends   ===================
INFO:root:Epoch:541 Global Model Test Loss:0.4687224065556246 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:541 Global Model Backdoor Test Loss:0.14069530367851257                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 542 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 542 Workers Selected : [1085, 431, 1019, 17, 671, 163, 1750, 1316, 365, 535]
INFO:root:FL Epoch: 542 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 542 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 542 Training on worker :1085
INFO:root:FL Epoch: 542 Using Learning rate : 0.016927500714617228 
INFO:root:FL Epoch: 542 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355167
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462765
INFO:root:FL Epoch: 542 Norm Difference for worker 1085 is 0.703844
INFO:root:FL Epoch: 542 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 542 Training on worker :431
INFO:root:FL Epoch: 542 Using Learning rate : 0.016927500714617228 
INFO:root:FL Epoch: 542 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635286
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474309
INFO:root:FL Epoch: 542 Norm Difference for worker 431 is 0.715786
INFO:root:FL Epoch: 542 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 542 Training on worker :1019
INFO:root:FL Epoch: 542 Using Learning rate : 0.016927500714617228 
INFO:root:FL Epoch: 542 Normal Training
INFO:root:Worker: 1019 Train Epoch: 0 [0/200 (0%)]	Loss: 0.278150
INFO:root:Worker: 1019 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391109
INFO:root:FL Epoch: 542 Norm Difference for worker 1019 is 0.687088
INFO:root:FL Epoch: 542 Done on worker:1019
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 542 Training on worker :17
INFO:root:FL Epoch: 542 Using Learning rate : 0.016927500714617228 
INFO:root:FL Epoch: 542 Normal Training
INFO:root:Worker: 17 Train Epoch: 0 [0/201 (0%)]	Loss: 0.666020
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 17 Train Epoch: 1 [0/201 (0%)]	Loss: 0.622624
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 542 Norm Difference for worker 17 is 0.734422
INFO:root:FL Epoch: 542 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 542 Training on worker :671
INFO:root:FL Epoch: 542 Using Learning rate : 0.016927500714617228 
INFO:root:FL Epoch: 542 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574836
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317438
INFO:root:FL Epoch: 542 Norm Difference for worker 671 is 0.682821
INFO:root:FL Epoch: 542 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 542 Training on worker :163
INFO:root:FL Epoch: 542 Using Learning rate : 0.016927500714617228 
INFO:root:FL Epoch: 542 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691191
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.606360
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 542 Norm Difference for worker 163 is 0.732911
INFO:root:FL Epoch: 542 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 542 Training on worker :1750
INFO:root:FL Epoch: 542 Using Learning rate : 0.016927500714617228 
INFO:root:FL Epoch: 542 Normal Training
INFO:root:Worker: 1750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656901
INFO:root:Worker: 1750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634699
INFO:root:FL Epoch: 542 Norm Difference for worker 1750 is 0.748373
INFO:root:FL Epoch: 542 Done on worker:1750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 542 Training on worker :1316
INFO:root:FL Epoch: 542 Using Learning rate : 0.016927500714617228 
INFO:root:FL Epoch: 542 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413446
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492970
INFO:root:FL Epoch: 542 Norm Difference for worker 1316 is 0.563965
INFO:root:FL Epoch: 542 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 542 Training on worker :365
INFO:root:FL Epoch: 542 Using Learning rate : 0.016927500714617228 
INFO:root:FL Epoch: 542 Normal Training
INFO:root:Worker: 365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420170
INFO:root:Worker: 365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514368
INFO:root:FL Epoch: 542 Norm Difference for worker 365 is 0.654984
INFO:root:FL Epoch: 542 Done on worker:365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 542 Training on worker :535
INFO:root:FL Epoch: 542 Using Learning rate : 0.016927500714617228 
INFO:root:FL Epoch: 542 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.252322
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539898
INFO:root:FL Epoch: 542 Norm Difference for worker 535 is 0.588059
INFO:root:FL Epoch: 542 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1316
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 542 Ends   ===================
INFO:root:Epoch:542 Global Model Test Loss:0.47918393331415515 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:542 Global Model Backdoor Test Loss:0.1014681061108907                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 543 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 543 Workers Selected : [807, 1321, 608, 1300, 1732, 245, 865, 1286, 1311, 189]
INFO:root:FL Epoch: 543 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 543 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 543 Training on worker :807
INFO:root:FL Epoch: 543 Using Learning rate : 0.01689364571318799 
INFO:root:FL Epoch: 543 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609376
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464300
INFO:root:FL Epoch: 543 Norm Difference for worker 807 is 0.837989
INFO:root:FL Epoch: 543 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 543 Training on worker :1321
INFO:root:FL Epoch: 543 Using Learning rate : 0.01689364571318799 
INFO:root:FL Epoch: 543 Normal Training
INFO:root:Worker: 1321 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689116
INFO:root:Worker: 1321 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385390
INFO:root:FL Epoch: 543 Norm Difference for worker 1321 is 0.828031
INFO:root:FL Epoch: 543 Done on worker:1321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 543 Training on worker :608
INFO:root:FL Epoch: 543 Using Learning rate : 0.01689364571318799 
INFO:root:FL Epoch: 543 Normal Training
INFO:root:Worker: 608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418157
INFO:root:Worker: 608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429466
INFO:root:FL Epoch: 543 Norm Difference for worker 608 is 0.863149
INFO:root:FL Epoch: 543 Done on worker:608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 543 Training on worker :1300
INFO:root:FL Epoch: 543 Using Learning rate : 0.01689364571318799 
INFO:root:FL Epoch: 543 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.239871
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414438
INFO:root:FL Epoch: 543 Norm Difference for worker 1300 is 0.823869
INFO:root:FL Epoch: 543 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 543 Training on worker :1732
INFO:root:FL Epoch: 543 Using Learning rate : 0.01689364571318799 
INFO:root:FL Epoch: 543 Normal Training
INFO:root:Worker: 1732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737169
INFO:root:Worker: 1732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388805
INFO:root:FL Epoch: 543 Norm Difference for worker 1732 is 0.86065
INFO:root:FL Epoch: 543 Done on worker:1732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 543 Training on worker :245
INFO:root:FL Epoch: 543 Using Learning rate : 0.01689364571318799 
INFO:root:FL Epoch: 543 Normal Training
INFO:root:Worker: 245 Train Epoch: 0 [0/201 (0%)]	Loss: 0.475172
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 245 Train Epoch: 1 [0/201 (0%)]	Loss: 0.514769
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 543 Norm Difference for worker 245 is 0.843215
INFO:root:FL Epoch: 543 Done on worker:245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 543 Training on worker :865
INFO:root:FL Epoch: 543 Using Learning rate : 0.01689364571318799 
INFO:root:FL Epoch: 543 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456121
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639124
INFO:root:FL Epoch: 543 Norm Difference for worker 865 is 0.780327
INFO:root:FL Epoch: 543 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 543 Training on worker :1286
INFO:root:FL Epoch: 543 Using Learning rate : 0.01689364571318799 
INFO:root:FL Epoch: 543 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724714
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489664
INFO:root:FL Epoch: 543 Norm Difference for worker 1286 is 0.838604
INFO:root:FL Epoch: 543 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 543 Training on worker :1311
INFO:root:FL Epoch: 543 Using Learning rate : 0.01689364571318799 
INFO:root:FL Epoch: 543 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488434
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551357
INFO:root:FL Epoch: 543 Norm Difference for worker 1311 is 0.992284
INFO:root:FL Epoch: 543 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 543 Training on worker :189
INFO:root:FL Epoch: 543 Using Learning rate : 0.01689364571318799 
INFO:root:FL Epoch: 543 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.586316
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.589177
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 543 Norm Difference for worker 189 is 0.839121
INFO:root:FL Epoch: 543 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 865
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 543 Ends   ===================
INFO:root:Epoch:543 Global Model Test Loss:0.5001245684483472 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:543 Global Model Backdoor Test Loss:0.14967756842573485                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 544 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 544 Workers Selected : [1045, 1586, 604, 485, 1560, 43, 1653, 8, 197, 1076]
INFO:root:FL Epoch: 544 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 544 Num points on workers: [200 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 544 Training on worker :1045
INFO:root:FL Epoch: 544 Using Learning rate : 0.016859858421761617 
INFO:root:FL Epoch: 544 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733847
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545406
INFO:root:FL Epoch: 544 Norm Difference for worker 1045 is 0.800621
INFO:root:FL Epoch: 544 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 544 Training on worker :1586
INFO:root:FL Epoch: 544 Using Learning rate : 0.016859858421761617 
INFO:root:FL Epoch: 544 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613347
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447279
INFO:root:FL Epoch: 544 Norm Difference for worker 1586 is 0.801809
INFO:root:FL Epoch: 544 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 544 Training on worker :604
INFO:root:FL Epoch: 544 Using Learning rate : 0.016859858421761617 
INFO:root:FL Epoch: 544 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400007
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.151558
INFO:root:FL Epoch: 544 Norm Difference for worker 604 is 0.848248
INFO:root:FL Epoch: 544 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 544 Training on worker :485
INFO:root:FL Epoch: 544 Using Learning rate : 0.016859858421761617 
INFO:root:FL Epoch: 544 Normal Training
INFO:root:Worker: 485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520965
INFO:root:Worker: 485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552504
INFO:root:FL Epoch: 544 Norm Difference for worker 485 is 0.769876
INFO:root:FL Epoch: 544 Done on worker:485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 544 Training on worker :1560
INFO:root:FL Epoch: 544 Using Learning rate : 0.016859858421761617 
INFO:root:FL Epoch: 544 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546117
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442240
INFO:root:FL Epoch: 544 Norm Difference for worker 1560 is 0.83515
INFO:root:FL Epoch: 544 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 544 Training on worker :43
INFO:root:FL Epoch: 544 Using Learning rate : 0.016859858421761617 
INFO:root:FL Epoch: 544 Normal Training
INFO:root:Worker: 43 Train Epoch: 0 [0/201 (0%)]	Loss: 0.880993
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 43 Train Epoch: 1 [0/201 (0%)]	Loss: 0.714707
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 544 Norm Difference for worker 43 is 0.849496
INFO:root:FL Epoch: 544 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 544 Training on worker :1653
INFO:root:FL Epoch: 544 Using Learning rate : 0.016859858421761617 
INFO:root:FL Epoch: 544 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401030
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311836
INFO:root:FL Epoch: 544 Norm Difference for worker 1653 is 0.776701
INFO:root:FL Epoch: 544 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 544 Training on worker :8
INFO:root:FL Epoch: 544 Using Learning rate : 0.016859858421761617 
INFO:root:FL Epoch: 544 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.737902
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.335180
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 544 Norm Difference for worker 8 is 0.830665
INFO:root:FL Epoch: 544 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 544 Training on worker :197
INFO:root:FL Epoch: 544 Using Learning rate : 0.016859858421761617 
INFO:root:FL Epoch: 544 Normal Training
INFO:root:Worker: 197 Train Epoch: 0 [0/201 (0%)]	Loss: 0.300905
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 197 Train Epoch: 1 [0/201 (0%)]	Loss: 0.544826
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 544 Norm Difference for worker 197 is 0.812847
INFO:root:FL Epoch: 544 Done on worker:197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 544 Training on worker :1076
INFO:root:FL Epoch: 544 Using Learning rate : 0.016859858421761617 
INFO:root:FL Epoch: 544 Normal Training
INFO:root:Worker: 1076 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677771
INFO:root:Worker: 1076 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409842
INFO:root:FL Epoch: 544 Norm Difference for worker 1076 is 0.805694
INFO:root:FL Epoch: 544 Done on worker:1076
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1045
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 544 Ends   ===================
INFO:root:Epoch:544 Global Model Test Loss:0.4790704723666696 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:544 Global Model Backdoor Test Loss:0.11980980386336644                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 545 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 545 Workers Selected : [1887, 1618, 192, 1922, 853, 409, 37, 1797, 1173, 354]
INFO:root:FL Epoch: 545 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 545 Num points on workers: [200 200 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 545 Training on worker :1887
INFO:root:FL Epoch: 545 Using Learning rate : 0.016826138704918094 
INFO:root:FL Epoch: 545 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487795
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417621
INFO:root:FL Epoch: 545 Norm Difference for worker 1887 is 0.70795
INFO:root:FL Epoch: 545 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 545 Training on worker :1618
INFO:root:FL Epoch: 545 Using Learning rate : 0.016826138704918094 
INFO:root:FL Epoch: 545 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530200
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455124
INFO:root:FL Epoch: 545 Norm Difference for worker 1618 is 0.693976
INFO:root:FL Epoch: 545 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 545 Training on worker :192
INFO:root:FL Epoch: 545 Using Learning rate : 0.016826138704918094 
INFO:root:FL Epoch: 545 Normal Training
INFO:root:Worker: 192 Train Epoch: 0 [0/201 (0%)]	Loss: 0.741315
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 192 Train Epoch: 1 [0/201 (0%)]	Loss: 0.575440
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 545 Norm Difference for worker 192 is 0.686442
INFO:root:FL Epoch: 545 Done on worker:192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 545 Training on worker :1922
INFO:root:FL Epoch: 545 Using Learning rate : 0.016826138704918094 
INFO:root:FL Epoch: 545 Normal Training
INFO:root:Worker: 1922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304704
INFO:root:Worker: 1922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449258
INFO:root:FL Epoch: 545 Norm Difference for worker 1922 is 0.672767
INFO:root:FL Epoch: 545 Done on worker:1922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 545 Training on worker :853
INFO:root:FL Epoch: 545 Using Learning rate : 0.016826138704918094 
INFO:root:FL Epoch: 545 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427546
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414917
INFO:root:FL Epoch: 545 Norm Difference for worker 853 is 0.723702
INFO:root:FL Epoch: 545 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 545 Training on worker :409
INFO:root:FL Epoch: 545 Using Learning rate : 0.016826138704918094 
INFO:root:FL Epoch: 545 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.267581
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486445
INFO:root:FL Epoch: 545 Norm Difference for worker 409 is 0.732442
INFO:root:FL Epoch: 545 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 545 Training on worker :37
INFO:root:FL Epoch: 545 Using Learning rate : 0.016826138704918094 
INFO:root:FL Epoch: 545 Normal Training
INFO:root:Worker: 37 Train Epoch: 0 [0/201 (0%)]	Loss: 0.605853
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 37 Train Epoch: 1 [0/201 (0%)]	Loss: 0.472962
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 545 Norm Difference for worker 37 is 0.749836
INFO:root:FL Epoch: 545 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 545 Training on worker :1797
INFO:root:FL Epoch: 545 Using Learning rate : 0.016826138704918094 
INFO:root:FL Epoch: 545 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668750
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531928
INFO:root:FL Epoch: 545 Norm Difference for worker 1797 is 0.785041
INFO:root:FL Epoch: 545 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 545 Training on worker :1173
INFO:root:FL Epoch: 545 Using Learning rate : 0.016826138704918094 
INFO:root:FL Epoch: 545 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473674
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313236
INFO:root:FL Epoch: 545 Norm Difference for worker 1173 is 0.659522
INFO:root:FL Epoch: 545 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 545 Training on worker :354
INFO:root:FL Epoch: 545 Using Learning rate : 0.016826138704918094 
INFO:root:FL Epoch: 545 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727777
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533344
INFO:root:FL Epoch: 545 Norm Difference for worker 354 is 0.714323
INFO:root:FL Epoch: 545 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1922
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 545 Ends   ===================
INFO:root:Epoch:545 Global Model Test Loss:0.5151930153369904 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:545 Global Model Backdoor Test Loss:0.16601302971442541                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 546 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 546 Workers Selected : [1581, 1807, 1605, 445, 1804, 852, 67, 1870, 1033, 1199]
INFO:root:FL Epoch: 546 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 546 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 546 Training on worker :1581
INFO:root:FL Epoch: 546 Using Learning rate : 0.016792486427508257 
INFO:root:FL Epoch: 546 Normal Training
INFO:root:Worker: 1581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554590
INFO:root:Worker: 1581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280339
INFO:root:FL Epoch: 546 Norm Difference for worker 1581 is 0.723857
INFO:root:FL Epoch: 546 Done on worker:1581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 546 Training on worker :1807
INFO:root:FL Epoch: 546 Using Learning rate : 0.016792486427508257 
INFO:root:FL Epoch: 546 Normal Training
INFO:root:Worker: 1807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627037
INFO:root:Worker: 1807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237737
INFO:root:FL Epoch: 546 Norm Difference for worker 1807 is 0.652424
INFO:root:FL Epoch: 546 Done on worker:1807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 546 Training on worker :1605
INFO:root:FL Epoch: 546 Using Learning rate : 0.016792486427508257 
INFO:root:FL Epoch: 546 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572845
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677446
INFO:root:FL Epoch: 546 Norm Difference for worker 1605 is 0.821978
INFO:root:FL Epoch: 546 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 546 Training on worker :445
INFO:root:FL Epoch: 546 Using Learning rate : 0.016792486427508257 
INFO:root:FL Epoch: 546 Normal Training
INFO:root:Worker: 445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327569
INFO:root:Worker: 445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343043
INFO:root:FL Epoch: 546 Norm Difference for worker 445 is 0.76225
INFO:root:FL Epoch: 546 Done on worker:445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 546 Training on worker :1804
INFO:root:FL Epoch: 546 Using Learning rate : 0.016792486427508257 
INFO:root:FL Epoch: 546 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531790
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380693
INFO:root:FL Epoch: 546 Norm Difference for worker 1804 is 0.753999
INFO:root:FL Epoch: 546 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 546 Training on worker :852
INFO:root:FL Epoch: 546 Using Learning rate : 0.016792486427508257 
INFO:root:FL Epoch: 546 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464509
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458962
INFO:root:FL Epoch: 546 Norm Difference for worker 852 is 0.758981
INFO:root:FL Epoch: 546 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 546 Training on worker :67
INFO:root:FL Epoch: 546 Using Learning rate : 0.016792486427508257 
INFO:root:FL Epoch: 546 Normal Training
INFO:root:Worker: 67 Train Epoch: 0 [0/201 (0%)]	Loss: 0.543974
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 67 Train Epoch: 1 [0/201 (0%)]	Loss: 0.319752
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 546 Norm Difference for worker 67 is 0.77254
INFO:root:FL Epoch: 546 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 546 Training on worker :1870
INFO:root:FL Epoch: 546 Using Learning rate : 0.016792486427508257 
INFO:root:FL Epoch: 546 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579955
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406899
INFO:root:FL Epoch: 546 Norm Difference for worker 1870 is 0.847609
INFO:root:FL Epoch: 546 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 546 Training on worker :1033
INFO:root:FL Epoch: 546 Using Learning rate : 0.016792486427508257 
INFO:root:FL Epoch: 546 Normal Training
INFO:root:Worker: 1033 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586845
INFO:root:Worker: 1033 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520123
INFO:root:FL Epoch: 546 Norm Difference for worker 1033 is 0.817755
INFO:root:FL Epoch: 546 Done on worker:1033
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 546 Training on worker :1199
INFO:root:FL Epoch: 546 Using Learning rate : 0.016792486427508257 
INFO:root:FL Epoch: 546 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533097
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464547
INFO:root:FL Epoch: 546 Norm Difference for worker 1199 is 0.733526
INFO:root:FL Epoch: 546 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 445
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 546 Ends   ===================
INFO:root:Epoch:546 Global Model Test Loss:0.48663826549754424 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:546 Global Model Backdoor Test Loss:0.09040977681676547                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 547 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 547 Workers Selected : [623, 1667, 1748, 1473, 484, 422, 1584, 1257, 247, 1862]
INFO:root:FL Epoch: 547 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 547 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 547 Training on worker :623
INFO:root:FL Epoch: 547 Using Learning rate : 0.016758901454653242 
INFO:root:FL Epoch: 547 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401551
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337304
INFO:root:FL Epoch: 547 Norm Difference for worker 623 is 0.688023
INFO:root:FL Epoch: 547 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 547 Training on worker :1667
INFO:root:FL Epoch: 547 Using Learning rate : 0.016758901454653242 
INFO:root:FL Epoch: 547 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420468
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426311
INFO:root:FL Epoch: 547 Norm Difference for worker 1667 is 0.726155
INFO:root:FL Epoch: 547 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 547 Training on worker :1748
INFO:root:FL Epoch: 547 Using Learning rate : 0.016758901454653242 
INFO:root:FL Epoch: 547 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602746
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626448
INFO:root:FL Epoch: 547 Norm Difference for worker 1748 is 0.781565
INFO:root:FL Epoch: 547 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 547 Training on worker :1473
INFO:root:FL Epoch: 547 Using Learning rate : 0.016758901454653242 
INFO:root:FL Epoch: 547 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544356
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424855
INFO:root:FL Epoch: 547 Norm Difference for worker 1473 is 0.781211
INFO:root:FL Epoch: 547 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 547 Training on worker :484
INFO:root:FL Epoch: 547 Using Learning rate : 0.016758901454653242 
INFO:root:FL Epoch: 547 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.836140
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345845
INFO:root:FL Epoch: 547 Norm Difference for worker 484 is 0.692638
INFO:root:FL Epoch: 547 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 547 Training on worker :422
INFO:root:FL Epoch: 547 Using Learning rate : 0.016758901454653242 
INFO:root:FL Epoch: 547 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774407
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302451
INFO:root:FL Epoch: 547 Norm Difference for worker 422 is 0.747639
INFO:root:FL Epoch: 547 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 547 Training on worker :1584
INFO:root:FL Epoch: 547 Using Learning rate : 0.016758901454653242 
INFO:root:FL Epoch: 547 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624353
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546225
INFO:root:FL Epoch: 547 Norm Difference for worker 1584 is 0.664261
INFO:root:FL Epoch: 547 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 547 Training on worker :1257
INFO:root:FL Epoch: 547 Using Learning rate : 0.016758901454653242 
INFO:root:FL Epoch: 547 Normal Training
INFO:root:Worker: 1257 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363805
INFO:root:Worker: 1257 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231210
INFO:root:FL Epoch: 547 Norm Difference for worker 1257 is 0.673716
INFO:root:FL Epoch: 547 Done on worker:1257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 547 Training on worker :247
INFO:root:FL Epoch: 547 Using Learning rate : 0.016758901454653242 
INFO:root:FL Epoch: 547 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.312148
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.507876
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 547 Norm Difference for worker 247 is 0.683588
INFO:root:FL Epoch: 547 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 547 Training on worker :1862
INFO:root:FL Epoch: 547 Using Learning rate : 0.016758901454653242 
INFO:root:FL Epoch: 547 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510383
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358121
INFO:root:FL Epoch: 547 Norm Difference for worker 1862 is 0.729348
INFO:root:FL Epoch: 547 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1257
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 547 Ends   ===================
INFO:root:Epoch:547 Global Model Test Loss:0.46969776469118457 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:547 Global Model Backdoor Test Loss:0.12527094905575117                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 548 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 548 Workers Selected : [1637, 1052, 976, 1674, 1323, 573, 1785, 1911, 105, 1649]
INFO:root:FL Epoch: 548 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 548 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 548 Training on worker :1637
INFO:root:FL Epoch: 548 Using Learning rate : 0.016725383651743933 
INFO:root:FL Epoch: 548 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562985
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630443
INFO:root:FL Epoch: 548 Norm Difference for worker 1637 is 0.679133
INFO:root:FL Epoch: 548 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 548 Training on worker :1052
INFO:root:FL Epoch: 548 Using Learning rate : 0.016725383651743933 
INFO:root:FL Epoch: 548 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510124
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367791
INFO:root:FL Epoch: 548 Norm Difference for worker 1052 is 0.724763
INFO:root:FL Epoch: 548 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 548 Training on worker :976
INFO:root:FL Epoch: 548 Using Learning rate : 0.016725383651743933 
INFO:root:FL Epoch: 548 Normal Training
INFO:root:Worker: 976 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586555
INFO:root:Worker: 976 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575589
INFO:root:FL Epoch: 548 Norm Difference for worker 976 is 0.756568
INFO:root:FL Epoch: 548 Done on worker:976
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 548 Training on worker :1674
INFO:root:FL Epoch: 548 Using Learning rate : 0.016725383651743933 
INFO:root:FL Epoch: 548 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495930
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515542
INFO:root:FL Epoch: 548 Norm Difference for worker 1674 is 0.64471
INFO:root:FL Epoch: 548 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 548 Training on worker :1323
INFO:root:FL Epoch: 548 Using Learning rate : 0.016725383651743933 
INFO:root:FL Epoch: 548 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552137
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476496
INFO:root:FL Epoch: 548 Norm Difference for worker 1323 is 0.734202
INFO:root:FL Epoch: 548 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 548 Training on worker :573
INFO:root:FL Epoch: 548 Using Learning rate : 0.016725383651743933 
INFO:root:FL Epoch: 548 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484763
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597077
INFO:root:FL Epoch: 548 Norm Difference for worker 573 is 0.676897
INFO:root:FL Epoch: 548 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 548 Training on worker :1785
INFO:root:FL Epoch: 548 Using Learning rate : 0.016725383651743933 
INFO:root:FL Epoch: 548 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489297
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380029
INFO:root:FL Epoch: 548 Norm Difference for worker 1785 is 0.670822
INFO:root:FL Epoch: 548 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 548 Training on worker :1911
INFO:root:FL Epoch: 548 Using Learning rate : 0.016725383651743933 
INFO:root:FL Epoch: 548 Normal Training
INFO:root:Worker: 1911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.292948
INFO:root:Worker: 1911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457110
INFO:root:FL Epoch: 548 Norm Difference for worker 1911 is 0.683861
INFO:root:FL Epoch: 548 Done on worker:1911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 548 Training on worker :105
INFO:root:FL Epoch: 548 Using Learning rate : 0.016725383651743933 
INFO:root:FL Epoch: 548 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.777247
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.402954
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 548 Norm Difference for worker 105 is 0.768102
INFO:root:FL Epoch: 548 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 548 Training on worker :1649
INFO:root:FL Epoch: 548 Using Learning rate : 0.016725383651743933 
INFO:root:FL Epoch: 548 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372182
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507645
INFO:root:FL Epoch: 548 Norm Difference for worker 1649 is 0.705096
INFO:root:FL Epoch: 548 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1674
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 548 Ends   ===================
INFO:root:Epoch:548 Global Model Test Loss:0.47211349711698647 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:548 Global Model Backdoor Test Loss:0.14791890357931456                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 549 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 549 Workers Selected : [1916, 646, 69, 999, 995, 1098, 338, 1684, 334, 1847]
INFO:root:FL Epoch: 549 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 549 Num points on workers: [200 200 201 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 549 Training on worker :1916
INFO:root:FL Epoch: 549 Using Learning rate : 0.016691932884440448 
INFO:root:FL Epoch: 549 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429701
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299514
INFO:root:FL Epoch: 549 Norm Difference for worker 1916 is 0.671582
INFO:root:FL Epoch: 549 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 549 Training on worker :646
INFO:root:FL Epoch: 549 Using Learning rate : 0.016691932884440448 
INFO:root:FL Epoch: 549 Normal Training
INFO:root:Worker: 646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580845
INFO:root:Worker: 646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537706
INFO:root:FL Epoch: 549 Norm Difference for worker 646 is 0.668229
INFO:root:FL Epoch: 549 Done on worker:646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 549 Training on worker :69
INFO:root:FL Epoch: 549 Using Learning rate : 0.016691932884440448 
INFO:root:FL Epoch: 549 Normal Training
INFO:root:Worker: 69 Train Epoch: 0 [0/201 (0%)]	Loss: 0.561916
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 69 Train Epoch: 1 [0/201 (0%)]	Loss: 0.458763
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 549 Norm Difference for worker 69 is 0.743807
INFO:root:FL Epoch: 549 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 549 Training on worker :999
INFO:root:FL Epoch: 549 Using Learning rate : 0.016691932884440448 
INFO:root:FL Epoch: 549 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492478
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580193
INFO:root:FL Epoch: 549 Norm Difference for worker 999 is 0.654284
INFO:root:FL Epoch: 549 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 549 Training on worker :995
INFO:root:FL Epoch: 549 Using Learning rate : 0.016691932884440448 
INFO:root:FL Epoch: 549 Normal Training
INFO:root:Worker: 995 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572890
INFO:root:Worker: 995 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463292
INFO:root:FL Epoch: 549 Norm Difference for worker 995 is 0.738663
INFO:root:FL Epoch: 549 Done on worker:995
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 549 Training on worker :1098
INFO:root:FL Epoch: 549 Using Learning rate : 0.016691932884440448 
INFO:root:FL Epoch: 549 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668635
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375198
INFO:root:FL Epoch: 549 Norm Difference for worker 1098 is 0.619142
INFO:root:FL Epoch: 549 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 549 Training on worker :338
INFO:root:FL Epoch: 549 Using Learning rate : 0.016691932884440448 
INFO:root:FL Epoch: 549 Normal Training
INFO:root:Worker: 338 Train Epoch: 0 [0/201 (0%)]	Loss: 0.480259
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 338 Train Epoch: 1 [0/201 (0%)]	Loss: 0.372928
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 549 Norm Difference for worker 338 is 0.637206
INFO:root:FL Epoch: 549 Done on worker:338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 549 Training on worker :1684
INFO:root:FL Epoch: 549 Using Learning rate : 0.016691932884440448 
INFO:root:FL Epoch: 549 Normal Training
INFO:root:Worker: 1684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542903
INFO:root:Worker: 1684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389528
INFO:root:FL Epoch: 549 Norm Difference for worker 1684 is 0.696163
INFO:root:FL Epoch: 549 Done on worker:1684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 549 Training on worker :334
INFO:root:FL Epoch: 549 Using Learning rate : 0.016691932884440448 
INFO:root:FL Epoch: 549 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.786630
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.485368
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 549 Norm Difference for worker 334 is 0.675093
INFO:root:FL Epoch: 549 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 549 Training on worker :1847
INFO:root:FL Epoch: 549 Using Learning rate : 0.016691932884440448 
INFO:root:FL Epoch: 549 Normal Training
INFO:root:Worker: 1847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803844
INFO:root:Worker: 1847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674526
INFO:root:FL Epoch: 549 Norm Difference for worker 1847 is 0.662537
INFO:root:FL Epoch: 549 Done on worker:1847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1098
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 549 Ends   ===================
INFO:root:Epoch:549 Global Model Test Loss:0.47685521490433636 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:549 Global Model Backdoor Test Loss:0.11187516773740451                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 550 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 550 Workers Selected : [1040, 598, 1751, 1280, 1514, 131, 1654, 1021, 35, 475]
INFO:root:FL Epoch: 550 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 550 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 550 Training on worker :1040
INFO:root:FL Epoch: 550 Using Learning rate : 0.016658549018671566 
INFO:root:FL Epoch: 550 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568605
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532633
INFO:root:FL Epoch: 550 Norm Difference for worker 1040 is 0.703311
INFO:root:FL Epoch: 550 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 550 Training on worker :598
INFO:root:FL Epoch: 550 Using Learning rate : 0.016658549018671566 
INFO:root:FL Epoch: 550 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.823237
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573129
INFO:root:FL Epoch: 550 Norm Difference for worker 598 is 0.671011
INFO:root:FL Epoch: 550 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 550 Training on worker :1751
INFO:root:FL Epoch: 550 Using Learning rate : 0.016658549018671566 
INFO:root:FL Epoch: 550 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.240204
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304789
INFO:root:FL Epoch: 550 Norm Difference for worker 1751 is 0.673401
INFO:root:FL Epoch: 550 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 550 Training on worker :1280
INFO:root:FL Epoch: 550 Using Learning rate : 0.016658549018671566 
INFO:root:FL Epoch: 550 Normal Training
INFO:root:Worker: 1280 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473982
INFO:root:Worker: 1280 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374513
INFO:root:FL Epoch: 550 Norm Difference for worker 1280 is 0.674946
INFO:root:FL Epoch: 550 Done on worker:1280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 550 Training on worker :1514
INFO:root:FL Epoch: 550 Using Learning rate : 0.016658549018671566 
INFO:root:FL Epoch: 550 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408955
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401382
INFO:root:FL Epoch: 550 Norm Difference for worker 1514 is 0.668478
INFO:root:FL Epoch: 550 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 550 Training on worker :131
INFO:root:FL Epoch: 550 Using Learning rate : 0.016658549018671566 
INFO:root:FL Epoch: 550 Normal Training
INFO:root:Worker: 131 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518183
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 131 Train Epoch: 1 [0/201 (0%)]	Loss: 0.525279
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 550 Norm Difference for worker 131 is 0.721112
INFO:root:FL Epoch: 550 Done on worker:131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 550 Training on worker :1654
INFO:root:FL Epoch: 550 Using Learning rate : 0.016658549018671566 
INFO:root:FL Epoch: 550 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543574
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686655
INFO:root:FL Epoch: 550 Norm Difference for worker 1654 is 0.73768
INFO:root:FL Epoch: 550 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 550 Training on worker :1021
INFO:root:FL Epoch: 550 Using Learning rate : 0.016658549018671566 
INFO:root:FL Epoch: 550 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509751
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391870
INFO:root:FL Epoch: 550 Norm Difference for worker 1021 is 0.667545
INFO:root:FL Epoch: 550 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 550 Training on worker :35
INFO:root:FL Epoch: 550 Using Learning rate : 0.016658549018671566 
INFO:root:FL Epoch: 550 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.483308
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.244575
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 550 Norm Difference for worker 35 is 0.69355
INFO:root:FL Epoch: 550 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 550 Training on worker :475
INFO:root:FL Epoch: 550 Using Learning rate : 0.016658549018671566 
INFO:root:FL Epoch: 550 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704693
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294827
INFO:root:FL Epoch: 550 Norm Difference for worker 475 is 0.61027
INFO:root:FL Epoch: 550 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 475
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 550 Ends   ===================
INFO:root:Epoch:550 Global Model Test Loss:0.48280372689752016 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:550 Global Model Backdoor Test Loss:0.1424901063243548                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 551 Begins ===================
INFO:root:FL Epoch: 551 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 551 Workers Selected : [0, 1, 2, 1925, 712, 218, 1646, 399, 1451, 456]
INFO:root:FL Epoch: 551 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 551 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 551 Training on worker :0
INFO:root:FL Epoch: 551 Using Learning rate : 0.003325046384126844 
INFO:root:FL Epoch: 551 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.230000
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195355
INFO:root:FL Epoch: 551 Worker: 0 Backdoor Test Loss: 0.11864493414759636 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 551 Worker: 0 Backdoor Train Loss: 0.14386600852012635 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 551 Norm Difference for worker 0 is 0.101172
INFO:root:FL Epoch: 551 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 551 Training on worker :1
INFO:root:FL Epoch: 551 Using Learning rate : 0.003325046384126844 
INFO:root:FL Epoch: 551 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.152477
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178573
INFO:root:FL Epoch: 551 Worker: 1 Backdoor Test Loss: 0.11846908802787463 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 551 Worker: 1 Backdoor Train Loss: 0.14460864365100862 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 551 Norm Difference for worker 1 is 0.095247
INFO:root:FL Epoch: 551 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 551 Training on worker :2
INFO:root:FL Epoch: 551 Using Learning rate : 0.003325046384126844 
INFO:root:FL Epoch: 551 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.282757
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207522
INFO:root:FL Epoch: 551 Worker: 2 Backdoor Test Loss: 0.1167501558860143 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 551 Worker: 2 Backdoor Train Loss: 0.14463508501648903 Backdoor Train Accuracy: 97.5
INFO:root:FL Epoch: 551 Norm Difference for worker 2 is 0.097135
INFO:root:FL Epoch: 551 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 551 Training on worker :1925
INFO:root:FL Epoch: 551 Using Learning rate : 0.016625231920634222 
INFO:root:FL Epoch: 551 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.299950
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310206
INFO:root:FL Epoch: 551 Norm Difference for worker 1925 is 0.660573
INFO:root:FL Epoch: 551 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 551 Training on worker :712
INFO:root:FL Epoch: 551 Using Learning rate : 0.016625231920634222 
INFO:root:FL Epoch: 551 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688751
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622410
INFO:root:FL Epoch: 551 Norm Difference for worker 712 is 0.720688
INFO:root:FL Epoch: 551 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 551 Training on worker :218
INFO:root:FL Epoch: 551 Using Learning rate : 0.016625231920634222 
INFO:root:FL Epoch: 551 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.374803
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.456896
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 551 Norm Difference for worker 218 is 0.722887
INFO:root:FL Epoch: 551 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 551 Training on worker :1646
INFO:root:FL Epoch: 551 Using Learning rate : 0.016625231920634222 
INFO:root:FL Epoch: 551 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515082
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448924
INFO:root:FL Epoch: 551 Norm Difference for worker 1646 is 0.812227
INFO:root:FL Epoch: 551 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 551 Training on worker :399
INFO:root:FL Epoch: 551 Using Learning rate : 0.016625231920634222 
INFO:root:FL Epoch: 551 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447076
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478853
INFO:root:FL Epoch: 551 Norm Difference for worker 399 is 0.705733
INFO:root:FL Epoch: 551 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 551 Training on worker :1451
INFO:root:FL Epoch: 551 Using Learning rate : 0.016625231920634222 
INFO:root:FL Epoch: 551 Normal Training
INFO:root:Worker: 1451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475939
INFO:root:Worker: 1451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461677
INFO:root:FL Epoch: 551 Norm Difference for worker 1451 is 0.670072
INFO:root:FL Epoch: 551 Done on worker:1451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 551 Training on worker :456
INFO:root:FL Epoch: 551 Using Learning rate : 0.016625231920634222 
INFO:root:FL Epoch: 551 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469718
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319286
INFO:root:FL Epoch: 551 Norm Difference for worker 456 is 0.653314
INFO:root:FL Epoch: 551 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 551 Ends   ===================
INFO:root:Epoch:551 Global Model Test Loss:0.48296802534776573 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:551 Global Model Backdoor Test Loss:0.11846908802787463                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 552 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 552 Workers Selected : [588, 721, 1883, 1861, 358, 1909, 374, 1674, 1237, 72]
INFO:root:FL Epoch: 552 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 552 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 552 Training on worker :588
INFO:root:FL Epoch: 552 Using Learning rate : 0.016591981456792953 
INFO:root:FL Epoch: 552 Normal Training
INFO:root:Worker: 588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542208
INFO:root:Worker: 588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386437
INFO:root:FL Epoch: 552 Norm Difference for worker 588 is 0.814147
INFO:root:FL Epoch: 552 Done on worker:588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 552 Training on worker :721
INFO:root:FL Epoch: 552 Using Learning rate : 0.016591981456792953 
INFO:root:FL Epoch: 552 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.878846
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451643
INFO:root:FL Epoch: 552 Norm Difference for worker 721 is 0.744785
INFO:root:FL Epoch: 552 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 552 Training on worker :1883
INFO:root:FL Epoch: 552 Using Learning rate : 0.016591981456792953 
INFO:root:FL Epoch: 552 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659191
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506156
INFO:root:FL Epoch: 552 Norm Difference for worker 1883 is 0.715652
INFO:root:FL Epoch: 552 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 552 Training on worker :1861
INFO:root:FL Epoch: 552 Using Learning rate : 0.016591981456792953 
INFO:root:FL Epoch: 552 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513306
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491412
INFO:root:FL Epoch: 552 Norm Difference for worker 1861 is 0.745987
INFO:root:FL Epoch: 552 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 552 Training on worker :358
INFO:root:FL Epoch: 552 Using Learning rate : 0.016591981456792953 
INFO:root:FL Epoch: 552 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469391
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410140
INFO:root:FL Epoch: 552 Norm Difference for worker 358 is 0.731405
INFO:root:FL Epoch: 552 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 552 Training on worker :1909
INFO:root:FL Epoch: 552 Using Learning rate : 0.016591981456792953 
INFO:root:FL Epoch: 552 Normal Training
INFO:root:Worker: 1909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.228157
INFO:root:Worker: 1909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306408
INFO:root:FL Epoch: 552 Norm Difference for worker 1909 is 0.750802
INFO:root:FL Epoch: 552 Done on worker:1909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 552 Training on worker :374
INFO:root:FL Epoch: 552 Using Learning rate : 0.016591981456792953 
INFO:root:FL Epoch: 552 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393279
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387120
INFO:root:FL Epoch: 552 Norm Difference for worker 374 is 0.70263
INFO:root:FL Epoch: 552 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 552 Training on worker :1674
INFO:root:FL Epoch: 552 Using Learning rate : 0.016591981456792953 
INFO:root:FL Epoch: 552 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463698
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272372
INFO:root:FL Epoch: 552 Norm Difference for worker 1674 is 0.568967
INFO:root:FL Epoch: 552 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 552 Training on worker :1237
INFO:root:FL Epoch: 552 Using Learning rate : 0.016591981456792953 
INFO:root:FL Epoch: 552 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516602
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347265
INFO:root:FL Epoch: 552 Norm Difference for worker 1237 is 0.812932
INFO:root:FL Epoch: 552 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 552 Training on worker :72
INFO:root:FL Epoch: 552 Using Learning rate : 0.016591981456792953 
INFO:root:FL Epoch: 552 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.605864
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.265453
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 552 Norm Difference for worker 72 is 0.684528
INFO:root:FL Epoch: 552 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1674
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 552 Ends   ===================
INFO:root:Epoch:552 Global Model Test Loss:0.4853823640767266 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:552 Global Model Backdoor Test Loss:0.09770876914262772                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 553 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 553 Workers Selected : [1237, 882, 946, 571, 1547, 1187, 1344, 1663, 105, 1843]
INFO:root:FL Epoch: 553 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 553 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 553 Training on worker :1237
INFO:root:FL Epoch: 553 Using Learning rate : 0.016558797493879368 
INFO:root:FL Epoch: 553 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679455
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377691
INFO:root:FL Epoch: 553 Norm Difference for worker 1237 is 0.899293
INFO:root:FL Epoch: 553 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 553 Training on worker :882
INFO:root:FL Epoch: 553 Using Learning rate : 0.016558797493879368 
INFO:root:FL Epoch: 553 Normal Training
INFO:root:Worker: 882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749718
INFO:root:Worker: 882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550124
INFO:root:FL Epoch: 553 Norm Difference for worker 882 is 0.703343
INFO:root:FL Epoch: 553 Done on worker:882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 553 Training on worker :946
INFO:root:FL Epoch: 553 Using Learning rate : 0.016558797493879368 
INFO:root:FL Epoch: 553 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589635
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530854
INFO:root:FL Epoch: 553 Norm Difference for worker 946 is 0.87657
INFO:root:FL Epoch: 553 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 553 Training on worker :571
INFO:root:FL Epoch: 553 Using Learning rate : 0.016558797493879368 
INFO:root:FL Epoch: 553 Normal Training
INFO:root:Worker: 571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.221682
INFO:root:Worker: 571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623718
INFO:root:FL Epoch: 553 Norm Difference for worker 571 is 0.800682
INFO:root:FL Epoch: 553 Done on worker:571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 553 Training on worker :1547
INFO:root:FL Epoch: 553 Using Learning rate : 0.016558797493879368 
INFO:root:FL Epoch: 553 Normal Training
INFO:root:Worker: 1547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457472
INFO:root:Worker: 1547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.161148
INFO:root:FL Epoch: 553 Norm Difference for worker 1547 is 0.811471
INFO:root:FL Epoch: 553 Done on worker:1547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 553 Training on worker :1187
INFO:root:FL Epoch: 553 Using Learning rate : 0.016558797493879368 
INFO:root:FL Epoch: 553 Normal Training
INFO:root:Worker: 1187 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526179
INFO:root:Worker: 1187 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244473
INFO:root:FL Epoch: 553 Norm Difference for worker 1187 is 0.679393
INFO:root:FL Epoch: 553 Done on worker:1187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 553 Training on worker :1344
INFO:root:FL Epoch: 553 Using Learning rate : 0.016558797493879368 
INFO:root:FL Epoch: 553 Normal Training
INFO:root:Worker: 1344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495480
INFO:root:Worker: 1344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665780
INFO:root:FL Epoch: 553 Norm Difference for worker 1344 is 0.84262
INFO:root:FL Epoch: 553 Done on worker:1344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 553 Training on worker :1663
INFO:root:FL Epoch: 553 Using Learning rate : 0.016558797493879368 
INFO:root:FL Epoch: 553 Normal Training
INFO:root:Worker: 1663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309184
INFO:root:Worker: 1663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582488
INFO:root:FL Epoch: 553 Norm Difference for worker 1663 is 0.781454
INFO:root:FL Epoch: 553 Done on worker:1663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 553 Training on worker :105
INFO:root:FL Epoch: 553 Using Learning rate : 0.016558797493879368 
INFO:root:FL Epoch: 553 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.665774
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.475268
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 553 Norm Difference for worker 105 is 0.888748
INFO:root:FL Epoch: 553 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 553 Training on worker :1843
INFO:root:FL Epoch: 553 Using Learning rate : 0.016558797493879368 
INFO:root:FL Epoch: 553 Normal Training
INFO:root:Worker: 1843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430667
INFO:root:Worker: 1843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364660
INFO:root:FL Epoch: 553 Norm Difference for worker 1843 is 0.723028
INFO:root:FL Epoch: 553 Done on worker:1843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 882
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 553 Ends   ===================
INFO:root:Epoch:553 Global Model Test Loss:0.4840709742377786 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:553 Global Model Backdoor Test Loss:0.10588028033574422                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 554 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 554 Workers Selected : [660, 1494, 1242, 1335, 1418, 184, 1837, 178, 10, 14]
INFO:root:FL Epoch: 554 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004
 0.1002994 0.1002994 0.1002994]
INFO:root:FL Epoch: 554 Num points on workers: [200 200 200 200 200 201 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 554 Training on worker :660
INFO:root:FL Epoch: 554 Using Learning rate : 0.01652567989889161 
INFO:root:FL Epoch: 554 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477972
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389035
INFO:root:FL Epoch: 554 Norm Difference for worker 660 is 0.736401
INFO:root:FL Epoch: 554 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 554 Training on worker :1494
INFO:root:FL Epoch: 554 Using Learning rate : 0.01652567989889161 
INFO:root:FL Epoch: 554 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697660
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277525
INFO:root:FL Epoch: 554 Norm Difference for worker 1494 is 0.698834
INFO:root:FL Epoch: 554 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 554 Training on worker :1242
INFO:root:FL Epoch: 554 Using Learning rate : 0.01652567989889161 
INFO:root:FL Epoch: 554 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422064
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498648
INFO:root:FL Epoch: 554 Norm Difference for worker 1242 is 0.781064
INFO:root:FL Epoch: 554 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 554 Training on worker :1335
INFO:root:FL Epoch: 554 Using Learning rate : 0.01652567989889161 
INFO:root:FL Epoch: 554 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493199
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379232
INFO:root:FL Epoch: 554 Norm Difference for worker 1335 is 0.707599
INFO:root:FL Epoch: 554 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 554 Training on worker :1418
INFO:root:FL Epoch: 554 Using Learning rate : 0.01652567989889161 
INFO:root:FL Epoch: 554 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464122
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.843709
INFO:root:FL Epoch: 554 Norm Difference for worker 1418 is 0.778786
INFO:root:FL Epoch: 554 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 554 Training on worker :184
INFO:root:FL Epoch: 554 Using Learning rate : 0.01652567989889161 
INFO:root:FL Epoch: 554 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.433450
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428779
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 554 Norm Difference for worker 184 is 0.665375
INFO:root:FL Epoch: 554 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 554 Training on worker :1837
INFO:root:FL Epoch: 554 Using Learning rate : 0.01652567989889161 
INFO:root:FL Epoch: 554 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572106
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308276
INFO:root:FL Epoch: 554 Norm Difference for worker 1837 is 0.755877
INFO:root:FL Epoch: 554 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 554 Training on worker :178
INFO:root:FL Epoch: 554 Using Learning rate : 0.01652567989889161 
INFO:root:FL Epoch: 554 Normal Training
INFO:root:Worker: 178 Train Epoch: 0 [0/201 (0%)]	Loss: 0.515036
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 178 Train Epoch: 1 [0/201 (0%)]	Loss: 0.397184
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 554 Norm Difference for worker 178 is 0.715774
INFO:root:FL Epoch: 554 Done on worker:178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 554 Training on worker :10
INFO:root:FL Epoch: 554 Using Learning rate : 0.01652567989889161 
INFO:root:FL Epoch: 554 Normal Training
INFO:root:Worker: 10 Train Epoch: 0 [0/201 (0%)]	Loss: 0.583908
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 10 Train Epoch: 1 [0/201 (0%)]	Loss: 0.540512
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 554 Norm Difference for worker 10 is 0.740073
INFO:root:FL Epoch: 554 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 554 Training on worker :14
INFO:root:FL Epoch: 554 Using Learning rate : 0.01652567989889161 
INFO:root:FL Epoch: 554 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.633341
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.323801
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 554 Norm Difference for worker 14 is 0.740766
INFO:root:FL Epoch: 554 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 184
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 554 Ends   ===================
INFO:root:Epoch:554 Global Model Test Loss:0.4853484297499937 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:554 Global Model Backdoor Test Loss:0.10010131696859996                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 555 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 555 Workers Selected : [196, 1723, 1727, 1583, 929, 174, 1542, 1680, 696, 659]
INFO:root:FL Epoch: 555 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 555 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 555 Training on worker :196
INFO:root:FL Epoch: 555 Using Learning rate : 0.016492628539093827 
INFO:root:FL Epoch: 555 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.554242
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431706
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 555 Norm Difference for worker 196 is 0.726479
INFO:root:FL Epoch: 555 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 555 Training on worker :1723
INFO:root:FL Epoch: 555 Using Learning rate : 0.016492628539093827 
INFO:root:FL Epoch: 555 Normal Training
INFO:root:Worker: 1723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652056
INFO:root:Worker: 1723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516803
INFO:root:FL Epoch: 555 Norm Difference for worker 1723 is 0.774629
INFO:root:FL Epoch: 555 Done on worker:1723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 555 Training on worker :1727
INFO:root:FL Epoch: 555 Using Learning rate : 0.016492628539093827 
INFO:root:FL Epoch: 555 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461418
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.727397
INFO:root:FL Epoch: 555 Norm Difference for worker 1727 is 0.762101
INFO:root:FL Epoch: 555 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 555 Training on worker :1583
INFO:root:FL Epoch: 555 Using Learning rate : 0.016492628539093827 
INFO:root:FL Epoch: 555 Normal Training
INFO:root:Worker: 1583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436866
INFO:root:Worker: 1583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603268
INFO:root:FL Epoch: 555 Norm Difference for worker 1583 is 0.739757
INFO:root:FL Epoch: 555 Done on worker:1583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 555 Training on worker :929
INFO:root:FL Epoch: 555 Using Learning rate : 0.016492628539093827 
INFO:root:FL Epoch: 555 Normal Training
INFO:root:Worker: 929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434193
INFO:root:Worker: 929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501638
INFO:root:FL Epoch: 555 Norm Difference for worker 929 is 0.726841
INFO:root:FL Epoch: 555 Done on worker:929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 555 Training on worker :174
INFO:root:FL Epoch: 555 Using Learning rate : 0.016492628539093827 
INFO:root:FL Epoch: 555 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603453
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.441349
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 555 Norm Difference for worker 174 is 0.720227
INFO:root:FL Epoch: 555 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 555 Training on worker :1542
INFO:root:FL Epoch: 555 Using Learning rate : 0.016492628539093827 
INFO:root:FL Epoch: 555 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596066
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549325
INFO:root:FL Epoch: 555 Norm Difference for worker 1542 is 0.793621
INFO:root:FL Epoch: 555 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 555 Training on worker :1680
INFO:root:FL Epoch: 555 Using Learning rate : 0.016492628539093827 
INFO:root:FL Epoch: 555 Normal Training
INFO:root:Worker: 1680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741315
INFO:root:Worker: 1680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523660
INFO:root:FL Epoch: 555 Norm Difference for worker 1680 is 0.723512
INFO:root:FL Epoch: 555 Done on worker:1680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 555 Training on worker :696
INFO:root:FL Epoch: 555 Using Learning rate : 0.016492628539093827 
INFO:root:FL Epoch: 555 Normal Training
INFO:root:Worker: 696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.832639
INFO:root:Worker: 696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329787
INFO:root:FL Epoch: 555 Norm Difference for worker 696 is 0.768613
INFO:root:FL Epoch: 555 Done on worker:696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 555 Training on worker :659
INFO:root:FL Epoch: 555 Using Learning rate : 0.016492628539093827 
INFO:root:FL Epoch: 555 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551895
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371151
INFO:root:FL Epoch: 555 Norm Difference for worker 659 is 0.738628
INFO:root:FL Epoch: 555 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1583
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 555 Ends   ===================
INFO:root:Epoch:555 Global Model Test Loss:0.5056820178733152 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:555 Global Model Backdoor Test Loss:0.20189214994510016                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 556 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 556 Workers Selected : [65, 648, 1515, 64, 1041, 823, 1336, 1648, 1233, 54]
INFO:root:FL Epoch: 556 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 556 Num points on workers: [201 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 556 Training on worker :65
INFO:root:FL Epoch: 556 Using Learning rate : 0.01645964328201564 
INFO:root:FL Epoch: 556 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.386444
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.383799
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 556 Norm Difference for worker 65 is 0.596525
INFO:root:FL Epoch: 556 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 556 Training on worker :648
INFO:root:FL Epoch: 556 Using Learning rate : 0.01645964328201564 
INFO:root:FL Epoch: 556 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565124
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428839
INFO:root:FL Epoch: 556 Norm Difference for worker 648 is 0.648965
INFO:root:FL Epoch: 556 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 556 Training on worker :1515
INFO:root:FL Epoch: 556 Using Learning rate : 0.01645964328201564 
INFO:root:FL Epoch: 556 Normal Training
INFO:root:Worker: 1515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398477
INFO:root:Worker: 1515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481004
INFO:root:FL Epoch: 556 Norm Difference for worker 1515 is 0.630627
INFO:root:FL Epoch: 556 Done on worker:1515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 556 Training on worker :64
INFO:root:FL Epoch: 556 Using Learning rate : 0.01645964328201564 
INFO:root:FL Epoch: 556 Normal Training
INFO:root:Worker: 64 Train Epoch: 0 [0/201 (0%)]	Loss: 0.715084
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 64 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419426
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 556 Norm Difference for worker 64 is 0.657818
INFO:root:FL Epoch: 556 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 556 Training on worker :1041
INFO:root:FL Epoch: 556 Using Learning rate : 0.01645964328201564 
INFO:root:FL Epoch: 556 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583826
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386268
INFO:root:FL Epoch: 556 Norm Difference for worker 1041 is 0.657988
INFO:root:FL Epoch: 556 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 556 Training on worker :823
INFO:root:FL Epoch: 556 Using Learning rate : 0.01645964328201564 
INFO:root:FL Epoch: 556 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421175
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.807466
INFO:root:FL Epoch: 556 Norm Difference for worker 823 is 0.726802
INFO:root:FL Epoch: 556 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 556 Training on worker :1336
INFO:root:FL Epoch: 556 Using Learning rate : 0.01645964328201564 
INFO:root:FL Epoch: 556 Normal Training
INFO:root:Worker: 1336 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383523
INFO:root:Worker: 1336 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376672
INFO:root:FL Epoch: 556 Norm Difference for worker 1336 is 0.69449
INFO:root:FL Epoch: 556 Done on worker:1336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 556 Training on worker :1648
INFO:root:FL Epoch: 556 Using Learning rate : 0.01645964328201564 
INFO:root:FL Epoch: 556 Normal Training
INFO:root:Worker: 1648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477716
INFO:root:Worker: 1648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297300
INFO:root:FL Epoch: 556 Norm Difference for worker 1648 is 0.641956
INFO:root:FL Epoch: 556 Done on worker:1648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 556 Training on worker :1233
INFO:root:FL Epoch: 556 Using Learning rate : 0.01645964328201564 
INFO:root:FL Epoch: 556 Normal Training
INFO:root:Worker: 1233 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349134
INFO:root:Worker: 1233 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508528
INFO:root:FL Epoch: 556 Norm Difference for worker 1233 is 0.692895
INFO:root:FL Epoch: 556 Done on worker:1233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 556 Training on worker :54
INFO:root:FL Epoch: 556 Using Learning rate : 0.01645964328201564 
INFO:root:FL Epoch: 556 Normal Training
INFO:root:Worker: 54 Train Epoch: 0 [0/201 (0%)]	Loss: 0.786458
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 54 Train Epoch: 1 [0/201 (0%)]	Loss: 0.541802
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 556 Norm Difference for worker 54 is 0.686291
INFO:root:FL Epoch: 556 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 65
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 556 Ends   ===================
INFO:root:Epoch:556 Global Model Test Loss:0.4973307234399459 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:556 Global Model Backdoor Test Loss:0.18291427691777548                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 557 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 557 Workers Selected : [1333, 1745, 1844, 1776, 288, 308, 1198, 441, 1571, 614]
INFO:root:FL Epoch: 557 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 557 Num points on workers: [200 200 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 557 Training on worker :1333
INFO:root:FL Epoch: 557 Using Learning rate : 0.016426723995451607 
INFO:root:FL Epoch: 557 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565213
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413644
INFO:root:FL Epoch: 557 Norm Difference for worker 1333 is 0.606022
INFO:root:FL Epoch: 557 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 557 Training on worker :1745
INFO:root:FL Epoch: 557 Using Learning rate : 0.016426723995451607 
INFO:root:FL Epoch: 557 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489091
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592387
INFO:root:FL Epoch: 557 Norm Difference for worker 1745 is 0.594981
INFO:root:FL Epoch: 557 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 557 Training on worker :1844
INFO:root:FL Epoch: 557 Using Learning rate : 0.016426723995451607 
INFO:root:FL Epoch: 557 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526067
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345033
INFO:root:FL Epoch: 557 Norm Difference for worker 1844 is 0.581023
INFO:root:FL Epoch: 557 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 557 Training on worker :1776
INFO:root:FL Epoch: 557 Using Learning rate : 0.016426723995451607 
INFO:root:FL Epoch: 557 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758470
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509259
INFO:root:FL Epoch: 557 Norm Difference for worker 1776 is 0.560329
INFO:root:FL Epoch: 557 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 557 Training on worker :288
INFO:root:FL Epoch: 557 Using Learning rate : 0.016426723995451607 
INFO:root:FL Epoch: 557 Normal Training
INFO:root:Worker: 288 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603746
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 288 Train Epoch: 1 [0/201 (0%)]	Loss: 0.416726
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 557 Norm Difference for worker 288 is 0.598175
INFO:root:FL Epoch: 557 Done on worker:288
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 557 Training on worker :308
INFO:root:FL Epoch: 557 Using Learning rate : 0.016426723995451607 
INFO:root:FL Epoch: 557 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.425645
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.362061
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 557 Norm Difference for worker 308 is 0.566319
INFO:root:FL Epoch: 557 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 557 Training on worker :1198
INFO:root:FL Epoch: 557 Using Learning rate : 0.016426723995451607 
INFO:root:FL Epoch: 557 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368765
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409034
INFO:root:FL Epoch: 557 Norm Difference for worker 1198 is 0.590036
INFO:root:FL Epoch: 557 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 557 Training on worker :441
INFO:root:FL Epoch: 557 Using Learning rate : 0.016426723995451607 
INFO:root:FL Epoch: 557 Normal Training
INFO:root:Worker: 441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597861
INFO:root:Worker: 441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475496
INFO:root:FL Epoch: 557 Norm Difference for worker 441 is 0.664078
INFO:root:FL Epoch: 557 Done on worker:441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 557 Training on worker :1571
INFO:root:FL Epoch: 557 Using Learning rate : 0.016426723995451607 
INFO:root:FL Epoch: 557 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381798
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421150
INFO:root:FL Epoch: 557 Norm Difference for worker 1571 is 0.614789
INFO:root:FL Epoch: 557 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 557 Training on worker :614
INFO:root:FL Epoch: 557 Using Learning rate : 0.016426723995451607 
INFO:root:FL Epoch: 557 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578236
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516325
INFO:root:FL Epoch: 557 Norm Difference for worker 614 is 0.602543
INFO:root:FL Epoch: 557 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1776
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 557 Ends   ===================
INFO:root:Epoch:557 Global Model Test Loss:0.4921874719507554 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:557 Global Model Backdoor Test Loss:0.16488698621590933                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 558 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 558 Workers Selected : [1581, 104, 380, 887, 392, 1518, 120, 905, 1181, 65]
INFO:root:FL Epoch: 558 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 558 Num points on workers: [200 201 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 558 Training on worker :1581
INFO:root:FL Epoch: 558 Using Learning rate : 0.016393870547460703 
INFO:root:FL Epoch: 558 Normal Training
INFO:root:Worker: 1581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589606
INFO:root:Worker: 1581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474949
INFO:root:FL Epoch: 558 Norm Difference for worker 1581 is 0.682454
INFO:root:FL Epoch: 558 Done on worker:1581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 558 Training on worker :104
INFO:root:FL Epoch: 558 Using Learning rate : 0.016393870547460703 
INFO:root:FL Epoch: 558 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.574775
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.514137
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 558 Norm Difference for worker 104 is 0.616919
INFO:root:FL Epoch: 558 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 558 Training on worker :380
INFO:root:FL Epoch: 558 Using Learning rate : 0.016393870547460703 
INFO:root:FL Epoch: 558 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772245
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.783538
INFO:root:FL Epoch: 558 Norm Difference for worker 380 is 0.639656
INFO:root:FL Epoch: 558 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 558 Training on worker :887
INFO:root:FL Epoch: 558 Using Learning rate : 0.016393870547460703 
INFO:root:FL Epoch: 558 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487811
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649584
INFO:root:FL Epoch: 558 Norm Difference for worker 887 is 0.654283
INFO:root:FL Epoch: 558 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 558 Training on worker :392
INFO:root:FL Epoch: 558 Using Learning rate : 0.016393870547460703 
INFO:root:FL Epoch: 558 Normal Training
INFO:root:Worker: 392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496995
INFO:root:Worker: 392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582796
INFO:root:FL Epoch: 558 Norm Difference for worker 392 is 0.641096
INFO:root:FL Epoch: 558 Done on worker:392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 558 Training on worker :1518
INFO:root:FL Epoch: 558 Using Learning rate : 0.016393870547460703 
INFO:root:FL Epoch: 558 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404377
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312279
INFO:root:FL Epoch: 558 Norm Difference for worker 1518 is 0.622736
INFO:root:FL Epoch: 558 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 558 Training on worker :120
INFO:root:FL Epoch: 558 Using Learning rate : 0.016393870547460703 
INFO:root:FL Epoch: 558 Normal Training
INFO:root:Worker: 120 Train Epoch: 0 [0/201 (0%)]	Loss: 0.545734
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 120 Train Epoch: 1 [0/201 (0%)]	Loss: 0.493862
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 558 Norm Difference for worker 120 is 0.615954
INFO:root:FL Epoch: 558 Done on worker:120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 558 Training on worker :905
INFO:root:FL Epoch: 558 Using Learning rate : 0.016393870547460703 
INFO:root:FL Epoch: 558 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748766
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502643
INFO:root:FL Epoch: 558 Norm Difference for worker 905 is 0.644773
INFO:root:FL Epoch: 558 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 558 Training on worker :1181
INFO:root:FL Epoch: 558 Using Learning rate : 0.016393870547460703 
INFO:root:FL Epoch: 558 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548822
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285503
INFO:root:FL Epoch: 558 Norm Difference for worker 1181 is 0.581564
INFO:root:FL Epoch: 558 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 558 Training on worker :65
INFO:root:FL Epoch: 558 Using Learning rate : 0.016393870547460703 
INFO:root:FL Epoch: 558 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.534043
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.291834
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 558 Norm Difference for worker 65 is 0.52144
INFO:root:FL Epoch: 558 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 65
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 558 Ends   ===================
INFO:root:Epoch:558 Global Model Test Loss:0.5035944861524245 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:558 Global Model Backdoor Test Loss:0.1782650239765644                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 559 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 559 Workers Selected : [676, 755, 955, 1854, 1219, 281, 1836, 832, 953, 1498]
INFO:root:FL Epoch: 559 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 559 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 559 Training on worker :676
INFO:root:FL Epoch: 559 Using Learning rate : 0.016361082806365782 
INFO:root:FL Epoch: 559 Normal Training
INFO:root:Worker: 676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503169
INFO:root:Worker: 676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407920
INFO:root:FL Epoch: 559 Norm Difference for worker 676 is 0.727331
INFO:root:FL Epoch: 559 Done on worker:676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 559 Training on worker :755
INFO:root:FL Epoch: 559 Using Learning rate : 0.016361082806365782 
INFO:root:FL Epoch: 559 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442125
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520241
INFO:root:FL Epoch: 559 Norm Difference for worker 755 is 0.732491
INFO:root:FL Epoch: 559 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 559 Training on worker :955
INFO:root:FL Epoch: 559 Using Learning rate : 0.016361082806365782 
INFO:root:FL Epoch: 559 Normal Training
INFO:root:Worker: 955 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403871
INFO:root:Worker: 955 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563393
INFO:root:FL Epoch: 559 Norm Difference for worker 955 is 0.680517
INFO:root:FL Epoch: 559 Done on worker:955
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 559 Training on worker :1854
INFO:root:FL Epoch: 559 Using Learning rate : 0.016361082806365782 
INFO:root:FL Epoch: 559 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576376
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491214
INFO:root:FL Epoch: 559 Norm Difference for worker 1854 is 0.723833
INFO:root:FL Epoch: 559 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 559 Training on worker :1219
INFO:root:FL Epoch: 559 Using Learning rate : 0.016361082806365782 
INFO:root:FL Epoch: 559 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466787
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370351
INFO:root:FL Epoch: 559 Norm Difference for worker 1219 is 0.696404
INFO:root:FL Epoch: 559 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 559 Training on worker :281
INFO:root:FL Epoch: 559 Using Learning rate : 0.016361082806365782 
INFO:root:FL Epoch: 559 Normal Training
INFO:root:Worker: 281 Train Epoch: 0 [0/201 (0%)]	Loss: 0.329178
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 281 Train Epoch: 1 [0/201 (0%)]	Loss: 0.245043
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 559 Norm Difference for worker 281 is 0.590048
INFO:root:FL Epoch: 559 Done on worker:281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 559 Training on worker :1836
INFO:root:FL Epoch: 559 Using Learning rate : 0.016361082806365782 
INFO:root:FL Epoch: 559 Normal Training
INFO:root:Worker: 1836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736773
INFO:root:Worker: 1836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410132
INFO:root:FL Epoch: 559 Norm Difference for worker 1836 is 0.699721
INFO:root:FL Epoch: 559 Done on worker:1836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 559 Training on worker :832
INFO:root:FL Epoch: 559 Using Learning rate : 0.016361082806365782 
INFO:root:FL Epoch: 559 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.947221
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564635
INFO:root:FL Epoch: 559 Norm Difference for worker 832 is 0.706447
INFO:root:FL Epoch: 559 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 559 Training on worker :953
INFO:root:FL Epoch: 559 Using Learning rate : 0.016361082806365782 
INFO:root:FL Epoch: 559 Normal Training
INFO:root:Worker: 953 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486162
INFO:root:Worker: 953 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442411
INFO:root:FL Epoch: 559 Norm Difference for worker 953 is 0.645815
INFO:root:FL Epoch: 559 Done on worker:953
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 559 Training on worker :1498
INFO:root:FL Epoch: 559 Using Learning rate : 0.016361082806365782 
INFO:root:FL Epoch: 559 Normal Training
INFO:root:Worker: 1498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514890
INFO:root:Worker: 1498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473709
INFO:root:FL Epoch: 559 Norm Difference for worker 1498 is 0.688581
INFO:root:FL Epoch: 559 Done on worker:1498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 281
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 559 Ends   ===================
INFO:root:Epoch:559 Global Model Test Loss:0.49337655305862427 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:559 Global Model Backdoor Test Loss:0.12491547813018163                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 560 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 560 Workers Selected : [752, 1335, 1381, 1057, 813, 767, 214, 100, 80, 1821]
INFO:root:FL Epoch: 560 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 560 Num points on workers: [200 200 200 200 200 200 201 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 560 Training on worker :752
INFO:root:FL Epoch: 560 Using Learning rate : 0.01632836064075305 
INFO:root:FL Epoch: 560 Normal Training
INFO:root:Worker: 752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588717
INFO:root:Worker: 752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341686
INFO:root:FL Epoch: 560 Norm Difference for worker 752 is 0.72982
INFO:root:FL Epoch: 560 Done on worker:752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 560 Training on worker :1335
INFO:root:FL Epoch: 560 Using Learning rate : 0.01632836064075305 
INFO:root:FL Epoch: 560 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571422
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519474
INFO:root:FL Epoch: 560 Norm Difference for worker 1335 is 0.68123
INFO:root:FL Epoch: 560 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 560 Training on worker :1381
INFO:root:FL Epoch: 560 Using Learning rate : 0.01632836064075305 
INFO:root:FL Epoch: 560 Normal Training
INFO:root:Worker: 1381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339672
INFO:root:Worker: 1381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665119
INFO:root:FL Epoch: 560 Norm Difference for worker 1381 is 0.717847
INFO:root:FL Epoch: 560 Done on worker:1381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 560 Training on worker :1057
INFO:root:FL Epoch: 560 Using Learning rate : 0.01632836064075305 
INFO:root:FL Epoch: 560 Normal Training
INFO:root:Worker: 1057 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580238
INFO:root:Worker: 1057 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604419
INFO:root:FL Epoch: 560 Norm Difference for worker 1057 is 0.718289
INFO:root:FL Epoch: 560 Done on worker:1057
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 560 Training on worker :813
INFO:root:FL Epoch: 560 Using Learning rate : 0.01632836064075305 
INFO:root:FL Epoch: 560 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484619
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496562
INFO:root:FL Epoch: 560 Norm Difference for worker 813 is 0.729348
INFO:root:FL Epoch: 560 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 560 Training on worker :767
INFO:root:FL Epoch: 560 Using Learning rate : 0.01632836064075305 
INFO:root:FL Epoch: 560 Normal Training
INFO:root:Worker: 767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468081
INFO:root:Worker: 767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446041
INFO:root:FL Epoch: 560 Norm Difference for worker 767 is 0.738099
INFO:root:FL Epoch: 560 Done on worker:767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 560 Training on worker :214
INFO:root:FL Epoch: 560 Using Learning rate : 0.01632836064075305 
INFO:root:FL Epoch: 560 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.349251
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.581802
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 560 Norm Difference for worker 214 is 0.699482
INFO:root:FL Epoch: 560 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 560 Training on worker :100
INFO:root:FL Epoch: 560 Using Learning rate : 0.01632836064075305 
INFO:root:FL Epoch: 560 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.556386
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.310619
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 560 Norm Difference for worker 100 is 0.646204
INFO:root:FL Epoch: 560 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 560 Training on worker :80
INFO:root:FL Epoch: 560 Using Learning rate : 0.01632836064075305 
INFO:root:FL Epoch: 560 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.301265
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.371200
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 560 Norm Difference for worker 80 is 0.606734
INFO:root:FL Epoch: 560 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 560 Training on worker :1821
INFO:root:FL Epoch: 560 Using Learning rate : 0.01632836064075305 
INFO:root:FL Epoch: 560 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651069
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471228
INFO:root:FL Epoch: 560 Norm Difference for worker 1821 is 0.657488
INFO:root:FL Epoch: 560 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 80
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 560 Ends   ===================
INFO:root:Epoch:560 Global Model Test Loss:0.4958336072809556 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:560 Global Model Backdoor Test Loss:0.1509471908211708                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 561 Begins ===================
INFO:root:FL Epoch: 561 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 561 Workers Selected : [0, 1, 2, 1618, 643, 1710, 966, 640, 1848, 1504]
INFO:root:FL Epoch: 561 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 561 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 561 Training on worker :0
INFO:root:FL Epoch: 561 Using Learning rate : 0.0032591407838943086 
INFO:root:FL Epoch: 561 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.273477
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.111431
INFO:root:FL Epoch: 561 Worker: 0 Backdoor Test Loss: 0.12464383741219838 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 561 Worker: 0 Backdoor Train Loss: 0.13898967057466508 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 561 Norm Difference for worker 0 is 0.09267
INFO:root:FL Epoch: 561 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 561 Training on worker :1
INFO:root:FL Epoch: 561 Using Learning rate : 0.0032591407838943086 
INFO:root:FL Epoch: 561 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.100167
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.164336
INFO:root:FL Epoch: 561 Worker: 1 Backdoor Test Loss: 0.1268523521721363 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 561 Worker: 1 Backdoor Train Loss: 0.13812604397535325 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 561 Norm Difference for worker 1 is 0.0935
INFO:root:FL Epoch: 561 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 561 Training on worker :2
INFO:root:FL Epoch: 561 Using Learning rate : 0.0032591407838943086 
INFO:root:FL Epoch: 561 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.118442
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.107858
INFO:root:FL Epoch: 561 Worker: 2 Backdoor Test Loss: 0.12313423678278923 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 561 Worker: 2 Backdoor Train Loss: 0.13820116817951203 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 561 Norm Difference for worker 2 is 0.093825
INFO:root:FL Epoch: 561 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 561 Training on worker :1618
INFO:root:FL Epoch: 561 Using Learning rate : 0.016295703919471546 
INFO:root:FL Epoch: 561 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392310
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441971
INFO:root:FL Epoch: 561 Norm Difference for worker 1618 is 0.735717
INFO:root:FL Epoch: 561 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 561 Training on worker :643
INFO:root:FL Epoch: 561 Using Learning rate : 0.016295703919471546 
INFO:root:FL Epoch: 561 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575245
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453056
INFO:root:FL Epoch: 561 Norm Difference for worker 643 is 0.813114
INFO:root:FL Epoch: 561 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 561 Training on worker :1710
INFO:root:FL Epoch: 561 Using Learning rate : 0.016295703919471546 
INFO:root:FL Epoch: 561 Normal Training
INFO:root:Worker: 1710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474154
INFO:root:Worker: 1710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622437
INFO:root:FL Epoch: 561 Norm Difference for worker 1710 is 0.762908
INFO:root:FL Epoch: 561 Done on worker:1710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 561 Training on worker :966
INFO:root:FL Epoch: 561 Using Learning rate : 0.016295703919471546 
INFO:root:FL Epoch: 561 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564558
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623140
INFO:root:FL Epoch: 561 Norm Difference for worker 966 is 0.706736
INFO:root:FL Epoch: 561 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 561 Training on worker :640
INFO:root:FL Epoch: 561 Using Learning rate : 0.016295703919471546 
INFO:root:FL Epoch: 561 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358811
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465849
INFO:root:FL Epoch: 561 Norm Difference for worker 640 is 0.778321
INFO:root:FL Epoch: 561 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 561 Training on worker :1848
INFO:root:FL Epoch: 561 Using Learning rate : 0.016295703919471546 
INFO:root:FL Epoch: 561 Normal Training
INFO:root:Worker: 1848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691061
INFO:root:Worker: 1848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454135
INFO:root:FL Epoch: 561 Norm Difference for worker 1848 is 0.77488
INFO:root:FL Epoch: 561 Done on worker:1848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 561 Training on worker :1504
INFO:root:FL Epoch: 561 Using Learning rate : 0.016295703919471546 
INFO:root:FL Epoch: 561 Normal Training
INFO:root:Worker: 1504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.864227
INFO:root:Worker: 1504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416177
INFO:root:FL Epoch: 561 Norm Difference for worker 1504 is 0.789777
INFO:root:FL Epoch: 561 Done on worker:1504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 561 Ends   ===================
INFO:root:Epoch:561 Global Model Test Loss:0.49699416756629944 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:561 Global Model Backdoor Test Loss:0.12464383741219838                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 562 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 562 Workers Selected : [648, 714, 824, 991, 1179, 1599, 585, 1926, 50, 1021]
INFO:root:FL Epoch: 562 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 562 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 562 Training on worker :648
INFO:root:FL Epoch: 562 Using Learning rate : 0.0162631125116326 
INFO:root:FL Epoch: 562 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571622
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464002
INFO:root:FL Epoch: 562 Norm Difference for worker 648 is 0.762459
INFO:root:FL Epoch: 562 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 562 Training on worker :714
INFO:root:FL Epoch: 562 Using Learning rate : 0.0162631125116326 
INFO:root:FL Epoch: 562 Normal Training
INFO:root:Worker: 714 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684455
INFO:root:Worker: 714 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551866
INFO:root:FL Epoch: 562 Norm Difference for worker 714 is 0.818844
INFO:root:FL Epoch: 562 Done on worker:714
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 562 Training on worker :824
INFO:root:FL Epoch: 562 Using Learning rate : 0.0162631125116326 
INFO:root:FL Epoch: 562 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575526
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329173
INFO:root:FL Epoch: 562 Norm Difference for worker 824 is 0.747942
INFO:root:FL Epoch: 562 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 562 Training on worker :991
INFO:root:FL Epoch: 562 Using Learning rate : 0.0162631125116326 
INFO:root:FL Epoch: 562 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412413
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359145
INFO:root:FL Epoch: 562 Norm Difference for worker 991 is 0.868035
INFO:root:FL Epoch: 562 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 562 Training on worker :1179
INFO:root:FL Epoch: 562 Using Learning rate : 0.0162631125116326 
INFO:root:FL Epoch: 562 Normal Training
INFO:root:Worker: 1179 Train Epoch: 0 [0/200 (0%)]	Loss: 0.208656
INFO:root:Worker: 1179 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241833
INFO:root:FL Epoch: 562 Norm Difference for worker 1179 is 0.730797
INFO:root:FL Epoch: 562 Done on worker:1179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 562 Training on worker :1599
INFO:root:FL Epoch: 562 Using Learning rate : 0.0162631125116326 
INFO:root:FL Epoch: 562 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545830
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305181
INFO:root:FL Epoch: 562 Norm Difference for worker 1599 is 0.781905
INFO:root:FL Epoch: 562 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 562 Training on worker :585
INFO:root:FL Epoch: 562 Using Learning rate : 0.0162631125116326 
INFO:root:FL Epoch: 562 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604126
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.841346
INFO:root:FL Epoch: 562 Norm Difference for worker 585 is 0.804436
INFO:root:FL Epoch: 562 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 562 Training on worker :1926
INFO:root:FL Epoch: 562 Using Learning rate : 0.0162631125116326 
INFO:root:FL Epoch: 562 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518903
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442726
INFO:root:FL Epoch: 562 Norm Difference for worker 1926 is 0.682035
INFO:root:FL Epoch: 562 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 562 Training on worker :50
INFO:root:FL Epoch: 562 Using Learning rate : 0.0162631125116326 
INFO:root:FL Epoch: 562 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.470753
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.437872
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 562 Norm Difference for worker 50 is 0.797435
INFO:root:FL Epoch: 562 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 562 Training on worker :1021
INFO:root:FL Epoch: 562 Using Learning rate : 0.0162631125116326 
INFO:root:FL Epoch: 562 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475805
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454560
INFO:root:FL Epoch: 562 Norm Difference for worker 1021 is 0.753771
INFO:root:FL Epoch: 562 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1926
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 562 Ends   ===================
INFO:root:Epoch:562 Global Model Test Loss:0.5031235042740317 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:562 Global Model Backdoor Test Loss:0.15438759823640189                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 563 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 563 Workers Selected : [1332, 1401, 480, 1193, 838, 313, 1411, 1295, 877, 456]
INFO:root:FL Epoch: 563 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 563 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 563 Training on worker :1332
INFO:root:FL Epoch: 563 Using Learning rate : 0.016230586286609335 
INFO:root:FL Epoch: 563 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648413
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492820
INFO:root:FL Epoch: 563 Norm Difference for worker 1332 is 0.773392
INFO:root:FL Epoch: 563 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 563 Training on worker :1401
INFO:root:FL Epoch: 563 Using Learning rate : 0.016230586286609335 
INFO:root:FL Epoch: 563 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489458
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425190
INFO:root:FL Epoch: 563 Norm Difference for worker 1401 is 0.758093
INFO:root:FL Epoch: 563 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 563 Training on worker :480
INFO:root:FL Epoch: 563 Using Learning rate : 0.016230586286609335 
INFO:root:FL Epoch: 563 Normal Training
INFO:root:Worker: 480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421423
INFO:root:Worker: 480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665639
INFO:root:FL Epoch: 563 Norm Difference for worker 480 is 0.789463
INFO:root:FL Epoch: 563 Done on worker:480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 563 Training on worker :1193
INFO:root:FL Epoch: 563 Using Learning rate : 0.016230586286609335 
INFO:root:FL Epoch: 563 Normal Training
INFO:root:Worker: 1193 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687445
INFO:root:Worker: 1193 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298764
INFO:root:FL Epoch: 563 Norm Difference for worker 1193 is 0.829679
INFO:root:FL Epoch: 563 Done on worker:1193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 563 Training on worker :838
INFO:root:FL Epoch: 563 Using Learning rate : 0.016230586286609335 
INFO:root:FL Epoch: 563 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759467
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537144
INFO:root:FL Epoch: 563 Norm Difference for worker 838 is 0.801616
INFO:root:FL Epoch: 563 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 563 Training on worker :313
INFO:root:FL Epoch: 563 Using Learning rate : 0.016230586286609335 
INFO:root:FL Epoch: 563 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.532159
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.467090
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 563 Norm Difference for worker 313 is 0.665896
INFO:root:FL Epoch: 563 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 563 Training on worker :1411
INFO:root:FL Epoch: 563 Using Learning rate : 0.016230586286609335 
INFO:root:FL Epoch: 563 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338528
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312961
INFO:root:FL Epoch: 563 Norm Difference for worker 1411 is 0.806568
INFO:root:FL Epoch: 563 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 563 Training on worker :1295
INFO:root:FL Epoch: 563 Using Learning rate : 0.016230586286609335 
INFO:root:FL Epoch: 563 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608880
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324743
INFO:root:FL Epoch: 563 Norm Difference for worker 1295 is 0.67326
INFO:root:FL Epoch: 563 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 563 Training on worker :877
INFO:root:FL Epoch: 563 Using Learning rate : 0.016230586286609335 
INFO:root:FL Epoch: 563 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505996
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505126
INFO:root:FL Epoch: 563 Norm Difference for worker 877 is 0.755143
INFO:root:FL Epoch: 563 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 563 Training on worker :456
INFO:root:FL Epoch: 563 Using Learning rate : 0.016230586286609335 
INFO:root:FL Epoch: 563 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570983
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353489
INFO:root:FL Epoch: 563 Norm Difference for worker 456 is 0.758582
INFO:root:FL Epoch: 563 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 313
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 563 Ends   ===================
INFO:root:Epoch:563 Global Model Test Loss:0.5025232872542214 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:563 Global Model Backdoor Test Loss:0.14073439066608748                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 564 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 564 Workers Selected : [161, 1851, 1054, 165, 574, 185, 319, 539, 667, 303]
INFO:root:FL Epoch: 564 Fraction of points on each worker in this round: [0.10024938 0.09975062 0.09975062 0.10024938 0.09975062 0.10024938
 0.10024938 0.09975062 0.09975062 0.10024938]
INFO:root:FL Epoch: 564 Num points on workers: [201 200 200 201 200 201 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 564 Training on worker :161
INFO:root:FL Epoch: 564 Using Learning rate : 0.016198125114036118 
INFO:root:FL Epoch: 564 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.439918
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.333891
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 564 Norm Difference for worker 161 is 0.703299
INFO:root:FL Epoch: 564 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 564 Training on worker :1851
INFO:root:FL Epoch: 564 Using Learning rate : 0.016198125114036118 
INFO:root:FL Epoch: 564 Normal Training
INFO:root:Worker: 1851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.256952
INFO:root:Worker: 1851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386663
INFO:root:FL Epoch: 564 Norm Difference for worker 1851 is 0.757842
INFO:root:FL Epoch: 564 Done on worker:1851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 564 Training on worker :1054
INFO:root:FL Epoch: 564 Using Learning rate : 0.016198125114036118 
INFO:root:FL Epoch: 564 Normal Training
INFO:root:Worker: 1054 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468734
INFO:root:Worker: 1054 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384970
INFO:root:FL Epoch: 564 Norm Difference for worker 1054 is 0.799752
INFO:root:FL Epoch: 564 Done on worker:1054
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 564 Training on worker :165
INFO:root:FL Epoch: 564 Using Learning rate : 0.016198125114036118 
INFO:root:FL Epoch: 564 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690422
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.356907
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 564 Norm Difference for worker 165 is 0.758576
INFO:root:FL Epoch: 564 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 564 Training on worker :574
INFO:root:FL Epoch: 564 Using Learning rate : 0.016198125114036118 
INFO:root:FL Epoch: 564 Normal Training
INFO:root:Worker: 574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437123
INFO:root:Worker: 574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352314
INFO:root:FL Epoch: 564 Norm Difference for worker 574 is 0.749462
INFO:root:FL Epoch: 564 Done on worker:574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 564 Training on worker :185
INFO:root:FL Epoch: 564 Using Learning rate : 0.016198125114036118 
INFO:root:FL Epoch: 564 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.446297
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.504256
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 564 Norm Difference for worker 185 is 0.758927
INFO:root:FL Epoch: 564 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 564 Training on worker :319
INFO:root:FL Epoch: 564 Using Learning rate : 0.016198125114036118 
INFO:root:FL Epoch: 564 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500533
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.348062
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 564 Norm Difference for worker 319 is 0.778951
INFO:root:FL Epoch: 564 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 564 Training on worker :539
INFO:root:FL Epoch: 564 Using Learning rate : 0.016198125114036118 
INFO:root:FL Epoch: 564 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474687
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445229
INFO:root:FL Epoch: 564 Norm Difference for worker 539 is 0.813972
INFO:root:FL Epoch: 564 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 564 Training on worker :667
INFO:root:FL Epoch: 564 Using Learning rate : 0.016198125114036118 
INFO:root:FL Epoch: 564 Normal Training
INFO:root:Worker: 667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671376
INFO:root:Worker: 667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345271
INFO:root:FL Epoch: 564 Norm Difference for worker 667 is 0.799268
INFO:root:FL Epoch: 564 Done on worker:667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 564 Training on worker :303
INFO:root:FL Epoch: 564 Using Learning rate : 0.016198125114036118 
INFO:root:FL Epoch: 564 Normal Training
INFO:root:Worker: 303 Train Epoch: 0 [0/201 (0%)]	Loss: 0.624580
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 303 Train Epoch: 1 [0/201 (0%)]	Loss: 0.422312
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 564 Norm Difference for worker 303 is 0.820669
INFO:root:FL Epoch: 564 Done on worker:303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 161
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 564 Ends   ===================
INFO:root:Epoch:564 Global Model Test Loss:0.5117198649574729 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:564 Global Model Backdoor Test Loss:0.09380642138421535                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 565 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 565 Workers Selected : [184, 1587, 703, 353, 1442, 1376, 959, 669, 1830, 1102]
INFO:root:FL Epoch: 565 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 565 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 565 Training on worker :184
INFO:root:FL Epoch: 565 Using Learning rate : 0.016165728863808043 
INFO:root:FL Epoch: 565 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.306411
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.283052
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 565 Norm Difference for worker 184 is 0.583482
INFO:root:FL Epoch: 565 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 565 Training on worker :1587
INFO:root:FL Epoch: 565 Using Learning rate : 0.016165728863808043 
INFO:root:FL Epoch: 565 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444229
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594098
INFO:root:FL Epoch: 565 Norm Difference for worker 1587 is 0.879937
INFO:root:FL Epoch: 565 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 565 Training on worker :703
INFO:root:FL Epoch: 565 Using Learning rate : 0.016165728863808043 
INFO:root:FL Epoch: 565 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535891
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375248
INFO:root:FL Epoch: 565 Norm Difference for worker 703 is 0.748607
INFO:root:FL Epoch: 565 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 565 Training on worker :353
INFO:root:FL Epoch: 565 Using Learning rate : 0.016165728863808043 
INFO:root:FL Epoch: 565 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407588
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338341
INFO:root:FL Epoch: 565 Norm Difference for worker 353 is 0.7428
INFO:root:FL Epoch: 565 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 565 Training on worker :1442
INFO:root:FL Epoch: 565 Using Learning rate : 0.016165728863808043 
INFO:root:FL Epoch: 565 Normal Training
INFO:root:Worker: 1442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439281
INFO:root:Worker: 1442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426897
INFO:root:FL Epoch: 565 Norm Difference for worker 1442 is 0.792377
INFO:root:FL Epoch: 565 Done on worker:1442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 565 Training on worker :1376
INFO:root:FL Epoch: 565 Using Learning rate : 0.016165728863808043 
INFO:root:FL Epoch: 565 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515525
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.168200
INFO:root:FL Epoch: 565 Norm Difference for worker 1376 is 0.807126
INFO:root:FL Epoch: 565 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 565 Training on worker :959
INFO:root:FL Epoch: 565 Using Learning rate : 0.016165728863808043 
INFO:root:FL Epoch: 565 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622932
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497032
INFO:root:FL Epoch: 565 Norm Difference for worker 959 is 0.823315
INFO:root:FL Epoch: 565 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 565 Training on worker :669
INFO:root:FL Epoch: 565 Using Learning rate : 0.016165728863808043 
INFO:root:FL Epoch: 565 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743898
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.181689
INFO:root:FL Epoch: 565 Norm Difference for worker 669 is 0.742067
INFO:root:FL Epoch: 565 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 565 Training on worker :1830
INFO:root:FL Epoch: 565 Using Learning rate : 0.016165728863808043 
INFO:root:FL Epoch: 565 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496724
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363142
INFO:root:FL Epoch: 565 Norm Difference for worker 1830 is 0.837625
INFO:root:FL Epoch: 565 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 565 Training on worker :1102
INFO:root:FL Epoch: 565 Using Learning rate : 0.016165728863808043 
INFO:root:FL Epoch: 565 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642481
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360604
INFO:root:FL Epoch: 565 Norm Difference for worker 1102 is 0.78255
INFO:root:FL Epoch: 565 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 184
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 565 Ends   ===================
INFO:root:Epoch:565 Global Model Test Loss:0.509291773333269 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:565 Global Model Backdoor Test Loss:0.10064930468797684                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 566 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 566 Workers Selected : [1351, 1724, 887, 1192, 624, 1905, 629, 890, 1653, 1794]
INFO:root:FL Epoch: 566 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 566 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 566 Training on worker :1351
INFO:root:FL Epoch: 566 Using Learning rate : 0.016133397406080427 
INFO:root:FL Epoch: 566 Normal Training
INFO:root:Worker: 1351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638230
INFO:root:Worker: 1351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556287
INFO:root:FL Epoch: 566 Norm Difference for worker 1351 is 0.872002
INFO:root:FL Epoch: 566 Done on worker:1351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 566 Training on worker :1724
INFO:root:FL Epoch: 566 Using Learning rate : 0.016133397406080427 
INFO:root:FL Epoch: 566 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576611
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582480
INFO:root:FL Epoch: 566 Norm Difference for worker 1724 is 0.905206
INFO:root:FL Epoch: 566 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 566 Training on worker :887
INFO:root:FL Epoch: 566 Using Learning rate : 0.016133397406080427 
INFO:root:FL Epoch: 566 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428720
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468054
INFO:root:FL Epoch: 566 Norm Difference for worker 887 is 0.875073
INFO:root:FL Epoch: 566 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 566 Training on worker :1192
INFO:root:FL Epoch: 566 Using Learning rate : 0.016133397406080427 
INFO:root:FL Epoch: 566 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396633
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327135
INFO:root:FL Epoch: 566 Norm Difference for worker 1192 is 0.860384
INFO:root:FL Epoch: 566 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 566 Training on worker :624
INFO:root:FL Epoch: 566 Using Learning rate : 0.016133397406080427 
INFO:root:FL Epoch: 566 Normal Training
INFO:root:Worker: 624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656368
INFO:root:Worker: 624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254913
INFO:root:FL Epoch: 566 Norm Difference for worker 624 is 0.761657
INFO:root:FL Epoch: 566 Done on worker:624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 566 Training on worker :1905
INFO:root:FL Epoch: 566 Using Learning rate : 0.016133397406080427 
INFO:root:FL Epoch: 566 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508730
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220357
INFO:root:FL Epoch: 566 Norm Difference for worker 1905 is 0.671015
INFO:root:FL Epoch: 566 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 566 Training on worker :629
INFO:root:FL Epoch: 566 Using Learning rate : 0.016133397406080427 
INFO:root:FL Epoch: 566 Normal Training
INFO:root:Worker: 629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405133
INFO:root:Worker: 629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508141
INFO:root:FL Epoch: 566 Norm Difference for worker 629 is 0.825346
INFO:root:FL Epoch: 566 Done on worker:629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 566 Training on worker :890
INFO:root:FL Epoch: 566 Using Learning rate : 0.016133397406080427 
INFO:root:FL Epoch: 566 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561136
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516685
INFO:root:FL Epoch: 566 Norm Difference for worker 890 is 0.925369
INFO:root:FL Epoch: 566 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 566 Training on worker :1653
INFO:root:FL Epoch: 566 Using Learning rate : 0.016133397406080427 
INFO:root:FL Epoch: 566 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527624
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252757
INFO:root:FL Epoch: 566 Norm Difference for worker 1653 is 0.767591
INFO:root:FL Epoch: 566 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 566 Training on worker :1794
INFO:root:FL Epoch: 566 Using Learning rate : 0.016133397406080427 
INFO:root:FL Epoch: 566 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.299166
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420435
INFO:root:FL Epoch: 566 Norm Difference for worker 1794 is 0.828724
INFO:root:FL Epoch: 566 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1905
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 566 Ends   ===================
INFO:root:Epoch:566 Global Model Test Loss:0.525658088571885 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:566 Global Model Backdoor Test Loss:0.14282001679142317                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 567 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 567 Workers Selected : [1509, 1066, 558, 1605, 399, 1525, 1148, 677, 1492, 327]
INFO:root:FL Epoch: 567 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 567 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 567 Training on worker :1509
INFO:root:FL Epoch: 567 Using Learning rate : 0.016101130611268267 
INFO:root:FL Epoch: 567 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.806773
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611722
INFO:root:FL Epoch: 567 Norm Difference for worker 1509 is 0.944377
INFO:root:FL Epoch: 567 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 567 Training on worker :1066
INFO:root:FL Epoch: 567 Using Learning rate : 0.016101130611268267 
INFO:root:FL Epoch: 567 Normal Training
INFO:root:Worker: 1066 Train Epoch: 0 [0/200 (0%)]	Loss: 0.251306
INFO:root:Worker: 1066 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457079
INFO:root:FL Epoch: 567 Norm Difference for worker 1066 is 0.892512
INFO:root:FL Epoch: 567 Done on worker:1066
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 567 Training on worker :558
INFO:root:FL Epoch: 567 Using Learning rate : 0.016101130611268267 
INFO:root:FL Epoch: 567 Normal Training
INFO:root:Worker: 558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783540
INFO:root:Worker: 558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514189
INFO:root:FL Epoch: 567 Norm Difference for worker 558 is 0.954457
INFO:root:FL Epoch: 567 Done on worker:558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 567 Training on worker :1605
INFO:root:FL Epoch: 567 Using Learning rate : 0.016101130611268267 
INFO:root:FL Epoch: 567 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587336
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349689
INFO:root:FL Epoch: 567 Norm Difference for worker 1605 is 0.938387
INFO:root:FL Epoch: 567 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 567 Training on worker :399
INFO:root:FL Epoch: 567 Using Learning rate : 0.016101130611268267 
INFO:root:FL Epoch: 567 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410771
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596331
INFO:root:FL Epoch: 567 Norm Difference for worker 399 is 0.886449
INFO:root:FL Epoch: 567 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 567 Training on worker :1525
INFO:root:FL Epoch: 567 Using Learning rate : 0.016101130611268267 
INFO:root:FL Epoch: 567 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733427
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490507
INFO:root:FL Epoch: 567 Norm Difference for worker 1525 is 0.981062
INFO:root:FL Epoch: 567 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 567 Training on worker :1148
INFO:root:FL Epoch: 567 Using Learning rate : 0.016101130611268267 
INFO:root:FL Epoch: 567 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.820684
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361570
INFO:root:FL Epoch: 567 Norm Difference for worker 1148 is 0.936054
INFO:root:FL Epoch: 567 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 567 Training on worker :677
INFO:root:FL Epoch: 567 Using Learning rate : 0.016101130611268267 
INFO:root:FL Epoch: 567 Normal Training
INFO:root:Worker: 677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422599
INFO:root:Worker: 677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303248
INFO:root:FL Epoch: 567 Norm Difference for worker 677 is 0.915798
INFO:root:FL Epoch: 567 Done on worker:677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 567 Training on worker :1492
INFO:root:FL Epoch: 567 Using Learning rate : 0.016101130611268267 
INFO:root:FL Epoch: 567 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529647
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647341
INFO:root:FL Epoch: 567 Norm Difference for worker 1492 is 0.952118
INFO:root:FL Epoch: 567 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 567 Training on worker :327
INFO:root:FL Epoch: 567 Using Learning rate : 0.016101130611268267 
INFO:root:FL Epoch: 567 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.599346
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.667180
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 567 Norm Difference for worker 327 is 0.919257
INFO:root:FL Epoch: 567 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1066
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 567 Ends   ===================
INFO:root:Epoch:567 Global Model Test Loss:0.5191231475156897 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:567 Global Model Backdoor Test Loss:0.1130801389614741                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 568 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 568 Workers Selected : [783, 277, 1708, 1063, 169, 1279, 247, 1366, 304, 1678]
INFO:root:FL Epoch: 568 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 568 Num points on workers: [200 201 200 200 201 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 568 Training on worker :783
INFO:root:FL Epoch: 568 Using Learning rate : 0.01606892835004573 
INFO:root:FL Epoch: 568 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645129
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416138
INFO:root:FL Epoch: 568 Norm Difference for worker 783 is 0.83561
INFO:root:FL Epoch: 568 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 568 Training on worker :277
INFO:root:FL Epoch: 568 Using Learning rate : 0.01606892835004573 
INFO:root:FL Epoch: 568 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.575252
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.418236
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 568 Norm Difference for worker 277 is 0.844582
INFO:root:FL Epoch: 568 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 568 Training on worker :1708
INFO:root:FL Epoch: 568 Using Learning rate : 0.01606892835004573 
INFO:root:FL Epoch: 568 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640490
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499815
INFO:root:FL Epoch: 568 Norm Difference for worker 1708 is 0.824551
INFO:root:FL Epoch: 568 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 568 Training on worker :1063
INFO:root:FL Epoch: 568 Using Learning rate : 0.01606892835004573 
INFO:root:FL Epoch: 568 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442473
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406538
INFO:root:FL Epoch: 568 Norm Difference for worker 1063 is 0.799916
INFO:root:FL Epoch: 568 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 568 Training on worker :169
INFO:root:FL Epoch: 568 Using Learning rate : 0.01606892835004573 
INFO:root:FL Epoch: 568 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.371994
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.293859
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 568 Norm Difference for worker 169 is 0.775119
INFO:root:FL Epoch: 568 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 568 Training on worker :1279
INFO:root:FL Epoch: 568 Using Learning rate : 0.01606892835004573 
INFO:root:FL Epoch: 568 Normal Training
INFO:root:Worker: 1279 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464975
INFO:root:Worker: 1279 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397206
INFO:root:FL Epoch: 568 Norm Difference for worker 1279 is 0.78569
INFO:root:FL Epoch: 568 Done on worker:1279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 568 Training on worker :247
INFO:root:FL Epoch: 568 Using Learning rate : 0.01606892835004573 
INFO:root:FL Epoch: 568 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.354028
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.414215
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 568 Norm Difference for worker 247 is 0.818932
INFO:root:FL Epoch: 568 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 568 Training on worker :1366
INFO:root:FL Epoch: 568 Using Learning rate : 0.01606892835004573 
INFO:root:FL Epoch: 568 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.261422
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314278
INFO:root:FL Epoch: 568 Norm Difference for worker 1366 is 0.731862
INFO:root:FL Epoch: 568 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 568 Training on worker :304
INFO:root:FL Epoch: 568 Using Learning rate : 0.01606892835004573 
INFO:root:FL Epoch: 568 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.393506
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.278847
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 568 Norm Difference for worker 304 is 0.74621
INFO:root:FL Epoch: 568 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 568 Training on worker :1678
INFO:root:FL Epoch: 568 Using Learning rate : 0.01606892835004573 
INFO:root:FL Epoch: 568 Normal Training
INFO:root:Worker: 1678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397255
INFO:root:Worker: 1678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368218
INFO:root:FL Epoch: 568 Norm Difference for worker 1678 is 0.772675
INFO:root:FL Epoch: 568 Done on worker:1678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1366
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 568 Ends   ===================
INFO:root:Epoch:568 Global Model Test Loss:0.4963540995822233 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:568 Global Model Backdoor Test Loss:0.16244139894843102                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 569 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 569 Workers Selected : [897, 768, 199, 1231, 1007, 245, 1031, 439, 680, 841]
INFO:root:FL Epoch: 569 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 569 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 569 Training on worker :897
INFO:root:FL Epoch: 569 Using Learning rate : 0.01603679049334564 
INFO:root:FL Epoch: 569 Normal Training
INFO:root:Worker: 897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632472
INFO:root:Worker: 897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669357
INFO:root:FL Epoch: 569 Norm Difference for worker 897 is 0.782694
INFO:root:FL Epoch: 569 Done on worker:897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 569 Training on worker :768
INFO:root:FL Epoch: 569 Using Learning rate : 0.01603679049334564 
INFO:root:FL Epoch: 569 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536866
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343328
INFO:root:FL Epoch: 569 Norm Difference for worker 768 is 0.669396
INFO:root:FL Epoch: 569 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 569 Training on worker :199
INFO:root:FL Epoch: 569 Using Learning rate : 0.01603679049334564 
INFO:root:FL Epoch: 569 Normal Training
INFO:root:Worker: 199 Train Epoch: 0 [0/201 (0%)]	Loss: 0.632102
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 199 Train Epoch: 1 [0/201 (0%)]	Loss: 0.515833
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 569 Norm Difference for worker 199 is 0.795536
INFO:root:FL Epoch: 569 Done on worker:199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 569 Training on worker :1231
INFO:root:FL Epoch: 569 Using Learning rate : 0.01603679049334564 
INFO:root:FL Epoch: 569 Normal Training
INFO:root:Worker: 1231 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483440
INFO:root:Worker: 1231 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404633
INFO:root:FL Epoch: 569 Norm Difference for worker 1231 is 0.719587
INFO:root:FL Epoch: 569 Done on worker:1231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 569 Training on worker :1007
INFO:root:FL Epoch: 569 Using Learning rate : 0.01603679049334564 
INFO:root:FL Epoch: 569 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.317257
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388074
INFO:root:FL Epoch: 569 Norm Difference for worker 1007 is 0.750574
INFO:root:FL Epoch: 569 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 569 Training on worker :245
INFO:root:FL Epoch: 569 Using Learning rate : 0.01603679049334564 
INFO:root:FL Epoch: 569 Normal Training
INFO:root:Worker: 245 Train Epoch: 0 [0/201 (0%)]	Loss: 0.449476
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 245 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446334
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 569 Norm Difference for worker 245 is 0.770032
INFO:root:FL Epoch: 569 Done on worker:245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 569 Training on worker :1031
INFO:root:FL Epoch: 569 Using Learning rate : 0.01603679049334564 
INFO:root:FL Epoch: 569 Normal Training
INFO:root:Worker: 1031 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655567
INFO:root:Worker: 1031 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254731
INFO:root:FL Epoch: 569 Norm Difference for worker 1031 is 0.757155
INFO:root:FL Epoch: 569 Done on worker:1031
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 569 Training on worker :439
INFO:root:FL Epoch: 569 Using Learning rate : 0.01603679049334564 
INFO:root:FL Epoch: 569 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529321
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359487
INFO:root:FL Epoch: 569 Norm Difference for worker 439 is 0.755205
INFO:root:FL Epoch: 569 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 569 Training on worker :680
INFO:root:FL Epoch: 569 Using Learning rate : 0.01603679049334564 
INFO:root:FL Epoch: 569 Normal Training
INFO:root:Worker: 680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562669
INFO:root:Worker: 680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.719062
INFO:root:FL Epoch: 569 Norm Difference for worker 680 is 0.723669
INFO:root:FL Epoch: 569 Done on worker:680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 569 Training on worker :841
INFO:root:FL Epoch: 569 Using Learning rate : 0.01603679049334564 
INFO:root:FL Epoch: 569 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536523
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336889
INFO:root:FL Epoch: 569 Norm Difference for worker 841 is 0.753848
INFO:root:FL Epoch: 569 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 768
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 569 Ends   ===================
INFO:root:Epoch:569 Global Model Test Loss:0.5094276193310233 and Test Accuracy:75.0 
INFO:root:Epoch:569 Global Model Backdoor Test Loss:0.10406095099945863                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 570 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 570 Workers Selected : [78, 158, 1509, 571, 30, 818, 201, 1021, 185, 750]
INFO:root:FL Epoch: 570 Fraction of points on each worker in this round: [0.10024938 0.10024938 0.09975062 0.09975062 0.10024938 0.09975062
 0.10024938 0.09975062 0.10024938 0.09975062]
INFO:root:FL Epoch: 570 Num points on workers: [201 201 200 200 201 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 570 Training on worker :78
INFO:root:FL Epoch: 570 Using Learning rate : 0.01600471691235895 
INFO:root:FL Epoch: 570 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.454979
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.476593
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 570 Norm Difference for worker 78 is 0.648174
INFO:root:FL Epoch: 570 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 570 Training on worker :158
INFO:root:FL Epoch: 570 Using Learning rate : 0.01600471691235895 
INFO:root:FL Epoch: 570 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676278
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.380889
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 570 Norm Difference for worker 158 is 0.865282
INFO:root:FL Epoch: 570 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 570 Training on worker :1509
INFO:root:FL Epoch: 570 Using Learning rate : 0.01600471691235895 
INFO:root:FL Epoch: 570 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388643
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543989
INFO:root:FL Epoch: 570 Norm Difference for worker 1509 is 0.79365
INFO:root:FL Epoch: 570 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 570 Training on worker :571
INFO:root:FL Epoch: 570 Using Learning rate : 0.01600471691235895 
INFO:root:FL Epoch: 570 Normal Training
INFO:root:Worker: 571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624220
INFO:root:Worker: 571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409599
INFO:root:FL Epoch: 570 Norm Difference for worker 571 is 0.789836
INFO:root:FL Epoch: 570 Done on worker:571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 570 Training on worker :30
INFO:root:FL Epoch: 570 Using Learning rate : 0.01600471691235895 
INFO:root:FL Epoch: 570 Normal Training
INFO:root:Worker: 30 Train Epoch: 0 [0/201 (0%)]	Loss: 0.565317
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 30 Train Epoch: 1 [0/201 (0%)]	Loss: 0.259975
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 570 Norm Difference for worker 30 is 0.838208
INFO:root:FL Epoch: 570 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 570 Training on worker :818
INFO:root:FL Epoch: 570 Using Learning rate : 0.01600471691235895 
INFO:root:FL Epoch: 570 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587692
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545476
INFO:root:FL Epoch: 570 Norm Difference for worker 818 is 0.797041
INFO:root:FL Epoch: 570 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 570 Training on worker :201
INFO:root:FL Epoch: 570 Using Learning rate : 0.01600471691235895 
INFO:root:FL Epoch: 570 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.758317
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.420633
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 570 Norm Difference for worker 201 is 0.890194
INFO:root:FL Epoch: 570 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 570 Training on worker :1021
INFO:root:FL Epoch: 570 Using Learning rate : 0.01600471691235895 
INFO:root:FL Epoch: 570 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438845
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467500
INFO:root:FL Epoch: 570 Norm Difference for worker 1021 is 0.706302
INFO:root:FL Epoch: 570 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 570 Training on worker :185
INFO:root:FL Epoch: 570 Using Learning rate : 0.01600471691235895 
INFO:root:FL Epoch: 570 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.377423
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.388300
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 570 Norm Difference for worker 185 is 0.799436
INFO:root:FL Epoch: 570 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 570 Training on worker :750
INFO:root:FL Epoch: 570 Using Learning rate : 0.01600471691235895 
INFO:root:FL Epoch: 570 Normal Training
INFO:root:Worker: 750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531254
INFO:root:Worker: 750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637737
INFO:root:FL Epoch: 570 Norm Difference for worker 750 is 0.803171
INFO:root:FL Epoch: 570 Done on worker:750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 78
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 570 Ends   ===================
INFO:root:Epoch:570 Global Model Test Loss:0.5116132725687588 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:570 Global Model Backdoor Test Loss:0.14184843003749847                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 571 Begins ===================
INFO:root:FL Epoch: 571 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 571 Workers Selected : [0, 1, 2, 1061, 1042, 1852, 1271, 1167, 671, 986]
INFO:root:FL Epoch: 571 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 571 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 571 Training on worker :0
INFO:root:FL Epoch: 571 Using Learning rate : 0.0031945414957068458 
INFO:root:FL Epoch: 571 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.200763
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.162827
INFO:root:FL Epoch: 571 Worker: 0 Backdoor Test Loss: 0.11928225432833035 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 571 Worker: 0 Backdoor Train Loss: 0.12300628423690796 Backdoor Train Accuracy: 98.0
INFO:root:FL Epoch: 571 Norm Difference for worker 0 is 0.091929
INFO:root:FL Epoch: 571 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 571 Training on worker :1
INFO:root:FL Epoch: 571 Using Learning rate : 0.0031945414957068458 
INFO:root:FL Epoch: 571 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.149559
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.064151
INFO:root:FL Epoch: 571 Worker: 1 Backdoor Test Loss: 0.1210847074786822 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 571 Worker: 1 Backdoor Train Loss: 0.1238382801413536 Backdoor Train Accuracy: 98.0
INFO:root:FL Epoch: 571 Norm Difference for worker 1 is 0.090461
INFO:root:FL Epoch: 571 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 571 Training on worker :2
INFO:root:FL Epoch: 571 Using Learning rate : 0.0031945414957068458 
INFO:root:FL Epoch: 571 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.118027
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.113175
INFO:root:FL Epoch: 571 Worker: 2 Backdoor Test Loss: 0.1216460590561231 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 571 Worker: 2 Backdoor Train Loss: 0.12328641265630721 Backdoor Train Accuracy: 98.0
INFO:root:FL Epoch: 571 Norm Difference for worker 2 is 0.090649
INFO:root:FL Epoch: 571 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 571 Training on worker :1061
INFO:root:FL Epoch: 571 Using Learning rate : 0.01597270747853423 
INFO:root:FL Epoch: 571 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529593
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611508
INFO:root:FL Epoch: 571 Norm Difference for worker 1061 is 0.793281
INFO:root:FL Epoch: 571 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 571 Training on worker :1042
INFO:root:FL Epoch: 571 Using Learning rate : 0.01597270747853423 
INFO:root:FL Epoch: 571 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326529
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281646
INFO:root:FL Epoch: 571 Norm Difference for worker 1042 is 0.665006
INFO:root:FL Epoch: 571 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 571 Training on worker :1852
INFO:root:FL Epoch: 571 Using Learning rate : 0.01597270747853423 
INFO:root:FL Epoch: 571 Normal Training
INFO:root:Worker: 1852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309528
INFO:root:Worker: 1852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425099
INFO:root:FL Epoch: 571 Norm Difference for worker 1852 is 0.745202
INFO:root:FL Epoch: 571 Done on worker:1852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 571 Training on worker :1271
INFO:root:FL Epoch: 571 Using Learning rate : 0.01597270747853423 
INFO:root:FL Epoch: 571 Normal Training
INFO:root:Worker: 1271 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586854
INFO:root:Worker: 1271 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577338
INFO:root:FL Epoch: 571 Norm Difference for worker 1271 is 0.806114
INFO:root:FL Epoch: 571 Done on worker:1271
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 571 Training on worker :1167
INFO:root:FL Epoch: 571 Using Learning rate : 0.01597270747853423 
INFO:root:FL Epoch: 571 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632253
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347275
INFO:root:FL Epoch: 571 Norm Difference for worker 1167 is 0.781664
INFO:root:FL Epoch: 571 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 571 Training on worker :671
INFO:root:FL Epoch: 571 Using Learning rate : 0.01597270747853423 
INFO:root:FL Epoch: 571 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437421
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335667
INFO:root:FL Epoch: 571 Norm Difference for worker 671 is 0.727898
INFO:root:FL Epoch: 571 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 571 Training on worker :986
INFO:root:FL Epoch: 571 Using Learning rate : 0.01597270747853423 
INFO:root:FL Epoch: 571 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640788
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648106
INFO:root:FL Epoch: 571 Norm Difference for worker 986 is 0.842327
INFO:root:FL Epoch: 571 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 571 Ends   ===================
INFO:root:Epoch:571 Global Model Test Loss:0.5118741042473737 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:571 Global Model Backdoor Test Loss:0.11928225432833035                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 572 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 572 Workers Selected : [1304, 439, 523, 1858, 473, 17, 1491, 1571, 364, 119]
INFO:root:FL Epoch: 572 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 572 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 572 Training on worker :1304
INFO:root:FL Epoch: 572 Using Learning rate : 0.01594076206357716 
INFO:root:FL Epoch: 572 Normal Training
INFO:root:Worker: 1304 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449705
INFO:root:Worker: 1304 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459000
INFO:root:FL Epoch: 572 Norm Difference for worker 1304 is 0.782734
INFO:root:FL Epoch: 572 Done on worker:1304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 572 Training on worker :439
INFO:root:FL Epoch: 572 Using Learning rate : 0.01594076206357716 
INFO:root:FL Epoch: 572 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566826
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565379
INFO:root:FL Epoch: 572 Norm Difference for worker 439 is 0.791943
INFO:root:FL Epoch: 572 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 572 Training on worker :523
INFO:root:FL Epoch: 572 Using Learning rate : 0.01594076206357716 
INFO:root:FL Epoch: 572 Normal Training
INFO:root:Worker: 523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398069
INFO:root:Worker: 523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497631
INFO:root:FL Epoch: 572 Norm Difference for worker 523 is 0.83919
INFO:root:FL Epoch: 572 Done on worker:523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 572 Training on worker :1858
INFO:root:FL Epoch: 572 Using Learning rate : 0.01594076206357716 
INFO:root:FL Epoch: 572 Normal Training
INFO:root:Worker: 1858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531088
INFO:root:Worker: 1858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.745399
INFO:root:FL Epoch: 572 Norm Difference for worker 1858 is 0.88397
INFO:root:FL Epoch: 572 Done on worker:1858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 572 Training on worker :473
INFO:root:FL Epoch: 572 Using Learning rate : 0.01594076206357716 
INFO:root:FL Epoch: 572 Normal Training
INFO:root:Worker: 473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565616
INFO:root:Worker: 473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517593
INFO:root:FL Epoch: 572 Norm Difference for worker 473 is 0.783692
INFO:root:FL Epoch: 572 Done on worker:473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 572 Training on worker :17
INFO:root:FL Epoch: 572 Using Learning rate : 0.01594076206357716 
INFO:root:FL Epoch: 572 Normal Training
INFO:root:Worker: 17 Train Epoch: 0 [0/201 (0%)]	Loss: 0.741698
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 17 Train Epoch: 1 [0/201 (0%)]	Loss: 0.536549
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 572 Norm Difference for worker 17 is 0.89091
INFO:root:FL Epoch: 572 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 572 Training on worker :1491
INFO:root:FL Epoch: 572 Using Learning rate : 0.01594076206357716 
INFO:root:FL Epoch: 572 Normal Training
INFO:root:Worker: 1491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.865847
INFO:root:Worker: 1491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255480
INFO:root:FL Epoch: 572 Norm Difference for worker 1491 is 0.811868
INFO:root:FL Epoch: 572 Done on worker:1491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 572 Training on worker :1571
INFO:root:FL Epoch: 572 Using Learning rate : 0.01594076206357716 
INFO:root:FL Epoch: 572 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570538
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463215
INFO:root:FL Epoch: 572 Norm Difference for worker 1571 is 0.851431
INFO:root:FL Epoch: 572 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 572 Training on worker :364
INFO:root:FL Epoch: 572 Using Learning rate : 0.01594076206357716 
INFO:root:FL Epoch: 572 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772107
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441773
INFO:root:FL Epoch: 572 Norm Difference for worker 364 is 0.767436
INFO:root:FL Epoch: 572 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 572 Training on worker :119
INFO:root:FL Epoch: 572 Using Learning rate : 0.01594076206357716 
INFO:root:FL Epoch: 572 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.309317
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446283
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 572 Norm Difference for worker 119 is 0.790539
INFO:root:FL Epoch: 572 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 364
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 572 Ends   ===================
INFO:root:Epoch:572 Global Model Test Loss:0.4967009302447824 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:572 Global Model Backdoor Test Loss:0.09898086388905843                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 573 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 573 Workers Selected : [1519, 1509, 112, 1748, 415, 1017, 782, 1715, 1356, 1342]
INFO:root:FL Epoch: 573 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 573 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 573 Training on worker :1519
INFO:root:FL Epoch: 573 Using Learning rate : 0.01590888053945001 
INFO:root:FL Epoch: 573 Normal Training
INFO:root:Worker: 1519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773109
INFO:root:Worker: 1519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557941
INFO:root:FL Epoch: 573 Norm Difference for worker 1519 is 0.798873
INFO:root:FL Epoch: 573 Done on worker:1519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 573 Training on worker :1509
INFO:root:FL Epoch: 573 Using Learning rate : 0.01590888053945001 
INFO:root:FL Epoch: 573 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560621
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424861
INFO:root:FL Epoch: 573 Norm Difference for worker 1509 is 0.830205
INFO:root:FL Epoch: 573 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 573 Training on worker :112
INFO:root:FL Epoch: 573 Using Learning rate : 0.01590888053945001 
INFO:root:FL Epoch: 573 Normal Training
INFO:root:Worker: 112 Train Epoch: 0 [0/201 (0%)]	Loss: 0.516123
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 112 Train Epoch: 1 [0/201 (0%)]	Loss: 0.547960
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 573 Norm Difference for worker 112 is 0.771909
INFO:root:FL Epoch: 573 Done on worker:112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 573 Training on worker :1748
INFO:root:FL Epoch: 573 Using Learning rate : 0.01590888053945001 
INFO:root:FL Epoch: 573 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642500
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482021
INFO:root:FL Epoch: 573 Norm Difference for worker 1748 is 0.830865
INFO:root:FL Epoch: 573 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 573 Training on worker :415
INFO:root:FL Epoch: 573 Using Learning rate : 0.01590888053945001 
INFO:root:FL Epoch: 573 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436503
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317864
INFO:root:FL Epoch: 573 Norm Difference for worker 415 is 0.668879
INFO:root:FL Epoch: 573 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 573 Training on worker :1017
INFO:root:FL Epoch: 573 Using Learning rate : 0.01590888053945001 
INFO:root:FL Epoch: 573 Normal Training
INFO:root:Worker: 1017 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657752
INFO:root:Worker: 1017 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633742
INFO:root:FL Epoch: 573 Norm Difference for worker 1017 is 0.757475
INFO:root:FL Epoch: 573 Done on worker:1017
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 573 Training on worker :782
INFO:root:FL Epoch: 573 Using Learning rate : 0.01590888053945001 
INFO:root:FL Epoch: 573 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587215
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536204
INFO:root:FL Epoch: 573 Norm Difference for worker 782 is 0.804949
INFO:root:FL Epoch: 573 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 573 Training on worker :1715
INFO:root:FL Epoch: 573 Using Learning rate : 0.01590888053945001 
INFO:root:FL Epoch: 573 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569283
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341145
INFO:root:FL Epoch: 573 Norm Difference for worker 1715 is 0.824005
INFO:root:FL Epoch: 573 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 573 Training on worker :1356
INFO:root:FL Epoch: 573 Using Learning rate : 0.01590888053945001 
INFO:root:FL Epoch: 573 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531977
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523323
INFO:root:FL Epoch: 573 Norm Difference for worker 1356 is 0.898666
INFO:root:FL Epoch: 573 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 573 Training on worker :1342
INFO:root:FL Epoch: 573 Using Learning rate : 0.01590888053945001 
INFO:root:FL Epoch: 573 Normal Training
INFO:root:Worker: 1342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.957382
INFO:root:Worker: 1342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459239
INFO:root:FL Epoch: 573 Norm Difference for worker 1342 is 0.736976
INFO:root:FL Epoch: 573 Done on worker:1342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 415
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 573 Ends   ===================
INFO:root:Epoch:573 Global Model Test Loss:0.4971696515293682 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:573 Global Model Backdoor Test Loss:0.10694243696828683                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 574 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 574 Workers Selected : [1498, 804, 643, 1075, 1437, 74, 979, 516, 1748, 1798]
INFO:root:FL Epoch: 574 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 574 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 574 Training on worker :1498
INFO:root:FL Epoch: 574 Using Learning rate : 0.015877062778371108 
INFO:root:FL Epoch: 574 Normal Training
INFO:root:Worker: 1498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688099
INFO:root:Worker: 1498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320159
INFO:root:FL Epoch: 574 Norm Difference for worker 1498 is 0.819741
INFO:root:FL Epoch: 574 Done on worker:1498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 574 Training on worker :804
INFO:root:FL Epoch: 574 Using Learning rate : 0.015877062778371108 
INFO:root:FL Epoch: 574 Normal Training
INFO:root:Worker: 804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734527
INFO:root:Worker: 804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380680
INFO:root:FL Epoch: 574 Norm Difference for worker 804 is 0.935735
INFO:root:FL Epoch: 574 Done on worker:804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 574 Training on worker :643
INFO:root:FL Epoch: 574 Using Learning rate : 0.015877062778371108 
INFO:root:FL Epoch: 574 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676199
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454511
INFO:root:FL Epoch: 574 Norm Difference for worker 643 is 0.841584
INFO:root:FL Epoch: 574 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 574 Training on worker :1075
INFO:root:FL Epoch: 574 Using Learning rate : 0.015877062778371108 
INFO:root:FL Epoch: 574 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675309
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341248
INFO:root:FL Epoch: 574 Norm Difference for worker 1075 is 0.827824
INFO:root:FL Epoch: 574 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 574 Training on worker :1437
INFO:root:FL Epoch: 574 Using Learning rate : 0.015877062778371108 
INFO:root:FL Epoch: 574 Normal Training
INFO:root:Worker: 1437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515250
INFO:root:Worker: 1437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368032
INFO:root:FL Epoch: 574 Norm Difference for worker 1437 is 0.86574
INFO:root:FL Epoch: 574 Done on worker:1437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 574 Training on worker :74
INFO:root:FL Epoch: 574 Using Learning rate : 0.015877062778371108 
INFO:root:FL Epoch: 574 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.740178
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.679217
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 574 Norm Difference for worker 74 is 0.851028
INFO:root:FL Epoch: 574 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 574 Training on worker :979
INFO:root:FL Epoch: 574 Using Learning rate : 0.015877062778371108 
INFO:root:FL Epoch: 574 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775869
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552719
INFO:root:FL Epoch: 574 Norm Difference for worker 979 is 0.895528
INFO:root:FL Epoch: 574 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 574 Training on worker :516
INFO:root:FL Epoch: 574 Using Learning rate : 0.015877062778371108 
INFO:root:FL Epoch: 574 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429416
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284586
INFO:root:FL Epoch: 574 Norm Difference for worker 516 is 0.761875
INFO:root:FL Epoch: 574 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 574 Training on worker :1748
INFO:root:FL Epoch: 574 Using Learning rate : 0.015877062778371108 
INFO:root:FL Epoch: 574 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.943819
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620594
INFO:root:FL Epoch: 574 Norm Difference for worker 1748 is 0.886152
INFO:root:FL Epoch: 574 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 574 Training on worker :1798
INFO:root:FL Epoch: 574 Using Learning rate : 0.015877062778371108 
INFO:root:FL Epoch: 574 Normal Training
INFO:root:Worker: 1798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763087
INFO:root:Worker: 1798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403234
INFO:root:FL Epoch: 574 Norm Difference for worker 1798 is 0.914722
INFO:root:FL Epoch: 574 Done on worker:1798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 516
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 574 Ends   ===================
INFO:root:Epoch:574 Global Model Test Loss:0.4967065032790689 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:574 Global Model Backdoor Test Loss:0.10032340884208679                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 575 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 575 Workers Selected : [317, 105, 1425, 1249, 401, 243, 53, 960, 1525, 1533]
INFO:root:FL Epoch: 575 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994 0.1002994
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 575 Num points on workers: [201 201 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 575 Training on worker :317
INFO:root:FL Epoch: 575 Using Learning rate : 0.015845308652814367 
INFO:root:FL Epoch: 575 Normal Training
INFO:root:Worker: 317 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595386
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 317 Train Epoch: 1 [0/201 (0%)]	Loss: 0.553336
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 575 Norm Difference for worker 317 is 0.834739
INFO:root:FL Epoch: 575 Done on worker:317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 575 Training on worker :105
INFO:root:FL Epoch: 575 Using Learning rate : 0.015845308652814367 
INFO:root:FL Epoch: 575 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.612086
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.420972
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 575 Norm Difference for worker 105 is 0.864749
INFO:root:FL Epoch: 575 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 575 Training on worker :1425
INFO:root:FL Epoch: 575 Using Learning rate : 0.015845308652814367 
INFO:root:FL Epoch: 575 Normal Training
INFO:root:Worker: 1425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515691
INFO:root:Worker: 1425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291092
INFO:root:FL Epoch: 575 Norm Difference for worker 1425 is 0.817481
INFO:root:FL Epoch: 575 Done on worker:1425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 575 Training on worker :1249
INFO:root:FL Epoch: 575 Using Learning rate : 0.015845308652814367 
INFO:root:FL Epoch: 575 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455475
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692438
INFO:root:FL Epoch: 575 Norm Difference for worker 1249 is 0.84202
INFO:root:FL Epoch: 575 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 575 Training on worker :401
INFO:root:FL Epoch: 575 Using Learning rate : 0.015845308652814367 
INFO:root:FL Epoch: 575 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576737
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338824
INFO:root:FL Epoch: 575 Norm Difference for worker 401 is 0.743801
INFO:root:FL Epoch: 575 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 575 Training on worker :243
INFO:root:FL Epoch: 575 Using Learning rate : 0.015845308652814367 
INFO:root:FL Epoch: 575 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691219
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.365558
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 575 Norm Difference for worker 243 is 0.701975
INFO:root:FL Epoch: 575 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 575 Training on worker :53
INFO:root:FL Epoch: 575 Using Learning rate : 0.015845308652814367 
INFO:root:FL Epoch: 575 Normal Training
INFO:root:Worker: 53 Train Epoch: 0 [0/201 (0%)]	Loss: 0.365770
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 53 Train Epoch: 1 [0/201 (0%)]	Loss: 0.354614
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 575 Norm Difference for worker 53 is 0.735689
INFO:root:FL Epoch: 575 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 575 Training on worker :960
INFO:root:FL Epoch: 575 Using Learning rate : 0.015845308652814367 
INFO:root:FL Epoch: 575 Normal Training
INFO:root:Worker: 960 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542153
INFO:root:Worker: 960 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341600
INFO:root:FL Epoch: 575 Norm Difference for worker 960 is 0.773044
INFO:root:FL Epoch: 575 Done on worker:960
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 575 Training on worker :1525
INFO:root:FL Epoch: 575 Using Learning rate : 0.015845308652814367 
INFO:root:FL Epoch: 575 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459265
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428774
INFO:root:FL Epoch: 575 Norm Difference for worker 1525 is 0.819701
INFO:root:FL Epoch: 575 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 575 Training on worker :1533
INFO:root:FL Epoch: 575 Using Learning rate : 0.015845308652814367 
INFO:root:FL Epoch: 575 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570240
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234548
INFO:root:FL Epoch: 575 Norm Difference for worker 1533 is 0.731949
INFO:root:FL Epoch: 575 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 401
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 575 Ends   ===================
INFO:root:Epoch:575 Global Model Test Loss:0.4910682895604302 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:575 Global Model Backdoor Test Loss:0.10983138034741084                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 576 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 576 Workers Selected : [1397, 18, 956, 910, 205, 740, 1557, 1744, 425, 1208]
INFO:root:FL Epoch: 576 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 576 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 576 Training on worker :1397
INFO:root:FL Epoch: 576 Using Learning rate : 0.015813618035508736 
INFO:root:FL Epoch: 576 Normal Training
INFO:root:Worker: 1397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.897919
INFO:root:Worker: 1397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342324
INFO:root:FL Epoch: 576 Norm Difference for worker 1397 is 0.671635
INFO:root:FL Epoch: 576 Done on worker:1397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 576 Training on worker :18
INFO:root:FL Epoch: 576 Using Learning rate : 0.015813618035508736 
INFO:root:FL Epoch: 576 Normal Training
INFO:root:Worker: 18 Train Epoch: 0 [0/201 (0%)]	Loss: 0.496405
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 18 Train Epoch: 1 [0/201 (0%)]	Loss: 0.345671
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 576 Norm Difference for worker 18 is 0.65211
INFO:root:FL Epoch: 576 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 576 Training on worker :956
INFO:root:FL Epoch: 576 Using Learning rate : 0.015813618035508736 
INFO:root:FL Epoch: 576 Normal Training
INFO:root:Worker: 956 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696019
INFO:root:Worker: 956 Train Epoch: 1 [0/200 (0%)]	Loss: 0.907018
INFO:root:FL Epoch: 576 Norm Difference for worker 956 is 0.728783
INFO:root:FL Epoch: 576 Done on worker:956
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 576 Training on worker :910
INFO:root:FL Epoch: 576 Using Learning rate : 0.015813618035508736 
INFO:root:FL Epoch: 576 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414050
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524518
INFO:root:FL Epoch: 576 Norm Difference for worker 910 is 0.745788
INFO:root:FL Epoch: 576 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 576 Training on worker :205
INFO:root:FL Epoch: 576 Using Learning rate : 0.015813618035508736 
INFO:root:FL Epoch: 576 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.534951
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.294617
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 576 Norm Difference for worker 205 is 0.689558
INFO:root:FL Epoch: 576 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 576 Training on worker :740
INFO:root:FL Epoch: 576 Using Learning rate : 0.015813618035508736 
INFO:root:FL Epoch: 576 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626059
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361485
INFO:root:FL Epoch: 576 Norm Difference for worker 740 is 0.673389
INFO:root:FL Epoch: 576 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 576 Training on worker :1557
INFO:root:FL Epoch: 576 Using Learning rate : 0.015813618035508736 
INFO:root:FL Epoch: 576 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382647
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589106
INFO:root:FL Epoch: 576 Norm Difference for worker 1557 is 0.707585
INFO:root:FL Epoch: 576 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 576 Training on worker :1744
INFO:root:FL Epoch: 576 Using Learning rate : 0.015813618035508736 
INFO:root:FL Epoch: 576 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.800626
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443658
INFO:root:FL Epoch: 576 Norm Difference for worker 1744 is 0.676509
INFO:root:FL Epoch: 576 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 576 Training on worker :425
INFO:root:FL Epoch: 576 Using Learning rate : 0.015813618035508736 
INFO:root:FL Epoch: 576 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529504
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457028
INFO:root:FL Epoch: 576 Norm Difference for worker 425 is 0.759915
INFO:root:FL Epoch: 576 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 576 Training on worker :1208
INFO:root:FL Epoch: 576 Using Learning rate : 0.015813618035508736 
INFO:root:FL Epoch: 576 Normal Training
INFO:root:Worker: 1208 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678269
INFO:root:Worker: 1208 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263684
INFO:root:FL Epoch: 576 Norm Difference for worker 1208 is 0.699376
INFO:root:FL Epoch: 576 Done on worker:1208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1397
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 576 Ends   ===================
INFO:root:Epoch:576 Global Model Test Loss:0.49204669805134044 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:576 Global Model Backdoor Test Loss:0.18177099898457527                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 577 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 577 Workers Selected : [1407, 59, 1055, 261, 1932, 581, 1253, 23, 462, 1153]
INFO:root:FL Epoch: 577 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 577 Num points on workers: [200 201 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 577 Training on worker :1407
INFO:root:FL Epoch: 577 Using Learning rate : 0.015781990799437717 
INFO:root:FL Epoch: 577 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540271
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378243
INFO:root:FL Epoch: 577 Norm Difference for worker 1407 is 0.691434
INFO:root:FL Epoch: 577 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 577 Training on worker :59
INFO:root:FL Epoch: 577 Using Learning rate : 0.015781990799437717 
INFO:root:FL Epoch: 577 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.682497
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.393170
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 577 Norm Difference for worker 59 is 0.698846
INFO:root:FL Epoch: 577 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 577 Training on worker :1055
INFO:root:FL Epoch: 577 Using Learning rate : 0.015781990799437717 
INFO:root:FL Epoch: 577 Normal Training
INFO:root:Worker: 1055 Train Epoch: 0 [0/200 (0%)]	Loss: 0.272910
INFO:root:Worker: 1055 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440003
INFO:root:FL Epoch: 577 Norm Difference for worker 1055 is 0.637738
INFO:root:FL Epoch: 577 Done on worker:1055
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 577 Training on worker :261
INFO:root:FL Epoch: 577 Using Learning rate : 0.015781990799437717 
INFO:root:FL Epoch: 577 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.502127
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.801286
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 577 Norm Difference for worker 261 is 0.729606
INFO:root:FL Epoch: 577 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 577 Training on worker :1932
INFO:root:FL Epoch: 577 Using Learning rate : 0.015781990799437717 
INFO:root:FL Epoch: 577 Normal Training
INFO:root:Worker: 1932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500849
INFO:root:Worker: 1932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337465
INFO:root:FL Epoch: 577 Norm Difference for worker 1932 is 0.699283
INFO:root:FL Epoch: 577 Done on worker:1932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 577 Training on worker :581
INFO:root:FL Epoch: 577 Using Learning rate : 0.015781990799437717 
INFO:root:FL Epoch: 577 Normal Training
INFO:root:Worker: 581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588081
INFO:root:Worker: 581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474627
INFO:root:FL Epoch: 577 Norm Difference for worker 581 is 0.733497
INFO:root:FL Epoch: 577 Done on worker:581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 577 Training on worker :1253
INFO:root:FL Epoch: 577 Using Learning rate : 0.015781990799437717 
INFO:root:FL Epoch: 577 Normal Training
INFO:root:Worker: 1253 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645791
INFO:root:Worker: 1253 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381255
INFO:root:FL Epoch: 577 Norm Difference for worker 1253 is 0.726849
INFO:root:FL Epoch: 577 Done on worker:1253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 577 Training on worker :23
INFO:root:FL Epoch: 577 Using Learning rate : 0.015781990799437717 
INFO:root:FL Epoch: 577 Normal Training
INFO:root:Worker: 23 Train Epoch: 0 [0/201 (0%)]	Loss: 0.632629
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 23 Train Epoch: 1 [0/201 (0%)]	Loss: 0.423080
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 577 Norm Difference for worker 23 is 0.707478
INFO:root:FL Epoch: 577 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 577 Training on worker :462
INFO:root:FL Epoch: 577 Using Learning rate : 0.015781990799437717 
INFO:root:FL Epoch: 577 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.289469
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686819
INFO:root:FL Epoch: 577 Norm Difference for worker 462 is 0.697422
INFO:root:FL Epoch: 577 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 577 Training on worker :1153
INFO:root:FL Epoch: 577 Using Learning rate : 0.015781990799437717 
INFO:root:FL Epoch: 577 Normal Training
INFO:root:Worker: 1153 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374597
INFO:root:Worker: 1153 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415353
INFO:root:FL Epoch: 577 Norm Difference for worker 1153 is 0.707083
INFO:root:FL Epoch: 577 Done on worker:1153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1055
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 577 Ends   ===================
INFO:root:Epoch:577 Global Model Test Loss:0.4902247295660131 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:577 Global Model Backdoor Test Loss:0.14363131299614906                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 578 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 578 Workers Selected : [1066, 1905, 777, 1310, 1028, 1906, 169, 573, 888, 1462]
INFO:root:FL Epoch: 578 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 578 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 578 Training on worker :1066
INFO:root:FL Epoch: 578 Using Learning rate : 0.015750426817838843 
INFO:root:FL Epoch: 578 Normal Training
INFO:root:Worker: 1066 Train Epoch: 0 [0/200 (0%)]	Loss: 0.243076
INFO:root:Worker: 1066 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452753
INFO:root:FL Epoch: 578 Norm Difference for worker 1066 is 0.552228
INFO:root:FL Epoch: 578 Done on worker:1066
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 578 Training on worker :1905
INFO:root:FL Epoch: 578 Using Learning rate : 0.015750426817838843 
INFO:root:FL Epoch: 578 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.181169
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.213073
INFO:root:FL Epoch: 578 Norm Difference for worker 1905 is 0.453649
INFO:root:FL Epoch: 578 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 578 Training on worker :777
INFO:root:FL Epoch: 578 Using Learning rate : 0.015750426817838843 
INFO:root:FL Epoch: 578 Normal Training
INFO:root:Worker: 777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762234
INFO:root:Worker: 777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569414
INFO:root:FL Epoch: 578 Norm Difference for worker 777 is 0.694721
INFO:root:FL Epoch: 578 Done on worker:777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 578 Training on worker :1310
INFO:root:FL Epoch: 578 Using Learning rate : 0.015750426817838843 
INFO:root:FL Epoch: 578 Normal Training
INFO:root:Worker: 1310 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508536
INFO:root:Worker: 1310 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344282
INFO:root:FL Epoch: 578 Norm Difference for worker 1310 is 0.649937
INFO:root:FL Epoch: 578 Done on worker:1310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 578 Training on worker :1028
INFO:root:FL Epoch: 578 Using Learning rate : 0.015750426817838843 
INFO:root:FL Epoch: 578 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.800081
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617997
INFO:root:FL Epoch: 578 Norm Difference for worker 1028 is 0.679651
INFO:root:FL Epoch: 578 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 578 Training on worker :1906
INFO:root:FL Epoch: 578 Using Learning rate : 0.015750426817838843 
INFO:root:FL Epoch: 578 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536129
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385835
INFO:root:FL Epoch: 578 Norm Difference for worker 1906 is 0.63486
INFO:root:FL Epoch: 578 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 578 Training on worker :169
INFO:root:FL Epoch: 578 Using Learning rate : 0.015750426817838843 
INFO:root:FL Epoch: 578 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.580999
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.373441
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 578 Norm Difference for worker 169 is 0.625408
INFO:root:FL Epoch: 578 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 578 Training on worker :573
INFO:root:FL Epoch: 578 Using Learning rate : 0.015750426817838843 
INFO:root:FL Epoch: 578 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479960
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359694
INFO:root:FL Epoch: 578 Norm Difference for worker 573 is 0.60978
INFO:root:FL Epoch: 578 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 578 Training on worker :888
INFO:root:FL Epoch: 578 Using Learning rate : 0.015750426817838843 
INFO:root:FL Epoch: 578 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500906
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524316
INFO:root:FL Epoch: 578 Norm Difference for worker 888 is 0.661593
INFO:root:FL Epoch: 578 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 578 Training on worker :1462
INFO:root:FL Epoch: 578 Using Learning rate : 0.015750426817838843 
INFO:root:FL Epoch: 578 Normal Training
INFO:root:Worker: 1462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.767022
INFO:root:Worker: 1462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260345
INFO:root:FL Epoch: 578 Norm Difference for worker 1462 is 0.669014
INFO:root:FL Epoch: 578 Done on worker:1462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1905
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 578 Ends   ===================
INFO:root:Epoch:578 Global Model Test Loss:0.49791914224624634 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:578 Global Model Backdoor Test Loss:0.11804491529862086                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 579 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 579 Workers Selected : [1554, 794, 1231, 1576, 294, 838, 310, 790, 612, 300]
INFO:root:FL Epoch: 579 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 579 Num points on workers: [200 200 200 200 201 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 579 Training on worker :1554
INFO:root:FL Epoch: 579 Using Learning rate : 0.015718925964203167 
INFO:root:FL Epoch: 579 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.291256
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402648
INFO:root:FL Epoch: 579 Norm Difference for worker 1554 is 0.684528
INFO:root:FL Epoch: 579 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 579 Training on worker :794
INFO:root:FL Epoch: 579 Using Learning rate : 0.015718925964203167 
INFO:root:FL Epoch: 579 Normal Training
INFO:root:Worker: 794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450283
INFO:root:Worker: 794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354598
INFO:root:FL Epoch: 579 Norm Difference for worker 794 is 0.793559
INFO:root:FL Epoch: 579 Done on worker:794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 579 Training on worker :1231
INFO:root:FL Epoch: 579 Using Learning rate : 0.015718925964203167 
INFO:root:FL Epoch: 579 Normal Training
INFO:root:Worker: 1231 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590649
INFO:root:Worker: 1231 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234903
INFO:root:FL Epoch: 579 Norm Difference for worker 1231 is 0.680295
INFO:root:FL Epoch: 579 Done on worker:1231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 579 Training on worker :1576
INFO:root:FL Epoch: 579 Using Learning rate : 0.015718925964203167 
INFO:root:FL Epoch: 579 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666863
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228659
INFO:root:FL Epoch: 579 Norm Difference for worker 1576 is 0.728203
INFO:root:FL Epoch: 579 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 579 Training on worker :294
INFO:root:FL Epoch: 579 Using Learning rate : 0.015718925964203167 
INFO:root:FL Epoch: 579 Normal Training
INFO:root:Worker: 294 Train Epoch: 0 [0/201 (0%)]	Loss: 0.650538
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 294 Train Epoch: 1 [0/201 (0%)]	Loss: 0.508833
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 579 Norm Difference for worker 294 is 0.84601
INFO:root:FL Epoch: 579 Done on worker:294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 579 Training on worker :838
INFO:root:FL Epoch: 579 Using Learning rate : 0.015718925964203167 
INFO:root:FL Epoch: 579 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515569
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670365
INFO:root:FL Epoch: 579 Norm Difference for worker 838 is 0.794847
INFO:root:FL Epoch: 579 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 579 Training on worker :310
INFO:root:FL Epoch: 579 Using Learning rate : 0.015718925964203167 
INFO:root:FL Epoch: 579 Normal Training
INFO:root:Worker: 310 Train Epoch: 0 [0/201 (0%)]	Loss: 0.484885
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 310 Train Epoch: 1 [0/201 (0%)]	Loss: 0.326259
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 579 Norm Difference for worker 310 is 0.720449
INFO:root:FL Epoch: 579 Done on worker:310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 579 Training on worker :790
INFO:root:FL Epoch: 579 Using Learning rate : 0.015718925964203167 
INFO:root:FL Epoch: 579 Normal Training
INFO:root:Worker: 790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.258509
INFO:root:Worker: 790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563223
INFO:root:FL Epoch: 579 Norm Difference for worker 790 is 0.817244
INFO:root:FL Epoch: 579 Done on worker:790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 579 Training on worker :612
INFO:root:FL Epoch: 579 Using Learning rate : 0.015718925964203167 
INFO:root:FL Epoch: 579 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548878
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195312
INFO:root:FL Epoch: 579 Norm Difference for worker 612 is 0.755075
INFO:root:FL Epoch: 579 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 579 Training on worker :300
INFO:root:FL Epoch: 579 Using Learning rate : 0.015718925964203167 
INFO:root:FL Epoch: 579 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.705882
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.709086
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 579 Norm Difference for worker 300 is 0.756375
INFO:root:FL Epoch: 579 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1231
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 579 Ends   ===================
INFO:root:Epoch:579 Global Model Test Loss:0.49266498229082895 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:579 Global Model Backdoor Test Loss:0.12579807018240294                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 580 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 580 Workers Selected : [932, 1259, 1268, 1635, 1840, 651, 1586, 332, 1409, 1110]
INFO:root:FL Epoch: 580 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 580 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 580 Training on worker :932
INFO:root:FL Epoch: 580 Using Learning rate : 0.01568748811227476 
INFO:root:FL Epoch: 580 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469786
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383933
INFO:root:FL Epoch: 580 Norm Difference for worker 932 is 0.716966
INFO:root:FL Epoch: 580 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 580 Training on worker :1259
INFO:root:FL Epoch: 580 Using Learning rate : 0.01568748811227476 
INFO:root:FL Epoch: 580 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659958
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688279
INFO:root:FL Epoch: 580 Norm Difference for worker 1259 is 0.673612
INFO:root:FL Epoch: 580 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 580 Training on worker :1268
INFO:root:FL Epoch: 580 Using Learning rate : 0.01568748811227476 
INFO:root:FL Epoch: 580 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750091
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258181
INFO:root:FL Epoch: 580 Norm Difference for worker 1268 is 0.694831
INFO:root:FL Epoch: 580 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 580 Training on worker :1635
INFO:root:FL Epoch: 580 Using Learning rate : 0.01568748811227476 
INFO:root:FL Epoch: 580 Normal Training
INFO:root:Worker: 1635 Train Epoch: 0 [0/200 (0%)]	Loss: 0.193274
INFO:root:Worker: 1635 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446632
INFO:root:FL Epoch: 580 Norm Difference for worker 1635 is 0.659342
INFO:root:FL Epoch: 580 Done on worker:1635
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 580 Training on worker :1840
INFO:root:FL Epoch: 580 Using Learning rate : 0.01568748811227476 
INFO:root:FL Epoch: 580 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569416
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582470
INFO:root:FL Epoch: 580 Norm Difference for worker 1840 is 0.75599
INFO:root:FL Epoch: 580 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 580 Training on worker :651
INFO:root:FL Epoch: 580 Using Learning rate : 0.01568748811227476 
INFO:root:FL Epoch: 580 Normal Training
INFO:root:Worker: 651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650048
INFO:root:Worker: 651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454351
INFO:root:FL Epoch: 580 Norm Difference for worker 651 is 0.757144
INFO:root:FL Epoch: 580 Done on worker:651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 580 Training on worker :1586
INFO:root:FL Epoch: 580 Using Learning rate : 0.01568748811227476 
INFO:root:FL Epoch: 580 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772180
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493517
INFO:root:FL Epoch: 580 Norm Difference for worker 1586 is 0.707504
INFO:root:FL Epoch: 580 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 580 Training on worker :332
INFO:root:FL Epoch: 580 Using Learning rate : 0.01568748811227476 
INFO:root:FL Epoch: 580 Normal Training
INFO:root:Worker: 332 Train Epoch: 0 [0/201 (0%)]	Loss: 0.663189
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 332 Train Epoch: 1 [0/201 (0%)]	Loss: 0.587083
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 580 Norm Difference for worker 332 is 0.742697
INFO:root:FL Epoch: 580 Done on worker:332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 580 Training on worker :1409
INFO:root:FL Epoch: 580 Using Learning rate : 0.01568748811227476 
INFO:root:FL Epoch: 580 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383653
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384951
INFO:root:FL Epoch: 580 Norm Difference for worker 1409 is 0.711209
INFO:root:FL Epoch: 580 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 580 Training on worker :1110
INFO:root:FL Epoch: 580 Using Learning rate : 0.01568748811227476 
INFO:root:FL Epoch: 580 Normal Training
INFO:root:Worker: 1110 Train Epoch: 0 [0/200 (0%)]	Loss: 1.091281
INFO:root:Worker: 1110 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313971
INFO:root:FL Epoch: 580 Norm Difference for worker 1110 is 0.805851
INFO:root:FL Epoch: 580 Done on worker:1110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1259
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 580 Ends   ===================
INFO:root:Epoch:580 Global Model Test Loss:0.4826492141274845 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:580 Global Model Backdoor Test Loss:0.13123405973116556                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 581 Begins ===================
INFO:root:FL Epoch: 581 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 581 Workers Selected : [0, 1, 2, 1679, 116, 928, 1045, 563, 1144, 438]
INFO:root:FL Epoch: 581 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 581 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 581 Training on worker :0
INFO:root:FL Epoch: 581 Using Learning rate : 0.003131222627210042 
INFO:root:FL Epoch: 581 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.230969
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.109850
INFO:root:FL Epoch: 581 Worker: 0 Backdoor Test Loss: 0.12200302754839261 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 581 Worker: 0 Backdoor Train Loss: 0.14909277707338334 Backdoor Train Accuracy: 98.0
INFO:root:FL Epoch: 581 Norm Difference for worker 0 is 0.104628
INFO:root:FL Epoch: 581 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 581 Training on worker :1
INFO:root:FL Epoch: 581 Using Learning rate : 0.003131222627210042 
INFO:root:FL Epoch: 581 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.303078
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.148207
INFO:root:FL Epoch: 581 Worker: 1 Backdoor Test Loss: 0.11948236698905627 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 581 Worker: 1 Backdoor Train Loss: 0.1502017967402935 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 581 Norm Difference for worker 1 is 0.097333
INFO:root:FL Epoch: 581 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 581 Training on worker :2
INFO:root:FL Epoch: 581 Using Learning rate : 0.003131222627210042 
INFO:root:FL Epoch: 581 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.153508
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.181604
INFO:root:FL Epoch: 581 Worker: 2 Backdoor Test Loss: 0.12193496276934941 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 581 Worker: 2 Backdoor Train Loss: 0.14922931641340256 Backdoor Train Accuracy: 97.5
INFO:root:FL Epoch: 581 Norm Difference for worker 2 is 0.101554
INFO:root:FL Epoch: 581 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 581 Training on worker :1679
INFO:root:FL Epoch: 581 Using Learning rate : 0.01565611313605021 
INFO:root:FL Epoch: 581 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717447
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410742
INFO:root:FL Epoch: 581 Norm Difference for worker 1679 is 0.653172
INFO:root:FL Epoch: 581 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 581 Training on worker :116
INFO:root:FL Epoch: 581 Using Learning rate : 0.01565611313605021 
INFO:root:FL Epoch: 581 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.792853
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.617646
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 581 Norm Difference for worker 116 is 0.743757
INFO:root:FL Epoch: 581 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 581 Training on worker :928
INFO:root:FL Epoch: 581 Using Learning rate : 0.01565611313605021 
INFO:root:FL Epoch: 581 Normal Training
INFO:root:Worker: 928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673341
INFO:root:Worker: 928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291721
INFO:root:FL Epoch: 581 Norm Difference for worker 928 is 0.633049
INFO:root:FL Epoch: 581 Done on worker:928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 581 Training on worker :1045
INFO:root:FL Epoch: 581 Using Learning rate : 0.01565611313605021 
INFO:root:FL Epoch: 581 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.294362
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267605
INFO:root:FL Epoch: 581 Norm Difference for worker 1045 is 0.55049
INFO:root:FL Epoch: 581 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 581 Training on worker :563
INFO:root:FL Epoch: 581 Using Learning rate : 0.01565611313605021 
INFO:root:FL Epoch: 581 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450480
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271951
INFO:root:FL Epoch: 581 Norm Difference for worker 563 is 0.596018
INFO:root:FL Epoch: 581 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 581 Training on worker :1144
INFO:root:FL Epoch: 581 Using Learning rate : 0.01565611313605021 
INFO:root:FL Epoch: 581 Normal Training
INFO:root:Worker: 1144 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585568
INFO:root:Worker: 1144 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452708
INFO:root:FL Epoch: 581 Norm Difference for worker 1144 is 0.617668
INFO:root:FL Epoch: 581 Done on worker:1144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 581 Training on worker :438
INFO:root:FL Epoch: 581 Using Learning rate : 0.01565611313605021 
INFO:root:FL Epoch: 581 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482215
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385582
INFO:root:FL Epoch: 581 Norm Difference for worker 438 is 0.678582
INFO:root:FL Epoch: 581 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 581 Ends   ===================
INFO:root:Epoch:581 Global Model Test Loss:0.4817136981908013 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:581 Global Model Backdoor Test Loss:0.12193496276934941                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 582 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 582 Workers Selected : [305, 780, 1929, 1520, 481, 1295, 101, 560, 999, 452]
INFO:root:FL Epoch: 582 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 582 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 582 Training on worker :305
INFO:root:FL Epoch: 582 Using Learning rate : 0.015624800909778108 
INFO:root:FL Epoch: 582 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.375936
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.430180
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 582 Norm Difference for worker 305 is 0.623564
INFO:root:FL Epoch: 582 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 582 Training on worker :780
INFO:root:FL Epoch: 582 Using Learning rate : 0.015624800909778108 
INFO:root:FL Epoch: 582 Normal Training
INFO:root:Worker: 780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701318
INFO:root:Worker: 780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583839
INFO:root:FL Epoch: 582 Norm Difference for worker 780 is 0.719093
INFO:root:FL Epoch: 582 Done on worker:780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 582 Training on worker :1929
INFO:root:FL Epoch: 582 Using Learning rate : 0.015624800909778108 
INFO:root:FL Epoch: 582 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394039
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383035
INFO:root:FL Epoch: 582 Norm Difference for worker 1929 is 0.672768
INFO:root:FL Epoch: 582 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 582 Training on worker :1520
INFO:root:FL Epoch: 582 Using Learning rate : 0.015624800909778108 
INFO:root:FL Epoch: 582 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519543
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.711478
INFO:root:FL Epoch: 582 Norm Difference for worker 1520 is 0.686846
INFO:root:FL Epoch: 582 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 582 Training on worker :481
INFO:root:FL Epoch: 582 Using Learning rate : 0.015624800909778108 
INFO:root:FL Epoch: 582 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621778
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359452
INFO:root:FL Epoch: 582 Norm Difference for worker 481 is 0.672273
INFO:root:FL Epoch: 582 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 582 Training on worker :1295
INFO:root:FL Epoch: 582 Using Learning rate : 0.015624800909778108 
INFO:root:FL Epoch: 582 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344232
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496767
INFO:root:FL Epoch: 582 Norm Difference for worker 1295 is 0.60193
INFO:root:FL Epoch: 582 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 582 Training on worker :101
INFO:root:FL Epoch: 582 Using Learning rate : 0.015624800909778108 
INFO:root:FL Epoch: 582 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.360766
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.337551
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 582 Norm Difference for worker 101 is 0.694207
INFO:root:FL Epoch: 582 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 582 Training on worker :560
INFO:root:FL Epoch: 582 Using Learning rate : 0.015624800909778108 
INFO:root:FL Epoch: 582 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539433
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336729
INFO:root:FL Epoch: 582 Norm Difference for worker 560 is 0.675928
INFO:root:FL Epoch: 582 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 582 Training on worker :999
INFO:root:FL Epoch: 582 Using Learning rate : 0.015624800909778108 
INFO:root:FL Epoch: 582 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393310
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419299
INFO:root:FL Epoch: 582 Norm Difference for worker 999 is 0.688991
INFO:root:FL Epoch: 582 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 582 Training on worker :452
INFO:root:FL Epoch: 582 Using Learning rate : 0.015624800909778108 
INFO:root:FL Epoch: 582 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383138
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393482
INFO:root:FL Epoch: 582 Norm Difference for worker 452 is 0.732987
INFO:root:FL Epoch: 582 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 305
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 582 Ends   ===================
INFO:root:Epoch:582 Global Model Test Loss:0.480060793021146 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:582 Global Model Backdoor Test Loss:0.13496078426639238                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 583 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 583 Workers Selected : [1594, 712, 1782, 1693, 835, 153, 986, 618, 24, 1431]
INFO:root:FL Epoch: 583 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 583 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 583 Training on worker :1594
INFO:root:FL Epoch: 583 Using Learning rate : 0.015593551307958553 
INFO:root:FL Epoch: 583 Normal Training
INFO:root:Worker: 1594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531327
INFO:root:Worker: 1594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452616
INFO:root:FL Epoch: 583 Norm Difference for worker 1594 is 0.59765
INFO:root:FL Epoch: 583 Done on worker:1594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 583 Training on worker :712
INFO:root:FL Epoch: 583 Using Learning rate : 0.015593551307958553 
INFO:root:FL Epoch: 583 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366589
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417373
INFO:root:FL Epoch: 583 Norm Difference for worker 712 is 0.632503
INFO:root:FL Epoch: 583 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 583 Training on worker :1782
INFO:root:FL Epoch: 583 Using Learning rate : 0.015593551307958553 
INFO:root:FL Epoch: 583 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332597
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466450
INFO:root:FL Epoch: 583 Norm Difference for worker 1782 is 0.608532
INFO:root:FL Epoch: 583 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 583 Training on worker :1693
INFO:root:FL Epoch: 583 Using Learning rate : 0.015593551307958553 
INFO:root:FL Epoch: 583 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514764
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278443
INFO:root:FL Epoch: 583 Norm Difference for worker 1693 is 0.557131
INFO:root:FL Epoch: 583 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 583 Training on worker :835
INFO:root:FL Epoch: 583 Using Learning rate : 0.015593551307958553 
INFO:root:FL Epoch: 583 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511913
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348407
INFO:root:FL Epoch: 583 Norm Difference for worker 835 is 0.598891
INFO:root:FL Epoch: 583 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 583 Training on worker :153
INFO:root:FL Epoch: 583 Using Learning rate : 0.015593551307958553 
INFO:root:FL Epoch: 583 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.332263
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.292217
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 583 Norm Difference for worker 153 is 0.596828
INFO:root:FL Epoch: 583 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 583 Training on worker :986
INFO:root:FL Epoch: 583 Using Learning rate : 0.015593551307958553 
INFO:root:FL Epoch: 583 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459510
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478106
INFO:root:FL Epoch: 583 Norm Difference for worker 986 is 0.624161
INFO:root:FL Epoch: 583 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 583 Training on worker :618
INFO:root:FL Epoch: 583 Using Learning rate : 0.015593551307958553 
INFO:root:FL Epoch: 583 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.284299
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433736
INFO:root:FL Epoch: 583 Norm Difference for worker 618 is 0.622666
INFO:root:FL Epoch: 583 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 583 Training on worker :24
INFO:root:FL Epoch: 583 Using Learning rate : 0.015593551307958553 
INFO:root:FL Epoch: 583 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.468454
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.474149
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 583 Norm Difference for worker 24 is 0.627267
INFO:root:FL Epoch: 583 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 583 Training on worker :1431
INFO:root:FL Epoch: 583 Using Learning rate : 0.015593551307958553 
INFO:root:FL Epoch: 583 Normal Training
INFO:root:Worker: 1431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427005
INFO:root:Worker: 1431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378175
INFO:root:FL Epoch: 583 Norm Difference for worker 1431 is 0.608874
INFO:root:FL Epoch: 583 Done on worker:1431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1693
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 583 Ends   ===================
INFO:root:Epoch:583 Global Model Test Loss:0.48255329097018523 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:583 Global Model Backdoor Test Loss:0.12852189068992934                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 584 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 584 Workers Selected : [459, 540, 192, 1368, 424, 223, 444, 1119, 917, 1924]
INFO:root:FL Epoch: 584 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 584 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 584 Training on worker :459
INFO:root:FL Epoch: 584 Using Learning rate : 0.015562364205342636 
INFO:root:FL Epoch: 584 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655694
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539810
INFO:root:FL Epoch: 584 Norm Difference for worker 459 is 0.646768
INFO:root:FL Epoch: 584 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 584 Training on worker :540
INFO:root:FL Epoch: 584 Using Learning rate : 0.015562364205342636 
INFO:root:FL Epoch: 584 Normal Training
INFO:root:Worker: 540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517590
INFO:root:Worker: 540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661488
INFO:root:FL Epoch: 584 Norm Difference for worker 540 is 0.641518
INFO:root:FL Epoch: 584 Done on worker:540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 584 Training on worker :192
INFO:root:FL Epoch: 584 Using Learning rate : 0.015562364205342636 
INFO:root:FL Epoch: 584 Normal Training
INFO:root:Worker: 192 Train Epoch: 0 [0/201 (0%)]	Loss: 0.652429
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 192 Train Epoch: 1 [0/201 (0%)]	Loss: 0.361871
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 584 Norm Difference for worker 192 is 0.621139
INFO:root:FL Epoch: 584 Done on worker:192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 584 Training on worker :1368
INFO:root:FL Epoch: 584 Using Learning rate : 0.015562364205342636 
INFO:root:FL Epoch: 584 Normal Training
INFO:root:Worker: 1368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494282
INFO:root:Worker: 1368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528729
INFO:root:FL Epoch: 584 Norm Difference for worker 1368 is 0.608264
INFO:root:FL Epoch: 584 Done on worker:1368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 584 Training on worker :424
INFO:root:FL Epoch: 584 Using Learning rate : 0.015562364205342636 
INFO:root:FL Epoch: 584 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605033
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507961
INFO:root:FL Epoch: 584 Norm Difference for worker 424 is 0.637166
INFO:root:FL Epoch: 584 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 584 Training on worker :223
INFO:root:FL Epoch: 584 Using Learning rate : 0.015562364205342636 
INFO:root:FL Epoch: 584 Normal Training
INFO:root:Worker: 223 Train Epoch: 0 [0/201 (0%)]	Loss: 0.514071
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 223 Train Epoch: 1 [0/201 (0%)]	Loss: 0.667332
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 584 Norm Difference for worker 223 is 0.674397
INFO:root:FL Epoch: 584 Done on worker:223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 584 Training on worker :444
INFO:root:FL Epoch: 584 Using Learning rate : 0.015562364205342636 
INFO:root:FL Epoch: 584 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.876707
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352708
INFO:root:FL Epoch: 584 Norm Difference for worker 444 is 0.647057
INFO:root:FL Epoch: 584 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 584 Training on worker :1119
INFO:root:FL Epoch: 584 Using Learning rate : 0.015562364205342636 
INFO:root:FL Epoch: 584 Normal Training
INFO:root:Worker: 1119 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350405
INFO:root:Worker: 1119 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497433
INFO:root:FL Epoch: 584 Norm Difference for worker 1119 is 0.599368
INFO:root:FL Epoch: 584 Done on worker:1119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 584 Training on worker :917
INFO:root:FL Epoch: 584 Using Learning rate : 0.015562364205342636 
INFO:root:FL Epoch: 584 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667495
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613671
INFO:root:FL Epoch: 584 Norm Difference for worker 917 is 0.686481
INFO:root:FL Epoch: 584 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 584 Training on worker :1924
INFO:root:FL Epoch: 584 Using Learning rate : 0.015562364205342636 
INFO:root:FL Epoch: 584 Normal Training
INFO:root:Worker: 1924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462066
INFO:root:Worker: 1924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480484
INFO:root:FL Epoch: 584 Norm Difference for worker 1924 is 0.599264
INFO:root:FL Epoch: 584 Done on worker:1924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1368
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 584 Ends   ===================
INFO:root:Epoch:584 Global Model Test Loss:0.48820968059932485 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:584 Global Model Backdoor Test Loss:0.1577487476170063                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 585 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 585 Workers Selected : [1334, 1921, 1397, 757, 1041, 1479, 1249, 1807, 357, 1506]
INFO:root:FL Epoch: 585 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 585 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 585 Training on worker :1334
INFO:root:FL Epoch: 585 Using Learning rate : 0.015531239476931953 
INFO:root:FL Epoch: 585 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609705
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314571
INFO:root:FL Epoch: 585 Norm Difference for worker 1334 is 0.597348
INFO:root:FL Epoch: 585 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 585 Training on worker :1921
INFO:root:FL Epoch: 585 Using Learning rate : 0.015531239476931953 
INFO:root:FL Epoch: 585 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499614
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519468
INFO:root:FL Epoch: 585 Norm Difference for worker 1921 is 0.635287
INFO:root:FL Epoch: 585 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 585 Training on worker :1397
INFO:root:FL Epoch: 585 Using Learning rate : 0.015531239476931953 
INFO:root:FL Epoch: 585 Normal Training
INFO:root:Worker: 1397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511716
INFO:root:Worker: 1397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406400
INFO:root:FL Epoch: 585 Norm Difference for worker 1397 is 0.493272
INFO:root:FL Epoch: 585 Done on worker:1397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 585 Training on worker :757
INFO:root:FL Epoch: 585 Using Learning rate : 0.015531239476931953 
INFO:root:FL Epoch: 585 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377833
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533755
INFO:root:FL Epoch: 585 Norm Difference for worker 757 is 0.634543
INFO:root:FL Epoch: 585 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 585 Training on worker :1041
INFO:root:FL Epoch: 585 Using Learning rate : 0.015531239476931953 
INFO:root:FL Epoch: 585 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581684
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530272
INFO:root:FL Epoch: 585 Norm Difference for worker 1041 is 0.618079
INFO:root:FL Epoch: 585 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 585 Training on worker :1479
INFO:root:FL Epoch: 585 Using Learning rate : 0.015531239476931953 
INFO:root:FL Epoch: 585 Normal Training
INFO:root:Worker: 1479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504106
INFO:root:Worker: 1479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226759
INFO:root:FL Epoch: 585 Norm Difference for worker 1479 is 0.591623
INFO:root:FL Epoch: 585 Done on worker:1479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 585 Training on worker :1249
INFO:root:FL Epoch: 585 Using Learning rate : 0.015531239476931953 
INFO:root:FL Epoch: 585 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717558
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493628
INFO:root:FL Epoch: 585 Norm Difference for worker 1249 is 0.688932
INFO:root:FL Epoch: 585 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 585 Training on worker :1807
INFO:root:FL Epoch: 585 Using Learning rate : 0.015531239476931953 
INFO:root:FL Epoch: 585 Normal Training
INFO:root:Worker: 1807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640036
INFO:root:Worker: 1807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341346
INFO:root:FL Epoch: 585 Norm Difference for worker 1807 is 0.599107
INFO:root:FL Epoch: 585 Done on worker:1807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 585 Training on worker :357
INFO:root:FL Epoch: 585 Using Learning rate : 0.015531239476931953 
INFO:root:FL Epoch: 585 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.282193
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331124
INFO:root:FL Epoch: 585 Norm Difference for worker 357 is 0.573593
INFO:root:FL Epoch: 585 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 585 Training on worker :1506
INFO:root:FL Epoch: 585 Using Learning rate : 0.015531239476931953 
INFO:root:FL Epoch: 585 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523338
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371479
INFO:root:FL Epoch: 585 Norm Difference for worker 1506 is 0.504704
INFO:root:FL Epoch: 585 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1397
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 585 Ends   ===================
INFO:root:Epoch:585 Global Model Test Loss:0.4847427115720861 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:585 Global Model Backdoor Test Loss:0.15250408773620924                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 586 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 586 Workers Selected : [546, 1815, 707, 353, 765, 248, 1947, 1395, 1735, 1729]
INFO:root:FL Epoch: 586 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 586 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 586 Training on worker :546
INFO:root:FL Epoch: 586 Using Learning rate : 0.015500176997978087 
INFO:root:FL Epoch: 586 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.318957
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346363
INFO:root:FL Epoch: 586 Norm Difference for worker 546 is 0.661237
INFO:root:FL Epoch: 586 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 586 Training on worker :1815
INFO:root:FL Epoch: 586 Using Learning rate : 0.015500176997978087 
INFO:root:FL Epoch: 586 Normal Training
INFO:root:Worker: 1815 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408149
INFO:root:Worker: 1815 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399535
INFO:root:FL Epoch: 586 Norm Difference for worker 1815 is 0.623537
INFO:root:FL Epoch: 586 Done on worker:1815
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 586 Training on worker :707
INFO:root:FL Epoch: 586 Using Learning rate : 0.015500176997978087 
INFO:root:FL Epoch: 586 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691607
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486046
INFO:root:FL Epoch: 586 Norm Difference for worker 707 is 0.655405
INFO:root:FL Epoch: 586 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 586 Training on worker :353
INFO:root:FL Epoch: 586 Using Learning rate : 0.015500176997978087 
INFO:root:FL Epoch: 586 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517456
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661097
INFO:root:FL Epoch: 586 Norm Difference for worker 353 is 0.642636
INFO:root:FL Epoch: 586 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 586 Training on worker :765
INFO:root:FL Epoch: 586 Using Learning rate : 0.015500176997978087 
INFO:root:FL Epoch: 586 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377894
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343545
INFO:root:FL Epoch: 586 Norm Difference for worker 765 is 0.675784
INFO:root:FL Epoch: 586 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 586 Training on worker :248
INFO:root:FL Epoch: 586 Using Learning rate : 0.015500176997978087 
INFO:root:FL Epoch: 586 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.354391
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.422497
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 586 Norm Difference for worker 248 is 0.654211
INFO:root:FL Epoch: 586 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 586 Training on worker :1947
INFO:root:FL Epoch: 586 Using Learning rate : 0.015500176997978087 
INFO:root:FL Epoch: 586 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.221525
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216481
INFO:root:FL Epoch: 586 Norm Difference for worker 1947 is 0.521967
INFO:root:FL Epoch: 586 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 586 Training on worker :1395
INFO:root:FL Epoch: 586 Using Learning rate : 0.015500176997978087 
INFO:root:FL Epoch: 586 Normal Training
INFO:root:Worker: 1395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315404
INFO:root:Worker: 1395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292168
INFO:root:FL Epoch: 586 Norm Difference for worker 1395 is 0.659347
INFO:root:FL Epoch: 586 Done on worker:1395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 586 Training on worker :1735
INFO:root:FL Epoch: 586 Using Learning rate : 0.015500176997978087 
INFO:root:FL Epoch: 586 Normal Training
INFO:root:Worker: 1735 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646749
INFO:root:Worker: 1735 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509926
INFO:root:FL Epoch: 586 Norm Difference for worker 1735 is 0.66346
INFO:root:FL Epoch: 586 Done on worker:1735
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 586 Training on worker :1729
INFO:root:FL Epoch: 586 Using Learning rate : 0.015500176997978087 
INFO:root:FL Epoch: 586 Normal Training
INFO:root:Worker: 1729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496428
INFO:root:Worker: 1729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466118
INFO:root:FL Epoch: 586 Norm Difference for worker 1729 is 0.731653
INFO:root:FL Epoch: 586 Done on worker:1729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1947
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 586 Ends   ===================
INFO:root:Epoch:586 Global Model Test Loss:0.48648401919533224 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:586 Global Model Backdoor Test Loss:0.12022701899210612                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 587 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 587 Workers Selected : [134, 1507, 700, 1293, 1148, 473, 855, 1266, 170, 422]
INFO:root:FL Epoch: 587 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 587 Num points on workers: [201 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 587 Training on worker :134
INFO:root:FL Epoch: 587 Using Learning rate : 0.015469176643982131 
INFO:root:FL Epoch: 587 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.404081
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.292579
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 587 Norm Difference for worker 134 is 0.73934
INFO:root:FL Epoch: 587 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 587 Training on worker :1507
INFO:root:FL Epoch: 587 Using Learning rate : 0.015469176643982131 
INFO:root:FL Epoch: 587 Normal Training
INFO:root:Worker: 1507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372147
INFO:root:Worker: 1507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509257
INFO:root:FL Epoch: 587 Norm Difference for worker 1507 is 0.810114
INFO:root:FL Epoch: 587 Done on worker:1507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 587 Training on worker :700
INFO:root:FL Epoch: 587 Using Learning rate : 0.015469176643982131 
INFO:root:FL Epoch: 587 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.292082
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475861
INFO:root:FL Epoch: 587 Norm Difference for worker 700 is 0.818835
INFO:root:FL Epoch: 587 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 587 Training on worker :1293
INFO:root:FL Epoch: 587 Using Learning rate : 0.015469176643982131 
INFO:root:FL Epoch: 587 Normal Training
INFO:root:Worker: 1293 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698293
INFO:root:Worker: 1293 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395128
INFO:root:FL Epoch: 587 Norm Difference for worker 1293 is 0.787446
INFO:root:FL Epoch: 587 Done on worker:1293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 587 Training on worker :1148
INFO:root:FL Epoch: 587 Using Learning rate : 0.015469176643982131 
INFO:root:FL Epoch: 587 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.982417
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.766266
INFO:root:FL Epoch: 587 Norm Difference for worker 1148 is 0.78179
INFO:root:FL Epoch: 587 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 587 Training on worker :473
INFO:root:FL Epoch: 587 Using Learning rate : 0.015469176643982131 
INFO:root:FL Epoch: 587 Normal Training
INFO:root:Worker: 473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542786
INFO:root:Worker: 473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366735
INFO:root:FL Epoch: 587 Norm Difference for worker 473 is 0.763268
INFO:root:FL Epoch: 587 Done on worker:473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 587 Training on worker :855
INFO:root:FL Epoch: 587 Using Learning rate : 0.015469176643982131 
INFO:root:FL Epoch: 587 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804430
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597620
INFO:root:FL Epoch: 587 Norm Difference for worker 855 is 0.800209
INFO:root:FL Epoch: 587 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 587 Training on worker :1266
INFO:root:FL Epoch: 587 Using Learning rate : 0.015469176643982131 
INFO:root:FL Epoch: 587 Normal Training
INFO:root:Worker: 1266 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546343
INFO:root:Worker: 1266 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587902
INFO:root:FL Epoch: 587 Norm Difference for worker 1266 is 0.806933
INFO:root:FL Epoch: 587 Done on worker:1266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 587 Training on worker :170
INFO:root:FL Epoch: 587 Using Learning rate : 0.015469176643982131 
INFO:root:FL Epoch: 587 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.423507
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419092
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 587 Norm Difference for worker 170 is 0.726813
INFO:root:FL Epoch: 587 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 587 Training on worker :422
INFO:root:FL Epoch: 587 Using Learning rate : 0.015469176643982131 
INFO:root:FL Epoch: 587 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.265013
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426656
INFO:root:FL Epoch: 587 Norm Difference for worker 422 is 0.731021
INFO:root:FL Epoch: 587 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 170
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 587 Ends   ===================
INFO:root:Epoch:587 Global Model Test Loss:0.4747031260939205 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:587 Global Model Backdoor Test Loss:0.12134963522354762                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 588 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 588 Workers Selected : [832, 1256, 1254, 1459, 72, 786, 887, 1099, 1137, 333]
INFO:root:FL Epoch: 588 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 588 Num points on workers: [200 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 588 Training on worker :832
INFO:root:FL Epoch: 588 Using Learning rate : 0.015438238290694168 
INFO:root:FL Epoch: 588 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758856
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331215
INFO:root:FL Epoch: 588 Norm Difference for worker 832 is 0.741337
INFO:root:FL Epoch: 588 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 588 Training on worker :1256
INFO:root:FL Epoch: 588 Using Learning rate : 0.015438238290694168 
INFO:root:FL Epoch: 588 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498818
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545532
INFO:root:FL Epoch: 588 Norm Difference for worker 1256 is 0.745722
INFO:root:FL Epoch: 588 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 588 Training on worker :1254
INFO:root:FL Epoch: 588 Using Learning rate : 0.015438238290694168 
INFO:root:FL Epoch: 588 Normal Training
INFO:root:Worker: 1254 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617687
INFO:root:Worker: 1254 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582333
INFO:root:FL Epoch: 588 Norm Difference for worker 1254 is 0.633142
INFO:root:FL Epoch: 588 Done on worker:1254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 588 Training on worker :1459
INFO:root:FL Epoch: 588 Using Learning rate : 0.015438238290694168 
INFO:root:FL Epoch: 588 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554958
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.863523
INFO:root:FL Epoch: 588 Norm Difference for worker 1459 is 0.773979
INFO:root:FL Epoch: 588 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 588 Training on worker :72
INFO:root:FL Epoch: 588 Using Learning rate : 0.015438238290694168 
INFO:root:FL Epoch: 588 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.510872
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.499518
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 588 Norm Difference for worker 72 is 0.669068
INFO:root:FL Epoch: 588 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 588 Training on worker :786
INFO:root:FL Epoch: 588 Using Learning rate : 0.015438238290694168 
INFO:root:FL Epoch: 588 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.882509
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598664
INFO:root:FL Epoch: 588 Norm Difference for worker 786 is 0.728271
INFO:root:FL Epoch: 588 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 588 Training on worker :887
INFO:root:FL Epoch: 588 Using Learning rate : 0.015438238290694168 
INFO:root:FL Epoch: 588 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550658
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444795
INFO:root:FL Epoch: 588 Norm Difference for worker 887 is 0.709455
INFO:root:FL Epoch: 588 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 588 Training on worker :1099
INFO:root:FL Epoch: 588 Using Learning rate : 0.015438238290694168 
INFO:root:FL Epoch: 588 Normal Training
INFO:root:Worker: 1099 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627172
INFO:root:Worker: 1099 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538139
INFO:root:FL Epoch: 588 Norm Difference for worker 1099 is 0.698292
INFO:root:FL Epoch: 588 Done on worker:1099
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 588 Training on worker :1137
INFO:root:FL Epoch: 588 Using Learning rate : 0.015438238290694168 
INFO:root:FL Epoch: 588 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491722
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368770
INFO:root:FL Epoch: 588 Norm Difference for worker 1137 is 0.723005
INFO:root:FL Epoch: 588 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 588 Training on worker :333
INFO:root:FL Epoch: 588 Using Learning rate : 0.015438238290694168 
INFO:root:FL Epoch: 588 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.615750
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.493559
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 588 Norm Difference for worker 333 is 0.61133
INFO:root:FL Epoch: 588 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 333
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 588 Ends   ===================
INFO:root:Epoch:588 Global Model Test Loss:0.48406975058948293 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:588 Global Model Backdoor Test Loss:0.17446277290582657                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 589 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 589 Workers Selected : [1513, 991, 1679, 1102, 716, 905, 546, 26, 1404, 1045]
INFO:root:FL Epoch: 589 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 589 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 589 Training on worker :1513
INFO:root:FL Epoch: 589 Using Learning rate : 0.015407361814112779 
INFO:root:FL Epoch: 589 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406174
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639427
INFO:root:FL Epoch: 589 Norm Difference for worker 1513 is 0.604504
INFO:root:FL Epoch: 589 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 589 Training on worker :991
INFO:root:FL Epoch: 589 Using Learning rate : 0.015407361814112779 
INFO:root:FL Epoch: 589 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553234
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650714
INFO:root:FL Epoch: 589 Norm Difference for worker 991 is 0.682242
INFO:root:FL Epoch: 589 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 589 Training on worker :1679
INFO:root:FL Epoch: 589 Using Learning rate : 0.015407361814112779 
INFO:root:FL Epoch: 589 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454987
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545125
INFO:root:FL Epoch: 589 Norm Difference for worker 1679 is 0.690063
INFO:root:FL Epoch: 589 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 589 Training on worker :1102
INFO:root:FL Epoch: 589 Using Learning rate : 0.015407361814112779 
INFO:root:FL Epoch: 589 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559745
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392611
INFO:root:FL Epoch: 589 Norm Difference for worker 1102 is 0.665479
INFO:root:FL Epoch: 589 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 589 Training on worker :716
INFO:root:FL Epoch: 589 Using Learning rate : 0.015407361814112779 
INFO:root:FL Epoch: 589 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652658
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389428
INFO:root:FL Epoch: 589 Norm Difference for worker 716 is 0.6018
INFO:root:FL Epoch: 589 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 589 Training on worker :905
INFO:root:FL Epoch: 589 Using Learning rate : 0.015407361814112779 
INFO:root:FL Epoch: 589 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493666
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583714
INFO:root:FL Epoch: 589 Norm Difference for worker 905 is 0.677108
INFO:root:FL Epoch: 589 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 589 Training on worker :546
INFO:root:FL Epoch: 589 Using Learning rate : 0.015407361814112779 
INFO:root:FL Epoch: 589 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689849
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523727
INFO:root:FL Epoch: 589 Norm Difference for worker 546 is 0.644548
INFO:root:FL Epoch: 589 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 589 Training on worker :26
INFO:root:FL Epoch: 589 Using Learning rate : 0.015407361814112779 
INFO:root:FL Epoch: 589 Normal Training
INFO:root:Worker: 26 Train Epoch: 0 [0/201 (0%)]	Loss: 0.678349
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 26 Train Epoch: 1 [0/201 (0%)]	Loss: 0.295510
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 589 Norm Difference for worker 26 is 0.603912
INFO:root:FL Epoch: 589 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 589 Training on worker :1404
INFO:root:FL Epoch: 589 Using Learning rate : 0.015407361814112779 
INFO:root:FL Epoch: 589 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430274
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407471
INFO:root:FL Epoch: 589 Norm Difference for worker 1404 is 0.598149
INFO:root:FL Epoch: 589 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 589 Training on worker :1045
INFO:root:FL Epoch: 589 Using Learning rate : 0.015407361814112779 
INFO:root:FL Epoch: 589 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386811
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612271
INFO:root:FL Epoch: 589 Norm Difference for worker 1045 is 0.551544
INFO:root:FL Epoch: 589 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1045
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 589 Ends   ===================
INFO:root:Epoch:589 Global Model Test Loss:0.48088397523936105 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:589 Global Model Backdoor Test Loss:0.11682718619704247                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 590 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 590 Workers Selected : [481, 1862, 29, 100, 807, 1488, 787, 447, 839, 251]
INFO:root:FL Epoch: 590 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 590 Num points on workers: [200 200 201 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 590 Training on worker :481
INFO:root:FL Epoch: 590 Using Learning rate : 0.015376547090484553 
INFO:root:FL Epoch: 590 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377432
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416006
INFO:root:FL Epoch: 590 Norm Difference for worker 481 is 0.705171
INFO:root:FL Epoch: 590 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 590 Training on worker :1862
INFO:root:FL Epoch: 590 Using Learning rate : 0.015376547090484553 
INFO:root:FL Epoch: 590 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431049
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331189
INFO:root:FL Epoch: 590 Norm Difference for worker 1862 is 0.696094
INFO:root:FL Epoch: 590 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 590 Training on worker :29
INFO:root:FL Epoch: 590 Using Learning rate : 0.015376547090484553 
INFO:root:FL Epoch: 590 Normal Training
INFO:root:Worker: 29 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503649
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 29 Train Epoch: 1 [0/201 (0%)]	Loss: 0.369051
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 590 Norm Difference for worker 29 is 0.744864
INFO:root:FL Epoch: 590 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 590 Training on worker :100
INFO:root:FL Epoch: 590 Using Learning rate : 0.015376547090484553 
INFO:root:FL Epoch: 590 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693564
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.337562
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 590 Norm Difference for worker 100 is 0.676955
INFO:root:FL Epoch: 590 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 590 Training on worker :807
INFO:root:FL Epoch: 590 Using Learning rate : 0.015376547090484553 
INFO:root:FL Epoch: 590 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531381
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285903
INFO:root:FL Epoch: 590 Norm Difference for worker 807 is 0.695572
INFO:root:FL Epoch: 590 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 590 Training on worker :1488
INFO:root:FL Epoch: 590 Using Learning rate : 0.015376547090484553 
INFO:root:FL Epoch: 590 Normal Training
INFO:root:Worker: 1488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415093
INFO:root:Worker: 1488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609816
INFO:root:FL Epoch: 590 Norm Difference for worker 1488 is 0.681767
INFO:root:FL Epoch: 590 Done on worker:1488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 590 Training on worker :787
INFO:root:FL Epoch: 590 Using Learning rate : 0.015376547090484553 
INFO:root:FL Epoch: 590 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469197
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429216
INFO:root:FL Epoch: 590 Norm Difference for worker 787 is 0.707725
INFO:root:FL Epoch: 590 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 590 Training on worker :447
INFO:root:FL Epoch: 590 Using Learning rate : 0.015376547090484553 
INFO:root:FL Epoch: 590 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423622
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.757753
INFO:root:FL Epoch: 590 Norm Difference for worker 447 is 0.720869
INFO:root:FL Epoch: 590 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 590 Training on worker :839
INFO:root:FL Epoch: 590 Using Learning rate : 0.015376547090484553 
INFO:root:FL Epoch: 590 Normal Training
INFO:root:Worker: 839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.265520
INFO:root:Worker: 839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351647
INFO:root:FL Epoch: 590 Norm Difference for worker 839 is 0.652784
INFO:root:FL Epoch: 590 Done on worker:839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 590 Training on worker :251
INFO:root:FL Epoch: 590 Using Learning rate : 0.015376547090484553 
INFO:root:FL Epoch: 590 Normal Training
INFO:root:Worker: 251 Train Epoch: 0 [0/201 (0%)]	Loss: 0.598641
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 251 Train Epoch: 1 [0/201 (0%)]	Loss: 0.299445
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 590 Norm Difference for worker 251 is 0.693505
INFO:root:FL Epoch: 590 Done on worker:251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1488
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 590 Ends   ===================
INFO:root:Epoch:590 Global Model Test Loss:0.4821644548107596 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:590 Global Model Backdoor Test Loss:0.15380574141939482                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 591 Begins ===================
INFO:root:FL Epoch: 591 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 591 Workers Selected : [0, 1, 2, 586, 541, 389, 613, 1869, 1176, 937]
INFO:root:FL Epoch: 591 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 591 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 591 Training on worker :0
INFO:root:FL Epoch: 591 Using Learning rate : 0.003069158799260717 
INFO:root:FL Epoch: 591 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.224691
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.162839
INFO:root:FL Epoch: 591 Worker: 0 Backdoor Test Loss: 0.13676601896683374 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 591 Worker: 0 Backdoor Train Loss: 0.1477967992424965 Backdoor Train Accuracy: 98.0
INFO:root:FL Epoch: 591 Norm Difference for worker 0 is 0.092628
INFO:root:FL Epoch: 591 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 591 Training on worker :1
INFO:root:FL Epoch: 591 Using Learning rate : 0.003069158799260717 
INFO:root:FL Epoch: 591 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.116184
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.157568
INFO:root:FL Epoch: 591 Worker: 1 Backdoor Test Loss: 0.13519640266895294 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 591 Worker: 1 Backdoor Train Loss: 0.14702953025698662 Backdoor Train Accuracy: 98.0
INFO:root:FL Epoch: 591 Norm Difference for worker 1 is 0.098242
INFO:root:FL Epoch: 591 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 591 Training on worker :2
INFO:root:FL Epoch: 591 Using Learning rate : 0.003069158799260717 
INFO:root:FL Epoch: 591 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.148249
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.153484
INFO:root:FL Epoch: 591 Worker: 2 Backdoor Test Loss: 0.1363554373383522 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 591 Worker: 2 Backdoor Train Loss: 0.14773271456360818 Backdoor Train Accuracy: 98.0
INFO:root:FL Epoch: 591 Norm Difference for worker 2 is 0.093624
INFO:root:FL Epoch: 591 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 591 Training on worker :586
INFO:root:FL Epoch: 591 Using Learning rate : 0.015345793996303585 
INFO:root:FL Epoch: 591 Normal Training
INFO:root:Worker: 586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583388
INFO:root:Worker: 586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337243
INFO:root:FL Epoch: 591 Norm Difference for worker 586 is 0.616381
INFO:root:FL Epoch: 591 Done on worker:586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 591 Training on worker :541
INFO:root:FL Epoch: 591 Using Learning rate : 0.015345793996303585 
INFO:root:FL Epoch: 591 Normal Training
INFO:root:Worker: 541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.297623
INFO:root:Worker: 541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410501
INFO:root:FL Epoch: 591 Norm Difference for worker 541 is 0.612625
INFO:root:FL Epoch: 591 Done on worker:541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 591 Training on worker :389
INFO:root:FL Epoch: 591 Using Learning rate : 0.015345793996303585 
INFO:root:FL Epoch: 591 Normal Training
INFO:root:Worker: 389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463995
INFO:root:Worker: 389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391421
INFO:root:FL Epoch: 591 Norm Difference for worker 389 is 0.634905
INFO:root:FL Epoch: 591 Done on worker:389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 591 Training on worker :613
INFO:root:FL Epoch: 591 Using Learning rate : 0.015345793996303585 
INFO:root:FL Epoch: 591 Normal Training
INFO:root:Worker: 613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669266
INFO:root:Worker: 613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486638
INFO:root:FL Epoch: 591 Norm Difference for worker 613 is 0.653674
INFO:root:FL Epoch: 591 Done on worker:613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 591 Training on worker :1869
INFO:root:FL Epoch: 591 Using Learning rate : 0.015345793996303585 
INFO:root:FL Epoch: 591 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599311
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451050
INFO:root:FL Epoch: 591 Norm Difference for worker 1869 is 0.605943
INFO:root:FL Epoch: 591 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 591 Training on worker :1176
INFO:root:FL Epoch: 591 Using Learning rate : 0.015345793996303585 
INFO:root:FL Epoch: 591 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544979
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275302
INFO:root:FL Epoch: 591 Norm Difference for worker 1176 is 0.502332
INFO:root:FL Epoch: 591 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 591 Training on worker :937
INFO:root:FL Epoch: 591 Using Learning rate : 0.015345793996303585 
INFO:root:FL Epoch: 591 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347267
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416598
INFO:root:FL Epoch: 591 Norm Difference for worker 937 is 0.627913
INFO:root:FL Epoch: 591 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 591 Ends   ===================
INFO:root:Epoch:591 Global Model Test Loss:0.4829318155260647 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:591 Global Model Backdoor Test Loss:0.13676601896683374                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 592 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 592 Workers Selected : [70, 1309, 1645, 252, 695, 1298, 1816, 1469, 1559, 596]
INFO:root:FL Epoch: 592 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 592 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 592 Training on worker :70
INFO:root:FL Epoch: 592 Using Learning rate : 0.015315102408310978 
INFO:root:FL Epoch: 592 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.403635
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.432535
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 592 Norm Difference for worker 70 is 0.585535
INFO:root:FL Epoch: 592 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 592 Training on worker :1309
INFO:root:FL Epoch: 592 Using Learning rate : 0.015315102408310978 
INFO:root:FL Epoch: 592 Normal Training
INFO:root:Worker: 1309 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296985
INFO:root:Worker: 1309 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339417
INFO:root:FL Epoch: 592 Norm Difference for worker 1309 is 0.637751
INFO:root:FL Epoch: 592 Done on worker:1309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 592 Training on worker :1645
INFO:root:FL Epoch: 592 Using Learning rate : 0.015315102408310978 
INFO:root:FL Epoch: 592 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630158
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437178
INFO:root:FL Epoch: 592 Norm Difference for worker 1645 is 0.665183
INFO:root:FL Epoch: 592 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 592 Training on worker :252
INFO:root:FL Epoch: 592 Using Learning rate : 0.015315102408310978 
INFO:root:FL Epoch: 592 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.411924
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.357269
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 592 Norm Difference for worker 252 is 0.621014
INFO:root:FL Epoch: 592 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 592 Training on worker :695
INFO:root:FL Epoch: 592 Using Learning rate : 0.015315102408310978 
INFO:root:FL Epoch: 592 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546980
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.719751
INFO:root:FL Epoch: 592 Norm Difference for worker 695 is 0.598292
INFO:root:FL Epoch: 592 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 592 Training on worker :1298
INFO:root:FL Epoch: 592 Using Learning rate : 0.015315102408310978 
INFO:root:FL Epoch: 592 Normal Training
INFO:root:Worker: 1298 Train Epoch: 0 [0/200 (0%)]	Loss: 0.258681
INFO:root:Worker: 1298 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474280
INFO:root:FL Epoch: 592 Norm Difference for worker 1298 is 0.634222
INFO:root:FL Epoch: 592 Done on worker:1298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 592 Training on worker :1816
INFO:root:FL Epoch: 592 Using Learning rate : 0.015315102408310978 
INFO:root:FL Epoch: 592 Normal Training
INFO:root:Worker: 1816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473793
INFO:root:Worker: 1816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528552
INFO:root:FL Epoch: 592 Norm Difference for worker 1816 is 0.623642
INFO:root:FL Epoch: 592 Done on worker:1816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 592 Training on worker :1469
INFO:root:FL Epoch: 592 Using Learning rate : 0.015315102408310978 
INFO:root:FL Epoch: 592 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552942
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604116
INFO:root:FL Epoch: 592 Norm Difference for worker 1469 is 0.676785
INFO:root:FL Epoch: 592 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 592 Training on worker :1559
INFO:root:FL Epoch: 592 Using Learning rate : 0.015315102408310978 
INFO:root:FL Epoch: 592 Normal Training
INFO:root:Worker: 1559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610540
INFO:root:Worker: 1559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521126
INFO:root:FL Epoch: 592 Norm Difference for worker 1559 is 0.640901
INFO:root:FL Epoch: 592 Done on worker:1559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 592 Training on worker :596
INFO:root:FL Epoch: 592 Using Learning rate : 0.015315102408310978 
INFO:root:FL Epoch: 592 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447018
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506786
INFO:root:FL Epoch: 592 Norm Difference for worker 596 is 0.682264
INFO:root:FL Epoch: 592 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 695
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 592 Ends   ===================
INFO:root:Epoch:592 Global Model Test Loss:0.47954245349940133 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:592 Global Model Backdoor Test Loss:0.141587662200133                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 593 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 593 Workers Selected : [1910, 681, 119, 86, 1536, 40, 1747, 1300, 59, 902]
INFO:root:FL Epoch: 593 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.1002994 0.0998004 0.1002994 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 593 Num points on workers: [200 200 201 201 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 593 Training on worker :1910
INFO:root:FL Epoch: 593 Using Learning rate : 0.015284472203494354 
INFO:root:FL Epoch: 593 Normal Training
INFO:root:Worker: 1910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599254
INFO:root:Worker: 1910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364280
INFO:root:FL Epoch: 593 Norm Difference for worker 1910 is 0.664617
INFO:root:FL Epoch: 593 Done on worker:1910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 593 Training on worker :681
INFO:root:FL Epoch: 593 Using Learning rate : 0.015284472203494354 
INFO:root:FL Epoch: 593 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437750
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334933
INFO:root:FL Epoch: 593 Norm Difference for worker 681 is 0.635985
INFO:root:FL Epoch: 593 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 593 Training on worker :119
INFO:root:FL Epoch: 593 Using Learning rate : 0.015284472203494354 
INFO:root:FL Epoch: 593 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.511680
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.379118
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 593 Norm Difference for worker 119 is 0.596872
INFO:root:FL Epoch: 593 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 593 Training on worker :86
INFO:root:FL Epoch: 593 Using Learning rate : 0.015284472203494354 
INFO:root:FL Epoch: 593 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.235372
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.261377
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 593 Norm Difference for worker 86 is 0.539181
INFO:root:FL Epoch: 593 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 593 Training on worker :1536
INFO:root:FL Epoch: 593 Using Learning rate : 0.015284472203494354 
INFO:root:FL Epoch: 593 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478757
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609624
INFO:root:FL Epoch: 593 Norm Difference for worker 1536 is 0.650733
INFO:root:FL Epoch: 593 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 593 Training on worker :40
INFO:root:FL Epoch: 593 Using Learning rate : 0.015284472203494354 
INFO:root:FL Epoch: 593 Normal Training
INFO:root:Worker: 40 Train Epoch: 0 [0/201 (0%)]	Loss: 0.561514
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 40 Train Epoch: 1 [0/201 (0%)]	Loss: 0.525675
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 593 Norm Difference for worker 40 is 0.691949
INFO:root:FL Epoch: 593 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 593 Training on worker :1747
INFO:root:FL Epoch: 593 Using Learning rate : 0.015284472203494354 
INFO:root:FL Epoch: 593 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407991
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282508
INFO:root:FL Epoch: 593 Norm Difference for worker 1747 is 0.648269
INFO:root:FL Epoch: 593 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 593 Training on worker :1300
INFO:root:FL Epoch: 593 Using Learning rate : 0.015284472203494354 
INFO:root:FL Epoch: 593 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605960
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440880
INFO:root:FL Epoch: 593 Norm Difference for worker 1300 is 0.61502
INFO:root:FL Epoch: 593 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 593 Training on worker :59
INFO:root:FL Epoch: 593 Using Learning rate : 0.015284472203494354 
INFO:root:FL Epoch: 593 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.282684
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447636
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 593 Norm Difference for worker 59 is 0.658646
INFO:root:FL Epoch: 593 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 593 Training on worker :902
INFO:root:FL Epoch: 593 Using Learning rate : 0.015284472203494354 
INFO:root:FL Epoch: 593 Normal Training
INFO:root:Worker: 902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323858
INFO:root:Worker: 902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371852
INFO:root:FL Epoch: 593 Norm Difference for worker 902 is 0.625776
INFO:root:FL Epoch: 593 Done on worker:902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 86
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 593 Ends   ===================
INFO:root:Epoch:593 Global Model Test Loss:0.48964448886759143 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:593 Global Model Backdoor Test Loss:0.16177087277173996                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 594 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 594 Workers Selected : [774, 1926, 1801, 399, 1725, 1837, 123, 912, 1829, 387]
INFO:root:FL Epoch: 594 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 594 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 594 Training on worker :774
INFO:root:FL Epoch: 594 Using Learning rate : 0.015253903259087365 
INFO:root:FL Epoch: 594 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.280760
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.163084
INFO:root:FL Epoch: 594 Norm Difference for worker 774 is 0.559411
INFO:root:FL Epoch: 594 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 594 Training on worker :1926
INFO:root:FL Epoch: 594 Using Learning rate : 0.015253903259087365 
INFO:root:FL Epoch: 594 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408343
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375417
INFO:root:FL Epoch: 594 Norm Difference for worker 1926 is 0.574247
INFO:root:FL Epoch: 594 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 594 Training on worker :1801
INFO:root:FL Epoch: 594 Using Learning rate : 0.015253903259087365 
INFO:root:FL Epoch: 594 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.231310
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578749
INFO:root:FL Epoch: 594 Norm Difference for worker 1801 is 0.686964
INFO:root:FL Epoch: 594 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 594 Training on worker :399
INFO:root:FL Epoch: 594 Using Learning rate : 0.015253903259087365 
INFO:root:FL Epoch: 594 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332499
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312337
INFO:root:FL Epoch: 594 Norm Difference for worker 399 is 0.745752
INFO:root:FL Epoch: 594 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 594 Training on worker :1725
INFO:root:FL Epoch: 594 Using Learning rate : 0.015253903259087365 
INFO:root:FL Epoch: 594 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472850
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433913
INFO:root:FL Epoch: 594 Norm Difference for worker 1725 is 0.786759
INFO:root:FL Epoch: 594 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 594 Training on worker :1837
INFO:root:FL Epoch: 594 Using Learning rate : 0.015253903259087365 
INFO:root:FL Epoch: 594 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525866
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320465
INFO:root:FL Epoch: 594 Norm Difference for worker 1837 is 0.693956
INFO:root:FL Epoch: 594 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 594 Training on worker :123
INFO:root:FL Epoch: 594 Using Learning rate : 0.015253903259087365 
INFO:root:FL Epoch: 594 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541956
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.367698
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 594 Norm Difference for worker 123 is 0.742632
INFO:root:FL Epoch: 594 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 594 Training on worker :912
INFO:root:FL Epoch: 594 Using Learning rate : 0.015253903259087365 
INFO:root:FL Epoch: 594 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500786
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477144
INFO:root:FL Epoch: 594 Norm Difference for worker 912 is 0.703733
INFO:root:FL Epoch: 594 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 594 Training on worker :1829
INFO:root:FL Epoch: 594 Using Learning rate : 0.015253903259087365 
INFO:root:FL Epoch: 594 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482253
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458769
INFO:root:FL Epoch: 594 Norm Difference for worker 1829 is 0.792757
INFO:root:FL Epoch: 594 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 594 Training on worker :387
INFO:root:FL Epoch: 594 Using Learning rate : 0.015253903259087365 
INFO:root:FL Epoch: 594 Normal Training
INFO:root:Worker: 387 Train Epoch: 0 [0/200 (0%)]	Loss: 0.958062
INFO:root:Worker: 387 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578781
INFO:root:FL Epoch: 594 Norm Difference for worker 387 is 0.747749
INFO:root:FL Epoch: 594 Done on worker:387
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 774
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 594 Ends   ===================
INFO:root:Epoch:594 Global Model Test Loss:0.5023566379266626 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:594 Global Model Backdoor Test Loss:0.1557076262931029                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 595 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 595 Workers Selected : [291, 813, 50, 1335, 830, 653, 483, 1654, 1248, 274]
INFO:root:FL Epoch: 595 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 595 Num points on workers: [201 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 595 Training on worker :291
INFO:root:FL Epoch: 595 Using Learning rate : 0.015223395452569191 
INFO:root:FL Epoch: 595 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.827885
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.462489
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 595 Norm Difference for worker 291 is 0.743608
INFO:root:FL Epoch: 595 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 595 Training on worker :813
INFO:root:FL Epoch: 595 Using Learning rate : 0.015223395452569191 
INFO:root:FL Epoch: 595 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654457
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504866
INFO:root:FL Epoch: 595 Norm Difference for worker 813 is 0.766726
INFO:root:FL Epoch: 595 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 595 Training on worker :50
INFO:root:FL Epoch: 595 Using Learning rate : 0.015223395452569191 
INFO:root:FL Epoch: 595 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.283889
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.283013
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 595 Norm Difference for worker 50 is 0.733017
INFO:root:FL Epoch: 595 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 595 Training on worker :1335
INFO:root:FL Epoch: 595 Using Learning rate : 0.015223395452569191 
INFO:root:FL Epoch: 595 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485246
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374018
INFO:root:FL Epoch: 595 Norm Difference for worker 1335 is 0.8265
INFO:root:FL Epoch: 595 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 595 Training on worker :830
INFO:root:FL Epoch: 595 Using Learning rate : 0.015223395452569191 
INFO:root:FL Epoch: 595 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577599
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339689
INFO:root:FL Epoch: 595 Norm Difference for worker 830 is 0.685499
INFO:root:FL Epoch: 595 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 595 Training on worker :653
INFO:root:FL Epoch: 595 Using Learning rate : 0.015223395452569191 
INFO:root:FL Epoch: 595 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.298082
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381958
INFO:root:FL Epoch: 595 Norm Difference for worker 653 is 0.681677
INFO:root:FL Epoch: 595 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 595 Training on worker :483
INFO:root:FL Epoch: 595 Using Learning rate : 0.015223395452569191 
INFO:root:FL Epoch: 595 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435275
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348844
INFO:root:FL Epoch: 595 Norm Difference for worker 483 is 0.796277
INFO:root:FL Epoch: 595 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 595 Training on worker :1654
INFO:root:FL Epoch: 595 Using Learning rate : 0.015223395452569191 
INFO:root:FL Epoch: 595 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.992632
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574425
INFO:root:FL Epoch: 595 Norm Difference for worker 1654 is 0.80866
INFO:root:FL Epoch: 595 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 595 Training on worker :1248
INFO:root:FL Epoch: 595 Using Learning rate : 0.015223395452569191 
INFO:root:FL Epoch: 595 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677909
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443314
INFO:root:FL Epoch: 595 Norm Difference for worker 1248 is 0.75053
INFO:root:FL Epoch: 595 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 595 Training on worker :274
INFO:root:FL Epoch: 595 Using Learning rate : 0.015223395452569191 
INFO:root:FL Epoch: 595 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.549092
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.243544
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 595 Norm Difference for worker 274 is 0.611276
INFO:root:FL Epoch: 595 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 274
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 595 Ends   ===================
INFO:root:Epoch:595 Global Model Test Loss:0.4957243993001826 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:595 Global Model Backdoor Test Loss:0.13285227119922638                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 596 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 596 Workers Selected : [1385, 108, 1824, 1767, 1165, 138, 227, 1226, 114, 486]
INFO:root:FL Epoch: 596 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994 0.1002994
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 596 Num points on workers: [200 201 200 200 200 201 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 596 Training on worker :1385
INFO:root:FL Epoch: 596 Using Learning rate : 0.015192948661664053 
INFO:root:FL Epoch: 596 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660747
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565822
INFO:root:FL Epoch: 596 Norm Difference for worker 1385 is 0.743653
INFO:root:FL Epoch: 596 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 596 Training on worker :108
INFO:root:FL Epoch: 596 Using Learning rate : 0.015192948661664053 
INFO:root:FL Epoch: 596 Normal Training
INFO:root:Worker: 108 Train Epoch: 0 [0/201 (0%)]	Loss: 0.407733
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 108 Train Epoch: 1 [0/201 (0%)]	Loss: 0.288972
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 596 Norm Difference for worker 108 is 0.753195
INFO:root:FL Epoch: 596 Done on worker:108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 596 Training on worker :1824
INFO:root:FL Epoch: 596 Using Learning rate : 0.015192948661664053 
INFO:root:FL Epoch: 596 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522003
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474000
INFO:root:FL Epoch: 596 Norm Difference for worker 1824 is 0.763518
INFO:root:FL Epoch: 596 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 596 Training on worker :1767
INFO:root:FL Epoch: 596 Using Learning rate : 0.015192948661664053 
INFO:root:FL Epoch: 596 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413721
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459392
INFO:root:FL Epoch: 596 Norm Difference for worker 1767 is 0.779831
INFO:root:FL Epoch: 596 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 596 Training on worker :1165
INFO:root:FL Epoch: 596 Using Learning rate : 0.015192948661664053 
INFO:root:FL Epoch: 596 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421432
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.197425
INFO:root:FL Epoch: 596 Norm Difference for worker 1165 is 0.767626
INFO:root:FL Epoch: 596 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 596 Training on worker :138
INFO:root:FL Epoch: 596 Using Learning rate : 0.015192948661664053 
INFO:root:FL Epoch: 596 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 1.224272
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.416065
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 596 Norm Difference for worker 138 is 0.805543
INFO:root:FL Epoch: 596 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 596 Training on worker :227
INFO:root:FL Epoch: 596 Using Learning rate : 0.015192948661664053 
INFO:root:FL Epoch: 596 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.329768
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.202012
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 596 Norm Difference for worker 227 is 0.758678
INFO:root:FL Epoch: 596 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 596 Training on worker :1226
INFO:root:FL Epoch: 596 Using Learning rate : 0.015192948661664053 
INFO:root:FL Epoch: 596 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333791
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588697
INFO:root:FL Epoch: 596 Norm Difference for worker 1226 is 0.788272
INFO:root:FL Epoch: 596 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 596 Training on worker :114
INFO:root:FL Epoch: 596 Using Learning rate : 0.015192948661664053 
INFO:root:FL Epoch: 596 Normal Training
INFO:root:Worker: 114 Train Epoch: 0 [0/201 (0%)]	Loss: 0.537388
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 114 Train Epoch: 1 [0/201 (0%)]	Loss: 0.585564
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 596 Norm Difference for worker 114 is 0.823479
INFO:root:FL Epoch: 596 Done on worker:114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 596 Training on worker :486
INFO:root:FL Epoch: 596 Using Learning rate : 0.015192948661664053 
INFO:root:FL Epoch: 596 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.268771
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325210
INFO:root:FL Epoch: 596 Norm Difference for worker 486 is 0.735946
INFO:root:FL Epoch: 596 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 227
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 596 Ends   ===================
INFO:root:Epoch:596 Global Model Test Loss:0.5030405468800488 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:596 Global Model Backdoor Test Loss:0.23129142572482428                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 597 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 597 Workers Selected : [337, 1927, 777, 117, 1379, 1198, 527, 1053, 1645, 917]
INFO:root:FL Epoch: 597 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 597 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 597 Training on worker :337
INFO:root:FL Epoch: 597 Using Learning rate : 0.015162562764340724 
INFO:root:FL Epoch: 597 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.388923
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.325845
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 597 Norm Difference for worker 337 is 0.631657
INFO:root:FL Epoch: 597 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 597 Training on worker :1927
INFO:root:FL Epoch: 597 Using Learning rate : 0.015162562764340724 
INFO:root:FL Epoch: 597 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688927
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520742
INFO:root:FL Epoch: 597 Norm Difference for worker 1927 is 0.688208
INFO:root:FL Epoch: 597 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 597 Training on worker :777
INFO:root:FL Epoch: 597 Using Learning rate : 0.015162562764340724 
INFO:root:FL Epoch: 597 Normal Training
INFO:root:Worker: 777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581314
INFO:root:Worker: 777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576011
INFO:root:FL Epoch: 597 Norm Difference for worker 777 is 0.673541
INFO:root:FL Epoch: 597 Done on worker:777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 597 Training on worker :117
INFO:root:FL Epoch: 597 Using Learning rate : 0.015162562764340724 
INFO:root:FL Epoch: 597 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.467593
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505136
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 597 Norm Difference for worker 117 is 0.638738
INFO:root:FL Epoch: 597 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 597 Training on worker :1379
INFO:root:FL Epoch: 597 Using Learning rate : 0.015162562764340724 
INFO:root:FL Epoch: 597 Normal Training
INFO:root:Worker: 1379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541885
INFO:root:Worker: 1379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368163
INFO:root:FL Epoch: 597 Norm Difference for worker 1379 is 0.611824
INFO:root:FL Epoch: 597 Done on worker:1379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 597 Training on worker :1198
INFO:root:FL Epoch: 597 Using Learning rate : 0.015162562764340724 
INFO:root:FL Epoch: 597 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650533
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358205
INFO:root:FL Epoch: 597 Norm Difference for worker 1198 is 0.651094
INFO:root:FL Epoch: 597 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 597 Training on worker :527
INFO:root:FL Epoch: 597 Using Learning rate : 0.015162562764340724 
INFO:root:FL Epoch: 597 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408365
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388895
INFO:root:FL Epoch: 597 Norm Difference for worker 527 is 0.711146
INFO:root:FL Epoch: 597 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 597 Training on worker :1053
INFO:root:FL Epoch: 597 Using Learning rate : 0.015162562764340724 
INFO:root:FL Epoch: 597 Normal Training
INFO:root:Worker: 1053 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626494
INFO:root:Worker: 1053 Train Epoch: 1 [0/200 (0%)]	Loss: 0.776749
INFO:root:FL Epoch: 597 Norm Difference for worker 1053 is 0.602382
INFO:root:FL Epoch: 597 Done on worker:1053
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 597 Training on worker :1645
INFO:root:FL Epoch: 597 Using Learning rate : 0.015162562764340724 
INFO:root:FL Epoch: 597 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543807
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448284
INFO:root:FL Epoch: 597 Norm Difference for worker 1645 is 0.755141
INFO:root:FL Epoch: 597 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 597 Training on worker :917
INFO:root:FL Epoch: 597 Using Learning rate : 0.015162562764340724 
INFO:root:FL Epoch: 597 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605061
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468502
INFO:root:FL Epoch: 597 Norm Difference for worker 917 is 0.691986
INFO:root:FL Epoch: 597 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1379
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 597 Ends   ===================
INFO:root:Epoch:597 Global Model Test Loss:0.48741257190704346 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:597 Global Model Backdoor Test Loss:0.1850399300456047                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 598 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 598 Workers Selected : [1469, 1630, 1186, 1921, 1671, 732, 997, 506, 1188, 398]
INFO:root:FL Epoch: 598 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 598 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 598 Training on worker :1469
INFO:root:FL Epoch: 598 Using Learning rate : 0.015132237638812045 
INFO:root:FL Epoch: 598 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611992
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498625
INFO:root:FL Epoch: 598 Norm Difference for worker 1469 is 0.643315
INFO:root:FL Epoch: 598 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 598 Training on worker :1630
INFO:root:FL Epoch: 598 Using Learning rate : 0.015132237638812045 
INFO:root:FL Epoch: 598 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666998
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361122
INFO:root:FL Epoch: 598 Norm Difference for worker 1630 is 0.644118
INFO:root:FL Epoch: 598 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 598 Training on worker :1186
INFO:root:FL Epoch: 598 Using Learning rate : 0.015132237638812045 
INFO:root:FL Epoch: 598 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412710
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617420
INFO:root:FL Epoch: 598 Norm Difference for worker 1186 is 0.682498
INFO:root:FL Epoch: 598 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 598 Training on worker :1921
INFO:root:FL Epoch: 598 Using Learning rate : 0.015132237638812045 
INFO:root:FL Epoch: 598 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639807
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571479
INFO:root:FL Epoch: 598 Norm Difference for worker 1921 is 0.63611
INFO:root:FL Epoch: 598 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 598 Training on worker :1671
INFO:root:FL Epoch: 598 Using Learning rate : 0.015132237638812045 
INFO:root:FL Epoch: 598 Normal Training
INFO:root:Worker: 1671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609430
INFO:root:Worker: 1671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289861
INFO:root:FL Epoch: 598 Norm Difference for worker 1671 is 0.611228
INFO:root:FL Epoch: 598 Done on worker:1671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 598 Training on worker :732
INFO:root:FL Epoch: 598 Using Learning rate : 0.015132237638812045 
INFO:root:FL Epoch: 598 Normal Training
INFO:root:Worker: 732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515001
INFO:root:Worker: 732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465257
INFO:root:FL Epoch: 598 Norm Difference for worker 732 is 0.663232
INFO:root:FL Epoch: 598 Done on worker:732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 598 Training on worker :997
INFO:root:FL Epoch: 598 Using Learning rate : 0.015132237638812045 
INFO:root:FL Epoch: 598 Normal Training
INFO:root:Worker: 997 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547554
INFO:root:Worker: 997 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374752
INFO:root:FL Epoch: 598 Norm Difference for worker 997 is 0.567338
INFO:root:FL Epoch: 598 Done on worker:997
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 598 Training on worker :506
INFO:root:FL Epoch: 598 Using Learning rate : 0.015132237638812045 
INFO:root:FL Epoch: 598 Normal Training
INFO:root:Worker: 506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598863
INFO:root:Worker: 506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509255
INFO:root:FL Epoch: 598 Norm Difference for worker 506 is 0.669114
INFO:root:FL Epoch: 598 Done on worker:506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 598 Training on worker :1188
INFO:root:FL Epoch: 598 Using Learning rate : 0.015132237638812045 
INFO:root:FL Epoch: 598 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586090
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583504
INFO:root:FL Epoch: 598 Norm Difference for worker 1188 is 0.64853
INFO:root:FL Epoch: 598 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 598 Training on worker :398
INFO:root:FL Epoch: 598 Using Learning rate : 0.015132237638812045 
INFO:root:FL Epoch: 598 Normal Training
INFO:root:Worker: 398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479034
INFO:root:Worker: 398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377724
INFO:root:FL Epoch: 598 Norm Difference for worker 398 is 0.617212
INFO:root:FL Epoch: 598 Done on worker:398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 997
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 598 Ends   ===================
INFO:root:Epoch:598 Global Model Test Loss:0.4983035764273475 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:598 Global Model Backdoor Test Loss:0.17926111817359924                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 599 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 599 Workers Selected : [33, 656, 758, 379, 1800, 821, 1258, 725, 768, 46]
INFO:root:FL Epoch: 599 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 599 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 599 Training on worker :33
INFO:root:FL Epoch: 599 Using Learning rate : 0.01510197316353442 
INFO:root:FL Epoch: 599 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.591635
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.551938
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 599 Norm Difference for worker 33 is 0.649077
INFO:root:FL Epoch: 599 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 599 Training on worker :656
INFO:root:FL Epoch: 599 Using Learning rate : 0.01510197316353442 
INFO:root:FL Epoch: 599 Normal Training
INFO:root:Worker: 656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623384
INFO:root:Worker: 656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381124
INFO:root:FL Epoch: 599 Norm Difference for worker 656 is 0.62534
INFO:root:FL Epoch: 599 Done on worker:656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 599 Training on worker :758
INFO:root:FL Epoch: 599 Using Learning rate : 0.01510197316353442 
INFO:root:FL Epoch: 599 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602225
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678332
INFO:root:FL Epoch: 599 Norm Difference for worker 758 is 0.698104
INFO:root:FL Epoch: 599 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 599 Training on worker :379
INFO:root:FL Epoch: 599 Using Learning rate : 0.01510197316353442 
INFO:root:FL Epoch: 599 Normal Training
INFO:root:Worker: 379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618291
INFO:root:Worker: 379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444675
INFO:root:FL Epoch: 599 Norm Difference for worker 379 is 0.678411
INFO:root:FL Epoch: 599 Done on worker:379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 599 Training on worker :1800
INFO:root:FL Epoch: 599 Using Learning rate : 0.01510197316353442 
INFO:root:FL Epoch: 599 Normal Training
INFO:root:Worker: 1800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488913
INFO:root:Worker: 1800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404608
INFO:root:FL Epoch: 599 Norm Difference for worker 1800 is 0.648231
INFO:root:FL Epoch: 599 Done on worker:1800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 599 Training on worker :821
INFO:root:FL Epoch: 599 Using Learning rate : 0.01510197316353442 
INFO:root:FL Epoch: 599 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733784
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404407
INFO:root:FL Epoch: 599 Norm Difference for worker 821 is 0.616068
INFO:root:FL Epoch: 599 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 599 Training on worker :1258
INFO:root:FL Epoch: 599 Using Learning rate : 0.01510197316353442 
INFO:root:FL Epoch: 599 Normal Training
INFO:root:Worker: 1258 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616438
INFO:root:Worker: 1258 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280434
INFO:root:FL Epoch: 599 Norm Difference for worker 1258 is 0.687978
INFO:root:FL Epoch: 599 Done on worker:1258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 599 Training on worker :725
INFO:root:FL Epoch: 599 Using Learning rate : 0.01510197316353442 
INFO:root:FL Epoch: 599 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389848
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516518
INFO:root:FL Epoch: 599 Norm Difference for worker 725 is 0.537426
INFO:root:FL Epoch: 599 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 599 Training on worker :768
INFO:root:FL Epoch: 599 Using Learning rate : 0.01510197316353442 
INFO:root:FL Epoch: 599 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411409
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199537
INFO:root:FL Epoch: 599 Norm Difference for worker 768 is 0.502058
INFO:root:FL Epoch: 599 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 599 Training on worker :46
INFO:root:FL Epoch: 599 Using Learning rate : 0.01510197316353442 
INFO:root:FL Epoch: 599 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.463463
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.421336
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 599 Norm Difference for worker 46 is 0.580772
INFO:root:FL Epoch: 599 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 768
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 599 Ends   ===================
INFO:root:Epoch:599 Global Model Test Loss:0.5026419145219466 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:599 Global Model Backdoor Test Loss:0.10542554905017217                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 600 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 600 Workers Selected : [1374, 653, 800, 738, 1855, 248, 298, 573, 1627, 1083]
INFO:root:FL Epoch: 600 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 600 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 600 Training on worker :1374
INFO:root:FL Epoch: 600 Using Learning rate : 0.015071769217207348 
INFO:root:FL Epoch: 600 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476005
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.844670
INFO:root:FL Epoch: 600 Norm Difference for worker 1374 is 0.733947
INFO:root:FL Epoch: 600 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 600 Training on worker :653
INFO:root:FL Epoch: 600 Using Learning rate : 0.015071769217207348 
INFO:root:FL Epoch: 600 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410815
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210873
INFO:root:FL Epoch: 600 Norm Difference for worker 653 is 0.615939
INFO:root:FL Epoch: 600 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 600 Training on worker :800
INFO:root:FL Epoch: 600 Using Learning rate : 0.015071769217207348 
INFO:root:FL Epoch: 600 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411522
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334001
INFO:root:FL Epoch: 600 Norm Difference for worker 800 is 0.742004
INFO:root:FL Epoch: 600 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 600 Training on worker :738
INFO:root:FL Epoch: 600 Using Learning rate : 0.015071769217207348 
INFO:root:FL Epoch: 600 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376475
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.744106
INFO:root:FL Epoch: 600 Norm Difference for worker 738 is 0.730952
INFO:root:FL Epoch: 600 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 600 Training on worker :1855
INFO:root:FL Epoch: 600 Using Learning rate : 0.015071769217207348 
INFO:root:FL Epoch: 600 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615794
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466346
INFO:root:FL Epoch: 600 Norm Difference for worker 1855 is 0.772087
INFO:root:FL Epoch: 600 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 600 Training on worker :248
INFO:root:FL Epoch: 600 Using Learning rate : 0.015071769217207348 
INFO:root:FL Epoch: 600 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.960797
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.599540
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 600 Norm Difference for worker 248 is 0.750493
INFO:root:FL Epoch: 600 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 600 Training on worker :298
INFO:root:FL Epoch: 600 Using Learning rate : 0.015071769217207348 
INFO:root:FL Epoch: 600 Normal Training
INFO:root:Worker: 298 Train Epoch: 0 [0/201 (0%)]	Loss: 0.658566
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 298 Train Epoch: 1 [0/201 (0%)]	Loss: 0.400079
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 600 Norm Difference for worker 298 is 0.680155
INFO:root:FL Epoch: 600 Done on worker:298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 600 Training on worker :573
INFO:root:FL Epoch: 600 Using Learning rate : 0.015071769217207348 
INFO:root:FL Epoch: 600 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347020
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467638
INFO:root:FL Epoch: 600 Norm Difference for worker 573 is 0.732885
INFO:root:FL Epoch: 600 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 600 Training on worker :1627
INFO:root:FL Epoch: 600 Using Learning rate : 0.015071769217207348 
INFO:root:FL Epoch: 600 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.265656
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367091
INFO:root:FL Epoch: 600 Norm Difference for worker 1627 is 0.644405
INFO:root:FL Epoch: 600 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 600 Training on worker :1083
INFO:root:FL Epoch: 600 Using Learning rate : 0.015071769217207348 
INFO:root:FL Epoch: 600 Normal Training
INFO:root:Worker: 1083 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501453
INFO:root:Worker: 1083 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522488
INFO:root:FL Epoch: 600 Norm Difference for worker 1083 is 0.710108
INFO:root:FL Epoch: 600 Done on worker:1083
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 653
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 600 Ends   ===================
INFO:root:Epoch:600 Global Model Test Loss:0.5050711333751678 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:600 Global Model Backdoor Test Loss:0.11661198114355405                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 601 Begins ===================
INFO:root:FL Epoch: 601 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 601 Workers Selected : [0, 1, 2, 163, 138, 1190, 701, 1254, 563, 1004]
INFO:root:FL Epoch: 601 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 601 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 601 Training on worker :0
INFO:root:FL Epoch: 601 Using Learning rate : 0.0030083251357545873 
INFO:root:FL Epoch: 601 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.212212
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.131479
INFO:root:FL Epoch: 601 Worker: 0 Backdoor Test Loss: 0.10725540978213151 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 601 Worker: 0 Backdoor Train Loss: 0.1203227698802948 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 601 Norm Difference for worker 0 is 0.082251
INFO:root:FL Epoch: 601 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 601 Training on worker :1
INFO:root:FL Epoch: 601 Using Learning rate : 0.0030083251357545873 
INFO:root:FL Epoch: 601 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.151092
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.172391
INFO:root:FL Epoch: 601 Worker: 1 Backdoor Test Loss: 0.10816083227594693 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 601 Worker: 1 Backdoor Train Loss: 0.11952272802591324 Backdoor Train Accuracy: 97.5
INFO:root:FL Epoch: 601 Norm Difference for worker 1 is 0.086571
INFO:root:FL Epoch: 601 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 601 Training on worker :2
INFO:root:FL Epoch: 601 Using Learning rate : 0.0030083251357545873 
INFO:root:FL Epoch: 601 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.065694
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.110523
INFO:root:FL Epoch: 601 Worker: 2 Backdoor Test Loss: 0.10997140283385913 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 601 Worker: 2 Backdoor Train Loss: 0.1197042740881443 Backdoor Train Accuracy: 98.0
INFO:root:FL Epoch: 601 Norm Difference for worker 2 is 0.084418
INFO:root:FL Epoch: 601 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 601 Training on worker :163
INFO:root:FL Epoch: 601 Using Learning rate : 0.015041625678772937 
INFO:root:FL Epoch: 601 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.817788
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.313539
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 601 Norm Difference for worker 163 is 0.804907
INFO:root:FL Epoch: 601 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 601 Training on worker :138
INFO:root:FL Epoch: 601 Using Learning rate : 0.015041625678772937 
INFO:root:FL Epoch: 601 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.527733
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415927
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 601 Norm Difference for worker 138 is 0.787238
INFO:root:FL Epoch: 601 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 601 Training on worker :1190
INFO:root:FL Epoch: 601 Using Learning rate : 0.015041625678772937 
INFO:root:FL Epoch: 601 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404266
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201552
INFO:root:FL Epoch: 601 Norm Difference for worker 1190 is 0.570491
INFO:root:FL Epoch: 601 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 601 Training on worker :701
INFO:root:FL Epoch: 601 Using Learning rate : 0.015041625678772937 
INFO:root:FL Epoch: 601 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440330
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427975
INFO:root:FL Epoch: 601 Norm Difference for worker 701 is 0.76189
INFO:root:FL Epoch: 601 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 601 Training on worker :1254
INFO:root:FL Epoch: 601 Using Learning rate : 0.015041625678772937 
INFO:root:FL Epoch: 601 Normal Training
INFO:root:Worker: 1254 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737201
INFO:root:Worker: 1254 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571479
INFO:root:FL Epoch: 601 Norm Difference for worker 1254 is 0.743613
INFO:root:FL Epoch: 601 Done on worker:1254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 601 Training on worker :563
INFO:root:FL Epoch: 601 Using Learning rate : 0.015041625678772937 
INFO:root:FL Epoch: 601 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433111
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225874
INFO:root:FL Epoch: 601 Norm Difference for worker 563 is 0.606938
INFO:root:FL Epoch: 601 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 601 Training on worker :1004
INFO:root:FL Epoch: 601 Using Learning rate : 0.015041625678772937 
INFO:root:FL Epoch: 601 Normal Training
INFO:root:Worker: 1004 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701247
INFO:root:Worker: 1004 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675827
INFO:root:FL Epoch: 601 Norm Difference for worker 1004 is 0.766135
INFO:root:FL Epoch: 601 Done on worker:1004
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 601 Ends   ===================
INFO:root:Epoch:601 Global Model Test Loss:0.5083105809548322 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:601 Global Model Backdoor Test Loss:0.10725540978213151                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 602 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 602 Workers Selected : [607, 1517, 1264, 1385, 623, 1075, 1805, 731, 742, 1898]
INFO:root:FL Epoch: 602 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 602 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 602 Training on worker :607
INFO:root:FL Epoch: 602 Using Learning rate : 0.01501154242741539 
INFO:root:FL Epoch: 602 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376221
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422742
INFO:root:FL Epoch: 602 Norm Difference for worker 607 is 0.784044
INFO:root:FL Epoch: 602 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 602 Training on worker :1517
INFO:root:FL Epoch: 602 Using Learning rate : 0.01501154242741539 
INFO:root:FL Epoch: 602 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.234995
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471884
INFO:root:FL Epoch: 602 Norm Difference for worker 1517 is 0.754788
INFO:root:FL Epoch: 602 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 602 Training on worker :1264
INFO:root:FL Epoch: 602 Using Learning rate : 0.01501154242741539 
INFO:root:FL Epoch: 602 Normal Training
INFO:root:Worker: 1264 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594113
INFO:root:Worker: 1264 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391898
INFO:root:FL Epoch: 602 Norm Difference for worker 1264 is 0.887238
INFO:root:FL Epoch: 602 Done on worker:1264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 602 Training on worker :1385
INFO:root:FL Epoch: 602 Using Learning rate : 0.01501154242741539 
INFO:root:FL Epoch: 602 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433045
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338813
INFO:root:FL Epoch: 602 Norm Difference for worker 1385 is 0.78278
INFO:root:FL Epoch: 602 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 602 Training on worker :623
INFO:root:FL Epoch: 602 Using Learning rate : 0.01501154242741539 
INFO:root:FL Epoch: 602 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690765
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570203
INFO:root:FL Epoch: 602 Norm Difference for worker 623 is 0.844818
INFO:root:FL Epoch: 602 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 602 Training on worker :1075
INFO:root:FL Epoch: 602 Using Learning rate : 0.01501154242741539 
INFO:root:FL Epoch: 602 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552741
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395433
INFO:root:FL Epoch: 602 Norm Difference for worker 1075 is 0.758477
INFO:root:FL Epoch: 602 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 602 Training on worker :1805
INFO:root:FL Epoch: 602 Using Learning rate : 0.01501154242741539 
INFO:root:FL Epoch: 602 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443319
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492795
INFO:root:FL Epoch: 602 Norm Difference for worker 1805 is 0.727197
INFO:root:FL Epoch: 602 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 602 Training on worker :731
INFO:root:FL Epoch: 602 Using Learning rate : 0.01501154242741539 
INFO:root:FL Epoch: 602 Normal Training
INFO:root:Worker: 731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.957097
INFO:root:Worker: 731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554630
INFO:root:FL Epoch: 602 Norm Difference for worker 731 is 0.84084
INFO:root:FL Epoch: 602 Done on worker:731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 602 Training on worker :742
INFO:root:FL Epoch: 602 Using Learning rate : 0.01501154242741539 
INFO:root:FL Epoch: 602 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509856
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279447
INFO:root:FL Epoch: 602 Norm Difference for worker 742 is 0.693711
INFO:root:FL Epoch: 602 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 602 Training on worker :1898
INFO:root:FL Epoch: 602 Using Learning rate : 0.01501154242741539 
INFO:root:FL Epoch: 602 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728907
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390852
INFO:root:FL Epoch: 602 Norm Difference for worker 1898 is 0.798223
INFO:root:FL Epoch: 602 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 742
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 602 Ends   ===================
INFO:root:Epoch:602 Global Model Test Loss:0.5130323487169602 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:602 Global Model Backdoor Test Loss:0.10099726170301437                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 603 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 603 Workers Selected : [1697, 438, 1000, 1152, 674, 1882, 1176, 1868, 78, 1171]
INFO:root:FL Epoch: 603 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 603 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 603 Training on worker :1697
INFO:root:FL Epoch: 603 Using Learning rate : 0.01498151934256056 
INFO:root:FL Epoch: 603 Normal Training
INFO:root:Worker: 1697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382842
INFO:root:Worker: 1697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408353
INFO:root:FL Epoch: 603 Norm Difference for worker 1697 is 0.783585
INFO:root:FL Epoch: 603 Done on worker:1697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 603 Training on worker :438
INFO:root:FL Epoch: 603 Using Learning rate : 0.01498151934256056 
INFO:root:FL Epoch: 603 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374717
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423883
INFO:root:FL Epoch: 603 Norm Difference for worker 438 is 0.779529
INFO:root:FL Epoch: 603 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 603 Training on worker :1000
INFO:root:FL Epoch: 603 Using Learning rate : 0.01498151934256056 
INFO:root:FL Epoch: 603 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.862199
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494908
INFO:root:FL Epoch: 603 Norm Difference for worker 1000 is 0.844521
INFO:root:FL Epoch: 603 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 603 Training on worker :1152
INFO:root:FL Epoch: 603 Using Learning rate : 0.01498151934256056 
INFO:root:FL Epoch: 603 Normal Training
INFO:root:Worker: 1152 Train Epoch: 0 [0/200 (0%)]	Loss: 0.939350
INFO:root:Worker: 1152 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556043
INFO:root:FL Epoch: 603 Norm Difference for worker 1152 is 0.88562
INFO:root:FL Epoch: 603 Done on worker:1152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 603 Training on worker :674
INFO:root:FL Epoch: 603 Using Learning rate : 0.01498151934256056 
INFO:root:FL Epoch: 603 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379547
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307148
INFO:root:FL Epoch: 603 Norm Difference for worker 674 is 0.787553
INFO:root:FL Epoch: 603 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 603 Training on worker :1882
INFO:root:FL Epoch: 603 Using Learning rate : 0.01498151934256056 
INFO:root:FL Epoch: 603 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729677
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517523
INFO:root:FL Epoch: 603 Norm Difference for worker 1882 is 0.8027
INFO:root:FL Epoch: 603 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 603 Training on worker :1176
INFO:root:FL Epoch: 603 Using Learning rate : 0.01498151934256056 
INFO:root:FL Epoch: 603 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341208
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245706
INFO:root:FL Epoch: 603 Norm Difference for worker 1176 is 0.566516
INFO:root:FL Epoch: 603 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 603 Training on worker :1868
INFO:root:FL Epoch: 603 Using Learning rate : 0.01498151934256056 
INFO:root:FL Epoch: 603 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.289569
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701899
INFO:root:FL Epoch: 603 Norm Difference for worker 1868 is 0.797632
INFO:root:FL Epoch: 603 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 603 Training on worker :78
INFO:root:FL Epoch: 603 Using Learning rate : 0.01498151934256056 
INFO:root:FL Epoch: 603 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.332157
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.210539
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 603 Norm Difference for worker 78 is 0.518712
INFO:root:FL Epoch: 603 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 603 Training on worker :1171
INFO:root:FL Epoch: 603 Using Learning rate : 0.01498151934256056 
INFO:root:FL Epoch: 603 Normal Training
INFO:root:Worker: 1171 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476481
INFO:root:Worker: 1171 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339486
INFO:root:FL Epoch: 603 Norm Difference for worker 1171 is 0.754943
INFO:root:FL Epoch: 603 Done on worker:1171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 78
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 603 Ends   ===================
INFO:root:Epoch:603 Global Model Test Loss:0.5251152322572821 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:603 Global Model Backdoor Test Loss:0.08236856137712796                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 604 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 604 Workers Selected : [42, 1565, 994, 591, 1772, 1731, 767, 1854, 1609, 1682]
INFO:root:FL Epoch: 604 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 604 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 604 Training on worker :42
INFO:root:FL Epoch: 604 Using Learning rate : 0.014951556303875438 
INFO:root:FL Epoch: 604 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.370397
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.256380
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 604 Norm Difference for worker 42 is 0.595694
INFO:root:FL Epoch: 604 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 604 Training on worker :1565
INFO:root:FL Epoch: 604 Using Learning rate : 0.014951556303875438 
INFO:root:FL Epoch: 604 Normal Training
INFO:root:Worker: 1565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705766
INFO:root:Worker: 1565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333468
INFO:root:FL Epoch: 604 Norm Difference for worker 1565 is 0.841117
INFO:root:FL Epoch: 604 Done on worker:1565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 604 Training on worker :994
INFO:root:FL Epoch: 604 Using Learning rate : 0.014951556303875438 
INFO:root:FL Epoch: 604 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.297167
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432814
INFO:root:FL Epoch: 604 Norm Difference for worker 994 is 0.835402
INFO:root:FL Epoch: 604 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 604 Training on worker :591
INFO:root:FL Epoch: 604 Using Learning rate : 0.014951556303875438 
INFO:root:FL Epoch: 604 Normal Training
INFO:root:Worker: 591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808667
INFO:root:Worker: 591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311988
INFO:root:FL Epoch: 604 Norm Difference for worker 591 is 0.835558
INFO:root:FL Epoch: 604 Done on worker:591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 604 Training on worker :1772
INFO:root:FL Epoch: 604 Using Learning rate : 0.014951556303875438 
INFO:root:FL Epoch: 604 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.944249
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551828
INFO:root:FL Epoch: 604 Norm Difference for worker 1772 is 0.81795
INFO:root:FL Epoch: 604 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 604 Training on worker :1731
INFO:root:FL Epoch: 604 Using Learning rate : 0.014951556303875438 
INFO:root:FL Epoch: 604 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448967
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600448
INFO:root:FL Epoch: 604 Norm Difference for worker 1731 is 0.792626
INFO:root:FL Epoch: 604 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 604 Training on worker :767
INFO:root:FL Epoch: 604 Using Learning rate : 0.014951556303875438 
INFO:root:FL Epoch: 604 Normal Training
INFO:root:Worker: 767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549637
INFO:root:Worker: 767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374424
INFO:root:FL Epoch: 604 Norm Difference for worker 767 is 0.815713
INFO:root:FL Epoch: 604 Done on worker:767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 604 Training on worker :1854
INFO:root:FL Epoch: 604 Using Learning rate : 0.014951556303875438 
INFO:root:FL Epoch: 604 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500478
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608438
INFO:root:FL Epoch: 604 Norm Difference for worker 1854 is 0.888021
INFO:root:FL Epoch: 604 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 604 Training on worker :1609
INFO:root:FL Epoch: 604 Using Learning rate : 0.014951556303875438 
INFO:root:FL Epoch: 604 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692365
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459555
INFO:root:FL Epoch: 604 Norm Difference for worker 1609 is 0.823248
INFO:root:FL Epoch: 604 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 604 Training on worker :1682
INFO:root:FL Epoch: 604 Using Learning rate : 0.014951556303875438 
INFO:root:FL Epoch: 604 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.178350
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368612
INFO:root:FL Epoch: 604 Norm Difference for worker 1682 is 0.777438
INFO:root:FL Epoch: 604 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 604 Ends   ===================
INFO:root:Epoch:604 Global Model Test Loss:0.5375475480275995 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:604 Global Model Backdoor Test Loss:0.09546517332394917                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 605 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 605 Workers Selected : [1229, 1879, 783, 290, 1711, 787, 1366, 1837, 1562, 898]
INFO:root:FL Epoch: 605 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 605 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 605 Training on worker :1229
INFO:root:FL Epoch: 605 Using Learning rate : 0.014921653191267687 
INFO:root:FL Epoch: 605 Normal Training
INFO:root:Worker: 1229 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606904
INFO:root:Worker: 1229 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457076
INFO:root:FL Epoch: 605 Norm Difference for worker 1229 is 0.880438
INFO:root:FL Epoch: 605 Done on worker:1229
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 605 Training on worker :1879
INFO:root:FL Epoch: 605 Using Learning rate : 0.014921653191267687 
INFO:root:FL Epoch: 605 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.278320
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452013
INFO:root:FL Epoch: 605 Norm Difference for worker 1879 is 0.787585
INFO:root:FL Epoch: 605 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 605 Training on worker :783
INFO:root:FL Epoch: 605 Using Learning rate : 0.014921653191267687 
INFO:root:FL Epoch: 605 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613647
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299462
INFO:root:FL Epoch: 605 Norm Difference for worker 783 is 0.803026
INFO:root:FL Epoch: 605 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 605 Training on worker :290
INFO:root:FL Epoch: 605 Using Learning rate : 0.014921653191267687 
INFO:root:FL Epoch: 605 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.585669
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470459
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 605 Norm Difference for worker 290 is 0.8298
INFO:root:FL Epoch: 605 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 605 Training on worker :1711
INFO:root:FL Epoch: 605 Using Learning rate : 0.014921653191267687 
INFO:root:FL Epoch: 605 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.889190
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509296
INFO:root:FL Epoch: 605 Norm Difference for worker 1711 is 0.914829
INFO:root:FL Epoch: 605 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 605 Training on worker :787
INFO:root:FL Epoch: 605 Using Learning rate : 0.014921653191267687 
INFO:root:FL Epoch: 605 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545505
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486962
INFO:root:FL Epoch: 605 Norm Difference for worker 787 is 0.823576
INFO:root:FL Epoch: 605 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 605 Training on worker :1366
INFO:root:FL Epoch: 605 Using Learning rate : 0.014921653191267687 
INFO:root:FL Epoch: 605 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.228509
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410918
INFO:root:FL Epoch: 605 Norm Difference for worker 1366 is 0.607241
INFO:root:FL Epoch: 605 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 605 Training on worker :1837
INFO:root:FL Epoch: 605 Using Learning rate : 0.014921653191267687 
INFO:root:FL Epoch: 605 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351644
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340276
INFO:root:FL Epoch: 605 Norm Difference for worker 1837 is 0.825301
INFO:root:FL Epoch: 605 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 605 Training on worker :1562
INFO:root:FL Epoch: 605 Using Learning rate : 0.014921653191267687 
INFO:root:FL Epoch: 605 Normal Training
INFO:root:Worker: 1562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.896018
INFO:root:Worker: 1562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490416
INFO:root:FL Epoch: 605 Norm Difference for worker 1562 is 0.865894
INFO:root:FL Epoch: 605 Done on worker:1562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 605 Training on worker :898
INFO:root:FL Epoch: 605 Using Learning rate : 0.014921653191267687 
INFO:root:FL Epoch: 605 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.916325
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634947
INFO:root:FL Epoch: 605 Norm Difference for worker 898 is 0.884459
INFO:root:FL Epoch: 605 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1366
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 605 Ends   ===================
INFO:root:Epoch:605 Global Model Test Loss:0.5367341304526609 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:605 Global Model Backdoor Test Loss:0.08479945547878742                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 606 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 606 Workers Selected : [43, 1346, 1944, 1012, 832, 366, 1013, 1230, 475, 495]
INFO:root:FL Epoch: 606 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 606 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 606 Training on worker :43
INFO:root:FL Epoch: 606 Using Learning rate : 0.014891809884885152 
INFO:root:FL Epoch: 606 Normal Training
INFO:root:Worker: 43 Train Epoch: 0 [0/201 (0%)]	Loss: 0.453787
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 43 Train Epoch: 1 [0/201 (0%)]	Loss: 0.544230
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 606 Norm Difference for worker 43 is 0.801966
INFO:root:FL Epoch: 606 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 606 Training on worker :1346
INFO:root:FL Epoch: 606 Using Learning rate : 0.014891809884885152 
INFO:root:FL Epoch: 606 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580302
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520228
INFO:root:FL Epoch: 606 Norm Difference for worker 1346 is 0.848636
INFO:root:FL Epoch: 606 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 606 Training on worker :1944
INFO:root:FL Epoch: 606 Using Learning rate : 0.014891809884885152 
INFO:root:FL Epoch: 606 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512767
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.175739
INFO:root:FL Epoch: 606 Norm Difference for worker 1944 is 0.745836
INFO:root:FL Epoch: 606 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 606 Training on worker :1012
INFO:root:FL Epoch: 606 Using Learning rate : 0.014891809884885152 
INFO:root:FL Epoch: 606 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700639
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345894
INFO:root:FL Epoch: 606 Norm Difference for worker 1012 is 0.827263
INFO:root:FL Epoch: 606 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 606 Training on worker :832
INFO:root:FL Epoch: 606 Using Learning rate : 0.014891809884885152 
INFO:root:FL Epoch: 606 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483633
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415023
INFO:root:FL Epoch: 606 Norm Difference for worker 832 is 0.898417
INFO:root:FL Epoch: 606 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 606 Training on worker :366
INFO:root:FL Epoch: 606 Using Learning rate : 0.014891809884885152 
INFO:root:FL Epoch: 606 Normal Training
INFO:root:Worker: 366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446923
INFO:root:Worker: 366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405559
INFO:root:FL Epoch: 606 Norm Difference for worker 366 is 0.842047
INFO:root:FL Epoch: 606 Done on worker:366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 606 Training on worker :1013
INFO:root:FL Epoch: 606 Using Learning rate : 0.014891809884885152 
INFO:root:FL Epoch: 606 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.838762
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692590
INFO:root:FL Epoch: 606 Norm Difference for worker 1013 is 0.91012
INFO:root:FL Epoch: 606 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 606 Training on worker :1230
INFO:root:FL Epoch: 606 Using Learning rate : 0.014891809884885152 
INFO:root:FL Epoch: 606 Normal Training
INFO:root:Worker: 1230 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632803
INFO:root:Worker: 1230 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325346
INFO:root:FL Epoch: 606 Norm Difference for worker 1230 is 0.893588
INFO:root:FL Epoch: 606 Done on worker:1230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 606 Training on worker :475
INFO:root:FL Epoch: 606 Using Learning rate : 0.014891809884885152 
INFO:root:FL Epoch: 606 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.249720
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562933
INFO:root:FL Epoch: 606 Norm Difference for worker 475 is 0.578776
INFO:root:FL Epoch: 606 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 606 Training on worker :495
INFO:root:FL Epoch: 606 Using Learning rate : 0.014891809884885152 
INFO:root:FL Epoch: 606 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440235
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703281
INFO:root:FL Epoch: 606 Norm Difference for worker 495 is 0.86139
INFO:root:FL Epoch: 606 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 475
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 606 Ends   ===================
INFO:root:Epoch:606 Global Model Test Loss:0.54967680924079 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:606 Global Model Backdoor Test Loss:0.10257092242439587                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 607 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 607 Workers Selected : [1183, 943, 1373, 1473, 992, 757, 1475, 680, 491, 1743]
INFO:root:FL Epoch: 607 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 607 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 607 Training on worker :1183
INFO:root:FL Epoch: 607 Using Learning rate : 0.014862026265115381 
INFO:root:FL Epoch: 607 Normal Training
INFO:root:Worker: 1183 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428221
INFO:root:Worker: 1183 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543649
INFO:root:FL Epoch: 607 Norm Difference for worker 1183 is 0.826085
INFO:root:FL Epoch: 607 Done on worker:1183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 607 Training on worker :943
INFO:root:FL Epoch: 607 Using Learning rate : 0.014862026265115381 
INFO:root:FL Epoch: 607 Normal Training
INFO:root:Worker: 943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476295
INFO:root:Worker: 943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505486
INFO:root:FL Epoch: 607 Norm Difference for worker 943 is 0.859393
INFO:root:FL Epoch: 607 Done on worker:943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 607 Training on worker :1373
INFO:root:FL Epoch: 607 Using Learning rate : 0.014862026265115381 
INFO:root:FL Epoch: 607 Normal Training
INFO:root:Worker: 1373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.184455
INFO:root:Worker: 1373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.775640
INFO:root:FL Epoch: 607 Norm Difference for worker 1373 is 0.842909
INFO:root:FL Epoch: 607 Done on worker:1373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 607 Training on worker :1473
INFO:root:FL Epoch: 607 Using Learning rate : 0.014862026265115381 
INFO:root:FL Epoch: 607 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637343
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535850
INFO:root:FL Epoch: 607 Norm Difference for worker 1473 is 0.851612
INFO:root:FL Epoch: 607 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 607 Training on worker :992
INFO:root:FL Epoch: 607 Using Learning rate : 0.014862026265115381 
INFO:root:FL Epoch: 607 Normal Training
INFO:root:Worker: 992 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427893
INFO:root:Worker: 992 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338585
INFO:root:FL Epoch: 607 Norm Difference for worker 992 is 0.854785
INFO:root:FL Epoch: 607 Done on worker:992
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 607 Training on worker :757
INFO:root:FL Epoch: 607 Using Learning rate : 0.014862026265115381 
INFO:root:FL Epoch: 607 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541357
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.716373
INFO:root:FL Epoch: 607 Norm Difference for worker 757 is 0.849341
INFO:root:FL Epoch: 607 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 607 Training on worker :1475
INFO:root:FL Epoch: 607 Using Learning rate : 0.014862026265115381 
INFO:root:FL Epoch: 607 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530519
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470444
INFO:root:FL Epoch: 607 Norm Difference for worker 1475 is 0.848457
INFO:root:FL Epoch: 607 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 607 Training on worker :680
INFO:root:FL Epoch: 607 Using Learning rate : 0.014862026265115381 
INFO:root:FL Epoch: 607 Normal Training
INFO:root:Worker: 680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380880
INFO:root:Worker: 680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427126
INFO:root:FL Epoch: 607 Norm Difference for worker 680 is 0.809603
INFO:root:FL Epoch: 607 Done on worker:680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 607 Training on worker :491
INFO:root:FL Epoch: 607 Using Learning rate : 0.014862026265115381 
INFO:root:FL Epoch: 607 Normal Training
INFO:root:Worker: 491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418513
INFO:root:Worker: 491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430961
INFO:root:FL Epoch: 607 Norm Difference for worker 491 is 0.747153
INFO:root:FL Epoch: 607 Done on worker:491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 607 Training on worker :1743
INFO:root:FL Epoch: 607 Using Learning rate : 0.014862026265115381 
INFO:root:FL Epoch: 607 Normal Training
INFO:root:Worker: 1743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.833740
INFO:root:Worker: 1743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299039
INFO:root:FL Epoch: 607 Norm Difference for worker 1743 is 0.789547
INFO:root:FL Epoch: 607 Done on worker:1743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 491
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 607 Ends   ===================
INFO:root:Epoch:607 Global Model Test Loss:0.5591941616114449 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:607 Global Model Backdoor Test Loss:0.1380575473109881                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 608 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 608 Workers Selected : [1623, 1108, 1748, 150, 1450, 611, 673, 1016, 676, 1248]
INFO:root:FL Epoch: 608 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 608 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 608 Training on worker :1623
INFO:root:FL Epoch: 608 Using Learning rate : 0.01483230221258515 
INFO:root:FL Epoch: 608 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550915
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443577
INFO:root:FL Epoch: 608 Norm Difference for worker 1623 is 0.803001
INFO:root:FL Epoch: 608 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 608 Training on worker :1108
INFO:root:FL Epoch: 608 Using Learning rate : 0.01483230221258515 
INFO:root:FL Epoch: 608 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312954
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538798
INFO:root:FL Epoch: 608 Norm Difference for worker 1108 is 0.815625
INFO:root:FL Epoch: 608 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 608 Training on worker :1748
INFO:root:FL Epoch: 608 Using Learning rate : 0.01483230221258515 
INFO:root:FL Epoch: 608 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465602
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421649
INFO:root:FL Epoch: 608 Norm Difference for worker 1748 is 0.7702
INFO:root:FL Epoch: 608 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 608 Training on worker :150
INFO:root:FL Epoch: 608 Using Learning rate : 0.01483230221258515 
INFO:root:FL Epoch: 608 Normal Training
INFO:root:Worker: 150 Train Epoch: 0 [0/201 (0%)]	Loss: 0.467123
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 150 Train Epoch: 1 [0/201 (0%)]	Loss: 0.613114
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 608 Norm Difference for worker 150 is 0.830604
INFO:root:FL Epoch: 608 Done on worker:150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 608 Training on worker :1450
INFO:root:FL Epoch: 608 Using Learning rate : 0.01483230221258515 
INFO:root:FL Epoch: 608 Normal Training
INFO:root:Worker: 1450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693144
INFO:root:Worker: 1450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515442
INFO:root:FL Epoch: 608 Norm Difference for worker 1450 is 0.755091
INFO:root:FL Epoch: 608 Done on worker:1450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 608 Training on worker :611
INFO:root:FL Epoch: 608 Using Learning rate : 0.01483230221258515 
INFO:root:FL Epoch: 608 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538577
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403449
INFO:root:FL Epoch: 608 Norm Difference for worker 611 is 0.800652
INFO:root:FL Epoch: 608 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 608 Training on worker :673
INFO:root:FL Epoch: 608 Using Learning rate : 0.01483230221258515 
INFO:root:FL Epoch: 608 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690805
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323880
INFO:root:FL Epoch: 608 Norm Difference for worker 673 is 0.737426
INFO:root:FL Epoch: 608 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 608 Training on worker :1016
INFO:root:FL Epoch: 608 Using Learning rate : 0.01483230221258515 
INFO:root:FL Epoch: 608 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696188
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324490
INFO:root:FL Epoch: 608 Norm Difference for worker 1016 is 0.794266
INFO:root:FL Epoch: 608 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 608 Training on worker :676
INFO:root:FL Epoch: 608 Using Learning rate : 0.01483230221258515 
INFO:root:FL Epoch: 608 Normal Training
INFO:root:Worker: 676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489314
INFO:root:Worker: 676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586056
INFO:root:FL Epoch: 608 Norm Difference for worker 676 is 0.801783
INFO:root:FL Epoch: 608 Done on worker:676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 608 Training on worker :1248
INFO:root:FL Epoch: 608 Using Learning rate : 0.01483230221258515 
INFO:root:FL Epoch: 608 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 1.042684
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362989
INFO:root:FL Epoch: 608 Norm Difference for worker 1248 is 0.773802
INFO:root:FL Epoch: 608 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 673
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 608 Ends   ===================
INFO:root:Epoch:608 Global Model Test Loss:0.5305043844615712 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:608 Global Model Backdoor Test Loss:0.11241890614231427                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 609 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 609 Workers Selected : [1095, 1034, 884, 1106, 854, 1812, 1365, 1153, 368, 741]
INFO:root:FL Epoch: 609 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 609 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 609 Training on worker :1095
INFO:root:FL Epoch: 609 Using Learning rate : 0.014802637608159981 
INFO:root:FL Epoch: 609 Normal Training
INFO:root:Worker: 1095 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491381
INFO:root:Worker: 1095 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423454
INFO:root:FL Epoch: 609 Norm Difference for worker 1095 is 0.704186
INFO:root:FL Epoch: 609 Done on worker:1095
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 609 Training on worker :1034
INFO:root:FL Epoch: 609 Using Learning rate : 0.014802637608159981 
INFO:root:FL Epoch: 609 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650877
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.808818
INFO:root:FL Epoch: 609 Norm Difference for worker 1034 is 0.781482
INFO:root:FL Epoch: 609 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 609 Training on worker :884
INFO:root:FL Epoch: 609 Using Learning rate : 0.014802637608159981 
INFO:root:FL Epoch: 609 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690092
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337067
INFO:root:FL Epoch: 609 Norm Difference for worker 884 is 0.711197
INFO:root:FL Epoch: 609 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 609 Training on worker :1106
INFO:root:FL Epoch: 609 Using Learning rate : 0.014802637608159981 
INFO:root:FL Epoch: 609 Normal Training
INFO:root:Worker: 1106 Train Epoch: 0 [0/200 (0%)]	Loss: 0.229895
INFO:root:Worker: 1106 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641025
INFO:root:FL Epoch: 609 Norm Difference for worker 1106 is 0.683825
INFO:root:FL Epoch: 609 Done on worker:1106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 609 Training on worker :854
INFO:root:FL Epoch: 609 Using Learning rate : 0.014802637608159981 
INFO:root:FL Epoch: 609 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590135
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188578
INFO:root:FL Epoch: 609 Norm Difference for worker 854 is 0.680858
INFO:root:FL Epoch: 609 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 609 Training on worker :1812
INFO:root:FL Epoch: 609 Using Learning rate : 0.014802637608159981 
INFO:root:FL Epoch: 609 Normal Training
INFO:root:Worker: 1812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541826
INFO:root:Worker: 1812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368354
INFO:root:FL Epoch: 609 Norm Difference for worker 1812 is 0.698133
INFO:root:FL Epoch: 609 Done on worker:1812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 609 Training on worker :1365
INFO:root:FL Epoch: 609 Using Learning rate : 0.014802637608159981 
INFO:root:FL Epoch: 609 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448150
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260503
INFO:root:FL Epoch: 609 Norm Difference for worker 1365 is 0.679543
INFO:root:FL Epoch: 609 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 609 Training on worker :1153
INFO:root:FL Epoch: 609 Using Learning rate : 0.014802637608159981 
INFO:root:FL Epoch: 609 Normal Training
INFO:root:Worker: 1153 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367330
INFO:root:Worker: 1153 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291024
INFO:root:FL Epoch: 609 Norm Difference for worker 1153 is 0.685447
INFO:root:FL Epoch: 609 Done on worker:1153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 609 Training on worker :368
INFO:root:FL Epoch: 609 Using Learning rate : 0.014802637608159981 
INFO:root:FL Epoch: 609 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683183
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.713089
INFO:root:FL Epoch: 609 Norm Difference for worker 368 is 0.725687
INFO:root:FL Epoch: 609 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 609 Training on worker :741
INFO:root:FL Epoch: 609 Using Learning rate : 0.014802637608159981 
INFO:root:FL Epoch: 609 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611024
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546678
INFO:root:FL Epoch: 609 Norm Difference for worker 741 is 0.768945
INFO:root:FL Epoch: 609 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1106
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 609 Ends   ===================
INFO:root:Epoch:609 Global Model Test Loss:0.5183240788824418 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:609 Global Model Backdoor Test Loss:0.11305741469065349                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 610 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 610 Workers Selected : [1588, 1566, 1373, 38, 609, 48, 1939, 569, 905, 90]
INFO:root:FL Epoch: 610 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 610 Num points on workers: [200 200 200 201 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 610 Training on worker :1588
INFO:root:FL Epoch: 610 Using Learning rate : 0.014773032332943659 
INFO:root:FL Epoch: 610 Normal Training
INFO:root:Worker: 1588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356125
INFO:root:Worker: 1588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444697
INFO:root:FL Epoch: 610 Norm Difference for worker 1588 is 0.646063
INFO:root:FL Epoch: 610 Done on worker:1588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 610 Training on worker :1566
INFO:root:FL Epoch: 610 Using Learning rate : 0.014773032332943659 
INFO:root:FL Epoch: 610 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493631
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305223
INFO:root:FL Epoch: 610 Norm Difference for worker 1566 is 0.598804
INFO:root:FL Epoch: 610 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 610 Training on worker :1373
INFO:root:FL Epoch: 610 Using Learning rate : 0.014773032332943659 
INFO:root:FL Epoch: 610 Normal Training
INFO:root:Worker: 1373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477032
INFO:root:Worker: 1373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594516
INFO:root:FL Epoch: 610 Norm Difference for worker 1373 is 0.700076
INFO:root:FL Epoch: 610 Done on worker:1373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 610 Training on worker :38
INFO:root:FL Epoch: 610 Using Learning rate : 0.014773032332943659 
INFO:root:FL Epoch: 610 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.341502
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.194350
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 610 Norm Difference for worker 38 is 0.525088
INFO:root:FL Epoch: 610 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 610 Training on worker :609
INFO:root:FL Epoch: 610 Using Learning rate : 0.014773032332943659 
INFO:root:FL Epoch: 610 Normal Training
INFO:root:Worker: 609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474193
INFO:root:Worker: 609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508790
INFO:root:FL Epoch: 610 Norm Difference for worker 609 is 0.691692
INFO:root:FL Epoch: 610 Done on worker:609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 610 Training on worker :48
INFO:root:FL Epoch: 610 Using Learning rate : 0.014773032332943659 
INFO:root:FL Epoch: 610 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.575321
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.504883
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 610 Norm Difference for worker 48 is 0.658084
INFO:root:FL Epoch: 610 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 610 Training on worker :1939
INFO:root:FL Epoch: 610 Using Learning rate : 0.014773032332943659 
INFO:root:FL Epoch: 610 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.850346
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492837
INFO:root:FL Epoch: 610 Norm Difference for worker 1939 is 0.743988
INFO:root:FL Epoch: 610 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 610 Training on worker :569
INFO:root:FL Epoch: 610 Using Learning rate : 0.014773032332943659 
INFO:root:FL Epoch: 610 Normal Training
INFO:root:Worker: 569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474892
INFO:root:Worker: 569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580005
INFO:root:FL Epoch: 610 Norm Difference for worker 569 is 0.71088
INFO:root:FL Epoch: 610 Done on worker:569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 610 Training on worker :905
INFO:root:FL Epoch: 610 Using Learning rate : 0.014773032332943659 
INFO:root:FL Epoch: 610 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614803
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434558
INFO:root:FL Epoch: 610 Norm Difference for worker 905 is 0.667723
INFO:root:FL Epoch: 610 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 610 Training on worker :90
INFO:root:FL Epoch: 610 Using Learning rate : 0.014773032332943659 
INFO:root:FL Epoch: 610 Normal Training
INFO:root:Worker: 90 Train Epoch: 0 [0/201 (0%)]	Loss: 0.669115
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 90 Train Epoch: 1 [0/201 (0%)]	Loss: 0.747749
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 610 Norm Difference for worker 90 is 0.734063
INFO:root:FL Epoch: 610 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 38
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 610 Ends   ===================
INFO:root:Epoch:610 Global Model Test Loss:0.5250242615447325 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:610 Global Model Backdoor Test Loss:0.07417513368030389                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 611 Begins ===================
INFO:root:FL Epoch: 611 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 611 Workers Selected : [0, 1, 2, 1347, 1697, 1523, 1370, 1900, 1837, 1578]
INFO:root:FL Epoch: 611 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 611 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 611 Training on worker :0
INFO:root:FL Epoch: 611 Using Learning rate : 0.0029486972536555546 
INFO:root:FL Epoch: 611 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.139512
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.150179
INFO:root:FL Epoch: 611 Worker: 0 Backdoor Test Loss: 0.07261342244843642 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 611 Worker: 0 Backdoor Train Loss: 0.10441769808530807 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 611 Norm Difference for worker 0 is 0.077165
INFO:root:FL Epoch: 611 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 611 Training on worker :1
INFO:root:FL Epoch: 611 Using Learning rate : 0.0029486972536555546 
INFO:root:FL Epoch: 611 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.166124
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.124456
INFO:root:FL Epoch: 611 Worker: 1 Backdoor Test Loss: 0.0725873311360677 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 611 Worker: 1 Backdoor Train Loss: 0.10373321026563645 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 611 Norm Difference for worker 1 is 0.082228
INFO:root:FL Epoch: 611 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 611 Training on worker :2
INFO:root:FL Epoch: 611 Using Learning rate : 0.0029486972536555546 
INFO:root:FL Epoch: 611 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.065266
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.148075
INFO:root:FL Epoch: 611 Worker: 2 Backdoor Test Loss: 0.07179108758767445 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 611 Worker: 2 Backdoor Train Loss: 0.10439397990703583 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 611 Norm Difference for worker 2 is 0.077339
INFO:root:FL Epoch: 611 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 611 Training on worker :1347
INFO:root:FL Epoch: 611 Using Learning rate : 0.014743486268277773 
INFO:root:FL Epoch: 611 Normal Training
INFO:root:Worker: 1347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620762
INFO:root:Worker: 1347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544604
INFO:root:FL Epoch: 611 Norm Difference for worker 1347 is 0.7863
INFO:root:FL Epoch: 611 Done on worker:1347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 611 Training on worker :1697
INFO:root:FL Epoch: 611 Using Learning rate : 0.014743486268277773 
INFO:root:FL Epoch: 611 Normal Training
INFO:root:Worker: 1697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.843924
INFO:root:Worker: 1697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295160
INFO:root:FL Epoch: 611 Norm Difference for worker 1697 is 0.772963
INFO:root:FL Epoch: 611 Done on worker:1697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 611 Training on worker :1523
INFO:root:FL Epoch: 611 Using Learning rate : 0.014743486268277773 
INFO:root:FL Epoch: 611 Normal Training
INFO:root:Worker: 1523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782695
INFO:root:Worker: 1523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362657
INFO:root:FL Epoch: 611 Norm Difference for worker 1523 is 0.756098
INFO:root:FL Epoch: 611 Done on worker:1523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 611 Training on worker :1370
INFO:root:FL Epoch: 611 Using Learning rate : 0.014743486268277773 
INFO:root:FL Epoch: 611 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675496
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618711
INFO:root:FL Epoch: 611 Norm Difference for worker 1370 is 0.727483
INFO:root:FL Epoch: 611 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 611 Training on worker :1900
INFO:root:FL Epoch: 611 Using Learning rate : 0.014743486268277773 
INFO:root:FL Epoch: 611 Normal Training
INFO:root:Worker: 1900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543369
INFO:root:Worker: 1900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480809
INFO:root:FL Epoch: 611 Norm Difference for worker 1900 is 0.786447
INFO:root:FL Epoch: 611 Done on worker:1900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 611 Training on worker :1837
INFO:root:FL Epoch: 611 Using Learning rate : 0.014743486268277773 
INFO:root:FL Epoch: 611 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375611
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360015
INFO:root:FL Epoch: 611 Norm Difference for worker 1837 is 0.780911
INFO:root:FL Epoch: 611 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 611 Training on worker :1578
INFO:root:FL Epoch: 611 Using Learning rate : 0.014743486268277773 
INFO:root:FL Epoch: 611 Normal Training
INFO:root:Worker: 1578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703782
INFO:root:Worker: 1578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338939
INFO:root:FL Epoch: 611 Norm Difference for worker 1578 is 0.723397
INFO:root:FL Epoch: 611 Done on worker:1578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 611 Ends   ===================
INFO:root:Epoch:611 Global Model Test Loss:0.5282860065207762 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:611 Global Model Backdoor Test Loss:0.07261342244843642                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 612 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 612 Workers Selected : [1440, 141, 1453, 738, 655, 1904, 396, 1209, 903, 881]
INFO:root:FL Epoch: 612 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 612 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 612 Training on worker :1440
INFO:root:FL Epoch: 612 Using Learning rate : 0.014713999295741218 
INFO:root:FL Epoch: 612 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364589
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405252
INFO:root:FL Epoch: 612 Norm Difference for worker 1440 is 0.744148
INFO:root:FL Epoch: 612 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 612 Training on worker :141
INFO:root:FL Epoch: 612 Using Learning rate : 0.014713999295741218 
INFO:root:FL Epoch: 612 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.351997
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.392476
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 612 Norm Difference for worker 141 is 0.715984
INFO:root:FL Epoch: 612 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 612 Training on worker :1453
INFO:root:FL Epoch: 612 Using Learning rate : 0.014713999295741218 
INFO:root:FL Epoch: 612 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486329
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535182
INFO:root:FL Epoch: 612 Norm Difference for worker 1453 is 0.805654
INFO:root:FL Epoch: 612 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 612 Training on worker :738
INFO:root:FL Epoch: 612 Using Learning rate : 0.014713999295741218 
INFO:root:FL Epoch: 612 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353057
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619034
INFO:root:FL Epoch: 612 Norm Difference for worker 738 is 0.819956
INFO:root:FL Epoch: 612 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 612 Training on worker :655
INFO:root:FL Epoch: 612 Using Learning rate : 0.014713999295741218 
INFO:root:FL Epoch: 612 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415569
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617160
INFO:root:FL Epoch: 612 Norm Difference for worker 655 is 0.724025
INFO:root:FL Epoch: 612 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 612 Training on worker :1904
INFO:root:FL Epoch: 612 Using Learning rate : 0.014713999295741218 
INFO:root:FL Epoch: 612 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666195
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594217
INFO:root:FL Epoch: 612 Norm Difference for worker 1904 is 0.730757
INFO:root:FL Epoch: 612 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 612 Training on worker :396
INFO:root:FL Epoch: 612 Using Learning rate : 0.014713999295741218 
INFO:root:FL Epoch: 612 Normal Training
INFO:root:Worker: 396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462728
INFO:root:Worker: 396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438491
INFO:root:FL Epoch: 612 Norm Difference for worker 396 is 0.725806
INFO:root:FL Epoch: 612 Done on worker:396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 612 Training on worker :1209
INFO:root:FL Epoch: 612 Using Learning rate : 0.014713999295741218 
INFO:root:FL Epoch: 612 Normal Training
INFO:root:Worker: 1209 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561148
INFO:root:Worker: 1209 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400832
INFO:root:FL Epoch: 612 Norm Difference for worker 1209 is 0.672621
INFO:root:FL Epoch: 612 Done on worker:1209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 612 Training on worker :903
INFO:root:FL Epoch: 612 Using Learning rate : 0.014713999295741218 
INFO:root:FL Epoch: 612 Normal Training
INFO:root:Worker: 903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550468
INFO:root:Worker: 903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381165
INFO:root:FL Epoch: 612 Norm Difference for worker 903 is 0.761734
INFO:root:FL Epoch: 612 Done on worker:903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 612 Training on worker :881
INFO:root:FL Epoch: 612 Using Learning rate : 0.014713999295741218 
INFO:root:FL Epoch: 612 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555287
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408667
INFO:root:FL Epoch: 612 Norm Difference for worker 881 is 0.663694
INFO:root:FL Epoch: 612 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1209
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 612 Ends   ===================
INFO:root:Epoch:612 Global Model Test Loss:0.5089967320947086 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:612 Global Model Backdoor Test Loss:0.09600698761641979                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 613 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 613 Workers Selected : [459, 6, 1260, 1890, 606, 1654, 276, 718, 1641, 1195]
INFO:root:FL Epoch: 613 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 613 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 613 Training on worker :459
INFO:root:FL Epoch: 613 Using Learning rate : 0.014684571297149736 
INFO:root:FL Epoch: 613 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374542
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589673
INFO:root:FL Epoch: 613 Norm Difference for worker 459 is 0.686679
INFO:root:FL Epoch: 613 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 613 Training on worker :6
INFO:root:FL Epoch: 613 Using Learning rate : 0.014684571297149736 
INFO:root:FL Epoch: 613 Normal Training
INFO:root:Worker: 6 Train Epoch: 0 [0/201 (0%)]	Loss: 0.464964
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 6 Train Epoch: 1 [0/201 (0%)]	Loss: 0.496442
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 613 Norm Difference for worker 6 is 0.637808
INFO:root:FL Epoch: 613 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 613 Training on worker :1260
INFO:root:FL Epoch: 613 Using Learning rate : 0.014684571297149736 
INFO:root:FL Epoch: 613 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569555
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494308
INFO:root:FL Epoch: 613 Norm Difference for worker 1260 is 0.7005
INFO:root:FL Epoch: 613 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 613 Training on worker :1890
INFO:root:FL Epoch: 613 Using Learning rate : 0.014684571297149736 
INFO:root:FL Epoch: 613 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700758
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620682
INFO:root:FL Epoch: 613 Norm Difference for worker 1890 is 0.763797
INFO:root:FL Epoch: 613 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 613 Training on worker :606
INFO:root:FL Epoch: 613 Using Learning rate : 0.014684571297149736 
INFO:root:FL Epoch: 613 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418946
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.193288
INFO:root:FL Epoch: 613 Norm Difference for worker 606 is 0.500717
INFO:root:FL Epoch: 613 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 613 Training on worker :1654
INFO:root:FL Epoch: 613 Using Learning rate : 0.014684571297149736 
INFO:root:FL Epoch: 613 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676697
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436360
INFO:root:FL Epoch: 613 Norm Difference for worker 1654 is 0.711766
INFO:root:FL Epoch: 613 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 613 Training on worker :276
INFO:root:FL Epoch: 613 Using Learning rate : 0.014684571297149736 
INFO:root:FL Epoch: 613 Normal Training
INFO:root:Worker: 276 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503794
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 276 Train Epoch: 1 [0/201 (0%)]	Loss: 0.266131
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 613 Norm Difference for worker 276 is 0.705408
INFO:root:FL Epoch: 613 Done on worker:276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 613 Training on worker :718
INFO:root:FL Epoch: 613 Using Learning rate : 0.014684571297149736 
INFO:root:FL Epoch: 613 Normal Training
INFO:root:Worker: 718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440011
INFO:root:Worker: 718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312687
INFO:root:FL Epoch: 613 Norm Difference for worker 718 is 0.701149
INFO:root:FL Epoch: 613 Done on worker:718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 613 Training on worker :1641
INFO:root:FL Epoch: 613 Using Learning rate : 0.014684571297149736 
INFO:root:FL Epoch: 613 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400402
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417087
INFO:root:FL Epoch: 613 Norm Difference for worker 1641 is 0.691449
INFO:root:FL Epoch: 613 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 613 Training on worker :1195
INFO:root:FL Epoch: 613 Using Learning rate : 0.014684571297149736 
INFO:root:FL Epoch: 613 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564208
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416022
INFO:root:FL Epoch: 613 Norm Difference for worker 1195 is 0.719237
INFO:root:FL Epoch: 613 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 606
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 613 Ends   ===================
INFO:root:Epoch:613 Global Model Test Loss:0.5259406496496761 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:613 Global Model Backdoor Test Loss:0.12105075766642888                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 614 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 614 Workers Selected : [1250, 1532, 1790, 1295, 290, 1589, 1759, 1893, 1747, 1008]
INFO:root:FL Epoch: 614 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 614 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 614 Training on worker :1250
INFO:root:FL Epoch: 614 Using Learning rate : 0.014655202154555434 
INFO:root:FL Epoch: 614 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494592
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434169
INFO:root:FL Epoch: 614 Norm Difference for worker 1250 is 0.690019
INFO:root:FL Epoch: 614 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 614 Training on worker :1532
INFO:root:FL Epoch: 614 Using Learning rate : 0.014655202154555434 
INFO:root:FL Epoch: 614 Normal Training
INFO:root:Worker: 1532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397063
INFO:root:Worker: 1532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596485
INFO:root:FL Epoch: 614 Norm Difference for worker 1532 is 0.686153
INFO:root:FL Epoch: 614 Done on worker:1532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 614 Training on worker :1790
INFO:root:FL Epoch: 614 Using Learning rate : 0.014655202154555434 
INFO:root:FL Epoch: 614 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748610
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668921
INFO:root:FL Epoch: 614 Norm Difference for worker 1790 is 0.729056
INFO:root:FL Epoch: 614 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 614 Training on worker :1295
INFO:root:FL Epoch: 614 Using Learning rate : 0.014655202154555434 
INFO:root:FL Epoch: 614 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546175
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335574
INFO:root:FL Epoch: 614 Norm Difference for worker 1295 is 0.644851
INFO:root:FL Epoch: 614 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 614 Training on worker :290
INFO:root:FL Epoch: 614 Using Learning rate : 0.014655202154555434 
INFO:root:FL Epoch: 614 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.664061
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.297488
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 614 Norm Difference for worker 290 is 0.757267
INFO:root:FL Epoch: 614 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 614 Training on worker :1589
INFO:root:FL Epoch: 614 Using Learning rate : 0.014655202154555434 
INFO:root:FL Epoch: 614 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.311814
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445784
INFO:root:FL Epoch: 614 Norm Difference for worker 1589 is 0.745687
INFO:root:FL Epoch: 614 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 614 Training on worker :1759
INFO:root:FL Epoch: 614 Using Learning rate : 0.014655202154555434 
INFO:root:FL Epoch: 614 Normal Training
INFO:root:Worker: 1759 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562933
INFO:root:Worker: 1759 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553015
INFO:root:FL Epoch: 614 Norm Difference for worker 1759 is 0.714249
INFO:root:FL Epoch: 614 Done on worker:1759
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 614 Training on worker :1893
INFO:root:FL Epoch: 614 Using Learning rate : 0.014655202154555434 
INFO:root:FL Epoch: 614 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643754
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544378
INFO:root:FL Epoch: 614 Norm Difference for worker 1893 is 0.807184
INFO:root:FL Epoch: 614 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 614 Training on worker :1747
INFO:root:FL Epoch: 614 Using Learning rate : 0.014655202154555434 
INFO:root:FL Epoch: 614 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609639
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466500
INFO:root:FL Epoch: 614 Norm Difference for worker 1747 is 0.788965
INFO:root:FL Epoch: 614 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 614 Training on worker :1008
INFO:root:FL Epoch: 614 Using Learning rate : 0.014655202154555434 
INFO:root:FL Epoch: 614 Normal Training
INFO:root:Worker: 1008 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812068
INFO:root:Worker: 1008 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501340
INFO:root:FL Epoch: 614 Norm Difference for worker 1008 is 0.810659
INFO:root:FL Epoch: 614 Done on worker:1008
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1295
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 614 Ends   ===================
INFO:root:Epoch:614 Global Model Test Loss:0.5212073255987728 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:614 Global Model Backdoor Test Loss:0.11876529331008594                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 615 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 615 Workers Selected : [1413, 172, 86, 370, 1824, 1386, 472, 1000, 637, 1934]
INFO:root:FL Epoch: 615 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 615 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 615 Training on worker :1413
INFO:root:FL Epoch: 615 Using Learning rate : 0.014625891750246324 
INFO:root:FL Epoch: 615 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672217
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393414
INFO:root:FL Epoch: 615 Norm Difference for worker 1413 is 0.718162
INFO:root:FL Epoch: 615 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 615 Training on worker :172
INFO:root:FL Epoch: 615 Using Learning rate : 0.014625891750246324 
INFO:root:FL Epoch: 615 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.466336
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.369133
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 615 Norm Difference for worker 172 is 0.692807
INFO:root:FL Epoch: 615 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 615 Training on worker :86
INFO:root:FL Epoch: 615 Using Learning rate : 0.014625891750246324 
INFO:root:FL Epoch: 615 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.178997
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.289054
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 615 Norm Difference for worker 86 is 0.493559
INFO:root:FL Epoch: 615 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 615 Training on worker :370
INFO:root:FL Epoch: 615 Using Learning rate : 0.014625891750246324 
INFO:root:FL Epoch: 615 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731337
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655776
INFO:root:FL Epoch: 615 Norm Difference for worker 370 is 0.719248
INFO:root:FL Epoch: 615 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 615 Training on worker :1824
INFO:root:FL Epoch: 615 Using Learning rate : 0.014625891750246324 
INFO:root:FL Epoch: 615 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.959040
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699812
INFO:root:FL Epoch: 615 Norm Difference for worker 1824 is 0.756336
INFO:root:FL Epoch: 615 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 615 Training on worker :1386
INFO:root:FL Epoch: 615 Using Learning rate : 0.014625891750246324 
INFO:root:FL Epoch: 615 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651340
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267772
INFO:root:FL Epoch: 615 Norm Difference for worker 1386 is 0.675018
INFO:root:FL Epoch: 615 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 615 Training on worker :472
INFO:root:FL Epoch: 615 Using Learning rate : 0.014625891750246324 
INFO:root:FL Epoch: 615 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442316
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.191392
INFO:root:FL Epoch: 615 Norm Difference for worker 472 is 0.678318
INFO:root:FL Epoch: 615 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 615 Training on worker :1000
INFO:root:FL Epoch: 615 Using Learning rate : 0.014625891750246324 
INFO:root:FL Epoch: 615 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.903699
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390391
INFO:root:FL Epoch: 615 Norm Difference for worker 1000 is 0.774548
INFO:root:FL Epoch: 615 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 615 Training on worker :637
INFO:root:FL Epoch: 615 Using Learning rate : 0.014625891750246324 
INFO:root:FL Epoch: 615 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540746
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455212
INFO:root:FL Epoch: 615 Norm Difference for worker 637 is 0.749327
INFO:root:FL Epoch: 615 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 615 Training on worker :1934
INFO:root:FL Epoch: 615 Using Learning rate : 0.014625891750246324 
INFO:root:FL Epoch: 615 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382217
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346779
INFO:root:FL Epoch: 615 Norm Difference for worker 1934 is 0.743545
INFO:root:FL Epoch: 615 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 86
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 615 Ends   ===================
INFO:root:Epoch:615 Global Model Test Loss:0.5169142326887917 and Test Accuracy:75.0 
INFO:root:Epoch:615 Global Model Backdoor Test Loss:0.08984227975209554                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 616 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 616 Workers Selected : [337, 431, 1785, 716, 52, 758, 1794, 162, 1203, 898]
INFO:root:FL Epoch: 616 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 616 Num points on workers: [201 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 616 Training on worker :337
INFO:root:FL Epoch: 616 Using Learning rate : 0.01459663996674583 
INFO:root:FL Epoch: 616 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.521115
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.247516
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 616 Norm Difference for worker 337 is 0.732977
INFO:root:FL Epoch: 616 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 616 Training on worker :431
INFO:root:FL Epoch: 616 Using Learning rate : 0.01459663996674583 
INFO:root:FL Epoch: 616 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475780
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509140
INFO:root:FL Epoch: 616 Norm Difference for worker 431 is 0.826239
INFO:root:FL Epoch: 616 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 616 Training on worker :1785
INFO:root:FL Epoch: 616 Using Learning rate : 0.01459663996674583 
INFO:root:FL Epoch: 616 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.795309
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499215
INFO:root:FL Epoch: 616 Norm Difference for worker 1785 is 0.844508
INFO:root:FL Epoch: 616 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 616 Training on worker :716
INFO:root:FL Epoch: 616 Using Learning rate : 0.01459663996674583 
INFO:root:FL Epoch: 616 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360998
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194526
INFO:root:FL Epoch: 616 Norm Difference for worker 716 is 0.741495
INFO:root:FL Epoch: 616 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 616 Training on worker :52
INFO:root:FL Epoch: 616 Using Learning rate : 0.01459663996674583 
INFO:root:FL Epoch: 616 Normal Training
INFO:root:Worker: 52 Train Epoch: 0 [0/201 (0%)]	Loss: 0.524862
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 52 Train Epoch: 1 [0/201 (0%)]	Loss: 0.650532
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 616 Norm Difference for worker 52 is 0.808488
INFO:root:FL Epoch: 616 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 616 Training on worker :758
INFO:root:FL Epoch: 616 Using Learning rate : 0.01459663996674583 
INFO:root:FL Epoch: 616 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487885
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.829976
INFO:root:FL Epoch: 616 Norm Difference for worker 758 is 0.828429
INFO:root:FL Epoch: 616 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 616 Training on worker :1794
INFO:root:FL Epoch: 616 Using Learning rate : 0.01459663996674583 
INFO:root:FL Epoch: 616 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387618
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375123
INFO:root:FL Epoch: 616 Norm Difference for worker 1794 is 0.820136
INFO:root:FL Epoch: 616 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 616 Training on worker :162
INFO:root:FL Epoch: 616 Using Learning rate : 0.01459663996674583 
INFO:root:FL Epoch: 616 Normal Training
INFO:root:Worker: 162 Train Epoch: 0 [0/201 (0%)]	Loss: 0.682376
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 162 Train Epoch: 1 [0/201 (0%)]	Loss: 0.443345
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 616 Norm Difference for worker 162 is 0.791351
INFO:root:FL Epoch: 616 Done on worker:162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 616 Training on worker :1203
INFO:root:FL Epoch: 616 Using Learning rate : 0.01459663996674583 
INFO:root:FL Epoch: 616 Normal Training
INFO:root:Worker: 1203 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370414
INFO:root:Worker: 1203 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424766
INFO:root:FL Epoch: 616 Norm Difference for worker 1203 is 0.796802
INFO:root:FL Epoch: 616 Done on worker:1203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 616 Training on worker :898
INFO:root:FL Epoch: 616 Using Learning rate : 0.01459663996674583 
INFO:root:FL Epoch: 616 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727928
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422068
INFO:root:FL Epoch: 616 Norm Difference for worker 898 is 0.822667
INFO:root:FL Epoch: 616 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 337
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 616 Ends   ===================
INFO:root:Epoch:616 Global Model Test Loss:0.5137349665164948 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:616 Global Model Backdoor Test Loss:0.09145187214016914                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 617 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 617 Workers Selected : [1578, 1877, 1722, 1440, 1829, 671, 994, 651, 1136, 1386]
INFO:root:FL Epoch: 617 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 617 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 617 Training on worker :1578
INFO:root:FL Epoch: 617 Using Learning rate : 0.01456744668681234 
INFO:root:FL Epoch: 617 Normal Training
INFO:root:Worker: 1578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368576
INFO:root:Worker: 1578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.773196
INFO:root:FL Epoch: 617 Norm Difference for worker 1578 is 0.668658
INFO:root:FL Epoch: 617 Done on worker:1578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 617 Training on worker :1877
INFO:root:FL Epoch: 617 Using Learning rate : 0.01456744668681234 
INFO:root:FL Epoch: 617 Normal Training
INFO:root:Worker: 1877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352585
INFO:root:Worker: 1877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580620
INFO:root:FL Epoch: 617 Norm Difference for worker 1877 is 0.685439
INFO:root:FL Epoch: 617 Done on worker:1877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 617 Training on worker :1722
INFO:root:FL Epoch: 617 Using Learning rate : 0.01456744668681234 
INFO:root:FL Epoch: 617 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670348
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247162
INFO:root:FL Epoch: 617 Norm Difference for worker 1722 is 0.733534
INFO:root:FL Epoch: 617 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 617 Training on worker :1440
INFO:root:FL Epoch: 617 Using Learning rate : 0.01456744668681234 
INFO:root:FL Epoch: 617 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735036
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686094
INFO:root:FL Epoch: 617 Norm Difference for worker 1440 is 0.707407
INFO:root:FL Epoch: 617 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 617 Training on worker :1829
INFO:root:FL Epoch: 617 Using Learning rate : 0.01456744668681234 
INFO:root:FL Epoch: 617 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674041
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278191
INFO:root:FL Epoch: 617 Norm Difference for worker 1829 is 0.748988
INFO:root:FL Epoch: 617 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 617 Training on worker :671
INFO:root:FL Epoch: 617 Using Learning rate : 0.01456744668681234 
INFO:root:FL Epoch: 617 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455244
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423940
INFO:root:FL Epoch: 617 Norm Difference for worker 671 is 0.667598
INFO:root:FL Epoch: 617 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 617 Training on worker :994
INFO:root:FL Epoch: 617 Using Learning rate : 0.01456744668681234 
INFO:root:FL Epoch: 617 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469778
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330872
INFO:root:FL Epoch: 617 Norm Difference for worker 994 is 0.73145
INFO:root:FL Epoch: 617 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 617 Training on worker :651
INFO:root:FL Epoch: 617 Using Learning rate : 0.01456744668681234 
INFO:root:FL Epoch: 617 Normal Training
INFO:root:Worker: 651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446917
INFO:root:Worker: 651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425261
INFO:root:FL Epoch: 617 Norm Difference for worker 651 is 0.736259
INFO:root:FL Epoch: 617 Done on worker:651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 617 Training on worker :1136
INFO:root:FL Epoch: 617 Using Learning rate : 0.01456744668681234 
INFO:root:FL Epoch: 617 Normal Training
INFO:root:Worker: 1136 Train Epoch: 0 [0/200 (0%)]	Loss: 0.295745
INFO:root:Worker: 1136 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464376
INFO:root:FL Epoch: 617 Norm Difference for worker 1136 is 0.720313
INFO:root:FL Epoch: 617 Done on worker:1136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 617 Training on worker :1386
INFO:root:FL Epoch: 617 Using Learning rate : 0.01456744668681234 
INFO:root:FL Epoch: 617 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519291
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366865
INFO:root:FL Epoch: 617 Norm Difference for worker 1386 is 0.710024
INFO:root:FL Epoch: 617 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1578
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 617 Ends   ===================
INFO:root:Epoch:617 Global Model Test Loss:0.5091862433096942 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:617 Global Model Backdoor Test Loss:0.12909431010484695                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 618 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 618 Workers Selected : [1394, 446, 1001, 597, 430, 98, 478, 1158, 171, 285]
INFO:root:FL Epoch: 618 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 618 Num points on workers: [200 200 200 200 200 201 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 618 Training on worker :1394
INFO:root:FL Epoch: 618 Using Learning rate : 0.014538311793438714 
INFO:root:FL Epoch: 618 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663520
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501170
INFO:root:FL Epoch: 618 Norm Difference for worker 1394 is 0.683972
INFO:root:FL Epoch: 618 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 618 Training on worker :446
INFO:root:FL Epoch: 618 Using Learning rate : 0.014538311793438714 
INFO:root:FL Epoch: 618 Normal Training
INFO:root:Worker: 446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394997
INFO:root:Worker: 446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412471
INFO:root:FL Epoch: 618 Norm Difference for worker 446 is 0.681036
INFO:root:FL Epoch: 618 Done on worker:446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 618 Training on worker :1001
INFO:root:FL Epoch: 618 Using Learning rate : 0.014538311793438714 
INFO:root:FL Epoch: 618 Normal Training
INFO:root:Worker: 1001 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608161
INFO:root:Worker: 1001 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393487
INFO:root:FL Epoch: 618 Norm Difference for worker 1001 is 0.675411
INFO:root:FL Epoch: 618 Done on worker:1001
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 618 Training on worker :597
INFO:root:FL Epoch: 618 Using Learning rate : 0.014538311793438714 
INFO:root:FL Epoch: 618 Normal Training
INFO:root:Worker: 597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458016
INFO:root:Worker: 597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374403
INFO:root:FL Epoch: 618 Norm Difference for worker 597 is 0.681518
INFO:root:FL Epoch: 618 Done on worker:597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 618 Training on worker :430
INFO:root:FL Epoch: 618 Using Learning rate : 0.014538311793438714 
INFO:root:FL Epoch: 618 Normal Training
INFO:root:Worker: 430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485388
INFO:root:Worker: 430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328264
INFO:root:FL Epoch: 618 Norm Difference for worker 430 is 0.621983
INFO:root:FL Epoch: 618 Done on worker:430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 618 Training on worker :98
INFO:root:FL Epoch: 618 Using Learning rate : 0.014538311793438714 
INFO:root:FL Epoch: 618 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.422250
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.352082
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 618 Norm Difference for worker 98 is 0.669599
INFO:root:FL Epoch: 618 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 618 Training on worker :478
INFO:root:FL Epoch: 618 Using Learning rate : 0.014538311793438714 
INFO:root:FL Epoch: 618 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405807
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430837
INFO:root:FL Epoch: 618 Norm Difference for worker 478 is 0.645418
INFO:root:FL Epoch: 618 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 618 Training on worker :1158
INFO:root:FL Epoch: 618 Using Learning rate : 0.014538311793438714 
INFO:root:FL Epoch: 618 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535869
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299436
INFO:root:FL Epoch: 618 Norm Difference for worker 1158 is 0.612085
INFO:root:FL Epoch: 618 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 618 Training on worker :171
INFO:root:FL Epoch: 618 Using Learning rate : 0.014538311793438714 
INFO:root:FL Epoch: 618 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.566364
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.606649
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 618 Norm Difference for worker 171 is 0.676159
INFO:root:FL Epoch: 618 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 618 Training on worker :285
INFO:root:FL Epoch: 618 Using Learning rate : 0.014538311793438714 
INFO:root:FL Epoch: 618 Normal Training
INFO:root:Worker: 285 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581932
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 285 Train Epoch: 1 [0/201 (0%)]	Loss: 0.491051
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 618 Norm Difference for worker 285 is 0.651299
INFO:root:FL Epoch: 618 Done on worker:285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1158
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 618 Ends   ===================
INFO:root:Epoch:618 Global Model Test Loss:0.5097828840508181 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:618 Global Model Backdoor Test Loss:0.11315427348017693                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 619 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 619 Workers Selected : [1565, 1770, 855, 807, 185, 421, 1904, 1529, 162, 1104]
INFO:root:FL Epoch: 619 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 619 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 619 Training on worker :1565
INFO:root:FL Epoch: 619 Using Learning rate : 0.014509235169851836 
INFO:root:FL Epoch: 619 Normal Training
INFO:root:Worker: 1565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751855
INFO:root:Worker: 1565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391720
INFO:root:FL Epoch: 619 Norm Difference for worker 1565 is 0.686249
INFO:root:FL Epoch: 619 Done on worker:1565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 619 Training on worker :1770
INFO:root:FL Epoch: 619 Using Learning rate : 0.014509235169851836 
INFO:root:FL Epoch: 619 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464106
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354258
INFO:root:FL Epoch: 619 Norm Difference for worker 1770 is 0.606314
INFO:root:FL Epoch: 619 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 619 Training on worker :855
INFO:root:FL Epoch: 619 Using Learning rate : 0.014509235169851836 
INFO:root:FL Epoch: 619 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549924
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392758
INFO:root:FL Epoch: 619 Norm Difference for worker 855 is 0.712051
INFO:root:FL Epoch: 619 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 619 Training on worker :807
INFO:root:FL Epoch: 619 Using Learning rate : 0.014509235169851836 
INFO:root:FL Epoch: 619 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390428
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493303
INFO:root:FL Epoch: 619 Norm Difference for worker 807 is 0.691913
INFO:root:FL Epoch: 619 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 619 Training on worker :185
INFO:root:FL Epoch: 619 Using Learning rate : 0.014509235169851836 
INFO:root:FL Epoch: 619 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518037
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.243710
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 619 Norm Difference for worker 185 is 0.632682
INFO:root:FL Epoch: 619 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 619 Training on worker :421
INFO:root:FL Epoch: 619 Using Learning rate : 0.014509235169851836 
INFO:root:FL Epoch: 619 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599260
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347157
INFO:root:FL Epoch: 619 Norm Difference for worker 421 is 0.6662
INFO:root:FL Epoch: 619 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 619 Training on worker :1904
INFO:root:FL Epoch: 619 Using Learning rate : 0.014509235169851836 
INFO:root:FL Epoch: 619 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376164
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412768
INFO:root:FL Epoch: 619 Norm Difference for worker 1904 is 0.626815
INFO:root:FL Epoch: 619 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 619 Training on worker :1529
INFO:root:FL Epoch: 619 Using Learning rate : 0.014509235169851836 
INFO:root:FL Epoch: 619 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.827863
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487928
INFO:root:FL Epoch: 619 Norm Difference for worker 1529 is 0.702026
INFO:root:FL Epoch: 619 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 619 Training on worker :162
INFO:root:FL Epoch: 619 Using Learning rate : 0.014509235169851836 
INFO:root:FL Epoch: 619 Normal Training
INFO:root:Worker: 162 Train Epoch: 0 [0/201 (0%)]	Loss: 0.649374
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 162 Train Epoch: 1 [0/201 (0%)]	Loss: 0.437677
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 619 Norm Difference for worker 162 is 0.628459
INFO:root:FL Epoch: 619 Done on worker:162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 619 Training on worker :1104
INFO:root:FL Epoch: 619 Using Learning rate : 0.014509235169851836 
INFO:root:FL Epoch: 619 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.847910
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536655
INFO:root:FL Epoch: 619 Norm Difference for worker 1104 is 0.727069
INFO:root:FL Epoch: 619 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1770
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 619 Ends   ===================
INFO:root:Epoch:619 Global Model Test Loss:0.5243916494004867 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:619 Global Model Backdoor Test Loss:0.12955566371480623                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 620 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 620 Workers Selected : [1780, 132, 501, 1727, 1308, 1584, 1596, 1485, 854, 363]
INFO:root:FL Epoch: 620 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 620 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 620 Training on worker :1780
INFO:root:FL Epoch: 620 Using Learning rate : 0.014480216699512133 
INFO:root:FL Epoch: 620 Normal Training
INFO:root:Worker: 1780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360012
INFO:root:Worker: 1780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274858
INFO:root:FL Epoch: 620 Norm Difference for worker 1780 is 0.613714
INFO:root:FL Epoch: 620 Done on worker:1780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 620 Training on worker :132
INFO:root:FL Epoch: 620 Using Learning rate : 0.014480216699512133 
INFO:root:FL Epoch: 620 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.486298
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.516787
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 620 Norm Difference for worker 132 is 0.687354
INFO:root:FL Epoch: 620 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 620 Training on worker :501
INFO:root:FL Epoch: 620 Using Learning rate : 0.014480216699512133 
INFO:root:FL Epoch: 620 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362738
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324563
INFO:root:FL Epoch: 620 Norm Difference for worker 501 is 0.625886
INFO:root:FL Epoch: 620 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 620 Training on worker :1727
INFO:root:FL Epoch: 620 Using Learning rate : 0.014480216699512133 
INFO:root:FL Epoch: 620 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571324
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477942
INFO:root:FL Epoch: 620 Norm Difference for worker 1727 is 0.59683
INFO:root:FL Epoch: 620 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 620 Training on worker :1308
INFO:root:FL Epoch: 620 Using Learning rate : 0.014480216699512133 
INFO:root:FL Epoch: 620 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564690
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178025
INFO:root:FL Epoch: 620 Norm Difference for worker 1308 is 0.647421
INFO:root:FL Epoch: 620 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 620 Training on worker :1584
INFO:root:FL Epoch: 620 Using Learning rate : 0.014480216699512133 
INFO:root:FL Epoch: 620 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469320
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216927
INFO:root:FL Epoch: 620 Norm Difference for worker 1584 is 0.625731
INFO:root:FL Epoch: 620 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 620 Training on worker :1596
INFO:root:FL Epoch: 620 Using Learning rate : 0.014480216699512133 
INFO:root:FL Epoch: 620 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.896248
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345749
INFO:root:FL Epoch: 620 Norm Difference for worker 1596 is 0.645668
INFO:root:FL Epoch: 620 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 620 Training on worker :1485
INFO:root:FL Epoch: 620 Using Learning rate : 0.014480216699512133 
INFO:root:FL Epoch: 620 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579579
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501279
INFO:root:FL Epoch: 620 Norm Difference for worker 1485 is 0.651676
INFO:root:FL Epoch: 620 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 620 Training on worker :854
INFO:root:FL Epoch: 620 Using Learning rate : 0.014480216699512133 
INFO:root:FL Epoch: 620 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404087
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439624
INFO:root:FL Epoch: 620 Norm Difference for worker 854 is 0.658203
INFO:root:FL Epoch: 620 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 620 Training on worker :363
INFO:root:FL Epoch: 620 Using Learning rate : 0.014480216699512133 
INFO:root:FL Epoch: 620 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419461
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408712
INFO:root:FL Epoch: 620 Norm Difference for worker 363 is 0.76564
INFO:root:FL Epoch: 620 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1727
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 620 Ends   ===================
INFO:root:Epoch:620 Global Model Test Loss:0.5201352221124312 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:620 Global Model Backdoor Test Loss:0.14621659244100252                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 621 Begins ===================
INFO:root:FL Epoch: 621 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 621 Workers Selected : [0, 1, 2, 331, 252, 1598, 852, 1672, 738, 1413]
INFO:root:FL Epoch: 621 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 621 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 621 Training on worker :0
INFO:root:FL Epoch: 621 Using Learning rate : 0.0028902512532226216 
INFO:root:FL Epoch: 621 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.136551
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.136459
INFO:root:FL Epoch: 621 Worker: 0 Backdoor Test Loss: 0.12493707860509555 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 621 Worker: 0 Backdoor Train Loss: 0.12473469153046608 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 621 Norm Difference for worker 0 is 0.077503
INFO:root:FL Epoch: 621 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 621 Training on worker :1
INFO:root:FL Epoch: 621 Using Learning rate : 0.0028902512532226216 
INFO:root:FL Epoch: 621 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.153160
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.082885
INFO:root:FL Epoch: 621 Worker: 1 Backdoor Test Loss: 0.12698526928822199 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 621 Worker: 1 Backdoor Train Loss: 0.12476062998175622 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 621 Norm Difference for worker 1 is 0.076957
INFO:root:FL Epoch: 621 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 621 Training on worker :2
INFO:root:FL Epoch: 621 Using Learning rate : 0.0028902512532226216 
INFO:root:FL Epoch: 621 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.141658
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255734
INFO:root:FL Epoch: 621 Worker: 2 Backdoor Test Loss: 0.12769440189003944 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 621 Worker: 2 Backdoor Train Loss: 0.12504220083355905 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 621 Norm Difference for worker 2 is 0.076278
INFO:root:FL Epoch: 621 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 621 Training on worker :331
INFO:root:FL Epoch: 621 Using Learning rate : 0.014451256266113108 
INFO:root:FL Epoch: 621 Normal Training
INFO:root:Worker: 331 Train Epoch: 0 [0/201 (0%)]	Loss: 0.588696
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 331 Train Epoch: 1 [0/201 (0%)]	Loss: 0.558171
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 621 Norm Difference for worker 331 is 0.643818
INFO:root:FL Epoch: 621 Done on worker:331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 621 Training on worker :252
INFO:root:FL Epoch: 621 Using Learning rate : 0.014451256266113108 
INFO:root:FL Epoch: 621 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541531
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.498361
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 621 Norm Difference for worker 252 is 0.592682
INFO:root:FL Epoch: 621 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 621 Training on worker :1598
INFO:root:FL Epoch: 621 Using Learning rate : 0.014451256266113108 
INFO:root:FL Epoch: 621 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635925
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222454
INFO:root:FL Epoch: 621 Norm Difference for worker 1598 is 0.590737
INFO:root:FL Epoch: 621 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 621 Training on worker :852
INFO:root:FL Epoch: 621 Using Learning rate : 0.014451256266113108 
INFO:root:FL Epoch: 621 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612116
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575111
INFO:root:FL Epoch: 621 Norm Difference for worker 852 is 0.663448
INFO:root:FL Epoch: 621 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 621 Training on worker :1672
INFO:root:FL Epoch: 621 Using Learning rate : 0.014451256266113108 
INFO:root:FL Epoch: 621 Normal Training
INFO:root:Worker: 1672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513221
INFO:root:Worker: 1672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400090
INFO:root:FL Epoch: 621 Norm Difference for worker 1672 is 0.598347
INFO:root:FL Epoch: 621 Done on worker:1672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 621 Training on worker :738
INFO:root:FL Epoch: 621 Using Learning rate : 0.014451256266113108 
INFO:root:FL Epoch: 621 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774750
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362163
INFO:root:FL Epoch: 621 Norm Difference for worker 738 is 0.676556
INFO:root:FL Epoch: 621 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 621 Training on worker :1413
INFO:root:FL Epoch: 621 Using Learning rate : 0.014451256266113108 
INFO:root:FL Epoch: 621 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549458
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359023
INFO:root:FL Epoch: 621 Norm Difference for worker 1413 is 0.659088
INFO:root:FL Epoch: 621 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 621 Ends   ===================
INFO:root:Epoch:621 Global Model Test Loss:0.5211376390036415 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:621 Global Model Backdoor Test Loss:0.12493707860509555                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 622 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 622 Workers Selected : [265, 1432, 207, 1520, 890, 723, 1096, 1450, 440, 1471]
INFO:root:FL Epoch: 622 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 622 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 622 Training on worker :265
INFO:root:FL Epoch: 622 Using Learning rate : 0.014422353753580884 
INFO:root:FL Epoch: 622 Normal Training
INFO:root:Worker: 265 Train Epoch: 0 [0/201 (0%)]	Loss: 0.829395
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 265 Train Epoch: 1 [0/201 (0%)]	Loss: 0.786222
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 622 Norm Difference for worker 265 is 0.708862
INFO:root:FL Epoch: 622 Done on worker:265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 622 Training on worker :1432
INFO:root:FL Epoch: 622 Using Learning rate : 0.014422353753580884 
INFO:root:FL Epoch: 622 Normal Training
INFO:root:Worker: 1432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409470
INFO:root:Worker: 1432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.151063
INFO:root:FL Epoch: 622 Norm Difference for worker 1432 is 0.624364
INFO:root:FL Epoch: 622 Done on worker:1432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 622 Training on worker :207
INFO:root:FL Epoch: 622 Using Learning rate : 0.014422353753580884 
INFO:root:FL Epoch: 622 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.635388
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.522648
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 622 Norm Difference for worker 207 is 0.7249
INFO:root:FL Epoch: 622 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 622 Training on worker :1520
INFO:root:FL Epoch: 622 Using Learning rate : 0.014422353753580884 
INFO:root:FL Epoch: 622 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532979
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667103
INFO:root:FL Epoch: 622 Norm Difference for worker 1520 is 0.667335
INFO:root:FL Epoch: 622 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 622 Training on worker :890
INFO:root:FL Epoch: 622 Using Learning rate : 0.014422353753580884 
INFO:root:FL Epoch: 622 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537551
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565990
INFO:root:FL Epoch: 622 Norm Difference for worker 890 is 0.694576
INFO:root:FL Epoch: 622 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 622 Training on worker :723
INFO:root:FL Epoch: 622 Using Learning rate : 0.014422353753580884 
INFO:root:FL Epoch: 622 Normal Training
INFO:root:Worker: 723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516420
INFO:root:Worker: 723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420793
INFO:root:FL Epoch: 622 Norm Difference for worker 723 is 0.601912
INFO:root:FL Epoch: 622 Done on worker:723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 622 Training on worker :1096
INFO:root:FL Epoch: 622 Using Learning rate : 0.014422353753580884 
INFO:root:FL Epoch: 622 Normal Training
INFO:root:Worker: 1096 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382967
INFO:root:Worker: 1096 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584438
INFO:root:FL Epoch: 622 Norm Difference for worker 1096 is 0.606931
INFO:root:FL Epoch: 622 Done on worker:1096
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 622 Training on worker :1450
INFO:root:FL Epoch: 622 Using Learning rate : 0.014422353753580884 
INFO:root:FL Epoch: 622 Normal Training
INFO:root:Worker: 1450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427985
INFO:root:Worker: 1450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361267
INFO:root:FL Epoch: 622 Norm Difference for worker 1450 is 0.649065
INFO:root:FL Epoch: 622 Done on worker:1450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 622 Training on worker :440
INFO:root:FL Epoch: 622 Using Learning rate : 0.014422353753580884 
INFO:root:FL Epoch: 622 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692137
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418270
INFO:root:FL Epoch: 622 Norm Difference for worker 440 is 0.58937
INFO:root:FL Epoch: 622 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 622 Training on worker :1471
INFO:root:FL Epoch: 622 Using Learning rate : 0.014422353753580884 
INFO:root:FL Epoch: 622 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721554
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480035
INFO:root:FL Epoch: 622 Norm Difference for worker 1471 is 0.704331
INFO:root:FL Epoch: 622 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 440
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 622 Ends   ===================
INFO:root:Epoch:622 Global Model Test Loss:0.5198841305340037 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:622 Global Model Backdoor Test Loss:0.10066492483019829                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 623 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 623 Workers Selected : [1477, 1688, 190, 1382, 1904, 742, 1629, 178, 1346, 1406]
INFO:root:FL Epoch: 623 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 623 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 623 Training on worker :1477
INFO:root:FL Epoch: 623 Using Learning rate : 0.014393509046073722 
INFO:root:FL Epoch: 623 Normal Training
INFO:root:Worker: 1477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354613
INFO:root:Worker: 1477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463770
INFO:root:FL Epoch: 623 Norm Difference for worker 1477 is 0.680368
INFO:root:FL Epoch: 623 Done on worker:1477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 623 Training on worker :1688
INFO:root:FL Epoch: 623 Using Learning rate : 0.014393509046073722 
INFO:root:FL Epoch: 623 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379390
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540116
INFO:root:FL Epoch: 623 Norm Difference for worker 1688 is 0.569191
INFO:root:FL Epoch: 623 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 623 Training on worker :190
INFO:root:FL Epoch: 623 Using Learning rate : 0.014393509046073722 
INFO:root:FL Epoch: 623 Normal Training
INFO:root:Worker: 190 Train Epoch: 0 [0/201 (0%)]	Loss: 0.439986
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 190 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428813
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 623 Norm Difference for worker 190 is 0.689274
INFO:root:FL Epoch: 623 Done on worker:190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 623 Training on worker :1382
INFO:root:FL Epoch: 623 Using Learning rate : 0.014393509046073722 
INFO:root:FL Epoch: 623 Normal Training
INFO:root:Worker: 1382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419086
INFO:root:Worker: 1382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665762
INFO:root:FL Epoch: 623 Norm Difference for worker 1382 is 0.67695
INFO:root:FL Epoch: 623 Done on worker:1382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 623 Training on worker :1904
INFO:root:FL Epoch: 623 Using Learning rate : 0.014393509046073722 
INFO:root:FL Epoch: 623 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395568
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609281
INFO:root:FL Epoch: 623 Norm Difference for worker 1904 is 0.612741
INFO:root:FL Epoch: 623 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 623 Training on worker :742
INFO:root:FL Epoch: 623 Using Learning rate : 0.014393509046073722 
INFO:root:FL Epoch: 623 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.253899
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372250
INFO:root:FL Epoch: 623 Norm Difference for worker 742 is 0.546331
INFO:root:FL Epoch: 623 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 623 Training on worker :1629
INFO:root:FL Epoch: 623 Using Learning rate : 0.014393509046073722 
INFO:root:FL Epoch: 623 Normal Training
INFO:root:Worker: 1629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.886540
INFO:root:Worker: 1629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611381
INFO:root:FL Epoch: 623 Norm Difference for worker 1629 is 0.68123
INFO:root:FL Epoch: 623 Done on worker:1629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 623 Training on worker :178
INFO:root:FL Epoch: 623 Using Learning rate : 0.014393509046073722 
INFO:root:FL Epoch: 623 Normal Training
INFO:root:Worker: 178 Train Epoch: 0 [0/201 (0%)]	Loss: 0.272806
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 178 Train Epoch: 1 [0/201 (0%)]	Loss: 0.339438
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 623 Norm Difference for worker 178 is 0.636678
INFO:root:FL Epoch: 623 Done on worker:178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 623 Training on worker :1346
INFO:root:FL Epoch: 623 Using Learning rate : 0.014393509046073722 
INFO:root:FL Epoch: 623 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 1.017903
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340950
INFO:root:FL Epoch: 623 Norm Difference for worker 1346 is 0.693653
INFO:root:FL Epoch: 623 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 623 Training on worker :1406
INFO:root:FL Epoch: 623 Using Learning rate : 0.014393509046073722 
INFO:root:FL Epoch: 623 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449711
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240248
INFO:root:FL Epoch: 623 Norm Difference for worker 1406 is 0.668788
INFO:root:FL Epoch: 623 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 742
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 623 Ends   ===================
INFO:root:Epoch:623 Global Model Test Loss:0.5348871122388279 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:623 Global Model Backdoor Test Loss:0.09323924159010251                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 624 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 624 Workers Selected : [1005, 998, 1599, 1223, 719, 279, 1149, 66, 805, 1920]
INFO:root:FL Epoch: 624 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 624 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 624 Training on worker :1005
INFO:root:FL Epoch: 624 Using Learning rate : 0.014364722027981575 
INFO:root:FL Epoch: 624 Normal Training
INFO:root:Worker: 1005 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635988
INFO:root:Worker: 1005 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554658
INFO:root:FL Epoch: 624 Norm Difference for worker 1005 is 0.647002
INFO:root:FL Epoch: 624 Done on worker:1005
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 624 Training on worker :998
INFO:root:FL Epoch: 624 Using Learning rate : 0.014364722027981575 
INFO:root:FL Epoch: 624 Normal Training
INFO:root:Worker: 998 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383371
INFO:root:Worker: 998 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450366
INFO:root:FL Epoch: 624 Norm Difference for worker 998 is 0.760132
INFO:root:FL Epoch: 624 Done on worker:998
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 624 Training on worker :1599
INFO:root:FL Epoch: 624 Using Learning rate : 0.014364722027981575 
INFO:root:FL Epoch: 624 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598967
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623263
INFO:root:FL Epoch: 624 Norm Difference for worker 1599 is 0.774098
INFO:root:FL Epoch: 624 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 624 Training on worker :1223
INFO:root:FL Epoch: 624 Using Learning rate : 0.014364722027981575 
INFO:root:FL Epoch: 624 Normal Training
INFO:root:Worker: 1223 Train Epoch: 0 [0/200 (0%)]	Loss: 0.921634
INFO:root:Worker: 1223 Train Epoch: 1 [0/200 (0%)]	Loss: 0.854893
INFO:root:FL Epoch: 624 Norm Difference for worker 1223 is 0.792836
INFO:root:FL Epoch: 624 Done on worker:1223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 624 Training on worker :719
INFO:root:FL Epoch: 624 Using Learning rate : 0.014364722027981575 
INFO:root:FL Epoch: 624 Normal Training
INFO:root:Worker: 719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617406
INFO:root:Worker: 719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561770
INFO:root:FL Epoch: 624 Norm Difference for worker 719 is 0.732783
INFO:root:FL Epoch: 624 Done on worker:719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 624 Training on worker :279
INFO:root:FL Epoch: 624 Using Learning rate : 0.014364722027981575 
INFO:root:FL Epoch: 624 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.646191
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.294325
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 624 Norm Difference for worker 279 is 0.761715
INFO:root:FL Epoch: 624 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 624 Training on worker :1149
INFO:root:FL Epoch: 624 Using Learning rate : 0.014364722027981575 
INFO:root:FL Epoch: 624 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483479
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314486
INFO:root:FL Epoch: 624 Norm Difference for worker 1149 is 0.761299
INFO:root:FL Epoch: 624 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 624 Training on worker :66
INFO:root:FL Epoch: 624 Using Learning rate : 0.014364722027981575 
INFO:root:FL Epoch: 624 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.510518
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.224865
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 624 Norm Difference for worker 66 is 0.736429
INFO:root:FL Epoch: 624 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 624 Training on worker :805
INFO:root:FL Epoch: 624 Using Learning rate : 0.014364722027981575 
INFO:root:FL Epoch: 624 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364016
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386604
INFO:root:FL Epoch: 624 Norm Difference for worker 805 is 0.743112
INFO:root:FL Epoch: 624 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 624 Training on worker :1920
INFO:root:FL Epoch: 624 Using Learning rate : 0.014364722027981575 
INFO:root:FL Epoch: 624 Normal Training
INFO:root:Worker: 1920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525716
INFO:root:Worker: 1920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571828
INFO:root:FL Epoch: 624 Norm Difference for worker 1920 is 0.743313
INFO:root:FL Epoch: 624 Done on worker:1920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1005
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 624 Ends   ===================
INFO:root:Epoch:624 Global Model Test Loss:0.5205113905317643 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:624 Global Model Backdoor Test Loss:0.0843564805885156                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 625 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 625 Workers Selected : [125, 315, 593, 250, 1008, 1364, 824, 487, 695, 198]
INFO:root:FL Epoch: 625 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.0998004 0.0998004 0.1002994]
INFO:root:FL Epoch: 625 Num points on workers: [201 201 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 625 Training on worker :125
INFO:root:FL Epoch: 625 Using Learning rate : 0.014335992583925612 
INFO:root:FL Epoch: 625 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.387790
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.262138
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 625 Norm Difference for worker 125 is 0.718072
INFO:root:FL Epoch: 625 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 625 Training on worker :315
INFO:root:FL Epoch: 625 Using Learning rate : 0.014335992583925612 
INFO:root:FL Epoch: 625 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.217128
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.338708
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 625 Norm Difference for worker 315 is 0.616946
INFO:root:FL Epoch: 625 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 625 Training on worker :593
INFO:root:FL Epoch: 625 Using Learning rate : 0.014335992583925612 
INFO:root:FL Epoch: 625 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576564
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455224
INFO:root:FL Epoch: 625 Norm Difference for worker 593 is 0.749753
INFO:root:FL Epoch: 625 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 625 Training on worker :250
INFO:root:FL Epoch: 625 Using Learning rate : 0.014335992583925612 
INFO:root:FL Epoch: 625 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.279035
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.390091
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 625 Norm Difference for worker 250 is 0.622128
INFO:root:FL Epoch: 625 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 625 Training on worker :1008
INFO:root:FL Epoch: 625 Using Learning rate : 0.014335992583925612 
INFO:root:FL Epoch: 625 Normal Training
INFO:root:Worker: 1008 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469686
INFO:root:Worker: 1008 Train Epoch: 1 [0/200 (0%)]	Loss: 0.967816
INFO:root:FL Epoch: 625 Norm Difference for worker 1008 is 0.828749
INFO:root:FL Epoch: 625 Done on worker:1008
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 625 Training on worker :1364
INFO:root:FL Epoch: 625 Using Learning rate : 0.014335992583925612 
INFO:root:FL Epoch: 625 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.208568
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304038
INFO:root:FL Epoch: 625 Norm Difference for worker 1364 is 0.692265
INFO:root:FL Epoch: 625 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 625 Training on worker :824
INFO:root:FL Epoch: 625 Using Learning rate : 0.014335992583925612 
INFO:root:FL Epoch: 625 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.843334
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480996
INFO:root:FL Epoch: 625 Norm Difference for worker 824 is 0.67376
INFO:root:FL Epoch: 625 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 625 Training on worker :487
INFO:root:FL Epoch: 625 Using Learning rate : 0.014335992583925612 
INFO:root:FL Epoch: 625 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.183471
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384977
INFO:root:FL Epoch: 625 Norm Difference for worker 487 is 0.596302
INFO:root:FL Epoch: 625 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 625 Training on worker :695
INFO:root:FL Epoch: 625 Using Learning rate : 0.014335992583925612 
INFO:root:FL Epoch: 625 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351503
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311336
INFO:root:FL Epoch: 625 Norm Difference for worker 695 is 0.58407
INFO:root:FL Epoch: 625 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 625 Training on worker :198
INFO:root:FL Epoch: 625 Using Learning rate : 0.014335992583925612 
INFO:root:FL Epoch: 625 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.391309
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.719708
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 625 Norm Difference for worker 198 is 0.77695
INFO:root:FL Epoch: 625 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 487
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 625 Ends   ===================
INFO:root:Epoch:625 Global Model Test Loss:0.525276441784466 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:625 Global Model Backdoor Test Loss:0.12948432192206383                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 626 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 626 Workers Selected : [1053, 684, 410, 840, 477, 530, 660, 1267, 513, 296]
INFO:root:FL Epoch: 626 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 626 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 626 Training on worker :1053
INFO:root:FL Epoch: 626 Using Learning rate : 0.014307320598757759 
INFO:root:FL Epoch: 626 Normal Training
INFO:root:Worker: 1053 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453141
INFO:root:Worker: 1053 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302184
INFO:root:FL Epoch: 626 Norm Difference for worker 1053 is 0.657299
INFO:root:FL Epoch: 626 Done on worker:1053
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 626 Training on worker :684
INFO:root:FL Epoch: 626 Using Learning rate : 0.014307320598757759 
INFO:root:FL Epoch: 626 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390058
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353359
INFO:root:FL Epoch: 626 Norm Difference for worker 684 is 0.714115
INFO:root:FL Epoch: 626 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 626 Training on worker :410
INFO:root:FL Epoch: 626 Using Learning rate : 0.014307320598757759 
INFO:root:FL Epoch: 626 Normal Training
INFO:root:Worker: 410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490789
INFO:root:Worker: 410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494854
INFO:root:FL Epoch: 626 Norm Difference for worker 410 is 0.722682
INFO:root:FL Epoch: 626 Done on worker:410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 626 Training on worker :840
INFO:root:FL Epoch: 626 Using Learning rate : 0.014307320598757759 
INFO:root:FL Epoch: 626 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.229177
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707758
INFO:root:FL Epoch: 626 Norm Difference for worker 840 is 0.720669
INFO:root:FL Epoch: 626 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 626 Training on worker :477
INFO:root:FL Epoch: 626 Using Learning rate : 0.014307320598757759 
INFO:root:FL Epoch: 626 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600374
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603075
INFO:root:FL Epoch: 626 Norm Difference for worker 477 is 0.746429
INFO:root:FL Epoch: 626 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 626 Training on worker :530
INFO:root:FL Epoch: 626 Using Learning rate : 0.014307320598757759 
INFO:root:FL Epoch: 626 Normal Training
INFO:root:Worker: 530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465401
INFO:root:Worker: 530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546566
INFO:root:FL Epoch: 626 Norm Difference for worker 530 is 0.77952
INFO:root:FL Epoch: 626 Done on worker:530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 626 Training on worker :660
INFO:root:FL Epoch: 626 Using Learning rate : 0.014307320598757759 
INFO:root:FL Epoch: 626 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687457
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378332
INFO:root:FL Epoch: 626 Norm Difference for worker 660 is 0.695963
INFO:root:FL Epoch: 626 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 626 Training on worker :1267
INFO:root:FL Epoch: 626 Using Learning rate : 0.014307320598757759 
INFO:root:FL Epoch: 626 Normal Training
INFO:root:Worker: 1267 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495180
INFO:root:Worker: 1267 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379630
INFO:root:FL Epoch: 626 Norm Difference for worker 1267 is 0.712601
INFO:root:FL Epoch: 626 Done on worker:1267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 626 Training on worker :513
INFO:root:FL Epoch: 626 Using Learning rate : 0.014307320598757759 
INFO:root:FL Epoch: 626 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.827447
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.794100
INFO:root:FL Epoch: 626 Norm Difference for worker 513 is 0.777855
INFO:root:FL Epoch: 626 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 626 Training on worker :296
INFO:root:FL Epoch: 626 Using Learning rate : 0.014307320598757759 
INFO:root:FL Epoch: 626 Normal Training
INFO:root:Worker: 296 Train Epoch: 0 [0/201 (0%)]	Loss: 0.430933
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 296 Train Epoch: 1 [0/201 (0%)]	Loss: 0.359209
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 626 Norm Difference for worker 296 is 0.764781
INFO:root:FL Epoch: 626 Done on worker:296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1053
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 626 Ends   ===================
INFO:root:Epoch:626 Global Model Test Loss:0.5377413542831645 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:626 Global Model Backdoor Test Loss:0.16668840001026788                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 627 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 627 Workers Selected : [358, 1702, 890, 850, 371, 1285, 1450, 49, 1623, 1502]
INFO:root:FL Epoch: 627 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 627 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 627 Training on worker :358
INFO:root:FL Epoch: 627 Using Learning rate : 0.014278705957560242 
INFO:root:FL Epoch: 627 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397558
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302468
INFO:root:FL Epoch: 627 Norm Difference for worker 358 is 0.642735
INFO:root:FL Epoch: 627 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 627 Training on worker :1702
INFO:root:FL Epoch: 627 Using Learning rate : 0.014278705957560242 
INFO:root:FL Epoch: 627 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349646
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358702
INFO:root:FL Epoch: 627 Norm Difference for worker 1702 is 0.622197
INFO:root:FL Epoch: 627 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 627 Training on worker :890
INFO:root:FL Epoch: 627 Using Learning rate : 0.014278705957560242 
INFO:root:FL Epoch: 627 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609460
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327365
INFO:root:FL Epoch: 627 Norm Difference for worker 890 is 0.698944
INFO:root:FL Epoch: 627 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 627 Training on worker :850
INFO:root:FL Epoch: 627 Using Learning rate : 0.014278705957560242 
INFO:root:FL Epoch: 627 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.845392
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545267
INFO:root:FL Epoch: 627 Norm Difference for worker 850 is 0.66421
INFO:root:FL Epoch: 627 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 627 Training on worker :371
INFO:root:FL Epoch: 627 Using Learning rate : 0.014278705957560242 
INFO:root:FL Epoch: 627 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527515
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406063
INFO:root:FL Epoch: 627 Norm Difference for worker 371 is 0.694903
INFO:root:FL Epoch: 627 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 627 Training on worker :1285
INFO:root:FL Epoch: 627 Using Learning rate : 0.014278705957560242 
INFO:root:FL Epoch: 627 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627352
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325293
INFO:root:FL Epoch: 627 Norm Difference for worker 1285 is 0.597101
INFO:root:FL Epoch: 627 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 627 Training on worker :1450
INFO:root:FL Epoch: 627 Using Learning rate : 0.014278705957560242 
INFO:root:FL Epoch: 627 Normal Training
INFO:root:Worker: 1450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605463
INFO:root:Worker: 1450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479233
INFO:root:FL Epoch: 627 Norm Difference for worker 1450 is 0.677206
INFO:root:FL Epoch: 627 Done on worker:1450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 627 Training on worker :49
INFO:root:FL Epoch: 627 Using Learning rate : 0.014278705957560242 
INFO:root:FL Epoch: 627 Normal Training
INFO:root:Worker: 49 Train Epoch: 0 [0/201 (0%)]	Loss: 0.491178
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 49 Train Epoch: 1 [0/201 (0%)]	Loss: 0.379089
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 627 Norm Difference for worker 49 is 0.758201
INFO:root:FL Epoch: 627 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 627 Training on worker :1623
INFO:root:FL Epoch: 627 Using Learning rate : 0.014278705957560242 
INFO:root:FL Epoch: 627 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354485
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598994
INFO:root:FL Epoch: 627 Norm Difference for worker 1623 is 0.737716
INFO:root:FL Epoch: 627 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 627 Training on worker :1502
INFO:root:FL Epoch: 627 Using Learning rate : 0.014278705957560242 
INFO:root:FL Epoch: 627 Normal Training
INFO:root:Worker: 1502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559327
INFO:root:Worker: 1502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323995
INFO:root:FL Epoch: 627 Norm Difference for worker 1502 is 0.625077
INFO:root:FL Epoch: 627 Done on worker:1502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1285
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 627 Ends   ===================
INFO:root:Epoch:627 Global Model Test Loss:0.5279916034025305 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:627 Global Model Backdoor Test Loss:0.14578552916646004                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 628 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 628 Workers Selected : [1496, 1175, 188, 1530, 250, 1880, 417, 73, 781, 931]
INFO:root:FL Epoch: 628 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 628 Num points on workers: [200 200 201 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 628 Training on worker :1496
INFO:root:FL Epoch: 628 Using Learning rate : 0.014250148545645124 
INFO:root:FL Epoch: 628 Normal Training
INFO:root:Worker: 1496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543427
INFO:root:Worker: 1496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463012
INFO:root:FL Epoch: 628 Norm Difference for worker 1496 is 0.657947
INFO:root:FL Epoch: 628 Done on worker:1496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 628 Training on worker :1175
INFO:root:FL Epoch: 628 Using Learning rate : 0.014250148545645124 
INFO:root:FL Epoch: 628 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548358
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443613
INFO:root:FL Epoch: 628 Norm Difference for worker 1175 is 0.703689
INFO:root:FL Epoch: 628 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 628 Training on worker :188
INFO:root:FL Epoch: 628 Using Learning rate : 0.014250148545645124 
INFO:root:FL Epoch: 628 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.554470
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.363201
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 628 Norm Difference for worker 188 is 0.708819
INFO:root:FL Epoch: 628 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 628 Training on worker :1530
INFO:root:FL Epoch: 628 Using Learning rate : 0.014250148545645124 
INFO:root:FL Epoch: 628 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705061
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534246
INFO:root:FL Epoch: 628 Norm Difference for worker 1530 is 0.726978
INFO:root:FL Epoch: 628 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 628 Training on worker :250
INFO:root:FL Epoch: 628 Using Learning rate : 0.014250148545645124 
INFO:root:FL Epoch: 628 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.790166
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.219294
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 628 Norm Difference for worker 250 is 0.649407
INFO:root:FL Epoch: 628 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 628 Training on worker :1880
INFO:root:FL Epoch: 628 Using Learning rate : 0.014250148545645124 
INFO:root:FL Epoch: 628 Normal Training
INFO:root:Worker: 1880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579928
INFO:root:Worker: 1880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324055
INFO:root:FL Epoch: 628 Norm Difference for worker 1880 is 0.748804
INFO:root:FL Epoch: 628 Done on worker:1880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 628 Training on worker :417
INFO:root:FL Epoch: 628 Using Learning rate : 0.014250148545645124 
INFO:root:FL Epoch: 628 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606126
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536341
INFO:root:FL Epoch: 628 Norm Difference for worker 417 is 0.687483
INFO:root:FL Epoch: 628 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 628 Training on worker :73
INFO:root:FL Epoch: 628 Using Learning rate : 0.014250148545645124 
INFO:root:FL Epoch: 628 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.502361
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.395085
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 628 Norm Difference for worker 73 is 0.736329
INFO:root:FL Epoch: 628 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 628 Training on worker :781
INFO:root:FL Epoch: 628 Using Learning rate : 0.014250148545645124 
INFO:root:FL Epoch: 628 Normal Training
INFO:root:Worker: 781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420053
INFO:root:Worker: 781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366799
INFO:root:FL Epoch: 628 Norm Difference for worker 781 is 0.655548
INFO:root:FL Epoch: 628 Done on worker:781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 628 Training on worker :931
INFO:root:FL Epoch: 628 Using Learning rate : 0.014250148545645124 
INFO:root:FL Epoch: 628 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666554
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626454
INFO:root:FL Epoch: 628 Norm Difference for worker 931 is 0.695691
INFO:root:FL Epoch: 628 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 250
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 628 Ends   ===================
INFO:root:Epoch:628 Global Model Test Loss:0.5311033918577082 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:628 Global Model Backdoor Test Loss:0.09933676198124886                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 629 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 629 Workers Selected : [573, 1218, 1481, 1222, 962, 866, 753, 639, 467, 1324]
INFO:root:FL Epoch: 629 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 629 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 629 Training on worker :573
INFO:root:FL Epoch: 629 Using Learning rate : 0.014221648248553834 
INFO:root:FL Epoch: 629 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443980
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506287
INFO:root:FL Epoch: 629 Norm Difference for worker 573 is 0.671694
INFO:root:FL Epoch: 629 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 629 Training on worker :1218
INFO:root:FL Epoch: 629 Using Learning rate : 0.014221648248553834 
INFO:root:FL Epoch: 629 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.981012
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328739
INFO:root:FL Epoch: 629 Norm Difference for worker 1218 is 0.769792
INFO:root:FL Epoch: 629 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 629 Training on worker :1481
INFO:root:FL Epoch: 629 Using Learning rate : 0.014221648248553834 
INFO:root:FL Epoch: 629 Normal Training
INFO:root:Worker: 1481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807148
INFO:root:Worker: 1481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307919
INFO:root:FL Epoch: 629 Norm Difference for worker 1481 is 0.765118
INFO:root:FL Epoch: 629 Done on worker:1481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 629 Training on worker :1222
INFO:root:FL Epoch: 629 Using Learning rate : 0.014221648248553834 
INFO:root:FL Epoch: 629 Normal Training
INFO:root:Worker: 1222 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435102
INFO:root:Worker: 1222 Train Epoch: 1 [0/200 (0%)]	Loss: 0.726822
INFO:root:FL Epoch: 629 Norm Difference for worker 1222 is 0.720514
INFO:root:FL Epoch: 629 Done on worker:1222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 629 Training on worker :962
INFO:root:FL Epoch: 629 Using Learning rate : 0.014221648248553834 
INFO:root:FL Epoch: 629 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361397
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268861
INFO:root:FL Epoch: 629 Norm Difference for worker 962 is 0.68679
INFO:root:FL Epoch: 629 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 629 Training on worker :866
INFO:root:FL Epoch: 629 Using Learning rate : 0.014221648248553834 
INFO:root:FL Epoch: 629 Normal Training
INFO:root:Worker: 866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714442
INFO:root:Worker: 866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546468
INFO:root:FL Epoch: 629 Norm Difference for worker 866 is 0.731621
INFO:root:FL Epoch: 629 Done on worker:866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 629 Training on worker :753
INFO:root:FL Epoch: 629 Using Learning rate : 0.014221648248553834 
INFO:root:FL Epoch: 629 Normal Training
INFO:root:Worker: 753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.924577
INFO:root:Worker: 753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515895
INFO:root:FL Epoch: 629 Norm Difference for worker 753 is 0.659366
INFO:root:FL Epoch: 629 Done on worker:753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 629 Training on worker :639
INFO:root:FL Epoch: 629 Using Learning rate : 0.014221648248553834 
INFO:root:FL Epoch: 629 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554220
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483840
INFO:root:FL Epoch: 629 Norm Difference for worker 639 is 0.674699
INFO:root:FL Epoch: 629 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 629 Training on worker :467
INFO:root:FL Epoch: 629 Using Learning rate : 0.014221648248553834 
INFO:root:FL Epoch: 629 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482325
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404676
INFO:root:FL Epoch: 629 Norm Difference for worker 467 is 0.623776
INFO:root:FL Epoch: 629 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 629 Training on worker :1324
INFO:root:FL Epoch: 629 Using Learning rate : 0.014221648248553834 
INFO:root:FL Epoch: 629 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531727
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478503
INFO:root:FL Epoch: 629 Norm Difference for worker 1324 is 0.62547
INFO:root:FL Epoch: 629 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 467
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 629 Ends   ===================
INFO:root:Epoch:629 Global Model Test Loss:0.5402212037759668 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:629 Global Model Backdoor Test Loss:0.1859428696334362                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 630 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 630 Workers Selected : [510, 1930, 1874, 1305, 567, 1866, 16, 1329, 1868, 483]
INFO:root:FL Epoch: 630 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 630 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 630 Training on worker :510
INFO:root:FL Epoch: 630 Using Learning rate : 0.014193204952056726 
INFO:root:FL Epoch: 630 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571816
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443186
INFO:root:FL Epoch: 630 Norm Difference for worker 510 is 0.742456
INFO:root:FL Epoch: 630 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 630 Training on worker :1930
INFO:root:FL Epoch: 630 Using Learning rate : 0.014193204952056726 
INFO:root:FL Epoch: 630 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703633
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.754366
INFO:root:FL Epoch: 630 Norm Difference for worker 1930 is 0.752954
INFO:root:FL Epoch: 630 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 630 Training on worker :1874
INFO:root:FL Epoch: 630 Using Learning rate : 0.014193204952056726 
INFO:root:FL Epoch: 630 Normal Training
INFO:root:Worker: 1874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460370
INFO:root:Worker: 1874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369478
INFO:root:FL Epoch: 630 Norm Difference for worker 1874 is 0.562712
INFO:root:FL Epoch: 630 Done on worker:1874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 630 Training on worker :1305
INFO:root:FL Epoch: 630 Using Learning rate : 0.014193204952056726 
INFO:root:FL Epoch: 630 Normal Training
INFO:root:Worker: 1305 Train Epoch: 0 [0/200 (0%)]	Loss: 0.974345
INFO:root:Worker: 1305 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294309
INFO:root:FL Epoch: 630 Norm Difference for worker 1305 is 0.728099
INFO:root:FL Epoch: 630 Done on worker:1305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 630 Training on worker :567
INFO:root:FL Epoch: 630 Using Learning rate : 0.014193204952056726 
INFO:root:FL Epoch: 630 Normal Training
INFO:root:Worker: 567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392740
INFO:root:Worker: 567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229998
INFO:root:FL Epoch: 630 Norm Difference for worker 567 is 0.589138
INFO:root:FL Epoch: 630 Done on worker:567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 630 Training on worker :1866
INFO:root:FL Epoch: 630 Using Learning rate : 0.014193204952056726 
INFO:root:FL Epoch: 630 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545245
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.228938
INFO:root:FL Epoch: 630 Norm Difference for worker 1866 is 0.742325
INFO:root:FL Epoch: 630 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 630 Training on worker :16
INFO:root:FL Epoch: 630 Using Learning rate : 0.014193204952056726 
INFO:root:FL Epoch: 630 Normal Training
INFO:root:Worker: 16 Train Epoch: 0 [0/201 (0%)]	Loss: 0.639888
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 16 Train Epoch: 1 [0/201 (0%)]	Loss: 0.486709
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 630 Norm Difference for worker 16 is 0.7304
INFO:root:FL Epoch: 630 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 630 Training on worker :1329
INFO:root:FL Epoch: 630 Using Learning rate : 0.014193204952056726 
INFO:root:FL Epoch: 630 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622202
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490608
INFO:root:FL Epoch: 630 Norm Difference for worker 1329 is 0.787213
INFO:root:FL Epoch: 630 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 630 Training on worker :1868
INFO:root:FL Epoch: 630 Using Learning rate : 0.014193204952056726 
INFO:root:FL Epoch: 630 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.329818
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555185
INFO:root:FL Epoch: 630 Norm Difference for worker 1868 is 0.660505
INFO:root:FL Epoch: 630 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 630 Training on worker :483
INFO:root:FL Epoch: 630 Using Learning rate : 0.014193204952056726 
INFO:root:FL Epoch: 630 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712519
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572507
INFO:root:FL Epoch: 630 Norm Difference for worker 483 is 0.730172
INFO:root:FL Epoch: 630 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1874
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 630 Ends   ===================
INFO:root:Epoch:630 Global Model Test Loss:0.527381123865352 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:630 Global Model Backdoor Test Loss:0.12628275652726492                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 631 Begins ===================
INFO:root:FL Epoch: 631 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 631 Workers Selected : [0, 1, 2, 1386, 1380, 347, 1315, 1866, 1628, 201]
INFO:root:FL Epoch: 631 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 631 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 631 Training on worker :0
INFO:root:FL Epoch: 631 Using Learning rate : 0.002832963708430522 
INFO:root:FL Epoch: 631 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.137651
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.151481
INFO:root:FL Epoch: 631 Worker: 0 Backdoor Test Loss: 0.11480138761301835 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 631 Worker: 0 Backdoor Train Loss: 0.10586079508066178 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 631 Norm Difference for worker 0 is 0.069898
INFO:root:FL Epoch: 631 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 631 Training on worker :1
INFO:root:FL Epoch: 631 Using Learning rate : 0.002832963708430522 
INFO:root:FL Epoch: 631 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.136124
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.142668
INFO:root:FL Epoch: 631 Worker: 1 Backdoor Test Loss: 0.1144423062602679 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 631 Worker: 1 Backdoor Train Loss: 0.10630203187465667 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 631 Norm Difference for worker 1 is 0.067401
INFO:root:FL Epoch: 631 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 631 Training on worker :2
INFO:root:FL Epoch: 631 Using Learning rate : 0.002832963708430522 
INFO:root:FL Epoch: 631 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.167830
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219271
INFO:root:FL Epoch: 631 Worker: 2 Backdoor Test Loss: 0.1140265508244435 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 631 Worker: 2 Backdoor Train Loss: 0.10569400861859321 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 631 Norm Difference for worker 2 is 0.071874
INFO:root:FL Epoch: 631 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 631 Training on worker :1386
INFO:root:FL Epoch: 631 Using Learning rate : 0.01416481854215261 
INFO:root:FL Epoch: 631 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340597
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.713128
INFO:root:FL Epoch: 631 Norm Difference for worker 1386 is 0.685872
INFO:root:FL Epoch: 631 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 631 Training on worker :1380
INFO:root:FL Epoch: 631 Using Learning rate : 0.01416481854215261 
INFO:root:FL Epoch: 631 Normal Training
INFO:root:Worker: 1380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.221373
INFO:root:Worker: 1380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624767
INFO:root:FL Epoch: 631 Norm Difference for worker 1380 is 0.716897
INFO:root:FL Epoch: 631 Done on worker:1380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 631 Training on worker :347
INFO:root:FL Epoch: 631 Using Learning rate : 0.01416481854215261 
INFO:root:FL Epoch: 631 Normal Training
INFO:root:Worker: 347 Train Epoch: 0 [0/200 (0%)]	Loss: 1.003277
INFO:root:Worker: 347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523815
INFO:root:FL Epoch: 631 Norm Difference for worker 347 is 0.748022
INFO:root:FL Epoch: 631 Done on worker:347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 631 Training on worker :1315
INFO:root:FL Epoch: 631 Using Learning rate : 0.01416481854215261 
INFO:root:FL Epoch: 631 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517562
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567055
INFO:root:FL Epoch: 631 Norm Difference for worker 1315 is 0.719971
INFO:root:FL Epoch: 631 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 631 Training on worker :1866
INFO:root:FL Epoch: 631 Using Learning rate : 0.01416481854215261 
INFO:root:FL Epoch: 631 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396120
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339225
INFO:root:FL Epoch: 631 Norm Difference for worker 1866 is 0.721016
INFO:root:FL Epoch: 631 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 631 Training on worker :1628
INFO:root:FL Epoch: 631 Using Learning rate : 0.01416481854215261 
INFO:root:FL Epoch: 631 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538007
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338337
INFO:root:FL Epoch: 631 Norm Difference for worker 1628 is 0.73535
INFO:root:FL Epoch: 631 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 631 Training on worker :201
INFO:root:FL Epoch: 631 Using Learning rate : 0.01416481854215261 
INFO:root:FL Epoch: 631 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.917850
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.387268
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 631 Norm Difference for worker 201 is 0.848279
INFO:root:FL Epoch: 631 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 631 Ends   ===================
INFO:root:Epoch:631 Global Model Test Loss:0.5317296210457297 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:631 Global Model Backdoor Test Loss:0.11480138761301835                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 632 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 632 Workers Selected : [1163, 172, 1453, 1739, 840, 1608, 371, 1040, 702, 1686]
INFO:root:FL Epoch: 632 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 632 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 632 Training on worker :1163
INFO:root:FL Epoch: 632 Using Learning rate : 0.014136488905068308 
INFO:root:FL Epoch: 632 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804778
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267981
INFO:root:FL Epoch: 632 Norm Difference for worker 1163 is 0.73226
INFO:root:FL Epoch: 632 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 632 Training on worker :172
INFO:root:FL Epoch: 632 Using Learning rate : 0.014136488905068308 
INFO:root:FL Epoch: 632 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.359113
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.433114
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 632 Norm Difference for worker 172 is 0.746142
INFO:root:FL Epoch: 632 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 632 Training on worker :1453
INFO:root:FL Epoch: 632 Using Learning rate : 0.014136488905068308 
INFO:root:FL Epoch: 632 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.302346
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240059
INFO:root:FL Epoch: 632 Norm Difference for worker 1453 is 0.693475
INFO:root:FL Epoch: 632 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 632 Training on worker :1739
INFO:root:FL Epoch: 632 Using Learning rate : 0.014136488905068308 
INFO:root:FL Epoch: 632 Normal Training
INFO:root:Worker: 1739 Train Epoch: 0 [0/200 (0%)]	Loss: 0.843916
INFO:root:Worker: 1739 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472723
INFO:root:FL Epoch: 632 Norm Difference for worker 1739 is 0.717581
INFO:root:FL Epoch: 632 Done on worker:1739
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 632 Training on worker :840
INFO:root:FL Epoch: 632 Using Learning rate : 0.014136488905068308 
INFO:root:FL Epoch: 632 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.841054
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429818
INFO:root:FL Epoch: 632 Norm Difference for worker 840 is 0.723931
INFO:root:FL Epoch: 632 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 632 Training on worker :1608
INFO:root:FL Epoch: 632 Using Learning rate : 0.014136488905068308 
INFO:root:FL Epoch: 632 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440476
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534862
INFO:root:FL Epoch: 632 Norm Difference for worker 1608 is 0.755045
INFO:root:FL Epoch: 632 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 632 Training on worker :371
INFO:root:FL Epoch: 632 Using Learning rate : 0.014136488905068308 
INFO:root:FL Epoch: 632 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762521
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619946
INFO:root:FL Epoch: 632 Norm Difference for worker 371 is 0.780505
INFO:root:FL Epoch: 632 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 632 Training on worker :1040
INFO:root:FL Epoch: 632 Using Learning rate : 0.014136488905068308 
INFO:root:FL Epoch: 632 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576142
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455804
INFO:root:FL Epoch: 632 Norm Difference for worker 1040 is 0.724739
INFO:root:FL Epoch: 632 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 632 Training on worker :702
INFO:root:FL Epoch: 632 Using Learning rate : 0.014136488905068308 
INFO:root:FL Epoch: 632 Normal Training
INFO:root:Worker: 702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498611
INFO:root:Worker: 702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416586
INFO:root:FL Epoch: 632 Norm Difference for worker 702 is 0.739197
INFO:root:FL Epoch: 632 Done on worker:702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 632 Training on worker :1686
INFO:root:FL Epoch: 632 Using Learning rate : 0.014136488905068308 
INFO:root:FL Epoch: 632 Normal Training
INFO:root:Worker: 1686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596344
INFO:root:Worker: 1686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329224
INFO:root:FL Epoch: 632 Norm Difference for worker 1686 is 0.723071
INFO:root:FL Epoch: 632 Done on worker:1686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1453
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 632 Ends   ===================
INFO:root:Epoch:632 Global Model Test Loss:0.519548798308653 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:632 Global Model Backdoor Test Loss:0.10912095258633296                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 633 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 633 Workers Selected : [936, 1529, 428, 1022, 1797, 133, 96, 1201, 1407, 422]
INFO:root:FL Epoch: 633 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 633 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 633 Training on worker :936
INFO:root:FL Epoch: 633 Using Learning rate : 0.01410821592725817 
INFO:root:FL Epoch: 633 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446915
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694081
INFO:root:FL Epoch: 633 Norm Difference for worker 936 is 0.752227
INFO:root:FL Epoch: 633 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 633 Training on worker :1529
INFO:root:FL Epoch: 633 Using Learning rate : 0.01410821592725817 
INFO:root:FL Epoch: 633 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506435
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342463
INFO:root:FL Epoch: 633 Norm Difference for worker 1529 is 0.813758
INFO:root:FL Epoch: 633 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 633 Training on worker :428
INFO:root:FL Epoch: 633 Using Learning rate : 0.01410821592725817 
INFO:root:FL Epoch: 633 Normal Training
INFO:root:Worker: 428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661425
INFO:root:Worker: 428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348824
INFO:root:FL Epoch: 633 Norm Difference for worker 428 is 0.686466
INFO:root:FL Epoch: 633 Done on worker:428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 633 Training on worker :1022
INFO:root:FL Epoch: 633 Using Learning rate : 0.01410821592725817 
INFO:root:FL Epoch: 633 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328220
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349965
INFO:root:FL Epoch: 633 Norm Difference for worker 1022 is 0.644195
INFO:root:FL Epoch: 633 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 633 Training on worker :1797
INFO:root:FL Epoch: 633 Using Learning rate : 0.01410821592725817 
INFO:root:FL Epoch: 633 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474440
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685376
INFO:root:FL Epoch: 633 Norm Difference for worker 1797 is 0.762049
INFO:root:FL Epoch: 633 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 633 Training on worker :133
INFO:root:FL Epoch: 633 Using Learning rate : 0.01410821592725817 
INFO:root:FL Epoch: 633 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.617316
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.448515
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 633 Norm Difference for worker 133 is 0.648349
INFO:root:FL Epoch: 633 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 633 Training on worker :96
INFO:root:FL Epoch: 633 Using Learning rate : 0.01410821592725817 
INFO:root:FL Epoch: 633 Normal Training
INFO:root:Worker: 96 Train Epoch: 0 [0/201 (0%)]	Loss: 0.419123
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 96 Train Epoch: 1 [0/201 (0%)]	Loss: 0.304377
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 633 Norm Difference for worker 96 is 0.744268
INFO:root:FL Epoch: 633 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 633 Training on worker :1201
INFO:root:FL Epoch: 633 Using Learning rate : 0.01410821592725817 
INFO:root:FL Epoch: 633 Normal Training
INFO:root:Worker: 1201 Train Epoch: 0 [0/200 (0%)]	Loss: 1.004018
INFO:root:Worker: 1201 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444693
INFO:root:FL Epoch: 633 Norm Difference for worker 1201 is 0.676168
INFO:root:FL Epoch: 633 Done on worker:1201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 633 Training on worker :1407
INFO:root:FL Epoch: 633 Using Learning rate : 0.01410821592725817 
INFO:root:FL Epoch: 633 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.283335
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374604
INFO:root:FL Epoch: 633 Norm Difference for worker 1407 is 0.711822
INFO:root:FL Epoch: 633 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 633 Training on worker :422
INFO:root:FL Epoch: 633 Using Learning rate : 0.01410821592725817 
INFO:root:FL Epoch: 633 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399897
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397252
INFO:root:FL Epoch: 633 Norm Difference for worker 422 is 0.683659
INFO:root:FL Epoch: 633 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 133
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 633 Ends   ===================
INFO:root:Epoch:633 Global Model Test Loss:0.5222055526340709 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:633 Global Model Backdoor Test Loss:0.11687822639942169                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 634 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 634 Workers Selected : [1767, 1620, 569, 55, 953, 253, 598, 295, 1199, 545]
INFO:root:FL Epoch: 634 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 634 Num points on workers: [200 200 200 201 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 634 Training on worker :1767
INFO:root:FL Epoch: 634 Using Learning rate : 0.014079999495403653 
INFO:root:FL Epoch: 634 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520623
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292838
INFO:root:FL Epoch: 634 Norm Difference for worker 1767 is 0.662965
INFO:root:FL Epoch: 634 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 634 Training on worker :1620
INFO:root:FL Epoch: 634 Using Learning rate : 0.014079999495403653 
INFO:root:FL Epoch: 634 Normal Training
INFO:root:Worker: 1620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.203243
INFO:root:Worker: 1620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321185
INFO:root:FL Epoch: 634 Norm Difference for worker 1620 is 0.60856
INFO:root:FL Epoch: 634 Done on worker:1620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 634 Training on worker :569
INFO:root:FL Epoch: 634 Using Learning rate : 0.014079999495403653 
INFO:root:FL Epoch: 634 Normal Training
INFO:root:Worker: 569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598892
INFO:root:Worker: 569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330273
INFO:root:FL Epoch: 634 Norm Difference for worker 569 is 0.714622
INFO:root:FL Epoch: 634 Done on worker:569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 634 Training on worker :55
INFO:root:FL Epoch: 634 Using Learning rate : 0.014079999495403653 
INFO:root:FL Epoch: 634 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.548079
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.360340
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 634 Norm Difference for worker 55 is 0.639555
INFO:root:FL Epoch: 634 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 634 Training on worker :953
INFO:root:FL Epoch: 634 Using Learning rate : 0.014079999495403653 
INFO:root:FL Epoch: 634 Normal Training
INFO:root:Worker: 953 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369797
INFO:root:Worker: 953 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463397
INFO:root:FL Epoch: 634 Norm Difference for worker 953 is 0.644223
INFO:root:FL Epoch: 634 Done on worker:953
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 634 Training on worker :253
INFO:root:FL Epoch: 634 Using Learning rate : 0.014079999495403653 
INFO:root:FL Epoch: 634 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.371997
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.648858
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 634 Norm Difference for worker 253 is 0.69703
INFO:root:FL Epoch: 634 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 634 Training on worker :598
INFO:root:FL Epoch: 634 Using Learning rate : 0.014079999495403653 
INFO:root:FL Epoch: 634 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565569
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418857
INFO:root:FL Epoch: 634 Norm Difference for worker 598 is 0.662132
INFO:root:FL Epoch: 634 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 634 Training on worker :295
INFO:root:FL Epoch: 634 Using Learning rate : 0.014079999495403653 
INFO:root:FL Epoch: 634 Normal Training
INFO:root:Worker: 295 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676216
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 295 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450816
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 634 Norm Difference for worker 295 is 0.725226
INFO:root:FL Epoch: 634 Done on worker:295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 634 Training on worker :1199
INFO:root:FL Epoch: 634 Using Learning rate : 0.014079999495403653 
INFO:root:FL Epoch: 634 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.818876
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329181
INFO:root:FL Epoch: 634 Norm Difference for worker 1199 is 0.69181
INFO:root:FL Epoch: 634 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 634 Training on worker :545
INFO:root:FL Epoch: 634 Using Learning rate : 0.014079999495403653 
INFO:root:FL Epoch: 634 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774699
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.777768
INFO:root:FL Epoch: 634 Norm Difference for worker 545 is 0.667127
INFO:root:FL Epoch: 634 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1620
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 634 Ends   ===================
INFO:root:Epoch:634 Global Model Test Loss:0.5220118655877954 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:634 Global Model Backdoor Test Loss:0.1119465430577596                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 635 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 635 Workers Selected : [444, 1452, 461, 140, 1000, 1210, 747, 33, 1773, 375]
INFO:root:FL Epoch: 635 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 635 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 635 Training on worker :444
INFO:root:FL Epoch: 635 Using Learning rate : 0.014051839496412847 
INFO:root:FL Epoch: 635 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686588
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537091
INFO:root:FL Epoch: 635 Norm Difference for worker 444 is 0.723354
INFO:root:FL Epoch: 635 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 635 Training on worker :1452
INFO:root:FL Epoch: 635 Using Learning rate : 0.014051839496412847 
INFO:root:FL Epoch: 635 Normal Training
INFO:root:Worker: 1452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463217
INFO:root:Worker: 1452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347132
INFO:root:FL Epoch: 635 Norm Difference for worker 1452 is 0.675932
INFO:root:FL Epoch: 635 Done on worker:1452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 635 Training on worker :461
INFO:root:FL Epoch: 635 Using Learning rate : 0.014051839496412847 
INFO:root:FL Epoch: 635 Normal Training
INFO:root:Worker: 461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529869
INFO:root:Worker: 461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312530
INFO:root:FL Epoch: 635 Norm Difference for worker 461 is 0.612865
INFO:root:FL Epoch: 635 Done on worker:461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 635 Training on worker :140
INFO:root:FL Epoch: 635 Using Learning rate : 0.014051839496412847 
INFO:root:FL Epoch: 635 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.824079
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.442694
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 635 Norm Difference for worker 140 is 0.69142
INFO:root:FL Epoch: 635 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 635 Training on worker :1000
INFO:root:FL Epoch: 635 Using Learning rate : 0.014051839496412847 
INFO:root:FL Epoch: 635 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594570
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256135
INFO:root:FL Epoch: 635 Norm Difference for worker 1000 is 0.703461
INFO:root:FL Epoch: 635 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 635 Training on worker :1210
INFO:root:FL Epoch: 635 Using Learning rate : 0.014051839496412847 
INFO:root:FL Epoch: 635 Normal Training
INFO:root:Worker: 1210 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480057
INFO:root:Worker: 1210 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474263
INFO:root:FL Epoch: 635 Norm Difference for worker 1210 is 0.674158
INFO:root:FL Epoch: 635 Done on worker:1210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 635 Training on worker :747
INFO:root:FL Epoch: 635 Using Learning rate : 0.014051839496412847 
INFO:root:FL Epoch: 635 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495426
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487712
INFO:root:FL Epoch: 635 Norm Difference for worker 747 is 0.683499
INFO:root:FL Epoch: 635 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 635 Training on worker :33
INFO:root:FL Epoch: 635 Using Learning rate : 0.014051839496412847 
INFO:root:FL Epoch: 635 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.674500
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.508814
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 635 Norm Difference for worker 33 is 0.648893
INFO:root:FL Epoch: 635 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 635 Training on worker :1773
INFO:root:FL Epoch: 635 Using Learning rate : 0.014051839496412847 
INFO:root:FL Epoch: 635 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378393
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309341
INFO:root:FL Epoch: 635 Norm Difference for worker 1773 is 0.661475
INFO:root:FL Epoch: 635 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 635 Training on worker :375
INFO:root:FL Epoch: 635 Using Learning rate : 0.014051839496412847 
INFO:root:FL Epoch: 635 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448985
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510661
INFO:root:FL Epoch: 635 Norm Difference for worker 375 is 0.724273
INFO:root:FL Epoch: 635 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 461
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 635 Ends   ===================
INFO:root:Epoch:635 Global Model Test Loss:0.5527935361160952 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:635 Global Model Backdoor Test Loss:0.20129901294906935                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 636 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 636 Workers Selected : [1596, 104, 1138, 367, 1834, 289, 475, 1888, 1798, 51]
INFO:root:FL Epoch: 636 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 636 Num points on workers: [200 201 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 636 Training on worker :1596
INFO:root:FL Epoch: 636 Using Learning rate : 0.01402373581742002 
INFO:root:FL Epoch: 636 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552106
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692007
INFO:root:FL Epoch: 636 Norm Difference for worker 1596 is 0.720389
INFO:root:FL Epoch: 636 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 636 Training on worker :104
INFO:root:FL Epoch: 636 Using Learning rate : 0.01402373581742002 
INFO:root:FL Epoch: 636 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.536043
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.358041
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 636 Norm Difference for worker 104 is 0.712689
INFO:root:FL Epoch: 636 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 636 Training on worker :1138
INFO:root:FL Epoch: 636 Using Learning rate : 0.01402373581742002 
INFO:root:FL Epoch: 636 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730150
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455738
INFO:root:FL Epoch: 636 Norm Difference for worker 1138 is 0.773871
INFO:root:FL Epoch: 636 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 636 Training on worker :367
INFO:root:FL Epoch: 636 Using Learning rate : 0.01402373581742002 
INFO:root:FL Epoch: 636 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565599
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428038
INFO:root:FL Epoch: 636 Norm Difference for worker 367 is 0.663533
INFO:root:FL Epoch: 636 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 636 Training on worker :1834
INFO:root:FL Epoch: 636 Using Learning rate : 0.01402373581742002 
INFO:root:FL Epoch: 636 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.295513
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556282
INFO:root:FL Epoch: 636 Norm Difference for worker 1834 is 0.667635
INFO:root:FL Epoch: 636 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 636 Training on worker :289
INFO:root:FL Epoch: 636 Using Learning rate : 0.01402373581742002 
INFO:root:FL Epoch: 636 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.535347
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.373571
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 636 Norm Difference for worker 289 is 0.622545
INFO:root:FL Epoch: 636 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 636 Training on worker :475
INFO:root:FL Epoch: 636 Using Learning rate : 0.01402373581742002 
INFO:root:FL Epoch: 636 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338011
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.160525
INFO:root:FL Epoch: 636 Norm Difference for worker 475 is 0.543622
INFO:root:FL Epoch: 636 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 636 Training on worker :1888
INFO:root:FL Epoch: 636 Using Learning rate : 0.01402373581742002 
INFO:root:FL Epoch: 636 Normal Training
INFO:root:Worker: 1888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640121
INFO:root:Worker: 1888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377001
INFO:root:FL Epoch: 636 Norm Difference for worker 1888 is 0.707467
INFO:root:FL Epoch: 636 Done on worker:1888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 636 Training on worker :1798
INFO:root:FL Epoch: 636 Using Learning rate : 0.01402373581742002 
INFO:root:FL Epoch: 636 Normal Training
INFO:root:Worker: 1798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529377
INFO:root:Worker: 1798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656212
INFO:root:FL Epoch: 636 Norm Difference for worker 1798 is 0.797014
INFO:root:FL Epoch: 636 Done on worker:1798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 636 Training on worker :51
INFO:root:FL Epoch: 636 Using Learning rate : 0.01402373581742002 
INFO:root:FL Epoch: 636 Normal Training
INFO:root:Worker: 51 Train Epoch: 0 [0/201 (0%)]	Loss: 0.461881
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 51 Train Epoch: 1 [0/201 (0%)]	Loss: 0.374687
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 636 Norm Difference for worker 51 is 0.659673
INFO:root:FL Epoch: 636 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 475
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 636 Ends   ===================
INFO:root:Epoch:636 Global Model Test Loss:0.5349409299738267 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:636 Global Model Backdoor Test Loss:0.12627339735627174                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 637 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 637 Workers Selected : [945, 15, 304, 957, 1361, 1848, 1090, 284, 1715, 208]
INFO:root:FL Epoch: 637 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.1002994 0.0998004 0.0998004 0.0998004 0.0998004
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 637 Num points on workers: [200 201 201 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 637 Training on worker :945
INFO:root:FL Epoch: 637 Using Learning rate : 0.01399568834578518 
INFO:root:FL Epoch: 637 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.278046
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.123307
INFO:root:FL Epoch: 637 Norm Difference for worker 945 is 0.500289
INFO:root:FL Epoch: 637 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 637 Training on worker :15
INFO:root:FL Epoch: 637 Using Learning rate : 0.01399568834578518 
INFO:root:FL Epoch: 637 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.396076
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.510906
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 637 Norm Difference for worker 15 is 0.675799
INFO:root:FL Epoch: 637 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 637 Training on worker :304
INFO:root:FL Epoch: 637 Using Learning rate : 0.01399568834578518 
INFO:root:FL Epoch: 637 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.477873
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.410178
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 637 Norm Difference for worker 304 is 0.722154
INFO:root:FL Epoch: 637 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 637 Training on worker :957
INFO:root:FL Epoch: 637 Using Learning rate : 0.01399568834578518 
INFO:root:FL Epoch: 637 Normal Training
INFO:root:Worker: 957 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590280
INFO:root:Worker: 957 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487308
INFO:root:FL Epoch: 637 Norm Difference for worker 957 is 0.700551
INFO:root:FL Epoch: 637 Done on worker:957
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 637 Training on worker :1361
INFO:root:FL Epoch: 637 Using Learning rate : 0.01399568834578518 
INFO:root:FL Epoch: 637 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645028
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348554
INFO:root:FL Epoch: 637 Norm Difference for worker 1361 is 0.721923
INFO:root:FL Epoch: 637 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 637 Training on worker :1848
INFO:root:FL Epoch: 637 Using Learning rate : 0.01399568834578518 
INFO:root:FL Epoch: 637 Normal Training
INFO:root:Worker: 1848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576698
INFO:root:Worker: 1848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296550
INFO:root:FL Epoch: 637 Norm Difference for worker 1848 is 0.709447
INFO:root:FL Epoch: 637 Done on worker:1848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 637 Training on worker :1090
INFO:root:FL Epoch: 637 Using Learning rate : 0.01399568834578518 
INFO:root:FL Epoch: 637 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555743
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291469
INFO:root:FL Epoch: 637 Norm Difference for worker 1090 is 0.707173
INFO:root:FL Epoch: 637 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 637 Training on worker :284
INFO:root:FL Epoch: 637 Using Learning rate : 0.01399568834578518 
INFO:root:FL Epoch: 637 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.589313
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.372752
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 637 Norm Difference for worker 284 is 0.791224
INFO:root:FL Epoch: 637 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 637 Training on worker :1715
INFO:root:FL Epoch: 637 Using Learning rate : 0.01399568834578518 
INFO:root:FL Epoch: 637 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628908
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479938
INFO:root:FL Epoch: 637 Norm Difference for worker 1715 is 0.679098
INFO:root:FL Epoch: 637 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 637 Training on worker :208
INFO:root:FL Epoch: 637 Using Learning rate : 0.01399568834578518 
INFO:root:FL Epoch: 637 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.460420
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.413923
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 637 Norm Difference for worker 208 is 0.672876
INFO:root:FL Epoch: 637 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 945
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 637 Ends   ===================
INFO:root:Epoch:637 Global Model Test Loss:0.5440737254479352 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:637 Global Model Backdoor Test Loss:0.11066132535537083                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 638 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 638 Workers Selected : [421, 1169, 907, 1176, 1511, 288, 1524, 1826, 1157, 919]
INFO:root:FL Epoch: 638 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 638 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 638 Training on worker :421
INFO:root:FL Epoch: 638 Using Learning rate : 0.01396769696909361 
INFO:root:FL Epoch: 638 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383834
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351064
INFO:root:FL Epoch: 638 Norm Difference for worker 421 is 0.771557
INFO:root:FL Epoch: 638 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 638 Training on worker :1169
INFO:root:FL Epoch: 638 Using Learning rate : 0.01396769696909361 
INFO:root:FL Epoch: 638 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520430
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222910
INFO:root:FL Epoch: 638 Norm Difference for worker 1169 is 0.777571
INFO:root:FL Epoch: 638 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 638 Training on worker :907
INFO:root:FL Epoch: 638 Using Learning rate : 0.01396769696909361 
INFO:root:FL Epoch: 638 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.953607
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362148
INFO:root:FL Epoch: 638 Norm Difference for worker 907 is 0.805921
INFO:root:FL Epoch: 638 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 638 Training on worker :1176
INFO:root:FL Epoch: 638 Using Learning rate : 0.01396769696909361 
INFO:root:FL Epoch: 638 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.266305
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401340
INFO:root:FL Epoch: 638 Norm Difference for worker 1176 is 0.578846
INFO:root:FL Epoch: 638 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 638 Training on worker :1511
INFO:root:FL Epoch: 638 Using Learning rate : 0.01396769696909361 
INFO:root:FL Epoch: 638 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773954
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318920
INFO:root:FL Epoch: 638 Norm Difference for worker 1511 is 0.801426
INFO:root:FL Epoch: 638 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 638 Training on worker :288
INFO:root:FL Epoch: 638 Using Learning rate : 0.01396769696909361 
INFO:root:FL Epoch: 638 Normal Training
INFO:root:Worker: 288 Train Epoch: 0 [0/201 (0%)]	Loss: 0.562578
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 288 Train Epoch: 1 [0/201 (0%)]	Loss: 0.426240
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 638 Norm Difference for worker 288 is 0.777241
INFO:root:FL Epoch: 638 Done on worker:288
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 638 Training on worker :1524
INFO:root:FL Epoch: 638 Using Learning rate : 0.01396769696909361 
INFO:root:FL Epoch: 638 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.302287
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549038
INFO:root:FL Epoch: 638 Norm Difference for worker 1524 is 0.794759
INFO:root:FL Epoch: 638 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 638 Training on worker :1826
INFO:root:FL Epoch: 638 Using Learning rate : 0.01396769696909361 
INFO:root:FL Epoch: 638 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.229077
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389596
INFO:root:FL Epoch: 638 Norm Difference for worker 1826 is 0.71594
INFO:root:FL Epoch: 638 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 638 Training on worker :1157
INFO:root:FL Epoch: 638 Using Learning rate : 0.01396769696909361 
INFO:root:FL Epoch: 638 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700415
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364143
INFO:root:FL Epoch: 638 Norm Difference for worker 1157 is 0.646756
INFO:root:FL Epoch: 638 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 638 Training on worker :919
INFO:root:FL Epoch: 638 Using Learning rate : 0.01396769696909361 
INFO:root:FL Epoch: 638 Normal Training
INFO:root:Worker: 919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.825558
INFO:root:Worker: 919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556723
INFO:root:FL Epoch: 638 Norm Difference for worker 919 is 0.72469
INFO:root:FL Epoch: 638 Done on worker:919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1176
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 638 Ends   ===================
INFO:root:Epoch:638 Global Model Test Loss:0.5411212567020866 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:638 Global Model Backdoor Test Loss:0.10762640337149303                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 639 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 639 Workers Selected : [1124, 583, 333, 158, 126, 459, 786, 991, 1294, 367]
INFO:root:FL Epoch: 639 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 639 Num points on workers: [200 200 201 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 639 Training on worker :1124
INFO:root:FL Epoch: 639 Using Learning rate : 0.013939761575155422 
INFO:root:FL Epoch: 639 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363593
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486352
INFO:root:FL Epoch: 639 Norm Difference for worker 1124 is 0.710295
INFO:root:FL Epoch: 639 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 639 Training on worker :583
INFO:root:FL Epoch: 639 Using Learning rate : 0.013939761575155422 
INFO:root:FL Epoch: 639 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391358
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520988
INFO:root:FL Epoch: 639 Norm Difference for worker 583 is 0.770984
INFO:root:FL Epoch: 639 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 639 Training on worker :333
INFO:root:FL Epoch: 639 Using Learning rate : 0.013939761575155422 
INFO:root:FL Epoch: 639 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.180808
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381827
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 639 Norm Difference for worker 333 is 0.582552
INFO:root:FL Epoch: 639 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 639 Training on worker :158
INFO:root:FL Epoch: 639 Using Learning rate : 0.013939761575155422 
INFO:root:FL Epoch: 639 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.742662
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.600531
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 639 Norm Difference for worker 158 is 0.757204
INFO:root:FL Epoch: 639 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 639 Training on worker :126
INFO:root:FL Epoch: 639 Using Learning rate : 0.013939761575155422 
INFO:root:FL Epoch: 639 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.361268
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.503209
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 639 Norm Difference for worker 126 is 0.727356
INFO:root:FL Epoch: 639 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 639 Training on worker :459
INFO:root:FL Epoch: 639 Using Learning rate : 0.013939761575155422 
INFO:root:FL Epoch: 639 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657453
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345318
INFO:root:FL Epoch: 639 Norm Difference for worker 459 is 0.757223
INFO:root:FL Epoch: 639 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 639 Training on worker :786
INFO:root:FL Epoch: 639 Using Learning rate : 0.013939761575155422 
INFO:root:FL Epoch: 639 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555008
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463156
INFO:root:FL Epoch: 639 Norm Difference for worker 786 is 0.72942
INFO:root:FL Epoch: 639 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 639 Training on worker :991
INFO:root:FL Epoch: 639 Using Learning rate : 0.013939761575155422 
INFO:root:FL Epoch: 639 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320953
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459279
INFO:root:FL Epoch: 639 Norm Difference for worker 991 is 0.733574
INFO:root:FL Epoch: 639 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 639 Training on worker :1294
INFO:root:FL Epoch: 639 Using Learning rate : 0.013939761575155422 
INFO:root:FL Epoch: 639 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783840
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339537
INFO:root:FL Epoch: 639 Norm Difference for worker 1294 is 0.790526
INFO:root:FL Epoch: 639 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 639 Training on worker :367
INFO:root:FL Epoch: 639 Using Learning rate : 0.013939761575155422 
INFO:root:FL Epoch: 639 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307090
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489387
INFO:root:FL Epoch: 639 Norm Difference for worker 367 is 0.746789
INFO:root:FL Epoch: 639 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 333
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 639 Ends   ===================
INFO:root:Epoch:639 Global Model Test Loss:0.5325592651086695 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:639 Global Model Backdoor Test Loss:0.12235621735453606                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 640 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 640 Workers Selected : [1829, 1217, 584, 1479, 451, 1313, 1673, 401, 885, 1525]
INFO:root:FL Epoch: 640 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 640 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 640 Training on worker :1829
INFO:root:FL Epoch: 640 Using Learning rate : 0.013911882052005112 
INFO:root:FL Epoch: 640 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628486
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501476
INFO:root:FL Epoch: 640 Norm Difference for worker 1829 is 0.805657
INFO:root:FL Epoch: 640 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 640 Training on worker :1217
INFO:root:FL Epoch: 640 Using Learning rate : 0.013911882052005112 
INFO:root:FL Epoch: 640 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544420
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451988
INFO:root:FL Epoch: 640 Norm Difference for worker 1217 is 0.763717
INFO:root:FL Epoch: 640 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 640 Training on worker :584
INFO:root:FL Epoch: 640 Using Learning rate : 0.013911882052005112 
INFO:root:FL Epoch: 640 Normal Training
INFO:root:Worker: 584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434675
INFO:root:Worker: 584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312200
INFO:root:FL Epoch: 640 Norm Difference for worker 584 is 0.737747
INFO:root:FL Epoch: 640 Done on worker:584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 640 Training on worker :1479
INFO:root:FL Epoch: 640 Using Learning rate : 0.013911882052005112 
INFO:root:FL Epoch: 640 Normal Training
INFO:root:Worker: 1479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616406
INFO:root:Worker: 1479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.756766
INFO:root:FL Epoch: 640 Norm Difference for worker 1479 is 0.711117
INFO:root:FL Epoch: 640 Done on worker:1479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 640 Training on worker :451
INFO:root:FL Epoch: 640 Using Learning rate : 0.013911882052005112 
INFO:root:FL Epoch: 640 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624323
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350982
INFO:root:FL Epoch: 640 Norm Difference for worker 451 is 0.778482
INFO:root:FL Epoch: 640 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 640 Training on worker :1313
INFO:root:FL Epoch: 640 Using Learning rate : 0.013911882052005112 
INFO:root:FL Epoch: 640 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307228
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215915
INFO:root:FL Epoch: 640 Norm Difference for worker 1313 is 0.580316
INFO:root:FL Epoch: 640 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 640 Training on worker :1673
INFO:root:FL Epoch: 640 Using Learning rate : 0.013911882052005112 
INFO:root:FL Epoch: 640 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622443
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553862
INFO:root:FL Epoch: 640 Norm Difference for worker 1673 is 0.746786
INFO:root:FL Epoch: 640 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 640 Training on worker :401
INFO:root:FL Epoch: 640 Using Learning rate : 0.013911882052005112 
INFO:root:FL Epoch: 640 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397963
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545191
INFO:root:FL Epoch: 640 Norm Difference for worker 401 is 0.631648
INFO:root:FL Epoch: 640 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 640 Training on worker :885
INFO:root:FL Epoch: 640 Using Learning rate : 0.013911882052005112 
INFO:root:FL Epoch: 640 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781072
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426644
INFO:root:FL Epoch: 640 Norm Difference for worker 885 is 0.768414
INFO:root:FL Epoch: 640 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 640 Training on worker :1525
INFO:root:FL Epoch: 640 Using Learning rate : 0.013911882052005112 
INFO:root:FL Epoch: 640 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.884972
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544372
INFO:root:FL Epoch: 640 Norm Difference for worker 1525 is 0.790634
INFO:root:FL Epoch: 640 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1313
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 640 Ends   ===================
INFO:root:Epoch:640 Global Model Test Loss:0.5360487454077777 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:640 Global Model Backdoor Test Loss:0.0958048477768898                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 641 Begins ===================
INFO:root:FL Epoch: 641 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 641 Workers Selected : [0, 1, 2, 1644, 1050, 1137, 72, 1710, 325, 74]
INFO:root:FL Epoch: 641 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 641 Num points on workers: [200 200 200 200 200 200 201 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 641 Training on worker :0
INFO:root:FL Epoch: 641 Using Learning rate : 0.0027768116575802204 
INFO:root:FL Epoch: 641 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.125657
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.144004
INFO:root:FL Epoch: 641 Worker: 0 Backdoor Test Loss: 0.08940288548668225 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 641 Worker: 0 Backdoor Train Loss: 0.08586496151983739 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 641 Norm Difference for worker 0 is 0.0648
INFO:root:FL Epoch: 641 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 641 Training on worker :1
INFO:root:FL Epoch: 641 Using Learning rate : 0.0027768116575802204 
INFO:root:FL Epoch: 641 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.066961
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.080723
INFO:root:FL Epoch: 641 Worker: 1 Backdoor Test Loss: 0.08914274722337723 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 641 Worker: 1 Backdoor Train Loss: 0.08583711087703705 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 641 Norm Difference for worker 1 is 0.065516
INFO:root:FL Epoch: 641 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 641 Training on worker :2
INFO:root:FL Epoch: 641 Using Learning rate : 0.0027768116575802204 
INFO:root:FL Epoch: 641 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.092873
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.077426
INFO:root:FL Epoch: 641 Worker: 2 Backdoor Test Loss: 0.08934054585794608 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 641 Worker: 2 Backdoor Train Loss: 0.08616981245577335 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 641 Norm Difference for worker 2 is 0.062185
INFO:root:FL Epoch: 641 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 641 Training on worker :1644
INFO:root:FL Epoch: 641 Using Learning rate : 0.013884058287901103 
INFO:root:FL Epoch: 641 Normal Training
INFO:root:Worker: 1644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538306
INFO:root:Worker: 1644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294565
INFO:root:FL Epoch: 641 Norm Difference for worker 1644 is 0.707419
INFO:root:FL Epoch: 641 Done on worker:1644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 641 Training on worker :1050
INFO:root:FL Epoch: 641 Using Learning rate : 0.013884058287901103 
INFO:root:FL Epoch: 641 Normal Training
INFO:root:Worker: 1050 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631250
INFO:root:Worker: 1050 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371146
INFO:root:FL Epoch: 641 Norm Difference for worker 1050 is 0.736244
INFO:root:FL Epoch: 641 Done on worker:1050
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 641 Training on worker :1137
INFO:root:FL Epoch: 641 Using Learning rate : 0.013884058287901103 
INFO:root:FL Epoch: 641 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.984035
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533031
INFO:root:FL Epoch: 641 Norm Difference for worker 1137 is 0.84968
INFO:root:FL Epoch: 641 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 641 Training on worker :72
INFO:root:FL Epoch: 641 Using Learning rate : 0.013884058287901103 
INFO:root:FL Epoch: 641 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.385154
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.177023
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 641 Norm Difference for worker 72 is 0.746536
INFO:root:FL Epoch: 641 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 641 Training on worker :1710
INFO:root:FL Epoch: 641 Using Learning rate : 0.013884058287901103 
INFO:root:FL Epoch: 641 Normal Training
INFO:root:Worker: 1710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519264
INFO:root:Worker: 1710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508592
INFO:root:FL Epoch: 641 Norm Difference for worker 1710 is 0.787839
INFO:root:FL Epoch: 641 Done on worker:1710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 641 Training on worker :325
INFO:root:FL Epoch: 641 Using Learning rate : 0.013884058287901103 
INFO:root:FL Epoch: 641 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.683184
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.309384
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 641 Norm Difference for worker 325 is 0.744318
INFO:root:FL Epoch: 641 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 641 Training on worker :74
INFO:root:FL Epoch: 641 Using Learning rate : 0.013884058287901103 
INFO:root:FL Epoch: 641 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.540916
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.503359
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 641 Norm Difference for worker 74 is 0.842768
INFO:root:FL Epoch: 641 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 641 Ends   ===================
INFO:root:Epoch:641 Global Model Test Loss:0.5398108889074886 and Test Accuracy:75.0 
INFO:root:Epoch:641 Global Model Backdoor Test Loss:0.08934054585794608                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 642 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 642 Workers Selected : [1904, 830, 1706, 724, 105, 669, 1838, 1426, 1525, 348]
INFO:root:FL Epoch: 642 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 642 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 642 Training on worker :1904
INFO:root:FL Epoch: 642 Using Learning rate : 0.013856290171325301 
INFO:root:FL Epoch: 642 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594060
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391315
INFO:root:FL Epoch: 642 Norm Difference for worker 1904 is 0.718076
INFO:root:FL Epoch: 642 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 642 Training on worker :830
INFO:root:FL Epoch: 642 Using Learning rate : 0.013856290171325301 
INFO:root:FL Epoch: 642 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460525
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.190217
INFO:root:FL Epoch: 642 Norm Difference for worker 830 is 0.673672
INFO:root:FL Epoch: 642 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 642 Training on worker :1706
INFO:root:FL Epoch: 642 Using Learning rate : 0.013856290171325301 
INFO:root:FL Epoch: 642 Normal Training
INFO:root:Worker: 1706 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452121
INFO:root:Worker: 1706 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548113
INFO:root:FL Epoch: 642 Norm Difference for worker 1706 is 0.78843
INFO:root:FL Epoch: 642 Done on worker:1706
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 642 Training on worker :724
INFO:root:FL Epoch: 642 Using Learning rate : 0.013856290171325301 
INFO:root:FL Epoch: 642 Normal Training
INFO:root:Worker: 724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671665
INFO:root:Worker: 724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345591
INFO:root:FL Epoch: 642 Norm Difference for worker 724 is 0.810483
INFO:root:FL Epoch: 642 Done on worker:724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 642 Training on worker :105
INFO:root:FL Epoch: 642 Using Learning rate : 0.013856290171325301 
INFO:root:FL Epoch: 642 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.516157
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.226062
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 642 Norm Difference for worker 105 is 0.814789
INFO:root:FL Epoch: 642 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 642 Training on worker :669
INFO:root:FL Epoch: 642 Using Learning rate : 0.013856290171325301 
INFO:root:FL Epoch: 642 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383207
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295316
INFO:root:FL Epoch: 642 Norm Difference for worker 669 is 0.774468
INFO:root:FL Epoch: 642 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 642 Training on worker :1838
INFO:root:FL Epoch: 642 Using Learning rate : 0.013856290171325301 
INFO:root:FL Epoch: 642 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660737
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639799
INFO:root:FL Epoch: 642 Norm Difference for worker 1838 is 0.931744
INFO:root:FL Epoch: 642 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 642 Training on worker :1426
INFO:root:FL Epoch: 642 Using Learning rate : 0.013856290171325301 
INFO:root:FL Epoch: 642 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662228
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328345
INFO:root:FL Epoch: 642 Norm Difference for worker 1426 is 0.832314
INFO:root:FL Epoch: 642 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 642 Training on worker :1525
INFO:root:FL Epoch: 642 Using Learning rate : 0.013856290171325301 
INFO:root:FL Epoch: 642 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462755
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524125
INFO:root:FL Epoch: 642 Norm Difference for worker 1525 is 0.878175
INFO:root:FL Epoch: 642 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 642 Training on worker :348
INFO:root:FL Epoch: 642 Using Learning rate : 0.013856290171325301 
INFO:root:FL Epoch: 642 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.860932
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618234
INFO:root:FL Epoch: 642 Norm Difference for worker 348 is 0.759995
INFO:root:FL Epoch: 642 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 830
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 642 Ends   ===================
INFO:root:Epoch:642 Global Model Test Loss:0.5435598650399376 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:642 Global Model Backdoor Test Loss:0.061548418986300625                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 643 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 643 Workers Selected : [1577, 779, 512, 235, 243, 191, 1671, 634, 443, 1020]
INFO:root:FL Epoch: 643 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 643 Num points on workers: [200 200 200 201 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 643 Training on worker :1577
INFO:root:FL Epoch: 643 Using Learning rate : 0.01382857759098265 
INFO:root:FL Epoch: 643 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598378
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.224477
INFO:root:FL Epoch: 643 Norm Difference for worker 1577 is 0.842903
INFO:root:FL Epoch: 643 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 643 Training on worker :779
INFO:root:FL Epoch: 643 Using Learning rate : 0.01382857759098265 
INFO:root:FL Epoch: 643 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393079
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369105
INFO:root:FL Epoch: 643 Norm Difference for worker 779 is 0.90834
INFO:root:FL Epoch: 643 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 643 Training on worker :512
INFO:root:FL Epoch: 643 Using Learning rate : 0.01382857759098265 
INFO:root:FL Epoch: 643 Normal Training
INFO:root:Worker: 512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778648
INFO:root:Worker: 512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364031
INFO:root:FL Epoch: 643 Norm Difference for worker 512 is 0.790555
INFO:root:FL Epoch: 643 Done on worker:512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 643 Training on worker :235
INFO:root:FL Epoch: 643 Using Learning rate : 0.01382857759098265 
INFO:root:FL Epoch: 643 Normal Training
INFO:root:Worker: 235 Train Epoch: 0 [0/201 (0%)]	Loss: 0.584917
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 235 Train Epoch: 1 [0/201 (0%)]	Loss: 0.609737
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 643 Norm Difference for worker 235 is 0.816616
INFO:root:FL Epoch: 643 Done on worker:235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 643 Training on worker :243
INFO:root:FL Epoch: 643 Using Learning rate : 0.01382857759098265 
INFO:root:FL Epoch: 643 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.276958
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.318121
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 643 Norm Difference for worker 243 is 0.750219
INFO:root:FL Epoch: 643 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 643 Training on worker :191
INFO:root:FL Epoch: 643 Using Learning rate : 0.01382857759098265 
INFO:root:FL Epoch: 643 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.393283
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.325324
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 643 Norm Difference for worker 191 is 0.814441
INFO:root:FL Epoch: 643 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 643 Training on worker :1671
INFO:root:FL Epoch: 643 Using Learning rate : 0.01382857759098265 
INFO:root:FL Epoch: 643 Normal Training
INFO:root:Worker: 1671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511779
INFO:root:Worker: 1671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.142158
INFO:root:FL Epoch: 643 Norm Difference for worker 1671 is 0.78147
INFO:root:FL Epoch: 643 Done on worker:1671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 643 Training on worker :634
INFO:root:FL Epoch: 643 Using Learning rate : 0.01382857759098265 
INFO:root:FL Epoch: 643 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699349
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309563
INFO:root:FL Epoch: 643 Norm Difference for worker 634 is 0.748116
INFO:root:FL Epoch: 643 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 643 Training on worker :443
INFO:root:FL Epoch: 643 Using Learning rate : 0.01382857759098265 
INFO:root:FL Epoch: 643 Normal Training
INFO:root:Worker: 443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.833708
INFO:root:Worker: 443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591480
INFO:root:FL Epoch: 643 Norm Difference for worker 443 is 0.849915
INFO:root:FL Epoch: 643 Done on worker:443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 643 Training on worker :1020
INFO:root:FL Epoch: 643 Using Learning rate : 0.01382857759098265 
INFO:root:FL Epoch: 643 Normal Training
INFO:root:Worker: 1020 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515906
INFO:root:Worker: 1020 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542198
INFO:root:FL Epoch: 643 Norm Difference for worker 1020 is 0.723261
INFO:root:FL Epoch: 643 Done on worker:1020
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1020
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 643 Ends   ===================
INFO:root:Epoch:643 Global Model Test Loss:0.529250293970108 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:643 Global Model Backdoor Test Loss:0.114007913817962                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 644 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 644 Workers Selected : [563, 1407, 1882, 1071, 1689, 574, 1118, 399, 1608, 1747]
INFO:root:FL Epoch: 644 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 644 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 644 Training on worker :563
INFO:root:FL Epoch: 644 Using Learning rate : 0.013800920435800685 
INFO:root:FL Epoch: 644 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428135
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312610
INFO:root:FL Epoch: 644 Norm Difference for worker 563 is 0.573777
INFO:root:FL Epoch: 644 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 644 Training on worker :1407
INFO:root:FL Epoch: 644 Using Learning rate : 0.013800920435800685 
INFO:root:FL Epoch: 644 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720018
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648839
INFO:root:FL Epoch: 644 Norm Difference for worker 1407 is 0.748109
INFO:root:FL Epoch: 644 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 644 Training on worker :1882
INFO:root:FL Epoch: 644 Using Learning rate : 0.013800920435800685 
INFO:root:FL Epoch: 644 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775468
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646748
INFO:root:FL Epoch: 644 Norm Difference for worker 1882 is 0.759345
INFO:root:FL Epoch: 644 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 644 Training on worker :1071
INFO:root:FL Epoch: 644 Using Learning rate : 0.013800920435800685 
INFO:root:FL Epoch: 644 Normal Training
INFO:root:Worker: 1071 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619312
INFO:root:Worker: 1071 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415741
INFO:root:FL Epoch: 644 Norm Difference for worker 1071 is 0.677165
INFO:root:FL Epoch: 644 Done on worker:1071
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 644 Training on worker :1689
INFO:root:FL Epoch: 644 Using Learning rate : 0.013800920435800685 
INFO:root:FL Epoch: 644 Normal Training
INFO:root:Worker: 1689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526179
INFO:root:Worker: 1689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451773
INFO:root:FL Epoch: 644 Norm Difference for worker 1689 is 0.729997
INFO:root:FL Epoch: 644 Done on worker:1689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 644 Training on worker :574
INFO:root:FL Epoch: 644 Using Learning rate : 0.013800920435800685 
INFO:root:FL Epoch: 644 Normal Training
INFO:root:Worker: 574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633311
INFO:root:Worker: 574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396221
INFO:root:FL Epoch: 644 Norm Difference for worker 574 is 0.689635
INFO:root:FL Epoch: 644 Done on worker:574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 644 Training on worker :1118
INFO:root:FL Epoch: 644 Using Learning rate : 0.013800920435800685 
INFO:root:FL Epoch: 644 Normal Training
INFO:root:Worker: 1118 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378182
INFO:root:Worker: 1118 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435842
INFO:root:FL Epoch: 644 Norm Difference for worker 1118 is 0.695661
INFO:root:FL Epoch: 644 Done on worker:1118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 644 Training on worker :399
INFO:root:FL Epoch: 644 Using Learning rate : 0.013800920435800685 
INFO:root:FL Epoch: 644 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530931
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.721233
INFO:root:FL Epoch: 644 Norm Difference for worker 399 is 0.714346
INFO:root:FL Epoch: 644 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 644 Training on worker :1608
INFO:root:FL Epoch: 644 Using Learning rate : 0.013800920435800685 
INFO:root:FL Epoch: 644 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807313
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332551
INFO:root:FL Epoch: 644 Norm Difference for worker 1608 is 0.741932
INFO:root:FL Epoch: 644 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 644 Training on worker :1747
INFO:root:FL Epoch: 644 Using Learning rate : 0.013800920435800685 
INFO:root:FL Epoch: 644 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601042
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427149
INFO:root:FL Epoch: 644 Norm Difference for worker 1747 is 0.715529
INFO:root:FL Epoch: 644 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 563
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 644 Ends   ===================
INFO:root:Epoch:644 Global Model Test Loss:0.5540820465368383 and Test Accuracy:75.0 
INFO:root:Epoch:644 Global Model Backdoor Test Loss:0.10994458012282848                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 645 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 645 Workers Selected : [1111, 1878, 1505, 1084, 1040, 1173, 1446, 805, 871, 453]
INFO:root:FL Epoch: 645 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 645 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 645 Training on worker :1111
INFO:root:FL Epoch: 645 Using Learning rate : 0.013773318594929083 
INFO:root:FL Epoch: 645 Normal Training
INFO:root:Worker: 1111 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755296
INFO:root:Worker: 1111 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342490
INFO:root:FL Epoch: 645 Norm Difference for worker 1111 is 0.670587
INFO:root:FL Epoch: 645 Done on worker:1111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 645 Training on worker :1878
INFO:root:FL Epoch: 645 Using Learning rate : 0.013773318594929083 
INFO:root:FL Epoch: 645 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.862025
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509035
INFO:root:FL Epoch: 645 Norm Difference for worker 1878 is 0.798779
INFO:root:FL Epoch: 645 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 645 Training on worker :1505
INFO:root:FL Epoch: 645 Using Learning rate : 0.013773318594929083 
INFO:root:FL Epoch: 645 Normal Training
INFO:root:Worker: 1505 Train Epoch: 0 [0/200 (0%)]	Loss: 1.055495
INFO:root:Worker: 1505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470704
INFO:root:FL Epoch: 645 Norm Difference for worker 1505 is 0.797619
INFO:root:FL Epoch: 645 Done on worker:1505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 645 Training on worker :1084
INFO:root:FL Epoch: 645 Using Learning rate : 0.013773318594929083 
INFO:root:FL Epoch: 645 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774481
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235390
INFO:root:FL Epoch: 645 Norm Difference for worker 1084 is 0.745308
INFO:root:FL Epoch: 645 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 645 Training on worker :1040
INFO:root:FL Epoch: 645 Using Learning rate : 0.013773318594929083 
INFO:root:FL Epoch: 645 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385864
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284888
INFO:root:FL Epoch: 645 Norm Difference for worker 1040 is 0.742178
INFO:root:FL Epoch: 645 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 645 Training on worker :1173
INFO:root:FL Epoch: 645 Using Learning rate : 0.013773318594929083 
INFO:root:FL Epoch: 645 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.224726
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266085
INFO:root:FL Epoch: 645 Norm Difference for worker 1173 is 0.638893
INFO:root:FL Epoch: 645 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 645 Training on worker :1446
INFO:root:FL Epoch: 645 Using Learning rate : 0.013773318594929083 
INFO:root:FL Epoch: 645 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.935764
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343669
INFO:root:FL Epoch: 645 Norm Difference for worker 1446 is 0.726237
INFO:root:FL Epoch: 645 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 645 Training on worker :805
INFO:root:FL Epoch: 645 Using Learning rate : 0.013773318594929083 
INFO:root:FL Epoch: 645 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742668
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384726
INFO:root:FL Epoch: 645 Norm Difference for worker 805 is 0.750119
INFO:root:FL Epoch: 645 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 645 Training on worker :871
INFO:root:FL Epoch: 645 Using Learning rate : 0.013773318594929083 
INFO:root:FL Epoch: 645 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346134
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204687
INFO:root:FL Epoch: 645 Norm Difference for worker 871 is 0.752955
INFO:root:FL Epoch: 645 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 645 Training on worker :453
INFO:root:FL Epoch: 645 Using Learning rate : 0.013773318594929083 
INFO:root:FL Epoch: 645 Normal Training
INFO:root:Worker: 453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794405
INFO:root:Worker: 453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604489
INFO:root:FL Epoch: 645 Norm Difference for worker 453 is 0.785691
INFO:root:FL Epoch: 645 Done on worker:453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1111
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 645 Ends   ===================
INFO:root:Epoch:645 Global Model Test Loss:0.5239428684991949 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:645 Global Model Backdoor Test Loss:0.09561931466062863                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 646 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 646 Workers Selected : [1056, 1824, 1566, 228, 917, 527, 169, 279, 1402, 1605]
INFO:root:FL Epoch: 646 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 646 Num points on workers: [200 200 200 201 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 646 Training on worker :1056
INFO:root:FL Epoch: 646 Using Learning rate : 0.013745771957739223 
INFO:root:FL Epoch: 646 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665654
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416731
INFO:root:FL Epoch: 646 Norm Difference for worker 1056 is 0.730532
INFO:root:FL Epoch: 646 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 646 Training on worker :1824
INFO:root:FL Epoch: 646 Using Learning rate : 0.013745771957739223 
INFO:root:FL Epoch: 646 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616049
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590214
INFO:root:FL Epoch: 646 Norm Difference for worker 1824 is 0.762118
INFO:root:FL Epoch: 646 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 646 Training on worker :1566
INFO:root:FL Epoch: 646 Using Learning rate : 0.013745771957739223 
INFO:root:FL Epoch: 646 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622467
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252054
INFO:root:FL Epoch: 646 Norm Difference for worker 1566 is 0.63151
INFO:root:FL Epoch: 646 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 646 Training on worker :228
INFO:root:FL Epoch: 646 Using Learning rate : 0.013745771957739223 
INFO:root:FL Epoch: 646 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.426594
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.215727
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 646 Norm Difference for worker 228 is 0.639753
INFO:root:FL Epoch: 646 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 646 Training on worker :917
INFO:root:FL Epoch: 646 Using Learning rate : 0.013745771957739223 
INFO:root:FL Epoch: 646 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533717
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299313
INFO:root:FL Epoch: 646 Norm Difference for worker 917 is 0.776087
INFO:root:FL Epoch: 646 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 646 Training on worker :527
INFO:root:FL Epoch: 646 Using Learning rate : 0.013745771957739223 
INFO:root:FL Epoch: 646 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476836
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513623
INFO:root:FL Epoch: 646 Norm Difference for worker 527 is 0.778466
INFO:root:FL Epoch: 646 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 646 Training on worker :169
INFO:root:FL Epoch: 646 Using Learning rate : 0.013745771957739223 
INFO:root:FL Epoch: 646 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.730018
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.591373
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 646 Norm Difference for worker 169 is 0.731097
INFO:root:FL Epoch: 646 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 646 Training on worker :279
INFO:root:FL Epoch: 646 Using Learning rate : 0.013745771957739223 
INFO:root:FL Epoch: 646 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.462269
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.480019
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 646 Norm Difference for worker 279 is 0.699657
INFO:root:FL Epoch: 646 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 646 Training on worker :1402
INFO:root:FL Epoch: 646 Using Learning rate : 0.013745771957739223 
INFO:root:FL Epoch: 646 Normal Training
INFO:root:Worker: 1402 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719533
INFO:root:Worker: 1402 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230245
INFO:root:FL Epoch: 646 Norm Difference for worker 1402 is 0.71473
INFO:root:FL Epoch: 646 Done on worker:1402
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 646 Training on worker :1605
INFO:root:FL Epoch: 646 Using Learning rate : 0.013745771957739223 
INFO:root:FL Epoch: 646 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478899
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476878
INFO:root:FL Epoch: 646 Norm Difference for worker 1605 is 0.748472
INFO:root:FL Epoch: 646 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 228
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 646 Ends   ===================
INFO:root:Epoch:646 Global Model Test Loss:0.5479213630451876 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:646 Global Model Backdoor Test Loss:0.1438202237089475                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 647 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 647 Workers Selected : [4, 146, 1929, 1862, 226, 1490, 914, 1000, 1175, 116]
INFO:root:FL Epoch: 647 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004
 0.0998004 0.0998004 0.1002994]
INFO:root:FL Epoch: 647 Num points on workers: [201 201 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 647 Training on worker :4
INFO:root:FL Epoch: 647 Using Learning rate : 0.013718280413823745 
INFO:root:FL Epoch: 647 Normal Training
INFO:root:Worker: 4 Train Epoch: 0 [0/201 (0%)]	Loss: 0.616262
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 4 Train Epoch: 1 [0/201 (0%)]	Loss: 0.382119
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 647 Norm Difference for worker 4 is 0.78233
INFO:root:FL Epoch: 647 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 647 Training on worker :146
INFO:root:FL Epoch: 647 Using Learning rate : 0.013718280413823745 
INFO:root:FL Epoch: 647 Normal Training
INFO:root:Worker: 146 Train Epoch: 0 [0/201 (0%)]	Loss: 0.648334
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 146 Train Epoch: 1 [0/201 (0%)]	Loss: 0.665641
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 647 Norm Difference for worker 146 is 0.778802
INFO:root:FL Epoch: 647 Done on worker:146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 647 Training on worker :1929
INFO:root:FL Epoch: 647 Using Learning rate : 0.013718280413823745 
INFO:root:FL Epoch: 647 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374748
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420709
INFO:root:FL Epoch: 647 Norm Difference for worker 1929 is 0.756298
INFO:root:FL Epoch: 647 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 647 Training on worker :1862
INFO:root:FL Epoch: 647 Using Learning rate : 0.013718280413823745 
INFO:root:FL Epoch: 647 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464340
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506411
INFO:root:FL Epoch: 647 Norm Difference for worker 1862 is 0.808234
INFO:root:FL Epoch: 647 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 647 Training on worker :226
INFO:root:FL Epoch: 647 Using Learning rate : 0.013718280413823745 
INFO:root:FL Epoch: 647 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.659234
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.525157
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 647 Norm Difference for worker 226 is 0.759854
INFO:root:FL Epoch: 647 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 647 Training on worker :1490
INFO:root:FL Epoch: 647 Using Learning rate : 0.013718280413823745 
INFO:root:FL Epoch: 647 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399050
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430627
INFO:root:FL Epoch: 647 Norm Difference for worker 1490 is 0.659533
INFO:root:FL Epoch: 647 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 647 Training on worker :914
INFO:root:FL Epoch: 647 Using Learning rate : 0.013718280413823745 
INFO:root:FL Epoch: 647 Normal Training
INFO:root:Worker: 914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412399
INFO:root:Worker: 914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577273
INFO:root:FL Epoch: 647 Norm Difference for worker 914 is 0.791899
INFO:root:FL Epoch: 647 Done on worker:914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 647 Training on worker :1000
INFO:root:FL Epoch: 647 Using Learning rate : 0.013718280413823745 
INFO:root:FL Epoch: 647 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682602
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469383
INFO:root:FL Epoch: 647 Norm Difference for worker 1000 is 0.803079
INFO:root:FL Epoch: 647 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 647 Training on worker :1175
INFO:root:FL Epoch: 647 Using Learning rate : 0.013718280413823745 
INFO:root:FL Epoch: 647 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.885143
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641502
INFO:root:FL Epoch: 647 Norm Difference for worker 1175 is 0.720252
INFO:root:FL Epoch: 647 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 647 Training on worker :116
INFO:root:FL Epoch: 647 Using Learning rate : 0.013718280413823745 
INFO:root:FL Epoch: 647 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.763304
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.400810
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 647 Norm Difference for worker 116 is 0.771901
INFO:root:FL Epoch: 647 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1490
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 647 Ends   ===================
INFO:root:Epoch:647 Global Model Test Loss:0.5404855135609122 and Test Accuracy:75.0 
INFO:root:Epoch:647 Global Model Backdoor Test Loss:0.13018904998898506                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 648 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 648 Workers Selected : [949, 1443, 890, 852, 689, 1895, 1574, 607, 277, 950]
INFO:root:FL Epoch: 648 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 648 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 648 Training on worker :949
INFO:root:FL Epoch: 648 Using Learning rate : 0.013690843852996099 
INFO:root:FL Epoch: 648 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484143
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515509
INFO:root:FL Epoch: 648 Norm Difference for worker 949 is 0.805503
INFO:root:FL Epoch: 648 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 648 Training on worker :1443
INFO:root:FL Epoch: 648 Using Learning rate : 0.013690843852996099 
INFO:root:FL Epoch: 648 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755069
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602722
INFO:root:FL Epoch: 648 Norm Difference for worker 1443 is 0.759601
INFO:root:FL Epoch: 648 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 648 Training on worker :890
INFO:root:FL Epoch: 648 Using Learning rate : 0.013690843852996099 
INFO:root:FL Epoch: 648 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589883
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652120
INFO:root:FL Epoch: 648 Norm Difference for worker 890 is 0.745926
INFO:root:FL Epoch: 648 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 648 Training on worker :852
INFO:root:FL Epoch: 648 Using Learning rate : 0.013690843852996099 
INFO:root:FL Epoch: 648 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577979
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515822
INFO:root:FL Epoch: 648 Norm Difference for worker 852 is 0.68241
INFO:root:FL Epoch: 648 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 648 Training on worker :689
INFO:root:FL Epoch: 648 Using Learning rate : 0.013690843852996099 
INFO:root:FL Epoch: 648 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504161
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.911745
INFO:root:FL Epoch: 648 Norm Difference for worker 689 is 0.746655
INFO:root:FL Epoch: 648 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 648 Training on worker :1895
INFO:root:FL Epoch: 648 Using Learning rate : 0.013690843852996099 
INFO:root:FL Epoch: 648 Normal Training
INFO:root:Worker: 1895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751360
INFO:root:Worker: 1895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589634
INFO:root:FL Epoch: 648 Norm Difference for worker 1895 is 0.767726
INFO:root:FL Epoch: 648 Done on worker:1895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 648 Training on worker :1574
INFO:root:FL Epoch: 648 Using Learning rate : 0.013690843852996099 
INFO:root:FL Epoch: 648 Normal Training
INFO:root:Worker: 1574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734826
INFO:root:Worker: 1574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524611
INFO:root:FL Epoch: 648 Norm Difference for worker 1574 is 0.748394
INFO:root:FL Epoch: 648 Done on worker:1574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 648 Training on worker :607
INFO:root:FL Epoch: 648 Using Learning rate : 0.013690843852996099 
INFO:root:FL Epoch: 648 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582114
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212766
INFO:root:FL Epoch: 648 Norm Difference for worker 607 is 0.749563
INFO:root:FL Epoch: 648 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 648 Training on worker :277
INFO:root:FL Epoch: 648 Using Learning rate : 0.013690843852996099 
INFO:root:FL Epoch: 648 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.465791
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.389867
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 648 Norm Difference for worker 277 is 0.762828
INFO:root:FL Epoch: 648 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 648 Training on worker :950
INFO:root:FL Epoch: 648 Using Learning rate : 0.013690843852996099 
INFO:root:FL Epoch: 648 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494451
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319341
INFO:root:FL Epoch: 648 Norm Difference for worker 950 is 0.736543
INFO:root:FL Epoch: 648 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 852
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 648 Ends   ===================
INFO:root:Epoch:648 Global Model Test Loss:0.5307183949386373 and Test Accuracy:75.0 
INFO:root:Epoch:648 Global Model Backdoor Test Loss:0.13731959958871207                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 649 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 649 Workers Selected : [1522, 782, 758, 912, 1379, 1210, 1104, 1023, 1212, 1352]
INFO:root:FL Epoch: 649 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 649 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 649 Training on worker :1522
INFO:root:FL Epoch: 649 Using Learning rate : 0.013663462165290106 
INFO:root:FL Epoch: 649 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456759
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617915
INFO:root:FL Epoch: 649 Norm Difference for worker 1522 is 0.645757
INFO:root:FL Epoch: 649 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 649 Training on worker :782
INFO:root:FL Epoch: 649 Using Learning rate : 0.013663462165290106 
INFO:root:FL Epoch: 649 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562079
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.819920
INFO:root:FL Epoch: 649 Norm Difference for worker 782 is 0.722671
INFO:root:FL Epoch: 649 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 649 Training on worker :758
INFO:root:FL Epoch: 649 Using Learning rate : 0.013663462165290106 
INFO:root:FL Epoch: 649 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614504
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.767541
INFO:root:FL Epoch: 649 Norm Difference for worker 758 is 0.692466
INFO:root:FL Epoch: 649 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 649 Training on worker :912
INFO:root:FL Epoch: 649 Using Learning rate : 0.013663462165290106 
INFO:root:FL Epoch: 649 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442470
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536915
INFO:root:FL Epoch: 649 Norm Difference for worker 912 is 0.643006
INFO:root:FL Epoch: 649 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 649 Training on worker :1379
INFO:root:FL Epoch: 649 Using Learning rate : 0.013663462165290106 
INFO:root:FL Epoch: 649 Normal Training
INFO:root:Worker: 1379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.160919
INFO:root:Worker: 1379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633843
INFO:root:FL Epoch: 649 Norm Difference for worker 1379 is 0.607342
INFO:root:FL Epoch: 649 Done on worker:1379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 649 Training on worker :1210
INFO:root:FL Epoch: 649 Using Learning rate : 0.013663462165290106 
INFO:root:FL Epoch: 649 Normal Training
INFO:root:Worker: 1210 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498039
INFO:root:Worker: 1210 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528297
INFO:root:FL Epoch: 649 Norm Difference for worker 1210 is 0.687172
INFO:root:FL Epoch: 649 Done on worker:1210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 649 Training on worker :1104
INFO:root:FL Epoch: 649 Using Learning rate : 0.013663462165290106 
INFO:root:FL Epoch: 649 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676055
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.738848
INFO:root:FL Epoch: 649 Norm Difference for worker 1104 is 0.696212
INFO:root:FL Epoch: 649 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 649 Training on worker :1023
INFO:root:FL Epoch: 649 Using Learning rate : 0.013663462165290106 
INFO:root:FL Epoch: 649 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495096
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285407
INFO:root:FL Epoch: 649 Norm Difference for worker 1023 is 0.551808
INFO:root:FL Epoch: 649 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 649 Training on worker :1212
INFO:root:FL Epoch: 649 Using Learning rate : 0.013663462165290106 
INFO:root:FL Epoch: 649 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447316
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370324
INFO:root:FL Epoch: 649 Norm Difference for worker 1212 is 0.655101
INFO:root:FL Epoch: 649 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 649 Training on worker :1352
INFO:root:FL Epoch: 649 Using Learning rate : 0.013663462165290106 
INFO:root:FL Epoch: 649 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561020
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440281
INFO:root:FL Epoch: 649 Norm Difference for worker 1352 is 0.688977
INFO:root:FL Epoch: 649 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1023
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 649 Ends   ===================
INFO:root:Epoch:649 Global Model Test Loss:0.5172760837218341 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:649 Global Model Backdoor Test Loss:0.11386242881417274                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 650 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 650 Workers Selected : [389, 411, 375, 1747, 319, 522, 1311, 1796, 76, 1590]
INFO:root:FL Epoch: 650 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 650 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 650 Training on worker :389
INFO:root:FL Epoch: 650 Using Learning rate : 0.013636135240959524 
INFO:root:FL Epoch: 650 Normal Training
INFO:root:Worker: 389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636910
INFO:root:Worker: 389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231159
INFO:root:FL Epoch: 650 Norm Difference for worker 389 is 0.68825
INFO:root:FL Epoch: 650 Done on worker:389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 650 Training on worker :411
INFO:root:FL Epoch: 650 Using Learning rate : 0.013636135240959524 
INFO:root:FL Epoch: 650 Normal Training
INFO:root:Worker: 411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578071
INFO:root:Worker: 411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336362
INFO:root:FL Epoch: 650 Norm Difference for worker 411 is 0.772938
INFO:root:FL Epoch: 650 Done on worker:411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 650 Training on worker :375
INFO:root:FL Epoch: 650 Using Learning rate : 0.013636135240959524 
INFO:root:FL Epoch: 650 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328933
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290792
INFO:root:FL Epoch: 650 Norm Difference for worker 375 is 0.747057
INFO:root:FL Epoch: 650 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 650 Training on worker :1747
INFO:root:FL Epoch: 650 Using Learning rate : 0.013636135240959524 
INFO:root:FL Epoch: 650 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369787
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544096
INFO:root:FL Epoch: 650 Norm Difference for worker 1747 is 0.734704
INFO:root:FL Epoch: 650 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 650 Training on worker :319
INFO:root:FL Epoch: 650 Using Learning rate : 0.013636135240959524 
INFO:root:FL Epoch: 650 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503464
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.355680
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 650 Norm Difference for worker 319 is 0.730395
INFO:root:FL Epoch: 650 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 650 Training on worker :522
INFO:root:FL Epoch: 650 Using Learning rate : 0.013636135240959524 
INFO:root:FL Epoch: 650 Normal Training
INFO:root:Worker: 522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579823
INFO:root:Worker: 522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201443
INFO:root:FL Epoch: 650 Norm Difference for worker 522 is 0.662888
INFO:root:FL Epoch: 650 Done on worker:522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 650 Training on worker :1311
INFO:root:FL Epoch: 650 Using Learning rate : 0.013636135240959524 
INFO:root:FL Epoch: 650 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488963
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564821
INFO:root:FL Epoch: 650 Norm Difference for worker 1311 is 0.801221
INFO:root:FL Epoch: 650 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 650 Training on worker :1796
INFO:root:FL Epoch: 650 Using Learning rate : 0.013636135240959524 
INFO:root:FL Epoch: 650 Normal Training
INFO:root:Worker: 1796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734344
INFO:root:Worker: 1796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410514
INFO:root:FL Epoch: 650 Norm Difference for worker 1796 is 0.754144
INFO:root:FL Epoch: 650 Done on worker:1796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 650 Training on worker :76
INFO:root:FL Epoch: 650 Using Learning rate : 0.013636135240959524 
INFO:root:FL Epoch: 650 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.534071
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446398
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 650 Norm Difference for worker 76 is 0.744156
INFO:root:FL Epoch: 650 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 650 Training on worker :1590
INFO:root:FL Epoch: 650 Using Learning rate : 0.013636135240959524 
INFO:root:FL Epoch: 650 Normal Training
INFO:root:Worker: 1590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714054
INFO:root:Worker: 1590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374234
INFO:root:FL Epoch: 650 Norm Difference for worker 1590 is 0.720491
INFO:root:FL Epoch: 650 Done on worker:1590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 522
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 650 Ends   ===================
INFO:root:Epoch:650 Global Model Test Loss:0.5064857286565444 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:650 Global Model Backdoor Test Loss:0.12382140755653381                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 651 Begins ===================
INFO:root:FL Epoch: 651 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 651 Workers Selected : [0, 1, 2, 1108, 1097, 1433, 1247, 1404, 1313, 684]
INFO:root:FL Epoch: 651 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 651 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 651 Training on worker :0
INFO:root:FL Epoch: 651 Using Learning rate : 0.0027217725940955214 
INFO:root:FL Epoch: 651 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.087023
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.091257
INFO:root:FL Epoch: 651 Worker: 0 Backdoor Test Loss: 0.10747011875112851 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 651 Worker: 0 Backdoor Train Loss: 0.10501581504940986 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 651 Norm Difference for worker 0 is 0.072016
INFO:root:FL Epoch: 651 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 651 Training on worker :1
INFO:root:FL Epoch: 651 Using Learning rate : 0.0027217725940955214 
INFO:root:FL Epoch: 651 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.220549
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220427
INFO:root:FL Epoch: 651 Worker: 1 Backdoor Test Loss: 0.1081013356645902 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 651 Worker: 1 Backdoor Train Loss: 0.10505780130624771 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 651 Norm Difference for worker 1 is 0.073774
INFO:root:FL Epoch: 651 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 651 Training on worker :2
INFO:root:FL Epoch: 651 Using Learning rate : 0.0027217725940955214 
INFO:root:FL Epoch: 651 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.195338
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.079427
INFO:root:FL Epoch: 651 Worker: 2 Backdoor Test Loss: 0.1069782202442487 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 651 Worker: 2 Backdoor Train Loss: 0.10470206141471863 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 651 Norm Difference for worker 2 is 0.073404
INFO:root:FL Epoch: 651 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 651 Training on worker :1108
INFO:root:FL Epoch: 651 Using Learning rate : 0.013608862970477607 
INFO:root:FL Epoch: 651 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362478
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.770582
INFO:root:FL Epoch: 651 Norm Difference for worker 1108 is 0.73038
INFO:root:FL Epoch: 651 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 651 Training on worker :1097
INFO:root:FL Epoch: 651 Using Learning rate : 0.013608862970477607 
INFO:root:FL Epoch: 651 Normal Training
INFO:root:Worker: 1097 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665360
INFO:root:Worker: 1097 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665284
INFO:root:FL Epoch: 651 Norm Difference for worker 1097 is 0.714829
INFO:root:FL Epoch: 651 Done on worker:1097
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 651 Training on worker :1433
INFO:root:FL Epoch: 651 Using Learning rate : 0.013608862970477607 
INFO:root:FL Epoch: 651 Normal Training
INFO:root:Worker: 1433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.875409
INFO:root:Worker: 1433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453471
INFO:root:FL Epoch: 651 Norm Difference for worker 1433 is 0.629875
INFO:root:FL Epoch: 651 Done on worker:1433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 651 Training on worker :1247
INFO:root:FL Epoch: 651 Using Learning rate : 0.013608862970477607 
INFO:root:FL Epoch: 651 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339675
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543570
INFO:root:FL Epoch: 651 Norm Difference for worker 1247 is 0.713551
INFO:root:FL Epoch: 651 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 651 Training on worker :1404
INFO:root:FL Epoch: 651 Using Learning rate : 0.013608862970477607 
INFO:root:FL Epoch: 651 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488404
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416135
INFO:root:FL Epoch: 651 Norm Difference for worker 1404 is 0.610024
INFO:root:FL Epoch: 651 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 651 Training on worker :1313
INFO:root:FL Epoch: 651 Using Learning rate : 0.013608862970477607 
INFO:root:FL Epoch: 651 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.195653
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.134946
INFO:root:FL Epoch: 651 Norm Difference for worker 1313 is 0.456163
INFO:root:FL Epoch: 651 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 651 Training on worker :684
INFO:root:FL Epoch: 651 Using Learning rate : 0.013608862970477607 
INFO:root:FL Epoch: 651 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391771
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511421
INFO:root:FL Epoch: 651 Norm Difference for worker 684 is 0.625472
INFO:root:FL Epoch: 651 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 651 Ends   ===================
INFO:root:Epoch:651 Global Model Test Loss:0.507809472434661 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:651 Global Model Backdoor Test Loss:0.10747011875112851                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 652 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 652 Workers Selected : [1459, 1133, 1333, 1274, 6, 1294, 853, 1204, 312, 111]
INFO:root:FL Epoch: 652 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 652 Num points on workers: [200 200 200 200 201 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 652 Training on worker :1459
INFO:root:FL Epoch: 652 Using Learning rate : 0.013581645244536651 
INFO:root:FL Epoch: 652 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.825976
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551151
INFO:root:FL Epoch: 652 Norm Difference for worker 1459 is 0.814517
INFO:root:FL Epoch: 652 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 652 Training on worker :1133
INFO:root:FL Epoch: 652 Using Learning rate : 0.013581645244536651 
INFO:root:FL Epoch: 652 Normal Training
INFO:root:Worker: 1133 Train Epoch: 0 [0/200 (0%)]	Loss: 0.885129
INFO:root:Worker: 1133 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471061
INFO:root:FL Epoch: 652 Norm Difference for worker 1133 is 0.713274
INFO:root:FL Epoch: 652 Done on worker:1133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 652 Training on worker :1333
INFO:root:FL Epoch: 652 Using Learning rate : 0.013581645244536651 
INFO:root:FL Epoch: 652 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666961
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414112
INFO:root:FL Epoch: 652 Norm Difference for worker 1333 is 0.763144
INFO:root:FL Epoch: 652 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 652 Training on worker :1274
INFO:root:FL Epoch: 652 Using Learning rate : 0.013581645244536651 
INFO:root:FL Epoch: 652 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422628
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492330
INFO:root:FL Epoch: 652 Norm Difference for worker 1274 is 0.776756
INFO:root:FL Epoch: 652 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 652 Training on worker :6
INFO:root:FL Epoch: 652 Using Learning rate : 0.013581645244536651 
INFO:root:FL Epoch: 652 Normal Training
INFO:root:Worker: 6 Train Epoch: 0 [0/201 (0%)]	Loss: 0.781253
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 6 Train Epoch: 1 [0/201 (0%)]	Loss: 0.224195
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 652 Norm Difference for worker 6 is 0.621771
INFO:root:FL Epoch: 652 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 652 Training on worker :1294
INFO:root:FL Epoch: 652 Using Learning rate : 0.013581645244536651 
INFO:root:FL Epoch: 652 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378416
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452389
INFO:root:FL Epoch: 652 Norm Difference for worker 1294 is 0.75069
INFO:root:FL Epoch: 652 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 652 Training on worker :853
INFO:root:FL Epoch: 652 Using Learning rate : 0.013581645244536651 
INFO:root:FL Epoch: 652 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709656
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380196
INFO:root:FL Epoch: 652 Norm Difference for worker 853 is 0.73917
INFO:root:FL Epoch: 652 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 652 Training on worker :1204
INFO:root:FL Epoch: 652 Using Learning rate : 0.013581645244536651 
INFO:root:FL Epoch: 652 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320845
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.225158
INFO:root:FL Epoch: 652 Norm Difference for worker 1204 is 0.697335
INFO:root:FL Epoch: 652 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 652 Training on worker :312
INFO:root:FL Epoch: 652 Using Learning rate : 0.013581645244536651 
INFO:root:FL Epoch: 652 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.648766
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.472370
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 652 Norm Difference for worker 312 is 0.726323
INFO:root:FL Epoch: 652 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 652 Training on worker :111
INFO:root:FL Epoch: 652 Using Learning rate : 0.013581645244536651 
INFO:root:FL Epoch: 652 Normal Training
INFO:root:Worker: 111 Train Epoch: 0 [0/201 (0%)]	Loss: 0.451018
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 111 Train Epoch: 1 [0/201 (0%)]	Loss: 0.630466
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 652 Norm Difference for worker 111 is 0.759791
INFO:root:FL Epoch: 652 Done on worker:111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 6
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 652 Ends   ===================
INFO:root:Epoch:652 Global Model Test Loss:0.5101360170280232 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:652 Global Model Backdoor Test Loss:0.08891961288948853                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 653 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 653 Workers Selected : [1448, 287, 1140, 793, 1896, 421, 213, 1873, 1936, 764]
INFO:root:FL Epoch: 653 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 653 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 653 Training on worker :1448
INFO:root:FL Epoch: 653 Using Learning rate : 0.013554481954047579 
INFO:root:FL Epoch: 653 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330833
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332374
INFO:root:FL Epoch: 653 Norm Difference for worker 1448 is 0.590795
INFO:root:FL Epoch: 653 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 653 Training on worker :287
INFO:root:FL Epoch: 653 Using Learning rate : 0.013554481954047579 
INFO:root:FL Epoch: 653 Normal Training
INFO:root:Worker: 287 Train Epoch: 0 [0/201 (0%)]	Loss: 0.851797
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 287 Train Epoch: 1 [0/201 (0%)]	Loss: 0.548476
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 653 Norm Difference for worker 287 is 0.737067
INFO:root:FL Epoch: 653 Done on worker:287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 653 Training on worker :1140
INFO:root:FL Epoch: 653 Using Learning rate : 0.013554481954047579 
INFO:root:FL Epoch: 653 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456909
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.742409
INFO:root:FL Epoch: 653 Norm Difference for worker 1140 is 0.789688
INFO:root:FL Epoch: 653 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 653 Training on worker :793
INFO:root:FL Epoch: 653 Using Learning rate : 0.013554481954047579 
INFO:root:FL Epoch: 653 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476977
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.178640
INFO:root:FL Epoch: 653 Norm Difference for worker 793 is 0.695997
INFO:root:FL Epoch: 653 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 653 Training on worker :1896
INFO:root:FL Epoch: 653 Using Learning rate : 0.013554481954047579 
INFO:root:FL Epoch: 653 Normal Training
INFO:root:Worker: 1896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505146
INFO:root:Worker: 1896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619522
INFO:root:FL Epoch: 653 Norm Difference for worker 1896 is 0.728507
INFO:root:FL Epoch: 653 Done on worker:1896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 653 Training on worker :421
INFO:root:FL Epoch: 653 Using Learning rate : 0.013554481954047579 
INFO:root:FL Epoch: 653 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 1.080240
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409325
INFO:root:FL Epoch: 653 Norm Difference for worker 421 is 0.781686
INFO:root:FL Epoch: 653 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 653 Training on worker :213
INFO:root:FL Epoch: 653 Using Learning rate : 0.013554481954047579 
INFO:root:FL Epoch: 653 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.862307
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.336171
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 653 Norm Difference for worker 213 is 0.76615
INFO:root:FL Epoch: 653 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 653 Training on worker :1873
INFO:root:FL Epoch: 653 Using Learning rate : 0.013554481954047579 
INFO:root:FL Epoch: 653 Normal Training
INFO:root:Worker: 1873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553322
INFO:root:Worker: 1873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309402
INFO:root:FL Epoch: 653 Norm Difference for worker 1873 is 0.762744
INFO:root:FL Epoch: 653 Done on worker:1873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 653 Training on worker :1936
INFO:root:FL Epoch: 653 Using Learning rate : 0.013554481954047579 
INFO:root:FL Epoch: 653 Normal Training
INFO:root:Worker: 1936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.271241
INFO:root:Worker: 1936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482025
INFO:root:FL Epoch: 653 Norm Difference for worker 1936 is 0.848374
INFO:root:FL Epoch: 653 Done on worker:1936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 653 Training on worker :764
INFO:root:FL Epoch: 653 Using Learning rate : 0.013554481954047579 
INFO:root:FL Epoch: 653 Normal Training
INFO:root:Worker: 764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699864
INFO:root:Worker: 764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314640
INFO:root:FL Epoch: 653 Norm Difference for worker 764 is 0.721406
INFO:root:FL Epoch: 653 Done on worker:764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1448
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 653 Ends   ===================
INFO:root:Epoch:653 Global Model Test Loss:0.5102093658026527 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:653 Global Model Backdoor Test Loss:0.11744082346558571                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 654 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 654 Workers Selected : [20, 53, 1915, 859, 1637, 1037, 375, 528, 1448, 1070]
INFO:root:FL Epoch: 654 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 654 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 654 Training on worker :20
INFO:root:FL Epoch: 654 Using Learning rate : 0.013527372990139484 
INFO:root:FL Epoch: 654 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.489325
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.480417
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 654 Norm Difference for worker 20 is 0.622309
INFO:root:FL Epoch: 654 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 654 Training on worker :53
INFO:root:FL Epoch: 654 Using Learning rate : 0.013527372990139484 
INFO:root:FL Epoch: 654 Normal Training
INFO:root:Worker: 53 Train Epoch: 0 [0/201 (0%)]	Loss: 0.530935
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 53 Train Epoch: 1 [0/201 (0%)]	Loss: 0.504934
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 654 Norm Difference for worker 53 is 0.648554
INFO:root:FL Epoch: 654 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 654 Training on worker :1915
INFO:root:FL Epoch: 654 Using Learning rate : 0.013527372990139484 
INFO:root:FL Epoch: 654 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671722
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.721257
INFO:root:FL Epoch: 654 Norm Difference for worker 1915 is 0.708432
INFO:root:FL Epoch: 654 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 654 Training on worker :859
INFO:root:FL Epoch: 654 Using Learning rate : 0.013527372990139484 
INFO:root:FL Epoch: 654 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481852
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340588
INFO:root:FL Epoch: 654 Norm Difference for worker 859 is 0.64439
INFO:root:FL Epoch: 654 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 654 Training on worker :1637
INFO:root:FL Epoch: 654 Using Learning rate : 0.013527372990139484 
INFO:root:FL Epoch: 654 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537060
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342020
INFO:root:FL Epoch: 654 Norm Difference for worker 1637 is 0.667651
INFO:root:FL Epoch: 654 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 654 Training on worker :1037
INFO:root:FL Epoch: 654 Using Learning rate : 0.013527372990139484 
INFO:root:FL Epoch: 654 Normal Training
INFO:root:Worker: 1037 Train Epoch: 0 [0/200 (0%)]	Loss: 0.940677
INFO:root:Worker: 1037 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682810
INFO:root:FL Epoch: 654 Norm Difference for worker 1037 is 0.700129
INFO:root:FL Epoch: 654 Done on worker:1037
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 654 Training on worker :375
INFO:root:FL Epoch: 654 Using Learning rate : 0.013527372990139484 
INFO:root:FL Epoch: 654 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681689
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400136
INFO:root:FL Epoch: 654 Norm Difference for worker 375 is 0.692874
INFO:root:FL Epoch: 654 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 654 Training on worker :528
INFO:root:FL Epoch: 654 Using Learning rate : 0.013527372990139484 
INFO:root:FL Epoch: 654 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447642
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438621
INFO:root:FL Epoch: 654 Norm Difference for worker 528 is 0.680363
INFO:root:FL Epoch: 654 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 654 Training on worker :1448
INFO:root:FL Epoch: 654 Using Learning rate : 0.013527372990139484 
INFO:root:FL Epoch: 654 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344732
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341103
INFO:root:FL Epoch: 654 Norm Difference for worker 1448 is 0.460413
INFO:root:FL Epoch: 654 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 654 Training on worker :1070
INFO:root:FL Epoch: 654 Using Learning rate : 0.013527372990139484 
INFO:root:FL Epoch: 654 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405012
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380032
INFO:root:FL Epoch: 654 Norm Difference for worker 1070 is 0.697732
INFO:root:FL Epoch: 654 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1448
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 654 Ends   ===================
INFO:root:Epoch:654 Global Model Test Loss:0.5204979689682231 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:654 Global Model Backdoor Test Loss:0.10198380177219708                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 655 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 655 Workers Selected : [248, 1827, 377, 1118, 1287, 306, 1415, 336, 1237, 1124]
INFO:root:FL Epoch: 655 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 655 Num points on workers: [201 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 655 Training on worker :248
INFO:root:FL Epoch: 655 Using Learning rate : 0.013500318244159204 
INFO:root:FL Epoch: 655 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.471656
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.334363
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 655 Norm Difference for worker 248 is 0.696439
INFO:root:FL Epoch: 655 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 655 Training on worker :1827
INFO:root:FL Epoch: 655 Using Learning rate : 0.013500318244159204 
INFO:root:FL Epoch: 655 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762446
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403777
INFO:root:FL Epoch: 655 Norm Difference for worker 1827 is 0.677155
INFO:root:FL Epoch: 655 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 655 Training on worker :377
INFO:root:FL Epoch: 655 Using Learning rate : 0.013500318244159204 
INFO:root:FL Epoch: 655 Normal Training
INFO:root:Worker: 377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.895321
INFO:root:Worker: 377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493893
INFO:root:FL Epoch: 655 Norm Difference for worker 377 is 0.771262
INFO:root:FL Epoch: 655 Done on worker:377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 655 Training on worker :1118
INFO:root:FL Epoch: 655 Using Learning rate : 0.013500318244159204 
INFO:root:FL Epoch: 655 Normal Training
INFO:root:Worker: 1118 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730304
INFO:root:Worker: 1118 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413572
INFO:root:FL Epoch: 655 Norm Difference for worker 1118 is 0.744498
INFO:root:FL Epoch: 655 Done on worker:1118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 655 Training on worker :1287
INFO:root:FL Epoch: 655 Using Learning rate : 0.013500318244159204 
INFO:root:FL Epoch: 655 Normal Training
INFO:root:Worker: 1287 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637630
INFO:root:Worker: 1287 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492057
INFO:root:FL Epoch: 655 Norm Difference for worker 1287 is 0.744089
INFO:root:FL Epoch: 655 Done on worker:1287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 655 Training on worker :306
INFO:root:FL Epoch: 655 Using Learning rate : 0.013500318244159204 
INFO:root:FL Epoch: 655 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.290988
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.536554
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 655 Norm Difference for worker 306 is 0.705792
INFO:root:FL Epoch: 655 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 655 Training on worker :1415
INFO:root:FL Epoch: 655 Using Learning rate : 0.013500318244159204 
INFO:root:FL Epoch: 655 Normal Training
INFO:root:Worker: 1415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.904618
INFO:root:Worker: 1415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.816067
INFO:root:FL Epoch: 655 Norm Difference for worker 1415 is 0.806377
INFO:root:FL Epoch: 655 Done on worker:1415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 655 Training on worker :336
INFO:root:FL Epoch: 655 Using Learning rate : 0.013500318244159204 
INFO:root:FL Epoch: 655 Normal Training
INFO:root:Worker: 336 Train Epoch: 0 [0/201 (0%)]	Loss: 0.734134
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 336 Train Epoch: 1 [0/201 (0%)]	Loss: 0.343805
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 655 Norm Difference for worker 336 is 0.702746
INFO:root:FL Epoch: 655 Done on worker:336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 655 Training on worker :1237
INFO:root:FL Epoch: 655 Using Learning rate : 0.013500318244159204 
INFO:root:FL Epoch: 655 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559435
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575578
INFO:root:FL Epoch: 655 Norm Difference for worker 1237 is 0.848889
INFO:root:FL Epoch: 655 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 655 Training on worker :1124
INFO:root:FL Epoch: 655 Using Learning rate : 0.013500318244159204 
INFO:root:FL Epoch: 655 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719514
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437491
INFO:root:FL Epoch: 655 Norm Difference for worker 1124 is 0.676422
INFO:root:FL Epoch: 655 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1124
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 655 Ends   ===================
INFO:root:Epoch:655 Global Model Test Loss:0.5278648821746602 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:655 Global Model Backdoor Test Loss:0.14710714543859163                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 656 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 656 Workers Selected : [1208, 847, 1418, 97, 558, 674, 1098, 1624, 983, 1079]
INFO:root:FL Epoch: 656 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 656 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 656 Training on worker :1208
INFO:root:FL Epoch: 656 Using Learning rate : 0.013473317607670884 
INFO:root:FL Epoch: 656 Normal Training
INFO:root:Worker: 1208 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447635
INFO:root:Worker: 1208 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402415
INFO:root:FL Epoch: 656 Norm Difference for worker 1208 is 0.595958
INFO:root:FL Epoch: 656 Done on worker:1208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 656 Training on worker :847
INFO:root:FL Epoch: 656 Using Learning rate : 0.013473317607670884 
INFO:root:FL Epoch: 656 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569336
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372338
INFO:root:FL Epoch: 656 Norm Difference for worker 847 is 0.638192
INFO:root:FL Epoch: 656 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 656 Training on worker :1418
INFO:root:FL Epoch: 656 Using Learning rate : 0.013473317607670884 
INFO:root:FL Epoch: 656 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441576
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423789
INFO:root:FL Epoch: 656 Norm Difference for worker 1418 is 0.694002
INFO:root:FL Epoch: 656 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 656 Training on worker :97
INFO:root:FL Epoch: 656 Using Learning rate : 0.013473317607670884 
INFO:root:FL Epoch: 656 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.391165
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.567761
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 656 Norm Difference for worker 97 is 0.609466
INFO:root:FL Epoch: 656 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 656 Training on worker :558
INFO:root:FL Epoch: 656 Using Learning rate : 0.013473317607670884 
INFO:root:FL Epoch: 656 Normal Training
INFO:root:Worker: 558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451003
INFO:root:Worker: 558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548265
INFO:root:FL Epoch: 656 Norm Difference for worker 558 is 0.684301
INFO:root:FL Epoch: 656 Done on worker:558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 656 Training on worker :674
INFO:root:FL Epoch: 656 Using Learning rate : 0.013473317607670884 
INFO:root:FL Epoch: 656 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560341
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496397
INFO:root:FL Epoch: 656 Norm Difference for worker 674 is 0.620251
INFO:root:FL Epoch: 656 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 656 Training on worker :1098
INFO:root:FL Epoch: 656 Using Learning rate : 0.013473317607670884 
INFO:root:FL Epoch: 656 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539544
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222567
INFO:root:FL Epoch: 656 Norm Difference for worker 1098 is 0.56368
INFO:root:FL Epoch: 656 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 656 Training on worker :1624
INFO:root:FL Epoch: 656 Using Learning rate : 0.013473317607670884 
INFO:root:FL Epoch: 656 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560143
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383143
INFO:root:FL Epoch: 656 Norm Difference for worker 1624 is 0.670454
INFO:root:FL Epoch: 656 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 656 Training on worker :983
INFO:root:FL Epoch: 656 Using Learning rate : 0.013473317607670884 
INFO:root:FL Epoch: 656 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.862018
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.718146
INFO:root:FL Epoch: 656 Norm Difference for worker 983 is 0.700738
INFO:root:FL Epoch: 656 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 656 Training on worker :1079
INFO:root:FL Epoch: 656 Using Learning rate : 0.013473317607670884 
INFO:root:FL Epoch: 656 Normal Training
INFO:root:Worker: 1079 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437675
INFO:root:Worker: 1079 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665949
INFO:root:FL Epoch: 656 Norm Difference for worker 1079 is 0.665104
INFO:root:FL Epoch: 656 Done on worker:1079
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1098
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 656 Ends   ===================
INFO:root:Epoch:656 Global Model Test Loss:0.5215583128087661 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:656 Global Model Backdoor Test Loss:0.11485268672307332                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 657 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 657 Workers Selected : [301, 892, 1357, 946, 1812, 217, 198, 160, 97, 78]
INFO:root:FL Epoch: 657 Fraction of points on each worker in this round: [0.1001994 0.0997009 0.0997009 0.0997009 0.0997009 0.1001994 0.1001994
 0.1001994 0.1001994 0.1001994]
INFO:root:FL Epoch: 657 Num points on workers: [201 200 200 200 200 201 201 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 657 Training on worker :301
INFO:root:FL Epoch: 657 Using Learning rate : 0.013446370972455544 
INFO:root:FL Epoch: 657 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.798087
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.399271
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 657 Norm Difference for worker 301 is 0.652021
INFO:root:FL Epoch: 657 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 657 Training on worker :892
INFO:root:FL Epoch: 657 Using Learning rate : 0.013446370972455544 
INFO:root:FL Epoch: 657 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425995
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523619
INFO:root:FL Epoch: 657 Norm Difference for worker 892 is 0.619616
INFO:root:FL Epoch: 657 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 657 Training on worker :1357
INFO:root:FL Epoch: 657 Using Learning rate : 0.013446370972455544 
INFO:root:FL Epoch: 657 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.255116
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651816
INFO:root:FL Epoch: 657 Norm Difference for worker 1357 is 0.706488
INFO:root:FL Epoch: 657 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 657 Training on worker :946
INFO:root:FL Epoch: 657 Using Learning rate : 0.013446370972455544 
INFO:root:FL Epoch: 657 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623514
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430790
INFO:root:FL Epoch: 657 Norm Difference for worker 946 is 0.702061
INFO:root:FL Epoch: 657 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 657 Training on worker :1812
INFO:root:FL Epoch: 657 Using Learning rate : 0.013446370972455544 
INFO:root:FL Epoch: 657 Normal Training
INFO:root:Worker: 1812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337739
INFO:root:Worker: 1812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617396
INFO:root:FL Epoch: 657 Norm Difference for worker 1812 is 0.661313
INFO:root:FL Epoch: 657 Done on worker:1812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 657 Training on worker :217
INFO:root:FL Epoch: 657 Using Learning rate : 0.013446370972455544 
INFO:root:FL Epoch: 657 Normal Training
INFO:root:Worker: 217 Train Epoch: 0 [0/201 (0%)]	Loss: 0.798153
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 217 Train Epoch: 1 [0/201 (0%)]	Loss: 0.658542
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 657 Norm Difference for worker 217 is 0.60512
INFO:root:FL Epoch: 657 Done on worker:217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 657 Training on worker :198
INFO:root:FL Epoch: 657 Using Learning rate : 0.013446370972455544 
INFO:root:FL Epoch: 657 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.519281
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.526933
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 657 Norm Difference for worker 198 is 0.650244
INFO:root:FL Epoch: 657 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 657 Training on worker :160
INFO:root:FL Epoch: 657 Using Learning rate : 0.013446370972455544 
INFO:root:FL Epoch: 657 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.471505
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.239046
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 657 Norm Difference for worker 160 is 0.652123
INFO:root:FL Epoch: 657 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 657 Training on worker :97
INFO:root:FL Epoch: 657 Using Learning rate : 0.013446370972455544 
INFO:root:FL Epoch: 657 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.758686
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.391584
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 657 Norm Difference for worker 97 is 0.599447
INFO:root:FL Epoch: 657 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 657 Training on worker :78
INFO:root:FL Epoch: 657 Using Learning rate : 0.013446370972455544 
INFO:root:FL Epoch: 657 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.300639
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.202796
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 657 Norm Difference for worker 78 is 0.495113
INFO:root:FL Epoch: 657 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 78
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 657 Ends   ===================
INFO:root:Epoch:657 Global Model Test Loss:0.5334658009164474 and Test Accuracy:75.0 
INFO:root:Epoch:657 Global Model Backdoor Test Loss:0.11407844846447308                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 658 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 658 Workers Selected : [993, 92, 497, 26, 364, 1508, 1296, 1117, 1009, 867]
INFO:root:FL Epoch: 658 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 658 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 658 Training on worker :993
INFO:root:FL Epoch: 658 Using Learning rate : 0.013419478230510632 
INFO:root:FL Epoch: 658 Normal Training
INFO:root:Worker: 993 Train Epoch: 0 [0/200 (0%)]	Loss: 0.200889
INFO:root:Worker: 993 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409208
INFO:root:FL Epoch: 658 Norm Difference for worker 993 is 0.784932
INFO:root:FL Epoch: 658 Done on worker:993
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 658 Training on worker :92
INFO:root:FL Epoch: 658 Using Learning rate : 0.013419478230510632 
INFO:root:FL Epoch: 658 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.433819
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.373158
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 658 Norm Difference for worker 92 is 0.682736
INFO:root:FL Epoch: 658 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 658 Training on worker :497
INFO:root:FL Epoch: 658 Using Learning rate : 0.013419478230510632 
INFO:root:FL Epoch: 658 Normal Training
INFO:root:Worker: 497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368695
INFO:root:Worker: 497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444201
INFO:root:FL Epoch: 658 Norm Difference for worker 497 is 0.655809
INFO:root:FL Epoch: 658 Done on worker:497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 658 Training on worker :26
INFO:root:FL Epoch: 658 Using Learning rate : 0.013419478230510632 
INFO:root:FL Epoch: 658 Normal Training
INFO:root:Worker: 26 Train Epoch: 0 [0/201 (0%)]	Loss: 0.612096
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 26 Train Epoch: 1 [0/201 (0%)]	Loss: 0.314006
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 658 Norm Difference for worker 26 is 0.664258
INFO:root:FL Epoch: 658 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 658 Training on worker :364
INFO:root:FL Epoch: 658 Using Learning rate : 0.013419478230510632 
INFO:root:FL Epoch: 658 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309732
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.167159
INFO:root:FL Epoch: 658 Norm Difference for worker 364 is 0.587613
INFO:root:FL Epoch: 658 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 658 Training on worker :1508
INFO:root:FL Epoch: 658 Using Learning rate : 0.013419478230510632 
INFO:root:FL Epoch: 658 Normal Training
INFO:root:Worker: 1508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599654
INFO:root:Worker: 1508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393866
INFO:root:FL Epoch: 658 Norm Difference for worker 1508 is 0.670335
INFO:root:FL Epoch: 658 Done on worker:1508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 658 Training on worker :1296
INFO:root:FL Epoch: 658 Using Learning rate : 0.013419478230510632 
INFO:root:FL Epoch: 658 Normal Training
INFO:root:Worker: 1296 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671851
INFO:root:Worker: 1296 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388781
INFO:root:FL Epoch: 658 Norm Difference for worker 1296 is 0.698934
INFO:root:FL Epoch: 658 Done on worker:1296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 658 Training on worker :1117
INFO:root:FL Epoch: 658 Using Learning rate : 0.013419478230510632 
INFO:root:FL Epoch: 658 Normal Training
INFO:root:Worker: 1117 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704875
INFO:root:Worker: 1117 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401323
INFO:root:FL Epoch: 658 Norm Difference for worker 1117 is 0.63917
INFO:root:FL Epoch: 658 Done on worker:1117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 658 Training on worker :1009
INFO:root:FL Epoch: 658 Using Learning rate : 0.013419478230510632 
INFO:root:FL Epoch: 658 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373318
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469853
INFO:root:FL Epoch: 658 Norm Difference for worker 1009 is 0.735678
INFO:root:FL Epoch: 658 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 658 Training on worker :867
INFO:root:FL Epoch: 658 Using Learning rate : 0.013419478230510632 
INFO:root:FL Epoch: 658 Normal Training
INFO:root:Worker: 867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381572
INFO:root:Worker: 867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549511
INFO:root:FL Epoch: 658 Norm Difference for worker 867 is 0.735532
INFO:root:FL Epoch: 658 Done on worker:867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 364
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 658 Ends   ===================
INFO:root:Epoch:658 Global Model Test Loss:0.5234477730358348 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:658 Global Model Backdoor Test Loss:0.07455650654931863                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 659 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 659 Workers Selected : [1706, 1346, 133, 699, 374, 827, 367, 1408, 741, 952]
INFO:root:FL Epoch: 659 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 659 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 659 Training on worker :1706
INFO:root:FL Epoch: 659 Using Learning rate : 0.013392639274049612 
INFO:root:FL Epoch: 659 Normal Training
INFO:root:Worker: 1706 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418281
INFO:root:Worker: 1706 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596770
INFO:root:FL Epoch: 659 Norm Difference for worker 1706 is 0.769363
INFO:root:FL Epoch: 659 Done on worker:1706
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 659 Training on worker :1346
INFO:root:FL Epoch: 659 Using Learning rate : 0.013392639274049612 
INFO:root:FL Epoch: 659 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602560
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.753183
INFO:root:FL Epoch: 659 Norm Difference for worker 1346 is 0.783966
INFO:root:FL Epoch: 659 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 659 Training on worker :133
INFO:root:FL Epoch: 659 Using Learning rate : 0.013392639274049612 
INFO:root:FL Epoch: 659 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494457
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.305821
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 659 Norm Difference for worker 133 is 0.564045
INFO:root:FL Epoch: 659 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 659 Training on worker :699
INFO:root:FL Epoch: 659 Using Learning rate : 0.013392639274049612 
INFO:root:FL Epoch: 659 Normal Training
INFO:root:Worker: 699 Train Epoch: 0 [0/200 (0%)]	Loss: 0.791324
INFO:root:Worker: 699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342984
INFO:root:FL Epoch: 659 Norm Difference for worker 699 is 0.724846
INFO:root:FL Epoch: 659 Done on worker:699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 659 Training on worker :374
INFO:root:FL Epoch: 659 Using Learning rate : 0.013392639274049612 
INFO:root:FL Epoch: 659 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618076
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441164
INFO:root:FL Epoch: 659 Norm Difference for worker 374 is 0.659978
INFO:root:FL Epoch: 659 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 659 Training on worker :827
INFO:root:FL Epoch: 659 Using Learning rate : 0.013392639274049612 
INFO:root:FL Epoch: 659 Normal Training
INFO:root:Worker: 827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529342
INFO:root:Worker: 827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522410
INFO:root:FL Epoch: 659 Norm Difference for worker 827 is 0.800723
INFO:root:FL Epoch: 659 Done on worker:827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 659 Training on worker :367
INFO:root:FL Epoch: 659 Using Learning rate : 0.013392639274049612 
INFO:root:FL Epoch: 659 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328918
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505860
INFO:root:FL Epoch: 659 Norm Difference for worker 367 is 0.734059
INFO:root:FL Epoch: 659 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 659 Training on worker :1408
INFO:root:FL Epoch: 659 Using Learning rate : 0.013392639274049612 
INFO:root:FL Epoch: 659 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727503
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393094
INFO:root:FL Epoch: 659 Norm Difference for worker 1408 is 0.736703
INFO:root:FL Epoch: 659 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 659 Training on worker :741
INFO:root:FL Epoch: 659 Using Learning rate : 0.013392639274049612 
INFO:root:FL Epoch: 659 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657928
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396733
INFO:root:FL Epoch: 659 Norm Difference for worker 741 is 0.743048
INFO:root:FL Epoch: 659 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 659 Training on worker :952
INFO:root:FL Epoch: 659 Using Learning rate : 0.013392639274049612 
INFO:root:FL Epoch: 659 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.282180
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567631
INFO:root:FL Epoch: 659 Norm Difference for worker 952 is 0.737972
INFO:root:FL Epoch: 659 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 133
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 659 Ends   ===================
INFO:root:Epoch:659 Global Model Test Loss:0.5290832168915692 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:659 Global Model Backdoor Test Loss:0.08067208093901475                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 660 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 660 Workers Selected : [580, 445, 1191, 908, 25, 749, 812, 244, 593, 618]
INFO:root:FL Epoch: 660 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 660 Num points on workers: [200 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 660 Training on worker :580
INFO:root:FL Epoch: 660 Using Learning rate : 0.013365853995501512 
INFO:root:FL Epoch: 660 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444557
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453750
INFO:root:FL Epoch: 660 Norm Difference for worker 580 is 0.805039
INFO:root:FL Epoch: 660 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 660 Training on worker :445
INFO:root:FL Epoch: 660 Using Learning rate : 0.013365853995501512 
INFO:root:FL Epoch: 660 Normal Training
INFO:root:Worker: 445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422515
INFO:root:Worker: 445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415255
INFO:root:FL Epoch: 660 Norm Difference for worker 445 is 0.657357
INFO:root:FL Epoch: 660 Done on worker:445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 660 Training on worker :1191
INFO:root:FL Epoch: 660 Using Learning rate : 0.013365853995501512 
INFO:root:FL Epoch: 660 Normal Training
INFO:root:Worker: 1191 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636033
INFO:root:Worker: 1191 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521752
INFO:root:FL Epoch: 660 Norm Difference for worker 1191 is 0.728274
INFO:root:FL Epoch: 660 Done on worker:1191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 660 Training on worker :908
INFO:root:FL Epoch: 660 Using Learning rate : 0.013365853995501512 
INFO:root:FL Epoch: 660 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591164
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316248
INFO:root:FL Epoch: 660 Norm Difference for worker 908 is 0.744526
INFO:root:FL Epoch: 660 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 660 Training on worker :25
INFO:root:FL Epoch: 660 Using Learning rate : 0.013365853995501512 
INFO:root:FL Epoch: 660 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.380801
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.535573
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 660 Norm Difference for worker 25 is 0.679611
INFO:root:FL Epoch: 660 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 660 Training on worker :749
INFO:root:FL Epoch: 660 Using Learning rate : 0.013365853995501512 
INFO:root:FL Epoch: 660 Normal Training
INFO:root:Worker: 749 Train Epoch: 0 [0/200 (0%)]	Loss: 0.785273
INFO:root:Worker: 749 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456554
INFO:root:FL Epoch: 660 Norm Difference for worker 749 is 0.693107
INFO:root:FL Epoch: 660 Done on worker:749
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 660 Training on worker :812
INFO:root:FL Epoch: 660 Using Learning rate : 0.013365853995501512 
INFO:root:FL Epoch: 660 Normal Training
INFO:root:Worker: 812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690669
INFO:root:Worker: 812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587623
INFO:root:FL Epoch: 660 Norm Difference for worker 812 is 0.75906
INFO:root:FL Epoch: 660 Done on worker:812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 660 Training on worker :244
INFO:root:FL Epoch: 660 Using Learning rate : 0.013365853995501512 
INFO:root:FL Epoch: 660 Normal Training
INFO:root:Worker: 244 Train Epoch: 0 [0/201 (0%)]	Loss: 0.702509
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 244 Train Epoch: 1 [0/201 (0%)]	Loss: 0.402617
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 660 Norm Difference for worker 244 is 0.663304
INFO:root:FL Epoch: 660 Done on worker:244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 660 Training on worker :593
INFO:root:FL Epoch: 660 Using Learning rate : 0.013365853995501512 
INFO:root:FL Epoch: 660 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701865
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360172
INFO:root:FL Epoch: 660 Norm Difference for worker 593 is 0.784131
INFO:root:FL Epoch: 660 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 660 Training on worker :618
INFO:root:FL Epoch: 660 Using Learning rate : 0.013365853995501512 
INFO:root:FL Epoch: 660 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601125
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322331
INFO:root:FL Epoch: 660 Norm Difference for worker 618 is 0.784148
INFO:root:FL Epoch: 660 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 244
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 660 Ends   ===================
INFO:root:Epoch:660 Global Model Test Loss:0.5134531943237081 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:660 Global Model Backdoor Test Loss:0.08813620482881863                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 661 Begins ===================
INFO:root:FL Epoch: 661 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 661 Workers Selected : [0, 1, 2, 607, 837, 17, 896, 1404, 909, 1212]
INFO:root:FL Epoch: 661 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 661 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 661 Training on worker :0
INFO:root:FL Epoch: 661 Using Learning rate : 0.0026678244575021014 
INFO:root:FL Epoch: 661 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.078635
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.076017
INFO:root:FL Epoch: 661 Worker: 0 Backdoor Test Loss: 0.08337600405017535 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 661 Worker: 0 Backdoor Train Loss: 0.10005113668739796 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 661 Norm Difference for worker 0 is 0.065098
INFO:root:FL Epoch: 661 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 661 Training on worker :1
INFO:root:FL Epoch: 661 Using Learning rate : 0.0026678244575021014 
INFO:root:FL Epoch: 661 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.073777
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.085437
INFO:root:FL Epoch: 661 Worker: 1 Backdoor Test Loss: 0.08381701571245988 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 661 Worker: 1 Backdoor Train Loss: 0.09944622963666916 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 661 Norm Difference for worker 1 is 0.068297
INFO:root:FL Epoch: 661 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 661 Training on worker :2
INFO:root:FL Epoch: 661 Using Learning rate : 0.0026678244575021014 
INFO:root:FL Epoch: 661 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.083046
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.204084
INFO:root:FL Epoch: 661 Worker: 2 Backdoor Test Loss: 0.08282272703945637 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 661 Worker: 2 Backdoor Train Loss: 0.09977666586637497 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 661 Norm Difference for worker 2 is 0.066557
INFO:root:FL Epoch: 661 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 661 Training on worker :607
INFO:root:FL Epoch: 661 Using Learning rate : 0.013339122287510509 
INFO:root:FL Epoch: 661 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465171
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335998
INFO:root:FL Epoch: 661 Norm Difference for worker 607 is 0.728107
INFO:root:FL Epoch: 661 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 661 Training on worker :837
INFO:root:FL Epoch: 661 Using Learning rate : 0.013339122287510509 
INFO:root:FL Epoch: 661 Normal Training
INFO:root:Worker: 837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377865
INFO:root:Worker: 837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220257
INFO:root:FL Epoch: 661 Norm Difference for worker 837 is 0.668214
INFO:root:FL Epoch: 661 Done on worker:837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 661 Training on worker :17
INFO:root:FL Epoch: 661 Using Learning rate : 0.013339122287510509 
INFO:root:FL Epoch: 661 Normal Training
INFO:root:Worker: 17 Train Epoch: 0 [0/201 (0%)]	Loss: 1.203505
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 17 Train Epoch: 1 [0/201 (0%)]	Loss: 0.543784
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 661 Norm Difference for worker 17 is 0.763197
INFO:root:FL Epoch: 661 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 661 Training on worker :896
INFO:root:FL Epoch: 661 Using Learning rate : 0.013339122287510509 
INFO:root:FL Epoch: 661 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715615
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399023
INFO:root:FL Epoch: 661 Norm Difference for worker 896 is 0.632501
INFO:root:FL Epoch: 661 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 661 Training on worker :1404
INFO:root:FL Epoch: 661 Using Learning rate : 0.013339122287510509 
INFO:root:FL Epoch: 661 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693406
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307254
INFO:root:FL Epoch: 661 Norm Difference for worker 1404 is 0.585696
INFO:root:FL Epoch: 661 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 661 Training on worker :909
INFO:root:FL Epoch: 661 Using Learning rate : 0.013339122287510509 
INFO:root:FL Epoch: 661 Normal Training
INFO:root:Worker: 909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.286271
INFO:root:Worker: 909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402444
INFO:root:FL Epoch: 661 Norm Difference for worker 909 is 0.604852
INFO:root:FL Epoch: 661 Done on worker:909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 661 Training on worker :1212
INFO:root:FL Epoch: 661 Using Learning rate : 0.013339122287510509 
INFO:root:FL Epoch: 661 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505403
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222267
INFO:root:FL Epoch: 661 Norm Difference for worker 1212 is 0.653429
INFO:root:FL Epoch: 661 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 661 Ends   ===================
INFO:root:Epoch:661 Global Model Test Loss:0.5165292007081649 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:661 Global Model Backdoor Test Loss:0.08282272703945637                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 662 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 662 Workers Selected : [1587, 831, 1744, 981, 535, 1490, 1495, 634, 1243, 571]
INFO:root:FL Epoch: 662 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 662 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 662 Training on worker :1587
INFO:root:FL Epoch: 662 Using Learning rate : 0.013312444042935488 
INFO:root:FL Epoch: 662 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631241
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470505
INFO:root:FL Epoch: 662 Norm Difference for worker 1587 is 0.816798
INFO:root:FL Epoch: 662 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 662 Training on worker :831
INFO:root:FL Epoch: 662 Using Learning rate : 0.013312444042935488 
INFO:root:FL Epoch: 662 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307291
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285052
INFO:root:FL Epoch: 662 Norm Difference for worker 831 is 0.578167
INFO:root:FL Epoch: 662 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 662 Training on worker :1744
INFO:root:FL Epoch: 662 Using Learning rate : 0.013312444042935488 
INFO:root:FL Epoch: 662 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.293288
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292253
INFO:root:FL Epoch: 662 Norm Difference for worker 1744 is 0.687975
INFO:root:FL Epoch: 662 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 662 Training on worker :981
INFO:root:FL Epoch: 662 Using Learning rate : 0.013312444042935488 
INFO:root:FL Epoch: 662 Normal Training
INFO:root:Worker: 981 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634309
INFO:root:Worker: 981 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459516
INFO:root:FL Epoch: 662 Norm Difference for worker 981 is 0.774892
INFO:root:FL Epoch: 662 Done on worker:981
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 662 Training on worker :535
INFO:root:FL Epoch: 662 Using Learning rate : 0.013312444042935488 
INFO:root:FL Epoch: 662 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360352
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188784
INFO:root:FL Epoch: 662 Norm Difference for worker 535 is 0.585062
INFO:root:FL Epoch: 662 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 662 Training on worker :1490
INFO:root:FL Epoch: 662 Using Learning rate : 0.013312444042935488 
INFO:root:FL Epoch: 662 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328241
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328054
INFO:root:FL Epoch: 662 Norm Difference for worker 1490 is 0.569583
INFO:root:FL Epoch: 662 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 662 Training on worker :1495
INFO:root:FL Epoch: 662 Using Learning rate : 0.013312444042935488 
INFO:root:FL Epoch: 662 Normal Training
INFO:root:Worker: 1495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725400
INFO:root:Worker: 1495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301909
INFO:root:FL Epoch: 662 Norm Difference for worker 1495 is 0.718501
INFO:root:FL Epoch: 662 Done on worker:1495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 662 Training on worker :634
INFO:root:FL Epoch: 662 Using Learning rate : 0.013312444042935488 
INFO:root:FL Epoch: 662 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.787334
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373049
INFO:root:FL Epoch: 662 Norm Difference for worker 634 is 0.652825
INFO:root:FL Epoch: 662 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 662 Training on worker :1243
INFO:root:FL Epoch: 662 Using Learning rate : 0.013312444042935488 
INFO:root:FL Epoch: 662 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655081
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515479
INFO:root:FL Epoch: 662 Norm Difference for worker 1243 is 0.782165
INFO:root:FL Epoch: 662 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 662 Training on worker :571
INFO:root:FL Epoch: 662 Using Learning rate : 0.013312444042935488 
INFO:root:FL Epoch: 662 Normal Training
INFO:root:Worker: 571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565566
INFO:root:Worker: 571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601755
INFO:root:FL Epoch: 662 Norm Difference for worker 571 is 0.672067
INFO:root:FL Epoch: 662 Done on worker:571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1490
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 662 Ends   ===================
INFO:root:Epoch:662 Global Model Test Loss:0.5584387130597058 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:662 Global Model Backdoor Test Loss:0.1374863882859548                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 663 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 663 Workers Selected : [335, 1320, 78, 417, 3, 371, 1139, 1410, 1867, 738]
INFO:root:FL Epoch: 663 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 663 Num points on workers: [201 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 663 Training on worker :335
INFO:root:FL Epoch: 663 Using Learning rate : 0.013285819154849617 
INFO:root:FL Epoch: 663 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.361731
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697287
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 663 Norm Difference for worker 335 is 0.738864
INFO:root:FL Epoch: 663 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 663 Training on worker :1320
INFO:root:FL Epoch: 663 Using Learning rate : 0.013285819154849617 
INFO:root:FL Epoch: 663 Normal Training
INFO:root:Worker: 1320 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454761
INFO:root:Worker: 1320 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192752
INFO:root:FL Epoch: 663 Norm Difference for worker 1320 is 0.747048
INFO:root:FL Epoch: 663 Done on worker:1320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 663 Training on worker :78
INFO:root:FL Epoch: 663 Using Learning rate : 0.013285819154849617 
INFO:root:FL Epoch: 663 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.274501
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.271514
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 663 Norm Difference for worker 78 is 0.414293
INFO:root:FL Epoch: 663 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 663 Training on worker :417
INFO:root:FL Epoch: 663 Using Learning rate : 0.013285819154849617 
INFO:root:FL Epoch: 663 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433605
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434816
INFO:root:FL Epoch: 663 Norm Difference for worker 417 is 0.800101
INFO:root:FL Epoch: 663 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 663 Training on worker :3
INFO:root:FL Epoch: 663 Using Learning rate : 0.013285819154849617 
INFO:root:FL Epoch: 663 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576922
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.865478
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 663 Norm Difference for worker 3 is 0.783497
INFO:root:FL Epoch: 663 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 663 Training on worker :371
INFO:root:FL Epoch: 663 Using Learning rate : 0.013285819154849617 
INFO:root:FL Epoch: 663 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813581
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349796
INFO:root:FL Epoch: 663 Norm Difference for worker 371 is 0.747549
INFO:root:FL Epoch: 663 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 663 Training on worker :1139
INFO:root:FL Epoch: 663 Using Learning rate : 0.013285819154849617 
INFO:root:FL Epoch: 663 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502433
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298931
INFO:root:FL Epoch: 663 Norm Difference for worker 1139 is 0.741509
INFO:root:FL Epoch: 663 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 663 Training on worker :1410
INFO:root:FL Epoch: 663 Using Learning rate : 0.013285819154849617 
INFO:root:FL Epoch: 663 Normal Training
INFO:root:Worker: 1410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.839495
INFO:root:Worker: 1410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278100
INFO:root:FL Epoch: 663 Norm Difference for worker 1410 is 0.70077
INFO:root:FL Epoch: 663 Done on worker:1410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 663 Training on worker :1867
INFO:root:FL Epoch: 663 Using Learning rate : 0.013285819154849617 
INFO:root:FL Epoch: 663 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.211953
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.770439
INFO:root:FL Epoch: 663 Norm Difference for worker 1867 is 0.766849
INFO:root:FL Epoch: 663 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 663 Training on worker :738
INFO:root:FL Epoch: 663 Using Learning rate : 0.013285819154849617 
INFO:root:FL Epoch: 663 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538196
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398681
INFO:root:FL Epoch: 663 Norm Difference for worker 738 is 0.780037
INFO:root:FL Epoch: 663 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 78
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 663 Ends   ===================
INFO:root:Epoch:663 Global Model Test Loss:0.5509762430892271 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:663 Global Model Backdoor Test Loss:0.0868393878142039                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 664 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 664 Workers Selected : [740, 258, 895, 807, 468, 1002, 239, 675, 1571, 1007]
INFO:root:FL Epoch: 664 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 664 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 664 Training on worker :740
INFO:root:FL Epoch: 664 Using Learning rate : 0.013259247516539919 
INFO:root:FL Epoch: 664 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634409
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.807518
INFO:root:FL Epoch: 664 Norm Difference for worker 740 is 0.772874
INFO:root:FL Epoch: 664 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 664 Training on worker :258
INFO:root:FL Epoch: 664 Using Learning rate : 0.013259247516539919 
INFO:root:FL Epoch: 664 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.608088
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.763691
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 664 Norm Difference for worker 258 is 0.851131
INFO:root:FL Epoch: 664 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 664 Training on worker :895
INFO:root:FL Epoch: 664 Using Learning rate : 0.013259247516539919 
INFO:root:FL Epoch: 664 Normal Training
INFO:root:Worker: 895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.867620
INFO:root:Worker: 895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527328
INFO:root:FL Epoch: 664 Norm Difference for worker 895 is 0.814346
INFO:root:FL Epoch: 664 Done on worker:895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 664 Training on worker :807
INFO:root:FL Epoch: 664 Using Learning rate : 0.013259247516539919 
INFO:root:FL Epoch: 664 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549192
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422799
INFO:root:FL Epoch: 664 Norm Difference for worker 807 is 0.833271
INFO:root:FL Epoch: 664 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 664 Training on worker :468
INFO:root:FL Epoch: 664 Using Learning rate : 0.013259247516539919 
INFO:root:FL Epoch: 664 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812798
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.741638
INFO:root:FL Epoch: 664 Norm Difference for worker 468 is 0.824879
INFO:root:FL Epoch: 664 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 664 Training on worker :1002
INFO:root:FL Epoch: 664 Using Learning rate : 0.013259247516539919 
INFO:root:FL Epoch: 664 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454256
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425934
INFO:root:FL Epoch: 664 Norm Difference for worker 1002 is 0.72894
INFO:root:FL Epoch: 664 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 664 Training on worker :239
INFO:root:FL Epoch: 664 Using Learning rate : 0.013259247516539919 
INFO:root:FL Epoch: 664 Normal Training
INFO:root:Worker: 239 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603250
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 239 Train Epoch: 1 [0/201 (0%)]	Loss: 0.387148
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 664 Norm Difference for worker 239 is 0.857558
INFO:root:FL Epoch: 664 Done on worker:239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 664 Training on worker :675
INFO:root:FL Epoch: 664 Using Learning rate : 0.013259247516539919 
INFO:root:FL Epoch: 664 Normal Training
INFO:root:Worker: 675 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548694
INFO:root:Worker: 675 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577498
INFO:root:FL Epoch: 664 Norm Difference for worker 675 is 0.791213
INFO:root:FL Epoch: 664 Done on worker:675
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 664 Training on worker :1571
INFO:root:FL Epoch: 664 Using Learning rate : 0.013259247516539919 
INFO:root:FL Epoch: 664 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524542
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308192
INFO:root:FL Epoch: 664 Norm Difference for worker 1571 is 0.761731
INFO:root:FL Epoch: 664 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 664 Training on worker :1007
INFO:root:FL Epoch: 664 Using Learning rate : 0.013259247516539919 
INFO:root:FL Epoch: 664 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667687
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257779
INFO:root:FL Epoch: 664 Norm Difference for worker 1007 is 0.81768
INFO:root:FL Epoch: 664 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1002
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 664 Ends   ===================
INFO:root:Epoch:664 Global Model Test Loss:0.5295351480736452 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:664 Global Model Backdoor Test Loss:0.08173495096464951                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 665 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 665 Workers Selected : [81, 351, 1764, 1030, 751, 1163, 582, 323, 1265, 143]
INFO:root:FL Epoch: 665 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 665 Num points on workers: [201 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 665 Training on worker :81
INFO:root:FL Epoch: 665 Using Learning rate : 0.013232729021506837 
INFO:root:FL Epoch: 665 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 1.060527
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.864568
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 665 Norm Difference for worker 81 is 0.845481
INFO:root:FL Epoch: 665 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 665 Training on worker :351
INFO:root:FL Epoch: 665 Using Learning rate : 0.013232729021506837 
INFO:root:FL Epoch: 665 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738749
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248409
INFO:root:FL Epoch: 665 Norm Difference for worker 351 is 0.790067
INFO:root:FL Epoch: 665 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 665 Training on worker :1764
INFO:root:FL Epoch: 665 Using Learning rate : 0.013232729021506837 
INFO:root:FL Epoch: 665 Normal Training
INFO:root:Worker: 1764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700857
INFO:root:Worker: 1764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654798
INFO:root:FL Epoch: 665 Norm Difference for worker 1764 is 0.813332
INFO:root:FL Epoch: 665 Done on worker:1764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 665 Training on worker :1030
INFO:root:FL Epoch: 665 Using Learning rate : 0.013232729021506837 
INFO:root:FL Epoch: 665 Normal Training
INFO:root:Worker: 1030 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442301
INFO:root:Worker: 1030 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465418
INFO:root:FL Epoch: 665 Norm Difference for worker 1030 is 0.788996
INFO:root:FL Epoch: 665 Done on worker:1030
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 665 Training on worker :751
INFO:root:FL Epoch: 665 Using Learning rate : 0.013232729021506837 
INFO:root:FL Epoch: 665 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492210
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328305
INFO:root:FL Epoch: 665 Norm Difference for worker 751 is 0.750113
INFO:root:FL Epoch: 665 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 665 Training on worker :1163
INFO:root:FL Epoch: 665 Using Learning rate : 0.013232729021506837 
INFO:root:FL Epoch: 665 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.272860
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593158
INFO:root:FL Epoch: 665 Norm Difference for worker 1163 is 0.748486
INFO:root:FL Epoch: 665 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 665 Training on worker :582
INFO:root:FL Epoch: 665 Using Learning rate : 0.013232729021506837 
INFO:root:FL Epoch: 665 Normal Training
INFO:root:Worker: 582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.834257
INFO:root:Worker: 582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.843483
INFO:root:FL Epoch: 665 Norm Difference for worker 582 is 0.830754
INFO:root:FL Epoch: 665 Done on worker:582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 665 Training on worker :323
INFO:root:FL Epoch: 665 Using Learning rate : 0.013232729021506837 
INFO:root:FL Epoch: 665 Normal Training
INFO:root:Worker: 323 Train Epoch: 0 [0/201 (0%)]	Loss: 0.730942
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 323 Train Epoch: 1 [0/201 (0%)]	Loss: 0.600619
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 665 Norm Difference for worker 323 is 0.869888
INFO:root:FL Epoch: 665 Done on worker:323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 665 Training on worker :1265
INFO:root:FL Epoch: 665 Using Learning rate : 0.013232729021506837 
INFO:root:FL Epoch: 665 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538150
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612983
INFO:root:FL Epoch: 665 Norm Difference for worker 1265 is 0.808987
INFO:root:FL Epoch: 665 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 665 Training on worker :143
INFO:root:FL Epoch: 665 Using Learning rate : 0.013232729021506837 
INFO:root:FL Epoch: 665 Normal Training
INFO:root:Worker: 143 Train Epoch: 0 [0/201 (0%)]	Loss: 0.753169
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 143 Train Epoch: 1 [0/201 (0%)]	Loss: 0.723390
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 665 Norm Difference for worker 143 is 0.795401
INFO:root:FL Epoch: 665 Done on worker:143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1163
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 665 Ends   ===================
INFO:root:Epoch:665 Global Model Test Loss:0.5220522582530975 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:665 Global Model Backdoor Test Loss:0.10120908046762149                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 666 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 666 Workers Selected : [1824, 1524, 512, 513, 1770, 173, 1460, 639, 1261, 1732]
INFO:root:FL Epoch: 666 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 666 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 666 Training on worker :1824
INFO:root:FL Epoch: 666 Using Learning rate : 0.013206263563463825 
INFO:root:FL Epoch: 666 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 1.017615
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492335
INFO:root:FL Epoch: 666 Norm Difference for worker 1824 is 0.702711
INFO:root:FL Epoch: 666 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 666 Training on worker :1524
INFO:root:FL Epoch: 666 Using Learning rate : 0.013206263563463825 
INFO:root:FL Epoch: 666 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677769
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445701
INFO:root:FL Epoch: 666 Norm Difference for worker 1524 is 0.750186
INFO:root:FL Epoch: 666 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 666 Training on worker :512
INFO:root:FL Epoch: 666 Using Learning rate : 0.013206263563463825 
INFO:root:FL Epoch: 666 Normal Training
INFO:root:Worker: 512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.829365
INFO:root:Worker: 512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.221606
INFO:root:FL Epoch: 666 Norm Difference for worker 512 is 0.733547
INFO:root:FL Epoch: 666 Done on worker:512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 666 Training on worker :513
INFO:root:FL Epoch: 666 Using Learning rate : 0.013206263563463825 
INFO:root:FL Epoch: 666 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.262192
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418470
INFO:root:FL Epoch: 666 Norm Difference for worker 513 is 0.78281
INFO:root:FL Epoch: 666 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 666 Training on worker :1770
INFO:root:FL Epoch: 666 Using Learning rate : 0.013206263563463825 
INFO:root:FL Epoch: 666 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.184490
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274982
INFO:root:FL Epoch: 666 Norm Difference for worker 1770 is 0.57763
INFO:root:FL Epoch: 666 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 666 Training on worker :173
INFO:root:FL Epoch: 666 Using Learning rate : 0.013206263563463825 
INFO:root:FL Epoch: 666 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596628
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.504874
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 666 Norm Difference for worker 173 is 0.703852
INFO:root:FL Epoch: 666 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 666 Training on worker :1460
INFO:root:FL Epoch: 666 Using Learning rate : 0.013206263563463825 
INFO:root:FL Epoch: 666 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.213227
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.226859
INFO:root:FL Epoch: 666 Norm Difference for worker 1460 is 0.51223
INFO:root:FL Epoch: 666 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 666 Training on worker :639
INFO:root:FL Epoch: 666 Using Learning rate : 0.013206263563463825 
INFO:root:FL Epoch: 666 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.280551
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521446
INFO:root:FL Epoch: 666 Norm Difference for worker 639 is 0.676324
INFO:root:FL Epoch: 666 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 666 Training on worker :1261
INFO:root:FL Epoch: 666 Using Learning rate : 0.013206263563463825 
INFO:root:FL Epoch: 666 Normal Training
INFO:root:Worker: 1261 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718618
INFO:root:Worker: 1261 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400261
INFO:root:FL Epoch: 666 Norm Difference for worker 1261 is 0.768139
INFO:root:FL Epoch: 666 Done on worker:1261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 666 Training on worker :1732
INFO:root:FL Epoch: 666 Using Learning rate : 0.013206263563463825 
INFO:root:FL Epoch: 666 Normal Training
INFO:root:Worker: 1732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.815373
INFO:root:Worker: 1732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570000
INFO:root:FL Epoch: 666 Norm Difference for worker 1732 is 0.711211
INFO:root:FL Epoch: 666 Done on worker:1732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1460
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 666 Ends   ===================
INFO:root:Epoch:666 Global Model Test Loss:0.5170267259373384 and Test Accuracy:75.0 
INFO:root:Epoch:666 Global Model Backdoor Test Loss:0.07777809413770835                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 667 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 667 Workers Selected : [1773, 938, 657, 1319, 1905, 21, 745, 488, 408, 1595]
INFO:root:FL Epoch: 667 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 667 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 667 Training on worker :1773
INFO:root:FL Epoch: 667 Using Learning rate : 0.013179851036336896 
INFO:root:FL Epoch: 667 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.225333
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307016
INFO:root:FL Epoch: 667 Norm Difference for worker 1773 is 0.983112
INFO:root:FL Epoch: 667 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 667 Training on worker :938
INFO:root:FL Epoch: 667 Using Learning rate : 0.013179851036336896 
INFO:root:FL Epoch: 667 Normal Training
INFO:root:Worker: 938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484536
INFO:root:Worker: 938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605128
INFO:root:FL Epoch: 667 Norm Difference for worker 938 is 0.867061
INFO:root:FL Epoch: 667 Done on worker:938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 667 Training on worker :657
INFO:root:FL Epoch: 667 Using Learning rate : 0.013179851036336896 
INFO:root:FL Epoch: 667 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442531
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587686
INFO:root:FL Epoch: 667 Norm Difference for worker 657 is 0.807806
INFO:root:FL Epoch: 667 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 667 Training on worker :1319
INFO:root:FL Epoch: 667 Using Learning rate : 0.013179851036336896 
INFO:root:FL Epoch: 667 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704586
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423557
INFO:root:FL Epoch: 667 Norm Difference for worker 1319 is 0.789963
INFO:root:FL Epoch: 667 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 667 Training on worker :1905
INFO:root:FL Epoch: 667 Using Learning rate : 0.013179851036336896 
INFO:root:FL Epoch: 667 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.255313
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.142799
INFO:root:FL Epoch: 667 Norm Difference for worker 1905 is 0.481415
INFO:root:FL Epoch: 667 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 667 Training on worker :21
INFO:root:FL Epoch: 667 Using Learning rate : 0.013179851036336896 
INFO:root:FL Epoch: 667 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.535610
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.300090
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 667 Norm Difference for worker 21 is 0.63928
INFO:root:FL Epoch: 667 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 667 Training on worker :745
INFO:root:FL Epoch: 667 Using Learning rate : 0.013179851036336896 
INFO:root:FL Epoch: 667 Normal Training
INFO:root:Worker: 745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496994
INFO:root:Worker: 745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616273
INFO:root:FL Epoch: 667 Norm Difference for worker 745 is 0.869045
INFO:root:FL Epoch: 667 Done on worker:745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 667 Training on worker :488
INFO:root:FL Epoch: 667 Using Learning rate : 0.013179851036336896 
INFO:root:FL Epoch: 667 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519694
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553487
INFO:root:FL Epoch: 667 Norm Difference for worker 488 is 0.776596
INFO:root:FL Epoch: 667 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 667 Training on worker :408
INFO:root:FL Epoch: 667 Using Learning rate : 0.013179851036336896 
INFO:root:FL Epoch: 667 Normal Training
INFO:root:Worker: 408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541950
INFO:root:Worker: 408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358162
INFO:root:FL Epoch: 667 Norm Difference for worker 408 is 0.74378
INFO:root:FL Epoch: 667 Done on worker:408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 667 Training on worker :1595
INFO:root:FL Epoch: 667 Using Learning rate : 0.013179851036336896 
INFO:root:FL Epoch: 667 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.264316
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500786
INFO:root:FL Epoch: 667 Norm Difference for worker 1595 is 0.635228
INFO:root:FL Epoch: 667 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1905
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 667 Ends   ===================
INFO:root:Epoch:667 Global Model Test Loss:0.5248574772301842 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:667 Global Model Backdoor Test Loss:0.09812752778331439                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 668 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 668 Workers Selected : [1586, 1317, 626, 1406, 854, 1493, 724, 1905, 1504, 843]
INFO:root:FL Epoch: 668 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 668 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 668 Training on worker :1586
INFO:root:FL Epoch: 668 Using Learning rate : 0.013153491334264224 
INFO:root:FL Epoch: 668 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690168
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353687
INFO:root:FL Epoch: 668 Norm Difference for worker 1586 is 0.861378
INFO:root:FL Epoch: 668 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 668 Training on worker :1317
INFO:root:FL Epoch: 668 Using Learning rate : 0.013153491334264224 
INFO:root:FL Epoch: 668 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547214
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636794
INFO:root:FL Epoch: 668 Norm Difference for worker 1317 is 0.839951
INFO:root:FL Epoch: 668 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 668 Training on worker :626
INFO:root:FL Epoch: 668 Using Learning rate : 0.013153491334264224 
INFO:root:FL Epoch: 668 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677561
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232297
INFO:root:FL Epoch: 668 Norm Difference for worker 626 is 0.806189
INFO:root:FL Epoch: 668 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 668 Training on worker :1406
INFO:root:FL Epoch: 668 Using Learning rate : 0.013153491334264224 
INFO:root:FL Epoch: 668 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486824
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425155
INFO:root:FL Epoch: 668 Norm Difference for worker 1406 is 0.816687
INFO:root:FL Epoch: 668 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 668 Training on worker :854
INFO:root:FL Epoch: 668 Using Learning rate : 0.013153491334264224 
INFO:root:FL Epoch: 668 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546077
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305826
INFO:root:FL Epoch: 668 Norm Difference for worker 854 is 0.784431
INFO:root:FL Epoch: 668 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 668 Training on worker :1493
INFO:root:FL Epoch: 668 Using Learning rate : 0.013153491334264224 
INFO:root:FL Epoch: 668 Normal Training
INFO:root:Worker: 1493 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762375
INFO:root:Worker: 1493 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506964
INFO:root:FL Epoch: 668 Norm Difference for worker 1493 is 0.785158
INFO:root:FL Epoch: 668 Done on worker:1493
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 668 Training on worker :724
INFO:root:FL Epoch: 668 Using Learning rate : 0.013153491334264224 
INFO:root:FL Epoch: 668 Normal Training
INFO:root:Worker: 724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658953
INFO:root:Worker: 724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358559
INFO:root:FL Epoch: 668 Norm Difference for worker 724 is 0.851061
INFO:root:FL Epoch: 668 Done on worker:724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 668 Training on worker :1905
INFO:root:FL Epoch: 668 Using Learning rate : 0.013153491334264224 
INFO:root:FL Epoch: 668 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.127190
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.177460
INFO:root:FL Epoch: 668 Norm Difference for worker 1905 is 0.332947
INFO:root:FL Epoch: 668 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 668 Training on worker :1504
INFO:root:FL Epoch: 668 Using Learning rate : 0.013153491334264224 
INFO:root:FL Epoch: 668 Normal Training
INFO:root:Worker: 1504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435668
INFO:root:Worker: 1504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431355
INFO:root:FL Epoch: 668 Norm Difference for worker 1504 is 0.873769
INFO:root:FL Epoch: 668 Done on worker:1504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 668 Training on worker :843
INFO:root:FL Epoch: 668 Using Learning rate : 0.013153491334264224 
INFO:root:FL Epoch: 668 Normal Training
INFO:root:Worker: 843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641989
INFO:root:Worker: 843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315402
INFO:root:FL Epoch: 668 Norm Difference for worker 843 is 0.803557
INFO:root:FL Epoch: 668 Done on worker:843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1905
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 668 Ends   ===================
INFO:root:Epoch:668 Global Model Test Loss:0.5272764318129596 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:668 Global Model Backdoor Test Loss:0.07610296023388703                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 669 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 669 Workers Selected : [554, 1448, 934, 1333, 217, 1698, 1453, 379, 1803, 488]
INFO:root:FL Epoch: 669 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 669 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 669 Training on worker :554
INFO:root:FL Epoch: 669 Using Learning rate : 0.013127184351595695 
INFO:root:FL Epoch: 669 Normal Training
INFO:root:Worker: 554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700141
INFO:root:Worker: 554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488552
INFO:root:FL Epoch: 669 Norm Difference for worker 554 is 0.95917
INFO:root:FL Epoch: 669 Done on worker:554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 669 Training on worker :1448
INFO:root:FL Epoch: 669 Using Learning rate : 0.013127184351595695 
INFO:root:FL Epoch: 669 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337568
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.141247
INFO:root:FL Epoch: 669 Norm Difference for worker 1448 is 0.520248
INFO:root:FL Epoch: 669 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 669 Training on worker :934
INFO:root:FL Epoch: 669 Using Learning rate : 0.013127184351595695 
INFO:root:FL Epoch: 669 Normal Training
INFO:root:Worker: 934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385006
INFO:root:Worker: 934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635142
INFO:root:FL Epoch: 669 Norm Difference for worker 934 is 0.934851
INFO:root:FL Epoch: 669 Done on worker:934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 669 Training on worker :1333
INFO:root:FL Epoch: 669 Using Learning rate : 0.013127184351595695 
INFO:root:FL Epoch: 669 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641964
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366391
INFO:root:FL Epoch: 669 Norm Difference for worker 1333 is 0.918796
INFO:root:FL Epoch: 669 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 669 Training on worker :217
INFO:root:FL Epoch: 669 Using Learning rate : 0.013127184351595695 
INFO:root:FL Epoch: 669 Normal Training
INFO:root:Worker: 217 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689630
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 217 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415156
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 669 Norm Difference for worker 217 is 0.835411
INFO:root:FL Epoch: 669 Done on worker:217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 669 Training on worker :1698
INFO:root:FL Epoch: 669 Using Learning rate : 0.013127184351595695 
INFO:root:FL Epoch: 669 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654376
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391962
INFO:root:FL Epoch: 669 Norm Difference for worker 1698 is 0.883822
INFO:root:FL Epoch: 669 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 669 Training on worker :1453
INFO:root:FL Epoch: 669 Using Learning rate : 0.013127184351595695 
INFO:root:FL Epoch: 669 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667592
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.198721
INFO:root:FL Epoch: 669 Norm Difference for worker 1453 is 0.727444
INFO:root:FL Epoch: 669 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 669 Training on worker :379
INFO:root:FL Epoch: 669 Using Learning rate : 0.013127184351595695 
INFO:root:FL Epoch: 669 Normal Training
INFO:root:Worker: 379 Train Epoch: 0 [0/200 (0%)]	Loss: 1.040292
INFO:root:Worker: 379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.720507
INFO:root:FL Epoch: 669 Norm Difference for worker 379 is 0.935249
INFO:root:FL Epoch: 669 Done on worker:379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 669 Training on worker :1803
INFO:root:FL Epoch: 669 Using Learning rate : 0.013127184351595695 
INFO:root:FL Epoch: 669 Normal Training
INFO:root:Worker: 1803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748390
INFO:root:Worker: 1803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233495
INFO:root:FL Epoch: 669 Norm Difference for worker 1803 is 0.887769
INFO:root:FL Epoch: 669 Done on worker:1803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 669 Training on worker :488
INFO:root:FL Epoch: 669 Using Learning rate : 0.013127184351595695 
INFO:root:FL Epoch: 669 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343988
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445825
INFO:root:FL Epoch: 669 Norm Difference for worker 488 is 0.893649
INFO:root:FL Epoch: 669 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1448
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 669 Ends   ===================
INFO:root:Epoch:669 Global Model Test Loss:0.5364065398188198 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:669 Global Model Backdoor Test Loss:0.06375209614634514                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 670 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 670 Workers Selected : [709, 1445, 1569, 618, 1559, 1202, 1010, 484, 1465, 613]
INFO:root:FL Epoch: 670 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 670 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 670 Training on worker :709
INFO:root:FL Epoch: 670 Using Learning rate : 0.0131009299828925 
INFO:root:FL Epoch: 670 Normal Training
INFO:root:Worker: 709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538046
INFO:root:Worker: 709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231257
INFO:root:FL Epoch: 670 Norm Difference for worker 709 is 0.879537
INFO:root:FL Epoch: 670 Done on worker:709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 670 Training on worker :1445
INFO:root:FL Epoch: 670 Using Learning rate : 0.0131009299828925 
INFO:root:FL Epoch: 670 Normal Training
INFO:root:Worker: 1445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354121
INFO:root:Worker: 1445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694300
INFO:root:FL Epoch: 670 Norm Difference for worker 1445 is 0.942666
INFO:root:FL Epoch: 670 Done on worker:1445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 670 Training on worker :1569
INFO:root:FL Epoch: 670 Using Learning rate : 0.0131009299828925 
INFO:root:FL Epoch: 670 Normal Training
INFO:root:Worker: 1569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544160
INFO:root:Worker: 1569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435415
INFO:root:FL Epoch: 670 Norm Difference for worker 1569 is 0.951708
INFO:root:FL Epoch: 670 Done on worker:1569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 670 Training on worker :618
INFO:root:FL Epoch: 670 Using Learning rate : 0.0131009299828925 
INFO:root:FL Epoch: 670 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778844
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.874075
INFO:root:FL Epoch: 670 Norm Difference for worker 618 is 0.873882
INFO:root:FL Epoch: 670 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 670 Training on worker :1559
INFO:root:FL Epoch: 670 Using Learning rate : 0.0131009299828925 
INFO:root:FL Epoch: 670 Normal Training
INFO:root:Worker: 1559 Train Epoch: 0 [0/200 (0%)]	Loss: 1.174750
INFO:root:Worker: 1559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525232
INFO:root:FL Epoch: 670 Norm Difference for worker 1559 is 0.89936
INFO:root:FL Epoch: 670 Done on worker:1559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 670 Training on worker :1202
INFO:root:FL Epoch: 670 Using Learning rate : 0.0131009299828925 
INFO:root:FL Epoch: 670 Normal Training
INFO:root:Worker: 1202 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513633
INFO:root:Worker: 1202 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421716
INFO:root:FL Epoch: 670 Norm Difference for worker 1202 is 0.857959
INFO:root:FL Epoch: 670 Done on worker:1202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 670 Training on worker :1010
INFO:root:FL Epoch: 670 Using Learning rate : 0.0131009299828925 
INFO:root:FL Epoch: 670 Normal Training
INFO:root:Worker: 1010 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707225
INFO:root:Worker: 1010 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241731
INFO:root:FL Epoch: 670 Norm Difference for worker 1010 is 0.82411
INFO:root:FL Epoch: 670 Done on worker:1010
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 670 Training on worker :484
INFO:root:FL Epoch: 670 Using Learning rate : 0.0131009299828925 
INFO:root:FL Epoch: 670 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642559
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426205
INFO:root:FL Epoch: 670 Norm Difference for worker 484 is 0.909541
INFO:root:FL Epoch: 670 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 670 Training on worker :1465
INFO:root:FL Epoch: 670 Using Learning rate : 0.0131009299828925 
INFO:root:FL Epoch: 670 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351049
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423184
INFO:root:FL Epoch: 670 Norm Difference for worker 1465 is 0.890958
INFO:root:FL Epoch: 670 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 670 Training on worker :613
INFO:root:FL Epoch: 670 Using Learning rate : 0.0131009299828925 
INFO:root:FL Epoch: 670 Normal Training
INFO:root:Worker: 613 Train Epoch: 0 [0/200 (0%)]	Loss: 1.088288
INFO:root:Worker: 613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233756
INFO:root:FL Epoch: 670 Norm Difference for worker 613 is 1.002182
INFO:root:FL Epoch: 670 Done on worker:613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1202
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 670 Ends   ===================
INFO:root:Epoch:670 Global Model Test Loss:0.49901674600208507 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:670 Global Model Backdoor Test Loss:0.07393467550476392                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 671 Begins ===================
INFO:root:FL Epoch: 671 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 671 Workers Selected : [0, 1, 2, 151, 1654, 1080, 91, 1467, 1247, 1165]
INFO:root:FL Epoch: 671 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 671 Num points on workers: [200 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 671 Training on worker :0
INFO:root:FL Epoch: 671 Using Learning rate : 0.0026149456245853435 
INFO:root:FL Epoch: 671 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.093086
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.083148
INFO:root:FL Epoch: 671 Worker: 0 Backdoor Test Loss: 0.06920886350174744 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 671 Worker: 0 Backdoor Train Loss: 0.07633217424154282 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 671 Norm Difference for worker 0 is 0.061304
INFO:root:FL Epoch: 671 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 671 Training on worker :1
INFO:root:FL Epoch: 671 Using Learning rate : 0.0026149456245853435 
INFO:root:FL Epoch: 671 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.119379
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.157939
INFO:root:FL Epoch: 671 Worker: 1 Backdoor Test Loss: 0.06979515838126342 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 671 Worker: 1 Backdoor Train Loss: 0.0765358790755272 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 671 Norm Difference for worker 1 is 0.059726
INFO:root:FL Epoch: 671 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 671 Training on worker :2
INFO:root:FL Epoch: 671 Using Learning rate : 0.0026149456245853435 
INFO:root:FL Epoch: 671 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.080904
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.079542
INFO:root:FL Epoch: 671 Worker: 2 Backdoor Test Loss: 0.06917987142999966 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 671 Worker: 2 Backdoor Train Loss: 0.0768788956105709 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 671 Norm Difference for worker 2 is 0.057113
INFO:root:FL Epoch: 671 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 671 Training on worker :151
INFO:root:FL Epoch: 671 Using Learning rate : 0.013074728122926718 
INFO:root:FL Epoch: 671 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.550174
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.315003
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 671 Norm Difference for worker 151 is 0.768374
INFO:root:FL Epoch: 671 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 671 Training on worker :1654
INFO:root:FL Epoch: 671 Using Learning rate : 0.013074728122926718 
INFO:root:FL Epoch: 671 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554381
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335273
INFO:root:FL Epoch: 671 Norm Difference for worker 1654 is 0.834203
INFO:root:FL Epoch: 671 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 671 Training on worker :1080
INFO:root:FL Epoch: 671 Using Learning rate : 0.013074728122926718 
INFO:root:FL Epoch: 671 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599742
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569463
INFO:root:FL Epoch: 671 Norm Difference for worker 1080 is 0.783149
INFO:root:FL Epoch: 671 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 671 Training on worker :91
INFO:root:FL Epoch: 671 Using Learning rate : 0.013074728122926718 
INFO:root:FL Epoch: 671 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.235463
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.354371
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 671 Norm Difference for worker 91 is 0.720684
INFO:root:FL Epoch: 671 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 671 Training on worker :1467
INFO:root:FL Epoch: 671 Using Learning rate : 0.013074728122926718 
INFO:root:FL Epoch: 671 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587794
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366327
INFO:root:FL Epoch: 671 Norm Difference for worker 1467 is 0.805634
INFO:root:FL Epoch: 671 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 671 Training on worker :1247
INFO:root:FL Epoch: 671 Using Learning rate : 0.013074728122926718 
INFO:root:FL Epoch: 671 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493932
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367896
INFO:root:FL Epoch: 671 Norm Difference for worker 1247 is 0.7436
INFO:root:FL Epoch: 671 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 671 Training on worker :1165
INFO:root:FL Epoch: 671 Using Learning rate : 0.013074728122926718 
INFO:root:FL Epoch: 671 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356099
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404314
INFO:root:FL Epoch: 671 Norm Difference for worker 1165 is 0.763534
INFO:root:FL Epoch: 671 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 671 Ends   ===================
INFO:root:Epoch:671 Global Model Test Loss:0.5006529408342698 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:671 Global Model Backdoor Test Loss:0.06917987142999966                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 672 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 672 Workers Selected : [55, 1275, 894, 1719, 433, 1880, 1000, 1374, 879, 853]
INFO:root:FL Epoch: 672 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 672 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 672 Training on worker :55
INFO:root:FL Epoch: 672 Using Learning rate : 0.013048578666680863 
INFO:root:FL Epoch: 672 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.355344
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.372855
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 672 Norm Difference for worker 55 is 0.769793
INFO:root:FL Epoch: 672 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 672 Training on worker :1275
INFO:root:FL Epoch: 672 Using Learning rate : 0.013048578666680863 
INFO:root:FL Epoch: 672 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.258326
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.143569
INFO:root:FL Epoch: 672 Norm Difference for worker 1275 is 0.560436
INFO:root:FL Epoch: 672 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 672 Training on worker :894
INFO:root:FL Epoch: 672 Using Learning rate : 0.013048578666680863 
INFO:root:FL Epoch: 672 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588387
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306339
INFO:root:FL Epoch: 672 Norm Difference for worker 894 is 0.778619
INFO:root:FL Epoch: 672 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 672 Training on worker :1719
INFO:root:FL Epoch: 672 Using Learning rate : 0.013048578666680863 
INFO:root:FL Epoch: 672 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.269404
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265870
INFO:root:FL Epoch: 672 Norm Difference for worker 1719 is 0.747594
INFO:root:FL Epoch: 672 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 672 Training on worker :433
INFO:root:FL Epoch: 672 Using Learning rate : 0.013048578666680863 
INFO:root:FL Epoch: 672 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663950
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671553
INFO:root:FL Epoch: 672 Norm Difference for worker 433 is 0.757549
INFO:root:FL Epoch: 672 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 672 Training on worker :1880
INFO:root:FL Epoch: 672 Using Learning rate : 0.013048578666680863 
INFO:root:FL Epoch: 672 Normal Training
INFO:root:Worker: 1880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662241
INFO:root:Worker: 1880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367312
INFO:root:FL Epoch: 672 Norm Difference for worker 1880 is 0.813055
INFO:root:FL Epoch: 672 Done on worker:1880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 672 Training on worker :1000
INFO:root:FL Epoch: 672 Using Learning rate : 0.013048578666680863 
INFO:root:FL Epoch: 672 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761096
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568761
INFO:root:FL Epoch: 672 Norm Difference for worker 1000 is 0.873356
INFO:root:FL Epoch: 672 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 672 Training on worker :1374
INFO:root:FL Epoch: 672 Using Learning rate : 0.013048578666680863 
INFO:root:FL Epoch: 672 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540406
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252209
INFO:root:FL Epoch: 672 Norm Difference for worker 1374 is 0.75893
INFO:root:FL Epoch: 672 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 672 Training on worker :879
INFO:root:FL Epoch: 672 Using Learning rate : 0.013048578666680863 
INFO:root:FL Epoch: 672 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593265
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451713
INFO:root:FL Epoch: 672 Norm Difference for worker 879 is 0.779627
INFO:root:FL Epoch: 672 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 672 Training on worker :853
INFO:root:FL Epoch: 672 Using Learning rate : 0.013048578666680863 
INFO:root:FL Epoch: 672 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622709
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536525
INFO:root:FL Epoch: 672 Norm Difference for worker 853 is 0.813447
INFO:root:FL Epoch: 672 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1275
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 672 Ends   ===================
INFO:root:Epoch:672 Global Model Test Loss:0.5090860496549046 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:672 Global Model Backdoor Test Loss:0.0581564586609602                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 673 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 673 Workers Selected : [548, 1156, 785, 1590, 1674, 880, 1577, 662, 1528, 386]
INFO:root:FL Epoch: 673 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 673 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 673 Training on worker :548
INFO:root:FL Epoch: 673 Using Learning rate : 0.013022481509347504 
INFO:root:FL Epoch: 673 Normal Training
INFO:root:Worker: 548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483748
INFO:root:Worker: 548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526950
INFO:root:FL Epoch: 673 Norm Difference for worker 548 is 0.813856
INFO:root:FL Epoch: 673 Done on worker:548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 673 Training on worker :1156
INFO:root:FL Epoch: 673 Using Learning rate : 0.013022481509347504 
INFO:root:FL Epoch: 673 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495212
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493680
INFO:root:FL Epoch: 673 Norm Difference for worker 1156 is 0.772325
INFO:root:FL Epoch: 673 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 673 Training on worker :785
INFO:root:FL Epoch: 673 Using Learning rate : 0.013022481509347504 
INFO:root:FL Epoch: 673 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805006
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312464
INFO:root:FL Epoch: 673 Norm Difference for worker 785 is 0.857459
INFO:root:FL Epoch: 673 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 673 Training on worker :1590
INFO:root:FL Epoch: 673 Using Learning rate : 0.013022481509347504 
INFO:root:FL Epoch: 673 Normal Training
INFO:root:Worker: 1590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727987
INFO:root:Worker: 1590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.125720
INFO:root:FL Epoch: 673 Norm Difference for worker 1590 is 0.894133
INFO:root:FL Epoch: 673 Done on worker:1590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 673 Training on worker :1674
INFO:root:FL Epoch: 673 Using Learning rate : 0.013022481509347504 
INFO:root:FL Epoch: 673 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523965
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.123813
INFO:root:FL Epoch: 673 Norm Difference for worker 1674 is 0.595907
INFO:root:FL Epoch: 673 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 673 Training on worker :880
INFO:root:FL Epoch: 673 Using Learning rate : 0.013022481509347504 
INFO:root:FL Epoch: 673 Normal Training
INFO:root:Worker: 880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326773
INFO:root:Worker: 880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416763
INFO:root:FL Epoch: 673 Norm Difference for worker 880 is 0.775442
INFO:root:FL Epoch: 673 Done on worker:880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 673 Training on worker :1577
INFO:root:FL Epoch: 673 Using Learning rate : 0.013022481509347504 
INFO:root:FL Epoch: 673 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683281
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446570
INFO:root:FL Epoch: 673 Norm Difference for worker 1577 is 0.890118
INFO:root:FL Epoch: 673 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 673 Training on worker :662
INFO:root:FL Epoch: 673 Using Learning rate : 0.013022481509347504 
INFO:root:FL Epoch: 673 Normal Training
INFO:root:Worker: 662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.937233
INFO:root:Worker: 662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.920056
INFO:root:FL Epoch: 673 Norm Difference for worker 662 is 0.84864
INFO:root:FL Epoch: 673 Done on worker:662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 673 Training on worker :1528
INFO:root:FL Epoch: 673 Using Learning rate : 0.013022481509347504 
INFO:root:FL Epoch: 673 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519426
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.156151
INFO:root:FL Epoch: 673 Norm Difference for worker 1528 is 0.668218
INFO:root:FL Epoch: 673 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 673 Training on worker :386
INFO:root:FL Epoch: 673 Using Learning rate : 0.013022481509347504 
INFO:root:FL Epoch: 673 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.290754
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.108928
INFO:root:FL Epoch: 673 Norm Difference for worker 386 is 0.608451
INFO:root:FL Epoch: 673 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1674
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 673 Ends   ===================
INFO:root:Epoch:673 Global Model Test Loss:0.5063193545621985 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:673 Global Model Backdoor Test Loss:0.06956094627579053                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 674 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 674 Workers Selected : [1866, 1598, 830, 460, 382, 1338, 838, 193, 457, 1938]
INFO:root:FL Epoch: 674 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 674 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 674 Training on worker :1866
INFO:root:FL Epoch: 674 Using Learning rate : 0.012996436546328809 
INFO:root:FL Epoch: 674 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602862
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571793
INFO:root:FL Epoch: 674 Norm Difference for worker 1866 is 0.898491
INFO:root:FL Epoch: 674 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 674 Training on worker :1598
INFO:root:FL Epoch: 674 Using Learning rate : 0.012996436546328809 
INFO:root:FL Epoch: 674 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509059
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417984
INFO:root:FL Epoch: 674 Norm Difference for worker 1598 is 0.765863
INFO:root:FL Epoch: 674 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 674 Training on worker :830
INFO:root:FL Epoch: 674 Using Learning rate : 0.012996436546328809 
INFO:root:FL Epoch: 674 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.280822
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369516
INFO:root:FL Epoch: 674 Norm Difference for worker 830 is 0.582783
INFO:root:FL Epoch: 674 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 674 Training on worker :460
INFO:root:FL Epoch: 674 Using Learning rate : 0.012996436546328809 
INFO:root:FL Epoch: 674 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296264
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348612
INFO:root:FL Epoch: 674 Norm Difference for worker 460 is 0.873632
INFO:root:FL Epoch: 674 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 674 Training on worker :382
INFO:root:FL Epoch: 674 Using Learning rate : 0.012996436546328809 
INFO:root:FL Epoch: 674 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.822082
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596194
INFO:root:FL Epoch: 674 Norm Difference for worker 382 is 0.830074
INFO:root:FL Epoch: 674 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 674 Training on worker :1338
INFO:root:FL Epoch: 674 Using Learning rate : 0.012996436546328809 
INFO:root:FL Epoch: 674 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308366
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.159473
INFO:root:FL Epoch: 674 Norm Difference for worker 1338 is 0.595107
INFO:root:FL Epoch: 674 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 674 Training on worker :838
INFO:root:FL Epoch: 674 Using Learning rate : 0.012996436546328809 
INFO:root:FL Epoch: 674 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696473
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.832153
INFO:root:FL Epoch: 674 Norm Difference for worker 838 is 0.807268
INFO:root:FL Epoch: 674 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 674 Training on worker :193
INFO:root:FL Epoch: 674 Using Learning rate : 0.012996436546328809 
INFO:root:FL Epoch: 674 Normal Training
INFO:root:Worker: 193 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698292
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 193 Train Epoch: 1 [0/201 (0%)]	Loss: 0.313599
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 674 Norm Difference for worker 193 is 0.866935
INFO:root:FL Epoch: 674 Done on worker:193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 674 Training on worker :457
INFO:root:FL Epoch: 674 Using Learning rate : 0.012996436546328809 
INFO:root:FL Epoch: 674 Normal Training
INFO:root:Worker: 457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753016
INFO:root:Worker: 457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369181
INFO:root:FL Epoch: 674 Norm Difference for worker 457 is 0.819933
INFO:root:FL Epoch: 674 Done on worker:457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 674 Training on worker :1938
INFO:root:FL Epoch: 674 Using Learning rate : 0.012996436546328809 
INFO:root:FL Epoch: 674 Normal Training
INFO:root:Worker: 1938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463710
INFO:root:Worker: 1938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342336
INFO:root:FL Epoch: 674 Norm Difference for worker 1938 is 0.804049
INFO:root:FL Epoch: 674 Done on worker:1938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1338
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 674 Ends   ===================
INFO:root:Epoch:674 Global Model Test Loss:0.5137789372135612 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:674 Global Model Backdoor Test Loss:0.06992015366752942                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 675 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 675 Workers Selected : [1290, 213, 1351, 1815, 282, 152, 1723, 1823, 752, 1239]
INFO:root:FL Epoch: 675 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 675 Num points on workers: [200 201 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 675 Training on worker :1290
INFO:root:FL Epoch: 675 Using Learning rate : 0.012970443673236149 
INFO:root:FL Epoch: 675 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.856986
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288392
INFO:root:FL Epoch: 675 Norm Difference for worker 1290 is 0.843907
INFO:root:FL Epoch: 675 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 675 Training on worker :213
INFO:root:FL Epoch: 675 Using Learning rate : 0.012970443673236149 
INFO:root:FL Epoch: 675 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.658745
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.462304
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 675 Norm Difference for worker 213 is 0.872075
INFO:root:FL Epoch: 675 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 675 Training on worker :1351
INFO:root:FL Epoch: 675 Using Learning rate : 0.012970443673236149 
INFO:root:FL Epoch: 675 Normal Training
INFO:root:Worker: 1351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543789
INFO:root:Worker: 1351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333482
INFO:root:FL Epoch: 675 Norm Difference for worker 1351 is 0.901942
INFO:root:FL Epoch: 675 Done on worker:1351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 675 Training on worker :1815
INFO:root:FL Epoch: 675 Using Learning rate : 0.012970443673236149 
INFO:root:FL Epoch: 675 Normal Training
INFO:root:Worker: 1815 Train Epoch: 0 [0/200 (0%)]	Loss: 0.228674
INFO:root:Worker: 1815 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340326
INFO:root:FL Epoch: 675 Norm Difference for worker 1815 is 0.710127
INFO:root:FL Epoch: 675 Done on worker:1815
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 675 Training on worker :282
INFO:root:FL Epoch: 675 Using Learning rate : 0.012970443673236149 
INFO:root:FL Epoch: 675 Normal Training
INFO:root:Worker: 282 Train Epoch: 0 [0/201 (0%)]	Loss: 0.665333
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 282 Train Epoch: 1 [0/201 (0%)]	Loss: 0.387921
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 675 Norm Difference for worker 282 is 0.770594
INFO:root:FL Epoch: 675 Done on worker:282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 675 Training on worker :152
INFO:root:FL Epoch: 675 Using Learning rate : 0.012970443673236149 
INFO:root:FL Epoch: 675 Normal Training
INFO:root:Worker: 152 Train Epoch: 0 [0/201 (0%)]	Loss: 0.535731
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 152 Train Epoch: 1 [0/201 (0%)]	Loss: 0.481615
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 675 Norm Difference for worker 152 is 0.798447
INFO:root:FL Epoch: 675 Done on worker:152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 675 Training on worker :1723
INFO:root:FL Epoch: 675 Using Learning rate : 0.012970443673236149 
INFO:root:FL Epoch: 675 Normal Training
INFO:root:Worker: 1723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401214
INFO:root:Worker: 1723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544172
INFO:root:FL Epoch: 675 Norm Difference for worker 1723 is 0.825243
INFO:root:FL Epoch: 675 Done on worker:1723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 675 Training on worker :1823
INFO:root:FL Epoch: 675 Using Learning rate : 0.012970443673236149 
INFO:root:FL Epoch: 675 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399937
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284985
INFO:root:FL Epoch: 675 Norm Difference for worker 1823 is 0.925092
INFO:root:FL Epoch: 675 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 675 Training on worker :752
INFO:root:FL Epoch: 675 Using Learning rate : 0.012970443673236149 
INFO:root:FL Epoch: 675 Normal Training
INFO:root:Worker: 752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434007
INFO:root:Worker: 752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.143075
INFO:root:FL Epoch: 675 Norm Difference for worker 752 is 0.856112
INFO:root:FL Epoch: 675 Done on worker:752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 675 Training on worker :1239
INFO:root:FL Epoch: 675 Using Learning rate : 0.012970443673236149 
INFO:root:FL Epoch: 675 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739120
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708068
INFO:root:FL Epoch: 675 Norm Difference for worker 1239 is 0.892835
INFO:root:FL Epoch: 675 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1815
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 675 Ends   ===================
INFO:root:Epoch:675 Global Model Test Loss:0.5276647052344154 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:675 Global Model Backdoor Test Loss:0.10716895510752995                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 676 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 676 Workers Selected : [1494, 1738, 1857, 453, 1466, 1132, 1586, 1646, 1059, 419]
INFO:root:FL Epoch: 676 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 676 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 676 Training on worker :1494
INFO:root:FL Epoch: 676 Using Learning rate : 0.012944502785889678 
INFO:root:FL Epoch: 676 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728580
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238602
INFO:root:FL Epoch: 676 Norm Difference for worker 1494 is 0.753018
INFO:root:FL Epoch: 676 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 676 Training on worker :1738
INFO:root:FL Epoch: 676 Using Learning rate : 0.012944502785889678 
INFO:root:FL Epoch: 676 Normal Training
INFO:root:Worker: 1738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460061
INFO:root:Worker: 1738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345090
INFO:root:FL Epoch: 676 Norm Difference for worker 1738 is 0.793171
INFO:root:FL Epoch: 676 Done on worker:1738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 676 Training on worker :1857
INFO:root:FL Epoch: 676 Using Learning rate : 0.012944502785889678 
INFO:root:FL Epoch: 676 Normal Training
INFO:root:Worker: 1857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.821647
INFO:root:Worker: 1857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399924
INFO:root:FL Epoch: 676 Norm Difference for worker 1857 is 0.831744
INFO:root:FL Epoch: 676 Done on worker:1857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 676 Training on worker :453
INFO:root:FL Epoch: 676 Using Learning rate : 0.012944502785889678 
INFO:root:FL Epoch: 676 Normal Training
INFO:root:Worker: 453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805048
INFO:root:Worker: 453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477862
INFO:root:FL Epoch: 676 Norm Difference for worker 453 is 0.769529
INFO:root:FL Epoch: 676 Done on worker:453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 676 Training on worker :1466
INFO:root:FL Epoch: 676 Using Learning rate : 0.012944502785889678 
INFO:root:FL Epoch: 676 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421912
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616282
INFO:root:FL Epoch: 676 Norm Difference for worker 1466 is 0.882081
INFO:root:FL Epoch: 676 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 676 Training on worker :1132
INFO:root:FL Epoch: 676 Using Learning rate : 0.012944502785889678 
INFO:root:FL Epoch: 676 Normal Training
INFO:root:Worker: 1132 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569129
INFO:root:Worker: 1132 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393377
INFO:root:FL Epoch: 676 Norm Difference for worker 1132 is 0.679227
INFO:root:FL Epoch: 676 Done on worker:1132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 676 Training on worker :1586
INFO:root:FL Epoch: 676 Using Learning rate : 0.012944502785889678 
INFO:root:FL Epoch: 676 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.854669
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364452
INFO:root:FL Epoch: 676 Norm Difference for worker 1586 is 0.774885
INFO:root:FL Epoch: 676 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 676 Training on worker :1646
INFO:root:FL Epoch: 676 Using Learning rate : 0.012944502785889678 
INFO:root:FL Epoch: 676 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711335
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669819
INFO:root:FL Epoch: 676 Norm Difference for worker 1646 is 0.821606
INFO:root:FL Epoch: 676 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 676 Training on worker :1059
INFO:root:FL Epoch: 676 Using Learning rate : 0.012944502785889678 
INFO:root:FL Epoch: 676 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.232741
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396683
INFO:root:FL Epoch: 676 Norm Difference for worker 1059 is 0.682165
INFO:root:FL Epoch: 676 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 676 Training on worker :419
INFO:root:FL Epoch: 676 Using Learning rate : 0.012944502785889678 
INFO:root:FL Epoch: 676 Normal Training
INFO:root:Worker: 419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338576
INFO:root:Worker: 419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317869
INFO:root:FL Epoch: 676 Norm Difference for worker 419 is 0.712575
INFO:root:FL Epoch: 676 Done on worker:419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1132
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 676 Ends   ===================
INFO:root:Epoch:676 Global Model Test Loss:0.523975703646155 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:676 Global Model Backdoor Test Loss:0.1082011063893636                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 677 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 677 Workers Selected : [952, 411, 415, 1448, 552, 1943, 679, 1277, 1416, 35]
INFO:root:FL Epoch: 677 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 677 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 677 Training on worker :952
INFO:root:FL Epoch: 677 Using Learning rate : 0.012918613780317898 
INFO:root:FL Epoch: 677 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467193
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624554
INFO:root:FL Epoch: 677 Norm Difference for worker 952 is 0.734984
INFO:root:FL Epoch: 677 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 677 Training on worker :411
INFO:root:FL Epoch: 677 Using Learning rate : 0.012918613780317898 
INFO:root:FL Epoch: 677 Normal Training
INFO:root:Worker: 411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558531
INFO:root:Worker: 411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600491
INFO:root:FL Epoch: 677 Norm Difference for worker 411 is 0.767379
INFO:root:FL Epoch: 677 Done on worker:411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 677 Training on worker :415
INFO:root:FL Epoch: 677 Using Learning rate : 0.012918613780317898 
INFO:root:FL Epoch: 677 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358796
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329185
INFO:root:FL Epoch: 677 Norm Difference for worker 415 is 0.562876
INFO:root:FL Epoch: 677 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 677 Training on worker :1448
INFO:root:FL Epoch: 677 Using Learning rate : 0.012918613780317898 
INFO:root:FL Epoch: 677 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.221247
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.227908
INFO:root:FL Epoch: 677 Norm Difference for worker 1448 is 0.429838
INFO:root:FL Epoch: 677 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 677 Training on worker :552
INFO:root:FL Epoch: 677 Using Learning rate : 0.012918613780317898 
INFO:root:FL Epoch: 677 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812738
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590340
INFO:root:FL Epoch: 677 Norm Difference for worker 552 is 0.730228
INFO:root:FL Epoch: 677 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 677 Training on worker :1943
INFO:root:FL Epoch: 677 Using Learning rate : 0.012918613780317898 
INFO:root:FL Epoch: 677 Normal Training
INFO:root:Worker: 1943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744802
INFO:root:Worker: 1943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399064
INFO:root:FL Epoch: 677 Norm Difference for worker 1943 is 0.752623
INFO:root:FL Epoch: 677 Done on worker:1943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 677 Training on worker :679
INFO:root:FL Epoch: 677 Using Learning rate : 0.012918613780317898 
INFO:root:FL Epoch: 677 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536031
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393330
INFO:root:FL Epoch: 677 Norm Difference for worker 679 is 0.749062
INFO:root:FL Epoch: 677 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 677 Training on worker :1277
INFO:root:FL Epoch: 677 Using Learning rate : 0.012918613780317898 
INFO:root:FL Epoch: 677 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511344
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290000
INFO:root:FL Epoch: 677 Norm Difference for worker 1277 is 0.678958
INFO:root:FL Epoch: 677 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 677 Training on worker :1416
INFO:root:FL Epoch: 677 Using Learning rate : 0.012918613780317898 
INFO:root:FL Epoch: 677 Normal Training
INFO:root:Worker: 1416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373541
INFO:root:Worker: 1416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391909
INFO:root:FL Epoch: 677 Norm Difference for worker 1416 is 0.69367
INFO:root:FL Epoch: 677 Done on worker:1416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 677 Training on worker :35
INFO:root:FL Epoch: 677 Using Learning rate : 0.012918613780317898 
INFO:root:FL Epoch: 677 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.614201
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.389171
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 677 Norm Difference for worker 35 is 0.660638
INFO:root:FL Epoch: 677 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1448
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 677 Ends   ===================
INFO:root:Epoch:677 Global Model Test Loss:0.527966814882615 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:677 Global Model Backdoor Test Loss:0.07223118841648102                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 678 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 678 Workers Selected : [1457, 196, 409, 1243, 850, 1688, 1945, 529, 1824, 301]
INFO:root:FL Epoch: 678 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 678 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 678 Training on worker :1457
INFO:root:FL Epoch: 678 Using Learning rate : 0.012892776552757263 
INFO:root:FL Epoch: 678 Normal Training
INFO:root:Worker: 1457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.870133
INFO:root:Worker: 1457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408686
INFO:root:FL Epoch: 678 Norm Difference for worker 1457 is 0.833862
INFO:root:FL Epoch: 678 Done on worker:1457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 678 Training on worker :196
INFO:root:FL Epoch: 678 Using Learning rate : 0.012892776552757263 
INFO:root:FL Epoch: 678 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.642802
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.641226
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 678 Norm Difference for worker 196 is 0.802166
INFO:root:FL Epoch: 678 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 678 Training on worker :409
INFO:root:FL Epoch: 678 Using Learning rate : 0.012892776552757263 
INFO:root:FL Epoch: 678 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379696
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542665
INFO:root:FL Epoch: 678 Norm Difference for worker 409 is 0.753278
INFO:root:FL Epoch: 678 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 678 Training on worker :1243
INFO:root:FL Epoch: 678 Using Learning rate : 0.012892776552757263 
INFO:root:FL Epoch: 678 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.994296
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376412
INFO:root:FL Epoch: 678 Norm Difference for worker 1243 is 0.82475
INFO:root:FL Epoch: 678 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 678 Training on worker :850
INFO:root:FL Epoch: 678 Using Learning rate : 0.012892776552757263 
INFO:root:FL Epoch: 678 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 1.002521
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333566
INFO:root:FL Epoch: 678 Norm Difference for worker 850 is 0.773009
INFO:root:FL Epoch: 678 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 678 Training on worker :1688
INFO:root:FL Epoch: 678 Using Learning rate : 0.012892776552757263 
INFO:root:FL Epoch: 678 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307084
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478672
INFO:root:FL Epoch: 678 Norm Difference for worker 1688 is 0.637566
INFO:root:FL Epoch: 678 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 678 Training on worker :1945
INFO:root:FL Epoch: 678 Using Learning rate : 0.012892776552757263 
INFO:root:FL Epoch: 678 Normal Training
INFO:root:Worker: 1945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.266169
INFO:root:Worker: 1945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665058
INFO:root:FL Epoch: 678 Norm Difference for worker 1945 is 0.78505
INFO:root:FL Epoch: 678 Done on worker:1945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 678 Training on worker :529
INFO:root:FL Epoch: 678 Using Learning rate : 0.012892776552757263 
INFO:root:FL Epoch: 678 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564539
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509645
INFO:root:FL Epoch: 678 Norm Difference for worker 529 is 0.806143
INFO:root:FL Epoch: 678 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 678 Training on worker :1824
INFO:root:FL Epoch: 678 Using Learning rate : 0.012892776552757263 
INFO:root:FL Epoch: 678 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692144
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376942
INFO:root:FL Epoch: 678 Norm Difference for worker 1824 is 0.80726
INFO:root:FL Epoch: 678 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 678 Training on worker :301
INFO:root:FL Epoch: 678 Using Learning rate : 0.012892776552757263 
INFO:root:FL Epoch: 678 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.784220
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.382568
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 678 Norm Difference for worker 301 is 0.839031
INFO:root:FL Epoch: 678 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1688
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 678 Ends   ===================
INFO:root:Epoch:678 Global Model Test Loss:0.5375694544876323 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:678 Global Model Backdoor Test Loss:0.07298224791884422                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 679 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 679 Workers Selected : [1556, 1805, 396, 462, 693, 700, 492, 688, 164, 1734]
INFO:root:FL Epoch: 679 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 679 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 679 Training on worker :1556
INFO:root:FL Epoch: 679 Using Learning rate : 0.012866990999651749 
INFO:root:FL Epoch: 679 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662102
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428149
INFO:root:FL Epoch: 679 Norm Difference for worker 1556 is 0.702686
INFO:root:FL Epoch: 679 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 679 Training on worker :1805
INFO:root:FL Epoch: 679 Using Learning rate : 0.012866990999651749 
INFO:root:FL Epoch: 679 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323348
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681403
INFO:root:FL Epoch: 679 Norm Difference for worker 1805 is 0.721129
INFO:root:FL Epoch: 679 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 679 Training on worker :396
INFO:root:FL Epoch: 679 Using Learning rate : 0.012866990999651749 
INFO:root:FL Epoch: 679 Normal Training
INFO:root:Worker: 396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542734
INFO:root:Worker: 396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455129
INFO:root:FL Epoch: 679 Norm Difference for worker 396 is 0.771241
INFO:root:FL Epoch: 679 Done on worker:396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 679 Training on worker :462
INFO:root:FL Epoch: 679 Using Learning rate : 0.012866990999651749 
INFO:root:FL Epoch: 679 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621000
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553367
INFO:root:FL Epoch: 679 Norm Difference for worker 462 is 0.786933
INFO:root:FL Epoch: 679 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 679 Training on worker :693
INFO:root:FL Epoch: 679 Using Learning rate : 0.012866990999651749 
INFO:root:FL Epoch: 679 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414473
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270438
INFO:root:FL Epoch: 679 Norm Difference for worker 693 is 0.695719
INFO:root:FL Epoch: 679 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 679 Training on worker :700
INFO:root:FL Epoch: 679 Using Learning rate : 0.012866990999651749 
INFO:root:FL Epoch: 679 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723024
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607651
INFO:root:FL Epoch: 679 Norm Difference for worker 700 is 0.814574
INFO:root:FL Epoch: 679 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 679 Training on worker :492
INFO:root:FL Epoch: 679 Using Learning rate : 0.012866990999651749 
INFO:root:FL Epoch: 679 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361006
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288537
INFO:root:FL Epoch: 679 Norm Difference for worker 492 is 0.68221
INFO:root:FL Epoch: 679 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 679 Training on worker :688
INFO:root:FL Epoch: 679 Using Learning rate : 0.012866990999651749 
INFO:root:FL Epoch: 679 Normal Training
INFO:root:Worker: 688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368663
INFO:root:Worker: 688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360683
INFO:root:FL Epoch: 679 Norm Difference for worker 688 is 0.7304
INFO:root:FL Epoch: 679 Done on worker:688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 679 Training on worker :164
INFO:root:FL Epoch: 679 Using Learning rate : 0.012866990999651749 
INFO:root:FL Epoch: 679 Normal Training
INFO:root:Worker: 164 Train Epoch: 0 [0/201 (0%)]	Loss: 0.637200
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 164 Train Epoch: 1 [0/201 (0%)]	Loss: 0.298069
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 679 Norm Difference for worker 164 is 0.776059
INFO:root:FL Epoch: 679 Done on worker:164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 679 Training on worker :1734
INFO:root:FL Epoch: 679 Using Learning rate : 0.012866990999651749 
INFO:root:FL Epoch: 679 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796388
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478191
INFO:root:FL Epoch: 679 Norm Difference for worker 1734 is 0.795815
INFO:root:FL Epoch: 679 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 492
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 679 Ends   ===================
INFO:root:Epoch:679 Global Model Test Loss:0.5353281988817102 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:679 Global Model Backdoor Test Loss:0.09768134728074074                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 680 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 680 Workers Selected : [616, 1015, 305, 191, 1119, 1854, 1670, 983, 1569, 980]
INFO:root:FL Epoch: 680 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 680 Num points on workers: [200 200 201 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 680 Training on worker :616
INFO:root:FL Epoch: 680 Using Learning rate : 0.012841257017652444 
INFO:root:FL Epoch: 680 Normal Training
INFO:root:Worker: 616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716487
INFO:root:Worker: 616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463830
INFO:root:FL Epoch: 680 Norm Difference for worker 616 is 0.729019
INFO:root:FL Epoch: 680 Done on worker:616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 680 Training on worker :1015
INFO:root:FL Epoch: 680 Using Learning rate : 0.012841257017652444 
INFO:root:FL Epoch: 680 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521235
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493799
INFO:root:FL Epoch: 680 Norm Difference for worker 1015 is 0.70634
INFO:root:FL Epoch: 680 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 680 Training on worker :305
INFO:root:FL Epoch: 680 Using Learning rate : 0.012841257017652444 
INFO:root:FL Epoch: 680 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.318229
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.648862
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 680 Norm Difference for worker 305 is 0.625658
INFO:root:FL Epoch: 680 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 680 Training on worker :191
INFO:root:FL Epoch: 680 Using Learning rate : 0.012841257017652444 
INFO:root:FL Epoch: 680 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.326621
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.146370
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 680 Norm Difference for worker 191 is 0.696635
INFO:root:FL Epoch: 680 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 680 Training on worker :1119
INFO:root:FL Epoch: 680 Using Learning rate : 0.012841257017652444 
INFO:root:FL Epoch: 680 Normal Training
INFO:root:Worker: 1119 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622106
INFO:root:Worker: 1119 Train Epoch: 1 [0/200 (0%)]	Loss: 0.130074
INFO:root:FL Epoch: 680 Norm Difference for worker 1119 is 0.646123
INFO:root:FL Epoch: 680 Done on worker:1119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 680 Training on worker :1854
INFO:root:FL Epoch: 680 Using Learning rate : 0.012841257017652444 
INFO:root:FL Epoch: 680 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760092
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546897
INFO:root:FL Epoch: 680 Norm Difference for worker 1854 is 0.779602
INFO:root:FL Epoch: 680 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 680 Training on worker :1670
INFO:root:FL Epoch: 680 Using Learning rate : 0.012841257017652444 
INFO:root:FL Epoch: 680 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.259119
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317901
INFO:root:FL Epoch: 680 Norm Difference for worker 1670 is 0.524879
INFO:root:FL Epoch: 680 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 680 Training on worker :983
INFO:root:FL Epoch: 680 Using Learning rate : 0.012841257017652444 
INFO:root:FL Epoch: 680 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568111
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551727
INFO:root:FL Epoch: 680 Norm Difference for worker 983 is 0.780872
INFO:root:FL Epoch: 680 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 680 Training on worker :1569
INFO:root:FL Epoch: 680 Using Learning rate : 0.012841257017652444 
INFO:root:FL Epoch: 680 Normal Training
INFO:root:Worker: 1569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585065
INFO:root:Worker: 1569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439139
INFO:root:FL Epoch: 680 Norm Difference for worker 1569 is 0.714814
INFO:root:FL Epoch: 680 Done on worker:1569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 680 Training on worker :980
INFO:root:FL Epoch: 680 Using Learning rate : 0.012841257017652444 
INFO:root:FL Epoch: 680 Normal Training
INFO:root:Worker: 980 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508623
INFO:root:Worker: 980 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546208
INFO:root:FL Epoch: 680 Norm Difference for worker 980 is 0.734952
INFO:root:FL Epoch: 680 Done on worker:980
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1670
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 680 Ends   ===================
INFO:root:Epoch:680 Global Model Test Loss:0.5423435375970953 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:680 Global Model Backdoor Test Loss:0.11304468909899394                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 681 Begins ===================
INFO:root:FL Epoch: 681 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 681 Workers Selected : [0, 1, 2, 561, 481, 321, 674, 79, 14, 483]
INFO:root:FL Epoch: 681 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 681 Num points on workers: [200 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 681 Training on worker :0
INFO:root:FL Epoch: 681 Using Learning rate : 0.0025631149007234277 
INFO:root:FL Epoch: 681 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.192499
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.111679
INFO:root:FL Epoch: 681 Worker: 0 Backdoor Test Loss: 0.10037950550516446 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 681 Worker: 0 Backdoor Train Loss: 0.09599885866045951 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 681 Norm Difference for worker 0 is 0.065965
INFO:root:FL Epoch: 681 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 681 Training on worker :1
INFO:root:FL Epoch: 681 Using Learning rate : 0.0025631149007234277 
INFO:root:FL Epoch: 681 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.098527
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.095884
INFO:root:FL Epoch: 681 Worker: 1 Backdoor Test Loss: 0.10111760472257932 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 681 Worker: 1 Backdoor Train Loss: 0.09632115438580513 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 681 Norm Difference for worker 1 is 0.063637
INFO:root:FL Epoch: 681 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 681 Training on worker :2
INFO:root:FL Epoch: 681 Using Learning rate : 0.0025631149007234277 
INFO:root:FL Epoch: 681 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.122716
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.160604
INFO:root:FL Epoch: 681 Worker: 2 Backdoor Test Loss: 0.09952587944765885 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 681 Worker: 2 Backdoor Train Loss: 0.09631961733102798 Backdoor Train Accuracy: 98.5
INFO:root:FL Epoch: 681 Norm Difference for worker 2 is 0.064107
INFO:root:FL Epoch: 681 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 681 Training on worker :561
INFO:root:FL Epoch: 681 Using Learning rate : 0.012815574503617139 
INFO:root:FL Epoch: 681 Normal Training
INFO:root:Worker: 561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400948
INFO:root:Worker: 561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364813
INFO:root:FL Epoch: 681 Norm Difference for worker 561 is 0.767213
INFO:root:FL Epoch: 681 Done on worker:561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 681 Training on worker :481
INFO:root:FL Epoch: 681 Using Learning rate : 0.012815574503617139 
INFO:root:FL Epoch: 681 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.290933
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497734
INFO:root:FL Epoch: 681 Norm Difference for worker 481 is 0.722604
INFO:root:FL Epoch: 681 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 681 Training on worker :321
INFO:root:FL Epoch: 681 Using Learning rate : 0.012815574503617139 
INFO:root:FL Epoch: 681 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.748354
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.660938
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 681 Norm Difference for worker 321 is 0.693175
INFO:root:FL Epoch: 681 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 681 Training on worker :674
INFO:root:FL Epoch: 681 Using Learning rate : 0.012815574503617139 
INFO:root:FL Epoch: 681 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586363
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215456
INFO:root:FL Epoch: 681 Norm Difference for worker 674 is 0.675575
INFO:root:FL Epoch: 681 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 681 Training on worker :79
INFO:root:FL Epoch: 681 Using Learning rate : 0.012815574503617139 
INFO:root:FL Epoch: 681 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.853060
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.438006
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 681 Norm Difference for worker 79 is 0.730565
INFO:root:FL Epoch: 681 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 681 Training on worker :14
INFO:root:FL Epoch: 681 Using Learning rate : 0.012815574503617139 
INFO:root:FL Epoch: 681 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.837971
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.373272
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 681 Norm Difference for worker 14 is 0.646159
INFO:root:FL Epoch: 681 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 681 Training on worker :483
INFO:root:FL Epoch: 681 Using Learning rate : 0.012815574503617139 
INFO:root:FL Epoch: 681 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620602
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465386
INFO:root:FL Epoch: 681 Norm Difference for worker 483 is 0.660637
INFO:root:FL Epoch: 681 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 681 Ends   ===================
INFO:root:Epoch:681 Global Model Test Loss:0.543262252036263 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:681 Global Model Backdoor Test Loss:0.10037950550516446                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 682 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 682 Workers Selected : [949, 863, 340, 58, 1181, 242, 1945, 1451, 1473, 477]
INFO:root:FL Epoch: 682 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 682 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 682 Training on worker :949
INFO:root:FL Epoch: 682 Using Learning rate : 0.012789943354609904 
INFO:root:FL Epoch: 682 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647405
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380388
INFO:root:FL Epoch: 682 Norm Difference for worker 949 is 0.80162
INFO:root:FL Epoch: 682 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 682 Training on worker :863
INFO:root:FL Epoch: 682 Using Learning rate : 0.012789943354609904 
INFO:root:FL Epoch: 682 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788557
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400882
INFO:root:FL Epoch: 682 Norm Difference for worker 863 is 0.742012
INFO:root:FL Epoch: 682 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 682 Training on worker :340
INFO:root:FL Epoch: 682 Using Learning rate : 0.012789943354609904 
INFO:root:FL Epoch: 682 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582729
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342810
INFO:root:FL Epoch: 682 Norm Difference for worker 340 is 0.704747
INFO:root:FL Epoch: 682 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 682 Training on worker :58
INFO:root:FL Epoch: 682 Using Learning rate : 0.012789943354609904 
INFO:root:FL Epoch: 682 Normal Training
INFO:root:Worker: 58 Train Epoch: 0 [0/201 (0%)]	Loss: 0.803144
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 58 Train Epoch: 1 [0/201 (0%)]	Loss: 0.411936
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 682 Norm Difference for worker 58 is 0.741004
INFO:root:FL Epoch: 682 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 682 Training on worker :1181
INFO:root:FL Epoch: 682 Using Learning rate : 0.012789943354609904 
INFO:root:FL Epoch: 682 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517169
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472145
INFO:root:FL Epoch: 682 Norm Difference for worker 1181 is 0.617129
INFO:root:FL Epoch: 682 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 682 Training on worker :242
INFO:root:FL Epoch: 682 Using Learning rate : 0.012789943354609904 
INFO:root:FL Epoch: 682 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.729045
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.872805
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 682 Norm Difference for worker 242 is 0.738461
INFO:root:FL Epoch: 682 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 682 Training on worker :1945
INFO:root:FL Epoch: 682 Using Learning rate : 0.012789943354609904 
INFO:root:FL Epoch: 682 Normal Training
INFO:root:Worker: 1945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348865
INFO:root:Worker: 1945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401346
INFO:root:FL Epoch: 682 Norm Difference for worker 1945 is 0.695782
INFO:root:FL Epoch: 682 Done on worker:1945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 682 Training on worker :1451
INFO:root:FL Epoch: 682 Using Learning rate : 0.012789943354609904 
INFO:root:FL Epoch: 682 Normal Training
INFO:root:Worker: 1451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453041
INFO:root:Worker: 1451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399565
INFO:root:FL Epoch: 682 Norm Difference for worker 1451 is 0.706961
INFO:root:FL Epoch: 682 Done on worker:1451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 682 Training on worker :1473
INFO:root:FL Epoch: 682 Using Learning rate : 0.012789943354609904 
INFO:root:FL Epoch: 682 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531212
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393867
INFO:root:FL Epoch: 682 Norm Difference for worker 1473 is 0.723326
INFO:root:FL Epoch: 682 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 682 Training on worker :477
INFO:root:FL Epoch: 682 Using Learning rate : 0.012789943354609904 
INFO:root:FL Epoch: 682 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561035
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624752
INFO:root:FL Epoch: 682 Norm Difference for worker 477 is 0.71506
INFO:root:FL Epoch: 682 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1181
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 682 Ends   ===================
INFO:root:Epoch:682 Global Model Test Loss:0.5238990801222184 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:682 Global Model Backdoor Test Loss:0.11025594423214595                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 683 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 683 Workers Selected : [849, 1204, 1327, 924, 1031, 409, 912, 401, 117, 1136]
INFO:root:FL Epoch: 683 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 683 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 683 Training on worker :849
INFO:root:FL Epoch: 683 Using Learning rate : 0.012764363467900686 
INFO:root:FL Epoch: 683 Normal Training
INFO:root:Worker: 849 Train Epoch: 0 [0/200 (0%)]	Loss: 0.995494
INFO:root:Worker: 849 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630102
INFO:root:FL Epoch: 683 Norm Difference for worker 849 is 0.663951
INFO:root:FL Epoch: 683 Done on worker:849
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 683 Training on worker :1204
INFO:root:FL Epoch: 683 Using Learning rate : 0.012764363467900686 
INFO:root:FL Epoch: 683 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362506
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699283
INFO:root:FL Epoch: 683 Norm Difference for worker 1204 is 0.682807
INFO:root:FL Epoch: 683 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 683 Training on worker :1327
INFO:root:FL Epoch: 683 Using Learning rate : 0.012764363467900686 
INFO:root:FL Epoch: 683 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383116
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.736458
INFO:root:FL Epoch: 683 Norm Difference for worker 1327 is 0.656171
INFO:root:FL Epoch: 683 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 683 Training on worker :924
INFO:root:FL Epoch: 683 Using Learning rate : 0.012764363467900686 
INFO:root:FL Epoch: 683 Normal Training
INFO:root:Worker: 924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416360
INFO:root:Worker: 924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329054
INFO:root:FL Epoch: 683 Norm Difference for worker 924 is 0.701716
INFO:root:FL Epoch: 683 Done on worker:924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 683 Training on worker :1031
INFO:root:FL Epoch: 683 Using Learning rate : 0.012764363467900686 
INFO:root:FL Epoch: 683 Normal Training
INFO:root:Worker: 1031 Train Epoch: 0 [0/200 (0%)]	Loss: 0.964514
INFO:root:Worker: 1031 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446915
INFO:root:FL Epoch: 683 Norm Difference for worker 1031 is 0.729022
INFO:root:FL Epoch: 683 Done on worker:1031
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 683 Training on worker :409
INFO:root:FL Epoch: 683 Using Learning rate : 0.012764363467900686 
INFO:root:FL Epoch: 683 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.892732
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603820
INFO:root:FL Epoch: 683 Norm Difference for worker 409 is 0.643292
INFO:root:FL Epoch: 683 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 683 Training on worker :912
INFO:root:FL Epoch: 683 Using Learning rate : 0.012764363467900686 
INFO:root:FL Epoch: 683 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621830
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520814
INFO:root:FL Epoch: 683 Norm Difference for worker 912 is 0.652554
INFO:root:FL Epoch: 683 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 683 Training on worker :401
INFO:root:FL Epoch: 683 Using Learning rate : 0.012764363467900686 
INFO:root:FL Epoch: 683 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400363
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645527
INFO:root:FL Epoch: 683 Norm Difference for worker 401 is 0.596161
INFO:root:FL Epoch: 683 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 683 Training on worker :117
INFO:root:FL Epoch: 683 Using Learning rate : 0.012764363467900686 
INFO:root:FL Epoch: 683 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.684179
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.225745
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 683 Norm Difference for worker 117 is 0.66105
INFO:root:FL Epoch: 683 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 683 Training on worker :1136
INFO:root:FL Epoch: 683 Using Learning rate : 0.012764363467900686 
INFO:root:FL Epoch: 683 Normal Training
INFO:root:Worker: 1136 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692901
INFO:root:Worker: 1136 Train Epoch: 1 [0/200 (0%)]	Loss: 0.821545
INFO:root:FL Epoch: 683 Norm Difference for worker 1136 is 0.695324
INFO:root:FL Epoch: 683 Done on worker:1136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 401
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 683 Ends   ===================
INFO:root:Epoch:683 Global Model Test Loss:0.5214249141076032 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:683 Global Model Backdoor Test Loss:0.08352142944931984                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 684 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 684 Workers Selected : [528, 141, 406, 1149, 639, 932, 865, 1944, 1827, 1174]
INFO:root:FL Epoch: 684 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 684 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 684 Training on worker :528
INFO:root:FL Epoch: 684 Using Learning rate : 0.012738834740964884 
INFO:root:FL Epoch: 684 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696915
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391915
INFO:root:FL Epoch: 684 Norm Difference for worker 528 is 0.704168
INFO:root:FL Epoch: 684 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 684 Training on worker :141
INFO:root:FL Epoch: 684 Using Learning rate : 0.012738834740964884 
INFO:root:FL Epoch: 684 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.431830
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.469240
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 684 Norm Difference for worker 141 is 0.674394
INFO:root:FL Epoch: 684 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 684 Training on worker :406
INFO:root:FL Epoch: 684 Using Learning rate : 0.012738834740964884 
INFO:root:FL Epoch: 684 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560910
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606104
INFO:root:FL Epoch: 684 Norm Difference for worker 406 is 0.76992
INFO:root:FL Epoch: 684 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 684 Training on worker :1149
INFO:root:FL Epoch: 684 Using Learning rate : 0.012738834740964884 
INFO:root:FL Epoch: 684 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737505
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439331
INFO:root:FL Epoch: 684 Norm Difference for worker 1149 is 0.71814
INFO:root:FL Epoch: 684 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 684 Training on worker :639
INFO:root:FL Epoch: 684 Using Learning rate : 0.012738834740964884 
INFO:root:FL Epoch: 684 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440555
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500230
INFO:root:FL Epoch: 684 Norm Difference for worker 639 is 0.755638
INFO:root:FL Epoch: 684 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 684 Training on worker :932
INFO:root:FL Epoch: 684 Using Learning rate : 0.012738834740964884 
INFO:root:FL Epoch: 684 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407711
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486649
INFO:root:FL Epoch: 684 Norm Difference for worker 932 is 0.710756
INFO:root:FL Epoch: 684 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 684 Training on worker :865
INFO:root:FL Epoch: 684 Using Learning rate : 0.012738834740964884 
INFO:root:FL Epoch: 684 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.247664
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417688
INFO:root:FL Epoch: 684 Norm Difference for worker 865 is 0.566096
INFO:root:FL Epoch: 684 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 684 Training on worker :1944
INFO:root:FL Epoch: 684 Using Learning rate : 0.012738834740964884 
INFO:root:FL Epoch: 684 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624696
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635232
INFO:root:FL Epoch: 684 Norm Difference for worker 1944 is 0.625057
INFO:root:FL Epoch: 684 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 684 Training on worker :1827
INFO:root:FL Epoch: 684 Using Learning rate : 0.012738834740964884 
INFO:root:FL Epoch: 684 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340076
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482476
INFO:root:FL Epoch: 684 Norm Difference for worker 1827 is 0.716915
INFO:root:FL Epoch: 684 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 684 Training on worker :1174
INFO:root:FL Epoch: 684 Using Learning rate : 0.012738834740964884 
INFO:root:FL Epoch: 684 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519265
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527543
INFO:root:FL Epoch: 684 Norm Difference for worker 1174 is 0.743906
INFO:root:FL Epoch: 684 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 865
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 684 Ends   ===================
INFO:root:Epoch:684 Global Model Test Loss:0.5201227112728006 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:684 Global Model Backdoor Test Loss:0.09553554095327854                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 685 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 685 Workers Selected : [496, 203, 42, 22, 915, 382, 62, 1040, 29, 779]
INFO:root:FL Epoch: 685 Fraction of points on each worker in this round: [0.09975062 0.10024938 0.10024938 0.10024938 0.09975062 0.09975062
 0.10024938 0.09975062 0.10024938 0.09975062]
INFO:root:FL Epoch: 685 Num points on workers: [200 201 201 201 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 685 Training on worker :496
INFO:root:FL Epoch: 685 Using Learning rate : 0.012713357071482953 
INFO:root:FL Epoch: 685 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401281
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286813
INFO:root:FL Epoch: 685 Norm Difference for worker 496 is 0.709217
INFO:root:FL Epoch: 685 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 685 Training on worker :203
INFO:root:FL Epoch: 685 Using Learning rate : 0.012713357071482953 
INFO:root:FL Epoch: 685 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.873849
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.455131
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 685 Norm Difference for worker 203 is 0.774451
INFO:root:FL Epoch: 685 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 685 Training on worker :42
INFO:root:FL Epoch: 685 Using Learning rate : 0.012713357071482953 
INFO:root:FL Epoch: 685 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.321080
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.231365
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 685 Norm Difference for worker 42 is 0.58345
INFO:root:FL Epoch: 685 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 685 Training on worker :22
INFO:root:FL Epoch: 685 Using Learning rate : 0.012713357071482953 
INFO:root:FL Epoch: 685 Normal Training
INFO:root:Worker: 22 Train Epoch: 0 [0/201 (0%)]	Loss: 0.777947
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 22 Train Epoch: 1 [0/201 (0%)]	Loss: 0.663171
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 685 Norm Difference for worker 22 is 0.789093
INFO:root:FL Epoch: 685 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 685 Training on worker :915
INFO:root:FL Epoch: 685 Using Learning rate : 0.012713357071482953 
INFO:root:FL Epoch: 685 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691259
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267252
INFO:root:FL Epoch: 685 Norm Difference for worker 915 is 0.972928
INFO:root:FL Epoch: 685 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 685 Training on worker :382
INFO:root:FL Epoch: 685 Using Learning rate : 0.012713357071482953 
INFO:root:FL Epoch: 685 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442667
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299901
INFO:root:FL Epoch: 685 Norm Difference for worker 382 is 0.714135
INFO:root:FL Epoch: 685 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 685 Training on worker :62
INFO:root:FL Epoch: 685 Using Learning rate : 0.012713357071482953 
INFO:root:FL Epoch: 685 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.433331
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.492703
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 685 Norm Difference for worker 62 is 0.790044
INFO:root:FL Epoch: 685 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 685 Training on worker :1040
INFO:root:FL Epoch: 685 Using Learning rate : 0.012713357071482953 
INFO:root:FL Epoch: 685 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577981
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.746181
INFO:root:FL Epoch: 685 Norm Difference for worker 1040 is 0.77769
INFO:root:FL Epoch: 685 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 685 Training on worker :29
INFO:root:FL Epoch: 685 Using Learning rate : 0.012713357071482953 
INFO:root:FL Epoch: 685 Normal Training
INFO:root:Worker: 29 Train Epoch: 0 [0/201 (0%)]	Loss: 0.463228
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 29 Train Epoch: 1 [0/201 (0%)]	Loss: 0.573165
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 685 Norm Difference for worker 29 is 0.784986
INFO:root:FL Epoch: 685 Done on worker:29
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 685 Training on worker :779
INFO:root:FL Epoch: 685 Using Learning rate : 0.012713357071482953 
INFO:root:FL Epoch: 685 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654503
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541551
INFO:root:FL Epoch: 685 Norm Difference for worker 779 is 0.760871
INFO:root:FL Epoch: 685 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 685 Ends   ===================
INFO:root:Epoch:685 Global Model Test Loss:0.5543793334680445 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:685 Global Model Backdoor Test Loss:0.12765739361445108                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 686 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 686 Workers Selected : [1637, 577, 971, 1234, 1712, 1120, 733, 1188, 1270, 393]
INFO:root:FL Epoch: 686 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 686 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 686 Training on worker :1637
INFO:root:FL Epoch: 686 Using Learning rate : 0.01268793035733999 
INFO:root:FL Epoch: 686 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693838
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522594
INFO:root:FL Epoch: 686 Norm Difference for worker 1637 is 0.895713
INFO:root:FL Epoch: 686 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 686 Training on worker :577
INFO:root:FL Epoch: 686 Using Learning rate : 0.01268793035733999 
INFO:root:FL Epoch: 686 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533216
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539934
INFO:root:FL Epoch: 686 Norm Difference for worker 577 is 0.791508
INFO:root:FL Epoch: 686 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 686 Training on worker :971
INFO:root:FL Epoch: 686 Using Learning rate : 0.01268793035733999 
INFO:root:FL Epoch: 686 Normal Training
INFO:root:Worker: 971 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352264
INFO:root:Worker: 971 Train Epoch: 1 [0/200 (0%)]	Loss: 0.740379
INFO:root:FL Epoch: 686 Norm Difference for worker 971 is 0.846205
INFO:root:FL Epoch: 686 Done on worker:971
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 686 Training on worker :1234
INFO:root:FL Epoch: 686 Using Learning rate : 0.01268793035733999 
INFO:root:FL Epoch: 686 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656079
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.721453
INFO:root:FL Epoch: 686 Norm Difference for worker 1234 is 0.858822
INFO:root:FL Epoch: 686 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 686 Training on worker :1712
INFO:root:FL Epoch: 686 Using Learning rate : 0.01268793035733999 
INFO:root:FL Epoch: 686 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.871684
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342089
INFO:root:FL Epoch: 686 Norm Difference for worker 1712 is 0.786583
INFO:root:FL Epoch: 686 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 686 Training on worker :1120
INFO:root:FL Epoch: 686 Using Learning rate : 0.01268793035733999 
INFO:root:FL Epoch: 686 Normal Training
INFO:root:Worker: 1120 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748643
INFO:root:Worker: 1120 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527981
INFO:root:FL Epoch: 686 Norm Difference for worker 1120 is 0.767385
INFO:root:FL Epoch: 686 Done on worker:1120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 686 Training on worker :733
INFO:root:FL Epoch: 686 Using Learning rate : 0.01268793035733999 
INFO:root:FL Epoch: 686 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321836
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292038
INFO:root:FL Epoch: 686 Norm Difference for worker 733 is 0.779602
INFO:root:FL Epoch: 686 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 686 Training on worker :1188
INFO:root:FL Epoch: 686 Using Learning rate : 0.01268793035733999 
INFO:root:FL Epoch: 686 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380354
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532007
INFO:root:FL Epoch: 686 Norm Difference for worker 1188 is 0.794969
INFO:root:FL Epoch: 686 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 686 Training on worker :1270
INFO:root:FL Epoch: 686 Using Learning rate : 0.01268793035733999 
INFO:root:FL Epoch: 686 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.301647
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370382
INFO:root:FL Epoch: 686 Norm Difference for worker 1270 is 0.610735
INFO:root:FL Epoch: 686 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 686 Training on worker :393
INFO:root:FL Epoch: 686 Using Learning rate : 0.01268793035733999 
INFO:root:FL Epoch: 686 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545358
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494350
INFO:root:FL Epoch: 686 Norm Difference for worker 393 is 0.892621
INFO:root:FL Epoch: 686 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1270
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 686 Ends   ===================
INFO:root:Epoch:686 Global Model Test Loss:0.5396523037377525 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:686 Global Model Backdoor Test Loss:0.09056711693604787                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 687 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 687 Workers Selected : [1318, 1307, 1255, 86, 1583, 73, 1774, 1361, 1191, 72]
INFO:root:FL Epoch: 687 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 687 Num points on workers: [200 200 200 201 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 687 Training on worker :1318
INFO:root:FL Epoch: 687 Using Learning rate : 0.01266255449662531 
INFO:root:FL Epoch: 687 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411429
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515944
INFO:root:FL Epoch: 687 Norm Difference for worker 1318 is 0.746561
INFO:root:FL Epoch: 687 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 687 Training on worker :1307
INFO:root:FL Epoch: 687 Using Learning rate : 0.01266255449662531 
INFO:root:FL Epoch: 687 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447102
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564460
INFO:root:FL Epoch: 687 Norm Difference for worker 1307 is 0.758365
INFO:root:FL Epoch: 687 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 687 Training on worker :1255
INFO:root:FL Epoch: 687 Using Learning rate : 0.01266255449662531 
INFO:root:FL Epoch: 687 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554830
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.727180
INFO:root:FL Epoch: 687 Norm Difference for worker 1255 is 0.804744
INFO:root:FL Epoch: 687 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 687 Training on worker :86
INFO:root:FL Epoch: 687 Using Learning rate : 0.01266255449662531 
INFO:root:FL Epoch: 687 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.317095
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.090809
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 687 Norm Difference for worker 86 is 0.459491
INFO:root:FL Epoch: 687 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 687 Training on worker :1583
INFO:root:FL Epoch: 687 Using Learning rate : 0.01266255449662531 
INFO:root:FL Epoch: 687 Normal Training
INFO:root:Worker: 1583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595060
INFO:root:Worker: 1583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389807
INFO:root:FL Epoch: 687 Norm Difference for worker 1583 is 0.666571
INFO:root:FL Epoch: 687 Done on worker:1583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 687 Training on worker :73
INFO:root:FL Epoch: 687 Using Learning rate : 0.01266255449662531 
INFO:root:FL Epoch: 687 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.355131
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.725185
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 687 Norm Difference for worker 73 is 0.834676
INFO:root:FL Epoch: 687 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 687 Training on worker :1774
INFO:root:FL Epoch: 687 Using Learning rate : 0.01266255449662531 
INFO:root:FL Epoch: 687 Normal Training
INFO:root:Worker: 1774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632517
INFO:root:Worker: 1774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.212078
INFO:root:FL Epoch: 687 Norm Difference for worker 1774 is 0.608389
INFO:root:FL Epoch: 687 Done on worker:1774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 687 Training on worker :1361
INFO:root:FL Epoch: 687 Using Learning rate : 0.01266255449662531 
INFO:root:FL Epoch: 687 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.918406
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277014
INFO:root:FL Epoch: 687 Norm Difference for worker 1361 is 0.811235
INFO:root:FL Epoch: 687 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 687 Training on worker :1191
INFO:root:FL Epoch: 687 Using Learning rate : 0.01266255449662531 
INFO:root:FL Epoch: 687 Normal Training
INFO:root:Worker: 1191 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672976
INFO:root:Worker: 1191 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275047
INFO:root:FL Epoch: 687 Norm Difference for worker 1191 is 0.694525
INFO:root:FL Epoch: 687 Done on worker:1191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 687 Training on worker :72
INFO:root:FL Epoch: 687 Using Learning rate : 0.01266255449662531 
INFO:root:FL Epoch: 687 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.368157
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428458
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 687 Norm Difference for worker 72 is 0.726504
INFO:root:FL Epoch: 687 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 86
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 687 Ends   ===================
INFO:root:Epoch:687 Global Model Test Loss:0.5354548464803135 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:687 Global Model Backdoor Test Loss:0.09242665581405163                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 688 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 688 Workers Selected : [1497, 860, 1140, 427, 1056, 1259, 134, 1401, 937, 1377]
INFO:root:FL Epoch: 688 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 688 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 688 Training on worker :1497
INFO:root:FL Epoch: 688 Using Learning rate : 0.012637229387632058 
INFO:root:FL Epoch: 688 Normal Training
INFO:root:Worker: 1497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.878720
INFO:root:Worker: 1497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455560
INFO:root:FL Epoch: 688 Norm Difference for worker 1497 is 0.774208
INFO:root:FL Epoch: 688 Done on worker:1497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 688 Training on worker :860
INFO:root:FL Epoch: 688 Using Learning rate : 0.012637229387632058 
INFO:root:FL Epoch: 688 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.855719
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566116
INFO:root:FL Epoch: 688 Norm Difference for worker 860 is 0.807284
INFO:root:FL Epoch: 688 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 688 Training on worker :1140
INFO:root:FL Epoch: 688 Using Learning rate : 0.012637229387632058 
INFO:root:FL Epoch: 688 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 1.070129
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423636
INFO:root:FL Epoch: 688 Norm Difference for worker 1140 is 0.830692
INFO:root:FL Epoch: 688 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 688 Training on worker :427
INFO:root:FL Epoch: 688 Using Learning rate : 0.012637229387632058 
INFO:root:FL Epoch: 688 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571630
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529566
INFO:root:FL Epoch: 688 Norm Difference for worker 427 is 0.797476
INFO:root:FL Epoch: 688 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 688 Training on worker :1056
INFO:root:FL Epoch: 688 Using Learning rate : 0.012637229387632058 
INFO:root:FL Epoch: 688 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681684
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542580
INFO:root:FL Epoch: 688 Norm Difference for worker 1056 is 0.803546
INFO:root:FL Epoch: 688 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 688 Training on worker :1259
INFO:root:FL Epoch: 688 Using Learning rate : 0.012637229387632058 
INFO:root:FL Epoch: 688 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604166
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.157403
INFO:root:FL Epoch: 688 Norm Difference for worker 1259 is 0.675527
INFO:root:FL Epoch: 688 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 688 Training on worker :134
INFO:root:FL Epoch: 688 Using Learning rate : 0.012637229387632058 
INFO:root:FL Epoch: 688 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.313954
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.292717
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 688 Norm Difference for worker 134 is 0.681503
INFO:root:FL Epoch: 688 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 688 Training on worker :1401
INFO:root:FL Epoch: 688 Using Learning rate : 0.012637229387632058 
INFO:root:FL Epoch: 688 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.945918
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370163
INFO:root:FL Epoch: 688 Norm Difference for worker 1401 is 0.774751
INFO:root:FL Epoch: 688 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 688 Training on worker :937
INFO:root:FL Epoch: 688 Using Learning rate : 0.012637229387632058 
INFO:root:FL Epoch: 688 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519051
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391300
INFO:root:FL Epoch: 688 Norm Difference for worker 937 is 0.739674
INFO:root:FL Epoch: 688 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 688 Training on worker :1377
INFO:root:FL Epoch: 688 Using Learning rate : 0.012637229387632058 
INFO:root:FL Epoch: 688 Normal Training
INFO:root:Worker: 1377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543651
INFO:root:Worker: 1377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482385
INFO:root:FL Epoch: 688 Norm Difference for worker 1377 is 0.779416
INFO:root:FL Epoch: 688 Done on worker:1377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1259
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 688 Ends   ===================
INFO:root:Epoch:688 Global Model Test Loss:0.5192856718512142 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:688 Global Model Backdoor Test Loss:0.07513957874228556                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 689 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 689 Workers Selected : [858, 1611, 442, 1751, 1626, 1430, 557, 6, 1406, 1934]
INFO:root:FL Epoch: 689 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 689 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 689 Training on worker :858
INFO:root:FL Epoch: 689 Using Learning rate : 0.012611954928856792 
INFO:root:FL Epoch: 689 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.178721
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555693
INFO:root:FL Epoch: 689 Norm Difference for worker 858 is 0.806404
INFO:root:FL Epoch: 689 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 689 Training on worker :1611
INFO:root:FL Epoch: 689 Using Learning rate : 0.012611954928856792 
INFO:root:FL Epoch: 689 Normal Training
INFO:root:Worker: 1611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.225491
INFO:root:Worker: 1611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683926
INFO:root:FL Epoch: 689 Norm Difference for worker 1611 is 0.743317
INFO:root:FL Epoch: 689 Done on worker:1611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 689 Training on worker :442
INFO:root:FL Epoch: 689 Using Learning rate : 0.012611954928856792 
INFO:root:FL Epoch: 689 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725359
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459098
INFO:root:FL Epoch: 689 Norm Difference for worker 442 is 0.726112
INFO:root:FL Epoch: 689 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 689 Training on worker :1751
INFO:root:FL Epoch: 689 Using Learning rate : 0.012611954928856792 
INFO:root:FL Epoch: 689 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 1.004423
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389969
INFO:root:FL Epoch: 689 Norm Difference for worker 1751 is 0.73468
INFO:root:FL Epoch: 689 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 689 Training on worker :1626
INFO:root:FL Epoch: 689 Using Learning rate : 0.012611954928856792 
INFO:root:FL Epoch: 689 Normal Training
INFO:root:Worker: 1626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709180
INFO:root:Worker: 1626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.234548
INFO:root:FL Epoch: 689 Norm Difference for worker 1626 is 0.724556
INFO:root:FL Epoch: 689 Done on worker:1626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 689 Training on worker :1430
INFO:root:FL Epoch: 689 Using Learning rate : 0.012611954928856792 
INFO:root:FL Epoch: 689 Normal Training
INFO:root:Worker: 1430 Train Epoch: 0 [0/200 (0%)]	Loss: 1.000199
INFO:root:Worker: 1430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247496
INFO:root:FL Epoch: 689 Norm Difference for worker 1430 is 0.839681
INFO:root:FL Epoch: 689 Done on worker:1430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 689 Training on worker :557
INFO:root:FL Epoch: 689 Using Learning rate : 0.012611954928856792 
INFO:root:FL Epoch: 689 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613919
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351338
INFO:root:FL Epoch: 689 Norm Difference for worker 557 is 0.614945
INFO:root:FL Epoch: 689 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 689 Training on worker :6
INFO:root:FL Epoch: 689 Using Learning rate : 0.012611954928856792 
INFO:root:FL Epoch: 689 Normal Training
INFO:root:Worker: 6 Train Epoch: 0 [0/201 (0%)]	Loss: 0.457236
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 6 Train Epoch: 1 [0/201 (0%)]	Loss: 0.205559
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 689 Norm Difference for worker 6 is 0.599593
INFO:root:FL Epoch: 689 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 689 Training on worker :1406
INFO:root:FL Epoch: 689 Using Learning rate : 0.012611954928856792 
INFO:root:FL Epoch: 689 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384322
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471675
INFO:root:FL Epoch: 689 Norm Difference for worker 1406 is 0.807999
INFO:root:FL Epoch: 689 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 689 Training on worker :1934
INFO:root:FL Epoch: 689 Using Learning rate : 0.012611954928856792 
INFO:root:FL Epoch: 689 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419933
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565435
INFO:root:FL Epoch: 689 Norm Difference for worker 1934 is 0.846364
INFO:root:FL Epoch: 689 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 6
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 689 Ends   ===================
INFO:root:Epoch:689 Global Model Test Loss:0.5238387952832615 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:689 Global Model Backdoor Test Loss:0.060089261581500374                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 690 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 690 Workers Selected : [406, 1256, 1544, 894, 738, 923, 1701, 1105, 182, 95]
INFO:root:FL Epoch: 690 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 690 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 690 Training on worker :406
INFO:root:FL Epoch: 690 Using Learning rate : 0.012586731018999079 
INFO:root:FL Epoch: 690 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465655
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594126
INFO:root:FL Epoch: 690 Norm Difference for worker 406 is 0.872068
INFO:root:FL Epoch: 690 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 690 Training on worker :1256
INFO:root:FL Epoch: 690 Using Learning rate : 0.012586731018999079 
INFO:root:FL Epoch: 690 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690385
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421388
INFO:root:FL Epoch: 690 Norm Difference for worker 1256 is 0.80248
INFO:root:FL Epoch: 690 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 690 Training on worker :1544
INFO:root:FL Epoch: 690 Using Learning rate : 0.012586731018999079 
INFO:root:FL Epoch: 690 Normal Training
INFO:root:Worker: 1544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699114
INFO:root:Worker: 1544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460555
INFO:root:FL Epoch: 690 Norm Difference for worker 1544 is 0.831561
INFO:root:FL Epoch: 690 Done on worker:1544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 690 Training on worker :894
INFO:root:FL Epoch: 690 Using Learning rate : 0.012586731018999079 
INFO:root:FL Epoch: 690 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451902
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439097
INFO:root:FL Epoch: 690 Norm Difference for worker 894 is 0.767595
INFO:root:FL Epoch: 690 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 690 Training on worker :738
INFO:root:FL Epoch: 690 Using Learning rate : 0.012586731018999079 
INFO:root:FL Epoch: 690 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600473
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606968
INFO:root:FL Epoch: 690 Norm Difference for worker 738 is 0.830752
INFO:root:FL Epoch: 690 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 690 Training on worker :923
INFO:root:FL Epoch: 690 Using Learning rate : 0.012586731018999079 
INFO:root:FL Epoch: 690 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323386
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.171634
INFO:root:FL Epoch: 690 Norm Difference for worker 923 is 0.769186
INFO:root:FL Epoch: 690 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 690 Training on worker :1701
INFO:root:FL Epoch: 690 Using Learning rate : 0.012586731018999079 
INFO:root:FL Epoch: 690 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405725
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381047
INFO:root:FL Epoch: 690 Norm Difference for worker 1701 is 0.782341
INFO:root:FL Epoch: 690 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 690 Training on worker :1105
INFO:root:FL Epoch: 690 Using Learning rate : 0.012586731018999079 
INFO:root:FL Epoch: 690 Normal Training
INFO:root:Worker: 1105 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358650
INFO:root:Worker: 1105 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383095
INFO:root:FL Epoch: 690 Norm Difference for worker 1105 is 0.742313
INFO:root:FL Epoch: 690 Done on worker:1105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 690 Training on worker :182
INFO:root:FL Epoch: 690 Using Learning rate : 0.012586731018999079 
INFO:root:FL Epoch: 690 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.615158
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.430602
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 690 Norm Difference for worker 182 is 0.802599
INFO:root:FL Epoch: 690 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 690 Training on worker :95
INFO:root:FL Epoch: 690 Using Learning rate : 0.012586731018999079 
INFO:root:FL Epoch: 690 Normal Training
INFO:root:Worker: 95 Train Epoch: 0 [0/201 (0%)]	Loss: 0.377438
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 95 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505584
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 690 Norm Difference for worker 95 is 0.785038
INFO:root:FL Epoch: 690 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1105
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 690 Ends   ===================
INFO:root:Epoch:690 Global Model Test Loss:0.5296310274039998 and Test Accuracy:75.0 
INFO:root:Epoch:690 Global Model Backdoor Test Loss:0.1417666350801786                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 691 Begins ===================
INFO:root:FL Epoch: 691 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 691 Workers Selected : [0, 1, 2, 1088, 523, 382, 1677, 98, 89, 290]
INFO:root:FL Epoch: 691 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 691 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 691 Training on worker :0
INFO:root:FL Epoch: 691 Using Learning rate : 0.002512311511392216 
INFO:root:FL Epoch: 691 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.112584
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.083296
INFO:root:FL Epoch: 691 Worker: 0 Backdoor Test Loss: 0.12218350420395534 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 691 Worker: 0 Backdoor Train Loss: 0.08094528093934059 Backdoor Train Accuracy: 99.5
INFO:root:FL Epoch: 691 Norm Difference for worker 0 is 0.067373
INFO:root:FL Epoch: 691 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 691 Training on worker :1
INFO:root:FL Epoch: 691 Using Learning rate : 0.002512311511392216 
INFO:root:FL Epoch: 691 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.130271
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.059138
INFO:root:FL Epoch: 691 Worker: 1 Backdoor Test Loss: 0.12358826957643032 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 691 Worker: 1 Backdoor Train Loss: 0.08184445984661579 Backdoor Train Accuracy: 99.0
INFO:root:FL Epoch: 691 Norm Difference for worker 1 is 0.062293
INFO:root:FL Epoch: 691 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 691 Training on worker :2
INFO:root:FL Epoch: 691 Using Learning rate : 0.002512311511392216 
INFO:root:FL Epoch: 691 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.073004
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.103737
INFO:root:FL Epoch: 691 Worker: 2 Backdoor Test Loss: 0.12335247918963432 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 691 Worker: 2 Backdoor Train Loss: 0.08150005415081978 Backdoor Train Accuracy: 100.0
INFO:root:FL Epoch: 691 Norm Difference for worker 2 is 0.062928
INFO:root:FL Epoch: 691 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 691 Training on worker :1088
INFO:root:FL Epoch: 691 Using Learning rate : 0.012561557556961082 
INFO:root:FL Epoch: 691 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521824
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215233
INFO:root:FL Epoch: 691 Norm Difference for worker 1088 is 0.623513
INFO:root:FL Epoch: 691 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 691 Training on worker :523
INFO:root:FL Epoch: 691 Using Learning rate : 0.012561557556961082 
INFO:root:FL Epoch: 691 Normal Training
INFO:root:Worker: 523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669781
INFO:root:Worker: 523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456097
INFO:root:FL Epoch: 691 Norm Difference for worker 523 is 0.768065
INFO:root:FL Epoch: 691 Done on worker:523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 691 Training on worker :382
INFO:root:FL Epoch: 691 Using Learning rate : 0.012561557556961082 
INFO:root:FL Epoch: 691 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652307
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407202
INFO:root:FL Epoch: 691 Norm Difference for worker 382 is 0.765956
INFO:root:FL Epoch: 691 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 691 Training on worker :1677
INFO:root:FL Epoch: 691 Using Learning rate : 0.012561557556961082 
INFO:root:FL Epoch: 691 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496587
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580028
INFO:root:FL Epoch: 691 Norm Difference for worker 1677 is 0.679248
INFO:root:FL Epoch: 691 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 691 Training on worker :98
INFO:root:FL Epoch: 691 Using Learning rate : 0.012561557556961082 
INFO:root:FL Epoch: 691 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.433634
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.714314
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 691 Norm Difference for worker 98 is 0.73421
INFO:root:FL Epoch: 691 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 691 Training on worker :89
INFO:root:FL Epoch: 691 Using Learning rate : 0.012561557556961082 
INFO:root:FL Epoch: 691 Normal Training
INFO:root:Worker: 89 Train Epoch: 0 [0/201 (0%)]	Loss: 0.650723
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 89 Train Epoch: 1 [0/201 (0%)]	Loss: 0.241293
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 691 Norm Difference for worker 89 is 0.760135
INFO:root:FL Epoch: 691 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 691 Training on worker :290
INFO:root:FL Epoch: 691 Using Learning rate : 0.012561557556961082 
INFO:root:FL Epoch: 691 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.900881
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.593163
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 691 Norm Difference for worker 290 is 0.736225
INFO:root:FL Epoch: 691 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 691 Ends   ===================
INFO:root:Epoch:691 Global Model Test Loss:0.5270420172635246 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:691 Global Model Backdoor Test Loss:0.12335247918963432                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 692 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 692 Workers Selected : [331, 1080, 1356, 698, 1944, 796, 259, 384, 392, 19]
INFO:root:FL Epoch: 692 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 692 Num points on workers: [201 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 692 Training on worker :331
INFO:root:FL Epoch: 692 Using Learning rate : 0.012536434441847159 
INFO:root:FL Epoch: 692 Normal Training
INFO:root:Worker: 331 Train Epoch: 0 [0/201 (0%)]	Loss: 0.717991
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 331 Train Epoch: 1 [0/201 (0%)]	Loss: 0.555297
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 692 Norm Difference for worker 331 is 0.780613
INFO:root:FL Epoch: 692 Done on worker:331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 692 Training on worker :1080
INFO:root:FL Epoch: 692 Using Learning rate : 0.012536434441847159 
INFO:root:FL Epoch: 692 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425211
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428730
INFO:root:FL Epoch: 692 Norm Difference for worker 1080 is 0.788371
INFO:root:FL Epoch: 692 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 692 Training on worker :1356
INFO:root:FL Epoch: 692 Using Learning rate : 0.012536434441847159 
INFO:root:FL Epoch: 692 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.909745
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668851
INFO:root:FL Epoch: 692 Norm Difference for worker 1356 is 0.819833
INFO:root:FL Epoch: 692 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 692 Training on worker :698
INFO:root:FL Epoch: 692 Using Learning rate : 0.012536434441847159 
INFO:root:FL Epoch: 692 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637683
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320000
INFO:root:FL Epoch: 692 Norm Difference for worker 698 is 0.717035
INFO:root:FL Epoch: 692 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 692 Training on worker :1944
INFO:root:FL Epoch: 692 Using Learning rate : 0.012536434441847159 
INFO:root:FL Epoch: 692 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527897
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346647
INFO:root:FL Epoch: 692 Norm Difference for worker 1944 is 0.712121
INFO:root:FL Epoch: 692 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 692 Training on worker :796
INFO:root:FL Epoch: 692 Using Learning rate : 0.012536434441847159 
INFO:root:FL Epoch: 692 Normal Training
INFO:root:Worker: 796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623141
INFO:root:Worker: 796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633217
INFO:root:FL Epoch: 692 Norm Difference for worker 796 is 0.733078
INFO:root:FL Epoch: 692 Done on worker:796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 692 Training on worker :259
INFO:root:FL Epoch: 692 Using Learning rate : 0.012536434441847159 
INFO:root:FL Epoch: 692 Normal Training
INFO:root:Worker: 259 Train Epoch: 0 [0/201 (0%)]	Loss: 0.559162
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 259 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691339
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 692 Norm Difference for worker 259 is 0.797765
INFO:root:FL Epoch: 692 Done on worker:259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 692 Training on worker :384
INFO:root:FL Epoch: 692 Using Learning rate : 0.012536434441847159 
INFO:root:FL Epoch: 692 Normal Training
INFO:root:Worker: 384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638079
INFO:root:Worker: 384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449973
INFO:root:FL Epoch: 692 Norm Difference for worker 384 is 0.743097
INFO:root:FL Epoch: 692 Done on worker:384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 692 Training on worker :392
INFO:root:FL Epoch: 692 Using Learning rate : 0.012536434441847159 
INFO:root:FL Epoch: 692 Normal Training
INFO:root:Worker: 392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735482
INFO:root:Worker: 392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.788557
INFO:root:FL Epoch: 692 Norm Difference for worker 392 is 0.667895
INFO:root:FL Epoch: 692 Done on worker:392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 692 Training on worker :19
INFO:root:FL Epoch: 692 Using Learning rate : 0.012536434441847159 
INFO:root:FL Epoch: 692 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.501286
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.371633
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 692 Norm Difference for worker 19 is 0.620315
INFO:root:FL Epoch: 692 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 19
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 692 Ends   ===================
INFO:root:Epoch:692 Global Model Test Loss:0.5005991704323712 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:692 Global Model Backdoor Test Loss:0.0868914828946193                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 693 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 693 Workers Selected : [1392, 707, 927, 1825, 923, 1449, 169, 1319, 496, 681]
INFO:root:FL Epoch: 693 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 693 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 693 Training on worker :1392
INFO:root:FL Epoch: 693 Using Learning rate : 0.012511361572963465 
INFO:root:FL Epoch: 693 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654324
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353162
INFO:root:FL Epoch: 693 Norm Difference for worker 1392 is 0.657015
INFO:root:FL Epoch: 693 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 693 Training on worker :707
INFO:root:FL Epoch: 693 Using Learning rate : 0.012511361572963465 
INFO:root:FL Epoch: 693 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371655
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351081
INFO:root:FL Epoch: 693 Norm Difference for worker 707 is 0.680861
INFO:root:FL Epoch: 693 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 693 Training on worker :927
INFO:root:FL Epoch: 693 Using Learning rate : 0.012511361572963465 
INFO:root:FL Epoch: 693 Normal Training
INFO:root:Worker: 927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.274629
INFO:root:Worker: 927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247015
INFO:root:FL Epoch: 693 Norm Difference for worker 927 is 0.598688
INFO:root:FL Epoch: 693 Done on worker:927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 693 Training on worker :1825
INFO:root:FL Epoch: 693 Using Learning rate : 0.012511361572963465 
INFO:root:FL Epoch: 693 Normal Training
INFO:root:Worker: 1825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484975
INFO:root:Worker: 1825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.738844
INFO:root:FL Epoch: 693 Norm Difference for worker 1825 is 0.767196
INFO:root:FL Epoch: 693 Done on worker:1825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 693 Training on worker :923
INFO:root:FL Epoch: 693 Using Learning rate : 0.012511361572963465 
INFO:root:FL Epoch: 693 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592052
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339143
INFO:root:FL Epoch: 693 Norm Difference for worker 923 is 0.765788
INFO:root:FL Epoch: 693 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 693 Training on worker :1449
INFO:root:FL Epoch: 693 Using Learning rate : 0.012511361572963465 
INFO:root:FL Epoch: 693 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781459
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532718
INFO:root:FL Epoch: 693 Norm Difference for worker 1449 is 0.800202
INFO:root:FL Epoch: 693 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 693 Training on worker :169
INFO:root:FL Epoch: 693 Using Learning rate : 0.012511361572963465 
INFO:root:FL Epoch: 693 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.300749
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.245906
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 693 Norm Difference for worker 169 is 0.691006
INFO:root:FL Epoch: 693 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 693 Training on worker :1319
INFO:root:FL Epoch: 693 Using Learning rate : 0.012511361572963465 
INFO:root:FL Epoch: 693 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.259122
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551620
INFO:root:FL Epoch: 693 Norm Difference for worker 1319 is 0.707905
INFO:root:FL Epoch: 693 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 693 Training on worker :496
INFO:root:FL Epoch: 693 Using Learning rate : 0.012511361572963465 
INFO:root:FL Epoch: 693 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580249
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.833015
INFO:root:FL Epoch: 693 Norm Difference for worker 496 is 0.667106
INFO:root:FL Epoch: 693 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 693 Training on worker :681
INFO:root:FL Epoch: 693 Using Learning rate : 0.012511361572963465 
INFO:root:FL Epoch: 693 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.298248
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617267
INFO:root:FL Epoch: 693 Norm Difference for worker 681 is 0.739954
INFO:root:FL Epoch: 693 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 927
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 693 Ends   ===================
INFO:root:Epoch:693 Global Model Test Loss:0.5107029781622046 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:693 Global Model Backdoor Test Loss:0.08920314597586791                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 694 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 694 Workers Selected : [999, 311, 1767, 1021, 1187, 1460, 822, 1804, 711, 228]
INFO:root:FL Epoch: 694 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 694 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 694 Training on worker :999
INFO:root:FL Epoch: 694 Using Learning rate : 0.012486338849817537 
INFO:root:FL Epoch: 694 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695352
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259535
INFO:root:FL Epoch: 694 Norm Difference for worker 999 is 0.736669
INFO:root:FL Epoch: 694 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 694 Training on worker :311
INFO:root:FL Epoch: 694 Using Learning rate : 0.012486338849817537 
INFO:root:FL Epoch: 694 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.379544
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.480047
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 694 Norm Difference for worker 311 is 0.700768
INFO:root:FL Epoch: 694 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 694 Training on worker :1767
INFO:root:FL Epoch: 694 Using Learning rate : 0.012486338849817537 
INFO:root:FL Epoch: 694 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401698
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263525
INFO:root:FL Epoch: 694 Norm Difference for worker 1767 is 0.709521
INFO:root:FL Epoch: 694 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 694 Training on worker :1021
INFO:root:FL Epoch: 694 Using Learning rate : 0.012486338849817537 
INFO:root:FL Epoch: 694 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733878
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552191
INFO:root:FL Epoch: 694 Norm Difference for worker 1021 is 0.706237
INFO:root:FL Epoch: 694 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 694 Training on worker :1187
INFO:root:FL Epoch: 694 Using Learning rate : 0.012486338849817537 
INFO:root:FL Epoch: 694 Normal Training
INFO:root:Worker: 1187 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552564
INFO:root:Worker: 1187 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573314
INFO:root:FL Epoch: 694 Norm Difference for worker 1187 is 0.637983
INFO:root:FL Epoch: 694 Done on worker:1187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 694 Training on worker :1460
INFO:root:FL Epoch: 694 Using Learning rate : 0.012486338849817537 
INFO:root:FL Epoch: 694 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.124069
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.113873
INFO:root:FL Epoch: 694 Norm Difference for worker 1460 is 0.442715
INFO:root:FL Epoch: 694 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 694 Training on worker :822
INFO:root:FL Epoch: 694 Using Learning rate : 0.012486338849817537 
INFO:root:FL Epoch: 694 Normal Training
INFO:root:Worker: 822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459018
INFO:root:Worker: 822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419033
INFO:root:FL Epoch: 694 Norm Difference for worker 822 is 0.660849
INFO:root:FL Epoch: 694 Done on worker:822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 694 Training on worker :1804
INFO:root:FL Epoch: 694 Using Learning rate : 0.012486338849817537 
INFO:root:FL Epoch: 694 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690669
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391436
INFO:root:FL Epoch: 694 Norm Difference for worker 1804 is 0.754188
INFO:root:FL Epoch: 694 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 694 Training on worker :711
INFO:root:FL Epoch: 694 Using Learning rate : 0.012486338849817537 
INFO:root:FL Epoch: 694 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503482
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485290
INFO:root:FL Epoch: 694 Norm Difference for worker 711 is 0.689173
INFO:root:FL Epoch: 694 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 694 Training on worker :228
INFO:root:FL Epoch: 694 Using Learning rate : 0.012486338849817537 
INFO:root:FL Epoch: 694 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.259862
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446515
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 694 Norm Difference for worker 228 is 0.571797
INFO:root:FL Epoch: 694 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1460
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 694 Ends   ===================
INFO:root:Epoch:694 Global Model Test Loss:0.5162798709729138 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:694 Global Model Backdoor Test Loss:0.06664365033308665                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 695 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 695 Workers Selected : [780, 63, 1298, 1777, 1947, 227, 1603, 1502, 1894, 1344]
INFO:root:FL Epoch: 695 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 695 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 695 Training on worker :780
INFO:root:FL Epoch: 695 Using Learning rate : 0.012461366172117903 
INFO:root:FL Epoch: 695 Normal Training
INFO:root:Worker: 780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392154
INFO:root:Worker: 780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238600
INFO:root:FL Epoch: 695 Norm Difference for worker 780 is 0.744175
INFO:root:FL Epoch: 695 Done on worker:780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 695 Training on worker :63
INFO:root:FL Epoch: 695 Using Learning rate : 0.012461366172117903 
INFO:root:FL Epoch: 695 Normal Training
INFO:root:Worker: 63 Train Epoch: 0 [0/201 (0%)]	Loss: 0.785185
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 63 Train Epoch: 1 [0/201 (0%)]	Loss: 0.513003
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 695 Norm Difference for worker 63 is 0.887603
INFO:root:FL Epoch: 695 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 695 Training on worker :1298
INFO:root:FL Epoch: 695 Using Learning rate : 0.012461366172117903 
INFO:root:FL Epoch: 695 Normal Training
INFO:root:Worker: 1298 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547383
INFO:root:Worker: 1298 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535085
INFO:root:FL Epoch: 695 Norm Difference for worker 1298 is 0.697968
INFO:root:FL Epoch: 695 Done on worker:1298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 695 Training on worker :1777
INFO:root:FL Epoch: 695 Using Learning rate : 0.012461366172117903 
INFO:root:FL Epoch: 695 Normal Training
INFO:root:Worker: 1777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351901
INFO:root:Worker: 1777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607371
INFO:root:FL Epoch: 695 Norm Difference for worker 1777 is 0.763711
INFO:root:FL Epoch: 695 Done on worker:1777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 695 Training on worker :1947
INFO:root:FL Epoch: 695 Using Learning rate : 0.012461366172117903 
INFO:root:FL Epoch: 695 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480997
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254542
INFO:root:FL Epoch: 695 Norm Difference for worker 1947 is 0.439195
INFO:root:FL Epoch: 695 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 695 Training on worker :227
INFO:root:FL Epoch: 695 Using Learning rate : 0.012461366172117903 
INFO:root:FL Epoch: 695 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699232
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.557205
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 695 Norm Difference for worker 227 is 0.713768
INFO:root:FL Epoch: 695 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 695 Training on worker :1603
INFO:root:FL Epoch: 695 Using Learning rate : 0.012461366172117903 
INFO:root:FL Epoch: 695 Normal Training
INFO:root:Worker: 1603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.196172
INFO:root:Worker: 1603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.102880
INFO:root:FL Epoch: 695 Norm Difference for worker 1603 is 0.73714
INFO:root:FL Epoch: 695 Done on worker:1603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 695 Training on worker :1502
INFO:root:FL Epoch: 695 Using Learning rate : 0.012461366172117903 
INFO:root:FL Epoch: 695 Normal Training
INFO:root:Worker: 1502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.181847
INFO:root:Worker: 1502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440451
INFO:root:FL Epoch: 695 Norm Difference for worker 1502 is 0.696626
INFO:root:FL Epoch: 695 Done on worker:1502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 695 Training on worker :1894
INFO:root:FL Epoch: 695 Using Learning rate : 0.012461366172117903 
INFO:root:FL Epoch: 695 Normal Training
INFO:root:Worker: 1894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.293346
INFO:root:Worker: 1894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488135
INFO:root:FL Epoch: 695 Norm Difference for worker 1894 is 0.794699
INFO:root:FL Epoch: 695 Done on worker:1894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 695 Training on worker :1344
INFO:root:FL Epoch: 695 Using Learning rate : 0.012461366172117903 
INFO:root:FL Epoch: 695 Normal Training
INFO:root:Worker: 1344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605499
INFO:root:Worker: 1344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577603
INFO:root:FL Epoch: 695 Norm Difference for worker 1344 is 0.808893
INFO:root:FL Epoch: 695 Done on worker:1344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1947
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 695 Ends   ===================
INFO:root:Epoch:695 Global Model Test Loss:0.518174955073525 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:695 Global Model Backdoor Test Loss:0.06094330114622911                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 696 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 696 Workers Selected : [83, 593, 676, 1241, 405, 1473, 912, 335, 726, 15]
INFO:root:FL Epoch: 696 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 696 Num points on workers: [201 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 696 Training on worker :83
INFO:root:FL Epoch: 696 Using Learning rate : 0.012436443439773667 
INFO:root:FL Epoch: 696 Normal Training
INFO:root:Worker: 83 Train Epoch: 0 [0/201 (0%)]	Loss: 0.613359
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 83 Train Epoch: 1 [0/201 (0%)]	Loss: 0.411718
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 696 Norm Difference for worker 83 is 0.862645
INFO:root:FL Epoch: 696 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 696 Training on worker :593
INFO:root:FL Epoch: 696 Using Learning rate : 0.012436443439773667 
INFO:root:FL Epoch: 696 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464775
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645347
INFO:root:FL Epoch: 696 Norm Difference for worker 593 is 0.869406
INFO:root:FL Epoch: 696 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 696 Training on worker :676
INFO:root:FL Epoch: 696 Using Learning rate : 0.012436443439773667 
INFO:root:FL Epoch: 696 Normal Training
INFO:root:Worker: 676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670002
INFO:root:Worker: 676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512846
INFO:root:FL Epoch: 696 Norm Difference for worker 676 is 0.87137
INFO:root:FL Epoch: 696 Done on worker:676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 696 Training on worker :1241
INFO:root:FL Epoch: 696 Using Learning rate : 0.012436443439773667 
INFO:root:FL Epoch: 696 Normal Training
INFO:root:Worker: 1241 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745694
INFO:root:Worker: 1241 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378477
INFO:root:FL Epoch: 696 Norm Difference for worker 1241 is 0.696908
INFO:root:FL Epoch: 696 Done on worker:1241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 696 Training on worker :405
INFO:root:FL Epoch: 696 Using Learning rate : 0.012436443439773667 
INFO:root:FL Epoch: 696 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514721
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333057
INFO:root:FL Epoch: 696 Norm Difference for worker 405 is 0.80835
INFO:root:FL Epoch: 696 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 696 Training on worker :1473
INFO:root:FL Epoch: 696 Using Learning rate : 0.012436443439773667 
INFO:root:FL Epoch: 696 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.809335
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530451
INFO:root:FL Epoch: 696 Norm Difference for worker 1473 is 0.947268
INFO:root:FL Epoch: 696 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 696 Training on worker :912
INFO:root:FL Epoch: 696 Using Learning rate : 0.012436443439773667 
INFO:root:FL Epoch: 696 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665264
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541959
INFO:root:FL Epoch: 696 Norm Difference for worker 912 is 0.800553
INFO:root:FL Epoch: 696 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 696 Training on worker :335
INFO:root:FL Epoch: 696 Using Learning rate : 0.012436443439773667 
INFO:root:FL Epoch: 696 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.953128
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.305804
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 696 Norm Difference for worker 335 is 0.777525
INFO:root:FL Epoch: 696 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 696 Training on worker :726
INFO:root:FL Epoch: 696 Using Learning rate : 0.012436443439773667 
INFO:root:FL Epoch: 696 Normal Training
INFO:root:Worker: 726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520057
INFO:root:Worker: 726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637129
INFO:root:FL Epoch: 696 Norm Difference for worker 726 is 0.834204
INFO:root:FL Epoch: 696 Done on worker:726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 696 Training on worker :15
INFO:root:FL Epoch: 696 Using Learning rate : 0.012436443439773667 
INFO:root:FL Epoch: 696 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.455294
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.171087
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 696 Norm Difference for worker 15 is 0.758301
INFO:root:FL Epoch: 696 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1241
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 696 Ends   ===================
INFO:root:Epoch:696 Global Model Test Loss:0.5153668610488668 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:696 Global Model Backdoor Test Loss:0.0713363653048873                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 697 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 697 Workers Selected : [733, 220, 907, 1530, 605, 307, 873, 1496, 391, 607]
INFO:root:FL Epoch: 697 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 697 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 697 Training on worker :733
INFO:root:FL Epoch: 697 Using Learning rate : 0.01241157055289412 
INFO:root:FL Epoch: 697 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506336
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378009
INFO:root:FL Epoch: 697 Norm Difference for worker 733 is 0.828203
INFO:root:FL Epoch: 697 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 697 Training on worker :220
INFO:root:FL Epoch: 697 Using Learning rate : 0.01241157055289412 
INFO:root:FL Epoch: 697 Normal Training
INFO:root:Worker: 220 Train Epoch: 0 [0/201 (0%)]	Loss: 0.410958
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 220 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505348
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 697 Norm Difference for worker 220 is 0.719952
INFO:root:FL Epoch: 697 Done on worker:220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 697 Training on worker :907
INFO:root:FL Epoch: 697 Using Learning rate : 0.01241157055289412 
INFO:root:FL Epoch: 697 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517415
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.748181
INFO:root:FL Epoch: 697 Norm Difference for worker 907 is 0.860257
INFO:root:FL Epoch: 697 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 697 Training on worker :1530
INFO:root:FL Epoch: 697 Using Learning rate : 0.01241157055289412 
INFO:root:FL Epoch: 697 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577989
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 1.004287
INFO:root:FL Epoch: 697 Norm Difference for worker 1530 is 0.817719
INFO:root:FL Epoch: 697 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 697 Training on worker :605
INFO:root:FL Epoch: 697 Using Learning rate : 0.01241157055289412 
INFO:root:FL Epoch: 697 Normal Training
INFO:root:Worker: 605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.857890
INFO:root:Worker: 605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369315
INFO:root:FL Epoch: 697 Norm Difference for worker 605 is 0.770923
INFO:root:FL Epoch: 697 Done on worker:605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 697 Training on worker :307
INFO:root:FL Epoch: 697 Using Learning rate : 0.01241157055289412 
INFO:root:FL Epoch: 697 Normal Training
INFO:root:Worker: 307 Train Epoch: 0 [0/201 (0%)]	Loss: 0.700476
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 307 Train Epoch: 1 [0/201 (0%)]	Loss: 0.613558
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 697 Norm Difference for worker 307 is 0.820218
INFO:root:FL Epoch: 697 Done on worker:307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 697 Training on worker :873
INFO:root:FL Epoch: 697 Using Learning rate : 0.01241157055289412 
INFO:root:FL Epoch: 697 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740440
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400806
INFO:root:FL Epoch: 697 Norm Difference for worker 873 is 0.870661
INFO:root:FL Epoch: 697 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 697 Training on worker :1496
INFO:root:FL Epoch: 697 Using Learning rate : 0.01241157055289412 
INFO:root:FL Epoch: 697 Normal Training
INFO:root:Worker: 1496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.946975
INFO:root:Worker: 1496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457596
INFO:root:FL Epoch: 697 Norm Difference for worker 1496 is 0.814606
INFO:root:FL Epoch: 697 Done on worker:1496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 697 Training on worker :391
INFO:root:FL Epoch: 697 Using Learning rate : 0.01241157055289412 
INFO:root:FL Epoch: 697 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387681
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192696
INFO:root:FL Epoch: 697 Norm Difference for worker 391 is 0.776696
INFO:root:FL Epoch: 697 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 697 Training on worker :607
INFO:root:FL Epoch: 697 Using Learning rate : 0.01241157055289412 
INFO:root:FL Epoch: 697 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573718
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351637
INFO:root:FL Epoch: 697 Norm Difference for worker 607 is 0.782583
INFO:root:FL Epoch: 697 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 220
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 697 Ends   ===================
INFO:root:Epoch:697 Global Model Test Loss:0.5265200856853934 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:697 Global Model Backdoor Test Loss:0.0896832247575124                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 698 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 698 Workers Selected : [1400, 441, 67, 585, 632, 280, 890, 1637, 897, 1319]
INFO:root:FL Epoch: 698 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 698 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 698 Training on worker :1400
INFO:root:FL Epoch: 698 Using Learning rate : 0.012386747411788331 
INFO:root:FL Epoch: 698 Normal Training
INFO:root:Worker: 1400 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450191
INFO:root:Worker: 1400 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415231
INFO:root:FL Epoch: 698 Norm Difference for worker 1400 is 0.668571
INFO:root:FL Epoch: 698 Done on worker:1400
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 698 Training on worker :441
INFO:root:FL Epoch: 698 Using Learning rate : 0.012386747411788331 
INFO:root:FL Epoch: 698 Normal Training
INFO:root:Worker: 441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597466
INFO:root:Worker: 441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.769082
INFO:root:FL Epoch: 698 Norm Difference for worker 441 is 0.796094
INFO:root:FL Epoch: 698 Done on worker:441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 698 Training on worker :67
INFO:root:FL Epoch: 698 Using Learning rate : 0.012386747411788331 
INFO:root:FL Epoch: 698 Normal Training
INFO:root:Worker: 67 Train Epoch: 0 [0/201 (0%)]	Loss: 0.750826
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 67 Train Epoch: 1 [0/201 (0%)]	Loss: 0.537166
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 698 Norm Difference for worker 67 is 0.717197
INFO:root:FL Epoch: 698 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 698 Training on worker :585
INFO:root:FL Epoch: 698 Using Learning rate : 0.012386747411788331 
INFO:root:FL Epoch: 698 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321778
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596902
INFO:root:FL Epoch: 698 Norm Difference for worker 585 is 0.731103
INFO:root:FL Epoch: 698 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 698 Training on worker :632
INFO:root:FL Epoch: 698 Using Learning rate : 0.012386747411788331 
INFO:root:FL Epoch: 698 Normal Training
INFO:root:Worker: 632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681441
INFO:root:Worker: 632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691992
INFO:root:FL Epoch: 698 Norm Difference for worker 632 is 0.686239
INFO:root:FL Epoch: 698 Done on worker:632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 698 Training on worker :280
INFO:root:FL Epoch: 698 Using Learning rate : 0.012386747411788331 
INFO:root:FL Epoch: 698 Normal Training
INFO:root:Worker: 280 Train Epoch: 0 [0/201 (0%)]	Loss: 0.660425
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 280 Train Epoch: 1 [0/201 (0%)]	Loss: 0.585655
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 698 Norm Difference for worker 280 is 0.631678
INFO:root:FL Epoch: 698 Done on worker:280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 698 Training on worker :890
INFO:root:FL Epoch: 698 Using Learning rate : 0.012386747411788331 
INFO:root:FL Epoch: 698 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472622
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487096
INFO:root:FL Epoch: 698 Norm Difference for worker 890 is 0.727901
INFO:root:FL Epoch: 698 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 698 Training on worker :1637
INFO:root:FL Epoch: 698 Using Learning rate : 0.012386747411788331 
INFO:root:FL Epoch: 698 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525292
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423274
INFO:root:FL Epoch: 698 Norm Difference for worker 1637 is 0.685954
INFO:root:FL Epoch: 698 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 698 Training on worker :897
INFO:root:FL Epoch: 698 Using Learning rate : 0.012386747411788331 
INFO:root:FL Epoch: 698 Normal Training
INFO:root:Worker: 897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747690
INFO:root:Worker: 897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503980
INFO:root:FL Epoch: 698 Norm Difference for worker 897 is 0.725216
INFO:root:FL Epoch: 698 Done on worker:897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 698 Training on worker :1319
INFO:root:FL Epoch: 698 Using Learning rate : 0.012386747411788331 
INFO:root:FL Epoch: 698 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368422
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506987
INFO:root:FL Epoch: 698 Norm Difference for worker 1319 is 0.696399
INFO:root:FL Epoch: 698 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 280
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 698 Ends   ===================
INFO:root:Epoch:698 Global Model Test Loss:0.5166223014102262 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:698 Global Model Backdoor Test Loss:0.09214538397888343                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 699 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 699 Workers Selected : [1014, 1779, 1466, 1440, 1234, 808, 479, 1215, 188, 1752]
INFO:root:FL Epoch: 699 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 699 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 699 Training on worker :1014
INFO:root:FL Epoch: 699 Using Learning rate : 0.012361973916964754 
INFO:root:FL Epoch: 699 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486535
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702873
INFO:root:FL Epoch: 699 Norm Difference for worker 1014 is 0.663119
INFO:root:FL Epoch: 699 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 699 Training on worker :1779
INFO:root:FL Epoch: 699 Using Learning rate : 0.012361973916964754 
INFO:root:FL Epoch: 699 Normal Training
INFO:root:Worker: 1779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617757
INFO:root:Worker: 1779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296752
INFO:root:FL Epoch: 699 Norm Difference for worker 1779 is 0.665838
INFO:root:FL Epoch: 699 Done on worker:1779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 699 Training on worker :1466
INFO:root:FL Epoch: 699 Using Learning rate : 0.012361973916964754 
INFO:root:FL Epoch: 699 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746356
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462344
INFO:root:FL Epoch: 699 Norm Difference for worker 1466 is 0.708553
INFO:root:FL Epoch: 699 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 699 Training on worker :1440
INFO:root:FL Epoch: 699 Using Learning rate : 0.012361973916964754 
INFO:root:FL Epoch: 699 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436217
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628897
INFO:root:FL Epoch: 699 Norm Difference for worker 1440 is 0.644772
INFO:root:FL Epoch: 699 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 699 Training on worker :1234
INFO:root:FL Epoch: 699 Using Learning rate : 0.012361973916964754 
INFO:root:FL Epoch: 699 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756138
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343476
INFO:root:FL Epoch: 699 Norm Difference for worker 1234 is 0.721503
INFO:root:FL Epoch: 699 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 699 Training on worker :808
INFO:root:FL Epoch: 699 Using Learning rate : 0.012361973916964754 
INFO:root:FL Epoch: 699 Normal Training
INFO:root:Worker: 808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579588
INFO:root:Worker: 808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412932
INFO:root:FL Epoch: 699 Norm Difference for worker 808 is 0.658469
INFO:root:FL Epoch: 699 Done on worker:808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 699 Training on worker :479
INFO:root:FL Epoch: 699 Using Learning rate : 0.012361973916964754 
INFO:root:FL Epoch: 699 Normal Training
INFO:root:Worker: 479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459677
INFO:root:Worker: 479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559681
INFO:root:FL Epoch: 699 Norm Difference for worker 479 is 0.716151
INFO:root:FL Epoch: 699 Done on worker:479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 699 Training on worker :1215
INFO:root:FL Epoch: 699 Using Learning rate : 0.012361973916964754 
INFO:root:FL Epoch: 699 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449702
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359448
INFO:root:FL Epoch: 699 Norm Difference for worker 1215 is 0.709407
INFO:root:FL Epoch: 699 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 699 Training on worker :188
INFO:root:FL Epoch: 699 Using Learning rate : 0.012361973916964754 
INFO:root:FL Epoch: 699 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.271590
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.433010
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 699 Norm Difference for worker 188 is 0.66056
INFO:root:FL Epoch: 699 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 699 Training on worker :1752
INFO:root:FL Epoch: 699 Using Learning rate : 0.012361973916964754 
INFO:root:FL Epoch: 699 Normal Training
INFO:root:Worker: 1752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349654
INFO:root:Worker: 1752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604003
INFO:root:FL Epoch: 699 Norm Difference for worker 1752 is 0.611571
INFO:root:FL Epoch: 699 Done on worker:1752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1752
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 699 Ends   ===================
INFO:root:Epoch:699 Global Model Test Loss:0.5196209637557759 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:699 Global Model Backdoor Test Loss:0.07889827713370323                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 700 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 700 Workers Selected : [465, 1676, 1137, 1286, 1292, 469, 679, 551, 1025, 1649]
INFO:root:FL Epoch: 700 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 700 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 700 Training on worker :465
INFO:root:FL Epoch: 700 Using Learning rate : 0.012337249969130826 
INFO:root:FL Epoch: 700 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461287
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622293
INFO:root:FL Epoch: 700 Norm Difference for worker 465 is 0.667814
INFO:root:FL Epoch: 700 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 700 Training on worker :1676
INFO:root:FL Epoch: 700 Using Learning rate : 0.012337249969130826 
INFO:root:FL Epoch: 700 Normal Training
INFO:root:Worker: 1676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611228
INFO:root:Worker: 1676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411027
INFO:root:FL Epoch: 700 Norm Difference for worker 1676 is 0.684606
INFO:root:FL Epoch: 700 Done on worker:1676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 700 Training on worker :1137
INFO:root:FL Epoch: 700 Using Learning rate : 0.012337249969130826 
INFO:root:FL Epoch: 700 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.850440
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365039
INFO:root:FL Epoch: 700 Norm Difference for worker 1137 is 0.669956
INFO:root:FL Epoch: 700 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 700 Training on worker :1286
INFO:root:FL Epoch: 700 Using Learning rate : 0.012337249969130826 
INFO:root:FL Epoch: 700 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503851
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522103
INFO:root:FL Epoch: 700 Norm Difference for worker 1286 is 0.652713
INFO:root:FL Epoch: 700 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 700 Training on worker :1292
INFO:root:FL Epoch: 700 Using Learning rate : 0.012337249969130826 
INFO:root:FL Epoch: 700 Normal Training
INFO:root:Worker: 1292 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634617
INFO:root:Worker: 1292 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387951
INFO:root:FL Epoch: 700 Norm Difference for worker 1292 is 0.694348
INFO:root:FL Epoch: 700 Done on worker:1292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 700 Training on worker :469
INFO:root:FL Epoch: 700 Using Learning rate : 0.012337249969130826 
INFO:root:FL Epoch: 700 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708213
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351740
INFO:root:FL Epoch: 700 Norm Difference for worker 469 is 0.652438
INFO:root:FL Epoch: 700 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 700 Training on worker :679
INFO:root:FL Epoch: 700 Using Learning rate : 0.012337249969130826 
INFO:root:FL Epoch: 700 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646632
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493988
INFO:root:FL Epoch: 700 Norm Difference for worker 679 is 0.642821
INFO:root:FL Epoch: 700 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 700 Training on worker :551
INFO:root:FL Epoch: 700 Using Learning rate : 0.012337249969130826 
INFO:root:FL Epoch: 700 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353936
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584604
INFO:root:FL Epoch: 700 Norm Difference for worker 551 is 0.646332
INFO:root:FL Epoch: 700 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 700 Training on worker :1025
INFO:root:FL Epoch: 700 Using Learning rate : 0.012337249969130826 
INFO:root:FL Epoch: 700 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572285
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374925
INFO:root:FL Epoch: 700 Norm Difference for worker 1025 is 0.691283
INFO:root:FL Epoch: 700 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 700 Training on worker :1649
INFO:root:FL Epoch: 700 Using Learning rate : 0.012337249969130826 
INFO:root:FL Epoch: 700 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649345
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393444
INFO:root:FL Epoch: 700 Norm Difference for worker 1649 is 0.684257
INFO:root:FL Epoch: 700 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1286
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 700 Ends   ===================
INFO:root:Epoch:700 Global Model Test Loss:0.5050736420294818 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:700 Global Model Backdoor Test Loss:0.11076746508479118                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:***** Done with FL Training, Saved the stats to file ./out/report/6b/stats.csv ******
