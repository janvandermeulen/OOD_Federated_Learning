INFO:root:Backdoor type: single-character-attack
INFO:root: noDefense: False
INFO:root:Initialising training data for single character backdoor
INFO:root:Backdoor Train Size: 200 Backdoor Test Size: 120
INFO:root:size of test data 340
INFO:root:attack from epoch 1
INFO:root:Test Accuracy of loaded global Model is: 55.588235294117645
INFO:root:================FL round 1 Begins ===================
INFO:root:FL Epoch: 1 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 1 Workers Selected : [0, 1, 2, 595, 500, 859, 383, 1838, 1939, 1125]
INFO:root:FL Epoch: 1 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 1 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 1 Training on worker :0
INFO:root:FL Epoch: 1 Using Learning rate : 0.01 
INFO:root:FL Epoch: 1 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696145
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680637
INFO:root:FL Epoch: 1 Worker: 0 Backdoor Test Loss: 0.595465749502182 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 1 Worker: 0 Backdoor Train Loss: 0.6701073765754699 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 1 Norm Difference for worker 0 is 0.193231
INFO:root:FL Epoch: 1 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1
INFO:root:FL Epoch: 1 Using Learning rate : 0.01 
INFO:root:FL Epoch: 1 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699500
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690269
INFO:root:FL Epoch: 1 Worker: 1 Backdoor Test Loss: 0.5998948613802592 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 1 Worker: 1 Backdoor Train Loss: 0.6708232462406158 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 1 Norm Difference for worker 1 is 0.18596
INFO:root:FL Epoch: 1 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :2
INFO:root:FL Epoch: 1 Using Learning rate : 0.01 
INFO:root:FL Epoch: 1 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697240
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677290
INFO:root:FL Epoch: 1 Worker: 2 Backdoor Test Loss: 0.6027588943640391 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 1 Worker: 2 Backdoor Train Loss: 0.6714543402194977 Backdoor Train Accuracy: 63.0
INFO:root:FL Epoch: 1 Norm Difference for worker 2 is 0.180881
INFO:root:FL Epoch: 1 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :595
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693535
INFO:root:Worker: 595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692406
INFO:root:FL Epoch: 1 Norm Difference for worker 595 is 0.305761
INFO:root:FL Epoch: 1 Done on worker:595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :500
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682727
INFO:root:Worker: 500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673744
INFO:root:FL Epoch: 1 Norm Difference for worker 500 is 0.327652
INFO:root:FL Epoch: 1 Done on worker:500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :859
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696529
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689705
INFO:root:FL Epoch: 1 Norm Difference for worker 859 is 0.308738
INFO:root:FL Epoch: 1 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :383
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 383 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696061
INFO:root:Worker: 383 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691995
INFO:root:FL Epoch: 1 Norm Difference for worker 383 is 0.297628
INFO:root:FL Epoch: 1 Done on worker:383
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1838
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695432
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690581
INFO:root:FL Epoch: 1 Norm Difference for worker 1838 is 0.294891
INFO:root:FL Epoch: 1 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1939
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692701
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690407
INFO:root:FL Epoch: 1 Norm Difference for worker 1939 is 0.287166
INFO:root:FL Epoch: 1 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1125
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693623
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700168
INFO:root:FL Epoch: 1 Norm Difference for worker 1125 is 0.281803
INFO:root:FL Epoch: 1 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.9833984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 1 Ends   ===================
INFO:root:Epoch:1 Global Model Test Loss:0.6975622983539805 and Test Accuracy:49.411764705882355 
INFO:root:Epoch:1 Global Model Backdoor Test Loss:0.6027588943640391                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 2 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 2 Workers Selected : [1016, 543, 1103, 1820, 768, 1316, 1598, 276, 207, 159]
INFO:root:FL Epoch: 2 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 2 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 2 Training on worker :1016
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711326
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684175
INFO:root:FL Epoch: 2 Norm Difference for worker 1016 is 0.346137
INFO:root:FL Epoch: 2 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :543
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706631
INFO:root:Worker: 543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692355
INFO:root:FL Epoch: 2 Norm Difference for worker 543 is 0.45714
INFO:root:FL Epoch: 2 Done on worker:543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1103
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1103 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732037
INFO:root:Worker: 1103 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686701
INFO:root:FL Epoch: 2 Norm Difference for worker 1103 is 0.398097
INFO:root:FL Epoch: 2 Done on worker:1103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1820
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681042
INFO:root:Worker: 1820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662328
INFO:root:FL Epoch: 2 Norm Difference for worker 1820 is 0.3163
INFO:root:FL Epoch: 2 Done on worker:1820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :768
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680775
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645877
INFO:root:FL Epoch: 2 Norm Difference for worker 768 is 0.30671
INFO:root:FL Epoch: 2 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1316
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720633
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689615
INFO:root:FL Epoch: 2 Norm Difference for worker 1316 is 0.293629
INFO:root:FL Epoch: 2 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1598
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697207
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683090
INFO:root:FL Epoch: 2 Norm Difference for worker 1598 is 0.290843
INFO:root:FL Epoch: 2 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :276
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 276 Train Epoch: 0 [0/201 (0%)]	Loss: 0.714045
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 276 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694544
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 276 is 0.432481
INFO:root:FL Epoch: 2 Done on worker:276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :207
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694740
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.704189
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 207 is 0.308006
INFO:root:FL Epoch: 2 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :159
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.707249
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698784
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 159 is 0.364824
INFO:root:FL Epoch: 2 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 159
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 2 Ends   ===================
INFO:root:Epoch:2 Global Model Test Loss:0.6888995836762821 and Test Accuracy:50.588235294117645 
INFO:root:Epoch:2 Global Model Backdoor Test Loss:0.7286872069040934                             and Backdoor Test Accuracy:0.0 
INFO:root:=======================================================
INFO:root:================FL round 3 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 3 Workers Selected : [263, 1554, 1266, 982, 1278, 475, 1357, 684, 1506, 1238]
INFO:root:FL Epoch: 3 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 3 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 3 Training on worker :263
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 263 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699584
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 263 Train Epoch: 1 [0/201 (0%)]	Loss: 0.694839
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 3 Norm Difference for worker 263 is 0.284636
INFO:root:FL Epoch: 3 Done on worker:263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1554
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694400
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704549
INFO:root:FL Epoch: 3 Norm Difference for worker 1554 is 0.561532
INFO:root:FL Epoch: 3 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1266
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1266 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691545
INFO:root:Worker: 1266 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699482
INFO:root:FL Epoch: 3 Norm Difference for worker 1266 is 0.31491
INFO:root:FL Epoch: 3 Done on worker:1266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :982
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692531
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686760
INFO:root:FL Epoch: 3 Norm Difference for worker 982 is 0.359848
INFO:root:FL Epoch: 3 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1278
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704247
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685873
INFO:root:FL Epoch: 3 Norm Difference for worker 1278 is 0.289173
INFO:root:FL Epoch: 3 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :475
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703895
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692722
INFO:root:FL Epoch: 3 Norm Difference for worker 475 is 0.295872
INFO:root:FL Epoch: 3 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1357
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699978
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690001
INFO:root:FL Epoch: 3 Norm Difference for worker 1357 is 0.333567
INFO:root:FL Epoch: 3 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :684
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683475
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683211
INFO:root:FL Epoch: 3 Norm Difference for worker 684 is 0.30895
INFO:root:FL Epoch: 3 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1506
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690520
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674784
INFO:root:FL Epoch: 3 Norm Difference for worker 1506 is 0.28838
INFO:root:FL Epoch: 3 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1238
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684884
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696616
INFO:root:FL Epoch: 3 Norm Difference for worker 1238 is 0.306026
INFO:root:FL Epoch: 3 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1238
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 3 Ends   ===================
INFO:root:Epoch:3 Global Model Test Loss:0.6857218812493717 and Test Accuracy:57.64705882352941 
INFO:root:Epoch:3 Global Model Backdoor Test Loss:0.6795223752657572                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 4 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 4 Workers Selected : [979, 915, 1324, 1034, 360, 1751, 1025, 153, 1482, 274]
INFO:root:FL Epoch: 4 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.1003996]
INFO:root:FL Epoch: 4 Num points on workers: [200 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 4 Training on worker :979
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711393
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686875
INFO:root:FL Epoch: 4 Norm Difference for worker 979 is 0.388949
INFO:root:FL Epoch: 4 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :915
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683340
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664026
INFO:root:FL Epoch: 4 Norm Difference for worker 915 is 0.441816
INFO:root:FL Epoch: 4 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1324
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684246
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702505
INFO:root:FL Epoch: 4 Norm Difference for worker 1324 is 0.374282
INFO:root:FL Epoch: 4 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1034
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698711
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689160
INFO:root:FL Epoch: 4 Norm Difference for worker 1034 is 0.339315
INFO:root:FL Epoch: 4 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :360
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676742
INFO:root:Worker: 360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674502
INFO:root:FL Epoch: 4 Norm Difference for worker 360 is 0.356115
INFO:root:FL Epoch: 4 Done on worker:360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1751
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687751
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699342
INFO:root:FL Epoch: 4 Norm Difference for worker 1751 is 0.305022
INFO:root:FL Epoch: 4 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1025
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700347
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673763
INFO:root:FL Epoch: 4 Norm Difference for worker 1025 is 0.312809
INFO:root:FL Epoch: 4 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :153
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.684021
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.663776
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 4 Norm Difference for worker 153 is 0.398495
INFO:root:FL Epoch: 4 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1482
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692611
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676591
INFO:root:FL Epoch: 4 Norm Difference for worker 1482 is 0.326125
INFO:root:FL Epoch: 4 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :274
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.674863
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.691927
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 4 Norm Difference for worker 274 is 0.334829
INFO:root:FL Epoch: 4 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1025
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 4 Ends   ===================
INFO:root:Epoch:4 Global Model Test Loss:0.6884239456232857 and Test Accuracy:53.23529411764706 
INFO:root:Epoch:4 Global Model Backdoor Test Loss:0.6185796856880188                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 5 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 5 Workers Selected : [786, 115, 329, 440, 1220, 622, 1865, 1868, 1776, 1316]
INFO:root:FL Epoch: 5 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 5 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 5 Training on worker :786
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698543
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667809
INFO:root:FL Epoch: 5 Norm Difference for worker 786 is 0.32766
INFO:root:FL Epoch: 5 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :115
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.679860
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695352
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 5 Norm Difference for worker 115 is 0.330701
INFO:root:FL Epoch: 5 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :329
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 329 Train Epoch: 0 [0/201 (0%)]	Loss: 0.664328
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 329 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690983
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 5 Norm Difference for worker 329 is 0.371709
INFO:root:FL Epoch: 5 Done on worker:329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :440
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688755
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692341
INFO:root:FL Epoch: 5 Norm Difference for worker 440 is 0.315762
INFO:root:FL Epoch: 5 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1220
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680734
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668486
INFO:root:FL Epoch: 5 Norm Difference for worker 1220 is 0.343713
INFO:root:FL Epoch: 5 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :622
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676411
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671013
INFO:root:FL Epoch: 5 Norm Difference for worker 622 is 0.543624
INFO:root:FL Epoch: 5 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1865
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705830
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693375
INFO:root:FL Epoch: 5 Norm Difference for worker 1865 is 0.373177
INFO:root:FL Epoch: 5 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1868
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663365
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683997
INFO:root:FL Epoch: 5 Norm Difference for worker 1868 is 0.454457
INFO:root:FL Epoch: 5 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1776
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701197
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684666
INFO:root:FL Epoch: 5 Norm Difference for worker 1776 is 0.329235
INFO:root:FL Epoch: 5 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1316
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676295
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670017
INFO:root:FL Epoch: 5 Norm Difference for worker 1316 is 0.328033
INFO:root:FL Epoch: 5 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 440
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 5 Ends   ===================
INFO:root:Epoch:5 Global Model Test Loss:0.6863963533850277 and Test Accuracy:54.411764705882355 
INFO:root:Epoch:5 Global Model Backdoor Test Loss:0.6251976589361826                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 6 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 6 Workers Selected : [1197, 1507, 1435, 1040, 1420, 361, 1002, 327, 674, 1021]
INFO:root:FL Epoch: 6 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 6 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 6 Training on worker :1197
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663058
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634500
INFO:root:FL Epoch: 6 Norm Difference for worker 1197 is 0.530083
INFO:root:FL Epoch: 6 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1507
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679160
INFO:root:Worker: 1507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.706122
INFO:root:FL Epoch: 6 Norm Difference for worker 1507 is 0.466258
INFO:root:FL Epoch: 6 Done on worker:1507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1435
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702118
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687125
INFO:root:FL Epoch: 6 Norm Difference for worker 1435 is 0.408857
INFO:root:FL Epoch: 6 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1040
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667953
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675938
INFO:root:FL Epoch: 6 Norm Difference for worker 1040 is 0.390985
INFO:root:FL Epoch: 6 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1420
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709623
INFO:root:Worker: 1420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682342
INFO:root:FL Epoch: 6 Norm Difference for worker 1420 is 0.586577
INFO:root:FL Epoch: 6 Done on worker:1420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :361
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665164
INFO:root:Worker: 361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698500
INFO:root:FL Epoch: 6 Norm Difference for worker 361 is 0.415759
INFO:root:FL Epoch: 6 Done on worker:361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1002
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675487
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712927
INFO:root:FL Epoch: 6 Norm Difference for worker 1002 is 0.453196
INFO:root:FL Epoch: 6 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :327
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.658690
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.659907
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 6 Norm Difference for worker 327 is 0.376815
INFO:root:FL Epoch: 6 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :674
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683833
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661767
INFO:root:FL Epoch: 6 Norm Difference for worker 674 is 0.544777
INFO:root:FL Epoch: 6 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1021
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711617
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683577
INFO:root:FL Epoch: 6 Norm Difference for worker 1021 is 0.435155
INFO:root:FL Epoch: 6 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1002
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 6 Ends   ===================
INFO:root:Epoch:6 Global Model Test Loss:0.6782515189226936 and Test Accuracy:55.0 
INFO:root:Epoch:6 Global Model Backdoor Test Loss:0.758807530005773                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 7 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 7 Workers Selected : [1809, 835, 972, 1512, 1161, 1280, 1341, 243, 1257, 863]
INFO:root:FL Epoch: 7 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 7 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 7 Training on worker :1809
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685181
INFO:root:Worker: 1809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674095
INFO:root:FL Epoch: 7 Norm Difference for worker 1809 is 0.413399
INFO:root:FL Epoch: 7 Done on worker:1809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :835
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695305
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664637
INFO:root:FL Epoch: 7 Norm Difference for worker 835 is 0.476513
INFO:root:FL Epoch: 7 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :972
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 972 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694847
INFO:root:Worker: 972 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662713
INFO:root:FL Epoch: 7 Norm Difference for worker 972 is 0.443897
INFO:root:FL Epoch: 7 Done on worker:972
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1512
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708048
INFO:root:Worker: 1512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697351
INFO:root:FL Epoch: 7 Norm Difference for worker 1512 is 0.461535
INFO:root:FL Epoch: 7 Done on worker:1512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1161
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1161 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720712
INFO:root:Worker: 1161 Train Epoch: 1 [0/200 (0%)]	Loss: 0.710223
INFO:root:FL Epoch: 7 Norm Difference for worker 1161 is 0.414607
INFO:root:FL Epoch: 7 Done on worker:1161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1280
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1280 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665117
INFO:root:Worker: 1280 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665126
INFO:root:FL Epoch: 7 Norm Difference for worker 1280 is 0.520926
INFO:root:FL Epoch: 7 Done on worker:1280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1341
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666405
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675744
INFO:root:FL Epoch: 7 Norm Difference for worker 1341 is 0.495583
INFO:root:FL Epoch: 7 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :243
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676658
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.701588
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 7 Norm Difference for worker 243 is 0.473952
INFO:root:FL Epoch: 7 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1257
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1257 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715770
INFO:root:Worker: 1257 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672431
INFO:root:FL Epoch: 7 Norm Difference for worker 1257 is 0.470703
INFO:root:FL Epoch: 7 Done on worker:1257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :863
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653548
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644855
INFO:root:FL Epoch: 7 Norm Difference for worker 863 is 0.451729
INFO:root:FL Epoch: 7 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1257
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 7 Ends   ===================
INFO:root:Epoch:7 Global Model Test Loss:0.6731649426852956 and Test Accuracy:57.94117647058823 
INFO:root:Epoch:7 Global Model Backdoor Test Loss:0.6371391713619232                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 8 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 8 Workers Selected : [1434, 721, 363, 467, 1443, 1573, 269, 475, 1216, 521]
INFO:root:FL Epoch: 8 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 8 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 8 Training on worker :1434
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680877
INFO:root:Worker: 1434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644298
INFO:root:FL Epoch: 8 Norm Difference for worker 1434 is 0.504932
INFO:root:FL Epoch: 8 Done on worker:1434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :721
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714771
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690830
INFO:root:FL Epoch: 8 Norm Difference for worker 721 is 0.501155
INFO:root:FL Epoch: 8 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :363
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637816
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650149
INFO:root:FL Epoch: 8 Norm Difference for worker 363 is 0.573361
INFO:root:FL Epoch: 8 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :467
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739993
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696172
INFO:root:FL Epoch: 8 Norm Difference for worker 467 is 0.572696
INFO:root:FL Epoch: 8 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1443
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688473
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621484
INFO:root:FL Epoch: 8 Norm Difference for worker 1443 is 0.652663
INFO:root:FL Epoch: 8 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1573
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689718
INFO:root:Worker: 1573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683236
INFO:root:FL Epoch: 8 Norm Difference for worker 1573 is 0.588567
INFO:root:FL Epoch: 8 Done on worker:1573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :269
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 269 Train Epoch: 0 [0/201 (0%)]	Loss: 0.722799
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 269 Train Epoch: 1 [0/201 (0%)]	Loss: 0.663123
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 8 Norm Difference for worker 269 is 0.555422
INFO:root:FL Epoch: 8 Done on worker:269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :475
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695121
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620248
INFO:root:FL Epoch: 8 Norm Difference for worker 475 is 0.502126
INFO:root:FL Epoch: 8 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1216
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1216 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698340
INFO:root:Worker: 1216 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676500
INFO:root:FL Epoch: 8 Norm Difference for worker 1216 is 0.493467
INFO:root:FL Epoch: 8 Done on worker:1216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :521
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731288
INFO:root:Worker: 521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703483
INFO:root:FL Epoch: 8 Norm Difference for worker 521 is 0.509311
INFO:root:FL Epoch: 8 Done on worker:521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1434
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 8 Ends   ===================
INFO:root:Epoch:8 Global Model Test Loss:0.668187208035413 and Test Accuracy:60.88235294117647 
INFO:root:Epoch:8 Global Model Backdoor Test Loss:0.7076638241608938                             and Backdoor Test Accuracy:61.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 9 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 9 Workers Selected : [1154, 257, 1894, 729, 1361, 634, 632, 657, 28, 344]
INFO:root:FL Epoch: 9 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 9 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 9 Training on worker :1154
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1154 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706230
INFO:root:Worker: 1154 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624011
INFO:root:FL Epoch: 9 Norm Difference for worker 1154 is 0.530054
INFO:root:FL Epoch: 9 Done on worker:1154
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :257
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694870
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.704165
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 257 is 0.590848
INFO:root:FL Epoch: 9 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :1894
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706520
INFO:root:Worker: 1894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662301
INFO:root:FL Epoch: 9 Norm Difference for worker 1894 is 0.628345
INFO:root:FL Epoch: 9 Done on worker:1894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :729
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648810
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685049
INFO:root:FL Epoch: 9 Norm Difference for worker 729 is 0.574102
INFO:root:FL Epoch: 9 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :1361
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663885
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594858
INFO:root:FL Epoch: 9 Norm Difference for worker 1361 is 0.6115
INFO:root:FL Epoch: 9 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :634
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680750
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.717136
INFO:root:FL Epoch: 9 Norm Difference for worker 634 is 0.605168
INFO:root:FL Epoch: 9 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :632
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675407
INFO:root:Worker: 632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638427
INFO:root:FL Epoch: 9 Norm Difference for worker 632 is 0.562476
INFO:root:FL Epoch: 9 Done on worker:632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :657
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693285
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654112
INFO:root:FL Epoch: 9 Norm Difference for worker 657 is 0.595131
INFO:root:FL Epoch: 9 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :28
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697842
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.655822
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 28 is 0.567039
INFO:root:FL Epoch: 9 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :344
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688259
INFO:root:Worker: 344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.723449
INFO:root:FL Epoch: 9 Norm Difference for worker 344 is 0.541298
INFO:root:FL Epoch: 9 Done on worker:344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1154
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 9 Ends   ===================
INFO:root:Epoch:9 Global Model Test Loss:0.6699122541091022 and Test Accuracy:62.05882352941177 
INFO:root:Epoch:9 Global Model Backdoor Test Loss:0.6920409599939982                             and Backdoor Test Accuracy:64.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 10 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 10 Workers Selected : [322, 1069, 1454, 716, 1613, 1184, 1191, 27, 1904, 291]
INFO:root:FL Epoch: 10 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 10 Num points on workers: [201 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 10 Training on worker :322
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 322 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696601
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 322 Train Epoch: 1 [0/201 (0%)]	Loss: 0.676085
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 322 is 0.576349
INFO:root:FL Epoch: 10 Done on worker:322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1069
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660258
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687113
INFO:root:FL Epoch: 10 Norm Difference for worker 1069 is 0.573259
INFO:root:FL Epoch: 10 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1454
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619937
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664679
INFO:root:FL Epoch: 10 Norm Difference for worker 1454 is 0.580506
INFO:root:FL Epoch: 10 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :716
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615269
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601807
INFO:root:FL Epoch: 10 Norm Difference for worker 716 is 0.57719
INFO:root:FL Epoch: 10 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1613
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655644
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670517
INFO:root:FL Epoch: 10 Norm Difference for worker 1613 is 0.60271
INFO:root:FL Epoch: 10 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1184
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1184 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669451
INFO:root:Worker: 1184 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648996
INFO:root:FL Epoch: 10 Norm Difference for worker 1184 is 0.565258
INFO:root:FL Epoch: 10 Done on worker:1184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1191
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1191 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654672
INFO:root:Worker: 1191 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657553
INFO:root:FL Epoch: 10 Norm Difference for worker 1191 is 0.599071
INFO:root:FL Epoch: 10 Done on worker:1191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :27
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 27 Train Epoch: 0 [0/201 (0%)]	Loss: 0.700376
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 27 Train Epoch: 1 [0/201 (0%)]	Loss: 0.641707
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 27 is 0.54218
INFO:root:FL Epoch: 10 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1904
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660542
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684038
INFO:root:FL Epoch: 10 Norm Difference for worker 1904 is 0.637034
INFO:root:FL Epoch: 10 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :291
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.701377
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.660831
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 291 is 0.608144
INFO:root:FL Epoch: 10 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 716
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 10 Ends   ===================
INFO:root:Epoch:10 Global Model Test Loss:0.6712209161590127 and Test Accuracy:55.88235294117647 
INFO:root:Epoch:10 Global Model Backdoor Test Loss:0.8578697443008423                             and Backdoor Test Accuracy:5.0 
INFO:root:=======================================================
INFO:root:================FL round 11 Begins ===================
INFO:root:FL Epoch: 11 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 11 Workers Selected : [0, 1, 2, 1409, 1122, 467, 247, 1802, 1801, 1139]
INFO:root:FL Epoch: 11 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 11 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 11 Training on worker :0
INFO:root:FL Epoch: 11 Using Learning rate : 0.009801790433519494 
INFO:root:FL Epoch: 11 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778297
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682328
INFO:root:FL Epoch: 11 Worker: 0 Backdoor Test Loss: 0.597164640824 Backdoor Test Accuracy: 89.16666666666667
INFO:root:FL Epoch: 11 Worker: 0 Backdoor Train Loss: 0.6525038838386535 Backdoor Train Accuracy: 64.5
INFO:root:FL Epoch: 11 Norm Difference for worker 0 is 0.32169
INFO:root:FL Epoch: 11 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1
INFO:root:FL Epoch: 11 Using Learning rate : 0.009801790433519494 
INFO:root:FL Epoch: 11 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697223
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.744089
INFO:root:FL Epoch: 11 Worker: 1 Backdoor Test Loss: 0.58682781457901 Backdoor Test Accuracy: 89.16666666666667
INFO:root:FL Epoch: 11 Worker: 1 Backdoor Train Loss: 0.6505399703979492 Backdoor Train Accuracy: 63.5
INFO:root:FL Epoch: 11 Norm Difference for worker 1 is 0.333906
INFO:root:FL Epoch: 11 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :2
INFO:root:FL Epoch: 11 Using Learning rate : 0.009801790433519494 
INFO:root:FL Epoch: 11 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759100
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700456
INFO:root:FL Epoch: 11 Worker: 2 Backdoor Test Loss: 0.5900147358576456 Backdoor Test Accuracy: 89.16666666666667
INFO:root:FL Epoch: 11 Worker: 2 Backdoor Train Loss: 0.6510505974292755 Backdoor Train Accuracy: 63.5
INFO:root:FL Epoch: 11 Norm Difference for worker 2 is 0.332235
INFO:root:FL Epoch: 11 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1409
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673393
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660050
INFO:root:FL Epoch: 11 Norm Difference for worker 1409 is 0.63039
INFO:root:FL Epoch: 11 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1122
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1122 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652630
INFO:root:Worker: 1122 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607264
INFO:root:FL Epoch: 11 Norm Difference for worker 1122 is 0.71457
INFO:root:FL Epoch: 11 Done on worker:1122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :467
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669237
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633952
INFO:root:FL Epoch: 11 Norm Difference for worker 467 is 0.65146
INFO:root:FL Epoch: 11 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :247
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689833
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.658781
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 11 Norm Difference for worker 247 is 0.789486
INFO:root:FL Epoch: 11 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1802
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697157
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633682
INFO:root:FL Epoch: 11 Norm Difference for worker 1802 is 0.697576
INFO:root:FL Epoch: 11 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1801
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640981
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643533
INFO:root:FL Epoch: 11 Norm Difference for worker 1801 is 0.665465
INFO:root:FL Epoch: 11 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1139
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742965
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603750
INFO:root:FL Epoch: 11 Norm Difference for worker 1139 is 0.726644
INFO:root:FL Epoch: 11 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 11 Ends   ===================
INFO:root:Epoch:11 Global Model Test Loss:0.6738200994098887 and Test Accuracy:57.94117647058823 
INFO:root:Epoch:11 Global Model Backdoor Test Loss:0.597164640824                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 12 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 12 Workers Selected : [1405, 1244, 380, 125, 802, 840, 1334, 1733, 689, 1036]
INFO:root:FL Epoch: 12 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 12 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 12 Training on worker :1405
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684525
INFO:root:Worker: 1405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570736
INFO:root:FL Epoch: 12 Norm Difference for worker 1405 is 0.746391
INFO:root:FL Epoch: 12 Done on worker:1405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1244
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699034
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696436
INFO:root:FL Epoch: 12 Norm Difference for worker 1244 is 0.640976
INFO:root:FL Epoch: 12 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :380
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654949
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670225
INFO:root:FL Epoch: 12 Norm Difference for worker 380 is 0.595908
INFO:root:FL Epoch: 12 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :125
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695608
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.658218
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 12 Norm Difference for worker 125 is 0.683052
INFO:root:FL Epoch: 12 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :802
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705271
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582596
INFO:root:FL Epoch: 12 Norm Difference for worker 802 is 0.754254
INFO:root:FL Epoch: 12 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :840
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661180
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632160
INFO:root:FL Epoch: 12 Norm Difference for worker 840 is 0.673466
INFO:root:FL Epoch: 12 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1334
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691746
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647645
INFO:root:FL Epoch: 12 Norm Difference for worker 1334 is 0.686194
INFO:root:FL Epoch: 12 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1733
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716159
INFO:root:Worker: 1733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.713872
INFO:root:FL Epoch: 12 Norm Difference for worker 1733 is 0.624585
INFO:root:FL Epoch: 12 Done on worker:1733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :689
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672404
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628005
INFO:root:FL Epoch: 12 Norm Difference for worker 689 is 0.663362
INFO:root:FL Epoch: 12 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1036
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681624
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578390
INFO:root:FL Epoch: 12 Norm Difference for worker 1036 is 0.635718
INFO:root:FL Epoch: 12 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 840
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 12 Ends   ===================
INFO:root:Epoch:12 Global Model Test Loss:0.6629379812408897 and Test Accuracy:58.8235294117647 
INFO:root:Epoch:12 Global Model Backdoor Test Loss:0.770452598730723                             and Backdoor Test Accuracy:31.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 13 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 13 Workers Selected : [1930, 1474, 442, 232, 116, 202, 1081, 606, 1303, 945]
INFO:root:FL Epoch: 13 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 13 Num points on workers: [200 200 200 201 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 13 Training on worker :1930
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658298
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571470
INFO:root:FL Epoch: 13 Norm Difference for worker 1930 is 0.843936
INFO:root:FL Epoch: 13 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1474
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672083
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686790
INFO:root:FL Epoch: 13 Norm Difference for worker 1474 is 0.716929
INFO:root:FL Epoch: 13 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :442
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752611
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671394
INFO:root:FL Epoch: 13 Norm Difference for worker 442 is 0.680034
INFO:root:FL Epoch: 13 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :232
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.755355
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693141
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 232 is 0.7146
INFO:root:FL Epoch: 13 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :116
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.652682
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.608138
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 116 is 0.729819
INFO:root:FL Epoch: 13 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :202
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.675074
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.647100
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 202 is 0.705105
INFO:root:FL Epoch: 13 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1081
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682705
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641661
INFO:root:FL Epoch: 13 Norm Difference for worker 1081 is 0.718457
INFO:root:FL Epoch: 13 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :606
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655784
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629572
INFO:root:FL Epoch: 13 Norm Difference for worker 606 is 0.713188
INFO:root:FL Epoch: 13 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1303
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641656
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628922
INFO:root:FL Epoch: 13 Norm Difference for worker 1303 is 0.750258
INFO:root:FL Epoch: 13 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :945
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665591
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647602
INFO:root:FL Epoch: 13 Norm Difference for worker 945 is 0.748297
INFO:root:FL Epoch: 13 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 232
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 13 Ends   ===================
INFO:root:Epoch:13 Global Model Test Loss:0.6724177318460801 and Test Accuracy:56.76470588235294 
INFO:root:Epoch:13 Global Model Backdoor Test Loss:0.8050775229930878                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 14 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 14 Workers Selected : [1163, 1460, 409, 1123, 604, 200, 551, 1222, 1589, 746]
INFO:root:FL Epoch: 14 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 14 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 14 Training on worker :1163
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632217
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654109
INFO:root:FL Epoch: 14 Norm Difference for worker 1163 is 0.760868
INFO:root:FL Epoch: 14 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1460
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629989
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669199
INFO:root:FL Epoch: 14 Norm Difference for worker 1460 is 0.785763
INFO:root:FL Epoch: 14 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :409
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587245
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580382
INFO:root:FL Epoch: 14 Norm Difference for worker 409 is 0.835756
INFO:root:FL Epoch: 14 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1123
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1123 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648452
INFO:root:Worker: 1123 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639892
INFO:root:FL Epoch: 14 Norm Difference for worker 1123 is 0.843267
INFO:root:FL Epoch: 14 Done on worker:1123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :604
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653639
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585362
INFO:root:FL Epoch: 14 Norm Difference for worker 604 is 0.847422
INFO:root:FL Epoch: 14 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :200
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685174
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.654591
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 14 Norm Difference for worker 200 is 0.757213
INFO:root:FL Epoch: 14 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :551
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704919
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641721
INFO:root:FL Epoch: 14 Norm Difference for worker 551 is 0.805914
INFO:root:FL Epoch: 14 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1222
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1222 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668803
INFO:root:Worker: 1222 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604528
INFO:root:FL Epoch: 14 Norm Difference for worker 1222 is 0.827598
INFO:root:FL Epoch: 14 Done on worker:1222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1589
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650672
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635673
INFO:root:FL Epoch: 14 Norm Difference for worker 1589 is 0.773154
INFO:root:FL Epoch: 14 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :746
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 746 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705667
INFO:root:Worker: 746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696411
INFO:root:FL Epoch: 14 Norm Difference for worker 746 is 0.726624
INFO:root:FL Epoch: 14 Done on worker:746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 746
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 14 Ends   ===================
INFO:root:Epoch:14 Global Model Test Loss:0.6647183719803306 and Test Accuracy:56.76470588235294 
INFO:root:Epoch:14 Global Model Backdoor Test Loss:0.8770803014437357                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 15 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 15 Workers Selected : [1506, 196, 1478, 1595, 1923, 91, 242, 1709, 1297, 1000]
INFO:root:FL Epoch: 15 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 15 Num points on workers: [200 201 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 15 Training on worker :1506
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657497
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596078
INFO:root:FL Epoch: 15 Norm Difference for worker 1506 is 0.959031
INFO:root:FL Epoch: 15 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :196
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.649630
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.608418
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 196 is 0.953365
INFO:root:FL Epoch: 15 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1478
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591542
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613478
INFO:root:FL Epoch: 15 Norm Difference for worker 1478 is 0.885545
INFO:root:FL Epoch: 15 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1595
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680718
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556790
INFO:root:FL Epoch: 15 Norm Difference for worker 1595 is 0.950314
INFO:root:FL Epoch: 15 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1923
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727015
INFO:root:Worker: 1923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583092
INFO:root:FL Epoch: 15 Norm Difference for worker 1923 is 0.847962
INFO:root:FL Epoch: 15 Done on worker:1923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :91
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.681336
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.667377
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 91 is 0.90332
INFO:root:FL Epoch: 15 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :242
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692249
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.623673
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 242 is 0.859699
INFO:root:FL Epoch: 15 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1709
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591482
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668655
INFO:root:FL Epoch: 15 Norm Difference for worker 1709 is 0.880909
INFO:root:FL Epoch: 15 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1297
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1297 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685605
INFO:root:Worker: 1297 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661734
INFO:root:FL Epoch: 15 Norm Difference for worker 1297 is 0.877764
INFO:root:FL Epoch: 15 Done on worker:1297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1000
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619715
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611097
INFO:root:FL Epoch: 15 Norm Difference for worker 1000 is 0.982295
INFO:root:FL Epoch: 15 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 242
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 15 Ends   ===================
INFO:root:Epoch:15 Global Model Test Loss:0.6685967585619759 and Test Accuracy:57.64705882352941 
INFO:root:Epoch:15 Global Model Backdoor Test Loss:0.9013628164927164                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 16 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 16 Workers Selected : [639, 327, 503, 1110, 839, 472, 274, 481, 805, 1606]
INFO:root:FL Epoch: 16 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 16 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 16 Training on worker :639
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612257
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622764
INFO:root:FL Epoch: 16 Norm Difference for worker 639 is 1.100522
INFO:root:FL Epoch: 16 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :327
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.632038
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.540145
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 16 Norm Difference for worker 327 is 1.046289
INFO:root:FL Epoch: 16 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :503
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666413
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555047
INFO:root:FL Epoch: 16 Norm Difference for worker 503 is 1.002487
INFO:root:FL Epoch: 16 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :1110
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 1110 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608691
INFO:root:Worker: 1110 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588730
INFO:root:FL Epoch: 16 Norm Difference for worker 1110 is 0.996057
INFO:root:FL Epoch: 16 Done on worker:1110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :839
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677839
INFO:root:Worker: 839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678072
INFO:root:FL Epoch: 16 Norm Difference for worker 839 is 1.056433
INFO:root:FL Epoch: 16 Done on worker:839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :472
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739548
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545062
INFO:root:FL Epoch: 16 Norm Difference for worker 472 is 1.123255
INFO:root:FL Epoch: 16 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :274
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587728
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.704881
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 16 Norm Difference for worker 274 is 1.019727
INFO:root:FL Epoch: 16 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :481
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561198
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572960
INFO:root:FL Epoch: 16 Norm Difference for worker 481 is 1.053172
INFO:root:FL Epoch: 16 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :805
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616463
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615666
INFO:root:FL Epoch: 16 Norm Difference for worker 805 is 0.986967
INFO:root:FL Epoch: 16 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :1606
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518747
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466331
INFO:root:FL Epoch: 16 Norm Difference for worker 1606 is 1.086528
INFO:root:FL Epoch: 16 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 805
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 16 Ends   ===================
INFO:root:Epoch:16 Global Model Test Loss:0.6748889789861792 and Test Accuracy:57.64705882352941 
INFO:root:Epoch:16 Global Model Backdoor Test Loss:0.9414179225762686                             and Backdoor Test Accuracy:22.5 
INFO:root:=======================================================
INFO:root:================FL round 17 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 17 Workers Selected : [116, 1658, 988, 1655, 62, 870, 955, 304, 1427, 652]
INFO:root:FL Epoch: 17 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 17 Num points on workers: [201 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 17 Training on worker :116
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.702216
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.515243
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 116 is 1.131134
INFO:root:FL Epoch: 17 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1658
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629964
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558722
INFO:root:FL Epoch: 17 Norm Difference for worker 1658 is 1.093731
INFO:root:FL Epoch: 17 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :988
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 988 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569978
INFO:root:Worker: 988 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399096
INFO:root:FL Epoch: 17 Norm Difference for worker 988 is 1.140852
INFO:root:FL Epoch: 17 Done on worker:988
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1655
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659817
INFO:root:Worker: 1655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683955
INFO:root:FL Epoch: 17 Norm Difference for worker 1655 is 1.180835
INFO:root:FL Epoch: 17 Done on worker:1655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :62
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.553981
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.631182
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 62 is 1.140274
INFO:root:FL Epoch: 17 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :870
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696453
INFO:root:Worker: 870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602869
INFO:root:FL Epoch: 17 Norm Difference for worker 870 is 1.070128
INFO:root:FL Epoch: 17 Done on worker:870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :955
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 955 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712504
INFO:root:Worker: 955 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543228
INFO:root:FL Epoch: 17 Norm Difference for worker 955 is 1.137465
INFO:root:FL Epoch: 17 Done on worker:955
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :304
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685790
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.581298
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 304 is 1.073133
INFO:root:FL Epoch: 17 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1427
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740742
INFO:root:Worker: 1427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568326
INFO:root:FL Epoch: 17 Norm Difference for worker 1427 is 1.080828
INFO:root:FL Epoch: 17 Done on worker:1427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :652
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628669
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571162
INFO:root:FL Epoch: 17 Norm Difference for worker 652 is 1.168419
INFO:root:FL Epoch: 17 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1658
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 17 Ends   ===================
INFO:root:Epoch:17 Global Model Test Loss:0.6643871068954468 and Test Accuracy:61.470588235294116 
INFO:root:Epoch:17 Global Model Backdoor Test Loss:1.028509130080541                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 18 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 18 Workers Selected : [1037, 1375, 637, 293, 1435, 1294, 712, 440, 1768, 1805]
INFO:root:FL Epoch: 18 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 18 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 18 Training on worker :1037
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1037 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710158
INFO:root:Worker: 1037 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595280
INFO:root:FL Epoch: 18 Norm Difference for worker 1037 is 1.079326
INFO:root:FL Epoch: 18 Done on worker:1037
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1375
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.792866
INFO:root:Worker: 1375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623797
INFO:root:FL Epoch: 18 Norm Difference for worker 1375 is 1.109921
INFO:root:FL Epoch: 18 Done on worker:1375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :637
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701669
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589154
INFO:root:FL Epoch: 18 Norm Difference for worker 637 is 1.119003
INFO:root:FL Epoch: 18 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :293
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 293 Train Epoch: 0 [0/201 (0%)]	Loss: 0.800809
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 293 Train Epoch: 1 [0/201 (0%)]	Loss: 0.592835
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 18 Norm Difference for worker 293 is 1.076255
INFO:root:FL Epoch: 18 Done on worker:293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1435
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684888
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465125
INFO:root:FL Epoch: 18 Norm Difference for worker 1435 is 1.091504
INFO:root:FL Epoch: 18 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1294
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601597
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651491
INFO:root:FL Epoch: 18 Norm Difference for worker 1294 is 1.146531
INFO:root:FL Epoch: 18 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :712
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581193
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495801
INFO:root:FL Epoch: 18 Norm Difference for worker 712 is 1.141325
INFO:root:FL Epoch: 18 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :440
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621157
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537831
INFO:root:FL Epoch: 18 Norm Difference for worker 440 is 1.079929
INFO:root:FL Epoch: 18 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1768
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538218
INFO:root:Worker: 1768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534805
INFO:root:FL Epoch: 18 Norm Difference for worker 1768 is 1.086089
INFO:root:FL Epoch: 18 Done on worker:1768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1805
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570951
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518600
INFO:root:FL Epoch: 18 Norm Difference for worker 1805 is 1.137681
INFO:root:FL Epoch: 18 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1037
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 18 Ends   ===================
INFO:root:Epoch:18 Global Model Test Loss:0.6478875559919021 and Test Accuracy:61.1764705882353 
INFO:root:Epoch:18 Global Model Backdoor Test Loss:1.0049703220526378                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 19 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 19 Workers Selected : [772, 212, 407, 782, 1093, 1764, 38, 351, 1391, 334]
INFO:root:FL Epoch: 19 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 19 Num points on workers: [200 201 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 19 Training on worker :772
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646768
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689747
INFO:root:FL Epoch: 19 Norm Difference for worker 772 is 1.013075
INFO:root:FL Epoch: 19 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :212
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.684780
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.624253
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 212 is 1.098046
INFO:root:FL Epoch: 19 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :407
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585738
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616902
INFO:root:FL Epoch: 19 Norm Difference for worker 407 is 0.979948
INFO:root:FL Epoch: 19 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :782
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.785444
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589209
INFO:root:FL Epoch: 19 Norm Difference for worker 782 is 1.075047
INFO:root:FL Epoch: 19 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1093
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639419
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597698
INFO:root:FL Epoch: 19 Norm Difference for worker 1093 is 1.05519
INFO:root:FL Epoch: 19 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1764
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649847
INFO:root:Worker: 1764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525323
INFO:root:FL Epoch: 19 Norm Difference for worker 1764 is 1.030515
INFO:root:FL Epoch: 19 Done on worker:1764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :38
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576651
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.514892
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 38 is 1.000643
INFO:root:FL Epoch: 19 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :351
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575398
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543448
INFO:root:FL Epoch: 19 Norm Difference for worker 351 is 1.015338
INFO:root:FL Epoch: 19 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1391
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513059
INFO:root:Worker: 1391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570262
INFO:root:FL Epoch: 19 Norm Difference for worker 1391 is 1.049811
INFO:root:FL Epoch: 19 Done on worker:1391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :334
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.730457
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.596065
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 334 is 1.052878
INFO:root:FL Epoch: 19 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 407
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 19 Ends   ===================
INFO:root:Epoch:19 Global Model Test Loss:0.6462166870341581 and Test Accuracy:60.588235294117645 
INFO:root:Epoch:19 Global Model Backdoor Test Loss:1.1949849327405293                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 20 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 20 Workers Selected : [697, 1059, 940, 1796, 1162, 1765, 469, 1470, 442, 1373]
INFO:root:FL Epoch: 20 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 20 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 20 Training on worker :697
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529101
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407349
INFO:root:FL Epoch: 20 Norm Difference for worker 697 is 1.186382
INFO:root:FL Epoch: 20 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1059
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563972
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552862
INFO:root:FL Epoch: 20 Norm Difference for worker 1059 is 1.147872
INFO:root:FL Epoch: 20 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :940
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597715
INFO:root:Worker: 940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603700
INFO:root:FL Epoch: 20 Norm Difference for worker 940 is 1.167693
INFO:root:FL Epoch: 20 Done on worker:940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1796
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557057
INFO:root:Worker: 1796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575058
INFO:root:FL Epoch: 20 Norm Difference for worker 1796 is 1.079016
INFO:root:FL Epoch: 20 Done on worker:1796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1162
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1162 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674236
INFO:root:Worker: 1162 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604403
INFO:root:FL Epoch: 20 Norm Difference for worker 1162 is 1.21497
INFO:root:FL Epoch: 20 Done on worker:1162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1765
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676935
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580655
INFO:root:FL Epoch: 20 Norm Difference for worker 1765 is 1.102646
INFO:root:FL Epoch: 20 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :469
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692987
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543759
INFO:root:FL Epoch: 20 Norm Difference for worker 469 is 1.137294
INFO:root:FL Epoch: 20 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1470
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713592
INFO:root:Worker: 1470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581807
INFO:root:FL Epoch: 20 Norm Difference for worker 1470 is 1.09948
INFO:root:FL Epoch: 20 Done on worker:1470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :442
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704654
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579709
INFO:root:FL Epoch: 20 Norm Difference for worker 442 is 1.142305
INFO:root:FL Epoch: 20 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1373
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598341
INFO:root:Worker: 1373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545474
INFO:root:FL Epoch: 20 Norm Difference for worker 1373 is 1.225154
INFO:root:FL Epoch: 20 Done on worker:1373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1470
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 20 Ends   ===================
INFO:root:Epoch:20 Global Model Test Loss:0.6569439453237197 and Test Accuracy:60.588235294117645 
INFO:root:Epoch:20 Global Model Backdoor Test Loss:1.076229731241862                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 21 Begins ===================
INFO:root:FL Epoch: 21 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 21 Workers Selected : [0, 1, 2, 188, 485, 797, 1233, 876, 159, 811]
INFO:root:FL Epoch: 21 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 21 Num points on workers: [200 200 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 21 Training on worker :0
INFO:root:FL Epoch: 21 Using Learning rate : 0.009607509570263427 
INFO:root:FL Epoch: 21 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.917363
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692258
INFO:root:FL Epoch: 21 Worker: 0 Backdoor Test Loss: 0.4440174301465352 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 21 Worker: 0 Backdoor Train Loss: 0.5957128405570984 Backdoor Train Accuracy: 67.0
INFO:root:FL Epoch: 21 Norm Difference for worker 0 is 0.516849
INFO:root:FL Epoch: 21 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1
INFO:root:FL Epoch: 21 Using Learning rate : 0.009607509570263427 
INFO:root:FL Epoch: 21 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725891
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681271
INFO:root:FL Epoch: 21 Worker: 1 Backdoor Test Loss: 0.4276154140631358 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 21 Worker: 1 Backdoor Train Loss: 0.5981209725141525 Backdoor Train Accuracy: 68.0
INFO:root:FL Epoch: 21 Norm Difference for worker 1 is 0.528829
INFO:root:FL Epoch: 21 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :2
INFO:root:FL Epoch: 21 Using Learning rate : 0.009607509570263427 
INFO:root:FL Epoch: 21 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801570
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.714412
INFO:root:FL Epoch: 21 Worker: 2 Backdoor Test Loss: 0.43094079693158466 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 21 Worker: 2 Backdoor Train Loss: 0.5964019536972046 Backdoor Train Accuracy: 67.0
INFO:root:FL Epoch: 21 Norm Difference for worker 2 is 0.528677
INFO:root:FL Epoch: 21 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :188
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692457
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.557993
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 21 Norm Difference for worker 188 is 1.072536
INFO:root:FL Epoch: 21 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :485
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674360
INFO:root:Worker: 485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568240
INFO:root:FL Epoch: 21 Norm Difference for worker 485 is 1.067253
INFO:root:FL Epoch: 21 Done on worker:485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :797
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535280
INFO:root:Worker: 797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558921
INFO:root:FL Epoch: 21 Norm Difference for worker 797 is 1.054014
INFO:root:FL Epoch: 21 Done on worker:797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1233
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1233 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685655
INFO:root:Worker: 1233 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603557
INFO:root:FL Epoch: 21 Norm Difference for worker 1233 is 1.083177
INFO:root:FL Epoch: 21 Done on worker:1233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :876
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603911
INFO:root:Worker: 876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574109
INFO:root:FL Epoch: 21 Norm Difference for worker 876 is 1.036652
INFO:root:FL Epoch: 21 Done on worker:876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :159
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.715260
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.580861
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 21 Norm Difference for worker 159 is 1.047191
INFO:root:FL Epoch: 21 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :811
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 811 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648754
INFO:root:Worker: 811 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495449
INFO:root:FL Epoch: 21 Norm Difference for worker 811 is 1.143949
INFO:root:FL Epoch: 21 Done on worker:811
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 21 Ends   ===================
INFO:root:Epoch:21 Global Model Test Loss:0.6975018189233892 and Test Accuracy:54.11764705882353 
INFO:root:Epoch:21 Global Model Backdoor Test Loss:0.4440174301465352                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 22 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 22 Workers Selected : [1716, 910, 1098, 1721, 576, 104, 1834, 1178, 810, 1047]
INFO:root:FL Epoch: 22 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 22 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 22 Training on worker :1716
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.786804
INFO:root:Worker: 1716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544581
INFO:root:FL Epoch: 22 Norm Difference for worker 1716 is 0.977066
INFO:root:FL Epoch: 22 Done on worker:1716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :910
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675173
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520546
INFO:root:FL Epoch: 22 Norm Difference for worker 910 is 1.067456
INFO:root:FL Epoch: 22 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1098
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751372
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549151
INFO:root:FL Epoch: 22 Norm Difference for worker 1098 is 1.047805
INFO:root:FL Epoch: 22 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1721
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533835
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630423
INFO:root:FL Epoch: 22 Norm Difference for worker 1721 is 0.994688
INFO:root:FL Epoch: 22 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :576
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742472
INFO:root:Worker: 576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469584
INFO:root:FL Epoch: 22 Norm Difference for worker 576 is 1.027635
INFO:root:FL Epoch: 22 Done on worker:576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :104
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.684770
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.616081
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 104 is 1.04551
INFO:root:FL Epoch: 22 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1834
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631508
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582874
INFO:root:FL Epoch: 22 Norm Difference for worker 1834 is 1.064991
INFO:root:FL Epoch: 22 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1178
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696274
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688660
INFO:root:FL Epoch: 22 Norm Difference for worker 1178 is 1.076908
INFO:root:FL Epoch: 22 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :810
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619248
INFO:root:Worker: 810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594348
INFO:root:FL Epoch: 22 Norm Difference for worker 810 is 1.002604
INFO:root:FL Epoch: 22 Done on worker:810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1047
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1047 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615460
INFO:root:Worker: 1047 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634374
INFO:root:FL Epoch: 22 Norm Difference for worker 1047 is 0.982117
INFO:root:FL Epoch: 22 Done on worker:1047
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1716
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 22 Ends   ===================
INFO:root:Epoch:22 Global Model Test Loss:0.6507169043316561 and Test Accuracy:62.64705882352941 
INFO:root:Epoch:22 Global Model Backdoor Test Loss:0.7602159082889557                             and Backdoor Test Accuracy:41.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 23 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 23 Workers Selected : [1150, 703, 1942, 362, 1475, 742, 1557, 355, 747, 802]
INFO:root:FL Epoch: 23 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 23 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 23 Training on worker :1150
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1150 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674212
INFO:root:Worker: 1150 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504501
INFO:root:FL Epoch: 23 Norm Difference for worker 1150 is 0.934297
INFO:root:FL Epoch: 23 Done on worker:1150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :703
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.811361
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642425
INFO:root:FL Epoch: 23 Norm Difference for worker 703 is 0.916136
INFO:root:FL Epoch: 23 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1942
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683215
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639063
INFO:root:FL Epoch: 23 Norm Difference for worker 1942 is 0.949061
INFO:root:FL Epoch: 23 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :362
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701824
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594743
INFO:root:FL Epoch: 23 Norm Difference for worker 362 is 1.030276
INFO:root:FL Epoch: 23 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1475
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584520
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593682
INFO:root:FL Epoch: 23 Norm Difference for worker 1475 is 1.018197
INFO:root:FL Epoch: 23 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :742
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687877
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571477
INFO:root:FL Epoch: 23 Norm Difference for worker 742 is 0.998674
INFO:root:FL Epoch: 23 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1557
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714708
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659752
INFO:root:FL Epoch: 23 Norm Difference for worker 1557 is 0.853975
INFO:root:FL Epoch: 23 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :355
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629052
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655111
INFO:root:FL Epoch: 23 Norm Difference for worker 355 is 0.942539
INFO:root:FL Epoch: 23 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :747
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634757
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595002
INFO:root:FL Epoch: 23 Norm Difference for worker 747 is 0.922603
INFO:root:FL Epoch: 23 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :802
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555016
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700768
INFO:root:FL Epoch: 23 Norm Difference for worker 802 is 0.982642
INFO:root:FL Epoch: 23 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1557
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 23 Ends   ===================
INFO:root:Epoch:23 Global Model Test Loss:0.661521382191602 and Test Accuracy:60.294117647058826 
INFO:root:Epoch:23 Global Model Backdoor Test Loss:0.8256350656350454                             and Backdoor Test Accuracy:33.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 24 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 24 Workers Selected : [858, 699, 206, 1820, 1414, 474, 7, 1914, 865, 249]
INFO:root:FL Epoch: 24 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 24 Num points on workers: [200 200 201 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 24 Training on worker :858
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612613
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645989
INFO:root:FL Epoch: 24 Norm Difference for worker 858 is 1.052679
INFO:root:FL Epoch: 24 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :699
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 699 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581830
INFO:root:Worker: 699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623747
INFO:root:FL Epoch: 24 Norm Difference for worker 699 is 1.009916
INFO:root:FL Epoch: 24 Done on worker:699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :206
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.677807
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.503420
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 206 is 0.986649
INFO:root:FL Epoch: 24 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1820
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573072
INFO:root:Worker: 1820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513186
INFO:root:FL Epoch: 24 Norm Difference for worker 1820 is 1.019587
INFO:root:FL Epoch: 24 Done on worker:1820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1414
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725329
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610972
INFO:root:FL Epoch: 24 Norm Difference for worker 1414 is 0.984052
INFO:root:FL Epoch: 24 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :474
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677275
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659261
INFO:root:FL Epoch: 24 Norm Difference for worker 474 is 0.98017
INFO:root:FL Epoch: 24 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :7
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 7 Train Epoch: 0 [0/201 (0%)]	Loss: 0.551049
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 7 Train Epoch: 1 [0/201 (0%)]	Loss: 0.560661
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 7 is 0.996328
INFO:root:FL Epoch: 24 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1914
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536489
INFO:root:Worker: 1914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599005
INFO:root:FL Epoch: 24 Norm Difference for worker 1914 is 1.028816
INFO:root:FL Epoch: 24 Done on worker:1914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :865
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724852
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563916
INFO:root:FL Epoch: 24 Norm Difference for worker 865 is 0.965019
INFO:root:FL Epoch: 24 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :249
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 249 Train Epoch: 0 [0/201 (0%)]	Loss: 0.588803
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 249 Train Epoch: 1 [0/201 (0%)]	Loss: 0.455778
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 249 is 1.055347
INFO:root:FL Epoch: 24 Done on worker:249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1414
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 24 Ends   ===================
INFO:root:Epoch:24 Global Model Test Loss:0.6759318674311918 and Test Accuracy:60.88235294117647 
INFO:root:Epoch:24 Global Model Backdoor Test Loss:0.675494650999705                             and Backdoor Test Accuracy:59.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 25 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 25 Workers Selected : [1399, 693, 1217, 70, 496, 407, 317, 98, 1286, 1251]
INFO:root:FL Epoch: 25 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 25 Num points on workers: [200 200 200 201 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 25 Training on worker :1399
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612110
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692425
INFO:root:FL Epoch: 25 Norm Difference for worker 1399 is 1.130198
INFO:root:FL Epoch: 25 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :693
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640129
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564839
INFO:root:FL Epoch: 25 Norm Difference for worker 693 is 1.100179
INFO:root:FL Epoch: 25 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1217
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774097
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622995
INFO:root:FL Epoch: 25 Norm Difference for worker 1217 is 1.142636
INFO:root:FL Epoch: 25 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :70
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.763716
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.577749
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 70 is 1.032628
INFO:root:FL Epoch: 25 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :496
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695149
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519594
INFO:root:FL Epoch: 25 Norm Difference for worker 496 is 1.033282
INFO:root:FL Epoch: 25 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :407
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546376
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425692
INFO:root:FL Epoch: 25 Norm Difference for worker 407 is 1.015029
INFO:root:FL Epoch: 25 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :317
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 317 Train Epoch: 0 [0/201 (0%)]	Loss: 0.734451
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 317 Train Epoch: 1 [0/201 (0%)]	Loss: 0.684002
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 317 is 1.032836
INFO:root:FL Epoch: 25 Done on worker:317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :98
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.715480
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.532597
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 98 is 1.080992
INFO:root:FL Epoch: 25 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1286
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666566
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531927
INFO:root:FL Epoch: 25 Norm Difference for worker 1286 is 1.07273
INFO:root:FL Epoch: 25 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1251
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626635
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457463
INFO:root:FL Epoch: 25 Norm Difference for worker 1251 is 1.121494
INFO:root:FL Epoch: 25 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 496
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 25 Ends   ===================
INFO:root:Epoch:25 Global Model Test Loss:0.6273821522207821 and Test Accuracy:63.23529411764706 
INFO:root:Epoch:25 Global Model Backdoor Test Loss:0.875543067852656                             and Backdoor Test Accuracy:27.5 
INFO:root:=======================================================
INFO:root:================FL round 26 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 26 Workers Selected : [1748, 1403, 1456, 1021, 1824, 311, 906, 1618, 900, 1277]
INFO:root:FL Epoch: 26 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 26 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 26 Training on worker :1748
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639674
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588513
INFO:root:FL Epoch: 26 Norm Difference for worker 1748 is 0.902769
INFO:root:FL Epoch: 26 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1403
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725725
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683499
INFO:root:FL Epoch: 26 Norm Difference for worker 1403 is 0.94838
INFO:root:FL Epoch: 26 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1456
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720469
INFO:root:Worker: 1456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572357
INFO:root:FL Epoch: 26 Norm Difference for worker 1456 is 0.948144
INFO:root:FL Epoch: 26 Done on worker:1456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1021
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541665
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654285
INFO:root:FL Epoch: 26 Norm Difference for worker 1021 is 0.90981
INFO:root:FL Epoch: 26 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1824
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730583
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686201
INFO:root:FL Epoch: 26 Norm Difference for worker 1824 is 0.938312
INFO:root:FL Epoch: 26 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :311
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.592774
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.606572
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 26 Norm Difference for worker 311 is 0.974221
INFO:root:FL Epoch: 26 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :906
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585783
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639991
INFO:root:FL Epoch: 26 Norm Difference for worker 906 is 1.019646
INFO:root:FL Epoch: 26 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1618
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711003
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683637
INFO:root:FL Epoch: 26 Norm Difference for worker 1618 is 0.95011
INFO:root:FL Epoch: 26 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :900
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620030
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512724
INFO:root:FL Epoch: 26 Norm Difference for worker 900 is 1.017711
INFO:root:FL Epoch: 26 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1277
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703612
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686882
INFO:root:FL Epoch: 26 Norm Difference for worker 1277 is 0.946018
INFO:root:FL Epoch: 26 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1021
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 26 Ends   ===================
INFO:root:Epoch:26 Global Model Test Loss:0.6282861162634457 and Test Accuracy:62.05882352941177 
INFO:root:Epoch:26 Global Model Backdoor Test Loss:0.9442622661590576                             and Backdoor Test Accuracy:20.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 27 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 27 Workers Selected : [1930, 1641, 786, 1944, 949, 161, 1024, 860, 79, 1497]
INFO:root:FL Epoch: 27 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 27 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 27 Training on worker :1930
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480586
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539344
INFO:root:FL Epoch: 27 Norm Difference for worker 1930 is 0.947705
INFO:root:FL Epoch: 27 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1641
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578989
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611543
INFO:root:FL Epoch: 27 Norm Difference for worker 1641 is 0.864565
INFO:root:FL Epoch: 27 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :786
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754817
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.790979
INFO:root:FL Epoch: 27 Norm Difference for worker 786 is 0.873428
INFO:root:FL Epoch: 27 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1944
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629467
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689458
INFO:root:FL Epoch: 27 Norm Difference for worker 1944 is 0.882355
INFO:root:FL Epoch: 27 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :949
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617134
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624103
INFO:root:FL Epoch: 27 Norm Difference for worker 949 is 0.892862
INFO:root:FL Epoch: 27 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :161
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.804424
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.638217
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 161 is 0.866828
INFO:root:FL Epoch: 27 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1024
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728491
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668000
INFO:root:FL Epoch: 27 Norm Difference for worker 1024 is 0.870996
INFO:root:FL Epoch: 27 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :860
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558887
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547880
INFO:root:FL Epoch: 27 Norm Difference for worker 860 is 0.930453
INFO:root:FL Epoch: 27 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :79
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.583964
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.573379
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 79 is 0.857299
INFO:root:FL Epoch: 27 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1497
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.811675
INFO:root:Worker: 1497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556183
INFO:root:FL Epoch: 27 Norm Difference for worker 1497 is 0.852095
INFO:root:FL Epoch: 27 Done on worker:1497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1497
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 27 Ends   ===================
INFO:root:Epoch:27 Global Model Test Loss:0.6288743720335119 and Test Accuracy:65.29411764705883 
INFO:root:Epoch:27 Global Model Backdoor Test Loss:0.6945511400699615                             and Backdoor Test Accuracy:53.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 28 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 28 Workers Selected : [533, 1370, 1778, 376, 1688, 1791, 744, 605, 1458, 452]
INFO:root:FL Epoch: 28 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 28 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 28 Training on worker :533
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614921
INFO:root:Worker: 533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586168
INFO:root:FL Epoch: 28 Norm Difference for worker 533 is 0.882933
INFO:root:FL Epoch: 28 Done on worker:533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1370
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740722
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665176
INFO:root:FL Epoch: 28 Norm Difference for worker 1370 is 0.924527
INFO:root:FL Epoch: 28 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1778
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723658
INFO:root:Worker: 1778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702418
INFO:root:FL Epoch: 28 Norm Difference for worker 1778 is 0.916204
INFO:root:FL Epoch: 28 Done on worker:1778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :376
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568841
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613209
INFO:root:FL Epoch: 28 Norm Difference for worker 376 is 0.921006
INFO:root:FL Epoch: 28 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1688
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646136
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613801
INFO:root:FL Epoch: 28 Norm Difference for worker 1688 is 0.914154
INFO:root:FL Epoch: 28 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1791
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710561
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500623
INFO:root:FL Epoch: 28 Norm Difference for worker 1791 is 0.926444
INFO:root:FL Epoch: 28 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :744
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629047
INFO:root:Worker: 744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541650
INFO:root:FL Epoch: 28 Norm Difference for worker 744 is 0.920972
INFO:root:FL Epoch: 28 Done on worker:744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :605
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642406
INFO:root:Worker: 605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598610
INFO:root:FL Epoch: 28 Norm Difference for worker 605 is 0.923329
INFO:root:FL Epoch: 28 Done on worker:605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1458
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651980
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668348
INFO:root:FL Epoch: 28 Norm Difference for worker 1458 is 0.899943
INFO:root:FL Epoch: 28 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :452
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743746
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488575
INFO:root:FL Epoch: 28 Norm Difference for worker 452 is 0.900925
INFO:root:FL Epoch: 28 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 452
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 28 Ends   ===================
INFO:root:Epoch:28 Global Model Test Loss:0.636446253341787 and Test Accuracy:63.8235294117647 
INFO:root:Epoch:28 Global Model Backdoor Test Loss:1.0337224404017131                             and Backdoor Test Accuracy:20.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 29 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 29 Workers Selected : [173, 1917, 1341, 789, 961, 1601, 1755, 1597, 1906, 545]
INFO:root:FL Epoch: 29 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 29 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 29 Training on worker :173
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.761637
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.509775
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 29 Norm Difference for worker 173 is 1.081555
INFO:root:FL Epoch: 29 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1917
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670692
INFO:root:Worker: 1917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662601
INFO:root:FL Epoch: 29 Norm Difference for worker 1917 is 1.008174
INFO:root:FL Epoch: 29 Done on worker:1917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1341
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673871
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564774
INFO:root:FL Epoch: 29 Norm Difference for worker 1341 is 1.01657
INFO:root:FL Epoch: 29 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :789
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580495
INFO:root:Worker: 789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703894
INFO:root:FL Epoch: 29 Norm Difference for worker 789 is 1.075775
INFO:root:FL Epoch: 29 Done on worker:789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :961
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533490
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685108
INFO:root:FL Epoch: 29 Norm Difference for worker 961 is 1.079514
INFO:root:FL Epoch: 29 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1601
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.879336
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570801
INFO:root:FL Epoch: 29 Norm Difference for worker 1601 is 1.053163
INFO:root:FL Epoch: 29 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1755
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521301
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608173
INFO:root:FL Epoch: 29 Norm Difference for worker 1755 is 1.057739
INFO:root:FL Epoch: 29 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1597
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589978
INFO:root:Worker: 1597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529591
INFO:root:FL Epoch: 29 Norm Difference for worker 1597 is 1.064422
INFO:root:FL Epoch: 29 Done on worker:1597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1906
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781459
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556264
INFO:root:FL Epoch: 29 Norm Difference for worker 1906 is 1.031232
INFO:root:FL Epoch: 29 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :545
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611756
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468516
INFO:root:FL Epoch: 29 Norm Difference for worker 545 is 1.015992
INFO:root:FL Epoch: 29 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1917
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 29 Ends   ===================
INFO:root:Epoch:29 Global Model Test Loss:0.641176420099595 and Test Accuracy:62.94117647058823 
INFO:root:Epoch:29 Global Model Backdoor Test Loss:0.7488905092080435                             and Backdoor Test Accuracy:42.5 
INFO:root:=======================================================
INFO:root:================FL round 30 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 30 Workers Selected : [97, 1517, 1598, 1172, 189, 1585, 1215, 439, 573, 1311]
INFO:root:FL Epoch: 30 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 30 Num points on workers: [201 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 30 Training on worker :97
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629305
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.559137
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 97 is 0.987088
INFO:root:FL Epoch: 30 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1517
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611571
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626983
INFO:root:FL Epoch: 30 Norm Difference for worker 1517 is 1.036394
INFO:root:FL Epoch: 30 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1598
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728922
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688033
INFO:root:FL Epoch: 30 Norm Difference for worker 1598 is 0.922339
INFO:root:FL Epoch: 30 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1172
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1172 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678651
INFO:root:Worker: 1172 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564258
INFO:root:FL Epoch: 30 Norm Difference for worker 1172 is 1.008897
INFO:root:FL Epoch: 30 Done on worker:1172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :189
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.738156
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.645995
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 189 is 0.952781
INFO:root:FL Epoch: 30 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1585
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659440
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638964
INFO:root:FL Epoch: 30 Norm Difference for worker 1585 is 1.058542
INFO:root:FL Epoch: 30 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1215
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591485
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599573
INFO:root:FL Epoch: 30 Norm Difference for worker 1215 is 1.004274
INFO:root:FL Epoch: 30 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :439
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633366
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673503
INFO:root:FL Epoch: 30 Norm Difference for worker 439 is 0.951081
INFO:root:FL Epoch: 30 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :573
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523829
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596572
INFO:root:FL Epoch: 30 Norm Difference for worker 573 is 1.039423
INFO:root:FL Epoch: 30 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1311
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631756
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535227
INFO:root:FL Epoch: 30 Norm Difference for worker 1311 is 0.987004
INFO:root:FL Epoch: 30 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1598
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 30 Ends   ===================
INFO:root:Epoch:30 Global Model Test Loss:0.6336683595881742 and Test Accuracy:65.29411764705883 
INFO:root:Epoch:30 Global Model Backdoor Test Loss:0.7717547516028086                             and Backdoor Test Accuracy:41.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 31 Begins ===================
INFO:root:FL Epoch: 31 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 31 Workers Selected : [0, 1, 2, 1693, 599, 1613, 1374, 698, 1310, 1539]
INFO:root:FL Epoch: 31 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 31 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 31 Training on worker :0
INFO:root:FL Epoch: 31 Using Learning rate : 0.009417079539575504 
INFO:root:FL Epoch: 31 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585067
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583887
INFO:root:FL Epoch: 31 Worker: 0 Backdoor Test Loss: 0.48277657230695087 Backdoor Test Accuracy: 85.0
INFO:root:FL Epoch: 31 Worker: 0 Backdoor Train Loss: 0.5524589329957962 Backdoor Train Accuracy: 69.5
INFO:root:FL Epoch: 31 Norm Difference for worker 0 is 0.336999
INFO:root:FL Epoch: 31 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1
INFO:root:FL Epoch: 31 Using Learning rate : 0.009417079539575504 
INFO:root:FL Epoch: 31 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581066
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514418
INFO:root:FL Epoch: 31 Worker: 1 Backdoor Test Loss: 0.49205293754736584 Backdoor Test Accuracy: 84.16666666666667
INFO:root:FL Epoch: 31 Worker: 1 Backdoor Train Loss: 0.5506908893585205 Backdoor Train Accuracy: 71.0
INFO:root:FL Epoch: 31 Norm Difference for worker 1 is 0.337454
INFO:root:FL Epoch: 31 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :2
INFO:root:FL Epoch: 31 Using Learning rate : 0.009417079539575504 
INFO:root:FL Epoch: 31 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625738
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660608
INFO:root:FL Epoch: 31 Worker: 2 Backdoor Test Loss: 0.4791334420442581 Backdoor Test Accuracy: 85.0
INFO:root:FL Epoch: 31 Worker: 2 Backdoor Train Loss: 0.5485694617033005 Backdoor Train Accuracy: 70.5
INFO:root:FL Epoch: 31 Norm Difference for worker 2 is 0.350036
INFO:root:FL Epoch: 31 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1693
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653823
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502222
INFO:root:FL Epoch: 31 Norm Difference for worker 1693 is 0.908492
INFO:root:FL Epoch: 31 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :599
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577037
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507117
INFO:root:FL Epoch: 31 Norm Difference for worker 599 is 0.985024
INFO:root:FL Epoch: 31 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1613
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566991
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652737
INFO:root:FL Epoch: 31 Norm Difference for worker 1613 is 0.997115
INFO:root:FL Epoch: 31 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1374
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610818
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576754
INFO:root:FL Epoch: 31 Norm Difference for worker 1374 is 0.962671
INFO:root:FL Epoch: 31 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :698
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577589
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539450
INFO:root:FL Epoch: 31 Norm Difference for worker 698 is 0.910596
INFO:root:FL Epoch: 31 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1310
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1310 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661837
INFO:root:Worker: 1310 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557792
INFO:root:FL Epoch: 31 Norm Difference for worker 1310 is 1.012031
INFO:root:FL Epoch: 31 Done on worker:1310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1539
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654111
INFO:root:Worker: 1539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587209
INFO:root:FL Epoch: 31 Norm Difference for worker 1539 is 0.956949
INFO:root:FL Epoch: 31 Done on worker:1539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 31 Ends   ===================
INFO:root:Epoch:31 Global Model Test Loss:0.6586606818086961 and Test Accuracy:61.470588235294116 
INFO:root:Epoch:31 Global Model Backdoor Test Loss:0.48277657230695087                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 32 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 32 Workers Selected : [1528, 546, 1315, 41, 504, 250, 655, 1640, 1386, 46]
INFO:root:FL Epoch: 32 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 32 Num points on workers: [200 200 200 201 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 32 Training on worker :1528
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782094
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584339
INFO:root:FL Epoch: 32 Norm Difference for worker 1528 is 1.010275
INFO:root:FL Epoch: 32 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :546
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647985
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598110
INFO:root:FL Epoch: 32 Norm Difference for worker 546 is 1.079393
INFO:root:FL Epoch: 32 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1315
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484337
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541309
INFO:root:FL Epoch: 32 Norm Difference for worker 1315 is 1.048258
INFO:root:FL Epoch: 32 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :41
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 41 Train Epoch: 0 [0/201 (0%)]	Loss: 0.647852
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 41 Train Epoch: 1 [0/201 (0%)]	Loss: 0.705359
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 32 Norm Difference for worker 41 is 0.978597
INFO:root:FL Epoch: 32 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :504
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580770
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632260
INFO:root:FL Epoch: 32 Norm Difference for worker 504 is 0.965694
INFO:root:FL Epoch: 32 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :250
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.550830
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.442986
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 32 Norm Difference for worker 250 is 0.977076
INFO:root:FL Epoch: 32 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :655
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522684
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496049
INFO:root:FL Epoch: 32 Norm Difference for worker 655 is 0.972105
INFO:root:FL Epoch: 32 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1640
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750285
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603444
INFO:root:FL Epoch: 32 Norm Difference for worker 1640 is 1.017352
INFO:root:FL Epoch: 32 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1386
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651380
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564056
INFO:root:FL Epoch: 32 Norm Difference for worker 1386 is 1.04314
INFO:root:FL Epoch: 32 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :46
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.871641
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.674488
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 32 Norm Difference for worker 46 is 1.074351
INFO:root:FL Epoch: 32 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1528
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 32 Ends   ===================
INFO:root:Epoch:32 Global Model Test Loss:0.6271322562414057 and Test Accuracy:64.70588235294117 
INFO:root:Epoch:32 Global Model Backdoor Test Loss:0.7602175871531168                             and Backdoor Test Accuracy:50.0 
INFO:root:=======================================================
INFO:root:================FL round 33 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 33 Workers Selected : [1149, 529, 986, 911, 260, 855, 478, 1001, 407, 1886]
INFO:root:FL Epoch: 33 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 33 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 33 Training on worker :1149
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641257
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647826
INFO:root:FL Epoch: 33 Norm Difference for worker 1149 is 1.094518
INFO:root:FL Epoch: 33 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :529
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647419
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.757132
INFO:root:FL Epoch: 33 Norm Difference for worker 529 is 1.090147
INFO:root:FL Epoch: 33 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :986
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724047
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464159
INFO:root:FL Epoch: 33 Norm Difference for worker 986 is 1.052936
INFO:root:FL Epoch: 33 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :911
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659924
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544892
INFO:root:FL Epoch: 33 Norm Difference for worker 911 is 1.094545
INFO:root:FL Epoch: 33 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :260
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.580043
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.587728
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 33 Norm Difference for worker 260 is 1.012926
INFO:root:FL Epoch: 33 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :855
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.828708
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597939
INFO:root:FL Epoch: 33 Norm Difference for worker 855 is 1.152381
INFO:root:FL Epoch: 33 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :478
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732428
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541260
INFO:root:FL Epoch: 33 Norm Difference for worker 478 is 1.13941
INFO:root:FL Epoch: 33 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1001
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1001 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536858
INFO:root:Worker: 1001 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633069
INFO:root:FL Epoch: 33 Norm Difference for worker 1001 is 1.075705
INFO:root:FL Epoch: 33 Done on worker:1001
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :407
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515215
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551938
INFO:root:FL Epoch: 33 Norm Difference for worker 407 is 1.046358
INFO:root:FL Epoch: 33 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1886
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675330
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542812
INFO:root:FL Epoch: 33 Norm Difference for worker 1886 is 1.060388
INFO:root:FL Epoch: 33 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 529
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 33 Ends   ===================
INFO:root:Epoch:33 Global Model Test Loss:0.6139520985238692 and Test Accuracy:64.70588235294117 
INFO:root:Epoch:33 Global Model Backdoor Test Loss:0.808241625626882                             and Backdoor Test Accuracy:32.5 
INFO:root:=======================================================
INFO:root:================FL round 34 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 34 Workers Selected : [1640, 942, 389, 907, 1081, 1797, 1890, 922, 1593, 1411]
INFO:root:FL Epoch: 34 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 34 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 34 Training on worker :1640
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728012
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577363
INFO:root:FL Epoch: 34 Norm Difference for worker 1640 is 0.860909
INFO:root:FL Epoch: 34 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :942
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606377
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666044
INFO:root:FL Epoch: 34 Norm Difference for worker 942 is 0.923243
INFO:root:FL Epoch: 34 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :389
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536164
INFO:root:Worker: 389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561345
INFO:root:FL Epoch: 34 Norm Difference for worker 389 is 0.96577
INFO:root:FL Epoch: 34 Done on worker:389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :907
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648620
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627875
INFO:root:FL Epoch: 34 Norm Difference for worker 907 is 1.000079
INFO:root:FL Epoch: 34 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1081
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760350
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592589
INFO:root:FL Epoch: 34 Norm Difference for worker 1081 is 0.898052
INFO:root:FL Epoch: 34 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1797
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599552
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613180
INFO:root:FL Epoch: 34 Norm Difference for worker 1797 is 0.947829
INFO:root:FL Epoch: 34 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1890
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630894
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649723
INFO:root:FL Epoch: 34 Norm Difference for worker 1890 is 0.913836
INFO:root:FL Epoch: 34 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :922
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662777
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638207
INFO:root:FL Epoch: 34 Norm Difference for worker 922 is 0.918167
INFO:root:FL Epoch: 34 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1593
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563503
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568924
INFO:root:FL Epoch: 34 Norm Difference for worker 1593 is 0.908347
INFO:root:FL Epoch: 34 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1411
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631675
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677597
INFO:root:FL Epoch: 34 Norm Difference for worker 1411 is 0.936881
INFO:root:FL Epoch: 34 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1640
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 34 Ends   ===================
INFO:root:Epoch:34 Global Model Test Loss:0.6189203420106102 and Test Accuracy:63.529411764705884 
INFO:root:Epoch:34 Global Model Backdoor Test Loss:0.8022958040237427                             and Backdoor Test Accuracy:34.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 35 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 35 Workers Selected : [1678, 1654, 1413, 547, 1443, 144, 892, 191, 340, 1558]
INFO:root:FL Epoch: 35 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 35 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 35 Training on worker :1678
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592213
INFO:root:Worker: 1678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620603
INFO:root:FL Epoch: 35 Norm Difference for worker 1678 is 0.874823
INFO:root:FL Epoch: 35 Done on worker:1678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1654
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602241
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614875
INFO:root:FL Epoch: 35 Norm Difference for worker 1654 is 0.863605
INFO:root:FL Epoch: 35 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1413
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571716
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638608
INFO:root:FL Epoch: 35 Norm Difference for worker 1413 is 0.886481
INFO:root:FL Epoch: 35 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :547
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536780
INFO:root:Worker: 547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651933
INFO:root:FL Epoch: 35 Norm Difference for worker 547 is 0.927757
INFO:root:FL Epoch: 35 Done on worker:547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1443
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.829755
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678287
INFO:root:FL Epoch: 35 Norm Difference for worker 1443 is 0.88008
INFO:root:FL Epoch: 35 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :144
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.624474
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.602515
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 144 is 0.898598
INFO:root:FL Epoch: 35 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :892
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.873781
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644676
INFO:root:FL Epoch: 35 Norm Difference for worker 892 is 0.884149
INFO:root:FL Epoch: 35 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :191
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.720537
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.708426
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 191 is 0.891236
INFO:root:FL Epoch: 35 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :340
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704192
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488191
INFO:root:FL Epoch: 35 Norm Difference for worker 340 is 0.89173
INFO:root:FL Epoch: 35 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1558
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736964
INFO:root:Worker: 1558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613814
INFO:root:FL Epoch: 35 Norm Difference for worker 1558 is 0.893808
INFO:root:FL Epoch: 35 Done on worker:1558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1678
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 35 Ends   ===================
INFO:root:Epoch:35 Global Model Test Loss:0.6112272301140953 and Test Accuracy:65.58823529411765 
INFO:root:Epoch:35 Global Model Backdoor Test Loss:0.7344204088052114                             and Backdoor Test Accuracy:52.5 
INFO:root:=======================================================
INFO:root:================FL round 36 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 36 Workers Selected : [1323, 1216, 1937, 432, 1511, 669, 1891, 1824, 228, 447]
INFO:root:FL Epoch: 36 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 36 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 36 Training on worker :1323
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.866471
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531750
INFO:root:FL Epoch: 36 Norm Difference for worker 1323 is 1.065405
INFO:root:FL Epoch: 36 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1216
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1216 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618229
INFO:root:Worker: 1216 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563036
INFO:root:FL Epoch: 36 Norm Difference for worker 1216 is 1.093332
INFO:root:FL Epoch: 36 Done on worker:1216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1937
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499736
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509139
INFO:root:FL Epoch: 36 Norm Difference for worker 1937 is 1.102894
INFO:root:FL Epoch: 36 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :432
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693446
INFO:root:Worker: 432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557616
INFO:root:FL Epoch: 36 Norm Difference for worker 432 is 0.986202
INFO:root:FL Epoch: 36 Done on worker:432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1511
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653430
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.740723
INFO:root:FL Epoch: 36 Norm Difference for worker 1511 is 1.108284
INFO:root:FL Epoch: 36 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :669
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659710
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558231
INFO:root:FL Epoch: 36 Norm Difference for worker 669 is 1.208196
INFO:root:FL Epoch: 36 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1891
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697553
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557401
INFO:root:FL Epoch: 36 Norm Difference for worker 1891 is 0.986785
INFO:root:FL Epoch: 36 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1824
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808685
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671495
INFO:root:FL Epoch: 36 Norm Difference for worker 1824 is 1.107919
INFO:root:FL Epoch: 36 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :228
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.623081
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.506312
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 36 Norm Difference for worker 228 is 1.127185
INFO:root:FL Epoch: 36 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :447
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499760
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602813
INFO:root:FL Epoch: 36 Norm Difference for worker 447 is 1.096793
INFO:root:FL Epoch: 36 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 432
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 36 Ends   ===================
INFO:root:Epoch:36 Global Model Test Loss:0.6123031290138469 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:36 Global Model Backdoor Test Loss:0.9302405615647634                             and Backdoor Test Accuracy:35.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 37 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 37 Workers Selected : [400, 3, 1265, 532, 1836, 270, 1792, 1318, 159, 894]
INFO:root:FL Epoch: 37 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 37 Num points on workers: [200 201 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 37 Training on worker :400
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 400 Train Epoch: 0 [0/200 (0%)]	Loss: 0.818042
INFO:root:Worker: 400 Train Epoch: 1 [0/200 (0%)]	Loss: 0.755094
INFO:root:FL Epoch: 37 Norm Difference for worker 400 is 1.119455
INFO:root:FL Epoch: 37 Done on worker:400
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :3
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.757562
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.611077
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 3 is 1.151807
INFO:root:FL Epoch: 37 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1265
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663044
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503157
INFO:root:FL Epoch: 37 Norm Difference for worker 1265 is 1.11437
INFO:root:FL Epoch: 37 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :532
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.800859
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502474
INFO:root:FL Epoch: 37 Norm Difference for worker 532 is 1.14406
INFO:root:FL Epoch: 37 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1836
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638643
INFO:root:Worker: 1836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427403
INFO:root:FL Epoch: 37 Norm Difference for worker 1836 is 1.0495
INFO:root:FL Epoch: 37 Done on worker:1836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :270
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.577321
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.549832
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 270 is 1.101277
INFO:root:FL Epoch: 37 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1792
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584233
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483105
INFO:root:FL Epoch: 37 Norm Difference for worker 1792 is 1.045112
INFO:root:FL Epoch: 37 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1318
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687846
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569981
INFO:root:FL Epoch: 37 Norm Difference for worker 1318 is 1.113803
INFO:root:FL Epoch: 37 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :159
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.471306
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.642045
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 159 is 1.074927
INFO:root:FL Epoch: 37 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :894
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715079
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543612
INFO:root:FL Epoch: 37 Norm Difference for worker 894 is 1.124709
INFO:root:FL Epoch: 37 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1836
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 37 Ends   ===================
INFO:root:Epoch:37 Global Model Test Loss:0.6110641693367678 and Test Accuracy:65.29411764705883 
INFO:root:Epoch:37 Global Model Backdoor Test Loss:0.9086995124816895                             and Backdoor Test Accuracy:34.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 38 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 38 Workers Selected : [91, 406, 1341, 1142, 961, 1634, 278, 1725, 1426, 171]
INFO:root:FL Epoch: 38 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 38 Num points on workers: [201 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 38 Training on worker :91
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.459326
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.613619
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 91 is 1.046231
INFO:root:FL Epoch: 38 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :406
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616183
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600752
INFO:root:FL Epoch: 38 Norm Difference for worker 406 is 1.082858
INFO:root:FL Epoch: 38 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1341
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707277
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578323
INFO:root:FL Epoch: 38 Norm Difference for worker 1341 is 0.996622
INFO:root:FL Epoch: 38 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1142
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621421
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529680
INFO:root:FL Epoch: 38 Norm Difference for worker 1142 is 1.030213
INFO:root:FL Epoch: 38 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :961
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676671
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459683
INFO:root:FL Epoch: 38 Norm Difference for worker 961 is 1.057819
INFO:root:FL Epoch: 38 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1634
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565973
INFO:root:Worker: 1634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549280
INFO:root:FL Epoch: 38 Norm Difference for worker 1634 is 1.051123
INFO:root:FL Epoch: 38 Done on worker:1634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :278
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.757567
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.646903
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 278 is 1.011704
INFO:root:FL Epoch: 38 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1725
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706183
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.715824
INFO:root:FL Epoch: 38 Norm Difference for worker 1725 is 1.082098
INFO:root:FL Epoch: 38 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1426
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677117
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660955
INFO:root:FL Epoch: 38 Norm Difference for worker 1426 is 1.066932
INFO:root:FL Epoch: 38 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :171
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.579588
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.737785
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 171 is 1.04879
INFO:root:FL Epoch: 38 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 278
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 38 Ends   ===================
INFO:root:Epoch:38 Global Model Test Loss:0.6216475753223195 and Test Accuracy:65.0 
INFO:root:Epoch:38 Global Model Backdoor Test Loss:0.719736377398173                             and Backdoor Test Accuracy:49.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 39 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 39 Workers Selected : [793, 1430, 1259, 83, 963, 727, 1798, 1045, 795, 1544]
INFO:root:FL Epoch: 39 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 39 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 39 Training on worker :793
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556193
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544532
INFO:root:FL Epoch: 39 Norm Difference for worker 793 is 0.874062
INFO:root:FL Epoch: 39 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1430
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615211
INFO:root:Worker: 1430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545473
INFO:root:FL Epoch: 39 Norm Difference for worker 1430 is 0.885488
INFO:root:FL Epoch: 39 Done on worker:1430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1259
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622197
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559729
INFO:root:FL Epoch: 39 Norm Difference for worker 1259 is 0.866438
INFO:root:FL Epoch: 39 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :83
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 83 Train Epoch: 0 [0/201 (0%)]	Loss: 0.600240
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 83 Train Epoch: 1 [0/201 (0%)]	Loss: 0.562035
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 39 Norm Difference for worker 83 is 0.883458
INFO:root:FL Epoch: 39 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :963
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 963 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631238
INFO:root:Worker: 963 Train Epoch: 1 [0/200 (0%)]	Loss: 0.801234
INFO:root:FL Epoch: 39 Norm Difference for worker 963 is 0.895999
INFO:root:FL Epoch: 39 Done on worker:963
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :727
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638197
INFO:root:Worker: 727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611082
INFO:root:FL Epoch: 39 Norm Difference for worker 727 is 0.931585
INFO:root:FL Epoch: 39 Done on worker:727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1798
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688139
INFO:root:Worker: 1798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622718
INFO:root:FL Epoch: 39 Norm Difference for worker 1798 is 0.862589
INFO:root:FL Epoch: 39 Done on worker:1798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1045
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639979
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673936
INFO:root:FL Epoch: 39 Norm Difference for worker 1045 is 0.895547
INFO:root:FL Epoch: 39 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :795
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575828
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609671
INFO:root:FL Epoch: 39 Norm Difference for worker 795 is 0.937654
INFO:root:FL Epoch: 39 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1544
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595520
INFO:root:Worker: 1544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604052
INFO:root:FL Epoch: 39 Norm Difference for worker 1544 is 0.864079
INFO:root:FL Epoch: 39 Done on worker:1544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 793
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 39 Ends   ===================
INFO:root:Epoch:39 Global Model Test Loss:0.6257785190554226 and Test Accuracy:65.88235294117646 
INFO:root:Epoch:39 Global Model Backdoor Test Loss:0.7359961370627085                             and Backdoor Test Accuracy:51.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 40 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 40 Workers Selected : [1876, 1511, 1817, 696, 514, 724, 71, 1627, 1036, 1139]
INFO:root:FL Epoch: 40 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 40 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 40 Training on worker :1876
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729375
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561417
INFO:root:FL Epoch: 40 Norm Difference for worker 1876 is 1.116665
INFO:root:FL Epoch: 40 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1511
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604912
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668011
INFO:root:FL Epoch: 40 Norm Difference for worker 1511 is 1.038802
INFO:root:FL Epoch: 40 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1817
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618813
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505120
INFO:root:FL Epoch: 40 Norm Difference for worker 1817 is 1.062309
INFO:root:FL Epoch: 40 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :696
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620678
INFO:root:Worker: 696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518121
INFO:root:FL Epoch: 40 Norm Difference for worker 696 is 1.001408
INFO:root:FL Epoch: 40 Done on worker:696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :514
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584150
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558625
INFO:root:FL Epoch: 40 Norm Difference for worker 514 is 1.035482
INFO:root:FL Epoch: 40 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :724
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555273
INFO:root:Worker: 724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649873
INFO:root:FL Epoch: 40 Norm Difference for worker 724 is 1.036988
INFO:root:FL Epoch: 40 Done on worker:724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :71
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.523252
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.570712
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 40 Norm Difference for worker 71 is 0.994471
INFO:root:FL Epoch: 40 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1627
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699196
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574389
INFO:root:FL Epoch: 40 Norm Difference for worker 1627 is 1.00212
INFO:root:FL Epoch: 40 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1036
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587938
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604262
INFO:root:FL Epoch: 40 Norm Difference for worker 1036 is 1.027447
INFO:root:FL Epoch: 40 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1139
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577552
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539995
INFO:root:FL Epoch: 40 Norm Difference for worker 1139 is 1.008952
INFO:root:FL Epoch: 40 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 696
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 40 Ends   ===================
INFO:root:Epoch:40 Global Model Test Loss:0.6393647982793695 and Test Accuracy:62.35294117647059 
INFO:root:Epoch:40 Global Model Backdoor Test Loss:1.0026430288950603                             and Backdoor Test Accuracy:24.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 41 Begins ===================
INFO:root:FL Epoch: 41 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 41 Workers Selected : [0, 1, 2, 431, 1920, 659, 855, 1679, 48, 359]
INFO:root:FL Epoch: 41 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 41 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 41 Training on worker :0
INFO:root:FL Epoch: 41 Using Learning rate : 0.009230424014270334 
INFO:root:FL Epoch: 41 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660736
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679861
INFO:root:FL Epoch: 41 Worker: 0 Backdoor Test Loss: 0.4328425923983256 Backdoor Test Accuracy: 86.66666666666667
INFO:root:FL Epoch: 41 Worker: 0 Backdoor Train Loss: 0.5366819351911545 Backdoor Train Accuracy: 72.0
INFO:root:FL Epoch: 41 Norm Difference for worker 0 is 0.496466
INFO:root:FL Epoch: 41 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1
INFO:root:FL Epoch: 41 Using Learning rate : 0.009230424014270334 
INFO:root:FL Epoch: 41 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.827355
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669548
INFO:root:FL Epoch: 41 Worker: 1 Backdoor Test Loss: 0.4333360294500987 Backdoor Test Accuracy: 86.66666666666667
INFO:root:FL Epoch: 41 Worker: 1 Backdoor Train Loss: 0.5372618943452835 Backdoor Train Accuracy: 72.5
INFO:root:FL Epoch: 41 Norm Difference for worker 1 is 0.49775
INFO:root:FL Epoch: 41 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :2
INFO:root:FL Epoch: 41 Using Learning rate : 0.009230424014270334 
INFO:root:FL Epoch: 41 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724349
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.779710
INFO:root:FL Epoch: 41 Worker: 2 Backdoor Test Loss: 0.4498955508073171 Backdoor Test Accuracy: 85.0
INFO:root:FL Epoch: 41 Worker: 2 Backdoor Train Loss: 0.5385558784008027 Backdoor Train Accuracy: 72.5
INFO:root:FL Epoch: 41 Norm Difference for worker 2 is 0.477224
INFO:root:FL Epoch: 41 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :431
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689622
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518346
INFO:root:FL Epoch: 41 Norm Difference for worker 431 is 1.026055
INFO:root:FL Epoch: 41 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1920
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705605
INFO:root:Worker: 1920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552731
INFO:root:FL Epoch: 41 Norm Difference for worker 1920 is 1.054564
INFO:root:FL Epoch: 41 Done on worker:1920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :659
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669552
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595203
INFO:root:FL Epoch: 41 Norm Difference for worker 659 is 1.044384
INFO:root:FL Epoch: 41 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :855
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742814
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686323
INFO:root:FL Epoch: 41 Norm Difference for worker 855 is 1.04799
INFO:root:FL Epoch: 41 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1679
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522368
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536768
INFO:root:FL Epoch: 41 Norm Difference for worker 1679 is 1.064679
INFO:root:FL Epoch: 41 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :48
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.735136
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538489
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 41 Norm Difference for worker 48 is 0.995111
INFO:root:FL Epoch: 41 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :359
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675990
INFO:root:Worker: 359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.740032
INFO:root:FL Epoch: 41 Norm Difference for worker 359 is 1.063754
INFO:root:FL Epoch: 41 Done on worker:359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 41 Ends   ===================
INFO:root:Epoch:41 Global Model Test Loss:0.6477535437135136 and Test Accuracy:63.529411764705884 
INFO:root:Epoch:41 Global Model Backdoor Test Loss:0.4498955508073171                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 42 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 42 Workers Selected : [1016, 758, 1919, 1693, 1465, 882, 176, 1854, 107, 77]
INFO:root:FL Epoch: 42 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 42 Num points on workers: [200 200 200 200 200 200 201 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 42 Training on worker :1016
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741959
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559040
INFO:root:FL Epoch: 42 Norm Difference for worker 1016 is 1.080654
INFO:root:FL Epoch: 42 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :758
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635330
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591645
INFO:root:FL Epoch: 42 Norm Difference for worker 758 is 0.996092
INFO:root:FL Epoch: 42 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1919
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.785172
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.742185
INFO:root:FL Epoch: 42 Norm Difference for worker 1919 is 1.06927
INFO:root:FL Epoch: 42 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1693
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698586
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612881
INFO:root:FL Epoch: 42 Norm Difference for worker 1693 is 0.994517
INFO:root:FL Epoch: 42 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1465
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583203
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661034
INFO:root:FL Epoch: 42 Norm Difference for worker 1465 is 0.992207
INFO:root:FL Epoch: 42 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :882
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651876
INFO:root:Worker: 882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668162
INFO:root:FL Epoch: 42 Norm Difference for worker 882 is 1.000822
INFO:root:FL Epoch: 42 Done on worker:882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :176
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 176 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518411
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 176 Train Epoch: 1 [0/201 (0%)]	Loss: 0.625795
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 176 is 1.012794
INFO:root:FL Epoch: 42 Done on worker:176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1854
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762742
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613809
INFO:root:FL Epoch: 42 Norm Difference for worker 1854 is 1.097819
INFO:root:FL Epoch: 42 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :107
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 107 Train Epoch: 0 [0/201 (0%)]	Loss: 0.845675
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 107 Train Epoch: 1 [0/201 (0%)]	Loss: 0.594203
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 107 is 1.073631
INFO:root:FL Epoch: 42 Done on worker:107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :77
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.538917
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.724245
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 42 Norm Difference for worker 77 is 1.043429
INFO:root:FL Epoch: 42 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 758
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 42 Ends   ===================
INFO:root:Epoch:42 Global Model Test Loss:0.6203556691899019 and Test Accuracy:65.0 
INFO:root:Epoch:42 Global Model Backdoor Test Loss:0.5833663443724314                             and Backdoor Test Accuracy:69.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 43 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 43 Workers Selected : [301, 961, 1081, 165, 1765, 96, 21, 425, 1827, 1721]
INFO:root:FL Epoch: 43 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994 0.1002994
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 43 Num points on workers: [201 200 200 201 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 43 Training on worker :301
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.760280
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.552624
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 301 is 0.963572
INFO:root:FL Epoch: 43 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :961
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686263
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596164
INFO:root:FL Epoch: 43 Norm Difference for worker 961 is 0.951356
INFO:root:FL Epoch: 43 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1081
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592897
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506960
INFO:root:FL Epoch: 43 Norm Difference for worker 1081 is 0.99244
INFO:root:FL Epoch: 43 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :165
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.551036
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.602281
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 165 is 0.964678
INFO:root:FL Epoch: 43 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1765
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594747
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703113
INFO:root:FL Epoch: 43 Norm Difference for worker 1765 is 0.941561
INFO:root:FL Epoch: 43 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :96
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 96 Train Epoch: 0 [0/201 (0%)]	Loss: 0.547036
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 96 Train Epoch: 1 [0/201 (0%)]	Loss: 0.671793
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 96 is 0.918217
INFO:root:FL Epoch: 43 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :21
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.376046
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.645051
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 43 Norm Difference for worker 21 is 0.940445
INFO:root:FL Epoch: 43 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :425
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672427
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.868872
INFO:root:FL Epoch: 43 Norm Difference for worker 425 is 0.948381
INFO:root:FL Epoch: 43 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1827
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655790
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628469
INFO:root:FL Epoch: 43 Norm Difference for worker 1827 is 0.973083
INFO:root:FL Epoch: 43 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1721
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597416
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581751
INFO:root:FL Epoch: 43 Norm Difference for worker 1721 is 1.002234
INFO:root:FL Epoch: 43 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 96
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 43 Ends   ===================
INFO:root:Epoch:43 Global Model Test Loss:0.6237877659937915 and Test Accuracy:66.17647058823529 
INFO:root:Epoch:43 Global Model Backdoor Test Loss:0.5922035872936249                             and Backdoor Test Accuracy:67.5 
INFO:root:=======================================================
INFO:root:================FL round 44 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 44 Workers Selected : [617, 842, 851, 604, 1478, 1239, 1744, 1946, 1499, 1072]
INFO:root:FL Epoch: 44 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 44 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 44 Training on worker :617
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634392
INFO:root:Worker: 617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520298
INFO:root:FL Epoch: 44 Norm Difference for worker 617 is 1.0605
INFO:root:FL Epoch: 44 Done on worker:617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :842
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 842 Train Epoch: 0 [0/200 (0%)]	Loss: 0.846977
INFO:root:Worker: 842 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676867
INFO:root:FL Epoch: 44 Norm Difference for worker 842 is 0.960419
INFO:root:FL Epoch: 44 Done on worker:842
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :851
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610741
INFO:root:Worker: 851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634148
INFO:root:FL Epoch: 44 Norm Difference for worker 851 is 0.901229
INFO:root:FL Epoch: 44 Done on worker:851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :604
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711281
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609052
INFO:root:FL Epoch: 44 Norm Difference for worker 604 is 0.976548
INFO:root:FL Epoch: 44 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1478
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581722
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580206
INFO:root:FL Epoch: 44 Norm Difference for worker 1478 is 0.949663
INFO:root:FL Epoch: 44 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1239
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617537
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643423
INFO:root:FL Epoch: 44 Norm Difference for worker 1239 is 0.933158
INFO:root:FL Epoch: 44 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1744
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780867
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571516
INFO:root:FL Epoch: 44 Norm Difference for worker 1744 is 0.948144
INFO:root:FL Epoch: 44 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1946
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591590
INFO:root:Worker: 1946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533879
INFO:root:FL Epoch: 44 Norm Difference for worker 1946 is 0.940642
INFO:root:FL Epoch: 44 Done on worker:1946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1499
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554334
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629037
INFO:root:FL Epoch: 44 Norm Difference for worker 1499 is 0.982079
INFO:root:FL Epoch: 44 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1072
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1072 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655972
INFO:root:Worker: 1072 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514487
INFO:root:FL Epoch: 44 Norm Difference for worker 1072 is 0.909963
INFO:root:FL Epoch: 44 Done on worker:1072
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 851
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 44 Ends   ===================
INFO:root:Epoch:44 Global Model Test Loss:0.6091713239164913 and Test Accuracy:67.94117647058823 
INFO:root:Epoch:44 Global Model Backdoor Test Loss:0.5759191115697225                             and Backdoor Test Accuracy:69.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 45 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 45 Workers Selected : [284, 629, 1483, 496, 1902, 261, 1691, 309, 195, 346]
INFO:root:FL Epoch: 45 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004
 0.1002994 0.1002994 0.0998004]
INFO:root:FL Epoch: 45 Num points on workers: [201 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 45 Training on worker :284
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.716399
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.604477
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 284 is 1.01841
INFO:root:FL Epoch: 45 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :629
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518317
INFO:root:Worker: 629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462444
INFO:root:FL Epoch: 45 Norm Difference for worker 629 is 1.029733
INFO:root:FL Epoch: 45 Done on worker:629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1483
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523210
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561721
INFO:root:FL Epoch: 45 Norm Difference for worker 1483 is 1.031312
INFO:root:FL Epoch: 45 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :496
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700628
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525567
INFO:root:FL Epoch: 45 Norm Difference for worker 496 is 0.952476
INFO:root:FL Epoch: 45 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1902
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604051
INFO:root:Worker: 1902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491999
INFO:root:FL Epoch: 45 Norm Difference for worker 1902 is 1.031432
INFO:root:FL Epoch: 45 Done on worker:1902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :261
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.599016
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.521100
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 261 is 1.008374
INFO:root:FL Epoch: 45 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1691
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695974
INFO:root:Worker: 1691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538926
INFO:root:FL Epoch: 45 Norm Difference for worker 1691 is 1.010306
INFO:root:FL Epoch: 45 Done on worker:1691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :309
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 309 Train Epoch: 0 [0/201 (0%)]	Loss: 0.737451
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 309 Train Epoch: 1 [0/201 (0%)]	Loss: 0.537199
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 309 is 1.038503
INFO:root:FL Epoch: 45 Done on worker:309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :195
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.625153
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.468463
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 195 is 1.071538
INFO:root:FL Epoch: 45 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :346
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578862
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664484
INFO:root:FL Epoch: 45 Norm Difference for worker 346 is 1.096301
INFO:root:FL Epoch: 45 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 496
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 45 Ends   ===================
INFO:root:Epoch:45 Global Model Test Loss:0.589037116836099 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:45 Global Model Backdoor Test Loss:0.6541234254837036                             and Backdoor Test Accuracy:59.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 46 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 46 Workers Selected : [1012, 1287, 1772, 973, 355, 15, 1335, 859, 1060, 1175]
INFO:root:FL Epoch: 46 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 46 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 46 Training on worker :1012
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664746
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581328
INFO:root:FL Epoch: 46 Norm Difference for worker 1012 is 1.016249
INFO:root:FL Epoch: 46 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1287
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1287 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681320
INFO:root:Worker: 1287 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597880
INFO:root:FL Epoch: 46 Norm Difference for worker 1287 is 1.145375
INFO:root:FL Epoch: 46 Done on worker:1287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1772
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718712
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551804
INFO:root:FL Epoch: 46 Norm Difference for worker 1772 is 1.07298
INFO:root:FL Epoch: 46 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :973
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588118
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.786963
INFO:root:FL Epoch: 46 Norm Difference for worker 973 is 1.136275
INFO:root:FL Epoch: 46 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :355
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682964
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.793247
INFO:root:FL Epoch: 46 Norm Difference for worker 355 is 1.109982
INFO:root:FL Epoch: 46 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :15
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.544138
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.416937
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 46 Norm Difference for worker 15 is 1.070711
INFO:root:FL Epoch: 46 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1335
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416936
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591416
INFO:root:FL Epoch: 46 Norm Difference for worker 1335 is 1.107659
INFO:root:FL Epoch: 46 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :859
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688532
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660829
INFO:root:FL Epoch: 46 Norm Difference for worker 859 is 1.155358
INFO:root:FL Epoch: 46 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1060
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1060 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499296
INFO:root:Worker: 1060 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514744
INFO:root:FL Epoch: 46 Norm Difference for worker 1060 is 1.14017
INFO:root:FL Epoch: 46 Done on worker:1060
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1175
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502463
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549134
INFO:root:FL Epoch: 46 Norm Difference for worker 1175 is 1.081982
INFO:root:FL Epoch: 46 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1012
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 46 Ends   ===================
INFO:root:Epoch:46 Global Model Test Loss:0.5976890272953931 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:46 Global Model Backdoor Test Loss:0.6801754534244537                             and Backdoor Test Accuracy:55.0 
INFO:root:=======================================================
INFO:root:================FL round 47 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 47 Workers Selected : [1026, 1386, 370, 1316, 1423, 1323, 1440, 374, 641, 685]
INFO:root:FL Epoch: 47 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 47 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 47 Training on worker :1026
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1026 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751660
INFO:root:Worker: 1026 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532315
INFO:root:FL Epoch: 47 Norm Difference for worker 1026 is 1.029851
INFO:root:FL Epoch: 47 Done on worker:1026
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1386
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642250
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564776
INFO:root:FL Epoch: 47 Norm Difference for worker 1386 is 1.011683
INFO:root:FL Epoch: 47 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :370
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633387
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531607
INFO:root:FL Epoch: 47 Norm Difference for worker 370 is 1.030131
INFO:root:FL Epoch: 47 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1316
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473966
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559170
INFO:root:FL Epoch: 47 Norm Difference for worker 1316 is 0.974466
INFO:root:FL Epoch: 47 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1423
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691156
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618037
INFO:root:FL Epoch: 47 Norm Difference for worker 1423 is 1.06004
INFO:root:FL Epoch: 47 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1323
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703945
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452697
INFO:root:FL Epoch: 47 Norm Difference for worker 1323 is 1.050504
INFO:root:FL Epoch: 47 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1440
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551008
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610856
INFO:root:FL Epoch: 47 Norm Difference for worker 1440 is 0.991497
INFO:root:FL Epoch: 47 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :374
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626168
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435422
INFO:root:FL Epoch: 47 Norm Difference for worker 374 is 1.034216
INFO:root:FL Epoch: 47 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :641
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513373
INFO:root:Worker: 641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681548
INFO:root:FL Epoch: 47 Norm Difference for worker 641 is 1.078347
INFO:root:FL Epoch: 47 Done on worker:641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :685
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595746
INFO:root:Worker: 685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572748
INFO:root:FL Epoch: 47 Norm Difference for worker 685 is 1.013261
INFO:root:FL Epoch: 47 Done on worker:685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1316
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 47 Ends   ===================
INFO:root:Epoch:47 Global Model Test Loss:0.5911551521104925 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:47 Global Model Backdoor Test Loss:0.6575227876504263                             and Backdoor Test Accuracy:60.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 48 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 48 Workers Selected : [742, 885, 169, 1527, 884, 1072, 458, 1623, 1318, 1808]
INFO:root:FL Epoch: 48 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 48 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 48 Training on worker :742
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562193
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536443
INFO:root:FL Epoch: 48 Norm Difference for worker 742 is 1.033435
INFO:root:FL Epoch: 48 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :885
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761894
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704793
INFO:root:FL Epoch: 48 Norm Difference for worker 885 is 1.048069
INFO:root:FL Epoch: 48 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :169
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.592815
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.594906
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 48 Norm Difference for worker 169 is 1.009068
INFO:root:FL Epoch: 48 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1527
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489060
INFO:root:Worker: 1527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656218
INFO:root:FL Epoch: 48 Norm Difference for worker 1527 is 1.010161
INFO:root:FL Epoch: 48 Done on worker:1527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :884
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588306
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547926
INFO:root:FL Epoch: 48 Norm Difference for worker 884 is 1.028335
INFO:root:FL Epoch: 48 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1072
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1072 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539600
INFO:root:Worker: 1072 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507632
INFO:root:FL Epoch: 48 Norm Difference for worker 1072 is 0.971652
INFO:root:FL Epoch: 48 Done on worker:1072
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :458
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507322
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533458
INFO:root:FL Epoch: 48 Norm Difference for worker 458 is 1.019978
INFO:root:FL Epoch: 48 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1623
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592802
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600954
INFO:root:FL Epoch: 48 Norm Difference for worker 1623 is 0.994921
INFO:root:FL Epoch: 48 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1318
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648802
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608459
INFO:root:FL Epoch: 48 Norm Difference for worker 1318 is 0.994436
INFO:root:FL Epoch: 48 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1808
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628216
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563134
INFO:root:FL Epoch: 48 Norm Difference for worker 1808 is 1.110405
INFO:root:FL Epoch: 48 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 169
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 48 Ends   ===================
INFO:root:Epoch:48 Global Model Test Loss:0.596349405891755 and Test Accuracy:67.6470588235294 
INFO:root:Epoch:48 Global Model Backdoor Test Loss:0.779817928870519                             and Backdoor Test Accuracy:45.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 49 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 49 Workers Selected : [1089, 1220, 832, 348, 1483, 1709, 170, 862, 1619, 52]
INFO:root:FL Epoch: 49 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 49 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 49 Training on worker :1089
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1089 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542255
INFO:root:Worker: 1089 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629133
INFO:root:FL Epoch: 49 Norm Difference for worker 1089 is 0.990398
INFO:root:FL Epoch: 49 Done on worker:1089
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1220
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499228
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487628
INFO:root:FL Epoch: 49 Norm Difference for worker 1220 is 0.961915
INFO:root:FL Epoch: 49 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :832
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606271
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520298
INFO:root:FL Epoch: 49 Norm Difference for worker 832 is 0.978491
INFO:root:FL Epoch: 49 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :348
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422882
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.778252
INFO:root:FL Epoch: 49 Norm Difference for worker 348 is 1.059243
INFO:root:FL Epoch: 49 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1483
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675057
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530257
INFO:root:FL Epoch: 49 Norm Difference for worker 1483 is 0.984938
INFO:root:FL Epoch: 49 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1709
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607745
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620443
INFO:root:FL Epoch: 49 Norm Difference for worker 1709 is 1.083808
INFO:root:FL Epoch: 49 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :170
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.636493
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.449132
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 170 is 1.040697
INFO:root:FL Epoch: 49 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :862
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692083
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582256
INFO:root:FL Epoch: 49 Norm Difference for worker 862 is 1.049036
INFO:root:FL Epoch: 49 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1619
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744961
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578283
INFO:root:FL Epoch: 49 Norm Difference for worker 1619 is 0.986962
INFO:root:FL Epoch: 49 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :52
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 52 Train Epoch: 0 [0/201 (0%)]	Loss: 0.544755
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 52 Train Epoch: 1 [0/201 (0%)]	Loss: 0.614863
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 52 is 1.042104
INFO:root:FL Epoch: 49 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1089
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 49 Ends   ===================
INFO:root:Epoch:49 Global Model Test Loss:0.5966541381443248 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:49 Global Model Backdoor Test Loss:0.8113861183325449                             and Backdoor Test Accuracy:41.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 50 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 50 Workers Selected : [1159, 973, 918, 978, 1454, 1102, 762, 302, 1871, 580]
INFO:root:FL Epoch: 50 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 50 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 50 Training on worker :1159
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1159 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763893
INFO:root:Worker: 1159 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626611
INFO:root:FL Epoch: 50 Norm Difference for worker 1159 is 1.047826
INFO:root:FL Epoch: 50 Done on worker:1159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :973
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648599
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692221
INFO:root:FL Epoch: 50 Norm Difference for worker 973 is 1.075505
INFO:root:FL Epoch: 50 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :918
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580939
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574304
INFO:root:FL Epoch: 50 Norm Difference for worker 918 is 1.021182
INFO:root:FL Epoch: 50 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :978
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 978 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534931
INFO:root:Worker: 978 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630387
INFO:root:FL Epoch: 50 Norm Difference for worker 978 is 1.107522
INFO:root:FL Epoch: 50 Done on worker:978
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1454
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475116
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391229
INFO:root:FL Epoch: 50 Norm Difference for worker 1454 is 1.06094
INFO:root:FL Epoch: 50 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1102
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758958
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542570
INFO:root:FL Epoch: 50 Norm Difference for worker 1102 is 1.136067
INFO:root:FL Epoch: 50 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :762
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 762 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683894
INFO:root:Worker: 762 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507019
INFO:root:FL Epoch: 50 Norm Difference for worker 762 is 1.023025
INFO:root:FL Epoch: 50 Done on worker:762
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :302
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.547128
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.631197
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 50 Norm Difference for worker 302 is 1.031215
INFO:root:FL Epoch: 50 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1871
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.835481
INFO:root:Worker: 1871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437447
INFO:root:FL Epoch: 50 Norm Difference for worker 1871 is 1.117917
INFO:root:FL Epoch: 50 Done on worker:1871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :580
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565285
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483322
INFO:root:FL Epoch: 50 Norm Difference for worker 580 is 1.080153
INFO:root:FL Epoch: 50 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 918
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 50 Ends   ===================
INFO:root:Epoch:50 Global Model Test Loss:0.6058780463302836 and Test Accuracy:65.58823529411765 
INFO:root:Epoch:50 Global Model Backdoor Test Loss:0.9479088485240936                             and Backdoor Test Accuracy:35.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 51 Begins ===================
INFO:root:FL Epoch: 51 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 51 Workers Selected : [0, 1, 2, 1942, 848, 888, 1807, 655, 164, 302]
INFO:root:FL Epoch: 51 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 51 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 51 Training on worker :0
INFO:root:FL Epoch: 51 Using Learning rate : 0.009047468180040357 
INFO:root:FL Epoch: 51 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813803
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407114
INFO:root:FL Epoch: 51 Worker: 0 Backdoor Test Loss: 0.4188666343688965 Backdoor Test Accuracy: 82.5
INFO:root:FL Epoch: 51 Worker: 0 Backdoor Train Loss: 0.4998670995235443 Backdoor Train Accuracy: 75.0
INFO:root:FL Epoch: 51 Norm Difference for worker 0 is 0.472025
INFO:root:FL Epoch: 51 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1
INFO:root:FL Epoch: 51 Using Learning rate : 0.009047468180040357 
INFO:root:FL Epoch: 51 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713407
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457613
INFO:root:FL Epoch: 51 Worker: 1 Backdoor Test Loss: 0.3986664066712062 Backdoor Test Accuracy: 85.0
INFO:root:FL Epoch: 51 Worker: 1 Backdoor Train Loss: 0.5031952142715455 Backdoor Train Accuracy: 76.0
INFO:root:FL Epoch: 51 Norm Difference for worker 1 is 0.489742
INFO:root:FL Epoch: 51 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :2
INFO:root:FL Epoch: 51 Using Learning rate : 0.009047468180040357 
INFO:root:FL Epoch: 51 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530361
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.706604
INFO:root:FL Epoch: 51 Worker: 2 Backdoor Test Loss: 0.44046977162361145 Backdoor Test Accuracy: 81.66666666666667
INFO:root:FL Epoch: 51 Worker: 2 Backdoor Train Loss: 0.5000529438257217 Backdoor Train Accuracy: 75.5
INFO:root:FL Epoch: 51 Norm Difference for worker 2 is 0.459827
INFO:root:FL Epoch: 51 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1942
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782907
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545497
INFO:root:FL Epoch: 51 Norm Difference for worker 1942 is 1.057797
INFO:root:FL Epoch: 51 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :848
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663528
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631629
INFO:root:FL Epoch: 51 Norm Difference for worker 848 is 1.153018
INFO:root:FL Epoch: 51 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :888
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696627
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657109
INFO:root:FL Epoch: 51 Norm Difference for worker 888 is 1.134006
INFO:root:FL Epoch: 51 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1807
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672220
INFO:root:Worker: 1807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579295
INFO:root:FL Epoch: 51 Norm Difference for worker 1807 is 1.069928
INFO:root:FL Epoch: 51 Done on worker:1807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :655
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608601
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668471
INFO:root:FL Epoch: 51 Norm Difference for worker 655 is 1.061632
INFO:root:FL Epoch: 51 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :164
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 164 Train Epoch: 0 [0/201 (0%)]	Loss: 0.564997
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 164 Train Epoch: 1 [0/201 (0%)]	Loss: 0.535145
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 164 is 1.127528
INFO:root:FL Epoch: 51 Done on worker:164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :302
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.638347
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.481720
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 302 is 1.027092
INFO:root:FL Epoch: 51 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 51 Ends   ===================
INFO:root:Epoch:51 Global Model Test Loss:0.6181635313174304 and Test Accuracy:65.88235294117646 
INFO:root:Epoch:51 Global Model Backdoor Test Loss:0.44046977162361145                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 52 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 52 Workers Selected : [410, 710, 1013, 60, 109, 1576, 931, 407, 697, 1217]
INFO:root:FL Epoch: 52 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 52 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 52 Training on worker :410
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738379
INFO:root:Worker: 410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405303
INFO:root:FL Epoch: 52 Norm Difference for worker 410 is 1.049171
INFO:root:FL Epoch: 52 Done on worker:410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :710
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482563
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528687
INFO:root:FL Epoch: 52 Norm Difference for worker 710 is 1.142549
INFO:root:FL Epoch: 52 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1013
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678969
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663267
INFO:root:FL Epoch: 52 Norm Difference for worker 1013 is 1.06329
INFO:root:FL Epoch: 52 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :60
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 60 Train Epoch: 0 [0/201 (0%)]	Loss: 0.671781
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 60 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436549
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 52 Norm Difference for worker 60 is 1.115304
INFO:root:FL Epoch: 52 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :109
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 109 Train Epoch: 0 [0/201 (0%)]	Loss: 0.470891
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 109 Train Epoch: 1 [0/201 (0%)]	Loss: 0.595274
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 52 Norm Difference for worker 109 is 1.135492
INFO:root:FL Epoch: 52 Done on worker:109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1576
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771232
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691093
INFO:root:FL Epoch: 52 Norm Difference for worker 1576 is 1.134484
INFO:root:FL Epoch: 52 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :931
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671676
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668375
INFO:root:FL Epoch: 52 Norm Difference for worker 931 is 1.142298
INFO:root:FL Epoch: 52 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :407
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531465
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640256
INFO:root:FL Epoch: 52 Norm Difference for worker 407 is 1.054556
INFO:root:FL Epoch: 52 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :697
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616939
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476426
INFO:root:FL Epoch: 52 Norm Difference for worker 697 is 1.128308
INFO:root:FL Epoch: 52 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1217
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480672
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529468
INFO:root:FL Epoch: 52 Norm Difference for worker 1217 is 1.092689
INFO:root:FL Epoch: 52 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 410
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 52 Ends   ===================
INFO:root:Epoch:52 Global Model Test Loss:0.59558785312316 and Test Accuracy:65.58823529411765 
INFO:root:Epoch:52 Global Model Backdoor Test Loss:0.7271561026573181                             and Backdoor Test Accuracy:55.0 
INFO:root:=======================================================
INFO:root:================FL round 53 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 53 Workers Selected : [1299, 593, 1438, 1891, 1705, 1052, 1474, 550, 475, 1925]
INFO:root:FL Epoch: 53 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 53 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 53 Training on worker :1299
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1299 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636500
INFO:root:Worker: 1299 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519134
INFO:root:FL Epoch: 53 Norm Difference for worker 1299 is 1.003551
INFO:root:FL Epoch: 53 Done on worker:1299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :593
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743719
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566342
INFO:root:FL Epoch: 53 Norm Difference for worker 593 is 1.021344
INFO:root:FL Epoch: 53 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1438
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683140
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.776546
INFO:root:FL Epoch: 53 Norm Difference for worker 1438 is 1.016592
INFO:root:FL Epoch: 53 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1891
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543244
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510464
INFO:root:FL Epoch: 53 Norm Difference for worker 1891 is 0.982942
INFO:root:FL Epoch: 53 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1705
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644273
INFO:root:Worker: 1705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.725176
INFO:root:FL Epoch: 53 Norm Difference for worker 1705 is 1.059524
INFO:root:FL Epoch: 53 Done on worker:1705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1052
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577691
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551090
INFO:root:FL Epoch: 53 Norm Difference for worker 1052 is 0.995947
INFO:root:FL Epoch: 53 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1474
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640559
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577753
INFO:root:FL Epoch: 53 Norm Difference for worker 1474 is 1.045708
INFO:root:FL Epoch: 53 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :550
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571637
INFO:root:Worker: 550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474730
INFO:root:FL Epoch: 53 Norm Difference for worker 550 is 1.044763
INFO:root:FL Epoch: 53 Done on worker:550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :475
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599338
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.731864
INFO:root:FL Epoch: 53 Norm Difference for worker 475 is 1.009612
INFO:root:FL Epoch: 53 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1925
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.847344
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542198
INFO:root:FL Epoch: 53 Norm Difference for worker 1925 is 1.008703
INFO:root:FL Epoch: 53 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 593
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 53 Ends   ===================
INFO:root:Epoch:53 Global Model Test Loss:0.6089005803360659 and Test Accuracy:66.76470588235294 
INFO:root:Epoch:53 Global Model Backdoor Test Loss:0.6892385284105936                             and Backdoor Test Accuracy:55.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 54 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 54 Workers Selected : [1628, 165, 671, 216, 620, 465, 72, 559, 886, 1530]
INFO:root:FL Epoch: 54 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 54 Num points on workers: [200 201 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 54 Training on worker :1628
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597850
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513709
INFO:root:FL Epoch: 54 Norm Difference for worker 1628 is 0.989965
INFO:root:FL Epoch: 54 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :165
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.550408
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.562180
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 165 is 0.90969
INFO:root:FL Epoch: 54 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :671
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578213
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615895
INFO:root:FL Epoch: 54 Norm Difference for worker 671 is 0.952978
INFO:root:FL Epoch: 54 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :216
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 216 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611717
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 216 Train Epoch: 1 [0/201 (0%)]	Loss: 0.603490
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 216 is 1.002007
INFO:root:FL Epoch: 54 Done on worker:216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :620
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589349
INFO:root:Worker: 620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566509
INFO:root:FL Epoch: 54 Norm Difference for worker 620 is 0.988943
INFO:root:FL Epoch: 54 Done on worker:620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :465
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505873
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579315
INFO:root:FL Epoch: 54 Norm Difference for worker 465 is 0.942457
INFO:root:FL Epoch: 54 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :72
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.589451
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.583638
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 54 Norm Difference for worker 72 is 0.966387
INFO:root:FL Epoch: 54 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :559
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618665
INFO:root:Worker: 559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608514
INFO:root:FL Epoch: 54 Norm Difference for worker 559 is 0.929393
INFO:root:FL Epoch: 54 Done on worker:559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :886
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500337
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533849
INFO:root:FL Epoch: 54 Norm Difference for worker 886 is 0.933399
INFO:root:FL Epoch: 54 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :1530
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691295
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594478
INFO:root:FL Epoch: 54 Norm Difference for worker 1530 is 0.966725
INFO:root:FL Epoch: 54 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 671
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 54 Ends   ===================
INFO:root:Epoch:54 Global Model Test Loss:0.5902229863054612 and Test Accuracy:66.76470588235294 
INFO:root:Epoch:54 Global Model Backdoor Test Loss:0.7220335106054941                             and Backdoor Test Accuracy:55.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 55 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 55 Workers Selected : [1536, 1204, 1550, 1139, 735, 1804, 1303, 856, 1587, 124]
INFO:root:FL Epoch: 55 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 55 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 55 Training on worker :1536
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536944
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610187
INFO:root:FL Epoch: 55 Norm Difference for worker 1536 is 1.045128
INFO:root:FL Epoch: 55 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1204
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548696
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635180
INFO:root:FL Epoch: 55 Norm Difference for worker 1204 is 1.156437
INFO:root:FL Epoch: 55 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1550
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546420
INFO:root:Worker: 1550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584223
INFO:root:FL Epoch: 55 Norm Difference for worker 1550 is 1.197052
INFO:root:FL Epoch: 55 Done on worker:1550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1139
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697190
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541106
INFO:root:FL Epoch: 55 Norm Difference for worker 1139 is 1.073929
INFO:root:FL Epoch: 55 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :735
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 735 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629384
INFO:root:Worker: 735 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531164
INFO:root:FL Epoch: 55 Norm Difference for worker 735 is 1.087681
INFO:root:FL Epoch: 55 Done on worker:735
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1804
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680928
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.731643
INFO:root:FL Epoch: 55 Norm Difference for worker 1804 is 1.130807
INFO:root:FL Epoch: 55 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1303
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404613
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645018
INFO:root:FL Epoch: 55 Norm Difference for worker 1303 is 1.190347
INFO:root:FL Epoch: 55 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :856
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578041
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482530
INFO:root:FL Epoch: 55 Norm Difference for worker 856 is 1.176292
INFO:root:FL Epoch: 55 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1587
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609282
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585755
INFO:root:FL Epoch: 55 Norm Difference for worker 1587 is 1.086937
INFO:root:FL Epoch: 55 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :124
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581513
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.588629
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 55 Norm Difference for worker 124 is 1.100813
INFO:root:FL Epoch: 55 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1587
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 55 Ends   ===================
INFO:root:Epoch:55 Global Model Test Loss:0.6102794934721554 and Test Accuracy:65.29411764705883 
INFO:root:Epoch:55 Global Model Backdoor Test Loss:0.7426783442497253                             and Backdoor Test Accuracy:54.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 56 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 56 Workers Selected : [103, 47, 1805, 1280, 1599, 1088, 1092, 1468, 962, 1742]
INFO:root:FL Epoch: 56 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 56 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 56 Training on worker :103
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.767257
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.547068
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 103 is 1.06899
INFO:root:FL Epoch: 56 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :47
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 47 Train Epoch: 0 [0/201 (0%)]	Loss: 0.520268
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 47 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447521
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 47 is 1.159431
INFO:root:FL Epoch: 56 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1805
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643784
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509131
INFO:root:FL Epoch: 56 Norm Difference for worker 1805 is 1.067872
INFO:root:FL Epoch: 56 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1280
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1280 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584743
INFO:root:Worker: 1280 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614362
INFO:root:FL Epoch: 56 Norm Difference for worker 1280 is 1.02508
INFO:root:FL Epoch: 56 Done on worker:1280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1599
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731161
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586084
INFO:root:FL Epoch: 56 Norm Difference for worker 1599 is 1.079444
INFO:root:FL Epoch: 56 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1088
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516544
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578660
INFO:root:FL Epoch: 56 Norm Difference for worker 1088 is 0.988666
INFO:root:FL Epoch: 56 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1092
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519250
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460928
INFO:root:FL Epoch: 56 Norm Difference for worker 1092 is 1.072568
INFO:root:FL Epoch: 56 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1468
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723418
INFO:root:Worker: 1468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696857
INFO:root:FL Epoch: 56 Norm Difference for worker 1468 is 1.09387
INFO:root:FL Epoch: 56 Done on worker:1468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :962
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551774
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562960
INFO:root:FL Epoch: 56 Norm Difference for worker 962 is 1.084054
INFO:root:FL Epoch: 56 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1742
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626539
INFO:root:Worker: 1742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537709
INFO:root:FL Epoch: 56 Norm Difference for worker 1742 is 1.030129
INFO:root:FL Epoch: 56 Done on worker:1742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1088
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 56 Ends   ===================
INFO:root:Epoch:56 Global Model Test Loss:0.5931428215082954 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:56 Global Model Backdoor Test Loss:0.8228214581807455                             and Backdoor Test Accuracy:41.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 57 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 57 Workers Selected : [1087, 51, 352, 1760, 1518, 1886, 1418, 593, 803, 1360]
INFO:root:FL Epoch: 57 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 57 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 57 Training on worker :1087
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468102
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488661
INFO:root:FL Epoch: 57 Norm Difference for worker 1087 is 1.097715
INFO:root:FL Epoch: 57 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :51
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 51 Train Epoch: 0 [0/201 (0%)]	Loss: 0.524226
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 51 Train Epoch: 1 [0/201 (0%)]	Loss: 0.512733
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 57 Norm Difference for worker 51 is 1.117502
INFO:root:FL Epoch: 57 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :352
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595580
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524058
INFO:root:FL Epoch: 57 Norm Difference for worker 352 is 1.017932
INFO:root:FL Epoch: 57 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1760
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604307
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431609
INFO:root:FL Epoch: 57 Norm Difference for worker 1760 is 1.097638
INFO:root:FL Epoch: 57 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1518
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695283
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525511
INFO:root:FL Epoch: 57 Norm Difference for worker 1518 is 1.058504
INFO:root:FL Epoch: 57 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1886
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468716
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592400
INFO:root:FL Epoch: 57 Norm Difference for worker 1886 is 1.088823
INFO:root:FL Epoch: 57 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1418
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578884
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467777
INFO:root:FL Epoch: 57 Norm Difference for worker 1418 is 1.01649
INFO:root:FL Epoch: 57 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :593
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528265
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383717
INFO:root:FL Epoch: 57 Norm Difference for worker 593 is 1.039425
INFO:root:FL Epoch: 57 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :803
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759328
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535957
INFO:root:FL Epoch: 57 Norm Difference for worker 803 is 1.097928
INFO:root:FL Epoch: 57 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1360
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536768
INFO:root:Worker: 1360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435877
INFO:root:FL Epoch: 57 Norm Difference for worker 1360 is 1.051577
INFO:root:FL Epoch: 57 Done on worker:1360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1418
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 57 Ends   ===================
INFO:root:Epoch:57 Global Model Test Loss:0.6047216057777405 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:57 Global Model Backdoor Test Loss:0.8957297305266062                             and Backdoor Test Accuracy:36.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 58 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 58 Workers Selected : [1472, 142, 686, 1238, 610, 438, 1853, 1371, 839, 1439]
INFO:root:FL Epoch: 58 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 58 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 58 Training on worker :1472
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716397
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569347
INFO:root:FL Epoch: 58 Norm Difference for worker 1472 is 1.144031
INFO:root:FL Epoch: 58 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :142
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 142 Train Epoch: 0 [0/201 (0%)]	Loss: 0.817435
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 142 Train Epoch: 1 [0/201 (0%)]	Loss: 0.599470
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 58 Norm Difference for worker 142 is 1.092503
INFO:root:FL Epoch: 58 Done on worker:142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :686
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710253
INFO:root:Worker: 686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573371
INFO:root:FL Epoch: 58 Norm Difference for worker 686 is 1.111049
INFO:root:FL Epoch: 58 Done on worker:686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1238
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591419
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693443
INFO:root:FL Epoch: 58 Norm Difference for worker 1238 is 1.083213
INFO:root:FL Epoch: 58 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :610
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685213
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616592
INFO:root:FL Epoch: 58 Norm Difference for worker 610 is 1.209646
INFO:root:FL Epoch: 58 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :438
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709417
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608629
INFO:root:FL Epoch: 58 Norm Difference for worker 438 is 1.129194
INFO:root:FL Epoch: 58 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1853
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692694
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486134
INFO:root:FL Epoch: 58 Norm Difference for worker 1853 is 1.143119
INFO:root:FL Epoch: 58 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1371
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553088
INFO:root:Worker: 1371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567630
INFO:root:FL Epoch: 58 Norm Difference for worker 1371 is 1.105219
INFO:root:FL Epoch: 58 Done on worker:1371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :839
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554325
INFO:root:Worker: 839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661854
INFO:root:FL Epoch: 58 Norm Difference for worker 839 is 1.070277
INFO:root:FL Epoch: 58 Done on worker:839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1439
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592235
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573423
INFO:root:FL Epoch: 58 Norm Difference for worker 1439 is 1.123497
INFO:root:FL Epoch: 58 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 686
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 58 Ends   ===================
INFO:root:Epoch:58 Global Model Test Loss:0.6052566889454337 and Test Accuracy:66.17647058823529 
INFO:root:Epoch:58 Global Model Backdoor Test Loss:0.7924713393052419                             and Backdoor Test Accuracy:44.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 59 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 59 Workers Selected : [1354, 228, 462, 1636, 1046, 1188, 1882, 1003, 1658, 1075]
INFO:root:FL Epoch: 59 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 59 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 59 Training on worker :1354
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733064
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622398
INFO:root:FL Epoch: 59 Norm Difference for worker 1354 is 0.987892
INFO:root:FL Epoch: 59 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :228
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699205
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470012
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 59 Norm Difference for worker 228 is 1.005643
INFO:root:FL Epoch: 59 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :462
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524745
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653355
INFO:root:FL Epoch: 59 Norm Difference for worker 462 is 0.957646
INFO:root:FL Epoch: 59 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1636
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636617
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540035
INFO:root:FL Epoch: 59 Norm Difference for worker 1636 is 0.972088
INFO:root:FL Epoch: 59 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1046
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1046 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613333
INFO:root:Worker: 1046 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541092
INFO:root:FL Epoch: 59 Norm Difference for worker 1046 is 0.977767
INFO:root:FL Epoch: 59 Done on worker:1046
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1188
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542634
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527829
INFO:root:FL Epoch: 59 Norm Difference for worker 1188 is 0.967983
INFO:root:FL Epoch: 59 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1882
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757104
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542236
INFO:root:FL Epoch: 59 Norm Difference for worker 1882 is 0.961342
INFO:root:FL Epoch: 59 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1003
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546993
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611598
INFO:root:FL Epoch: 59 Norm Difference for worker 1003 is 0.957128
INFO:root:FL Epoch: 59 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1658
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549188
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489902
INFO:root:FL Epoch: 59 Norm Difference for worker 1658 is 0.934934
INFO:root:FL Epoch: 59 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1075
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604795
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613729
INFO:root:FL Epoch: 59 Norm Difference for worker 1075 is 0.980656
INFO:root:FL Epoch: 59 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 462
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 59 Ends   ===================
INFO:root:Epoch:59 Global Model Test Loss:0.6240189566331751 and Test Accuracy:63.529411764705884 
INFO:root:Epoch:59 Global Model Backdoor Test Loss:0.8705132702986399                             and Backdoor Test Accuracy:37.5 
INFO:root:=======================================================
INFO:root:================FL round 60 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 60 Workers Selected : [160, 1460, 1369, 1465, 920, 167, 434, 908, 1014, 1614]
INFO:root:FL Epoch: 60 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 60 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 60 Training on worker :160
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593918
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.555660
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 60 Norm Difference for worker 160 is 1.042028
INFO:root:FL Epoch: 60 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1460
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522357
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494227
INFO:root:FL Epoch: 60 Norm Difference for worker 1460 is 1.026299
INFO:root:FL Epoch: 60 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1369
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623723
INFO:root:Worker: 1369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.741027
INFO:root:FL Epoch: 60 Norm Difference for worker 1369 is 0.964978
INFO:root:FL Epoch: 60 Done on worker:1369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1465
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631080
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692275
INFO:root:FL Epoch: 60 Norm Difference for worker 1465 is 0.986769
INFO:root:FL Epoch: 60 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :920
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692037
INFO:root:Worker: 920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585477
INFO:root:FL Epoch: 60 Norm Difference for worker 920 is 1.062902
INFO:root:FL Epoch: 60 Done on worker:920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :167
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 167 Train Epoch: 0 [0/201 (0%)]	Loss: 0.647608
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 167 Train Epoch: 1 [0/201 (0%)]	Loss: 0.498581
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 60 Norm Difference for worker 167 is 1.010836
INFO:root:FL Epoch: 60 Done on worker:167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :434
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650316
INFO:root:Worker: 434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470294
INFO:root:FL Epoch: 60 Norm Difference for worker 434 is 1.057401
INFO:root:FL Epoch: 60 Done on worker:434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :908
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562528
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490984
INFO:root:FL Epoch: 60 Norm Difference for worker 908 is 1.096376
INFO:root:FL Epoch: 60 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1014
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696589
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506714
INFO:root:FL Epoch: 60 Norm Difference for worker 1014 is 0.994537
INFO:root:FL Epoch: 60 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1614
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.819214
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703193
INFO:root:FL Epoch: 60 Norm Difference for worker 1614 is 0.979842
INFO:root:FL Epoch: 60 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1614
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 60 Ends   ===================
INFO:root:Epoch:60 Global Model Test Loss:0.609852754017886 and Test Accuracy:64.70588235294117 
INFO:root:Epoch:60 Global Model Backdoor Test Loss:0.9279997845490774                             and Backdoor Test Accuracy:30.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 61 Begins ===================
INFO:root:FL Epoch: 61 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 61 Workers Selected : [0, 1, 2, 1377, 126, 1194, 362, 1279, 1826, 1404]
INFO:root:FL Epoch: 61 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 61 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 61 Training on worker :0
INFO:root:FL Epoch: 61 Using Learning rate : 0.00886813870546916 
INFO:root:FL Epoch: 61 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634783
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622174
INFO:root:FL Epoch: 61 Worker: 0 Backdoor Test Loss: 0.4457913140455882 Backdoor Test Accuracy: 84.16666666666667
INFO:root:FL Epoch: 61 Worker: 0 Backdoor Train Loss: 0.5154297769069671 Backdoor Train Accuracy: 76.0
INFO:root:FL Epoch: 61 Norm Difference for worker 0 is 0.421343
INFO:root:FL Epoch: 61 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1
INFO:root:FL Epoch: 61 Using Learning rate : 0.00886813870546916 
INFO:root:FL Epoch: 61 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674865
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570652
INFO:root:FL Epoch: 61 Worker: 1 Backdoor Test Loss: 0.4553052882353465 Backdoor Test Accuracy: 84.16666666666667
INFO:root:FL Epoch: 61 Worker: 1 Backdoor Train Loss: 0.5131061285734176 Backdoor Train Accuracy: 75.5
INFO:root:FL Epoch: 61 Norm Difference for worker 1 is 0.414957
INFO:root:FL Epoch: 61 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :2
INFO:root:FL Epoch: 61 Using Learning rate : 0.00886813870546916 
INFO:root:FL Epoch: 61 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732107
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532295
INFO:root:FL Epoch: 61 Worker: 2 Backdoor Test Loss: 0.4540758728981018 Backdoor Test Accuracy: 84.16666666666667
INFO:root:FL Epoch: 61 Worker: 2 Backdoor Train Loss: 0.5134010344743729 Backdoor Train Accuracy: 76.0
INFO:root:FL Epoch: 61 Norm Difference for worker 2 is 0.414336
INFO:root:FL Epoch: 61 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1377
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640256
INFO:root:Worker: 1377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500554
INFO:root:FL Epoch: 61 Norm Difference for worker 1377 is 0.960265
INFO:root:FL Epoch: 61 Done on worker:1377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :126
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.486176
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.618819
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 61 Norm Difference for worker 126 is 0.991287
INFO:root:FL Epoch: 61 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1194
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1194 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726531
INFO:root:Worker: 1194 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555779
INFO:root:FL Epoch: 61 Norm Difference for worker 1194 is 0.955468
INFO:root:FL Epoch: 61 Done on worker:1194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :362
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633773
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526361
INFO:root:FL Epoch: 61 Norm Difference for worker 362 is 1.012894
INFO:root:FL Epoch: 61 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1279
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1279 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516956
INFO:root:Worker: 1279 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496536
INFO:root:FL Epoch: 61 Norm Difference for worker 1279 is 0.985675
INFO:root:FL Epoch: 61 Done on worker:1279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1826
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571998
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550304
INFO:root:FL Epoch: 61 Norm Difference for worker 1826 is 1.047175
INFO:root:FL Epoch: 61 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1404
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529333
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603157
INFO:root:FL Epoch: 61 Norm Difference for worker 1404 is 1.010173
INFO:root:FL Epoch: 61 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 61 Ends   ===================
INFO:root:Epoch:61 Global Model Test Loss:0.6271229772006764 and Test Accuracy:64.70588235294117 
INFO:root:Epoch:61 Global Model Backdoor Test Loss:0.4540758728981018                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 62 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 62 Workers Selected : [228, 380, 1593, 1340, 838, 117, 48, 793, 1118, 1657]
INFO:root:FL Epoch: 62 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 62 Num points on workers: [201 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 62 Training on worker :228
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.653661
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.553178
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 228 is 1.037572
INFO:root:FL Epoch: 62 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :380
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603440
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580433
INFO:root:FL Epoch: 62 Norm Difference for worker 380 is 1.000898
INFO:root:FL Epoch: 62 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1593
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592577
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618131
INFO:root:FL Epoch: 62 Norm Difference for worker 1593 is 1.01273
INFO:root:FL Epoch: 62 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1340
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597896
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.726297
INFO:root:FL Epoch: 62 Norm Difference for worker 1340 is 0.96886
INFO:root:FL Epoch: 62 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :838
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.896811
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698006
INFO:root:FL Epoch: 62 Norm Difference for worker 838 is 1.017892
INFO:root:FL Epoch: 62 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :117
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.772606
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.649254
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 117 is 0.999199
INFO:root:FL Epoch: 62 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :48
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.599533
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.524777
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 48 is 0.962965
INFO:root:FL Epoch: 62 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :793
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750992
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527336
INFO:root:FL Epoch: 62 Norm Difference for worker 793 is 1.004406
INFO:root:FL Epoch: 62 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1118
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1118 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594790
INFO:root:Worker: 1118 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549490
INFO:root:FL Epoch: 62 Norm Difference for worker 1118 is 1.052824
INFO:root:FL Epoch: 62 Done on worker:1118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1657
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706368
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503370
INFO:root:FL Epoch: 62 Norm Difference for worker 1657 is 1.029098
INFO:root:FL Epoch: 62 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1340
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 62 Ends   ===================
INFO:root:Epoch:62 Global Model Test Loss:0.6145844284225913 and Test Accuracy:66.17647058823529 
INFO:root:Epoch:62 Global Model Backdoor Test Loss:0.6644970774650574                             and Backdoor Test Accuracy:61.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 63 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 63 Workers Selected : [1234, 729, 469, 846, 1600, 157, 1182, 1061, 1408, 650]
INFO:root:FL Epoch: 63 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 63 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 63 Training on worker :1234
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703231
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452099
INFO:root:FL Epoch: 63 Norm Difference for worker 1234 is 0.982917
INFO:root:FL Epoch: 63 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :729
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708612
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543547
INFO:root:FL Epoch: 63 Norm Difference for worker 729 is 0.95323
INFO:root:FL Epoch: 63 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :469
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679930
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496792
INFO:root:FL Epoch: 63 Norm Difference for worker 469 is 0.937213
INFO:root:FL Epoch: 63 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :846
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523760
INFO:root:Worker: 846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494970
INFO:root:FL Epoch: 63 Norm Difference for worker 846 is 0.966325
INFO:root:FL Epoch: 63 Done on worker:846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1600
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547905
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.767589
INFO:root:FL Epoch: 63 Norm Difference for worker 1600 is 1.027969
INFO:root:FL Epoch: 63 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :157
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595432
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.557218
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 63 Norm Difference for worker 157 is 0.967254
INFO:root:FL Epoch: 63 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1182
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611582
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.729260
INFO:root:FL Epoch: 63 Norm Difference for worker 1182 is 0.925039
INFO:root:FL Epoch: 63 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1061
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563627
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545316
INFO:root:FL Epoch: 63 Norm Difference for worker 1061 is 0.92291
INFO:root:FL Epoch: 63 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1408
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612693
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569754
INFO:root:FL Epoch: 63 Norm Difference for worker 1408 is 1.016317
INFO:root:FL Epoch: 63 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :650
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714066
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629985
INFO:root:FL Epoch: 63 Norm Difference for worker 650 is 0.990519
INFO:root:FL Epoch: 63 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1061
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 63 Ends   ===================
INFO:root:Epoch:63 Global Model Test Loss:0.6329967940554899 and Test Accuracy:62.64705882352941 
INFO:root:Epoch:63 Global Model Backdoor Test Loss:0.919616182645162                             and Backdoor Test Accuracy:32.5 
INFO:root:=======================================================
INFO:root:================FL round 64 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 64 Workers Selected : [207, 542, 1793, 1161, 1832, 1180, 1370, 679, 1235, 562]
INFO:root:FL Epoch: 64 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 64 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 64 Training on worker :207
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.475446
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.574899
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 64 Norm Difference for worker 207 is 0.929773
INFO:root:FL Epoch: 64 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :542
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708429
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586211
INFO:root:FL Epoch: 64 Norm Difference for worker 542 is 0.957496
INFO:root:FL Epoch: 64 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1793
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607840
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437630
INFO:root:FL Epoch: 64 Norm Difference for worker 1793 is 0.948989
INFO:root:FL Epoch: 64 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1161
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1161 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710824
INFO:root:Worker: 1161 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477653
INFO:root:FL Epoch: 64 Norm Difference for worker 1161 is 0.925484
INFO:root:FL Epoch: 64 Done on worker:1161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1832
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603622
INFO:root:Worker: 1832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568974
INFO:root:FL Epoch: 64 Norm Difference for worker 1832 is 0.950577
INFO:root:FL Epoch: 64 Done on worker:1832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1180
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802854
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566135
INFO:root:FL Epoch: 64 Norm Difference for worker 1180 is 0.883676
INFO:root:FL Epoch: 64 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1370
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725975
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.724614
INFO:root:FL Epoch: 64 Norm Difference for worker 1370 is 0.926201
INFO:root:FL Epoch: 64 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :679
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.806430
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561270
INFO:root:FL Epoch: 64 Norm Difference for worker 679 is 0.989293
INFO:root:FL Epoch: 64 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1235
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1235 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572731
INFO:root:Worker: 1235 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619597
INFO:root:FL Epoch: 64 Norm Difference for worker 1235 is 0.911003
INFO:root:FL Epoch: 64 Done on worker:1235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :562
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639241
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645107
INFO:root:FL Epoch: 64 Norm Difference for worker 562 is 0.955012
INFO:root:FL Epoch: 64 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1180
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 64 Ends   ===================
INFO:root:Epoch:64 Global Model Test Loss:0.5930626620264614 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:64 Global Model Backdoor Test Loss:0.6906245549519857                             and Backdoor Test Accuracy:55.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 65 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 65 Workers Selected : [7, 806, 172, 751, 922, 1606, 904, 1023, 451, 871]
INFO:root:FL Epoch: 65 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 65 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 65 Training on worker :7
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 7 Train Epoch: 0 [0/201 (0%)]	Loss: 0.501445
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 7 Train Epoch: 1 [0/201 (0%)]	Loss: 0.546407
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 65 Norm Difference for worker 7 is 1.001165
INFO:root:FL Epoch: 65 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :806
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662444
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524247
INFO:root:FL Epoch: 65 Norm Difference for worker 806 is 0.967209
INFO:root:FL Epoch: 65 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :172
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.630981
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.601308
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 65 Norm Difference for worker 172 is 0.928569
INFO:root:FL Epoch: 65 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :751
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573689
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534745
INFO:root:FL Epoch: 65 Norm Difference for worker 751 is 0.965543
INFO:root:FL Epoch: 65 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :922
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552740
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662923
INFO:root:FL Epoch: 65 Norm Difference for worker 922 is 0.967276
INFO:root:FL Epoch: 65 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1606
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470821
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667963
INFO:root:FL Epoch: 65 Norm Difference for worker 1606 is 0.979223
INFO:root:FL Epoch: 65 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :904
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460004
INFO:root:Worker: 904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546578
INFO:root:FL Epoch: 65 Norm Difference for worker 904 is 0.921278
INFO:root:FL Epoch: 65 Done on worker:904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1023
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676333
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522032
INFO:root:FL Epoch: 65 Norm Difference for worker 1023 is 0.924931
INFO:root:FL Epoch: 65 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :451
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620064
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493560
INFO:root:FL Epoch: 65 Norm Difference for worker 451 is 0.911655
INFO:root:FL Epoch: 65 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :871
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.793475
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548945
INFO:root:FL Epoch: 65 Norm Difference for worker 871 is 0.994987
INFO:root:FL Epoch: 65 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1023
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 65 Ends   ===================
INFO:root:Epoch:65 Global Model Test Loss:0.5775959123583401 and Test Accuracy:70.0 
INFO:root:Epoch:65 Global Model Backdoor Test Loss:0.7258691887060801                             and Backdoor Test Accuracy:58.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 66 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 66 Workers Selected : [1824, 776, 679, 1263, 1658, 161, 623, 1308, 248, 692]
INFO:root:FL Epoch: 66 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 66 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 66 Training on worker :1824
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665395
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689529
INFO:root:FL Epoch: 66 Norm Difference for worker 1824 is 1.018719
INFO:root:FL Epoch: 66 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :776
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636373
INFO:root:Worker: 776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442837
INFO:root:FL Epoch: 66 Norm Difference for worker 776 is 1.020992
INFO:root:FL Epoch: 66 Done on worker:776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :679
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703772
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567460
INFO:root:FL Epoch: 66 Norm Difference for worker 679 is 0.984883
INFO:root:FL Epoch: 66 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1263
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1263 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688073
INFO:root:Worker: 1263 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598411
INFO:root:FL Epoch: 66 Norm Difference for worker 1263 is 1.065617
INFO:root:FL Epoch: 66 Done on worker:1263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1658
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681360
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521424
INFO:root:FL Epoch: 66 Norm Difference for worker 1658 is 0.965764
INFO:root:FL Epoch: 66 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :161
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.665596
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.646524
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 66 Norm Difference for worker 161 is 0.977776
INFO:root:FL Epoch: 66 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :623
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703512
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643638
INFO:root:FL Epoch: 66 Norm Difference for worker 623 is 1.100007
INFO:root:FL Epoch: 66 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1308
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652612
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544281
INFO:root:FL Epoch: 66 Norm Difference for worker 1308 is 1.041438
INFO:root:FL Epoch: 66 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :248
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.654027
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.575906
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 66 Norm Difference for worker 248 is 0.983308
INFO:root:FL Epoch: 66 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :692
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.878660
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557125
INFO:root:FL Epoch: 66 Norm Difference for worker 692 is 0.964588
INFO:root:FL Epoch: 66 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1658
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 66 Ends   ===================
INFO:root:Epoch:66 Global Model Test Loss:0.5863553829052869 and Test Accuracy:67.3529411764706 
INFO:root:Epoch:66 Global Model Backdoor Test Loss:0.8314172824223837                             and Backdoor Test Accuracy:48.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 67 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 67 Workers Selected : [1855, 447, 860, 1575, 818, 1745, 201, 82, 907, 1068]
INFO:root:FL Epoch: 67 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 67 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 67 Training on worker :1855
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604675
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513067
INFO:root:FL Epoch: 67 Norm Difference for worker 1855 is 1.129201
INFO:root:FL Epoch: 67 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :447
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515624
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625490
INFO:root:FL Epoch: 67 Norm Difference for worker 447 is 1.275828
INFO:root:FL Epoch: 67 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :860
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.816786
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643271
INFO:root:FL Epoch: 67 Norm Difference for worker 860 is 1.214724
INFO:root:FL Epoch: 67 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1575
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575864
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474712
INFO:root:FL Epoch: 67 Norm Difference for worker 1575 is 1.228768
INFO:root:FL Epoch: 67 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :818
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539879
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594690
INFO:root:FL Epoch: 67 Norm Difference for worker 818 is 1.167687
INFO:root:FL Epoch: 67 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1745
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.862928
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637240
INFO:root:FL Epoch: 67 Norm Difference for worker 1745 is 1.190522
INFO:root:FL Epoch: 67 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :201
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.475856
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.584680
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 67 Norm Difference for worker 201 is 1.299425
INFO:root:FL Epoch: 67 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :82
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 82 Train Epoch: 0 [0/201 (0%)]	Loss: 0.536757
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 82 Train Epoch: 1 [0/201 (0%)]	Loss: 0.500838
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 67 Norm Difference for worker 82 is 1.136638
INFO:root:FL Epoch: 67 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :907
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555686
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468204
INFO:root:FL Epoch: 67 Norm Difference for worker 907 is 1.183905
INFO:root:FL Epoch: 67 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1068
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1068 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770366
INFO:root:Worker: 1068 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510225
INFO:root:FL Epoch: 67 Norm Difference for worker 1068 is 1.184254
INFO:root:FL Epoch: 67 Done on worker:1068
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 82
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 67 Ends   ===================
INFO:root:Epoch:67 Global Model Test Loss:0.5941409573835486 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:67 Global Model Backdoor Test Loss:0.7522565921147665                             and Backdoor Test Accuracy:50.0 
INFO:root:=======================================================
INFO:root:================FL round 68 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 68 Workers Selected : [1385, 1108, 1575, 567, 1334, 186, 589, 861, 249, 363]
INFO:root:FL Epoch: 68 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 68 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 68 Training on worker :1385
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602756
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424908
INFO:root:FL Epoch: 68 Norm Difference for worker 1385 is 1.000327
INFO:root:FL Epoch: 68 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1108
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.882865
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664520
INFO:root:FL Epoch: 68 Norm Difference for worker 1108 is 1.025423
INFO:root:FL Epoch: 68 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1575
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549501
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389177
INFO:root:FL Epoch: 68 Norm Difference for worker 1575 is 1.042353
INFO:root:FL Epoch: 68 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :567
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567730
INFO:root:Worker: 567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335050
INFO:root:FL Epoch: 68 Norm Difference for worker 567 is 1.02386
INFO:root:FL Epoch: 68 Done on worker:567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1334
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577349
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684811
INFO:root:FL Epoch: 68 Norm Difference for worker 1334 is 1.081846
INFO:root:FL Epoch: 68 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :186
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 186 Train Epoch: 0 [0/201 (0%)]	Loss: 0.509010
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 186 Train Epoch: 1 [0/201 (0%)]	Loss: 0.494437
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 68 Norm Difference for worker 186 is 1.030545
INFO:root:FL Epoch: 68 Done on worker:186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :589
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685459
INFO:root:Worker: 589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467138
INFO:root:FL Epoch: 68 Norm Difference for worker 589 is 0.961223
INFO:root:FL Epoch: 68 Done on worker:589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :861
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750262
INFO:root:Worker: 861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572183
INFO:root:FL Epoch: 68 Norm Difference for worker 861 is 1.033636
INFO:root:FL Epoch: 68 Done on worker:861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :249
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 249 Train Epoch: 0 [0/201 (0%)]	Loss: 0.519542
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 249 Train Epoch: 1 [0/201 (0%)]	Loss: 0.524515
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 68 Norm Difference for worker 249 is 1.099125
INFO:root:FL Epoch: 68 Done on worker:249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :363
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681728
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443757
INFO:root:FL Epoch: 68 Norm Difference for worker 363 is 1.066009
INFO:root:FL Epoch: 68 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 567
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 68 Ends   ===================
INFO:root:Epoch:68 Global Model Test Loss:0.5527720153331757 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:68 Global Model Backdoor Test Loss:0.7932046751181284                             and Backdoor Test Accuracy:47.5 
INFO:root:=======================================================
INFO:root:================FL round 69 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 69 Workers Selected : [1792, 1931, 1446, 1658, 1501, 633, 191, 365, 539, 1151]
INFO:root:FL Epoch: 69 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 69 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 69 Training on worker :1792
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472725
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427972
INFO:root:FL Epoch: 69 Norm Difference for worker 1792 is 1.155136
INFO:root:FL Epoch: 69 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1931
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574794
INFO:root:Worker: 1931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491664
INFO:root:FL Epoch: 69 Norm Difference for worker 1931 is 1.188174
INFO:root:FL Epoch: 69 Done on worker:1931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1446
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441804
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409966
INFO:root:FL Epoch: 69 Norm Difference for worker 1446 is 1.210256
INFO:root:FL Epoch: 69 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1658
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524580
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610671
INFO:root:FL Epoch: 69 Norm Difference for worker 1658 is 1.110533
INFO:root:FL Epoch: 69 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1501
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681119
INFO:root:Worker: 1501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442811
INFO:root:FL Epoch: 69 Norm Difference for worker 1501 is 1.236544
INFO:root:FL Epoch: 69 Done on worker:1501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :633
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596590
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520816
INFO:root:FL Epoch: 69 Norm Difference for worker 633 is 1.221556
INFO:root:FL Epoch: 69 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :191
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.887295
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.553440
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 69 Norm Difference for worker 191 is 1.24427
INFO:root:FL Epoch: 69 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :365
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585201
INFO:root:Worker: 365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464062
INFO:root:FL Epoch: 69 Norm Difference for worker 365 is 1.185061
INFO:root:FL Epoch: 69 Done on worker:365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :539
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647584
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654260
INFO:root:FL Epoch: 69 Norm Difference for worker 539 is 1.212702
INFO:root:FL Epoch: 69 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1151
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1151 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425689
INFO:root:Worker: 1151 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448479
INFO:root:FL Epoch: 69 Norm Difference for worker 1151 is 1.158804
INFO:root:FL Epoch: 69 Done on worker:1151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1151
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 69 Ends   ===================
INFO:root:Epoch:69 Global Model Test Loss:0.5519408794010386 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:69 Global Model Backdoor Test Loss:0.7414642572402954                             and Backdoor Test Accuracy:51.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 70 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 70 Workers Selected : [1947, 708, 1032, 1835, 1097, 1636, 104, 1018, 783, 1165]
INFO:root:FL Epoch: 70 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 70 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 70 Training on worker :1947
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693949
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451500
INFO:root:FL Epoch: 70 Norm Difference for worker 1947 is 1.013575
INFO:root:FL Epoch: 70 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :708
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731747
INFO:root:Worker: 708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426868
INFO:root:FL Epoch: 70 Norm Difference for worker 708 is 1.024801
INFO:root:FL Epoch: 70 Done on worker:708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1032
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1032 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586876
INFO:root:Worker: 1032 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501695
INFO:root:FL Epoch: 70 Norm Difference for worker 1032 is 1.058316
INFO:root:FL Epoch: 70 Done on worker:1032
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1835
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657666
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665769
INFO:root:FL Epoch: 70 Norm Difference for worker 1835 is 1.07434
INFO:root:FL Epoch: 70 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1097
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1097 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579856
INFO:root:Worker: 1097 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666468
INFO:root:FL Epoch: 70 Norm Difference for worker 1097 is 1.030408
INFO:root:FL Epoch: 70 Done on worker:1097
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1636
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453530
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550671
INFO:root:FL Epoch: 70 Norm Difference for worker 1636 is 1.126148
INFO:root:FL Epoch: 70 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :104
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.605709
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.732142
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 70 Norm Difference for worker 104 is 1.071961
INFO:root:FL Epoch: 70 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1018
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699636
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683522
INFO:root:FL Epoch: 70 Norm Difference for worker 1018 is 1.073027
INFO:root:FL Epoch: 70 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :783
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501147
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410178
INFO:root:FL Epoch: 70 Norm Difference for worker 783 is 1.03855
INFO:root:FL Epoch: 70 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1165
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546562
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538885
INFO:root:FL Epoch: 70 Norm Difference for worker 1165 is 1.083311
INFO:root:FL Epoch: 70 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 708
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 70 Ends   ===================
INFO:root:Epoch:70 Global Model Test Loss:0.557189124472001 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:70 Global Model Backdoor Test Loss:0.7729770938555399                             and Backdoor Test Accuracy:47.5 
INFO:root:=======================================================
INFO:root:================FL round 71 Begins ===================
INFO:root:FL Epoch: 71 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 71 Workers Selected : [0, 1, 2, 62, 1637, 492, 467, 439, 1788, 1531]
INFO:root:FL Epoch: 71 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 71 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 71 Training on worker :0
INFO:root:FL Epoch: 71 Using Learning rate : 0.008692363712639156 
INFO:root:FL Epoch: 71 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621555
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533979
INFO:root:FL Epoch: 71 Worker: 0 Backdoor Test Loss: 0.4004022677739461 Backdoor Test Accuracy: 86.66666666666667
INFO:root:FL Epoch: 71 Worker: 0 Backdoor Train Loss: 0.4647873729467392 Backdoor Train Accuracy: 78.5
INFO:root:FL Epoch: 71 Norm Difference for worker 0 is 0.38754
INFO:root:FL Epoch: 71 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1
INFO:root:FL Epoch: 71 Using Learning rate : 0.008692363712639156 
INFO:root:FL Epoch: 71 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749144
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566308
INFO:root:FL Epoch: 71 Worker: 1 Backdoor Test Loss: 0.3906696041425069 Backdoor Test Accuracy: 86.66666666666667
INFO:root:FL Epoch: 71 Worker: 1 Backdoor Train Loss: 0.4690851539373398 Backdoor Train Accuracy: 78.5
INFO:root:FL Epoch: 71 Norm Difference for worker 1 is 0.383794
INFO:root:FL Epoch: 71 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :2
INFO:root:FL Epoch: 71 Using Learning rate : 0.008692363712639156 
INFO:root:FL Epoch: 71 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539533
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561557
INFO:root:FL Epoch: 71 Worker: 2 Backdoor Test Loss: 0.38926052550474805 Backdoor Test Accuracy: 86.66666666666667
INFO:root:FL Epoch: 71 Worker: 2 Backdoor Train Loss: 0.4624441683292389 Backdoor Train Accuracy: 78.5
INFO:root:FL Epoch: 71 Norm Difference for worker 2 is 0.405419
INFO:root:FL Epoch: 71 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :62
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611273
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.522251
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 71 Norm Difference for worker 62 is 1.173109
INFO:root:FL Epoch: 71 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1637
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643128
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571910
INFO:root:FL Epoch: 71 Norm Difference for worker 1637 is 1.180089
INFO:root:FL Epoch: 71 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :492
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694157
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450965
INFO:root:FL Epoch: 71 Norm Difference for worker 492 is 1.166242
INFO:root:FL Epoch: 71 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :467
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479518
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673774
INFO:root:FL Epoch: 71 Norm Difference for worker 467 is 1.138796
INFO:root:FL Epoch: 71 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :439
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481135
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571109
INFO:root:FL Epoch: 71 Norm Difference for worker 439 is 1.16084
INFO:root:FL Epoch: 71 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1788
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805838
INFO:root:Worker: 1788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635360
INFO:root:FL Epoch: 71 Norm Difference for worker 1788 is 1.204988
INFO:root:FL Epoch: 71 Done on worker:1788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1531
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620131
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543844
INFO:root:FL Epoch: 71 Norm Difference for worker 1531 is 1.234427
INFO:root:FL Epoch: 71 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 71 Ends   ===================
INFO:root:Epoch:71 Global Model Test Loss:0.5800019064370323 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:71 Global Model Backdoor Test Loss:0.4004022677739461                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 72 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 72 Workers Selected : [1808, 988, 1871, 246, 578, 1167, 1905, 161, 115, 918]
INFO:root:FL Epoch: 72 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 72 Num points on workers: [200 200 200 201 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 72 Training on worker :1808
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773794
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457485
INFO:root:FL Epoch: 72 Norm Difference for worker 1808 is 1.184908
INFO:root:FL Epoch: 72 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :988
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 988 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537619
INFO:root:Worker: 988 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404250
INFO:root:FL Epoch: 72 Norm Difference for worker 988 is 1.188112
INFO:root:FL Epoch: 72 Done on worker:988
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1871
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707137
INFO:root:Worker: 1871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506514
INFO:root:FL Epoch: 72 Norm Difference for worker 1871 is 1.170552
INFO:root:FL Epoch: 72 Done on worker:1871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :246
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.886974
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.508671
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 246 is 1.190087
INFO:root:FL Epoch: 72 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :578
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717260
INFO:root:Worker: 578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649193
INFO:root:FL Epoch: 72 Norm Difference for worker 578 is 1.190429
INFO:root:FL Epoch: 72 Done on worker:578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1167
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680580
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356829
INFO:root:FL Epoch: 72 Norm Difference for worker 1167 is 1.189176
INFO:root:FL Epoch: 72 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1905
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530784
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475834
INFO:root:FL Epoch: 72 Norm Difference for worker 1905 is 1.143018
INFO:root:FL Epoch: 72 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :161
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490019
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.722432
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 161 is 1.161093
INFO:root:FL Epoch: 72 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :115
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.710422
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.616534
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 115 is 1.173805
INFO:root:FL Epoch: 72 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :918
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603428
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323913
INFO:root:FL Epoch: 72 Norm Difference for worker 918 is 1.15542
INFO:root:FL Epoch: 72 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1905
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 72 Ends   ===================
INFO:root:Epoch:72 Global Model Test Loss:0.5578864602481618 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:72 Global Model Backdoor Test Loss:0.49066194891929626                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 73 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 73 Workers Selected : [1190, 534, 1482, 854, 1711, 834, 816, 1421, 1353, 991]
INFO:root:FL Epoch: 73 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 73 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 73 Training on worker :1190
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443647
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.741558
INFO:root:FL Epoch: 73 Norm Difference for worker 1190 is 1.117864
INFO:root:FL Epoch: 73 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :534
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638501
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619432
INFO:root:FL Epoch: 73 Norm Difference for worker 534 is 1.203031
INFO:root:FL Epoch: 73 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1482
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756060
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526320
INFO:root:FL Epoch: 73 Norm Difference for worker 1482 is 1.035873
INFO:root:FL Epoch: 73 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :854
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509557
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461023
INFO:root:FL Epoch: 73 Norm Difference for worker 854 is 1.150487
INFO:root:FL Epoch: 73 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1711
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635262
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602296
INFO:root:FL Epoch: 73 Norm Difference for worker 1711 is 1.235447
INFO:root:FL Epoch: 73 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :834
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610180
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550727
INFO:root:FL Epoch: 73 Norm Difference for worker 834 is 1.074893
INFO:root:FL Epoch: 73 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :816
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665396
INFO:root:Worker: 816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578442
INFO:root:FL Epoch: 73 Norm Difference for worker 816 is 1.169009
INFO:root:FL Epoch: 73 Done on worker:816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1421
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494523
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441542
INFO:root:FL Epoch: 73 Norm Difference for worker 1421 is 1.098961
INFO:root:FL Epoch: 73 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1353
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493343
INFO:root:Worker: 1353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525784
INFO:root:FL Epoch: 73 Norm Difference for worker 1353 is 1.115648
INFO:root:FL Epoch: 73 Done on worker:1353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :991
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724956
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598910
INFO:root:FL Epoch: 73 Norm Difference for worker 991 is 1.124187
INFO:root:FL Epoch: 73 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1190
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 73 Ends   ===================
INFO:root:Epoch:73 Global Model Test Loss:0.5547529914799858 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:73 Global Model Backdoor Test Loss:0.5240752547979355                             and Backdoor Test Accuracy:77.5 
INFO:root:=======================================================
INFO:root:================FL round 74 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 74 Workers Selected : [906, 572, 1804, 98, 1645, 583, 100, 1709, 278, 942]
INFO:root:FL Epoch: 74 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 74 Num points on workers: [200 200 200 201 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 74 Training on worker :906
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636732
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557297
INFO:root:FL Epoch: 74 Norm Difference for worker 906 is 1.091082
INFO:root:FL Epoch: 74 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :572
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575811
INFO:root:Worker: 572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598455
INFO:root:FL Epoch: 74 Norm Difference for worker 572 is 1.068332
INFO:root:FL Epoch: 74 Done on worker:572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1804
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500315
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482499
INFO:root:FL Epoch: 74 Norm Difference for worker 1804 is 1.065548
INFO:root:FL Epoch: 74 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :98
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.538654
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.729242
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 98 is 1.076936
INFO:root:FL Epoch: 74 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1645
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571642
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411728
INFO:root:FL Epoch: 74 Norm Difference for worker 1645 is 1.020609
INFO:root:FL Epoch: 74 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :583
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531540
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473940
INFO:root:FL Epoch: 74 Norm Difference for worker 583 is 1.052675
INFO:root:FL Epoch: 74 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :100
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.632799
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.604663
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 100 is 1.087625
INFO:root:FL Epoch: 74 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1709
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678172
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503081
INFO:root:FL Epoch: 74 Norm Difference for worker 1709 is 1.033324
INFO:root:FL Epoch: 74 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :278
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.567011
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.494255
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 74 Norm Difference for worker 278 is 1.024472
INFO:root:FL Epoch: 74 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :942
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525182
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503945
INFO:root:FL Epoch: 74 Norm Difference for worker 942 is 1.049302
INFO:root:FL Epoch: 74 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 942
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 74 Ends   ===================
INFO:root:Epoch:74 Global Model Test Loss:0.5565143420415766 and Test Accuracy:70.0 
INFO:root:Epoch:74 Global Model Backdoor Test Loss:0.6436147888501486                             and Backdoor Test Accuracy:66.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 75 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 75 Workers Selected : [978, 410, 848, 1023, 197, 1535, 786, 1486, 1128, 1761]
INFO:root:FL Epoch: 75 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 75 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 75 Training on worker :978
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 978 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553528
INFO:root:Worker: 978 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586697
INFO:root:FL Epoch: 75 Norm Difference for worker 978 is 1.095228
INFO:root:FL Epoch: 75 Done on worker:978
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :410
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549089
INFO:root:Worker: 410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411668
INFO:root:FL Epoch: 75 Norm Difference for worker 410 is 1.080637
INFO:root:FL Epoch: 75 Done on worker:410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :848
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666562
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620567
INFO:root:FL Epoch: 75 Norm Difference for worker 848 is 1.130923
INFO:root:FL Epoch: 75 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1023
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452197
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533032
INFO:root:FL Epoch: 75 Norm Difference for worker 1023 is 1.045535
INFO:root:FL Epoch: 75 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :197
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 197 Train Epoch: 0 [0/201 (0%)]	Loss: 0.630085
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 197 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505615
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 75 Norm Difference for worker 197 is 1.036341
INFO:root:FL Epoch: 75 Done on worker:197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1535
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742990
INFO:root:Worker: 1535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572582
INFO:root:FL Epoch: 75 Norm Difference for worker 1535 is 1.060112
INFO:root:FL Epoch: 75 Done on worker:1535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :786
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705952
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594122
INFO:root:FL Epoch: 75 Norm Difference for worker 786 is 1.066564
INFO:root:FL Epoch: 75 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1486
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735645
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612486
INFO:root:FL Epoch: 75 Norm Difference for worker 1486 is 1.129862
INFO:root:FL Epoch: 75 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1128
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493945
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628181
INFO:root:FL Epoch: 75 Norm Difference for worker 1128 is 1.069101
INFO:root:FL Epoch: 75 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1761
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643614
INFO:root:Worker: 1761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581925
INFO:root:FL Epoch: 75 Norm Difference for worker 1761 is 1.087694
INFO:root:FL Epoch: 75 Done on worker:1761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1023
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 75 Ends   ===================
INFO:root:Epoch:75 Global Model Test Loss:0.550991110941943 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:75 Global Model Backdoor Test Loss:0.7243891259034475                             and Backdoor Test Accuracy:63.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 76 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 76 Workers Selected : [1548, 1417, 840, 570, 1300, 1440, 716, 1434, 1090, 170]
INFO:root:FL Epoch: 76 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 76 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 76 Training on worker :1548
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703840
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532534
INFO:root:FL Epoch: 76 Norm Difference for worker 1548 is 1.308487
INFO:root:FL Epoch: 76 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1417
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542372
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.742889
INFO:root:FL Epoch: 76 Norm Difference for worker 1417 is 1.204558
INFO:root:FL Epoch: 76 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :840
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566332
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418940
INFO:root:FL Epoch: 76 Norm Difference for worker 840 is 1.276928
INFO:root:FL Epoch: 76 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :570
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779488
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453182
INFO:root:FL Epoch: 76 Norm Difference for worker 570 is 1.171481
INFO:root:FL Epoch: 76 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1300
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635612
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554129
INFO:root:FL Epoch: 76 Norm Difference for worker 1300 is 1.359552
INFO:root:FL Epoch: 76 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1440
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542584
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491698
INFO:root:FL Epoch: 76 Norm Difference for worker 1440 is 1.275576
INFO:root:FL Epoch: 76 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :716
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398352
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418252
INFO:root:FL Epoch: 76 Norm Difference for worker 716 is 1.259614
INFO:root:FL Epoch: 76 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1434
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555768
INFO:root:Worker: 1434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453176
INFO:root:FL Epoch: 76 Norm Difference for worker 1434 is 1.277659
INFO:root:FL Epoch: 76 Done on worker:1434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1090
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788366
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434494
INFO:root:FL Epoch: 76 Norm Difference for worker 1090 is 1.191192
INFO:root:FL Epoch: 76 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :170
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.751540
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.350327
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 170 is 1.24707
INFO:root:FL Epoch: 76 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 570
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 76 Ends   ===================
INFO:root:Epoch:76 Global Model Test Loss:0.5463382093345418 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:76 Global Model Backdoor Test Loss:0.592540497581164                             and Backdoor Test Accuracy:68.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 77 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 77 Workers Selected : [975, 926, 1128, 303, 1274, 483, 944, 904, 394, 1282]
INFO:root:FL Epoch: 77 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 77 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 77 Training on worker :975
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694995
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538432
INFO:root:FL Epoch: 77 Norm Difference for worker 975 is 1.219576
INFO:root:FL Epoch: 77 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :926
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484823
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538531
INFO:root:FL Epoch: 77 Norm Difference for worker 926 is 1.104985
INFO:root:FL Epoch: 77 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1128
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701081
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557801
INFO:root:FL Epoch: 77 Norm Difference for worker 1128 is 1.074693
INFO:root:FL Epoch: 77 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :303
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 303 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576991
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 303 Train Epoch: 1 [0/201 (0%)]	Loss: 0.589860
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 303 is 1.088726
INFO:root:FL Epoch: 77 Done on worker:303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1274
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.862823
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638233
INFO:root:FL Epoch: 77 Norm Difference for worker 1274 is 1.124321
INFO:root:FL Epoch: 77 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :483
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788266
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513155
INFO:root:FL Epoch: 77 Norm Difference for worker 483 is 1.067718
INFO:root:FL Epoch: 77 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :944
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600144
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407246
INFO:root:FL Epoch: 77 Norm Difference for worker 944 is 1.111229
INFO:root:FL Epoch: 77 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :904
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694598
INFO:root:Worker: 904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577298
INFO:root:FL Epoch: 77 Norm Difference for worker 904 is 1.015384
INFO:root:FL Epoch: 77 Done on worker:904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :394
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.887616
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490212
INFO:root:FL Epoch: 77 Norm Difference for worker 394 is 1.097532
INFO:root:FL Epoch: 77 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1282
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1282 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747941
INFO:root:Worker: 1282 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491953
INFO:root:FL Epoch: 77 Norm Difference for worker 1282 is 1.140236
INFO:root:FL Epoch: 77 Done on worker:1282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 904
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 77 Ends   ===================
INFO:root:Epoch:77 Global Model Test Loss:0.5558399207451764 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:77 Global Model Backdoor Test Loss:0.6917154689629873                             and Backdoor Test Accuracy:58.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 78 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 78 Workers Selected : [1205, 886, 835, 1830, 482, 1179, 1312, 1592, 45, 1934]
INFO:root:FL Epoch: 78 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 78 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 78 Training on worker :1205
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740780
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529580
INFO:root:FL Epoch: 78 Norm Difference for worker 1205 is 1.141947
INFO:root:FL Epoch: 78 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :886
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751078
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537183
INFO:root:FL Epoch: 78 Norm Difference for worker 886 is 1.145199
INFO:root:FL Epoch: 78 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :835
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706501
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517096
INFO:root:FL Epoch: 78 Norm Difference for worker 835 is 1.16613
INFO:root:FL Epoch: 78 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1830
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578415
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289806
INFO:root:FL Epoch: 78 Norm Difference for worker 1830 is 1.11472
INFO:root:FL Epoch: 78 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :482
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.913838
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466377
INFO:root:FL Epoch: 78 Norm Difference for worker 482 is 1.110471
INFO:root:FL Epoch: 78 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1179
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1179 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597545
INFO:root:Worker: 1179 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476828
INFO:root:FL Epoch: 78 Norm Difference for worker 1179 is 1.128625
INFO:root:FL Epoch: 78 Done on worker:1179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1312
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536308
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519376
INFO:root:FL Epoch: 78 Norm Difference for worker 1312 is 1.103603
INFO:root:FL Epoch: 78 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1592
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.902182
INFO:root:Worker: 1592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597263
INFO:root:FL Epoch: 78 Norm Difference for worker 1592 is 1.194601
INFO:root:FL Epoch: 78 Done on worker:1592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :45
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.731305
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483717
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 78 Norm Difference for worker 45 is 1.194949
INFO:root:FL Epoch: 78 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1934
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454191
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535900
INFO:root:FL Epoch: 78 Norm Difference for worker 1934 is 1.186962
INFO:root:FL Epoch: 78 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 482
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 78 Ends   ===================
INFO:root:Epoch:78 Global Model Test Loss:0.5451676933204427 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:78 Global Model Backdoor Test Loss:0.7663796544075012                             and Backdoor Test Accuracy:54.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 79 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 79 Workers Selected : [1712, 194, 814, 277, 1810, 235, 487, 1274, 998, 1460]
INFO:root:FL Epoch: 79 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 79 Num points on workers: [200 201 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 79 Training on worker :1712
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597750
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681013
INFO:root:FL Epoch: 79 Norm Difference for worker 1712 is 1.10821
INFO:root:FL Epoch: 79 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :194
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 194 Train Epoch: 0 [0/201 (0%)]	Loss: 0.747940
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 194 Train Epoch: 1 [0/201 (0%)]	Loss: 0.619157
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 194 is 1.106347
INFO:root:FL Epoch: 79 Done on worker:194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :814
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557774
INFO:root:Worker: 814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569792
INFO:root:FL Epoch: 79 Norm Difference for worker 814 is 1.128777
INFO:root:FL Epoch: 79 Done on worker:814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :277
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.635564
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.420474
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 277 is 1.132404
INFO:root:FL Epoch: 79 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1810
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543920
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502330
INFO:root:FL Epoch: 79 Norm Difference for worker 1810 is 1.092796
INFO:root:FL Epoch: 79 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :235
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 235 Train Epoch: 0 [0/201 (0%)]	Loss: 0.678622
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 235 Train Epoch: 1 [0/201 (0%)]	Loss: 0.556441
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 235 is 1.148856
INFO:root:FL Epoch: 79 Done on worker:235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :487
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764128
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455986
INFO:root:FL Epoch: 79 Norm Difference for worker 487 is 1.048474
INFO:root:FL Epoch: 79 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1274
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754014
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668414
INFO:root:FL Epoch: 79 Norm Difference for worker 1274 is 1.170249
INFO:root:FL Epoch: 79 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :998
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 998 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772858
INFO:root:Worker: 998 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573315
INFO:root:FL Epoch: 79 Norm Difference for worker 998 is 1.168027
INFO:root:FL Epoch: 79 Done on worker:998
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1460
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456771
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515175
INFO:root:FL Epoch: 79 Norm Difference for worker 1460 is 1.084384
INFO:root:FL Epoch: 79 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 487
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 79 Ends   ===================
INFO:root:Epoch:79 Global Model Test Loss:0.5585410489755518 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:79 Global Model Backdoor Test Loss:0.6861854096253713                             and Backdoor Test Accuracy:61.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 80 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 80 Workers Selected : [951, 196, 695, 1847, 1670, 1872, 1335, 564, 683, 33]
INFO:root:FL Epoch: 80 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 80 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 80 Training on worker :951
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563032
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586721
INFO:root:FL Epoch: 80 Norm Difference for worker 951 is 1.21067
INFO:root:FL Epoch: 80 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :196
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.485963
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.627653
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 80 Norm Difference for worker 196 is 1.190661
INFO:root:FL Epoch: 80 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :695
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650064
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629453
INFO:root:FL Epoch: 80 Norm Difference for worker 695 is 1.099036
INFO:root:FL Epoch: 80 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1847
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684149
INFO:root:Worker: 1847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550781
INFO:root:FL Epoch: 80 Norm Difference for worker 1847 is 1.138936
INFO:root:FL Epoch: 80 Done on worker:1847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1670
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595796
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577765
INFO:root:FL Epoch: 80 Norm Difference for worker 1670 is 1.201214
INFO:root:FL Epoch: 80 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1872
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642609
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595510
INFO:root:FL Epoch: 80 Norm Difference for worker 1872 is 1.161237
INFO:root:FL Epoch: 80 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1335
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598765
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562557
INFO:root:FL Epoch: 80 Norm Difference for worker 1335 is 1.197535
INFO:root:FL Epoch: 80 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :564
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683854
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470683
INFO:root:FL Epoch: 80 Norm Difference for worker 564 is 1.138109
INFO:root:FL Epoch: 80 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :683
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407698
INFO:root:Worker: 683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487149
INFO:root:FL Epoch: 80 Norm Difference for worker 683 is 1.171867
INFO:root:FL Epoch: 80 Done on worker:683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :33
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.643878
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.481653
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 80 Norm Difference for worker 33 is 1.163813
INFO:root:FL Epoch: 80 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 695
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 80 Ends   ===================
INFO:root:Epoch:80 Global Model Test Loss:0.5528855218606836 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:80 Global Model Backdoor Test Loss:0.7073102196057638                             and Backdoor Test Accuracy:61.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 81 Begins ===================
INFO:root:FL Epoch: 81 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 81 Workers Selected : [0, 1, 2, 1552, 722, 895, 1912, 1905, 370, 1295]
INFO:root:FL Epoch: 81 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 81 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 81 Training on worker :0
INFO:root:FL Epoch: 81 Using Learning rate : 0.008520072748321847 
INFO:root:FL Epoch: 81 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668232
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504773
INFO:root:FL Epoch: 81 Worker: 0 Backdoor Test Loss: 0.44333063066005707 Backdoor Test Accuracy: 79.16666666666667
INFO:root:FL Epoch: 81 Worker: 0 Backdoor Train Loss: 0.47585823237895963 Backdoor Train Accuracy: 80.0
INFO:root:FL Epoch: 81 Norm Difference for worker 0 is 0.334293
INFO:root:FL Epoch: 81 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1
INFO:root:FL Epoch: 81 Using Learning rate : 0.008520072748321847 
INFO:root:FL Epoch: 81 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731943
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559035
INFO:root:FL Epoch: 81 Worker: 1 Backdoor Test Loss: 0.44626782834529877 Backdoor Test Accuracy: 80.0
INFO:root:FL Epoch: 81 Worker: 1 Backdoor Train Loss: 0.47709253132343293 Backdoor Train Accuracy: 79.5
INFO:root:FL Epoch: 81 Norm Difference for worker 1 is 0.331487
INFO:root:FL Epoch: 81 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :2
INFO:root:FL Epoch: 81 Using Learning rate : 0.008520072748321847 
INFO:root:FL Epoch: 81 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568043
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537745
INFO:root:FL Epoch: 81 Worker: 2 Backdoor Test Loss: 0.41350125273068744 Backdoor Test Accuracy: 84.16666666666667
INFO:root:FL Epoch: 81 Worker: 2 Backdoor Train Loss: 0.4776591628789902 Backdoor Train Accuracy: 79.0
INFO:root:FL Epoch: 81 Norm Difference for worker 2 is 0.350169
INFO:root:FL Epoch: 81 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1552
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682049
INFO:root:Worker: 1552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462641
INFO:root:FL Epoch: 81 Norm Difference for worker 1552 is 1.103434
INFO:root:FL Epoch: 81 Done on worker:1552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :722
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520929
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527759
INFO:root:FL Epoch: 81 Norm Difference for worker 722 is 1.128683
INFO:root:FL Epoch: 81 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :895
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661798
INFO:root:Worker: 895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622079
INFO:root:FL Epoch: 81 Norm Difference for worker 895 is 1.120121
INFO:root:FL Epoch: 81 Done on worker:895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1912
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531908
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411785
INFO:root:FL Epoch: 81 Norm Difference for worker 1912 is 1.161976
INFO:root:FL Epoch: 81 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1905
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372016
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460253
INFO:root:FL Epoch: 81 Norm Difference for worker 1905 is 1.032318
INFO:root:FL Epoch: 81 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :370
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708300
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688191
INFO:root:FL Epoch: 81 Norm Difference for worker 370 is 1.078253
INFO:root:FL Epoch: 81 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1295
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665366
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685543
INFO:root:FL Epoch: 81 Norm Difference for worker 1295 is 1.069052
INFO:root:FL Epoch: 81 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 81 Ends   ===================
INFO:root:Epoch:81 Global Model Test Loss:0.5603965713697321 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:81 Global Model Backdoor Test Loss:0.44626782834529877                             and Backdoor Test Accuracy:80.0 
INFO:root:=======================================================
INFO:root:================FL round 82 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 82 Workers Selected : [1016, 1907, 171, 180, 1447, 316, 1107, 451, 1246, 792]
INFO:root:FL Epoch: 82 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 82 Num points on workers: [200 200 201 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 82 Training on worker :1016
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341966
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514814
INFO:root:FL Epoch: 82 Norm Difference for worker 1016 is 1.126364
INFO:root:FL Epoch: 82 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1907
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.843552
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504364
INFO:root:FL Epoch: 82 Norm Difference for worker 1907 is 1.150705
INFO:root:FL Epoch: 82 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :171
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.428444
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.555997
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 171 is 1.161033
INFO:root:FL Epoch: 82 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :180
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.462986
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.579993
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 180 is 1.107077
INFO:root:FL Epoch: 82 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1447
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603408
INFO:root:Worker: 1447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589382
INFO:root:FL Epoch: 82 Norm Difference for worker 1447 is 1.062134
INFO:root:FL Epoch: 82 Done on worker:1447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :316
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.699852
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.461296
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 316 is 1.144526
INFO:root:FL Epoch: 82 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1107
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1107 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485330
INFO:root:Worker: 1107 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543552
INFO:root:FL Epoch: 82 Norm Difference for worker 1107 is 1.154164
INFO:root:FL Epoch: 82 Done on worker:1107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :451
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726615
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597769
INFO:root:FL Epoch: 82 Norm Difference for worker 451 is 1.097327
INFO:root:FL Epoch: 82 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1246
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1246 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677312
INFO:root:Worker: 1246 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534648
INFO:root:FL Epoch: 82 Norm Difference for worker 1246 is 1.098165
INFO:root:FL Epoch: 82 Done on worker:1246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :792
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486602
INFO:root:Worker: 792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595513
INFO:root:FL Epoch: 82 Norm Difference for worker 792 is 1.123645
INFO:root:FL Epoch: 82 Done on worker:792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1447
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 82 Ends   ===================
INFO:root:Epoch:82 Global Model Test Loss:0.55606129414895 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:82 Global Model Backdoor Test Loss:0.562764585018158                             and Backdoor Test Accuracy:72.5 
INFO:root:=======================================================
INFO:root:================FL round 83 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 83 Workers Selected : [1537, 890, 1098, 872, 1229, 169, 1490, 659, 81, 873]
INFO:root:FL Epoch: 83 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 83 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 83 Training on worker :1537
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617594
INFO:root:Worker: 1537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574670
INFO:root:FL Epoch: 83 Norm Difference for worker 1537 is 1.104674
INFO:root:FL Epoch: 83 Done on worker:1537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :890
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485372
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602031
INFO:root:FL Epoch: 83 Norm Difference for worker 890 is 1.099136
INFO:root:FL Epoch: 83 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1098
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647270
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523397
INFO:root:FL Epoch: 83 Norm Difference for worker 1098 is 1.060496
INFO:root:FL Epoch: 83 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :872
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710428
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473469
INFO:root:FL Epoch: 83 Norm Difference for worker 872 is 1.048588
INFO:root:FL Epoch: 83 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1229
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1229 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448211
INFO:root:Worker: 1229 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499604
INFO:root:FL Epoch: 83 Norm Difference for worker 1229 is 1.042479
INFO:root:FL Epoch: 83 Done on worker:1229
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :169
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500512
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.539835
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 83 Norm Difference for worker 169 is 1.032673
INFO:root:FL Epoch: 83 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1490
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430929
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431069
INFO:root:FL Epoch: 83 Norm Difference for worker 1490 is 1.062644
INFO:root:FL Epoch: 83 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :659
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548581
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491279
INFO:root:FL Epoch: 83 Norm Difference for worker 659 is 1.049967
INFO:root:FL Epoch: 83 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :81
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.560906
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.707121
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 83 Norm Difference for worker 81 is 1.093133
INFO:root:FL Epoch: 83 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :873
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574741
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568164
INFO:root:FL Epoch: 83 Norm Difference for worker 873 is 1.065333
INFO:root:FL Epoch: 83 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1490
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 83 Ends   ===================
INFO:root:Epoch:83 Global Model Test Loss:0.596926888998817 and Test Accuracy:67.94117647058823 
INFO:root:Epoch:83 Global Model Backdoor Test Loss:0.8533566395441691                             and Backdoor Test Accuracy:42.5 
INFO:root:=======================================================
INFO:root:================FL round 84 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 84 Workers Selected : [1878, 1224, 132, 198, 140, 649, 436, 86, 1238, 1616]
INFO:root:FL Epoch: 84 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.1002994 0.1002994 0.0998004 0.0998004
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 84 Num points on workers: [200 200 201 201 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 84 Training on worker :1878
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677942
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592090
INFO:root:FL Epoch: 84 Norm Difference for worker 1878 is 1.073655
INFO:root:FL Epoch: 84 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1224
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1224 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520247
INFO:root:Worker: 1224 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645304
INFO:root:FL Epoch: 84 Norm Difference for worker 1224 is 0.942136
INFO:root:FL Epoch: 84 Done on worker:1224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :132
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.720823
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686774
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 132 is 1.026269
INFO:root:FL Epoch: 84 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :198
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526890
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.526588
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 198 is 1.01986
INFO:root:FL Epoch: 84 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :140
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.721905
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.599410
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 140 is 1.018256
INFO:root:FL Epoch: 84 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :649
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436612
INFO:root:Worker: 649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637408
INFO:root:FL Epoch: 84 Norm Difference for worker 649 is 1.110299
INFO:root:FL Epoch: 84 Done on worker:649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :436
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530863
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388810
INFO:root:FL Epoch: 84 Norm Difference for worker 436 is 1.086878
INFO:root:FL Epoch: 84 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :86
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.458620
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.504813
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 86 is 1.061228
INFO:root:FL Epoch: 84 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1238
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543301
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522690
INFO:root:FL Epoch: 84 Norm Difference for worker 1238 is 0.998391
INFO:root:FL Epoch: 84 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1616
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584348
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.705033
INFO:root:FL Epoch: 84 Norm Difference for worker 1616 is 1.003978
INFO:root:FL Epoch: 84 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1224
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 84 Ends   ===================
INFO:root:Epoch:84 Global Model Test Loss:0.601156003334943 and Test Accuracy:65.29411764705883 
INFO:root:Epoch:84 Global Model Backdoor Test Loss:0.8847926557064056                             and Backdoor Test Accuracy:37.5 
INFO:root:=======================================================
INFO:root:================FL round 85 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 85 Workers Selected : [376, 587, 1674, 1650, 1395, 747, 841, 1713, 586, 76]
INFO:root:FL Epoch: 85 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 85 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 85 Training on worker :376
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678738
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492791
INFO:root:FL Epoch: 85 Norm Difference for worker 376 is 0.953953
INFO:root:FL Epoch: 85 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :587
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549899
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586937
INFO:root:FL Epoch: 85 Norm Difference for worker 587 is 0.90369
INFO:root:FL Epoch: 85 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1674
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607656
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555791
INFO:root:FL Epoch: 85 Norm Difference for worker 1674 is 0.961969
INFO:root:FL Epoch: 85 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1650
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796624
INFO:root:Worker: 1650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561532
INFO:root:FL Epoch: 85 Norm Difference for worker 1650 is 0.940763
INFO:root:FL Epoch: 85 Done on worker:1650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1395
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.787614
INFO:root:Worker: 1395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602538
INFO:root:FL Epoch: 85 Norm Difference for worker 1395 is 0.863723
INFO:root:FL Epoch: 85 Done on worker:1395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :747
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714143
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585383
INFO:root:FL Epoch: 85 Norm Difference for worker 747 is 0.962081
INFO:root:FL Epoch: 85 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :841
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528944
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541565
INFO:root:FL Epoch: 85 Norm Difference for worker 841 is 0.939006
INFO:root:FL Epoch: 85 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1713
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588652
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584782
INFO:root:FL Epoch: 85 Norm Difference for worker 1713 is 0.984322
INFO:root:FL Epoch: 85 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :586
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501931
INFO:root:Worker: 586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501006
INFO:root:FL Epoch: 85 Norm Difference for worker 586 is 0.951572
INFO:root:FL Epoch: 85 Done on worker:586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :76
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.613801
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.432594
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 85 Norm Difference for worker 76 is 0.919092
INFO:root:FL Epoch: 85 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1395
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 85 Ends   ===================
INFO:root:Epoch:85 Global Model Test Loss:0.5642752962953904 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:85 Global Model Backdoor Test Loss:0.6502324839433035                             and Backdoor Test Accuracy:62.5 
INFO:root:=======================================================
INFO:root:================FL round 86 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 86 Workers Selected : [1588, 653, 1926, 1027, 529, 1929, 184, 1709, 74, 1001]
INFO:root:FL Epoch: 86 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 86 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 86 Training on worker :1588
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553334
INFO:root:Worker: 1588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543648
INFO:root:FL Epoch: 86 Norm Difference for worker 1588 is 1.029492
INFO:root:FL Epoch: 86 Done on worker:1588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :653
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509850
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580214
INFO:root:FL Epoch: 86 Norm Difference for worker 653 is 0.98924
INFO:root:FL Epoch: 86 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1926
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636183
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364841
INFO:root:FL Epoch: 86 Norm Difference for worker 1926 is 1.039319
INFO:root:FL Epoch: 86 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1027
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1027 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633568
INFO:root:Worker: 1027 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619572
INFO:root:FL Epoch: 86 Norm Difference for worker 1027 is 1.019511
INFO:root:FL Epoch: 86 Done on worker:1027
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :529
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543420
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435270
INFO:root:FL Epoch: 86 Norm Difference for worker 529 is 0.991991
INFO:root:FL Epoch: 86 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1929
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572983
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460120
INFO:root:FL Epoch: 86 Norm Difference for worker 1929 is 1.039129
INFO:root:FL Epoch: 86 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :184
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.396533
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483335
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 86 Norm Difference for worker 184 is 0.97067
INFO:root:FL Epoch: 86 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1709
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601722
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523966
INFO:root:FL Epoch: 86 Norm Difference for worker 1709 is 0.975276
INFO:root:FL Epoch: 86 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :74
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.469699
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.668422
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 86 Norm Difference for worker 74 is 1.024652
INFO:root:FL Epoch: 86 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1001
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1001 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604645
INFO:root:Worker: 1001 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483091
INFO:root:FL Epoch: 86 Norm Difference for worker 1001 is 0.93614
INFO:root:FL Epoch: 86 Done on worker:1001
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 184
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 86 Ends   ===================
INFO:root:Epoch:86 Global Model Test Loss:0.5805338515954859 and Test Accuracy:69.11764705882354 
INFO:root:Epoch:86 Global Model Backdoor Test Loss:0.7136661112308502                             and Backdoor Test Accuracy:57.5 
INFO:root:=======================================================
INFO:root:================FL round 87 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 87 Workers Selected : [1919, 211, 692, 756, 452, 1940, 1274, 505, 1090, 674]
INFO:root:FL Epoch: 87 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 87 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 87 Training on worker :1919
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537589
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502580
INFO:root:FL Epoch: 87 Norm Difference for worker 1919 is 1.177044
INFO:root:FL Epoch: 87 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :211
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.512151
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.553540
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 87 Norm Difference for worker 211 is 1.155582
INFO:root:FL Epoch: 87 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :692
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642141
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383276
INFO:root:FL Epoch: 87 Norm Difference for worker 692 is 1.178336
INFO:root:FL Epoch: 87 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :756
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579731
INFO:root:Worker: 756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666328
INFO:root:FL Epoch: 87 Norm Difference for worker 756 is 1.195534
INFO:root:FL Epoch: 87 Done on worker:756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :452
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652639
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560523
INFO:root:FL Epoch: 87 Norm Difference for worker 452 is 1.217182
INFO:root:FL Epoch: 87 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1940
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504857
INFO:root:Worker: 1940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256153
INFO:root:FL Epoch: 87 Norm Difference for worker 1940 is 1.126121
INFO:root:FL Epoch: 87 Done on worker:1940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1274
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479381
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548952
INFO:root:FL Epoch: 87 Norm Difference for worker 1274 is 1.16486
INFO:root:FL Epoch: 87 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :505
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521539
INFO:root:Worker: 505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.825609
INFO:root:FL Epoch: 87 Norm Difference for worker 505 is 1.290698
INFO:root:FL Epoch: 87 Done on worker:505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1090
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794589
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489827
INFO:root:FL Epoch: 87 Norm Difference for worker 1090 is 1.188952
INFO:root:FL Epoch: 87 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :674
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570064
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566033
INFO:root:FL Epoch: 87 Norm Difference for worker 674 is 1.223757
INFO:root:FL Epoch: 87 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1090
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 87 Ends   ===================
INFO:root:Epoch:87 Global Model Test Loss:0.5496091421912698 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:87 Global Model Backdoor Test Loss:0.5611223230759302                             and Backdoor Test Accuracy:69.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 88 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 88 Workers Selected : [754, 1867, 1196, 1355, 1912, 1919, 1518, 818, 1600, 1594]
INFO:root:FL Epoch: 88 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 88 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 88 Training on worker :754
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719813
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396307
INFO:root:FL Epoch: 88 Norm Difference for worker 754 is 1.196478
INFO:root:FL Epoch: 88 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1867
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639140
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513596
INFO:root:FL Epoch: 88 Norm Difference for worker 1867 is 1.238276
INFO:root:FL Epoch: 88 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1196
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1196 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658578
INFO:root:Worker: 1196 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463218
INFO:root:FL Epoch: 88 Norm Difference for worker 1196 is 1.202893
INFO:root:FL Epoch: 88 Done on worker:1196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1355
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455600
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564617
INFO:root:FL Epoch: 88 Norm Difference for worker 1355 is 1.203373
INFO:root:FL Epoch: 88 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1912
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556803
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544157
INFO:root:FL Epoch: 88 Norm Difference for worker 1912 is 1.264812
INFO:root:FL Epoch: 88 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1919
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742197
INFO:root:Worker: 1919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507448
INFO:root:FL Epoch: 88 Norm Difference for worker 1919 is 1.217059
INFO:root:FL Epoch: 88 Done on worker:1919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1518
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483311
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406119
INFO:root:FL Epoch: 88 Norm Difference for worker 1518 is 1.244767
INFO:root:FL Epoch: 88 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :818
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535736
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525007
INFO:root:FL Epoch: 88 Norm Difference for worker 818 is 1.213265
INFO:root:FL Epoch: 88 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1600
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532669
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.718772
INFO:root:FL Epoch: 88 Norm Difference for worker 1600 is 1.34971
INFO:root:FL Epoch: 88 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1594
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579091
INFO:root:Worker: 1594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521123
INFO:root:FL Epoch: 88 Norm Difference for worker 1594 is 1.19757
INFO:root:FL Epoch: 88 Done on worker:1594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1594
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 88 Ends   ===================
INFO:root:Epoch:88 Global Model Test Loss:0.5522716764141532 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:88 Global Model Backdoor Test Loss:0.5224763800700506                             and Backdoor Test Accuracy:70.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 89 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 89 Workers Selected : [1856, 476, 191, 401, 350, 34, 742, 1521, 1275, 107]
INFO:root:FL Epoch: 89 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 89 Num points on workers: [200 200 201 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 89 Training on worker :1856
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542359
INFO:root:Worker: 1856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559869
INFO:root:FL Epoch: 89 Norm Difference for worker 1856 is 1.042368
INFO:root:FL Epoch: 89 Done on worker:1856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :476
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596676
INFO:root:Worker: 476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537688
INFO:root:FL Epoch: 89 Norm Difference for worker 476 is 0.955942
INFO:root:FL Epoch: 89 Done on worker:476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :191
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.480715
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.579173
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 191 is 1.014699
INFO:root:FL Epoch: 89 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :401
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537217
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504619
INFO:root:FL Epoch: 89 Norm Difference for worker 401 is 1.009681
INFO:root:FL Epoch: 89 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :350
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568314
INFO:root:Worker: 350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673190
INFO:root:FL Epoch: 89 Norm Difference for worker 350 is 1.035286
INFO:root:FL Epoch: 89 Done on worker:350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :34
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 34 Train Epoch: 0 [0/201 (0%)]	Loss: 0.605337
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 34 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447102
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 34 is 1.076828
INFO:root:FL Epoch: 89 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :742
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687604
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499781
INFO:root:FL Epoch: 89 Norm Difference for worker 742 is 1.025419
INFO:root:FL Epoch: 89 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1521
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555454
INFO:root:Worker: 1521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430611
INFO:root:FL Epoch: 89 Norm Difference for worker 1521 is 0.956157
INFO:root:FL Epoch: 89 Done on worker:1521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1275
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542835
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524943
INFO:root:FL Epoch: 89 Norm Difference for worker 1275 is 1.087271
INFO:root:FL Epoch: 89 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :107
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 107 Train Epoch: 0 [0/201 (0%)]	Loss: 0.732783
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 107 Train Epoch: 1 [0/201 (0%)]	Loss: 0.581966
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 107 is 1.043962
INFO:root:FL Epoch: 89 Done on worker:107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1521
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 89 Ends   ===================
INFO:root:Epoch:89 Global Model Test Loss:0.5366704499020296 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:89 Global Model Backdoor Test Loss:0.6335528691609701                             and Backdoor Test Accuracy:63.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 90 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 90 Workers Selected : [1193, 930, 1680, 1543, 25, 1115, 1856, 687, 24, 850]
INFO:root:FL Epoch: 90 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 90 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 90 Training on worker :1193
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1193 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672883
INFO:root:Worker: 1193 Train Epoch: 1 [0/200 (0%)]	Loss: 0.793126
INFO:root:FL Epoch: 90 Norm Difference for worker 1193 is 1.208752
INFO:root:FL Epoch: 90 Done on worker:1193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :930
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605698
INFO:root:Worker: 930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451106
INFO:root:FL Epoch: 90 Norm Difference for worker 930 is 0.968214
INFO:root:FL Epoch: 90 Done on worker:930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1680
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546802
INFO:root:Worker: 1680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551199
INFO:root:FL Epoch: 90 Norm Difference for worker 1680 is 0.987614
INFO:root:FL Epoch: 90 Done on worker:1680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1543
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628949
INFO:root:Worker: 1543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533861
INFO:root:FL Epoch: 90 Norm Difference for worker 1543 is 1.070859
INFO:root:FL Epoch: 90 Done on worker:1543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :25
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.537299
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.405649
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 90 Norm Difference for worker 25 is 0.981762
INFO:root:FL Epoch: 90 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1115
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1115 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758491
INFO:root:Worker: 1115 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524654
INFO:root:FL Epoch: 90 Norm Difference for worker 1115 is 1.031334
INFO:root:FL Epoch: 90 Done on worker:1115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1856
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510813
INFO:root:Worker: 1856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390302
INFO:root:FL Epoch: 90 Norm Difference for worker 1856 is 1.063316
INFO:root:FL Epoch: 90 Done on worker:1856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :687
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750751
INFO:root:Worker: 687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583465
INFO:root:FL Epoch: 90 Norm Difference for worker 687 is 1.068347
INFO:root:FL Epoch: 90 Done on worker:687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :24
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.731129
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.580886
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 90 Norm Difference for worker 24 is 1.148488
INFO:root:FL Epoch: 90 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :850
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677201
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533201
INFO:root:FL Epoch: 90 Norm Difference for worker 850 is 1.079976
INFO:root:FL Epoch: 90 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 25
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 90 Ends   ===================
INFO:root:Epoch:90 Global Model Test Loss:0.5366943443522734 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:90 Global Model Backdoor Test Loss:0.6198048690954844                             and Backdoor Test Accuracy:62.5 
INFO:root:=======================================================
INFO:root:================FL round 91 Begins ===================
INFO:root:FL Epoch: 91 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 91 Workers Selected : [0, 1, 2, 623, 1591, 1404, 853, 1441, 944, 1326]
INFO:root:FL Epoch: 91 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 91 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 91 Training on worker :0
INFO:root:FL Epoch: 91 Using Learning rate : 0.008351196755739124 
INFO:root:FL Epoch: 91 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548750
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613241
INFO:root:FL Epoch: 91 Worker: 0 Backdoor Test Loss: 0.3632183273633321 Backdoor Test Accuracy: 86.66666666666667
INFO:root:FL Epoch: 91 Worker: 0 Backdoor Train Loss: 0.4394260972738266 Backdoor Train Accuracy: 81.5
INFO:root:FL Epoch: 91 Norm Difference for worker 0 is 0.32119
INFO:root:FL Epoch: 91 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1
INFO:root:FL Epoch: 91 Using Learning rate : 0.008351196755739124 
INFO:root:FL Epoch: 91 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479849
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463749
INFO:root:FL Epoch: 91 Worker: 1 Backdoor Test Loss: 0.34175905585289 Backdoor Test Accuracy: 86.66666666666667
INFO:root:FL Epoch: 91 Worker: 1 Backdoor Train Loss: 0.4434752225875854 Backdoor Train Accuracy: 80.5
INFO:root:FL Epoch: 91 Norm Difference for worker 1 is 0.328983
INFO:root:FL Epoch: 91 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :2
INFO:root:FL Epoch: 91 Using Learning rate : 0.008351196755739124 
INFO:root:FL Epoch: 91 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552560
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591376
INFO:root:FL Epoch: 91 Worker: 2 Backdoor Test Loss: 0.3626030584176381 Backdoor Test Accuracy: 86.66666666666667
INFO:root:FL Epoch: 91 Worker: 2 Backdoor Train Loss: 0.44013920426368713 Backdoor Train Accuracy: 80.5
INFO:root:FL Epoch: 91 Norm Difference for worker 2 is 0.31812
INFO:root:FL Epoch: 91 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :623
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701457
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515025
INFO:root:FL Epoch: 91 Norm Difference for worker 623 is 1.031496
INFO:root:FL Epoch: 91 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1591
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686551
INFO:root:Worker: 1591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629942
INFO:root:FL Epoch: 91 Norm Difference for worker 1591 is 1.047778
INFO:root:FL Epoch: 91 Done on worker:1591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1404
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442634
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386304
INFO:root:FL Epoch: 91 Norm Difference for worker 1404 is 1.081387
INFO:root:FL Epoch: 91 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :853
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.839921
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570612
INFO:root:FL Epoch: 91 Norm Difference for worker 853 is 1.045492
INFO:root:FL Epoch: 91 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1441
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547846
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686366
INFO:root:FL Epoch: 91 Norm Difference for worker 1441 is 1.114193
INFO:root:FL Epoch: 91 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :944
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.840043
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662226
INFO:root:FL Epoch: 91 Norm Difference for worker 944 is 0.97659
INFO:root:FL Epoch: 91 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1326
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613547
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621406
INFO:root:FL Epoch: 91 Norm Difference for worker 1326 is 0.988556
INFO:root:FL Epoch: 91 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 91 Ends   ===================
INFO:root:Epoch:91 Global Model Test Loss:0.54903264782008 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:91 Global Model Backdoor Test Loss:0.3632183273633321                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 92 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 92 Workers Selected : [845, 1139, 844, 540, 872, 1177, 1685, 175, 376, 1367]
INFO:root:FL Epoch: 92 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 92 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 92 Training on worker :845
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664496
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634166
INFO:root:FL Epoch: 92 Norm Difference for worker 845 is 1.063269
INFO:root:FL Epoch: 92 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1139
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487049
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523268
INFO:root:FL Epoch: 92 Norm Difference for worker 1139 is 1.08687
INFO:root:FL Epoch: 92 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :844
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.825620
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486392
INFO:root:FL Epoch: 92 Norm Difference for worker 844 is 1.026426
INFO:root:FL Epoch: 92 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :540
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450089
INFO:root:Worker: 540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396002
INFO:root:FL Epoch: 92 Norm Difference for worker 540 is 1.13501
INFO:root:FL Epoch: 92 Done on worker:540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :872
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644459
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549259
INFO:root:FL Epoch: 92 Norm Difference for worker 872 is 1.118701
INFO:root:FL Epoch: 92 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1177
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1177 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734281
INFO:root:Worker: 1177 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472601
INFO:root:FL Epoch: 92 Norm Difference for worker 1177 is 1.096634
INFO:root:FL Epoch: 92 Done on worker:1177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1685
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529859
INFO:root:Worker: 1685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549448
INFO:root:FL Epoch: 92 Norm Difference for worker 1685 is 1.035558
INFO:root:FL Epoch: 92 Done on worker:1685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :175
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 175 Train Epoch: 0 [0/201 (0%)]	Loss: 0.583747
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 175 Train Epoch: 1 [0/201 (0%)]	Loss: 0.597469
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 92 Norm Difference for worker 175 is 1.112049
INFO:root:FL Epoch: 92 Done on worker:175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :376
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709801
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662301
INFO:root:FL Epoch: 92 Norm Difference for worker 376 is 1.084494
INFO:root:FL Epoch: 92 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1367
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775357
INFO:root:Worker: 1367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558925
INFO:root:FL Epoch: 92 Norm Difference for worker 1367 is 1.162845
INFO:root:FL Epoch: 92 Done on worker:1367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1685
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 92 Ends   ===================
INFO:root:Epoch:92 Global Model Test Loss:0.5377918937627006 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:92 Global Model Backdoor Test Loss:0.5681150952974955                             and Backdoor Test Accuracy:72.5 
INFO:root:=======================================================
INFO:root:================FL round 93 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 93 Workers Selected : [48, 872, 1196, 1390, 1195, 341, 279, 241, 1160, 1421]
INFO:root:FL Epoch: 93 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 93 Num points on workers: [201 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 93 Training on worker :48
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.643124
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.480572
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 48 is 0.989247
INFO:root:FL Epoch: 93 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :872
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724572
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517052
INFO:root:FL Epoch: 93 Norm Difference for worker 872 is 0.989222
INFO:root:FL Epoch: 93 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1196
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1196 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569584
INFO:root:Worker: 1196 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492303
INFO:root:FL Epoch: 93 Norm Difference for worker 1196 is 0.973275
INFO:root:FL Epoch: 93 Done on worker:1196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1390
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684078
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604076
INFO:root:FL Epoch: 93 Norm Difference for worker 1390 is 1.002757
INFO:root:FL Epoch: 93 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1195
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584937
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473692
INFO:root:FL Epoch: 93 Norm Difference for worker 1195 is 0.95733
INFO:root:FL Epoch: 93 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :341
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650840
INFO:root:Worker: 341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566471
INFO:root:FL Epoch: 93 Norm Difference for worker 341 is 1.005638
INFO:root:FL Epoch: 93 Done on worker:341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :279
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603015
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.541152
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 279 is 0.937025
INFO:root:FL Epoch: 93 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :241
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 241 Train Epoch: 0 [0/201 (0%)]	Loss: 0.664436
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 241 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538969
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 241 is 0.978935
INFO:root:FL Epoch: 93 Done on worker:241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1160
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1160 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751460
INFO:root:Worker: 1160 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688504
INFO:root:FL Epoch: 93 Norm Difference for worker 1160 is 0.956963
INFO:root:FL Epoch: 93 Done on worker:1160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1421
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485773
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542560
INFO:root:FL Epoch: 93 Norm Difference for worker 1421 is 1.006078
INFO:root:FL Epoch: 93 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 279
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 93 Ends   ===================
INFO:root:Epoch:93 Global Model Test Loss:0.5333396932658028 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:93 Global Model Backdoor Test Loss:0.568791518608729                             and Backdoor Test Accuracy:70.0 
INFO:root:=======================================================
INFO:root:================FL round 94 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 94 Workers Selected : [1770, 149, 1939, 1250, 809, 301, 636, 1925, 125, 1537]
INFO:root:FL Epoch: 94 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 94 Num points on workers: [200 201 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 94 Training on worker :1770
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618620
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582500
INFO:root:FL Epoch: 94 Norm Difference for worker 1770 is 0.969053
INFO:root:FL Epoch: 94 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :149
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 149 Train Epoch: 0 [0/201 (0%)]	Loss: 0.416972
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 149 Train Epoch: 1 [0/201 (0%)]	Loss: 0.438290
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 149 is 1.015417
INFO:root:FL Epoch: 94 Done on worker:149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1939
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699309
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567494
INFO:root:FL Epoch: 94 Norm Difference for worker 1939 is 0.929805
INFO:root:FL Epoch: 94 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1250
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571101
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519076
INFO:root:FL Epoch: 94 Norm Difference for worker 1250 is 0.963307
INFO:root:FL Epoch: 94 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :809
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687360
INFO:root:Worker: 809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461967
INFO:root:FL Epoch: 94 Norm Difference for worker 809 is 0.969256
INFO:root:FL Epoch: 94 Done on worker:809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :301
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.709323
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.524811
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 301 is 0.923366
INFO:root:FL Epoch: 94 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :636
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698440
INFO:root:Worker: 636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513223
INFO:root:FL Epoch: 94 Norm Difference for worker 636 is 0.973018
INFO:root:FL Epoch: 94 Done on worker:636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1925
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.790341
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659951
INFO:root:FL Epoch: 94 Norm Difference for worker 1925 is 0.944398
INFO:root:FL Epoch: 94 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :125
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.543336
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.442967
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 125 is 0.956925
INFO:root:FL Epoch: 94 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1537
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749269
INFO:root:Worker: 1537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517533
INFO:root:FL Epoch: 94 Norm Difference for worker 1537 is 0.934736
INFO:root:FL Epoch: 94 Done on worker:1537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1925
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 94 Ends   ===================
INFO:root:Epoch:94 Global Model Test Loss:0.5436320673016941 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:94 Global Model Backdoor Test Loss:0.5645601550738016                             and Backdoor Test Accuracy:71.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 95 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 95 Workers Selected : [1495, 1264, 469, 1275, 734, 1533, 1555, 94, 311, 243]
INFO:root:FL Epoch: 95 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 95 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 95 Training on worker :1495
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608668
INFO:root:Worker: 1495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522626
INFO:root:FL Epoch: 95 Norm Difference for worker 1495 is 0.925644
INFO:root:FL Epoch: 95 Done on worker:1495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1264
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1264 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500006
INFO:root:Worker: 1264 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359562
INFO:root:FL Epoch: 95 Norm Difference for worker 1264 is 0.938704
INFO:root:FL Epoch: 95 Done on worker:1264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :469
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763727
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577622
INFO:root:FL Epoch: 95 Norm Difference for worker 469 is 0.855425
INFO:root:FL Epoch: 95 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1275
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561517
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445843
INFO:root:FL Epoch: 95 Norm Difference for worker 1275 is 1.027889
INFO:root:FL Epoch: 95 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :734
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565205
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493061
INFO:root:FL Epoch: 95 Norm Difference for worker 734 is 0.933434
INFO:root:FL Epoch: 95 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1533
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612695
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536763
INFO:root:FL Epoch: 95 Norm Difference for worker 1533 is 0.8916
INFO:root:FL Epoch: 95 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1555
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614686
INFO:root:Worker: 1555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542395
INFO:root:FL Epoch: 95 Norm Difference for worker 1555 is 0.885664
INFO:root:FL Epoch: 95 Done on worker:1555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :94
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/201 (0%)]	Loss: 0.589173
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 94 Train Epoch: 1 [0/201 (0%)]	Loss: 0.561249
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 95 Norm Difference for worker 94 is 0.95772
INFO:root:FL Epoch: 95 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :311
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.510837
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.519464
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 95 Norm Difference for worker 311 is 0.913053
INFO:root:FL Epoch: 95 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :243
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.613497
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428649
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 95 Norm Difference for worker 243 is 1.003878
INFO:root:FL Epoch: 95 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 469
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 95 Ends   ===================
INFO:root:Epoch:95 Global Model Test Loss:0.540285645162358 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:95 Global Model Backdoor Test Loss:0.6703114112218221                             and Backdoor Test Accuracy:60.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 96 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 96 Workers Selected : [1199, 1172, 440, 207, 205, 542, 1428, 1348, 1135, 308]
INFO:root:FL Epoch: 96 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 96 Num points on workers: [200 200 200 201 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 96 Training on worker :1199
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607126
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658938
INFO:root:FL Epoch: 96 Norm Difference for worker 1199 is 0.911243
INFO:root:FL Epoch: 96 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1172
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1172 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603762
INFO:root:Worker: 1172 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661712
INFO:root:FL Epoch: 96 Norm Difference for worker 1172 is 1.023962
INFO:root:FL Epoch: 96 Done on worker:1172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :440
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579299
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526639
INFO:root:FL Epoch: 96 Norm Difference for worker 440 is 0.949504
INFO:root:FL Epoch: 96 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :207
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.746165
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.648005
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 207 is 0.982021
INFO:root:FL Epoch: 96 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :205
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.468027
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.630869
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 205 is 0.923284
INFO:root:FL Epoch: 96 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :542
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575034
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516591
INFO:root:FL Epoch: 96 Norm Difference for worker 542 is 0.982013
INFO:root:FL Epoch: 96 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1428
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592721
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521483
INFO:root:FL Epoch: 96 Norm Difference for worker 1428 is 0.972709
INFO:root:FL Epoch: 96 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1348
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700609
INFO:root:Worker: 1348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592996
INFO:root:FL Epoch: 96 Norm Difference for worker 1348 is 0.916807
INFO:root:FL Epoch: 96 Done on worker:1348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1135
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1135 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652093
INFO:root:Worker: 1135 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568251
INFO:root:FL Epoch: 96 Norm Difference for worker 1135 is 0.897889
INFO:root:FL Epoch: 96 Done on worker:1135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :308
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.551306
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.677893
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 308 is 0.973934
INFO:root:FL Epoch: 96 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1135
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 96 Ends   ===================
INFO:root:Epoch:96 Global Model Test Loss:0.5595704632646897 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:96 Global Model Backdoor Test Loss:0.8288346628348032                             and Backdoor Test Accuracy:40.0 
INFO:root:=======================================================
INFO:root:================FL round 97 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 97 Workers Selected : [848, 769, 627, 413, 1061, 1302, 1445, 973, 110, 15]
INFO:root:FL Epoch: 97 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 97 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 97 Training on worker :848
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665481
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563274
INFO:root:FL Epoch: 97 Norm Difference for worker 848 is 0.975807
INFO:root:FL Epoch: 97 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :769
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.857400
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580246
INFO:root:FL Epoch: 97 Norm Difference for worker 769 is 0.955921
INFO:root:FL Epoch: 97 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :627
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506850
INFO:root:Worker: 627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507381
INFO:root:FL Epoch: 97 Norm Difference for worker 627 is 0.989677
INFO:root:FL Epoch: 97 Done on worker:627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :413
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617060
INFO:root:Worker: 413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514626
INFO:root:FL Epoch: 97 Norm Difference for worker 413 is 0.998075
INFO:root:FL Epoch: 97 Done on worker:413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1061
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717960
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515889
INFO:root:FL Epoch: 97 Norm Difference for worker 1061 is 0.933158
INFO:root:FL Epoch: 97 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1302
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1302 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714316
INFO:root:Worker: 1302 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609048
INFO:root:FL Epoch: 97 Norm Difference for worker 1302 is 0.957868
INFO:root:FL Epoch: 97 Done on worker:1302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1445
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749670
INFO:root:Worker: 1445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656703
INFO:root:FL Epoch: 97 Norm Difference for worker 1445 is 0.981252
INFO:root:FL Epoch: 97 Done on worker:1445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :973
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610226
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547351
INFO:root:FL Epoch: 97 Norm Difference for worker 973 is 1.015077
INFO:root:FL Epoch: 97 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :110
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 110 Train Epoch: 0 [0/201 (0%)]	Loss: 0.583592
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 110 Train Epoch: 1 [0/201 (0%)]	Loss: 0.660989
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 110 is 1.010266
INFO:root:FL Epoch: 97 Done on worker:110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :15
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.439353
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.462793
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 15 is 0.986927
INFO:root:FL Epoch: 97 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1061
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 97 Ends   ===================
INFO:root:Epoch:97 Global Model Test Loss:0.5272272930425757 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:97 Global Model Backdoor Test Loss:0.6873508095741272                             and Backdoor Test Accuracy:60.0 
INFO:root:=======================================================
INFO:root:================FL round 98 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 98 Workers Selected : [633, 77, 1548, 734, 1609, 1375, 1209, 1751, 1773, 1238]
INFO:root:FL Epoch: 98 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 98 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 98 Training on worker :633
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.837914
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407377
INFO:root:FL Epoch: 98 Norm Difference for worker 633 is 1.134531
INFO:root:FL Epoch: 98 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :77
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.648220
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419340
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 98 Norm Difference for worker 77 is 1.12905
INFO:root:FL Epoch: 98 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1548
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.964823
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560285
INFO:root:FL Epoch: 98 Norm Difference for worker 1548 is 1.14069
INFO:root:FL Epoch: 98 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :734
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710905
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472300
INFO:root:FL Epoch: 98 Norm Difference for worker 734 is 1.116586
INFO:root:FL Epoch: 98 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1609
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581302
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474477
INFO:root:FL Epoch: 98 Norm Difference for worker 1609 is 1.186448
INFO:root:FL Epoch: 98 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1375
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613250
INFO:root:Worker: 1375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569413
INFO:root:FL Epoch: 98 Norm Difference for worker 1375 is 1.177158
INFO:root:FL Epoch: 98 Done on worker:1375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1209
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1209 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681590
INFO:root:Worker: 1209 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475640
INFO:root:FL Epoch: 98 Norm Difference for worker 1209 is 1.145503
INFO:root:FL Epoch: 98 Done on worker:1209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1751
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620629
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444525
INFO:root:FL Epoch: 98 Norm Difference for worker 1751 is 1.175405
INFO:root:FL Epoch: 98 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1773
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446599
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497762
INFO:root:FL Epoch: 98 Norm Difference for worker 1773 is 1.200878
INFO:root:FL Epoch: 98 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1238
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572750
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617807
INFO:root:FL Epoch: 98 Norm Difference for worker 1238 is 1.164015
INFO:root:FL Epoch: 98 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 734
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 98 Ends   ===================
INFO:root:Epoch:98 Global Model Test Loss:0.5596733584123499 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:98 Global Model Backdoor Test Loss:0.6355366706848145                             and Backdoor Test Accuracy:61.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 99 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 99 Workers Selected : [1854, 1767, 1325, 857, 918, 86, 420, 564, 958, 800]
INFO:root:FL Epoch: 99 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 99 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 99 Training on worker :1854
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665990
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555086
INFO:root:FL Epoch: 99 Norm Difference for worker 1854 is 1.095226
INFO:root:FL Epoch: 99 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1767
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646749
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506681
INFO:root:FL Epoch: 99 Norm Difference for worker 1767 is 1.044839
INFO:root:FL Epoch: 99 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1325
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1325 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641589
INFO:root:Worker: 1325 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595060
INFO:root:FL Epoch: 99 Norm Difference for worker 1325 is 1.120932
INFO:root:FL Epoch: 99 Done on worker:1325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :857
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627664
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622473
INFO:root:FL Epoch: 99 Norm Difference for worker 857 is 1.14106
INFO:root:FL Epoch: 99 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :918
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581388
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371870
INFO:root:FL Epoch: 99 Norm Difference for worker 918 is 1.018118
INFO:root:FL Epoch: 99 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :86
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.679800
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.499859
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 99 Norm Difference for worker 86 is 1.11408
INFO:root:FL Epoch: 99 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :420
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486858
INFO:root:Worker: 420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532597
INFO:root:FL Epoch: 99 Norm Difference for worker 420 is 1.135522
INFO:root:FL Epoch: 99 Done on worker:420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :564
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458171
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509409
INFO:root:FL Epoch: 99 Norm Difference for worker 564 is 1.123401
INFO:root:FL Epoch: 99 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :958
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614723
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536844
INFO:root:FL Epoch: 99 Norm Difference for worker 958 is 1.071058
INFO:root:FL Epoch: 99 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :800
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540552
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666734
INFO:root:FL Epoch: 99 Norm Difference for worker 800 is 1.146333
INFO:root:FL Epoch: 99 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 918
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 99 Ends   ===================
INFO:root:Epoch:99 Global Model Test Loss:0.5573563856237075 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:99 Global Model Backdoor Test Loss:0.788595070441564                             and Backdoor Test Accuracy:52.5 
INFO:root:=======================================================
INFO:root:================FL round 100 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 100 Workers Selected : [1823, 1049, 1864, 1066, 1740, 1716, 840, 11, 1887, 845]
INFO:root:FL Epoch: 100 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 100 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 100 Training on worker :1823
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661891
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464599
INFO:root:FL Epoch: 100 Norm Difference for worker 1823 is 1.249834
INFO:root:FL Epoch: 100 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1049
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1049 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548528
INFO:root:Worker: 1049 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552728
INFO:root:FL Epoch: 100 Norm Difference for worker 1049 is 1.124728
INFO:root:FL Epoch: 100 Done on worker:1049
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1864
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626960
INFO:root:Worker: 1864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566193
INFO:root:FL Epoch: 100 Norm Difference for worker 1864 is 1.184499
INFO:root:FL Epoch: 100 Done on worker:1864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1066
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1066 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516352
INFO:root:Worker: 1066 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506113
INFO:root:FL Epoch: 100 Norm Difference for worker 1066 is 1.186187
INFO:root:FL Epoch: 100 Done on worker:1066
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1740
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812136
INFO:root:Worker: 1740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486288
INFO:root:FL Epoch: 100 Norm Difference for worker 1740 is 1.150255
INFO:root:FL Epoch: 100 Done on worker:1740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1716
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504645
INFO:root:Worker: 1716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624769
INFO:root:FL Epoch: 100 Norm Difference for worker 1716 is 1.113928
INFO:root:FL Epoch: 100 Done on worker:1716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :840
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686091
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317116
INFO:root:FL Epoch: 100 Norm Difference for worker 840 is 1.185039
INFO:root:FL Epoch: 100 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :11
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 11 Train Epoch: 0 [0/201 (0%)]	Loss: 0.499987
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 11 Train Epoch: 1 [0/201 (0%)]	Loss: 0.728601
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 100 Norm Difference for worker 11 is 1.184762
INFO:root:FL Epoch: 100 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1887
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749648
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472313
INFO:root:FL Epoch: 100 Norm Difference for worker 1887 is 1.142037
INFO:root:FL Epoch: 100 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :845
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743965
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490249
INFO:root:FL Epoch: 100 Norm Difference for worker 845 is 1.145823
INFO:root:FL Epoch: 100 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1887
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 100 Ends   ===================
INFO:root:Epoch:100 Global Model Test Loss:0.5531331651351031 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:100 Global Model Backdoor Test Loss:0.6467036008834839                             and Backdoor Test Accuracy:64.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 101 Begins ===================
INFO:root:FL Epoch: 101 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 101 Workers Selected : [0, 1, 2, 1526, 1322, 862, 701, 1726, 526, 1267]
INFO:root:FL Epoch: 101 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 101 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 101 Training on worker :0
INFO:root:FL Epoch: 101 Using Learning rate : 0.008185668046884278 
INFO:root:FL Epoch: 101 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406833
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393070
INFO:root:FL Epoch: 101 Worker: 0 Backdoor Test Loss: 0.3738759110371272 Backdoor Test Accuracy: 85.0
INFO:root:FL Epoch: 101 Worker: 0 Backdoor Train Loss: 0.41337904036045076 Backdoor Train Accuracy: 82.0
INFO:root:FL Epoch: 101 Norm Difference for worker 0 is 0.325221
INFO:root:FL Epoch: 101 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1
INFO:root:FL Epoch: 101 Using Learning rate : 0.008185668046884278 
INFO:root:FL Epoch: 101 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347437
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410194
INFO:root:FL Epoch: 101 Worker: 1 Backdoor Test Loss: 0.36812275151411694 Backdoor Test Accuracy: 85.0
INFO:root:FL Epoch: 101 Worker: 1 Backdoor Train Loss: 0.41480680704116824 Backdoor Train Accuracy: 82.0
INFO:root:FL Epoch: 101 Norm Difference for worker 1 is 0.327366
INFO:root:FL Epoch: 101 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :2
INFO:root:FL Epoch: 101 Using Learning rate : 0.008185668046884278 
INFO:root:FL Epoch: 101 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643811
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453246
INFO:root:FL Epoch: 101 Worker: 2 Backdoor Test Loss: 0.36482639114061993 Backdoor Test Accuracy: 85.83333333333333
INFO:root:FL Epoch: 101 Worker: 2 Backdoor Train Loss: 0.4148024171590805 Backdoor Train Accuracy: 82.5
INFO:root:FL Epoch: 101 Norm Difference for worker 2 is 0.325738
INFO:root:FL Epoch: 101 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1526
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652269
INFO:root:Worker: 1526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427610
INFO:root:FL Epoch: 101 Norm Difference for worker 1526 is 1.060759
INFO:root:FL Epoch: 101 Done on worker:1526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1322
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1322 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539107
INFO:root:Worker: 1322 Train Epoch: 1 [0/200 (0%)]	Loss: 0.726945
INFO:root:FL Epoch: 101 Norm Difference for worker 1322 is 1.179349
INFO:root:FL Epoch: 101 Done on worker:1322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :862
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563246
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453733
INFO:root:FL Epoch: 101 Norm Difference for worker 862 is 1.138089
INFO:root:FL Epoch: 101 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :701
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381752
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586655
INFO:root:FL Epoch: 101 Norm Difference for worker 701 is 1.128799
INFO:root:FL Epoch: 101 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1726
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446433
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558769
INFO:root:FL Epoch: 101 Norm Difference for worker 1726 is 1.156347
INFO:root:FL Epoch: 101 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :526
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508801
INFO:root:Worker: 526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445852
INFO:root:FL Epoch: 101 Norm Difference for worker 526 is 1.045776
INFO:root:FL Epoch: 101 Done on worker:526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1267
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1267 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553660
INFO:root:Worker: 1267 Train Epoch: 1 [0/200 (0%)]	Loss: 0.716870
INFO:root:FL Epoch: 101 Norm Difference for worker 1267 is 1.057247
INFO:root:FL Epoch: 101 Done on worker:1267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 101 Ends   ===================
INFO:root:Epoch:101 Global Model Test Loss:0.565462754053228 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:101 Global Model Backdoor Test Loss:0.3738759110371272                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 102 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 102 Workers Selected : [1911, 427, 1354, 10, 1326, 1947, 1506, 1248, 887, 1077]
INFO:root:FL Epoch: 102 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 102 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 102 Training on worker :1911
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714036
INFO:root:Worker: 1911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361322
INFO:root:FL Epoch: 102 Norm Difference for worker 1911 is 1.0867
INFO:root:FL Epoch: 102 Done on worker:1911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :427
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510724
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558483
INFO:root:FL Epoch: 102 Norm Difference for worker 427 is 1.170958
INFO:root:FL Epoch: 102 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1354
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703946
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.705258
INFO:root:FL Epoch: 102 Norm Difference for worker 1354 is 1.152425
INFO:root:FL Epoch: 102 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :10
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 10 Train Epoch: 0 [0/201 (0%)]	Loss: 0.592097
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 10 Train Epoch: 1 [0/201 (0%)]	Loss: 0.480194
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 102 Norm Difference for worker 10 is 1.167812
INFO:root:FL Epoch: 102 Done on worker:10
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1326
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485302
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622861
INFO:root:FL Epoch: 102 Norm Difference for worker 1326 is 1.121188
INFO:root:FL Epoch: 102 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1947
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349778
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624106
INFO:root:FL Epoch: 102 Norm Difference for worker 1947 is 1.101739
INFO:root:FL Epoch: 102 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1506
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636967
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451906
INFO:root:FL Epoch: 102 Norm Difference for worker 1506 is 1.164933
INFO:root:FL Epoch: 102 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1248
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.840498
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680194
INFO:root:FL Epoch: 102 Norm Difference for worker 1248 is 1.155699
INFO:root:FL Epoch: 102 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :887
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607418
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511522
INFO:root:FL Epoch: 102 Norm Difference for worker 887 is 1.188699
INFO:root:FL Epoch: 102 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1077
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1077 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544115
INFO:root:Worker: 1077 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438203
INFO:root:FL Epoch: 102 Norm Difference for worker 1077 is 1.047237
INFO:root:FL Epoch: 102 Done on worker:1077
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1911
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 102 Ends   ===================
INFO:root:Epoch:102 Global Model Test Loss:0.5521394400035634 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:102 Global Model Backdoor Test Loss:0.5235574543476105                             and Backdoor Test Accuracy:75.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 103 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 103 Workers Selected : [1424, 869, 1947, 1218, 731, 391, 1873, 163, 1175, 1457]
INFO:root:FL Epoch: 103 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 103 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 103 Training on worker :1424
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536508
INFO:root:Worker: 1424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407033
INFO:root:FL Epoch: 103 Norm Difference for worker 1424 is 1.151713
INFO:root:FL Epoch: 103 Done on worker:1424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :869
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512286
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487539
INFO:root:FL Epoch: 103 Norm Difference for worker 869 is 1.083671
INFO:root:FL Epoch: 103 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1947
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722836
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413828
INFO:root:FL Epoch: 103 Norm Difference for worker 1947 is 1.032585
INFO:root:FL Epoch: 103 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1218
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524555
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496802
INFO:root:FL Epoch: 103 Norm Difference for worker 1218 is 1.073702
INFO:root:FL Epoch: 103 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :731
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583437
INFO:root:Worker: 731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.739339
INFO:root:FL Epoch: 103 Norm Difference for worker 731 is 1.032264
INFO:root:FL Epoch: 103 Done on worker:731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :391
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620590
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486259
INFO:root:FL Epoch: 103 Norm Difference for worker 391 is 1.047989
INFO:root:FL Epoch: 103 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1873
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536079
INFO:root:Worker: 1873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629834
INFO:root:FL Epoch: 103 Norm Difference for worker 1873 is 1.138805
INFO:root:FL Epoch: 103 Done on worker:1873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :163
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.538399
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.603441
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 103 Norm Difference for worker 163 is 1.055247
INFO:root:FL Epoch: 103 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1175
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682811
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589742
INFO:root:FL Epoch: 103 Norm Difference for worker 1175 is 1.058053
INFO:root:FL Epoch: 103 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1457
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606709
INFO:root:Worker: 1457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540228
INFO:root:FL Epoch: 103 Norm Difference for worker 1457 is 1.099167
INFO:root:FL Epoch: 103 Done on worker:1457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1947
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 103 Ends   ===================
INFO:root:Epoch:103 Global Model Test Loss:0.536190811325522 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:103 Global Model Backdoor Test Loss:0.5256267786026001                             and Backdoor Test Accuracy:73.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 104 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 104 Workers Selected : [612, 1157, 1471, 128, 66, 879, 1042, 1632, 150, 1712]
INFO:root:FL Epoch: 104 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 104 Num points on workers: [200 200 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 104 Training on worker :612
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757143
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590734
INFO:root:FL Epoch: 104 Norm Difference for worker 612 is 1.198244
INFO:root:FL Epoch: 104 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1157
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677834
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.710540
INFO:root:FL Epoch: 104 Norm Difference for worker 1157 is 1.287104
INFO:root:FL Epoch: 104 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1471
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561197
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539380
INFO:root:FL Epoch: 104 Norm Difference for worker 1471 is 1.153706
INFO:root:FL Epoch: 104 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :128
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.594930
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.560184
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 128 is 1.264464
INFO:root:FL Epoch: 104 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :66
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.583770
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.465305
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 66 is 1.157156
INFO:root:FL Epoch: 104 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :879
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462750
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542483
INFO:root:FL Epoch: 104 Norm Difference for worker 879 is 1.181538
INFO:root:FL Epoch: 104 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1042
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479769
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443499
INFO:root:FL Epoch: 104 Norm Difference for worker 1042 is 1.273608
INFO:root:FL Epoch: 104 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1632
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514304
INFO:root:Worker: 1632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432169
INFO:root:FL Epoch: 104 Norm Difference for worker 1632 is 1.189697
INFO:root:FL Epoch: 104 Done on worker:1632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :150
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 150 Train Epoch: 0 [0/201 (0%)]	Loss: 0.614502
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 150 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381286
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 150 is 1.18051
INFO:root:FL Epoch: 104 Done on worker:150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1712
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734989
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526339
INFO:root:FL Epoch: 104 Norm Difference for worker 1712 is 1.175836
INFO:root:FL Epoch: 104 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1712
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 104 Ends   ===================
INFO:root:Epoch:104 Global Model Test Loss:0.5631050011690926 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:104 Global Model Backdoor Test Loss:0.4500173479318619                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 105 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 105 Workers Selected : [1124, 766, 284, 1589, 1409, 1883, 833, 1441, 847, 1423]
INFO:root:FL Epoch: 105 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 105 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 105 Training on worker :1124
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.892700
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627610
INFO:root:FL Epoch: 105 Norm Difference for worker 1124 is 1.063486
INFO:root:FL Epoch: 105 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :766
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551615
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444881
INFO:root:FL Epoch: 105 Norm Difference for worker 766 is 1.061978
INFO:root:FL Epoch: 105 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :284
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.513627
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.665629
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 105 Norm Difference for worker 284 is 1.114847
INFO:root:FL Epoch: 105 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1589
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565132
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549516
INFO:root:FL Epoch: 105 Norm Difference for worker 1589 is 1.065019
INFO:root:FL Epoch: 105 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1409
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628512
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656351
INFO:root:FL Epoch: 105 Norm Difference for worker 1409 is 1.028328
INFO:root:FL Epoch: 105 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1883
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648517
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557825
INFO:root:FL Epoch: 105 Norm Difference for worker 1883 is 1.051659
INFO:root:FL Epoch: 105 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :833
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620438
INFO:root:Worker: 833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499787
INFO:root:FL Epoch: 105 Norm Difference for worker 833 is 1.069458
INFO:root:FL Epoch: 105 Done on worker:833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1441
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605223
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508979
INFO:root:FL Epoch: 105 Norm Difference for worker 1441 is 1.083402
INFO:root:FL Epoch: 105 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :847
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712205
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675363
INFO:root:FL Epoch: 105 Norm Difference for worker 847 is 1.05947
INFO:root:FL Epoch: 105 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1423
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580585
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560400
INFO:root:FL Epoch: 105 Norm Difference for worker 1423 is 1.066091
INFO:root:FL Epoch: 105 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1409
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 105 Ends   ===================
INFO:root:Epoch:105 Global Model Test Loss:0.5535616892225602 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:105 Global Model Backdoor Test Loss:0.5463669349749883                             and Backdoor Test Accuracy:71.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 106 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 106 Workers Selected : [534, 186, 452, 985, 1302, 1826, 274, 1833, 626, 1265]
INFO:root:FL Epoch: 106 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 106 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 106 Training on worker :534
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796350
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451029
INFO:root:FL Epoch: 106 Norm Difference for worker 534 is 1.019608
INFO:root:FL Epoch: 106 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :186
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 186 Train Epoch: 0 [0/201 (0%)]	Loss: 0.514893
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 186 Train Epoch: 1 [0/201 (0%)]	Loss: 0.503547
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 106 Norm Difference for worker 186 is 1.05641
INFO:root:FL Epoch: 106 Done on worker:186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :452
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586716
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473870
INFO:root:FL Epoch: 106 Norm Difference for worker 452 is 1.017997
INFO:root:FL Epoch: 106 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :985
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 985 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648081
INFO:root:Worker: 985 Train Epoch: 1 [0/200 (0%)]	Loss: 0.725049
INFO:root:FL Epoch: 106 Norm Difference for worker 985 is 1.017344
INFO:root:FL Epoch: 106 Done on worker:985
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1302
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1302 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662228
INFO:root:Worker: 1302 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582134
INFO:root:FL Epoch: 106 Norm Difference for worker 1302 is 1.015876
INFO:root:FL Epoch: 106 Done on worker:1302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1826
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754615
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444146
INFO:root:FL Epoch: 106 Norm Difference for worker 1826 is 0.985396
INFO:root:FL Epoch: 106 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :274
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.457634
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428927
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 106 Norm Difference for worker 274 is 0.995607
INFO:root:FL Epoch: 106 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1833
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439779
INFO:root:Worker: 1833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670770
INFO:root:FL Epoch: 106 Norm Difference for worker 1833 is 0.978606
INFO:root:FL Epoch: 106 Done on worker:1833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :626
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579095
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604681
INFO:root:FL Epoch: 106 Norm Difference for worker 626 is 0.994296
INFO:root:FL Epoch: 106 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1265
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697964
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603598
INFO:root:FL Epoch: 106 Norm Difference for worker 1265 is 1.011949
INFO:root:FL Epoch: 106 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1826
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 106 Ends   ===================
INFO:root:Epoch:106 Global Model Test Loss:0.5377712635432973 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:106 Global Model Backdoor Test Loss:0.5208165099223455                             and Backdoor Test Accuracy:70.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 107 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 107 Workers Selected : [1731, 1909, 1927, 1664, 392, 575, 1365, 308, 1329, 142]
INFO:root:FL Epoch: 107 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.1003996]
INFO:root:FL Epoch: 107 Num points on workers: [200 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 107 Training on worker :1731
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605252
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531667
INFO:root:FL Epoch: 107 Norm Difference for worker 1731 is 1.096995
INFO:root:FL Epoch: 107 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1909
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559486
INFO:root:Worker: 1909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464897
INFO:root:FL Epoch: 107 Norm Difference for worker 1909 is 1.156604
INFO:root:FL Epoch: 107 Done on worker:1909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1927
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372304
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503874
INFO:root:FL Epoch: 107 Norm Difference for worker 1927 is 1.133679
INFO:root:FL Epoch: 107 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1664
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492059
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636817
INFO:root:FL Epoch: 107 Norm Difference for worker 1664 is 1.129297
INFO:root:FL Epoch: 107 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :392
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572175
INFO:root:Worker: 392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534703
INFO:root:FL Epoch: 107 Norm Difference for worker 392 is 1.17002
INFO:root:FL Epoch: 107 Done on worker:392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :575
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674264
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524248
INFO:root:FL Epoch: 107 Norm Difference for worker 575 is 1.2332
INFO:root:FL Epoch: 107 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1365
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722350
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475269
INFO:root:FL Epoch: 107 Norm Difference for worker 1365 is 1.17372
INFO:root:FL Epoch: 107 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :308
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.628858
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.639124
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 107 Norm Difference for worker 308 is 1.172559
INFO:root:FL Epoch: 107 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1329
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733307
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435422
INFO:root:FL Epoch: 107 Norm Difference for worker 1329 is 1.098193
INFO:root:FL Epoch: 107 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :142
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 142 Train Epoch: 0 [0/201 (0%)]	Loss: 0.758168
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 142 Train Epoch: 1 [0/201 (0%)]	Loss: 0.514670
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 107 Norm Difference for worker 142 is 1.165227
INFO:root:FL Epoch: 107 Done on worker:142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1731
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 107 Ends   ===================
INFO:root:Epoch:107 Global Model Test Loss:0.534829697188209 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:107 Global Model Backdoor Test Loss:0.47547170023123425                             and Backdoor Test Accuracy:76.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 108 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 108 Workers Selected : [65, 163, 504, 120, 1859, 1651, 1272, 595, 487, 1181]
INFO:root:FL Epoch: 108 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 108 Num points on workers: [201 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 108 Training on worker :65
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.682234
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.583507
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 65 is 1.162173
INFO:root:FL Epoch: 108 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :163
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.612363
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.437525
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 163 is 1.151088
INFO:root:FL Epoch: 108 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :504
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462928
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481673
INFO:root:FL Epoch: 108 Norm Difference for worker 504 is 1.177246
INFO:root:FL Epoch: 108 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :120
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 120 Train Epoch: 0 [0/201 (0%)]	Loss: 0.630022
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 120 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419192
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 120 is 1.209199
INFO:root:FL Epoch: 108 Done on worker:120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1859
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550564
INFO:root:Worker: 1859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499405
INFO:root:FL Epoch: 108 Norm Difference for worker 1859 is 1.105961
INFO:root:FL Epoch: 108 Done on worker:1859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1651
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503945
INFO:root:Worker: 1651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.714112
INFO:root:FL Epoch: 108 Norm Difference for worker 1651 is 1.174212
INFO:root:FL Epoch: 108 Done on worker:1651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1272
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1272 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452540
INFO:root:Worker: 1272 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585624
INFO:root:FL Epoch: 108 Norm Difference for worker 1272 is 1.159889
INFO:root:FL Epoch: 108 Done on worker:1272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :595
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532959
INFO:root:Worker: 595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464918
INFO:root:FL Epoch: 108 Norm Difference for worker 595 is 1.117384
INFO:root:FL Epoch: 108 Done on worker:595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :487
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646634
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331380
INFO:root:FL Epoch: 108 Norm Difference for worker 487 is 1.135992
INFO:root:FL Epoch: 108 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1181
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599052
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434188
INFO:root:FL Epoch: 108 Norm Difference for worker 1181 is 1.12325
INFO:root:FL Epoch: 108 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 487
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 108 Ends   ===================
INFO:root:Epoch:108 Global Model Test Loss:0.5445784979006824 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:108 Global Model Backdoor Test Loss:0.5398324926694235                             and Backdoor Test Accuracy:71.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 109 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 109 Workers Selected : [659, 1630, 147, 1704, 1338, 376, 790, 1004, 1131, 172]
INFO:root:FL Epoch: 109 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 109 Num points on workers: [200 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 109 Training on worker :659
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744661
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662926
INFO:root:FL Epoch: 109 Norm Difference for worker 659 is 1.218235
INFO:root:FL Epoch: 109 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1630
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694222
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.749216
INFO:root:FL Epoch: 109 Norm Difference for worker 1630 is 1.267902
INFO:root:FL Epoch: 109 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :147
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.566589
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.555183
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 147 is 1.176679
INFO:root:FL Epoch: 109 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1704
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477592
INFO:root:Worker: 1704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428129
INFO:root:FL Epoch: 109 Norm Difference for worker 1704 is 1.229713
INFO:root:FL Epoch: 109 Done on worker:1704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1338
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600986
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571455
INFO:root:FL Epoch: 109 Norm Difference for worker 1338 is 1.128557
INFO:root:FL Epoch: 109 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :376
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.924993
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568943
INFO:root:FL Epoch: 109 Norm Difference for worker 376 is 1.221003
INFO:root:FL Epoch: 109 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :790
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729897
INFO:root:Worker: 790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411326
INFO:root:FL Epoch: 109 Norm Difference for worker 790 is 1.231445
INFO:root:FL Epoch: 109 Done on worker:790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1004
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1004 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711503
INFO:root:Worker: 1004 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632023
INFO:root:FL Epoch: 109 Norm Difference for worker 1004 is 1.24452
INFO:root:FL Epoch: 109 Done on worker:1004
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1131
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503858
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606206
INFO:root:FL Epoch: 109 Norm Difference for worker 1131 is 1.185511
INFO:root:FL Epoch: 109 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :172
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.579970
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.462137
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 172 is 1.2101
INFO:root:FL Epoch: 109 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1338
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 109 Ends   ===================
INFO:root:Epoch:109 Global Model Test Loss:0.5389329703415141 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:109 Global Model Backdoor Test Loss:0.5389546503623327                             and Backdoor Test Accuracy:71.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 110 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 110 Workers Selected : [191, 844, 1062, 1182, 1038, 791, 1015, 160, 803, 902]
INFO:root:FL Epoch: 110 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 110 Num points on workers: [201 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 110 Training on worker :191
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.522393
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.489959
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 191 is 1.134071
INFO:root:FL Epoch: 110 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :844
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618694
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468200
INFO:root:FL Epoch: 110 Norm Difference for worker 844 is 1.081595
INFO:root:FL Epoch: 110 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1062
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1062 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608029
INFO:root:Worker: 1062 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517594
INFO:root:FL Epoch: 110 Norm Difference for worker 1062 is 1.077457
INFO:root:FL Epoch: 110 Done on worker:1062
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1182
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425921
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586401
INFO:root:FL Epoch: 110 Norm Difference for worker 1182 is 1.042709
INFO:root:FL Epoch: 110 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1038
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1038 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645138
INFO:root:Worker: 1038 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492261
INFO:root:FL Epoch: 110 Norm Difference for worker 1038 is 1.127976
INFO:root:FL Epoch: 110 Done on worker:1038
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :791
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515070
INFO:root:Worker: 791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485985
INFO:root:FL Epoch: 110 Norm Difference for worker 791 is 1.062868
INFO:root:FL Epoch: 110 Done on worker:791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1015
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733862
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489777
INFO:root:FL Epoch: 110 Norm Difference for worker 1015 is 1.0729
INFO:root:FL Epoch: 110 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :160
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.501300
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.469427
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 160 is 1.128996
INFO:root:FL Epoch: 110 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :803
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454055
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634054
INFO:root:FL Epoch: 110 Norm Difference for worker 803 is 1.145467
INFO:root:FL Epoch: 110 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :902
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337703
INFO:root:Worker: 902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425664
INFO:root:FL Epoch: 110 Norm Difference for worker 902 is 1.111634
INFO:root:FL Epoch: 110 Done on worker:902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1182
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 110 Ends   ===================
INFO:root:Epoch:110 Global Model Test Loss:0.5563570962232702 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:110 Global Model Backdoor Test Loss:0.6098320583502451                             and Backdoor Test Accuracy:65.0 
INFO:root:=======================================================
INFO:root:================FL round 111 Begins ===================
INFO:root:FL Epoch: 111 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 111 Workers Selected : [0, 1, 2, 212, 603, 1485, 1334, 260, 1352, 1619]
INFO:root:FL Epoch: 111 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 111 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 111 Training on worker :0
INFO:root:FL Epoch: 111 Using Learning rate : 0.00802342027539165 
INFO:root:FL Epoch: 111 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426693
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446102
INFO:root:FL Epoch: 111 Worker: 0 Backdoor Test Loss: 0.3060463195045789 Backdoor Test Accuracy: 90.0
INFO:root:FL Epoch: 111 Worker: 0 Backdoor Train Loss: 0.39269617199897766 Backdoor Train Accuracy: 84.5
INFO:root:FL Epoch: 111 Norm Difference for worker 0 is 0.327841
INFO:root:FL Epoch: 111 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1
INFO:root:FL Epoch: 111 Using Learning rate : 0.00802342027539165 
INFO:root:FL Epoch: 111 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599821
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458613
INFO:root:FL Epoch: 111 Worker: 1 Backdoor Test Loss: 0.31653493146101636 Backdoor Test Accuracy: 88.33333333333333
INFO:root:FL Epoch: 111 Worker: 1 Backdoor Train Loss: 0.39100836366415026 Backdoor Train Accuracy: 84.5
INFO:root:FL Epoch: 111 Norm Difference for worker 1 is 0.317829
INFO:root:FL Epoch: 111 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :2
INFO:root:FL Epoch: 111 Using Learning rate : 0.00802342027539165 
INFO:root:FL Epoch: 111 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466828
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517439
INFO:root:FL Epoch: 111 Worker: 2 Backdoor Test Loss: 0.3392587552467982 Backdoor Test Accuracy: 86.66666666666667
INFO:root:FL Epoch: 111 Worker: 2 Backdoor Train Loss: 0.38822962045669557 Backdoor Train Accuracy: 85.0
INFO:root:FL Epoch: 111 Norm Difference for worker 2 is 0.315633
INFO:root:FL Epoch: 111 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :212
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.246364
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.400895
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 212 is 1.181145
INFO:root:FL Epoch: 111 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :603
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590430
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533100
INFO:root:FL Epoch: 111 Norm Difference for worker 603 is 1.178539
INFO:root:FL Epoch: 111 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1485
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392794
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.716359
INFO:root:FL Epoch: 111 Norm Difference for worker 1485 is 1.124947
INFO:root:FL Epoch: 111 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1334
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574937
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670758
INFO:root:FL Epoch: 111 Norm Difference for worker 1334 is 1.112282
INFO:root:FL Epoch: 111 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :260
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.548362
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.497721
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 260 is 1.111521
INFO:root:FL Epoch: 111 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1352
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599692
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540809
INFO:root:FL Epoch: 111 Norm Difference for worker 1352 is 1.231335
INFO:root:FL Epoch: 111 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1619
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778406
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697816
INFO:root:FL Epoch: 111 Norm Difference for worker 1619 is 1.123511
INFO:root:FL Epoch: 111 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 111 Ends   ===================
INFO:root:Epoch:111 Global Model Test Loss:0.5485773612471188 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:111 Global Model Backdoor Test Loss:0.3392587552467982                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 112 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 112 Workers Selected : [254, 253, 267, 1281, 552, 1889, 1555, 1475, 334, 202]
INFO:root:FL Epoch: 112 Fraction of points on each worker in this round: [0.10024938 0.10024938 0.10024938 0.09975062 0.09975062 0.09975062
 0.09975062 0.09975062 0.10024938 0.10024938]
INFO:root:FL Epoch: 112 Num points on workers: [201 201 201 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 112 Training on worker :254
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 254 Train Epoch: 0 [0/201 (0%)]	Loss: 0.720585
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 254 Train Epoch: 1 [0/201 (0%)]	Loss: 0.400605
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 254 is 1.163863
INFO:root:FL Epoch: 112 Done on worker:254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :253
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.582942
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.426042
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 253 is 1.170564
INFO:root:FL Epoch: 112 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :267
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 267 Train Epoch: 0 [0/201 (0%)]	Loss: 0.776993
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 267 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436277
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 267 is 1.164752
INFO:root:FL Epoch: 112 Done on worker:267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1281
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1281 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503080
INFO:root:Worker: 1281 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434647
INFO:root:FL Epoch: 112 Norm Difference for worker 1281 is 1.165967
INFO:root:FL Epoch: 112 Done on worker:1281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :552
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597744
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599245
INFO:root:FL Epoch: 112 Norm Difference for worker 552 is 1.222285
INFO:root:FL Epoch: 112 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1889
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449997
INFO:root:Worker: 1889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.718079
INFO:root:FL Epoch: 112 Norm Difference for worker 1889 is 1.212479
INFO:root:FL Epoch: 112 Done on worker:1889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1555
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420328
INFO:root:Worker: 1555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550057
INFO:root:FL Epoch: 112 Norm Difference for worker 1555 is 1.142466
INFO:root:FL Epoch: 112 Done on worker:1555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1475
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683150
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488990
INFO:root:FL Epoch: 112 Norm Difference for worker 1475 is 1.280572
INFO:root:FL Epoch: 112 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :334
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.520305
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.353856
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 334 is 1.223943
INFO:root:FL Epoch: 112 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :202
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490538
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.498249
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 202 is 1.233121
INFO:root:FL Epoch: 112 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 254
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 112 Ends   ===================
INFO:root:Epoch:112 Global Model Test Loss:0.5778131888193243 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:112 Global Model Backdoor Test Loss:0.41668377816677094                             and Backdoor Test Accuracy:80.0 
INFO:root:=======================================================
INFO:root:================FL round 113 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 113 Workers Selected : [173, 1677, 1063, 828, 1243, 1645, 701, 511, 1769, 539]
INFO:root:FL Epoch: 113 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 113 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 113 Training on worker :173
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.590231
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.346983
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 113 Norm Difference for worker 173 is 1.023785
INFO:root:FL Epoch: 113 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1677
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554858
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659178
INFO:root:FL Epoch: 113 Norm Difference for worker 1677 is 0.969259
INFO:root:FL Epoch: 113 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1063
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566042
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537776
INFO:root:FL Epoch: 113 Norm Difference for worker 1063 is 1.047015
INFO:root:FL Epoch: 113 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :828
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721907
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483418
INFO:root:FL Epoch: 113 Norm Difference for worker 828 is 1.065162
INFO:root:FL Epoch: 113 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1243
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700633
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625713
INFO:root:FL Epoch: 113 Norm Difference for worker 1243 is 1.048237
INFO:root:FL Epoch: 113 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1645
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587292
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537296
INFO:root:FL Epoch: 113 Norm Difference for worker 1645 is 0.947199
INFO:root:FL Epoch: 113 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :701
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548352
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531045
INFO:root:FL Epoch: 113 Norm Difference for worker 701 is 1.017418
INFO:root:FL Epoch: 113 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :511
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644695
INFO:root:Worker: 511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454823
INFO:root:FL Epoch: 113 Norm Difference for worker 511 is 1.013224
INFO:root:FL Epoch: 113 Done on worker:511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1769
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607757
INFO:root:Worker: 1769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551021
INFO:root:FL Epoch: 113 Norm Difference for worker 1769 is 1.020335
INFO:root:FL Epoch: 113 Done on worker:1769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :539
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679653
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594094
INFO:root:FL Epoch: 113 Norm Difference for worker 539 is 1.00052
INFO:root:FL Epoch: 113 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1677
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 113 Ends   ===================
INFO:root:Epoch:113 Global Model Test Loss:0.5820064194062177 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:113 Global Model Backdoor Test Loss:0.4857018490632375                             and Backdoor Test Accuracy:75.0 
INFO:root:=======================================================
INFO:root:================FL round 114 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 114 Workers Selected : [1682, 817, 747, 1065, 615, 439, 501, 1941, 729, 1621]
INFO:root:FL Epoch: 114 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 114 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 114 Training on worker :1682
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611764
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539492
INFO:root:FL Epoch: 114 Norm Difference for worker 1682 is 1.057376
INFO:root:FL Epoch: 114 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :817
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692652
INFO:root:Worker: 817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448244
INFO:root:FL Epoch: 114 Norm Difference for worker 817 is 1.051058
INFO:root:FL Epoch: 114 Done on worker:817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :747
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492068
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466284
INFO:root:FL Epoch: 114 Norm Difference for worker 747 is 1.045701
INFO:root:FL Epoch: 114 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1065
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514283
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520856
INFO:root:FL Epoch: 114 Norm Difference for worker 1065 is 1.126985
INFO:root:FL Epoch: 114 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :615
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 615 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710583
INFO:root:Worker: 615 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423681
INFO:root:FL Epoch: 114 Norm Difference for worker 615 is 1.028436
INFO:root:FL Epoch: 114 Done on worker:615
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :439
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739971
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490658
INFO:root:FL Epoch: 114 Norm Difference for worker 439 is 1.041764
INFO:root:FL Epoch: 114 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :501
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596178
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546260
INFO:root:FL Epoch: 114 Norm Difference for worker 501 is 1.056707
INFO:root:FL Epoch: 114 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1941
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680241
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686876
INFO:root:FL Epoch: 114 Norm Difference for worker 1941 is 1.011473
INFO:root:FL Epoch: 114 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :729
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671246
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579210
INFO:root:FL Epoch: 114 Norm Difference for worker 729 is 1.077694
INFO:root:FL Epoch: 114 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1621
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648485
INFO:root:Worker: 1621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556494
INFO:root:FL Epoch: 114 Norm Difference for worker 1621 is 1.030828
INFO:root:FL Epoch: 114 Done on worker:1621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 747
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 114 Ends   ===================
INFO:root:Epoch:114 Global Model Test Loss:0.5850512578206903 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:114 Global Model Backdoor Test Loss:0.4581172466278076                             and Backdoor Test Accuracy:78.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 115 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 115 Workers Selected : [1247, 1891, 1092, 1160, 1542, 1248, 1758, 206, 881, 1311]
INFO:root:FL Epoch: 115 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 115 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 115 Training on worker :1247
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573767
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581383
INFO:root:FL Epoch: 115 Norm Difference for worker 1247 is 1.125799
INFO:root:FL Epoch: 115 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1891
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616108
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522493
INFO:root:FL Epoch: 115 Norm Difference for worker 1891 is 1.082276
INFO:root:FL Epoch: 115 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1092
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636655
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552494
INFO:root:FL Epoch: 115 Norm Difference for worker 1092 is 1.126759
INFO:root:FL Epoch: 115 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1160
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1160 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587531
INFO:root:Worker: 1160 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576599
INFO:root:FL Epoch: 115 Norm Difference for worker 1160 is 1.212168
INFO:root:FL Epoch: 115 Done on worker:1160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1542
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466004
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676241
INFO:root:FL Epoch: 115 Norm Difference for worker 1542 is 1.140923
INFO:root:FL Epoch: 115 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1248
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708590
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553962
INFO:root:FL Epoch: 115 Norm Difference for worker 1248 is 1.050913
INFO:root:FL Epoch: 115 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1758
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.918443
INFO:root:Worker: 1758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625658
INFO:root:FL Epoch: 115 Norm Difference for worker 1758 is 1.046825
INFO:root:FL Epoch: 115 Done on worker:1758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :206
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.582053
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.500310
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 115 Norm Difference for worker 206 is 1.093975
INFO:root:FL Epoch: 115 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :881
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554062
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398164
INFO:root:FL Epoch: 115 Norm Difference for worker 881 is 1.13358
INFO:root:FL Epoch: 115 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1311
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592279
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617534
INFO:root:FL Epoch: 115 Norm Difference for worker 1311 is 1.128639
INFO:root:FL Epoch: 115 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1758
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 115 Ends   ===================
INFO:root:Epoch:115 Global Model Test Loss:0.5900181005982792 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:115 Global Model Backdoor Test Loss:0.5072103639443716                             and Backdoor Test Accuracy:74.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 116 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 116 Workers Selected : [670, 77, 14, 831, 557, 1196, 1519, 237, 1512, 592]
INFO:root:FL Epoch: 116 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 116 Num points on workers: [200 201 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 116 Training on worker :670
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716203
INFO:root:Worker: 670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497963
INFO:root:FL Epoch: 116 Norm Difference for worker 670 is 1.065352
INFO:root:FL Epoch: 116 Done on worker:670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :77
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.711925
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.493844
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 77 is 1.09069
INFO:root:FL Epoch: 116 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :14
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.488854
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.535911
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 14 is 0.979679
INFO:root:FL Epoch: 116 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :831
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434342
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526259
INFO:root:FL Epoch: 116 Norm Difference for worker 831 is 1.122107
INFO:root:FL Epoch: 116 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :557
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475409
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576644
INFO:root:FL Epoch: 116 Norm Difference for worker 557 is 1.029864
INFO:root:FL Epoch: 116 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1196
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1196 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706275
INFO:root:Worker: 1196 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658809
INFO:root:FL Epoch: 116 Norm Difference for worker 1196 is 1.038453
INFO:root:FL Epoch: 116 Done on worker:1196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1519
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539916
INFO:root:Worker: 1519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587732
INFO:root:FL Epoch: 116 Norm Difference for worker 1519 is 0.96614
INFO:root:FL Epoch: 116 Done on worker:1519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :237
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 237 Train Epoch: 0 [0/201 (0%)]	Loss: 0.542208
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 237 Train Epoch: 1 [0/201 (0%)]	Loss: 0.467766
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 237 is 1.01804
INFO:root:FL Epoch: 116 Done on worker:237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1512
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525531
INFO:root:Worker: 1512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533954
INFO:root:FL Epoch: 116 Norm Difference for worker 1512 is 1.180092
INFO:root:FL Epoch: 116 Done on worker:1512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :592
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.791834
INFO:root:Worker: 592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550613
INFO:root:FL Epoch: 116 Norm Difference for worker 592 is 1.071733
INFO:root:FL Epoch: 116 Done on worker:592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1519
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 116 Ends   ===================
INFO:root:Epoch:116 Global Model Test Loss:0.5826336758978227 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:116 Global Model Backdoor Test Loss:0.48875493307908374                             and Backdoor Test Accuracy:80.0 
INFO:root:=======================================================
INFO:root:================FL round 117 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 117 Workers Selected : [300, 251, 562, 1356, 204, 809, 968, 1645, 1482, 844]
INFO:root:FL Epoch: 117 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 117 Num points on workers: [201 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 117 Training on worker :300
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.520619
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.549575
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 300 is 0.939664
INFO:root:FL Epoch: 117 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :251
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 251 Train Epoch: 0 [0/201 (0%)]	Loss: 0.496736
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 251 Train Epoch: 1 [0/201 (0%)]	Loss: 0.506907
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 251 is 0.973804
INFO:root:FL Epoch: 117 Done on worker:251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :562
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596577
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523717
INFO:root:FL Epoch: 117 Norm Difference for worker 562 is 1.015795
INFO:root:FL Epoch: 117 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1356
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667351
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581544
INFO:root:FL Epoch: 117 Norm Difference for worker 1356 is 0.974047
INFO:root:FL Epoch: 117 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :204
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.645702
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.559693
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 204 is 1.004664
INFO:root:FL Epoch: 117 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :809
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642149
INFO:root:Worker: 809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613951
INFO:root:FL Epoch: 117 Norm Difference for worker 809 is 0.91789
INFO:root:FL Epoch: 117 Done on worker:809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :968
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549413
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693763
INFO:root:FL Epoch: 117 Norm Difference for worker 968 is 1.005804
INFO:root:FL Epoch: 117 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1645
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660342
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505463
INFO:root:FL Epoch: 117 Norm Difference for worker 1645 is 0.954752
INFO:root:FL Epoch: 117 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1482
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611173
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590878
INFO:root:FL Epoch: 117 Norm Difference for worker 1482 is 0.942524
INFO:root:FL Epoch: 117 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :844
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499366
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564254
INFO:root:FL Epoch: 117 Norm Difference for worker 844 is 0.976439
INFO:root:FL Epoch: 117 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 809
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 117 Ends   ===================
INFO:root:Epoch:117 Global Model Test Loss:0.5854645985014298 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:117 Global Model Backdoor Test Loss:0.5662380158901215                             and Backdoor Test Accuracy:70.0 
INFO:root:=======================================================
INFO:root:================FL round 118 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 118 Workers Selected : [191, 1890, 999, 1404, 725, 1853, 1315, 1082, 862, 84]
INFO:root:FL Epoch: 118 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 118 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 118 Training on worker :191
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.546471
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.484499
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 118 Norm Difference for worker 191 is 1.096916
INFO:root:FL Epoch: 118 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1890
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655490
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669264
INFO:root:FL Epoch: 118 Norm Difference for worker 1890 is 0.948278
INFO:root:FL Epoch: 118 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :999
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704923
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611870
INFO:root:FL Epoch: 118 Norm Difference for worker 999 is 0.983546
INFO:root:FL Epoch: 118 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1404
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420078
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456788
INFO:root:FL Epoch: 118 Norm Difference for worker 1404 is 1.007398
INFO:root:FL Epoch: 118 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :725
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466770
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610333
INFO:root:FL Epoch: 118 Norm Difference for worker 725 is 1.000258
INFO:root:FL Epoch: 118 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1853
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604225
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533629
INFO:root:FL Epoch: 118 Norm Difference for worker 1853 is 1.012177
INFO:root:FL Epoch: 118 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1315
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565515
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404524
INFO:root:FL Epoch: 118 Norm Difference for worker 1315 is 0.989959
INFO:root:FL Epoch: 118 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1082
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492206
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526049
INFO:root:FL Epoch: 118 Norm Difference for worker 1082 is 1.017151
INFO:root:FL Epoch: 118 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :862
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597198
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578896
INFO:root:FL Epoch: 118 Norm Difference for worker 862 is 1.027671
INFO:root:FL Epoch: 118 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :84
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 84 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593779
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 84 Train Epoch: 1 [0/201 (0%)]	Loss: 0.582098
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 118 Norm Difference for worker 84 is 1.000137
INFO:root:FL Epoch: 118 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1082
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 118 Ends   ===================
INFO:root:Epoch:118 Global Model Test Loss:0.5676349524189445 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:118 Global Model Backdoor Test Loss:0.5328195293744405                             and Backdoor Test Accuracy:73.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 119 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 119 Workers Selected : [917, 474, 748, 1071, 436, 1413, 141, 439, 281, 1415]
INFO:root:FL Epoch: 119 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 119 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 119 Training on worker :917
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519832
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579689
INFO:root:FL Epoch: 119 Norm Difference for worker 917 is 1.115299
INFO:root:FL Epoch: 119 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :474
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442176
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540922
INFO:root:FL Epoch: 119 Norm Difference for worker 474 is 1.076586
INFO:root:FL Epoch: 119 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :748
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583726
INFO:root:Worker: 748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.892860
INFO:root:FL Epoch: 119 Norm Difference for worker 748 is 1.095929
INFO:root:FL Epoch: 119 Done on worker:748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1071
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1071 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530618
INFO:root:Worker: 1071 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435499
INFO:root:FL Epoch: 119 Norm Difference for worker 1071 is 1.090856
INFO:root:FL Epoch: 119 Done on worker:1071
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :436
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610631
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613722
INFO:root:FL Epoch: 119 Norm Difference for worker 436 is 1.056896
INFO:root:FL Epoch: 119 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1413
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648234
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530222
INFO:root:FL Epoch: 119 Norm Difference for worker 1413 is 1.125293
INFO:root:FL Epoch: 119 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :141
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.656391
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.605447
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 119 Norm Difference for worker 141 is 1.038748
INFO:root:FL Epoch: 119 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :439
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.877203
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588511
INFO:root:FL Epoch: 119 Norm Difference for worker 439 is 1.093201
INFO:root:FL Epoch: 119 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :281
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 281 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593389
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 281 Train Epoch: 1 [0/201 (0%)]	Loss: 0.521085
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 119 Norm Difference for worker 281 is 1.041437
INFO:root:FL Epoch: 119 Done on worker:281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1415
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633664
INFO:root:Worker: 1415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636194
INFO:root:FL Epoch: 119 Norm Difference for worker 1415 is 1.077286
INFO:root:FL Epoch: 119 Done on worker:1415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 141
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 119 Ends   ===================
INFO:root:Epoch:119 Global Model Test Loss:0.5526732364121605 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:119 Global Model Backdoor Test Loss:0.3941282133261363                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 120 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 120 Workers Selected : [672, 1130, 89, 766, 604, 1934, 1085, 1785, 799, 394]
INFO:root:FL Epoch: 120 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 120 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 120 Training on worker :672
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.870116
INFO:root:Worker: 672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612543
INFO:root:FL Epoch: 120 Norm Difference for worker 672 is 1.189872
INFO:root:FL Epoch: 120 Done on worker:672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1130
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1130 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569534
INFO:root:Worker: 1130 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573063
INFO:root:FL Epoch: 120 Norm Difference for worker 1130 is 1.159042
INFO:root:FL Epoch: 120 Done on worker:1130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :89
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 89 Train Epoch: 0 [0/201 (0%)]	Loss: 0.429610
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 89 Train Epoch: 1 [0/201 (0%)]	Loss: 0.592829
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 120 Norm Difference for worker 89 is 1.17077
INFO:root:FL Epoch: 120 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :766
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415347
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284398
INFO:root:FL Epoch: 120 Norm Difference for worker 766 is 1.121377
INFO:root:FL Epoch: 120 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :604
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591483
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487879
INFO:root:FL Epoch: 120 Norm Difference for worker 604 is 1.207178
INFO:root:FL Epoch: 120 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1934
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681089
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566157
INFO:root:FL Epoch: 120 Norm Difference for worker 1934 is 1.166565
INFO:root:FL Epoch: 120 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1085
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537936
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618264
INFO:root:FL Epoch: 120 Norm Difference for worker 1085 is 1.16132
INFO:root:FL Epoch: 120 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1785
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709863
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585908
INFO:root:FL Epoch: 120 Norm Difference for worker 1785 is 1.1357
INFO:root:FL Epoch: 120 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :799
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332571
INFO:root:Worker: 799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587873
INFO:root:FL Epoch: 120 Norm Difference for worker 799 is 1.1743
INFO:root:FL Epoch: 120 Done on worker:799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :394
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584829
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522980
INFO:root:FL Epoch: 120 Norm Difference for worker 394 is 1.229508
INFO:root:FL Epoch: 120 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 89
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 120 Ends   ===================
INFO:root:Epoch:120 Global Model Test Loss:0.5602703988552094 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:120 Global Model Backdoor Test Loss:0.34089627861976624                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 121 Begins ===================
INFO:root:FL Epoch: 121 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 121 Workers Selected : [0, 1, 2, 1516, 1691, 1534, 1245, 1693, 520, 996]
INFO:root:FL Epoch: 121 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 121 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 121 Training on worker :0
INFO:root:FL Epoch: 121 Using Learning rate : 0.007864388409944021 
INFO:root:FL Epoch: 121 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445911
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470759
INFO:root:FL Epoch: 121 Worker: 0 Backdoor Test Loss: 0.2648953050374985 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 121 Worker: 0 Backdoor Train Loss: 0.37223235368728635 Backdoor Train Accuracy: 86.0
INFO:root:FL Epoch: 121 Norm Difference for worker 0 is 0.256103
INFO:root:FL Epoch: 121 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1
INFO:root:FL Epoch: 121 Using Learning rate : 0.007864388409944021 
INFO:root:FL Epoch: 121 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536962
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303253
INFO:root:FL Epoch: 121 Worker: 1 Backdoor Test Loss: 0.27434493601322174 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 121 Worker: 1 Backdoor Train Loss: 0.3699418842792511 Backdoor Train Accuracy: 86.5
INFO:root:FL Epoch: 121 Norm Difference for worker 1 is 0.267552
INFO:root:FL Epoch: 121 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :2
INFO:root:FL Epoch: 121 Using Learning rate : 0.007864388409944021 
INFO:root:FL Epoch: 121 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427570
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345246
INFO:root:FL Epoch: 121 Worker: 2 Backdoor Test Loss: 0.26584915071725845 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 121 Worker: 2 Backdoor Train Loss: 0.37129213809967043 Backdoor Train Accuracy: 85.5
INFO:root:FL Epoch: 121 Norm Difference for worker 2 is 0.260329
INFO:root:FL Epoch: 121 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1516
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808059
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691791
INFO:root:FL Epoch: 121 Norm Difference for worker 1516 is 1.020802
INFO:root:FL Epoch: 121 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1691
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1691 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570836
INFO:root:Worker: 1691 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486008
INFO:root:FL Epoch: 121 Norm Difference for worker 1691 is 1.074511
INFO:root:FL Epoch: 121 Done on worker:1691
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1534
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677441
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407410
INFO:root:FL Epoch: 121 Norm Difference for worker 1534 is 1.124963
INFO:root:FL Epoch: 121 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1245
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1245 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612166
INFO:root:Worker: 1245 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407958
INFO:root:FL Epoch: 121 Norm Difference for worker 1245 is 1.059212
INFO:root:FL Epoch: 121 Done on worker:1245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1693
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691264
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413588
INFO:root:FL Epoch: 121 Norm Difference for worker 1693 is 1.041495
INFO:root:FL Epoch: 121 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :520
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679291
INFO:root:Worker: 520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502295
INFO:root:FL Epoch: 121 Norm Difference for worker 520 is 1.010801
INFO:root:FL Epoch: 121 Done on worker:520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :996
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755015
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544756
INFO:root:FL Epoch: 121 Norm Difference for worker 996 is 1.090147
INFO:root:FL Epoch: 121 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 121 Ends   ===================
INFO:root:Epoch:121 Global Model Test Loss:0.5574187653906205 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:121 Global Model Backdoor Test Loss:0.26584915071725845                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 122 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 122 Workers Selected : [847, 302, 1156, 1187, 252, 460, 1246, 151, 556, 1367]
INFO:root:FL Epoch: 122 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 122 Num points on workers: [200 201 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 122 Training on worker :847
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692955
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431892
INFO:root:FL Epoch: 122 Norm Difference for worker 847 is 1.179508
INFO:root:FL Epoch: 122 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :302
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 302 Train Epoch: 0 [0/201 (0%)]	Loss: 0.505243
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 302 Train Epoch: 1 [0/201 (0%)]	Loss: 0.501050
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 302 is 1.079079
INFO:root:FL Epoch: 122 Done on worker:302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1156
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730991
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530373
INFO:root:FL Epoch: 122 Norm Difference for worker 1156 is 1.116089
INFO:root:FL Epoch: 122 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1187
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1187 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711844
INFO:root:Worker: 1187 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493884
INFO:root:FL Epoch: 122 Norm Difference for worker 1187 is 1.078471
INFO:root:FL Epoch: 122 Done on worker:1187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :252
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676779
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.454762
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 252 is 1.134529
INFO:root:FL Epoch: 122 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :460
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534672
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612673
INFO:root:FL Epoch: 122 Norm Difference for worker 460 is 1.147044
INFO:root:FL Epoch: 122 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1246
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1246 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669326
INFO:root:Worker: 1246 Train Epoch: 1 [0/200 (0%)]	Loss: 0.736088
INFO:root:FL Epoch: 122 Norm Difference for worker 1246 is 1.132115
INFO:root:FL Epoch: 122 Done on worker:1246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :151
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595101
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.501356
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 151 is 1.191872
INFO:root:FL Epoch: 122 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :556
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721351
INFO:root:Worker: 556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697464
INFO:root:FL Epoch: 122 Norm Difference for worker 556 is 1.181523
INFO:root:FL Epoch: 122 Done on worker:556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1367
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545620
INFO:root:Worker: 1367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556172
INFO:root:FL Epoch: 122 Norm Difference for worker 1367 is 1.203912
INFO:root:FL Epoch: 122 Done on worker:1367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 302
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 122 Ends   ===================
INFO:root:Epoch:122 Global Model Test Loss:0.5671784492099986 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:122 Global Model Backdoor Test Loss:0.30219310025374096                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 123 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 123 Workers Selected : [900, 614, 1916, 1149, 1225, 315, 66, 959, 938, 1349]
INFO:root:FL Epoch: 123 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 123 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 123 Training on worker :900
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.777786
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623015
INFO:root:FL Epoch: 123 Norm Difference for worker 900 is 1.222297
INFO:root:FL Epoch: 123 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :614
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431021
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465523
INFO:root:FL Epoch: 123 Norm Difference for worker 614 is 1.17254
INFO:root:FL Epoch: 123 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1916
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608908
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399200
INFO:root:FL Epoch: 123 Norm Difference for worker 1916 is 1.171301
INFO:root:FL Epoch: 123 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1149
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584203
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638830
INFO:root:FL Epoch: 123 Norm Difference for worker 1149 is 1.267008
INFO:root:FL Epoch: 123 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1225
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1225 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774662
INFO:root:Worker: 1225 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524022
INFO:root:FL Epoch: 123 Norm Difference for worker 1225 is 1.122603
INFO:root:FL Epoch: 123 Done on worker:1225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :315
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.631323
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.437809
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 315 is 1.10861
INFO:root:FL Epoch: 123 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :66
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.614023
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.596927
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 66 is 1.135015
INFO:root:FL Epoch: 123 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :959
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375028
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525043
INFO:root:FL Epoch: 123 Norm Difference for worker 959 is 1.222245
INFO:root:FL Epoch: 123 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :938
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521667
INFO:root:Worker: 938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552591
INFO:root:FL Epoch: 123 Norm Difference for worker 938 is 1.159672
INFO:root:FL Epoch: 123 Done on worker:938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1349
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650892
INFO:root:Worker: 1349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540142
INFO:root:FL Epoch: 123 Norm Difference for worker 1349 is 1.125977
INFO:root:FL Epoch: 123 Done on worker:1349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 66
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 123 Ends   ===================
INFO:root:Epoch:123 Global Model Test Loss:0.5954223660861745 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:123 Global Model Backdoor Test Loss:0.4665359208981196                             and Backdoor Test Accuracy:76.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 124 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 124 Workers Selected : [1329, 1737, 570, 1802, 1438, 725, 394, 456, 1801, 1221]
INFO:root:FL Epoch: 124 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 124 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 124 Training on worker :1329
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433575
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561675
INFO:root:FL Epoch: 124 Norm Difference for worker 1329 is 1.085897
INFO:root:FL Epoch: 124 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1737
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524985
INFO:root:Worker: 1737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581382
INFO:root:FL Epoch: 124 Norm Difference for worker 1737 is 1.139803
INFO:root:FL Epoch: 124 Done on worker:1737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :570
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422475
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281255
INFO:root:FL Epoch: 124 Norm Difference for worker 570 is 1.06158
INFO:root:FL Epoch: 124 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1802
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662487
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545634
INFO:root:FL Epoch: 124 Norm Difference for worker 1802 is 1.262426
INFO:root:FL Epoch: 124 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1438
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.848788
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560909
INFO:root:FL Epoch: 124 Norm Difference for worker 1438 is 1.126957
INFO:root:FL Epoch: 124 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :725
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408513
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514726
INFO:root:FL Epoch: 124 Norm Difference for worker 725 is 1.073818
INFO:root:FL Epoch: 124 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :394
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616787
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571405
INFO:root:FL Epoch: 124 Norm Difference for worker 394 is 1.154465
INFO:root:FL Epoch: 124 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :456
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479198
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383941
INFO:root:FL Epoch: 124 Norm Difference for worker 456 is 1.195235
INFO:root:FL Epoch: 124 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1801
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575354
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580906
INFO:root:FL Epoch: 124 Norm Difference for worker 1801 is 1.159251
INFO:root:FL Epoch: 124 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1221
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1221 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748779
INFO:root:Worker: 1221 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602039
INFO:root:FL Epoch: 124 Norm Difference for worker 1221 is 1.101385
INFO:root:FL Epoch: 124 Done on worker:1221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 570
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 124 Ends   ===================
INFO:root:Epoch:124 Global Model Test Loss:0.5517625458100263 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:124 Global Model Backdoor Test Loss:0.3804638733466466                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 125 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 125 Workers Selected : [371, 455, 747, 106, 1722, 631, 374, 1617, 513, 1270]
INFO:root:FL Epoch: 125 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 125 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 125 Training on worker :371
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674724
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369623
INFO:root:FL Epoch: 125 Norm Difference for worker 371 is 1.199702
INFO:root:FL Epoch: 125 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :455
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653163
INFO:root:Worker: 455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521978
INFO:root:FL Epoch: 125 Norm Difference for worker 455 is 1.348573
INFO:root:FL Epoch: 125 Done on worker:455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :747
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524409
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377265
INFO:root:FL Epoch: 125 Norm Difference for worker 747 is 1.225563
INFO:root:FL Epoch: 125 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :106
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.618374
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.412851
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 125 Norm Difference for worker 106 is 1.290895
INFO:root:FL Epoch: 125 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1722
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780878
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473953
INFO:root:FL Epoch: 125 Norm Difference for worker 1722 is 1.23019
INFO:root:FL Epoch: 125 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :631
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633515
INFO:root:Worker: 631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594732
INFO:root:FL Epoch: 125 Norm Difference for worker 631 is 1.256947
INFO:root:FL Epoch: 125 Done on worker:631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :374
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478199
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649114
INFO:root:FL Epoch: 125 Norm Difference for worker 374 is 1.226761
INFO:root:FL Epoch: 125 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1617
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624504
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637417
INFO:root:FL Epoch: 125 Norm Difference for worker 1617 is 1.312673
INFO:root:FL Epoch: 125 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :513
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548227
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558113
INFO:root:FL Epoch: 125 Norm Difference for worker 513 is 1.204453
INFO:root:FL Epoch: 125 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1270
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.849549
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.748223
INFO:root:FL Epoch: 125 Norm Difference for worker 1270 is 1.168364
INFO:root:FL Epoch: 125 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1270
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 125 Ends   ===================
INFO:root:Epoch:125 Global Model Test Loss:0.5721466085490059 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:125 Global Model Backdoor Test Loss:0.3952777832746506                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 126 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 126 Workers Selected : [1262, 808, 93, 1323, 1090, 844, 915, 433, 605, 416]
INFO:root:FL Epoch: 126 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 126 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 126 Training on worker :1262
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1262 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597785
INFO:root:Worker: 1262 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539658
INFO:root:FL Epoch: 126 Norm Difference for worker 1262 is 1.117489
INFO:root:FL Epoch: 126 Done on worker:1262
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :808
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547387
INFO:root:Worker: 808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388997
INFO:root:FL Epoch: 126 Norm Difference for worker 808 is 1.104958
INFO:root:FL Epoch: 126 Done on worker:808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :93
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 93 Train Epoch: 0 [0/201 (0%)]	Loss: 0.630348
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 93 Train Epoch: 1 [0/201 (0%)]	Loss: 0.363716
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 126 Norm Difference for worker 93 is 1.091513
INFO:root:FL Epoch: 126 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1323
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1323 Train Epoch: 0 [0/200 (0%)]	Loss: 0.795540
INFO:root:Worker: 1323 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660594
INFO:root:FL Epoch: 126 Norm Difference for worker 1323 is 1.133269
INFO:root:FL Epoch: 126 Done on worker:1323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1090
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489737
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366477
INFO:root:FL Epoch: 126 Norm Difference for worker 1090 is 1.074497
INFO:root:FL Epoch: 126 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :844
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583097
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574218
INFO:root:FL Epoch: 126 Norm Difference for worker 844 is 1.109069
INFO:root:FL Epoch: 126 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :915
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616908
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625151
INFO:root:FL Epoch: 126 Norm Difference for worker 915 is 1.085198
INFO:root:FL Epoch: 126 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :433
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667340
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.709769
INFO:root:FL Epoch: 126 Norm Difference for worker 433 is 1.103123
INFO:root:FL Epoch: 126 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :605
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.835602
INFO:root:Worker: 605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688541
INFO:root:FL Epoch: 126 Norm Difference for worker 605 is 1.126519
INFO:root:FL Epoch: 126 Done on worker:605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :416
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594996
INFO:root:Worker: 416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393443
INFO:root:FL Epoch: 126 Norm Difference for worker 416 is 1.116126
INFO:root:FL Epoch: 126 Done on worker:416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 915
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 126 Ends   ===================
INFO:root:Epoch:126 Global Model Test Loss:0.5878951567060807 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:126 Global Model Backdoor Test Loss:0.35865041613578796                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 127 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 127 Workers Selected : [857, 1514, 267, 1586, 889, 1059, 1388, 1617, 1454, 1616]
INFO:root:FL Epoch: 127 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 127 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 127 Training on worker :857
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501043
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489986
INFO:root:FL Epoch: 127 Norm Difference for worker 857 is 0.978161
INFO:root:FL Epoch: 127 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1514
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621679
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672453
INFO:root:FL Epoch: 127 Norm Difference for worker 1514 is 0.998092
INFO:root:FL Epoch: 127 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :267
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 267 Train Epoch: 0 [0/201 (0%)]	Loss: 0.497226
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 267 Train Epoch: 1 [0/201 (0%)]	Loss: 0.498112
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 127 Norm Difference for worker 267 is 0.968247
INFO:root:FL Epoch: 127 Done on worker:267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1586
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561680
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473674
INFO:root:FL Epoch: 127 Norm Difference for worker 1586 is 1.000834
INFO:root:FL Epoch: 127 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :889
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744509
INFO:root:Worker: 889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489686
INFO:root:FL Epoch: 127 Norm Difference for worker 889 is 0.978011
INFO:root:FL Epoch: 127 Done on worker:889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1059
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540584
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499725
INFO:root:FL Epoch: 127 Norm Difference for worker 1059 is 1.016376
INFO:root:FL Epoch: 127 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1388
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574528
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549161
INFO:root:FL Epoch: 127 Norm Difference for worker 1388 is 1.001347
INFO:root:FL Epoch: 127 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1617
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479183
INFO:root:Worker: 1617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.740318
INFO:root:FL Epoch: 127 Norm Difference for worker 1617 is 0.968496
INFO:root:FL Epoch: 127 Done on worker:1617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1454
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605364
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477871
INFO:root:FL Epoch: 127 Norm Difference for worker 1454 is 0.942691
INFO:root:FL Epoch: 127 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1616
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539581
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.736582
INFO:root:FL Epoch: 127 Norm Difference for worker 1616 is 0.998757
INFO:root:FL Epoch: 127 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1454
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 127 Ends   ===================
INFO:root:Epoch:127 Global Model Test Loss:0.5730875099406523 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:127 Global Model Backdoor Test Loss:0.40691517293453217                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 128 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 128 Workers Selected : [310, 104, 160, 498, 577, 1023, 911, 823, 1667, 754]
INFO:root:FL Epoch: 128 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 128 Num points on workers: [201 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 128 Training on worker :310
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 310 Train Epoch: 0 [0/201 (0%)]	Loss: 0.628062
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 310 Train Epoch: 1 [0/201 (0%)]	Loss: 0.529810
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 310 is 1.096433
INFO:root:FL Epoch: 128 Done on worker:310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :104
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.574154
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.533071
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 104 is 1.136228
INFO:root:FL Epoch: 128 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :160
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.708693
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.621035
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 160 is 1.150118
INFO:root:FL Epoch: 128 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :498
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552414
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547451
INFO:root:FL Epoch: 128 Norm Difference for worker 498 is 1.123063
INFO:root:FL Epoch: 128 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :577
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.777151
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530027
INFO:root:FL Epoch: 128 Norm Difference for worker 577 is 1.072934
INFO:root:FL Epoch: 128 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1023
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437152
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512575
INFO:root:FL Epoch: 128 Norm Difference for worker 1023 is 1.0904
INFO:root:FL Epoch: 128 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :911
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569678
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471704
INFO:root:FL Epoch: 128 Norm Difference for worker 911 is 1.161759
INFO:root:FL Epoch: 128 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :823
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526868
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408934
INFO:root:FL Epoch: 128 Norm Difference for worker 823 is 1.148323
INFO:root:FL Epoch: 128 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1667
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478684
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490459
INFO:root:FL Epoch: 128 Norm Difference for worker 1667 is 1.126105
INFO:root:FL Epoch: 128 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :754
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673623
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458494
INFO:root:FL Epoch: 128 Norm Difference for worker 754 is 1.151353
INFO:root:FL Epoch: 128 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 310
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 128 Ends   ===================
INFO:root:Epoch:128 Global Model Test Loss:0.576572365620557 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:128 Global Model Backdoor Test Loss:0.4390571117401123                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 129 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 129 Workers Selected : [1492, 354, 33, 1440, 773, 1028, 863, 755, 1307, 1724]
INFO:root:FL Epoch: 129 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 129 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 129 Training on worker :1492
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.791793
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435415
INFO:root:FL Epoch: 129 Norm Difference for worker 1492 is 1.169929
INFO:root:FL Epoch: 129 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :354
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512389
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632447
INFO:root:FL Epoch: 129 Norm Difference for worker 354 is 1.236481
INFO:root:FL Epoch: 129 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :33
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.444684
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.566695
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 129 Norm Difference for worker 33 is 1.105879
INFO:root:FL Epoch: 129 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1440
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651492
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419575
INFO:root:FL Epoch: 129 Norm Difference for worker 1440 is 1.145151
INFO:root:FL Epoch: 129 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :773
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534081
INFO:root:Worker: 773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461231
INFO:root:FL Epoch: 129 Norm Difference for worker 773 is 1.197542
INFO:root:FL Epoch: 129 Done on worker:773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1028
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595764
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576738
INFO:root:FL Epoch: 129 Norm Difference for worker 1028 is 1.128422
INFO:root:FL Epoch: 129 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :863
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561679
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618342
INFO:root:FL Epoch: 129 Norm Difference for worker 863 is 1.200554
INFO:root:FL Epoch: 129 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :755
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621022
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487771
INFO:root:FL Epoch: 129 Norm Difference for worker 755 is 1.226066
INFO:root:FL Epoch: 129 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1307
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474989
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519927
INFO:root:FL Epoch: 129 Norm Difference for worker 1307 is 1.200424
INFO:root:FL Epoch: 129 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1724
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668332
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691726
INFO:root:FL Epoch: 129 Norm Difference for worker 1724 is 1.209127
INFO:root:FL Epoch: 129 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 33
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 129 Ends   ===================
INFO:root:Epoch:129 Global Model Test Loss:0.5823294239885667 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:129 Global Model Backdoor Test Loss:0.47377845148245495                             and Backdoor Test Accuracy:82.5 
INFO:root:=======================================================
INFO:root:================FL round 130 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 130 Workers Selected : [324, 145, 544, 970, 1423, 1402, 689, 1486, 765, 11]
INFO:root:FL Epoch: 130 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 130 Num points on workers: [201 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 130 Training on worker :324
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.488228
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.672962
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 324 is 1.117105
INFO:root:FL Epoch: 130 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :145
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.684718
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.441900
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 145 is 1.041903
INFO:root:FL Epoch: 130 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :544
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542356
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589840
INFO:root:FL Epoch: 130 Norm Difference for worker 544 is 1.094305
INFO:root:FL Epoch: 130 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :970
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 970 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752240
INFO:root:Worker: 970 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394219
INFO:root:FL Epoch: 130 Norm Difference for worker 970 is 1.107489
INFO:root:FL Epoch: 130 Done on worker:970
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1423
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589161
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336476
INFO:root:FL Epoch: 130 Norm Difference for worker 1423 is 1.076998
INFO:root:FL Epoch: 130 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1402
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1402 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617228
INFO:root:Worker: 1402 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563932
INFO:root:FL Epoch: 130 Norm Difference for worker 1402 is 1.078524
INFO:root:FL Epoch: 130 Done on worker:1402
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :689
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474379
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503575
INFO:root:FL Epoch: 130 Norm Difference for worker 689 is 1.085866
INFO:root:FL Epoch: 130 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1486
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778092
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538594
INFO:root:FL Epoch: 130 Norm Difference for worker 1486 is 1.085102
INFO:root:FL Epoch: 130 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :765
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565362
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486811
INFO:root:FL Epoch: 130 Norm Difference for worker 765 is 1.108396
INFO:root:FL Epoch: 130 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :11
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 11 Train Epoch: 0 [0/201 (0%)]	Loss: 0.528658
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 11 Train Epoch: 1 [0/201 (0%)]	Loss: 0.552786
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 11 is 1.066496
INFO:root:FL Epoch: 130 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 145
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 130 Ends   ===================
INFO:root:Epoch:130 Global Model Test Loss:0.5722994681666879 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:130 Global Model Backdoor Test Loss:0.4498947362105052                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 131 Begins ===================
INFO:root:FL Epoch: 131 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 131 Workers Selected : [0, 1, 2, 1513, 1131, 516, 950, 910, 386, 240]
INFO:root:FL Epoch: 131 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 131 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 131 Training on worker :0
INFO:root:FL Epoch: 131 Using Learning rate : 0.00770850870820709 
INFO:root:FL Epoch: 131 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570136
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362597
INFO:root:FL Epoch: 131 Worker: 0 Backdoor Test Loss: 0.28168821583191556 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 131 Worker: 0 Backdoor Train Loss: 0.3460249200463295 Backdoor Train Accuracy: 87.5
INFO:root:FL Epoch: 131 Norm Difference for worker 0 is 0.296847
INFO:root:FL Epoch: 131 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1
INFO:root:FL Epoch: 131 Using Learning rate : 0.00770850870820709 
INFO:root:FL Epoch: 131 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405154
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409616
INFO:root:FL Epoch: 131 Worker: 1 Backdoor Test Loss: 0.2700321053465207 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 131 Worker: 1 Backdoor Train Loss: 0.34492270797491076 Backdoor Train Accuracy: 87.5
INFO:root:FL Epoch: 131 Norm Difference for worker 1 is 0.306167
INFO:root:FL Epoch: 131 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :2
INFO:root:FL Epoch: 131 Using Learning rate : 0.00770850870820709 
INFO:root:FL Epoch: 131 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370962
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514001
INFO:root:FL Epoch: 131 Worker: 2 Backdoor Test Loss: 0.2868078698714574 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 131 Worker: 2 Backdoor Train Loss: 0.3428352802991867 Backdoor Train Accuracy: 87.5
INFO:root:FL Epoch: 131 Norm Difference for worker 2 is 0.306329
INFO:root:FL Epoch: 131 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1513
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662927
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553445
INFO:root:FL Epoch: 131 Norm Difference for worker 1513 is 1.049316
INFO:root:FL Epoch: 131 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1131
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667143
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609873
INFO:root:FL Epoch: 131 Norm Difference for worker 1131 is 1.196929
INFO:root:FL Epoch: 131 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :516
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584359
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.720876
INFO:root:FL Epoch: 131 Norm Difference for worker 516 is 1.132151
INFO:root:FL Epoch: 131 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :950
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.904256
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507484
INFO:root:FL Epoch: 131 Norm Difference for worker 950 is 1.113222
INFO:root:FL Epoch: 131 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :910
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607359
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342024
INFO:root:FL Epoch: 131 Norm Difference for worker 910 is 1.118937
INFO:root:FL Epoch: 131 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :386
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581363
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485497
INFO:root:FL Epoch: 131 Norm Difference for worker 386 is 1.206225
INFO:root:FL Epoch: 131 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :240
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 240 Train Epoch: 0 [0/201 (0%)]	Loss: 0.648321
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 240 Train Epoch: 1 [0/201 (0%)]	Loss: 0.666274
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 131 Norm Difference for worker 240 is 1.152922
INFO:root:FL Epoch: 131 Done on worker:240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 131 Ends   ===================
INFO:root:Epoch:131 Global Model Test Loss:0.5789466254851398 and Test Accuracy:70.0 
INFO:root:Epoch:131 Global Model Backdoor Test Loss:0.2868078698714574                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 132 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 132 Workers Selected : [1511, 1912, 355, 961, 352, 366, 136, 335, 1156, 1522]
INFO:root:FL Epoch: 132 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 132 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 132 Training on worker :1511
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 1.042724
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566739
INFO:root:FL Epoch: 132 Norm Difference for worker 1511 is 1.237342
INFO:root:FL Epoch: 132 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1912
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444698
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457927
INFO:root:FL Epoch: 132 Norm Difference for worker 1912 is 1.243194
INFO:root:FL Epoch: 132 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :355
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621087
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518391
INFO:root:FL Epoch: 132 Norm Difference for worker 355 is 1.279956
INFO:root:FL Epoch: 132 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :961
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619872
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667430
INFO:root:FL Epoch: 132 Norm Difference for worker 961 is 1.288456
INFO:root:FL Epoch: 132 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :352
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566413
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553520
INFO:root:FL Epoch: 132 Norm Difference for worker 352 is 1.195552
INFO:root:FL Epoch: 132 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :366
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769785
INFO:root:Worker: 366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526009
INFO:root:FL Epoch: 132 Norm Difference for worker 366 is 1.261974
INFO:root:FL Epoch: 132 Done on worker:366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :136
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 136 Train Epoch: 0 [0/201 (0%)]	Loss: 0.565311
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 136 Train Epoch: 1 [0/201 (0%)]	Loss: 0.420643
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 136 is 1.202907
INFO:root:FL Epoch: 132 Done on worker:136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :335
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.449459
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.465633
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 335 is 1.207616
INFO:root:FL Epoch: 132 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1156
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467569
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508675
INFO:root:FL Epoch: 132 Norm Difference for worker 1156 is 1.183186
INFO:root:FL Epoch: 132 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1522
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514167
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509206
INFO:root:FL Epoch: 132 Norm Difference for worker 1522 is 1.244675
INFO:root:FL Epoch: 132 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 136
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 132 Ends   ===================
INFO:root:Epoch:132 Global Model Test Loss:0.5946198368773741 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:132 Global Model Backdoor Test Loss:0.2521243567268054                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 133 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 133 Workers Selected : [1447, 1313, 1892, 700, 1180, 208, 1366, 1174, 968, 869]
INFO:root:FL Epoch: 133 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 133 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 133 Training on worker :1447
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.850686
INFO:root:Worker: 1447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680546
INFO:root:FL Epoch: 133 Norm Difference for worker 1447 is 1.274374
INFO:root:FL Epoch: 133 Done on worker:1447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1313
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591640
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535160
INFO:root:FL Epoch: 133 Norm Difference for worker 1313 is 1.316348
INFO:root:FL Epoch: 133 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1892
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457223
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472616
INFO:root:FL Epoch: 133 Norm Difference for worker 1892 is 1.291157
INFO:root:FL Epoch: 133 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :700
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586790
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607325
INFO:root:FL Epoch: 133 Norm Difference for worker 700 is 1.405477
INFO:root:FL Epoch: 133 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1180
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449251
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546761
INFO:root:FL Epoch: 133 Norm Difference for worker 1180 is 1.283764
INFO:root:FL Epoch: 133 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :208
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.501873
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419026
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 133 Norm Difference for worker 208 is 1.365172
INFO:root:FL Epoch: 133 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1366
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511773
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448562
INFO:root:FL Epoch: 133 Norm Difference for worker 1366 is 1.299268
INFO:root:FL Epoch: 133 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1174
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600210
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501280
INFO:root:FL Epoch: 133 Norm Difference for worker 1174 is 1.298102
INFO:root:FL Epoch: 133 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :968
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597989
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401099
INFO:root:FL Epoch: 133 Norm Difference for worker 968 is 1.314712
INFO:root:FL Epoch: 133 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :869
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.831820
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463118
INFO:root:FL Epoch: 133 Norm Difference for worker 869 is 1.322422
INFO:root:FL Epoch: 133 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1892
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 133 Ends   ===================
INFO:root:Epoch:133 Global Model Test Loss:0.5688077263972339 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:133 Global Model Backdoor Test Loss:0.2748857339223226                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 134 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 134 Workers Selected : [1137, 1389, 158, 892, 314, 737, 1206, 362, 1354, 650]
INFO:root:FL Epoch: 134 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 134 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 134 Training on worker :1137
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812532
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567709
INFO:root:FL Epoch: 134 Norm Difference for worker 1137 is 1.168033
INFO:root:FL Epoch: 134 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1389
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.790700
INFO:root:Worker: 1389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617022
INFO:root:FL Epoch: 134 Norm Difference for worker 1389 is 1.119068
INFO:root:FL Epoch: 134 Done on worker:1389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :158
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.632287
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.442846
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 134 Norm Difference for worker 158 is 1.090216
INFO:root:FL Epoch: 134 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :892
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519547
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 1.032801
INFO:root:FL Epoch: 134 Norm Difference for worker 892 is 1.106802
INFO:root:FL Epoch: 134 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :314
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 314 Train Epoch: 0 [0/201 (0%)]	Loss: 0.610039
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 314 Train Epoch: 1 [0/201 (0%)]	Loss: 0.886160
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 134 Norm Difference for worker 314 is 1.126978
INFO:root:FL Epoch: 134 Done on worker:314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :737
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654582
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466236
INFO:root:FL Epoch: 134 Norm Difference for worker 737 is 1.09297
INFO:root:FL Epoch: 134 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1206
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1206 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634904
INFO:root:Worker: 1206 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587791
INFO:root:FL Epoch: 134 Norm Difference for worker 1206 is 1.103918
INFO:root:FL Epoch: 134 Done on worker:1206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :362
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466287
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537643
INFO:root:FL Epoch: 134 Norm Difference for worker 362 is 1.174389
INFO:root:FL Epoch: 134 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1354
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531544
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651081
INFO:root:FL Epoch: 134 Norm Difference for worker 1354 is 1.100283
INFO:root:FL Epoch: 134 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :650
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732459
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404223
INFO:root:FL Epoch: 134 Norm Difference for worker 650 is 1.108399
INFO:root:FL Epoch: 134 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 314
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 134 Ends   ===================
INFO:root:Epoch:134 Global Model Test Loss:0.5846585701493656 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:134 Global Model Backdoor Test Loss:0.5061350762844086                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 135 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 135 Workers Selected : [1702, 19, 779, 1874, 153, 751, 1409, 1891, 1327, 312]
INFO:root:FL Epoch: 135 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 135 Num points on workers: [200 201 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 135 Training on worker :1702
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659237
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515143
INFO:root:FL Epoch: 135 Norm Difference for worker 1702 is 0.907995
INFO:root:FL Epoch: 135 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :19
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.564240
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697083
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 19 is 0.921256
INFO:root:FL Epoch: 135 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :779
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626568
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558195
INFO:root:FL Epoch: 135 Norm Difference for worker 779 is 0.96657
INFO:root:FL Epoch: 135 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1874
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775513
INFO:root:Worker: 1874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453826
INFO:root:FL Epoch: 135 Norm Difference for worker 1874 is 0.943968
INFO:root:FL Epoch: 135 Done on worker:1874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :153
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.472161
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.607479
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 153 is 0.937201
INFO:root:FL Epoch: 135 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :751
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724263
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425691
INFO:root:FL Epoch: 135 Norm Difference for worker 751 is 0.931688
INFO:root:FL Epoch: 135 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1409
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595401
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417587
INFO:root:FL Epoch: 135 Norm Difference for worker 1409 is 0.957753
INFO:root:FL Epoch: 135 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1891
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626957
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602550
INFO:root:FL Epoch: 135 Norm Difference for worker 1891 is 0.909651
INFO:root:FL Epoch: 135 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1327
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583255
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492659
INFO:root:FL Epoch: 135 Norm Difference for worker 1327 is 0.966377
INFO:root:FL Epoch: 135 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :312
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.600793
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.589474
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 312 is 0.905879
INFO:root:FL Epoch: 135 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 312
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 135 Ends   ===================
INFO:root:Epoch:135 Global Model Test Loss:0.5670701510765973 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:135 Global Model Backdoor Test Loss:0.31578420102596283                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 136 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 136 Workers Selected : [950, 1614, 1069, 1082, 755, 211, 626, 1801, 592, 113]
INFO:root:FL Epoch: 136 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 136 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 136 Training on worker :950
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588113
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592447
INFO:root:FL Epoch: 136 Norm Difference for worker 950 is 0.998352
INFO:root:FL Epoch: 136 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1614
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621485
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496146
INFO:root:FL Epoch: 136 Norm Difference for worker 1614 is 1.064866
INFO:root:FL Epoch: 136 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1069
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513655
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607361
INFO:root:FL Epoch: 136 Norm Difference for worker 1069 is 1.060128
INFO:root:FL Epoch: 136 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1082
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465891
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471313
INFO:root:FL Epoch: 136 Norm Difference for worker 1082 is 1.019393
INFO:root:FL Epoch: 136 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :755
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.830480
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471492
INFO:root:FL Epoch: 136 Norm Difference for worker 755 is 1.042382
INFO:root:FL Epoch: 136 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :211
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.714991
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.646478
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 211 is 0.99832
INFO:root:FL Epoch: 136 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :626
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641712
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514043
INFO:root:FL Epoch: 136 Norm Difference for worker 626 is 0.996756
INFO:root:FL Epoch: 136 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1801
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422605
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473217
INFO:root:FL Epoch: 136 Norm Difference for worker 1801 is 0.960727
INFO:root:FL Epoch: 136 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :592
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668425
INFO:root:Worker: 592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382794
INFO:root:FL Epoch: 136 Norm Difference for worker 592 is 1.008851
INFO:root:FL Epoch: 136 Done on worker:592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :113
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 113 Train Epoch: 0 [0/201 (0%)]	Loss: 0.407098
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 113 Train Epoch: 1 [0/201 (0%)]	Loss: 0.396972
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 113 is 0.990954
INFO:root:FL Epoch: 136 Done on worker:113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1082
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 136 Ends   ===================
INFO:root:Epoch:136 Global Model Test Loss:0.5600573543240043 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:136 Global Model Backdoor Test Loss:0.28532858937978745                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 137 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 137 Workers Selected : [935, 1785, 769, 514, 59, 1601, 1554, 1492, 393, 1921]
INFO:root:FL Epoch: 137 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 137 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 137 Training on worker :935
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432841
INFO:root:Worker: 935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548936
INFO:root:FL Epoch: 137 Norm Difference for worker 935 is 1.315242
INFO:root:FL Epoch: 137 Done on worker:935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1785
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573191
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606241
INFO:root:FL Epoch: 137 Norm Difference for worker 1785 is 1.371631
INFO:root:FL Epoch: 137 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :769
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474654
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648896
INFO:root:FL Epoch: 137 Norm Difference for worker 769 is 1.395145
INFO:root:FL Epoch: 137 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :514
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459857
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654415
INFO:root:FL Epoch: 137 Norm Difference for worker 514 is 1.352759
INFO:root:FL Epoch: 137 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :59
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.410560
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.578984
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 137 Norm Difference for worker 59 is 1.441169
INFO:root:FL Epoch: 137 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1601
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415748
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454718
INFO:root:FL Epoch: 137 Norm Difference for worker 1601 is 1.338214
INFO:root:FL Epoch: 137 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1554
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577740
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449908
INFO:root:FL Epoch: 137 Norm Difference for worker 1554 is 1.269697
INFO:root:FL Epoch: 137 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1492
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.820283
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588170
INFO:root:FL Epoch: 137 Norm Difference for worker 1492 is 1.426399
INFO:root:FL Epoch: 137 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :393
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692035
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390519
INFO:root:FL Epoch: 137 Norm Difference for worker 393 is 1.394113
INFO:root:FL Epoch: 137 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1921
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566694
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637948
INFO:root:FL Epoch: 137 Norm Difference for worker 1921 is 1.397268
INFO:root:FL Epoch: 137 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 935
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 137 Ends   ===================
INFO:root:Epoch:137 Global Model Test Loss:0.5691904671051923 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:137 Global Model Backdoor Test Loss:0.4666731059551239                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 138 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 138 Workers Selected : [589, 1143, 1020, 1022, 730, 346, 92, 139, 1469, 1364]
INFO:root:FL Epoch: 138 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 138 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 138 Training on worker :589
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548830
INFO:root:Worker: 589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606960
INFO:root:FL Epoch: 138 Norm Difference for worker 589 is 1.088502
INFO:root:FL Epoch: 138 Done on worker:589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1143
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1143 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567019
INFO:root:Worker: 1143 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690289
INFO:root:FL Epoch: 138 Norm Difference for worker 1143 is 1.211352
INFO:root:FL Epoch: 138 Done on worker:1143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1020
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1020 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433861
INFO:root:Worker: 1020 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630774
INFO:root:FL Epoch: 138 Norm Difference for worker 1020 is 1.157363
INFO:root:FL Epoch: 138 Done on worker:1020
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1022
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527203
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595656
INFO:root:FL Epoch: 138 Norm Difference for worker 1022 is 1.004046
INFO:root:FL Epoch: 138 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :730
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562204
INFO:root:Worker: 730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498161
INFO:root:FL Epoch: 138 Norm Difference for worker 730 is 1.204291
INFO:root:FL Epoch: 138 Done on worker:730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :346
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525303
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489942
INFO:root:FL Epoch: 138 Norm Difference for worker 346 is 1.194168
INFO:root:FL Epoch: 138 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :92
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694541
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.525535
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 92 is 1.065998
INFO:root:FL Epoch: 138 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :139
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 139 Train Epoch: 0 [0/201 (0%)]	Loss: 0.585961
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 139 Train Epoch: 1 [0/201 (0%)]	Loss: 0.761684
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 139 is 1.179221
INFO:root:FL Epoch: 138 Done on worker:139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1469
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536774
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497055
INFO:root:FL Epoch: 138 Norm Difference for worker 1469 is 1.06201
INFO:root:FL Epoch: 138 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1364
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405615
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425634
INFO:root:FL Epoch: 138 Norm Difference for worker 1364 is 1.138821
INFO:root:FL Epoch: 138 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 92
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 138 Ends   ===================
INFO:root:Epoch:138 Global Model Test Loss:0.5667807705262128 and Test Accuracy:70.0 
INFO:root:Epoch:138 Global Model Backdoor Test Loss:0.5261635979016622                             and Backdoor Test Accuracy:79.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 139 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 139 Workers Selected : [545, 55, 702, 1861, 1745, 524, 900, 492, 1013, 1556]
INFO:root:FL Epoch: 139 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 139 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 139 Training on worker :545
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570982
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.724103
INFO:root:FL Epoch: 139 Norm Difference for worker 545 is 1.01987
INFO:root:FL Epoch: 139 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :55
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.448757
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.413755
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 139 Norm Difference for worker 55 is 0.956517
INFO:root:FL Epoch: 139 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :702
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511017
INFO:root:Worker: 702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373999
INFO:root:FL Epoch: 139 Norm Difference for worker 702 is 0.993459
INFO:root:FL Epoch: 139 Done on worker:702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1861
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566947
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546315
INFO:root:FL Epoch: 139 Norm Difference for worker 1861 is 1.042866
INFO:root:FL Epoch: 139 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1745
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732311
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534847
INFO:root:FL Epoch: 139 Norm Difference for worker 1745 is 1.00355
INFO:root:FL Epoch: 139 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :524
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514214
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.713105
INFO:root:FL Epoch: 139 Norm Difference for worker 524 is 0.957556
INFO:root:FL Epoch: 139 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :900
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708377
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522121
INFO:root:FL Epoch: 139 Norm Difference for worker 900 is 1.021754
INFO:root:FL Epoch: 139 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :492
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372960
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437476
INFO:root:FL Epoch: 139 Norm Difference for worker 492 is 1.039691
INFO:root:FL Epoch: 139 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1013
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441398
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602219
INFO:root:FL Epoch: 139 Norm Difference for worker 1013 is 1.009368
INFO:root:FL Epoch: 139 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1556
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630411
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520708
INFO:root:FL Epoch: 139 Norm Difference for worker 1556 is 0.985438
INFO:root:FL Epoch: 139 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 55
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 139 Ends   ===================
INFO:root:Epoch:139 Global Model Test Loss:0.5646469032063204 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:139 Global Model Backdoor Test Loss:0.38103704154491425                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 140 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 140 Workers Selected : [1834, 946, 646, 1428, 50, 1198, 1355, 222, 1642, 1223]
INFO:root:FL Epoch: 140 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 140 Num points on workers: [200 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 140 Training on worker :1834
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.860191
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611011
INFO:root:FL Epoch: 140 Norm Difference for worker 1834 is 1.197333
INFO:root:FL Epoch: 140 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :946
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664361
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576957
INFO:root:FL Epoch: 140 Norm Difference for worker 946 is 1.177733
INFO:root:FL Epoch: 140 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :646
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646964
INFO:root:Worker: 646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554004
INFO:root:FL Epoch: 140 Norm Difference for worker 646 is 1.165886
INFO:root:FL Epoch: 140 Done on worker:646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1428
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391488
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370711
INFO:root:FL Epoch: 140 Norm Difference for worker 1428 is 1.128324
INFO:root:FL Epoch: 140 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :50
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.664124
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.378265
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 140 Norm Difference for worker 50 is 1.182927
INFO:root:FL Epoch: 140 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1198
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401644
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513051
INFO:root:FL Epoch: 140 Norm Difference for worker 1198 is 1.114967
INFO:root:FL Epoch: 140 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1355
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662164
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513483
INFO:root:FL Epoch: 140 Norm Difference for worker 1355 is 1.151989
INFO:root:FL Epoch: 140 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :222
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.438659
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.477698
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 140 Norm Difference for worker 222 is 1.066706
INFO:root:FL Epoch: 140 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1642
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626626
INFO:root:Worker: 1642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484820
INFO:root:FL Epoch: 140 Norm Difference for worker 1642 is 1.226614
INFO:root:FL Epoch: 140 Done on worker:1642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1223
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1223 Train Epoch: 0 [0/200 (0%)]	Loss: 1.010625
INFO:root:Worker: 1223 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595771
INFO:root:FL Epoch: 140 Norm Difference for worker 1223 is 1.143616
INFO:root:FL Epoch: 140 Done on worker:1223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 222
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 140 Ends   ===================
INFO:root:Epoch:140 Global Model Test Loss:0.5872773755999172 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:140 Global Model Backdoor Test Loss:0.4321335007747014                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 141 Begins ===================
INFO:root:FL Epoch: 141 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 141 Workers Selected : [0, 1, 2, 1878, 962, 549, 976, 769, 465, 1750]
INFO:root:FL Epoch: 141 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 141 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 141 Training on worker :0
INFO:root:FL Epoch: 141 Using Learning rate : 0.007555718691280597 
INFO:root:FL Epoch: 141 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506385
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257483
INFO:root:FL Epoch: 141 Worker: 0 Backdoor Test Loss: 0.24747389058272043 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 141 Worker: 0 Backdoor Train Loss: 0.32889426201581956 Backdoor Train Accuracy: 89.0
INFO:root:FL Epoch: 141 Norm Difference for worker 0 is 0.2986
INFO:root:FL Epoch: 141 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1
INFO:root:FL Epoch: 141 Using Learning rate : 0.007555718691280597 
INFO:root:FL Epoch: 141 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.352078
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402273
INFO:root:FL Epoch: 141 Worker: 1 Backdoor Test Loss: 0.24204261104265848 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 141 Worker: 1 Backdoor Train Loss: 0.32918294072151183 Backdoor Train Accuracy: 88.5
INFO:root:FL Epoch: 141 Norm Difference for worker 1 is 0.298972
INFO:root:FL Epoch: 141 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :2
INFO:root:FL Epoch: 141 Using Learning rate : 0.007555718691280597 
INFO:root:FL Epoch: 141 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347564
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398145
INFO:root:FL Epoch: 141 Worker: 2 Backdoor Test Loss: 0.23528150469064713 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 141 Worker: 2 Backdoor Train Loss: 0.3323811501264572 Backdoor Train Accuracy: 88.0
INFO:root:FL Epoch: 141 Norm Difference for worker 2 is 0.298855
INFO:root:FL Epoch: 141 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1878
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.767761
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564926
INFO:root:FL Epoch: 141 Norm Difference for worker 1878 is 1.262968
INFO:root:FL Epoch: 141 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :962
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677480
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574602
INFO:root:FL Epoch: 141 Norm Difference for worker 962 is 1.159805
INFO:root:FL Epoch: 141 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :549
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711355
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493685
INFO:root:FL Epoch: 141 Norm Difference for worker 549 is 1.163765
INFO:root:FL Epoch: 141 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :976
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 976 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804402
INFO:root:Worker: 976 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668501
INFO:root:FL Epoch: 141 Norm Difference for worker 976 is 1.148787
INFO:root:FL Epoch: 141 Done on worker:976
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :769
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807337
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409287
INFO:root:FL Epoch: 141 Norm Difference for worker 769 is 1.163743
INFO:root:FL Epoch: 141 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :465
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567285
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608607
INFO:root:FL Epoch: 141 Norm Difference for worker 465 is 1.138597
INFO:root:FL Epoch: 141 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1750
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.936732
INFO:root:Worker: 1750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421357
INFO:root:FL Epoch: 141 Norm Difference for worker 1750 is 1.091052
INFO:root:FL Epoch: 141 Done on worker:1750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 141 Ends   ===================
INFO:root:Epoch:141 Global Model Test Loss:0.5959513134816113 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:141 Global Model Backdoor Test Loss:0.24204261104265848                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 142 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 142 Workers Selected : [1841, 1522, 23, 1157, 56, 1269, 442, 577, 219, 1614]
INFO:root:FL Epoch: 142 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 142 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 142 Training on worker :1841
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386842
INFO:root:Worker: 1841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513949
INFO:root:FL Epoch: 142 Norm Difference for worker 1841 is 1.2137
INFO:root:FL Epoch: 142 Done on worker:1841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1522
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739014
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646076
INFO:root:FL Epoch: 142 Norm Difference for worker 1522 is 1.182081
INFO:root:FL Epoch: 142 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :23
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 23 Train Epoch: 0 [0/201 (0%)]	Loss: 0.795920
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 23 Train Epoch: 1 [0/201 (0%)]	Loss: 0.565317
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 23 is 1.314714
INFO:root:FL Epoch: 142 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1157
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552816
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531044
INFO:root:FL Epoch: 142 Norm Difference for worker 1157 is 1.313353
INFO:root:FL Epoch: 142 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :56
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.562666
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.418779
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 56 is 1.174659
INFO:root:FL Epoch: 142 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1269
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1269 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541232
INFO:root:Worker: 1269 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578726
INFO:root:FL Epoch: 142 Norm Difference for worker 1269 is 1.21097
INFO:root:FL Epoch: 142 Done on worker:1269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :442
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801641
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503590
INFO:root:FL Epoch: 142 Norm Difference for worker 442 is 1.23325
INFO:root:FL Epoch: 142 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :577
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604561
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439663
INFO:root:FL Epoch: 142 Norm Difference for worker 577 is 1.222832
INFO:root:FL Epoch: 142 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :219
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 219 Train Epoch: 0 [0/201 (0%)]	Loss: 0.724974
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 219 Train Epoch: 1 [0/201 (0%)]	Loss: 0.362102
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 142 Norm Difference for worker 219 is 1.272296
INFO:root:FL Epoch: 142 Done on worker:219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1614
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579982
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538679
INFO:root:FL Epoch: 142 Norm Difference for worker 1614 is 1.29197
INFO:root:FL Epoch: 142 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1522
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 142 Ends   ===================
INFO:root:Epoch:142 Global Model Test Loss:0.5793240035281462 and Test Accuracy:69.11764705882354 
INFO:root:Epoch:142 Global Model Backdoor Test Loss:0.311243603626887                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 143 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 143 Workers Selected : [1520, 1151, 182, 755, 86, 1828, 1417, 504, 250, 634]
INFO:root:FL Epoch: 143 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 143 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 143 Training on worker :1520
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522852
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495862
INFO:root:FL Epoch: 143 Norm Difference for worker 1520 is 1.125157
INFO:root:FL Epoch: 143 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1151
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1151 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672845
INFO:root:Worker: 1151 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491202
INFO:root:FL Epoch: 143 Norm Difference for worker 1151 is 1.044478
INFO:root:FL Epoch: 143 Done on worker:1151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :182
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.821176
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431798
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 182 is 1.123463
INFO:root:FL Epoch: 143 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :755
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641462
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485543
INFO:root:FL Epoch: 143 Norm Difference for worker 755 is 1.109863
INFO:root:FL Epoch: 143 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :86
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.425477
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.362534
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 86 is 1.024673
INFO:root:FL Epoch: 143 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1828
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350861
INFO:root:Worker: 1828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478972
INFO:root:FL Epoch: 143 Norm Difference for worker 1828 is 1.122738
INFO:root:FL Epoch: 143 Done on worker:1828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1417
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589544
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600248
INFO:root:FL Epoch: 143 Norm Difference for worker 1417 is 1.040387
INFO:root:FL Epoch: 143 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :504
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552160
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529977
INFO:root:FL Epoch: 143 Norm Difference for worker 504 is 1.102834
INFO:root:FL Epoch: 143 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :250
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576137
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.490897
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 250 is 1.064989
INFO:root:FL Epoch: 143 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :634
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434281
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391276
INFO:root:FL Epoch: 143 Norm Difference for worker 634 is 1.040648
INFO:root:FL Epoch: 143 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 86
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 143 Ends   ===================
INFO:root:Epoch:143 Global Model Test Loss:0.5928920209407806 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:143 Global Model Backdoor Test Loss:0.3434040645758311                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 144 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 144 Workers Selected : [1753, 1838, 71, 711, 960, 665, 1500, 1467, 800, 787]
INFO:root:FL Epoch: 144 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 144 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 144 Training on worker :1753
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812770
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263838
INFO:root:FL Epoch: 144 Norm Difference for worker 1753 is 1.124247
INFO:root:FL Epoch: 144 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1838
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.815130
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598114
INFO:root:FL Epoch: 144 Norm Difference for worker 1838 is 1.139683
INFO:root:FL Epoch: 144 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :71
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.763185
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.487399
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 144 Norm Difference for worker 71 is 1.200194
INFO:root:FL Epoch: 144 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :711
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567375
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543801
INFO:root:FL Epoch: 144 Norm Difference for worker 711 is 1.190857
INFO:root:FL Epoch: 144 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :960
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 960 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701611
INFO:root:Worker: 960 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335292
INFO:root:FL Epoch: 144 Norm Difference for worker 960 is 1.174717
INFO:root:FL Epoch: 144 Done on worker:960
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :665
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760431
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524430
INFO:root:FL Epoch: 144 Norm Difference for worker 665 is 1.197963
INFO:root:FL Epoch: 144 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1500
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.829370
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636309
INFO:root:FL Epoch: 144 Norm Difference for worker 1500 is 1.219894
INFO:root:FL Epoch: 144 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1467
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632554
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386887
INFO:root:FL Epoch: 144 Norm Difference for worker 1467 is 1.119281
INFO:root:FL Epoch: 144 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :800
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499496
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404372
INFO:root:FL Epoch: 144 Norm Difference for worker 800 is 1.175528
INFO:root:FL Epoch: 144 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :787
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 1.008551
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.772965
INFO:root:FL Epoch: 144 Norm Difference for worker 787 is 1.277103
INFO:root:FL Epoch: 144 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1467
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 144 Ends   ===================
INFO:root:Epoch:144 Global Model Test Loss:0.588566673152587 and Test Accuracy:67.94117647058823 
INFO:root:Epoch:144 Global Model Backdoor Test Loss:0.41512635350227356                             and Backdoor Test Accuracy:82.5 
INFO:root:=======================================================
INFO:root:================FL round 145 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 145 Workers Selected : [380, 95, 818, 1766, 1585, 1927, 1721, 478, 1393, 1170]
INFO:root:FL Epoch: 145 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 145 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 145 Training on worker :380
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657893
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550317
INFO:root:FL Epoch: 145 Norm Difference for worker 380 is 1.059588
INFO:root:FL Epoch: 145 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :95
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 95 Train Epoch: 0 [0/201 (0%)]	Loss: 0.564039
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 95 Train Epoch: 1 [0/201 (0%)]	Loss: 0.412246
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 145 Norm Difference for worker 95 is 1.092962
INFO:root:FL Epoch: 145 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :818
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689169
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605006
INFO:root:FL Epoch: 145 Norm Difference for worker 818 is 1.076165
INFO:root:FL Epoch: 145 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1766
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687504
INFO:root:Worker: 1766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688662
INFO:root:FL Epoch: 145 Norm Difference for worker 1766 is 1.052128
INFO:root:FL Epoch: 145 Done on worker:1766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1585
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579599
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447535
INFO:root:FL Epoch: 145 Norm Difference for worker 1585 is 1.106197
INFO:root:FL Epoch: 145 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1927
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715788
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.746720
INFO:root:FL Epoch: 145 Norm Difference for worker 1927 is 1.070184
INFO:root:FL Epoch: 145 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1721
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562684
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674998
INFO:root:FL Epoch: 145 Norm Difference for worker 1721 is 1.043444
INFO:root:FL Epoch: 145 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :478
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646489
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.742907
INFO:root:FL Epoch: 145 Norm Difference for worker 478 is 1.049611
INFO:root:FL Epoch: 145 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1393
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532569
INFO:root:Worker: 1393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559768
INFO:root:FL Epoch: 145 Norm Difference for worker 1393 is 1.088047
INFO:root:FL Epoch: 145 Done on worker:1393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1170
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1170 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605275
INFO:root:Worker: 1170 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478968
INFO:root:FL Epoch: 145 Norm Difference for worker 1170 is 1.078979
INFO:root:FL Epoch: 145 Done on worker:1170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1393
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 145 Ends   ===================
INFO:root:Epoch:145 Global Model Test Loss:0.5787052687476663 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:145 Global Model Backdoor Test Loss:0.3722638537486394                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 146 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 146 Workers Selected : [968, 715, 798, 1158, 1312, 656, 911, 391, 42, 800]
INFO:root:FL Epoch: 146 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 146 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 146 Training on worker :968
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713770
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534157
INFO:root:FL Epoch: 146 Norm Difference for worker 968 is 0.941776
INFO:root:FL Epoch: 146 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :715
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563047
INFO:root:Worker: 715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600985
INFO:root:FL Epoch: 146 Norm Difference for worker 715 is 0.923414
INFO:root:FL Epoch: 146 Done on worker:715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :798
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729371
INFO:root:Worker: 798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374491
INFO:root:FL Epoch: 146 Norm Difference for worker 798 is 0.994768
INFO:root:FL Epoch: 146 Done on worker:798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :1158
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576879
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590810
INFO:root:FL Epoch: 146 Norm Difference for worker 1158 is 0.943563
INFO:root:FL Epoch: 146 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :1312
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481132
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525140
INFO:root:FL Epoch: 146 Norm Difference for worker 1312 is 0.967553
INFO:root:FL Epoch: 146 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :656
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521649
INFO:root:Worker: 656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648060
INFO:root:FL Epoch: 146 Norm Difference for worker 656 is 1.001359
INFO:root:FL Epoch: 146 Done on worker:656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :911
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655779
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708533
INFO:root:FL Epoch: 146 Norm Difference for worker 911 is 0.958995
INFO:root:FL Epoch: 146 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :391
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536345
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553921
INFO:root:FL Epoch: 146 Norm Difference for worker 391 is 0.962801
INFO:root:FL Epoch: 146 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :42
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.578153
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.435242
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 146 Norm Difference for worker 42 is 0.919685
INFO:root:FL Epoch: 146 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :800
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559247
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635792
INFO:root:FL Epoch: 146 Norm Difference for worker 800 is 1.078801
INFO:root:FL Epoch: 146 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 146 Ends   ===================
INFO:root:Epoch:146 Global Model Test Loss:0.5959927001420189 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:146 Global Model Backdoor Test Loss:0.41490953663984936                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 147 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 147 Workers Selected : [1230, 1810, 202, 692, 1869, 1931, 1058, 783, 536, 950]
INFO:root:FL Epoch: 147 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 147 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 147 Training on worker :1230
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1230 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668926
INFO:root:Worker: 1230 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444142
INFO:root:FL Epoch: 147 Norm Difference for worker 1230 is 1.027046
INFO:root:FL Epoch: 147 Done on worker:1230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1810
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603253
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483510
INFO:root:FL Epoch: 147 Norm Difference for worker 1810 is 1.012352
INFO:root:FL Epoch: 147 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :202
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.782884
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.457415
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 147 Norm Difference for worker 202 is 1.100704
INFO:root:FL Epoch: 147 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :692
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676508
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538833
INFO:root:FL Epoch: 147 Norm Difference for worker 692 is 1.074268
INFO:root:FL Epoch: 147 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1869
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470661
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635221
INFO:root:FL Epoch: 147 Norm Difference for worker 1869 is 1.072629
INFO:root:FL Epoch: 147 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1931
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491794
INFO:root:Worker: 1931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624834
INFO:root:FL Epoch: 147 Norm Difference for worker 1931 is 1.092502
INFO:root:FL Epoch: 147 Done on worker:1931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1058
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1058 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761886
INFO:root:Worker: 1058 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466346
INFO:root:FL Epoch: 147 Norm Difference for worker 1058 is 1.097513
INFO:root:FL Epoch: 147 Done on worker:1058
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :783
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625399
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496531
INFO:root:FL Epoch: 147 Norm Difference for worker 783 is 1.101037
INFO:root:FL Epoch: 147 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :536
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434628
INFO:root:Worker: 536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413182
INFO:root:FL Epoch: 147 Norm Difference for worker 536 is 1.062687
INFO:root:FL Epoch: 147 Done on worker:536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :950
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450532
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477620
INFO:root:FL Epoch: 147 Norm Difference for worker 950 is 1.06425
INFO:root:FL Epoch: 147 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1810
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 147 Ends   ===================
INFO:root:Epoch:147 Global Model Test Loss:0.5933121004525352 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:147 Global Model Backdoor Test Loss:0.3814050455888112                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 148 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 148 Workers Selected : [376, 932, 206, 532, 1088, 339, 1682, 436, 1295, 1789]
INFO:root:FL Epoch: 148 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 148 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 148 Training on worker :376
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315910
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470505
INFO:root:FL Epoch: 148 Norm Difference for worker 376 is 1.141499
INFO:root:FL Epoch: 148 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :932
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461334
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292312
INFO:root:FL Epoch: 148 Norm Difference for worker 932 is 1.12663
INFO:root:FL Epoch: 148 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :206
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.562562
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.613904
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 148 Norm Difference for worker 206 is 1.125907
INFO:root:FL Epoch: 148 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :532
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599156
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605484
INFO:root:FL Epoch: 148 Norm Difference for worker 532 is 1.19974
INFO:root:FL Epoch: 148 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1088
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484436
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501930
INFO:root:FL Epoch: 148 Norm Difference for worker 1088 is 1.066078
INFO:root:FL Epoch: 148 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :339
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 339 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611458
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 339 Train Epoch: 1 [0/201 (0%)]	Loss: 0.783279
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 148 Norm Difference for worker 339 is 1.12604
INFO:root:FL Epoch: 148 Done on worker:339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1682
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655177
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417314
INFO:root:FL Epoch: 148 Norm Difference for worker 1682 is 1.101313
INFO:root:FL Epoch: 148 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :436
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461464
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627291
INFO:root:FL Epoch: 148 Norm Difference for worker 436 is 1.198155
INFO:root:FL Epoch: 148 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1295
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367027
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509639
INFO:root:FL Epoch: 148 Norm Difference for worker 1295 is 1.103709
INFO:root:FL Epoch: 148 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1789
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699607
INFO:root:Worker: 1789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415085
INFO:root:FL Epoch: 148 Norm Difference for worker 1789 is 1.150035
INFO:root:FL Epoch: 148 Done on worker:1789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1088
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 148 Ends   ===================
INFO:root:Epoch:148 Global Model Test Loss:0.5829364184071036 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:148 Global Model Backdoor Test Loss:0.42843833565711975                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 149 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 149 Workers Selected : [648, 1268, 337, 1086, 1112, 725, 610, 1600, 335, 996]
INFO:root:FL Epoch: 149 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 149 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 149 Training on worker :648
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463180
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528223
INFO:root:FL Epoch: 149 Norm Difference for worker 648 is 1.251512
INFO:root:FL Epoch: 149 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1268
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569227
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514666
INFO:root:FL Epoch: 149 Norm Difference for worker 1268 is 1.268603
INFO:root:FL Epoch: 149 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :337
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.393928
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.607922
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 149 Norm Difference for worker 337 is 1.265199
INFO:root:FL Epoch: 149 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1086
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572414
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520055
INFO:root:FL Epoch: 149 Norm Difference for worker 1086 is 1.188837
INFO:root:FL Epoch: 149 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1112
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1112 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648628
INFO:root:Worker: 1112 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421516
INFO:root:FL Epoch: 149 Norm Difference for worker 1112 is 1.159499
INFO:root:FL Epoch: 149 Done on worker:1112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :725
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503199
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482665
INFO:root:FL Epoch: 149 Norm Difference for worker 725 is 1.281852
INFO:root:FL Epoch: 149 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :610
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671955
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571304
INFO:root:FL Epoch: 149 Norm Difference for worker 610 is 1.321194
INFO:root:FL Epoch: 149 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1600
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520713
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444164
INFO:root:FL Epoch: 149 Norm Difference for worker 1600 is 1.354494
INFO:root:FL Epoch: 149 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :335
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.390818
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.521796
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 149 Norm Difference for worker 335 is 1.264896
INFO:root:FL Epoch: 149 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :996
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695457
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308436
INFO:root:FL Epoch: 149 Norm Difference for worker 996 is 1.233117
INFO:root:FL Epoch: 149 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1112
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 149 Ends   ===================
INFO:root:Epoch:149 Global Model Test Loss:0.5790258260334239 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:149 Global Model Backdoor Test Loss:0.5953804949919382                             and Backdoor Test Accuracy:66.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 150 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 150 Workers Selected : [969, 73, 1089, 1428, 306, 424, 1357, 441, 62, 459]
INFO:root:FL Epoch: 150 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 150 Num points on workers: [200 201 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 150 Training on worker :969
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 969 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479059
INFO:root:Worker: 969 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436263
INFO:root:FL Epoch: 150 Norm Difference for worker 969 is 1.0828
INFO:root:FL Epoch: 150 Done on worker:969
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :73
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.535406
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446686
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 73 is 1.131555
INFO:root:FL Epoch: 150 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1089
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1089 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474851
INFO:root:Worker: 1089 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336110
INFO:root:FL Epoch: 150 Norm Difference for worker 1089 is 0.988843
INFO:root:FL Epoch: 150 Done on worker:1089
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1428
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748302
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.721025
INFO:root:FL Epoch: 150 Norm Difference for worker 1428 is 1.133034
INFO:root:FL Epoch: 150 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :306
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.624465
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.637909
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 306 is 1.115152
INFO:root:FL Epoch: 150 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :424
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534246
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509941
INFO:root:FL Epoch: 150 Norm Difference for worker 424 is 1.001798
INFO:root:FL Epoch: 150 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1357
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678142
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523458
INFO:root:FL Epoch: 150 Norm Difference for worker 1357 is 1.13696
INFO:root:FL Epoch: 150 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :441
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.829688
INFO:root:Worker: 441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.781264
INFO:root:FL Epoch: 150 Norm Difference for worker 441 is 1.231985
INFO:root:FL Epoch: 150 Done on worker:441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :62
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.673763
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.830920
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 62 is 1.111101
INFO:root:FL Epoch: 150 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :459
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534691
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455946
INFO:root:FL Epoch: 150 Norm Difference for worker 459 is 1.133182
INFO:root:FL Epoch: 150 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 424
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 150 Ends   ===================
INFO:root:Epoch:150 Global Model Test Loss:0.571503758430481 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:150 Global Model Backdoor Test Loss:0.49961547056833905                             and Backdoor Test Accuracy:75.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 151 Begins ===================
INFO:root:FL Epoch: 151 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 151 Workers Selected : [0, 1, 2, 954, 1013, 183, 593, 1646, 153, 653]
INFO:root:FL Epoch: 151 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 151 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 151 Training on worker :0
INFO:root:FL Epoch: 151 Using Learning rate : 0.00740595711865586 
INFO:root:FL Epoch: 151 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399554
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436286
INFO:root:FL Epoch: 151 Worker: 0 Backdoor Test Loss: 0.2830788567662239 Backdoor Test Accuracy: 89.16666666666667
INFO:root:FL Epoch: 151 Worker: 0 Backdoor Train Loss: 0.3354543700814247 Backdoor Train Accuracy: 87.5
INFO:root:FL Epoch: 151 Norm Difference for worker 0 is 0.289215
INFO:root:FL Epoch: 151 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1
INFO:root:FL Epoch: 151 Using Learning rate : 0.00740595711865586 
INFO:root:FL Epoch: 151 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377421
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316990
INFO:root:FL Epoch: 151 Worker: 1 Backdoor Test Loss: 0.30400583644707996 Backdoor Test Accuracy: 89.16666666666667
INFO:root:FL Epoch: 151 Worker: 1 Backdoor Train Loss: 0.33593764901161194 Backdoor Train Accuracy: 87.0
INFO:root:FL Epoch: 151 Norm Difference for worker 1 is 0.274307
INFO:root:FL Epoch: 151 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :2
INFO:root:FL Epoch: 151 Using Learning rate : 0.00740595711865586 
INFO:root:FL Epoch: 151 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509946
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496735
INFO:root:FL Epoch: 151 Worker: 2 Backdoor Test Loss: 0.28790268301963806 Backdoor Test Accuracy: 89.16666666666667
INFO:root:FL Epoch: 151 Worker: 2 Backdoor Train Loss: 0.337765109539032 Backdoor Train Accuracy: 87.0
INFO:root:FL Epoch: 151 Norm Difference for worker 2 is 0.281992
INFO:root:FL Epoch: 151 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :954
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 954 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606166
INFO:root:Worker: 954 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411710
INFO:root:FL Epoch: 151 Norm Difference for worker 954 is 1.033911
INFO:root:FL Epoch: 151 Done on worker:954
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1013
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723115
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542507
INFO:root:FL Epoch: 151 Norm Difference for worker 1013 is 1.102275
INFO:root:FL Epoch: 151 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :183
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 183 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626196
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 183 Train Epoch: 1 [0/201 (0%)]	Loss: 0.458833
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 151 Norm Difference for worker 183 is 1.087196
INFO:root:FL Epoch: 151 Done on worker:183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :593
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592593
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463618
INFO:root:FL Epoch: 151 Norm Difference for worker 593 is 1.060417
INFO:root:FL Epoch: 151 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1646
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493216
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535020
INFO:root:FL Epoch: 151 Norm Difference for worker 1646 is 0.997956
INFO:root:FL Epoch: 151 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :153
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.594519
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.413117
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 151 Norm Difference for worker 153 is 0.978232
INFO:root:FL Epoch: 151 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :653
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328474
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560165
INFO:root:FL Epoch: 151 Norm Difference for worker 653 is 1.080444
INFO:root:FL Epoch: 151 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 151 Ends   ===================
INFO:root:Epoch:151 Global Model Test Loss:0.5700511213611154 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:151 Global Model Backdoor Test Loss:0.30400583644707996                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 152 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 152 Workers Selected : [1082, 949, 1688, 734, 277, 966, 748, 886, 918, 418]
INFO:root:FL Epoch: 152 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 152 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 152 Training on worker :1082
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365489
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257582
INFO:root:FL Epoch: 152 Norm Difference for worker 1082 is 1.051618
INFO:root:FL Epoch: 152 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :949
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657091
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596981
INFO:root:FL Epoch: 152 Norm Difference for worker 949 is 1.200538
INFO:root:FL Epoch: 152 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :1688
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603277
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316114
INFO:root:FL Epoch: 152 Norm Difference for worker 1688 is 1.092441
INFO:root:FL Epoch: 152 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :734
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527813
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281237
INFO:root:FL Epoch: 152 Norm Difference for worker 734 is 1.067072
INFO:root:FL Epoch: 152 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :277
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.634495
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.525645
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 152 Norm Difference for worker 277 is 1.141657
INFO:root:FL Epoch: 152 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :966
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568328
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416289
INFO:root:FL Epoch: 152 Norm Difference for worker 966 is 1.096604
INFO:root:FL Epoch: 152 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :748
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778311
INFO:root:Worker: 748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651279
INFO:root:FL Epoch: 152 Norm Difference for worker 748 is 1.174943
INFO:root:FL Epoch: 152 Done on worker:748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :886
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542879
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587291
INFO:root:FL Epoch: 152 Norm Difference for worker 886 is 1.067854
INFO:root:FL Epoch: 152 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :918
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589128
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589209
INFO:root:FL Epoch: 152 Norm Difference for worker 918 is 1.108023
INFO:root:FL Epoch: 152 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :418
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497601
INFO:root:Worker: 418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390419
INFO:root:FL Epoch: 152 Norm Difference for worker 418 is 1.170066
INFO:root:FL Epoch: 152 Done on worker:418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1082
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 152 Ends   ===================
INFO:root:Epoch:152 Global Model Test Loss:0.6142306993989384 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:152 Global Model Backdoor Test Loss:0.28769412885109585                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 153 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 153 Workers Selected : [115, 899, 1476, 185, 482, 1640, 1042, 354, 626, 922]
INFO:root:FL Epoch: 153 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 153 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 153 Training on worker :115
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 115 Train Epoch: 0 [0/201 (0%)]	Loss: 0.863293
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 115 Train Epoch: 1 [0/201 (0%)]	Loss: 0.391348
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 115 is 1.444233
INFO:root:FL Epoch: 153 Done on worker:115
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :899
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691799
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436460
INFO:root:FL Epoch: 153 Norm Difference for worker 899 is 1.734949
INFO:root:FL Epoch: 153 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1476
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686527
INFO:root:Worker: 1476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309116
INFO:root:FL Epoch: 153 Norm Difference for worker 1476 is 1.522288
INFO:root:FL Epoch: 153 Done on worker:1476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :185
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.449074
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.285888
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 185 is 1.596993
INFO:root:FL Epoch: 153 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :482
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621957
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628656
INFO:root:FL Epoch: 153 Norm Difference for worker 482 is 1.464959
INFO:root:FL Epoch: 153 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1640
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673911
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626222
INFO:root:FL Epoch: 153 Norm Difference for worker 1640 is 1.522978
INFO:root:FL Epoch: 153 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1042
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770709
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248821
INFO:root:FL Epoch: 153 Norm Difference for worker 1042 is 1.611638
INFO:root:FL Epoch: 153 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :354
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613099
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.736844
INFO:root:FL Epoch: 153 Norm Difference for worker 354 is 1.616035
INFO:root:FL Epoch: 153 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :626
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729787
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375869
INFO:root:FL Epoch: 153 Norm Difference for worker 626 is 1.533943
INFO:root:FL Epoch: 153 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :922
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598465
INFO:root:Worker: 922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479169
INFO:root:FL Epoch: 153 Norm Difference for worker 922 is 1.616808
INFO:root:FL Epoch: 153 Done on worker:922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 115
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 153 Ends   ===================
INFO:root:Epoch:153 Global Model Test Loss:0.6147478275439319 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:153 Global Model Backdoor Test Loss:0.36842957387367886                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 154 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 154 Workers Selected : [1534, 1285, 791, 829, 1852, 1002, 160, 1586, 1575, 545]
INFO:root:FL Epoch: 154 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 154 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 154 Training on worker :1534
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577870
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326067
INFO:root:FL Epoch: 154 Norm Difference for worker 1534 is 1.330902
INFO:root:FL Epoch: 154 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1285
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597407
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439007
INFO:root:FL Epoch: 154 Norm Difference for worker 1285 is 1.265021
INFO:root:FL Epoch: 154 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :791
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376785
INFO:root:Worker: 791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469551
INFO:root:FL Epoch: 154 Norm Difference for worker 791 is 1.292299
INFO:root:FL Epoch: 154 Done on worker:791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :829
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 1.003582
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651389
INFO:root:FL Epoch: 154 Norm Difference for worker 829 is 1.389552
INFO:root:FL Epoch: 154 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1852
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327012
INFO:root:Worker: 1852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422400
INFO:root:FL Epoch: 154 Norm Difference for worker 1852 is 1.262831
INFO:root:FL Epoch: 154 Done on worker:1852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1002
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673867
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395196
INFO:root:FL Epoch: 154 Norm Difference for worker 1002 is 1.189558
INFO:root:FL Epoch: 154 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :160
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.772019
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.512760
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 154 Norm Difference for worker 160 is 1.244009
INFO:root:FL Epoch: 154 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1586
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412919
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.964630
INFO:root:FL Epoch: 154 Norm Difference for worker 1586 is 1.341643
INFO:root:FL Epoch: 154 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1575
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381978
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348757
INFO:root:FL Epoch: 154 Norm Difference for worker 1575 is 1.398244
INFO:root:FL Epoch: 154 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :545
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647174
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377846
INFO:root:FL Epoch: 154 Norm Difference for worker 545 is 1.222845
INFO:root:FL Epoch: 154 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1002
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 154 Ends   ===================
INFO:root:Epoch:154 Global Model Test Loss:0.5609645492890302 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:154 Global Model Backdoor Test Loss:0.23300732672214508                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 155 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 155 Workers Selected : [1219, 334, 82, 426, 457, 687, 836, 1157, 845, 422]
INFO:root:FL Epoch: 155 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 155 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 155 Training on worker :1219
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556571
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450952
INFO:root:FL Epoch: 155 Norm Difference for worker 1219 is 1.374425
INFO:root:FL Epoch: 155 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :334
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687929
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.416570
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 155 Norm Difference for worker 334 is 1.295967
INFO:root:FL Epoch: 155 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :82
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 82 Train Epoch: 0 [0/201 (0%)]	Loss: 0.732740
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 82 Train Epoch: 1 [0/201 (0%)]	Loss: 0.429039
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 155 Norm Difference for worker 82 is 1.316929
INFO:root:FL Epoch: 155 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :426
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511971
INFO:root:Worker: 426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446677
INFO:root:FL Epoch: 155 Norm Difference for worker 426 is 1.261947
INFO:root:FL Epoch: 155 Done on worker:426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :457
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486982
INFO:root:Worker: 457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386195
INFO:root:FL Epoch: 155 Norm Difference for worker 457 is 1.366141
INFO:root:FL Epoch: 155 Done on worker:457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :687
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619961
INFO:root:Worker: 687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503440
INFO:root:FL Epoch: 155 Norm Difference for worker 687 is 1.455604
INFO:root:FL Epoch: 155 Done on worker:687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :836
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611136
INFO:root:Worker: 836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460016
INFO:root:FL Epoch: 155 Norm Difference for worker 836 is 1.321868
INFO:root:FL Epoch: 155 Done on worker:836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1157
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.841703
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384925
INFO:root:FL Epoch: 155 Norm Difference for worker 1157 is 1.438957
INFO:root:FL Epoch: 155 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :845
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411279
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489710
INFO:root:FL Epoch: 155 Norm Difference for worker 845 is 1.352591
INFO:root:FL Epoch: 155 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :422
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587439
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625802
INFO:root:FL Epoch: 155 Norm Difference for worker 422 is 1.349776
INFO:root:FL Epoch: 155 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 426
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 155 Ends   ===================
INFO:root:Epoch:155 Global Model Test Loss:0.5426587129340452 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:155 Global Model Backdoor Test Loss:0.3009817923108737                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 156 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 156 Workers Selected : [1330, 1035, 774, 1736, 1439, 824, 957, 80, 952, 703]
INFO:root:FL Epoch: 156 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 156 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 156 Training on worker :1330
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563160
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503186
INFO:root:FL Epoch: 156 Norm Difference for worker 1330 is 1.313461
INFO:root:FL Epoch: 156 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1035
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1035 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659722
INFO:root:Worker: 1035 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532128
INFO:root:FL Epoch: 156 Norm Difference for worker 1035 is 1.356327
INFO:root:FL Epoch: 156 Done on worker:1035
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :774
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473789
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471218
INFO:root:FL Epoch: 156 Norm Difference for worker 774 is 1.260915
INFO:root:FL Epoch: 156 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1736
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556133
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680677
INFO:root:FL Epoch: 156 Norm Difference for worker 1736 is 1.272784
INFO:root:FL Epoch: 156 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1439
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 1.088377
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531654
INFO:root:FL Epoch: 156 Norm Difference for worker 1439 is 1.285019
INFO:root:FL Epoch: 156 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :824
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703479
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625546
INFO:root:FL Epoch: 156 Norm Difference for worker 824 is 1.235279
INFO:root:FL Epoch: 156 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :957
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 957 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510357
INFO:root:Worker: 957 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475586
INFO:root:FL Epoch: 156 Norm Difference for worker 957 is 1.256944
INFO:root:FL Epoch: 156 Done on worker:957
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :80
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.712614
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.414488
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 156 Norm Difference for worker 80 is 1.230111
INFO:root:FL Epoch: 156 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :952
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497365
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610493
INFO:root:FL Epoch: 156 Norm Difference for worker 952 is 1.352319
INFO:root:FL Epoch: 156 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :703
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513892
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599751
INFO:root:FL Epoch: 156 Norm Difference for worker 703 is 1.309744
INFO:root:FL Epoch: 156 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 824
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 156 Ends   ===================
INFO:root:Epoch:156 Global Model Test Loss:0.5467258288579828 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:156 Global Model Backdoor Test Loss:0.36574336389700574                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 157 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 157 Workers Selected : [1090, 1884, 1139, 349, 877, 538, 147, 1085, 1142, 98]
INFO:root:FL Epoch: 157 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 157 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 157 Training on worker :1090
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401523
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481744
INFO:root:FL Epoch: 157 Norm Difference for worker 1090 is 1.072745
INFO:root:FL Epoch: 157 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1884
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578563
INFO:root:Worker: 1884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455344
INFO:root:FL Epoch: 157 Norm Difference for worker 1884 is 1.060719
INFO:root:FL Epoch: 157 Done on worker:1884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1139
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547309
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418977
INFO:root:FL Epoch: 157 Norm Difference for worker 1139 is 1.097968
INFO:root:FL Epoch: 157 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :349
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513245
INFO:root:Worker: 349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338650
INFO:root:FL Epoch: 157 Norm Difference for worker 349 is 1.023589
INFO:root:FL Epoch: 157 Done on worker:349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :877
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548797
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581865
INFO:root:FL Epoch: 157 Norm Difference for worker 877 is 1.122477
INFO:root:FL Epoch: 157 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :538
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479341
INFO:root:Worker: 538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.805368
INFO:root:FL Epoch: 157 Norm Difference for worker 538 is 1.029102
INFO:root:FL Epoch: 157 Done on worker:538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :147
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.470727
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.523271
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 157 Norm Difference for worker 147 is 1.044568
INFO:root:FL Epoch: 157 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1085
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609023
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554091
INFO:root:FL Epoch: 157 Norm Difference for worker 1085 is 1.067878
INFO:root:FL Epoch: 157 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1142
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708450
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497006
INFO:root:FL Epoch: 157 Norm Difference for worker 1142 is 1.020004
INFO:root:FL Epoch: 157 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :98
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.636816
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.533524
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 157 Norm Difference for worker 98 is 1.060665
INFO:root:FL Epoch: 157 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 349
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 157 Ends   ===================
INFO:root:Epoch:157 Global Model Test Loss:0.5343201353269464 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:157 Global Model Backdoor Test Loss:0.314883994559447                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 158 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 158 Workers Selected : [527, 126, 1253, 917, 1316, 1311, 311, 779, 1872, 900]
INFO:root:FL Epoch: 158 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 158 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 158 Training on worker :527
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744531
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515308
INFO:root:FL Epoch: 158 Norm Difference for worker 527 is 1.053655
INFO:root:FL Epoch: 158 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :126
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.541368
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.647316
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 126 is 1.017545
INFO:root:FL Epoch: 158 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1253
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1253 Train Epoch: 0 [0/200 (0%)]	Loss: 0.837125
INFO:root:Worker: 1253 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699967
INFO:root:FL Epoch: 158 Norm Difference for worker 1253 is 1.073934
INFO:root:FL Epoch: 158 Done on worker:1253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :917
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679679
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519437
INFO:root:FL Epoch: 158 Norm Difference for worker 917 is 1.040534
INFO:root:FL Epoch: 158 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1316
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470817
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555952
INFO:root:FL Epoch: 158 Norm Difference for worker 1316 is 0.979023
INFO:root:FL Epoch: 158 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1311
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473816
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.724720
INFO:root:FL Epoch: 158 Norm Difference for worker 1311 is 1.042797
INFO:root:FL Epoch: 158 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :311
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 311 Train Epoch: 0 [0/201 (0%)]	Loss: 0.458578
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 311 Train Epoch: 1 [0/201 (0%)]	Loss: 0.421457
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 311 is 1.024233
INFO:root:FL Epoch: 158 Done on worker:311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :779
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596566
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390208
INFO:root:FL Epoch: 158 Norm Difference for worker 779 is 1.146233
INFO:root:FL Epoch: 158 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1872
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503234
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658360
INFO:root:FL Epoch: 158 Norm Difference for worker 1872 is 1.111071
INFO:root:FL Epoch: 158 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :900
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610334
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531028
INFO:root:FL Epoch: 158 Norm Difference for worker 900 is 1.099555
INFO:root:FL Epoch: 158 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1316
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 158 Ends   ===================
INFO:root:Epoch:158 Global Model Test Loss:0.5430563407785752 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:158 Global Model Backdoor Test Loss:0.26949238777160645                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 159 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 159 Workers Selected : [757, 1832, 439, 689, 232, 1446, 1516, 603, 1899, 1913]
INFO:root:FL Epoch: 159 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 159 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 159 Training on worker :757
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537663
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518718
INFO:root:FL Epoch: 159 Norm Difference for worker 757 is 1.026504
INFO:root:FL Epoch: 159 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1832
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610160
INFO:root:Worker: 1832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426693
INFO:root:FL Epoch: 159 Norm Difference for worker 1832 is 1.047836
INFO:root:FL Epoch: 159 Done on worker:1832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :439
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336859
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409976
INFO:root:FL Epoch: 159 Norm Difference for worker 439 is 1.019963
INFO:root:FL Epoch: 159 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :689
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499439
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601049
INFO:root:FL Epoch: 159 Norm Difference for worker 689 is 1.016116
INFO:root:FL Epoch: 159 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :232
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.528953
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.573145
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 159 Norm Difference for worker 232 is 0.973404
INFO:root:FL Epoch: 159 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1446
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482032
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634648
INFO:root:FL Epoch: 159 Norm Difference for worker 1446 is 1.067584
INFO:root:FL Epoch: 159 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1516
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421360
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607472
INFO:root:FL Epoch: 159 Norm Difference for worker 1516 is 0.984632
INFO:root:FL Epoch: 159 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :603
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643838
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395803
INFO:root:FL Epoch: 159 Norm Difference for worker 603 is 1.065272
INFO:root:FL Epoch: 159 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1899
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611549
INFO:root:Worker: 1899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563053
INFO:root:FL Epoch: 159 Norm Difference for worker 1899 is 1.062153
INFO:root:FL Epoch: 159 Done on worker:1899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1913
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697617
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539132
INFO:root:FL Epoch: 159 Norm Difference for worker 1913 is 1.045604
INFO:root:FL Epoch: 159 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 232
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 159 Ends   ===================
INFO:root:Epoch:159 Global Model Test Loss:0.5530134211568272 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:159 Global Model Backdoor Test Loss:0.4305484692255656                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 160 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 160 Workers Selected : [492, 665, 1803, 1792, 1299, 384, 1039, 603, 159, 209]
INFO:root:FL Epoch: 160 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 160 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 160 Training on worker :492
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671947
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455045
INFO:root:FL Epoch: 160 Norm Difference for worker 492 is 0.969873
INFO:root:FL Epoch: 160 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :665
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.832465
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621797
INFO:root:FL Epoch: 160 Norm Difference for worker 665 is 0.975445
INFO:root:FL Epoch: 160 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1803
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495850
INFO:root:Worker: 1803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457812
INFO:root:FL Epoch: 160 Norm Difference for worker 1803 is 0.99815
INFO:root:FL Epoch: 160 Done on worker:1803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1792
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633600
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485869
INFO:root:FL Epoch: 160 Norm Difference for worker 1792 is 0.938748
INFO:root:FL Epoch: 160 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1299
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1299 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607008
INFO:root:Worker: 1299 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421037
INFO:root:FL Epoch: 160 Norm Difference for worker 1299 is 0.969571
INFO:root:FL Epoch: 160 Done on worker:1299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :384
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595911
INFO:root:Worker: 384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593612
INFO:root:FL Epoch: 160 Norm Difference for worker 384 is 0.999282
INFO:root:FL Epoch: 160 Done on worker:384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1039
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1039 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613863
INFO:root:Worker: 1039 Train Epoch: 1 [0/200 (0%)]	Loss: 0.706904
INFO:root:FL Epoch: 160 Norm Difference for worker 1039 is 0.952532
INFO:root:FL Epoch: 160 Done on worker:1039
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :603
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524662
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599721
INFO:root:FL Epoch: 160 Norm Difference for worker 603 is 1.012299
INFO:root:FL Epoch: 160 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :159
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697392
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.355705
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 159 is 0.98171
INFO:root:FL Epoch: 160 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :209
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 209 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517929
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 209 Train Epoch: 1 [0/201 (0%)]	Loss: 0.457515
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 209 is 0.955002
INFO:root:FL Epoch: 160 Done on worker:209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1792
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 160 Ends   ===================
INFO:root:Epoch:160 Global Model Test Loss:0.5550069458344403 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:160 Global Model Backdoor Test Loss:0.3622766584157944                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 161 Begins ===================
INFO:root:FL Epoch: 161 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 161 Workers Selected : [0, 1, 2, 906, 1144, 1064, 596, 1021, 234, 1844]
INFO:root:FL Epoch: 161 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 161 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 161 Training on worker :0
INFO:root:FL Epoch: 161 Using Learning rate : 0.00725916396366966 
INFO:root:FL Epoch: 161 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.290236
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428781
INFO:root:FL Epoch: 161 Worker: 0 Backdoor Test Loss: 0.26820866018533707 Backdoor Test Accuracy: 90.83333333333333
INFO:root:FL Epoch: 161 Worker: 0 Backdoor Train Loss: 0.3200154840946198 Backdoor Train Accuracy: 89.0
INFO:root:FL Epoch: 161 Norm Difference for worker 0 is 0.233429
INFO:root:FL Epoch: 161 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1
INFO:root:FL Epoch: 161 Using Learning rate : 0.00725916396366966 
INFO:root:FL Epoch: 161 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547085
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279206
INFO:root:FL Epoch: 161 Worker: 1 Backdoor Test Loss: 0.26606330772240955 Backdoor Test Accuracy: 90.83333333333333
INFO:root:FL Epoch: 161 Worker: 1 Backdoor Train Loss: 0.3188671439886093 Backdoor Train Accuracy: 88.0
INFO:root:FL Epoch: 161 Norm Difference for worker 1 is 0.239356
INFO:root:FL Epoch: 161 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :2
INFO:root:FL Epoch: 161 Using Learning rate : 0.00725916396366966 
INFO:root:FL Epoch: 161 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323829
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283111
INFO:root:FL Epoch: 161 Worker: 2 Backdoor Test Loss: 0.2612927109003067 Backdoor Test Accuracy: 91.66666666666667
INFO:root:FL Epoch: 161 Worker: 2 Backdoor Train Loss: 0.31900010257959366 Backdoor Train Accuracy: 88.5
INFO:root:FL Epoch: 161 Norm Difference for worker 2 is 0.240295
INFO:root:FL Epoch: 161 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :906
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467561
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.742951
INFO:root:FL Epoch: 161 Norm Difference for worker 906 is 1.14169
INFO:root:FL Epoch: 161 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1144
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1144 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554010
INFO:root:Worker: 1144 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404240
INFO:root:FL Epoch: 161 Norm Difference for worker 1144 is 1.076449
INFO:root:FL Epoch: 161 Done on worker:1144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1064
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1064 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577329
INFO:root:Worker: 1064 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403870
INFO:root:FL Epoch: 161 Norm Difference for worker 1064 is 1.171664
INFO:root:FL Epoch: 161 Done on worker:1064
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :596
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656059
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629652
INFO:root:FL Epoch: 161 Norm Difference for worker 596 is 1.156062
INFO:root:FL Epoch: 161 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1021
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407182
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453045
INFO:root:FL Epoch: 161 Norm Difference for worker 1021 is 1.081167
INFO:root:FL Epoch: 161 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :234
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 234 Train Epoch: 0 [0/201 (0%)]	Loss: 0.495215
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 234 Train Epoch: 1 [0/201 (0%)]	Loss: 0.347783
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 161 Norm Difference for worker 234 is 1.112573
INFO:root:FL Epoch: 161 Done on worker:234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1844
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542653
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539909
INFO:root:FL Epoch: 161 Norm Difference for worker 1844 is 1.076802
INFO:root:FL Epoch: 161 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 161 Ends   ===================
INFO:root:Epoch:161 Global Model Test Loss:0.5592430304078495 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:161 Global Model Backdoor Test Loss:0.26820866018533707                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 162 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 162 Workers Selected : [941, 1390, 1941, 884, 44, 1585, 1081, 1024, 1886, 1439]
INFO:root:FL Epoch: 162 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 162 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 162 Training on worker :941
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480878
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383315
INFO:root:FL Epoch: 162 Norm Difference for worker 941 is 1.090825
INFO:root:FL Epoch: 162 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1390
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645931
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513565
INFO:root:FL Epoch: 162 Norm Difference for worker 1390 is 1.203849
INFO:root:FL Epoch: 162 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1941
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526633
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309128
INFO:root:FL Epoch: 162 Norm Difference for worker 1941 is 1.156039
INFO:root:FL Epoch: 162 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :884
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573148
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464948
INFO:root:FL Epoch: 162 Norm Difference for worker 884 is 1.179908
INFO:root:FL Epoch: 162 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :44
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 44 Train Epoch: 0 [0/201 (0%)]	Loss: 0.465072
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 44 Train Epoch: 1 [0/201 (0%)]	Loss: 0.438106
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 162 Norm Difference for worker 44 is 1.217869
INFO:root:FL Epoch: 162 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1585
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613115
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394681
INFO:root:FL Epoch: 162 Norm Difference for worker 1585 is 1.262378
INFO:root:FL Epoch: 162 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1081
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692374
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620961
INFO:root:FL Epoch: 162 Norm Difference for worker 1081 is 1.275708
INFO:root:FL Epoch: 162 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1024
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494462
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523965
INFO:root:FL Epoch: 162 Norm Difference for worker 1024 is 1.18771
INFO:root:FL Epoch: 162 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1886
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783780
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436658
INFO:root:FL Epoch: 162 Norm Difference for worker 1886 is 1.196627
INFO:root:FL Epoch: 162 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1439
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486603
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553536
INFO:root:FL Epoch: 162 Norm Difference for worker 1439 is 1.198301
INFO:root:FL Epoch: 162 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1024
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 162 Ends   ===================
INFO:root:Epoch:162 Global Model Test Loss:0.5595841144814211 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:162 Global Model Backdoor Test Loss:0.42851153016090393                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 163 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 163 Workers Selected : [1559, 1487, 359, 1586, 1338, 1840, 901, 711, 1413, 431]
INFO:root:FL Epoch: 163 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 163 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 163 Training on worker :1559
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512806
INFO:root:Worker: 1559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508800
INFO:root:FL Epoch: 163 Norm Difference for worker 1559 is 0.935916
INFO:root:FL Epoch: 163 Done on worker:1559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1487
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631035
INFO:root:Worker: 1487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473118
INFO:root:FL Epoch: 163 Norm Difference for worker 1487 is 1.027861
INFO:root:FL Epoch: 163 Done on worker:1487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :359
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551841
INFO:root:Worker: 359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657213
INFO:root:FL Epoch: 163 Norm Difference for worker 359 is 0.926131
INFO:root:FL Epoch: 163 Done on worker:359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1586
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613459
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.741463
INFO:root:FL Epoch: 163 Norm Difference for worker 1586 is 0.990895
INFO:root:FL Epoch: 163 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1338
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571779
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439505
INFO:root:FL Epoch: 163 Norm Difference for worker 1338 is 0.940063
INFO:root:FL Epoch: 163 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1840
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606330
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494645
INFO:root:FL Epoch: 163 Norm Difference for worker 1840 is 0.939462
INFO:root:FL Epoch: 163 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :901
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 901 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469242
INFO:root:Worker: 901 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409653
INFO:root:FL Epoch: 163 Norm Difference for worker 901 is 0.972102
INFO:root:FL Epoch: 163 Done on worker:901
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :711
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588819
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641298
INFO:root:FL Epoch: 163 Norm Difference for worker 711 is 0.931902
INFO:root:FL Epoch: 163 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1413
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485661
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344350
INFO:root:FL Epoch: 163 Norm Difference for worker 1413 is 0.974869
INFO:root:FL Epoch: 163 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :431
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547261
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428376
INFO:root:FL Epoch: 163 Norm Difference for worker 431 is 0.952988
INFO:root:FL Epoch: 163 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1338
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 163 Ends   ===================
INFO:root:Epoch:163 Global Model Test Loss:0.5364192689166349 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:163 Global Model Backdoor Test Loss:0.2882705107331276                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 164 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 164 Workers Selected : [1316, 898, 465, 599, 1822, 1634, 1455, 250, 791, 1388]
INFO:root:FL Epoch: 164 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 164 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 164 Training on worker :1316
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487540
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373144
INFO:root:FL Epoch: 164 Norm Difference for worker 1316 is 0.994817
INFO:root:FL Epoch: 164 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :898
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364980
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341806
INFO:root:FL Epoch: 164 Norm Difference for worker 898 is 1.144853
INFO:root:FL Epoch: 164 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :465
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641787
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464287
INFO:root:FL Epoch: 164 Norm Difference for worker 465 is 1.135671
INFO:root:FL Epoch: 164 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :599
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480436
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525521
INFO:root:FL Epoch: 164 Norm Difference for worker 599 is 1.156102
INFO:root:FL Epoch: 164 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1822
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663156
INFO:root:Worker: 1822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418127
INFO:root:FL Epoch: 164 Norm Difference for worker 1822 is 1.14247
INFO:root:FL Epoch: 164 Done on worker:1822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1634
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540516
INFO:root:Worker: 1634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556276
INFO:root:FL Epoch: 164 Norm Difference for worker 1634 is 1.151123
INFO:root:FL Epoch: 164 Done on worker:1634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1455
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.785925
INFO:root:Worker: 1455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514907
INFO:root:FL Epoch: 164 Norm Difference for worker 1455 is 1.108816
INFO:root:FL Epoch: 164 Done on worker:1455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :250
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.545204
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.644614
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 250 is 1.130429
INFO:root:FL Epoch: 164 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :791
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531728
INFO:root:Worker: 791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365246
INFO:root:FL Epoch: 164 Norm Difference for worker 791 is 1.087328
INFO:root:FL Epoch: 164 Done on worker:791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1388
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468339
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628236
INFO:root:FL Epoch: 164 Norm Difference for worker 1388 is 1.204973
INFO:root:FL Epoch: 164 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1316
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 164 Ends   ===================
INFO:root:Epoch:164 Global Model Test Loss:0.5497638811083401 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:164 Global Model Backdoor Test Loss:0.2719487076004346                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 165 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 165 Workers Selected : [1295, 1294, 1754, 782, 108, 1018, 832, 133, 12, 34]
INFO:root:FL Epoch: 165 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004
 0.1002994 0.1002994 0.1002994]
INFO:root:FL Epoch: 165 Num points on workers: [200 200 200 200 201 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 165 Training on worker :1295
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500405
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387760
INFO:root:FL Epoch: 165 Norm Difference for worker 1295 is 1.253134
INFO:root:FL Epoch: 165 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :1294
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570124
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390567
INFO:root:FL Epoch: 165 Norm Difference for worker 1294 is 1.412609
INFO:root:FL Epoch: 165 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :1754
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682182
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474906
INFO:root:FL Epoch: 165 Norm Difference for worker 1754 is 1.274197
INFO:root:FL Epoch: 165 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :782
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486007
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502116
INFO:root:FL Epoch: 165 Norm Difference for worker 782 is 1.383565
INFO:root:FL Epoch: 165 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :108
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 108 Train Epoch: 0 [0/201 (0%)]	Loss: 0.569698
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 108 Train Epoch: 1 [0/201 (0%)]	Loss: 0.267184
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 108 is 1.210931
INFO:root:FL Epoch: 165 Done on worker:108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :1018
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416714
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562263
INFO:root:FL Epoch: 165 Norm Difference for worker 1018 is 1.304966
INFO:root:FL Epoch: 165 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :832
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646024
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326257
INFO:root:FL Epoch: 165 Norm Difference for worker 832 is 1.456179
INFO:root:FL Epoch: 165 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :133
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.458099
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470955
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 133 is 1.277516
INFO:root:FL Epoch: 165 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :12
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 12 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576582
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 12 Train Epoch: 1 [0/201 (0%)]	Loss: 0.473508
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 12 is 1.314875
INFO:root:FL Epoch: 165 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :34
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 34 Train Epoch: 0 [0/201 (0%)]	Loss: 0.268011
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 34 Train Epoch: 1 [0/201 (0%)]	Loss: 0.305329
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 34 is 1.3339
INFO:root:FL Epoch: 165 Done on worker:34
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 108
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 165 Ends   ===================
INFO:root:Epoch:165 Global Model Test Loss:0.5471970018218545 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:165 Global Model Backdoor Test Loss:0.3124598413705826                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 166 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 166 Workers Selected : [319, 958, 1164, 515, 688, 1693, 1070, 1237, 1365, 936]
INFO:root:FL Epoch: 166 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 166 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 166 Training on worker :319
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 319 Train Epoch: 0 [0/201 (0%)]	Loss: 0.489790
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 319 Train Epoch: 1 [0/201 (0%)]	Loss: 0.298390
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 166 Norm Difference for worker 319 is 1.203845
INFO:root:FL Epoch: 166 Done on worker:319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :958
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733002
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649038
INFO:root:FL Epoch: 166 Norm Difference for worker 958 is 1.265402
INFO:root:FL Epoch: 166 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1164
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1164 Train Epoch: 0 [0/200 (0%)]	Loss: 0.886021
INFO:root:Worker: 1164 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509007
INFO:root:FL Epoch: 166 Norm Difference for worker 1164 is 1.256424
INFO:root:FL Epoch: 166 Done on worker:1164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :515
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590440
INFO:root:Worker: 515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708390
INFO:root:FL Epoch: 166 Norm Difference for worker 515 is 1.217454
INFO:root:FL Epoch: 166 Done on worker:515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :688
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600570
INFO:root:Worker: 688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293502
INFO:root:FL Epoch: 166 Norm Difference for worker 688 is 1.225501
INFO:root:FL Epoch: 166 Done on worker:688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1693
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715827
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654330
INFO:root:FL Epoch: 166 Norm Difference for worker 1693 is 1.235675
INFO:root:FL Epoch: 166 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1070
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480090
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537316
INFO:root:FL Epoch: 166 Norm Difference for worker 1070 is 1.298549
INFO:root:FL Epoch: 166 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1237
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722800
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454715
INFO:root:FL Epoch: 166 Norm Difference for worker 1237 is 1.191648
INFO:root:FL Epoch: 166 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1365
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409739
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587196
INFO:root:FL Epoch: 166 Norm Difference for worker 1365 is 1.237398
INFO:root:FL Epoch: 166 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :936
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576440
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522319
INFO:root:FL Epoch: 166 Norm Difference for worker 936 is 1.261003
INFO:root:FL Epoch: 166 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1693
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 166 Ends   ===================
INFO:root:Epoch:166 Global Model Test Loss:0.5342105854960049 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:166 Global Model Backdoor Test Loss:0.4298095901807149                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 167 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 167 Workers Selected : [106, 755, 81, 1241, 665, 1244, 1755, 1189, 785, 1463]
INFO:root:FL Epoch: 167 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 167 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 167 Training on worker :106
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.580388
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.534106
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 167 Norm Difference for worker 106 is 0.966852
INFO:root:FL Epoch: 167 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :755
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597895
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434946
INFO:root:FL Epoch: 167 Norm Difference for worker 755 is 1.005432
INFO:root:FL Epoch: 167 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :81
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.530779
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.585732
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 167 Norm Difference for worker 81 is 0.956989
INFO:root:FL Epoch: 167 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1241
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1241 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466692
INFO:root:Worker: 1241 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314777
INFO:root:FL Epoch: 167 Norm Difference for worker 1241 is 0.927485
INFO:root:FL Epoch: 167 Done on worker:1241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :665
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560501
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462582
INFO:root:FL Epoch: 167 Norm Difference for worker 665 is 1.003314
INFO:root:FL Epoch: 167 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1244
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360226
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400840
INFO:root:FL Epoch: 167 Norm Difference for worker 1244 is 1.024169
INFO:root:FL Epoch: 167 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1755
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428949
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512986
INFO:root:FL Epoch: 167 Norm Difference for worker 1755 is 0.996919
INFO:root:FL Epoch: 167 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1189
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1189 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557973
INFO:root:Worker: 1189 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679267
INFO:root:FL Epoch: 167 Norm Difference for worker 1189 is 0.967548
INFO:root:FL Epoch: 167 Done on worker:1189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :785
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584193
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521063
INFO:root:FL Epoch: 167 Norm Difference for worker 785 is 0.976566
INFO:root:FL Epoch: 167 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1463
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573506
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370178
INFO:root:FL Epoch: 167 Norm Difference for worker 1463 is 1.000233
INFO:root:FL Epoch: 167 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1241
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 167 Ends   ===================
INFO:root:Epoch:167 Global Model Test Loss:0.5304892904618207 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:167 Global Model Backdoor Test Loss:0.4831655075152715                             and Backdoor Test Accuracy:75.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 168 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 168 Workers Selected : [1872, 1711, 18, 202, 30, 1782, 1869, 1830, 1197, 1476]
INFO:root:FL Epoch: 168 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 168 Num points on workers: [200 200 201 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 168 Training on worker :1872
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510128
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535718
INFO:root:FL Epoch: 168 Norm Difference for worker 1872 is 1.170695
INFO:root:FL Epoch: 168 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1711
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461000
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565229
INFO:root:FL Epoch: 168 Norm Difference for worker 1711 is 1.12229
INFO:root:FL Epoch: 168 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :18
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 18 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490618
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 18 Train Epoch: 1 [0/201 (0%)]	Loss: 0.548943
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 18 is 1.091591
INFO:root:FL Epoch: 168 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :202
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.594962
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483831
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 202 is 1.116637
INFO:root:FL Epoch: 168 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :30
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 30 Train Epoch: 0 [0/201 (0%)]	Loss: 0.451870
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 30 Train Epoch: 1 [0/201 (0%)]	Loss: 0.471229
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 30 is 1.093919
INFO:root:FL Epoch: 168 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1782
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697147
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540061
INFO:root:FL Epoch: 168 Norm Difference for worker 1782 is 1.088153
INFO:root:FL Epoch: 168 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1869
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494542
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412853
INFO:root:FL Epoch: 168 Norm Difference for worker 1869 is 1.066056
INFO:root:FL Epoch: 168 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1830
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471229
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387632
INFO:root:FL Epoch: 168 Norm Difference for worker 1830 is 1.136241
INFO:root:FL Epoch: 168 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1197
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626010
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562622
INFO:root:FL Epoch: 168 Norm Difference for worker 1197 is 1.151178
INFO:root:FL Epoch: 168 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1476
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703259
INFO:root:Worker: 1476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378305
INFO:root:FL Epoch: 168 Norm Difference for worker 1476 is 1.102284
INFO:root:FL Epoch: 168 Done on worker:1476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 18
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 168 Ends   ===================
INFO:root:Epoch:168 Global Model Test Loss:0.5278452722465291 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:168 Global Model Backdoor Test Loss:0.34576651950677234                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 169 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 169 Workers Selected : [945, 273, 1442, 952, 1360, 854, 821, 1782, 807, 24]
INFO:root:FL Epoch: 169 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 169 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 169 Training on worker :945
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564965
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506454
INFO:root:FL Epoch: 169 Norm Difference for worker 945 is 1.134885
INFO:root:FL Epoch: 169 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :273
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 273 Train Epoch: 0 [0/201 (0%)]	Loss: 0.468638
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 273 Train Epoch: 1 [0/201 (0%)]	Loss: 0.438556
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 273 is 1.123924
INFO:root:FL Epoch: 169 Done on worker:273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1442
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547592
INFO:root:Worker: 1442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403367
INFO:root:FL Epoch: 169 Norm Difference for worker 1442 is 1.174204
INFO:root:FL Epoch: 169 Done on worker:1442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :952
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624183
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384527
INFO:root:FL Epoch: 169 Norm Difference for worker 952 is 1.162052
INFO:root:FL Epoch: 169 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1360
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680985
INFO:root:Worker: 1360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479239
INFO:root:FL Epoch: 169 Norm Difference for worker 1360 is 1.188359
INFO:root:FL Epoch: 169 Done on worker:1360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :854
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420819
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477907
INFO:root:FL Epoch: 169 Norm Difference for worker 854 is 1.166533
INFO:root:FL Epoch: 169 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :821
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743184
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543354
INFO:root:FL Epoch: 169 Norm Difference for worker 821 is 1.17237
INFO:root:FL Epoch: 169 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1782
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530318
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425772
INFO:root:FL Epoch: 169 Norm Difference for worker 1782 is 1.17003
INFO:root:FL Epoch: 169 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :807
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.811618
INFO:root:Worker: 807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290116
INFO:root:FL Epoch: 169 Norm Difference for worker 807 is 1.181817
INFO:root:FL Epoch: 169 Done on worker:807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :24
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.738404
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.445306
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 24 is 1.1922
INFO:root:FL Epoch: 169 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 273
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 169 Ends   ===================
INFO:root:Epoch:169 Global Model Test Loss:0.5283384112750783 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:169 Global Model Backdoor Test Loss:0.31088787317276                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 170 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 170 Workers Selected : [603, 40, 1838, 467, 350, 263, 1301, 833, 465, 863]
INFO:root:FL Epoch: 170 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 170 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 170 Training on worker :603
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716997
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455604
INFO:root:FL Epoch: 170 Norm Difference for worker 603 is 1.367971
INFO:root:FL Epoch: 170 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :40
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 40 Train Epoch: 0 [0/201 (0%)]	Loss: 0.272909
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 40 Train Epoch: 1 [0/201 (0%)]	Loss: 0.390061
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 170 Norm Difference for worker 40 is 1.221231
INFO:root:FL Epoch: 170 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1838
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654052
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318334
INFO:root:FL Epoch: 170 Norm Difference for worker 1838 is 1.267551
INFO:root:FL Epoch: 170 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :467
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500284
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415599
INFO:root:FL Epoch: 170 Norm Difference for worker 467 is 1.18324
INFO:root:FL Epoch: 170 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :350
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565753
INFO:root:Worker: 350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596285
INFO:root:FL Epoch: 170 Norm Difference for worker 350 is 1.300361
INFO:root:FL Epoch: 170 Done on worker:350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :263
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 263 Train Epoch: 0 [0/201 (0%)]	Loss: 0.579413
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 263 Train Epoch: 1 [0/201 (0%)]	Loss: 0.506551
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 170 Norm Difference for worker 263 is 1.259615
INFO:root:FL Epoch: 170 Done on worker:263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1301
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1301 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535182
INFO:root:Worker: 1301 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472361
INFO:root:FL Epoch: 170 Norm Difference for worker 1301 is 1.35381
INFO:root:FL Epoch: 170 Done on worker:1301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :833
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493132
INFO:root:Worker: 833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514383
INFO:root:FL Epoch: 170 Norm Difference for worker 833 is 1.185449
INFO:root:FL Epoch: 170 Done on worker:833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :465
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.902142
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526912
INFO:root:FL Epoch: 170 Norm Difference for worker 465 is 1.258998
INFO:root:FL Epoch: 170 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :863
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532441
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.719200
INFO:root:FL Epoch: 170 Norm Difference for worker 863 is 1.30749
INFO:root:FL Epoch: 170 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 467
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 170 Ends   ===================
INFO:root:Epoch:170 Global Model Test Loss:0.5507309033590204 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:170 Global Model Backdoor Test Loss:0.34406236559152603                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 171 Begins ===================
INFO:root:FL Epoch: 171 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 171 Workers Selected : [0, 1, 2, 694, 1305, 1063, 1767, 318, 760, 1876]
INFO:root:FL Epoch: 171 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 171 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 171 Training on worker :0
INFO:root:FL Epoch: 171 Using Learning rate : 0.0071152803894446726 
INFO:root:FL Epoch: 171 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.300658
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241474
INFO:root:FL Epoch: 171 Worker: 0 Backdoor Test Loss: 0.23694211492935816 Backdoor Test Accuracy: 90.83333333333333
INFO:root:FL Epoch: 171 Worker: 0 Backdoor Train Loss: 0.2965084418654442 Backdoor Train Accuracy: 88.5
INFO:root:FL Epoch: 171 Norm Difference for worker 0 is 0.256942
INFO:root:FL Epoch: 171 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1
INFO:root:FL Epoch: 171 Using Learning rate : 0.0071152803894446726 
INFO:root:FL Epoch: 171 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.303856
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285563
INFO:root:FL Epoch: 171 Worker: 1 Backdoor Test Loss: 0.25111735612154007 Backdoor Test Accuracy: 90.83333333333333
INFO:root:FL Epoch: 171 Worker: 1 Backdoor Train Loss: 0.29513546377420424 Backdoor Train Accuracy: 88.0
INFO:root:FL Epoch: 171 Norm Difference for worker 1 is 0.258854
INFO:root:FL Epoch: 171 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :2
INFO:root:FL Epoch: 171 Using Learning rate : 0.0071152803894446726 
INFO:root:FL Epoch: 171 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520089
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306788
INFO:root:FL Epoch: 171 Worker: 2 Backdoor Test Loss: 0.24166848758856455 Backdoor Test Accuracy: 90.83333333333333
INFO:root:FL Epoch: 171 Worker: 2 Backdoor Train Loss: 0.29675683528184893 Backdoor Train Accuracy: 89.0
INFO:root:FL Epoch: 171 Norm Difference for worker 2 is 0.256126
INFO:root:FL Epoch: 171 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :694
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512654
INFO:root:Worker: 694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625540
INFO:root:FL Epoch: 171 Norm Difference for worker 694 is 1.243685
INFO:root:FL Epoch: 171 Done on worker:694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1305
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1305 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358916
INFO:root:Worker: 1305 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490876
INFO:root:FL Epoch: 171 Norm Difference for worker 1305 is 1.321519
INFO:root:FL Epoch: 171 Done on worker:1305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1063
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499041
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553357
INFO:root:FL Epoch: 171 Norm Difference for worker 1063 is 1.32698
INFO:root:FL Epoch: 171 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1767
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558013
INFO:root:Worker: 1767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558922
INFO:root:FL Epoch: 171 Norm Difference for worker 1767 is 1.296106
INFO:root:FL Epoch: 171 Done on worker:1767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :318
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.474120
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.521272
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 171 Norm Difference for worker 318 is 1.273656
INFO:root:FL Epoch: 171 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :760
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641988
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630961
INFO:root:FL Epoch: 171 Norm Difference for worker 760 is 1.367589
INFO:root:FL Epoch: 171 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1876
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683768
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541374
INFO:root:FL Epoch: 171 Norm Difference for worker 1876 is 1.368816
INFO:root:FL Epoch: 171 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 171 Ends   ===================
INFO:root:Epoch:171 Global Model Test Loss:0.5525382669533 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:171 Global Model Backdoor Test Loss:0.23694211492935816                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 172 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 172 Workers Selected : [1003, 375, 966, 334, 312, 1747, 1294, 737, 1064, 1392]
INFO:root:FL Epoch: 172 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 172 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 172 Training on worker :1003
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476175
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381068
INFO:root:FL Epoch: 172 Norm Difference for worker 1003 is 1.308284
INFO:root:FL Epoch: 172 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :375
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500078
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402506
INFO:root:FL Epoch: 172 Norm Difference for worker 375 is 1.287836
INFO:root:FL Epoch: 172 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :966
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.831044
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545566
INFO:root:FL Epoch: 172 Norm Difference for worker 966 is 1.307722
INFO:root:FL Epoch: 172 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :334
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.269893
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.422889
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 172 Norm Difference for worker 334 is 1.345342
INFO:root:FL Epoch: 172 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :312
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.476022
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.322613
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 172 Norm Difference for worker 312 is 1.264251
INFO:root:FL Epoch: 172 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1747
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544732
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522690
INFO:root:FL Epoch: 172 Norm Difference for worker 1747 is 1.388371
INFO:root:FL Epoch: 172 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1294
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 1.264181
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625601
INFO:root:FL Epoch: 172 Norm Difference for worker 1294 is 1.435698
INFO:root:FL Epoch: 172 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :737
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477064
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466035
INFO:root:FL Epoch: 172 Norm Difference for worker 737 is 1.322613
INFO:root:FL Epoch: 172 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1064
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1064 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715333
INFO:root:Worker: 1064 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453072
INFO:root:FL Epoch: 172 Norm Difference for worker 1064 is 1.393732
INFO:root:FL Epoch: 172 Done on worker:1064
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1392
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743420
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417269
INFO:root:FL Epoch: 172 Norm Difference for worker 1392 is 1.253426
INFO:root:FL Epoch: 172 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 312
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 172 Ends   ===================
INFO:root:Epoch:172 Global Model Test Loss:0.5492803033660439 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:172 Global Model Backdoor Test Loss:0.264730562766393                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 173 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 173 Workers Selected : [1721, 1093, 1173, 968, 270, 894, 594, 1009, 1378, 906]
INFO:root:FL Epoch: 173 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 173 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 173 Training on worker :1721
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513572
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413718
INFO:root:FL Epoch: 173 Norm Difference for worker 1721 is 1.198333
INFO:root:FL Epoch: 173 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1093
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779366
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626875
INFO:root:FL Epoch: 173 Norm Difference for worker 1093 is 1.215192
INFO:root:FL Epoch: 173 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1173
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428808
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516390
INFO:root:FL Epoch: 173 Norm Difference for worker 1173 is 1.139415
INFO:root:FL Epoch: 173 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :968
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659684
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452302
INFO:root:FL Epoch: 173 Norm Difference for worker 968 is 1.335585
INFO:root:FL Epoch: 173 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :270
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.392446
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.496898
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 173 Norm Difference for worker 270 is 1.268507
INFO:root:FL Epoch: 173 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :894
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659295
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432061
INFO:root:FL Epoch: 173 Norm Difference for worker 894 is 1.247106
INFO:root:FL Epoch: 173 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :594
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485814
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636992
INFO:root:FL Epoch: 173 Norm Difference for worker 594 is 1.292373
INFO:root:FL Epoch: 173 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1009
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613401
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439061
INFO:root:FL Epoch: 173 Norm Difference for worker 1009 is 1.160673
INFO:root:FL Epoch: 173 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :1378
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741861
INFO:root:Worker: 1378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422845
INFO:root:FL Epoch: 173 Norm Difference for worker 1378 is 1.246591
INFO:root:FL Epoch: 173 Done on worker:1378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :906
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721531
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541868
INFO:root:FL Epoch: 173 Norm Difference for worker 906 is 1.255203
INFO:root:FL Epoch: 173 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1173
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 173 Ends   ===================
INFO:root:Epoch:173 Global Model Test Loss:0.5536594636300031 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:173 Global Model Backdoor Test Loss:0.29125071316957474                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 174 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 174 Workers Selected : [1667, 907, 1313, 522, 913, 1260, 1683, 925, 1459, 1264]
INFO:root:FL Epoch: 174 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 174 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 174 Training on worker :1667
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547731
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.725722
INFO:root:FL Epoch: 174 Norm Difference for worker 1667 is 1.291385
INFO:root:FL Epoch: 174 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :907
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.925922
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595947
INFO:root:FL Epoch: 174 Norm Difference for worker 907 is 1.212843
INFO:root:FL Epoch: 174 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1313
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579514
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369067
INFO:root:FL Epoch: 174 Norm Difference for worker 1313 is 1.232503
INFO:root:FL Epoch: 174 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :522
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606046
INFO:root:Worker: 522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609637
INFO:root:FL Epoch: 174 Norm Difference for worker 522 is 1.176539
INFO:root:FL Epoch: 174 Done on worker:522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :913
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644959
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410129
INFO:root:FL Epoch: 174 Norm Difference for worker 913 is 1.315721
INFO:root:FL Epoch: 174 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1260
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705054
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582216
INFO:root:FL Epoch: 174 Norm Difference for worker 1260 is 1.19649
INFO:root:FL Epoch: 174 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1683
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627506
INFO:root:Worker: 1683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542639
INFO:root:FL Epoch: 174 Norm Difference for worker 1683 is 1.273558
INFO:root:FL Epoch: 174 Done on worker:1683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :925
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461109
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570477
INFO:root:FL Epoch: 174 Norm Difference for worker 925 is 1.213406
INFO:root:FL Epoch: 174 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1459
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763909
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676928
INFO:root:FL Epoch: 174 Norm Difference for worker 1459 is 1.326409
INFO:root:FL Epoch: 174 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1264
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1264 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502938
INFO:root:Worker: 1264 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445032
INFO:root:FL Epoch: 174 Norm Difference for worker 1264 is 1.260759
INFO:root:FL Epoch: 174 Done on worker:1264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 522
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 174 Ends   ===================
INFO:root:Epoch:174 Global Model Test Loss:0.5289085191838881 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:174 Global Model Backdoor Test Loss:0.25808049986759823                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 175 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 175 Workers Selected : [850, 914, 1212, 1570, 305, 1197, 1169, 1057, 1584, 1528]
INFO:root:FL Epoch: 175 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 175 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 175 Training on worker :850
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409546
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609127
INFO:root:FL Epoch: 175 Norm Difference for worker 850 is 1.168802
INFO:root:FL Epoch: 175 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :914
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667330
INFO:root:Worker: 914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476659
INFO:root:FL Epoch: 175 Norm Difference for worker 914 is 1.19672
INFO:root:FL Epoch: 175 Done on worker:914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1212
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553426
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483523
INFO:root:FL Epoch: 175 Norm Difference for worker 1212 is 1.135977
INFO:root:FL Epoch: 175 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1570
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662938
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421781
INFO:root:FL Epoch: 175 Norm Difference for worker 1570 is 1.171279
INFO:root:FL Epoch: 175 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :305
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.528361
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.334023
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 175 Norm Difference for worker 305 is 1.06709
INFO:root:FL Epoch: 175 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1197
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758648
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598746
INFO:root:FL Epoch: 175 Norm Difference for worker 1197 is 1.191087
INFO:root:FL Epoch: 175 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1169
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597885
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448117
INFO:root:FL Epoch: 175 Norm Difference for worker 1169 is 1.142122
INFO:root:FL Epoch: 175 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1057
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1057 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556473
INFO:root:Worker: 1057 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415963
INFO:root:FL Epoch: 175 Norm Difference for worker 1057 is 1.106443
INFO:root:FL Epoch: 175 Done on worker:1057
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1584
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.817306
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506660
INFO:root:FL Epoch: 175 Norm Difference for worker 1584 is 1.147093
INFO:root:FL Epoch: 175 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1528
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552631
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475768
INFO:root:FL Epoch: 175 Norm Difference for worker 1528 is 1.068941
INFO:root:FL Epoch: 175 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 305
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 175 Ends   ===================
INFO:root:Epoch:175 Global Model Test Loss:0.5422426321927238 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:175 Global Model Backdoor Test Loss:0.3245234588781993                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 176 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 176 Workers Selected : [637, 1889, 528, 1101, 1673, 974, 1233, 787, 977, 516]
INFO:root:FL Epoch: 176 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 176 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 176 Training on worker :637
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683845
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517681
INFO:root:FL Epoch: 176 Norm Difference for worker 637 is 1.130214
INFO:root:FL Epoch: 176 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1889
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503167
INFO:root:Worker: 1889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693885
INFO:root:FL Epoch: 176 Norm Difference for worker 1889 is 1.089201
INFO:root:FL Epoch: 176 Done on worker:1889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :528
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576433
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424972
INFO:root:FL Epoch: 176 Norm Difference for worker 528 is 1.153003
INFO:root:FL Epoch: 176 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1101
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1101 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546482
INFO:root:Worker: 1101 Train Epoch: 1 [0/200 (0%)]	Loss: 0.762202
INFO:root:FL Epoch: 176 Norm Difference for worker 1101 is 0.978978
INFO:root:FL Epoch: 176 Done on worker:1101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1673
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705318
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461611
INFO:root:FL Epoch: 176 Norm Difference for worker 1673 is 1.046147
INFO:root:FL Epoch: 176 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :974
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 974 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584157
INFO:root:Worker: 974 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533556
INFO:root:FL Epoch: 176 Norm Difference for worker 974 is 0.9963
INFO:root:FL Epoch: 176 Done on worker:974
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1233
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1233 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530822
INFO:root:Worker: 1233 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445198
INFO:root:FL Epoch: 176 Norm Difference for worker 1233 is 1.159266
INFO:root:FL Epoch: 176 Done on worker:1233
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :787
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583136
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508532
INFO:root:FL Epoch: 176 Norm Difference for worker 787 is 1.080911
INFO:root:FL Epoch: 176 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :977
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697009
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581233
INFO:root:FL Epoch: 176 Norm Difference for worker 977 is 1.085844
INFO:root:FL Epoch: 176 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :516
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449738
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466072
INFO:root:FL Epoch: 176 Norm Difference for worker 516 is 1.070513
INFO:root:FL Epoch: 176 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1101
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 176 Ends   ===================
INFO:root:Epoch:176 Global Model Test Loss:0.5391686944400563 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:176 Global Model Backdoor Test Loss:0.32282287379105884                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 177 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 177 Workers Selected : [313, 908, 557, 881, 1256, 539, 8, 220, 342, 1936]
INFO:root:FL Epoch: 177 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 177 Num points on workers: [201 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 177 Training on worker :313
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.456849
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.539987
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 313 is 1.015942
INFO:root:FL Epoch: 177 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :908
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439933
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315801
INFO:root:FL Epoch: 177 Norm Difference for worker 908 is 0.944363
INFO:root:FL Epoch: 177 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :557
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698999
INFO:root:Worker: 557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614283
INFO:root:FL Epoch: 177 Norm Difference for worker 557 is 0.961744
INFO:root:FL Epoch: 177 Done on worker:557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :881
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540378
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504366
INFO:root:FL Epoch: 177 Norm Difference for worker 881 is 0.942875
INFO:root:FL Epoch: 177 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1256
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736288
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613477
INFO:root:FL Epoch: 177 Norm Difference for worker 1256 is 0.908388
INFO:root:FL Epoch: 177 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :539
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498753
INFO:root:Worker: 539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439393
INFO:root:FL Epoch: 177 Norm Difference for worker 539 is 0.979111
INFO:root:FL Epoch: 177 Done on worker:539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :8
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.669284
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.606156
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 8 is 0.929363
INFO:root:FL Epoch: 177 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :220
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 220 Train Epoch: 0 [0/201 (0%)]	Loss: 0.455904
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 220 Train Epoch: 1 [0/201 (0%)]	Loss: 0.546739
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 220 is 0.86919
INFO:root:FL Epoch: 177 Done on worker:220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :342
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617982
INFO:root:Worker: 342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569682
INFO:root:FL Epoch: 177 Norm Difference for worker 342 is 0.914353
INFO:root:FL Epoch: 177 Done on worker:342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1936
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591218
INFO:root:Worker: 1936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343388
INFO:root:FL Epoch: 177 Norm Difference for worker 1936 is 0.941597
INFO:root:FL Epoch: 177 Done on worker:1936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 220
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 177 Ends   ===================
INFO:root:Epoch:177 Global Model Test Loss:0.5353913394843831 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:177 Global Model Backdoor Test Loss:0.28562018771966297                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 178 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 178 Workers Selected : [1855, 418, 1550, 1800, 1189, 611, 325, 983, 666, 70]
INFO:root:FL Epoch: 178 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 178 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 178 Training on worker :1855
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756207
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500473
INFO:root:FL Epoch: 178 Norm Difference for worker 1855 is 1.014655
INFO:root:FL Epoch: 178 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :418
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671978
INFO:root:Worker: 418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433287
INFO:root:FL Epoch: 178 Norm Difference for worker 418 is 1.052506
INFO:root:FL Epoch: 178 Done on worker:418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1550
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410023
INFO:root:Worker: 1550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394274
INFO:root:FL Epoch: 178 Norm Difference for worker 1550 is 1.089473
INFO:root:FL Epoch: 178 Done on worker:1550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1800
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533882
INFO:root:Worker: 1800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563965
INFO:root:FL Epoch: 178 Norm Difference for worker 1800 is 1.028311
INFO:root:FL Epoch: 178 Done on worker:1800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1189
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1189 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502048
INFO:root:Worker: 1189 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397786
INFO:root:FL Epoch: 178 Norm Difference for worker 1189 is 1.027932
INFO:root:FL Epoch: 178 Done on worker:1189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :611
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696872
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491447
INFO:root:FL Epoch: 178 Norm Difference for worker 611 is 1.088751
INFO:root:FL Epoch: 178 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :325
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.363169
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428381
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 178 Norm Difference for worker 325 is 1.04064
INFO:root:FL Epoch: 178 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :983
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641666
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455108
INFO:root:FL Epoch: 178 Norm Difference for worker 983 is 1.108472
INFO:root:FL Epoch: 178 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :666
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593912
INFO:root:Worker: 666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473875
INFO:root:FL Epoch: 178 Norm Difference for worker 666 is 1.028406
INFO:root:FL Epoch: 178 Done on worker:666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :70
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.713003
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.591234
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 178 Norm Difference for worker 70 is 0.947862
INFO:root:FL Epoch: 178 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 70
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 178 Ends   ===================
INFO:root:Epoch:178 Global Model Test Loss:0.5473965669379515 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:178 Global Model Backdoor Test Loss:0.34174442291259766                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 179 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 179 Workers Selected : [1226, 1285, 972, 393, 977, 59, 575, 472, 1689, 565]
INFO:root:FL Epoch: 179 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 179 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 179 Training on worker :1226
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449505
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407462
INFO:root:FL Epoch: 179 Norm Difference for worker 1226 is 1.018214
INFO:root:FL Epoch: 179 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1285
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631446
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442499
INFO:root:FL Epoch: 179 Norm Difference for worker 1285 is 0.962667
INFO:root:FL Epoch: 179 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :972
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 972 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572221
INFO:root:Worker: 972 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404615
INFO:root:FL Epoch: 179 Norm Difference for worker 972 is 1.006372
INFO:root:FL Epoch: 179 Done on worker:972
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :393
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490642
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653830
INFO:root:FL Epoch: 179 Norm Difference for worker 393 is 0.980785
INFO:root:FL Epoch: 179 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :977
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436414
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524393
INFO:root:FL Epoch: 179 Norm Difference for worker 977 is 1.013487
INFO:root:FL Epoch: 179 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :59
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.548516
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.344443
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 179 Norm Difference for worker 59 is 0.993008
INFO:root:FL Epoch: 179 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :575
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658311
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503279
INFO:root:FL Epoch: 179 Norm Difference for worker 575 is 1.026135
INFO:root:FL Epoch: 179 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :472
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650791
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517850
INFO:root:FL Epoch: 179 Norm Difference for worker 472 is 1.014748
INFO:root:FL Epoch: 179 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1689
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.806484
INFO:root:Worker: 1689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368489
INFO:root:FL Epoch: 179 Norm Difference for worker 1689 is 1.023725
INFO:root:FL Epoch: 179 Done on worker:1689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :565
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540951
INFO:root:Worker: 565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484289
INFO:root:FL Epoch: 179 Norm Difference for worker 565 is 0.988462
INFO:root:FL Epoch: 179 Done on worker:565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1285
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 179 Ends   ===================
INFO:root:Epoch:179 Global Model Test Loss:0.5382043894599465 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:179 Global Model Backdoor Test Loss:0.34568263590335846                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 180 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 180 Workers Selected : [1850, 989, 611, 637, 1690, 1250, 844, 1444, 120, 134]
INFO:root:FL Epoch: 180 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 180 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 180 Training on worker :1850
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572192
INFO:root:Worker: 1850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433713
INFO:root:FL Epoch: 180 Norm Difference for worker 1850 is 1.033939
INFO:root:FL Epoch: 180 Done on worker:1850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :989
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 989 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461093
INFO:root:Worker: 989 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685729
INFO:root:FL Epoch: 180 Norm Difference for worker 989 is 1.06491
INFO:root:FL Epoch: 180 Done on worker:989
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :611
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533201
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484755
INFO:root:FL Epoch: 180 Norm Difference for worker 611 is 1.049955
INFO:root:FL Epoch: 180 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :637
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.830006
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539900
INFO:root:FL Epoch: 180 Norm Difference for worker 637 is 1.092937
INFO:root:FL Epoch: 180 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1690
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385270
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449960
INFO:root:FL Epoch: 180 Norm Difference for worker 1690 is 1.073665
INFO:root:FL Epoch: 180 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1250
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678742
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567830
INFO:root:FL Epoch: 180 Norm Difference for worker 1250 is 1.014279
INFO:root:FL Epoch: 180 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :844
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531354
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654419
INFO:root:FL Epoch: 180 Norm Difference for worker 844 is 0.985242
INFO:root:FL Epoch: 180 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1444
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617459
INFO:root:Worker: 1444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620238
INFO:root:FL Epoch: 180 Norm Difference for worker 1444 is 1.018996
INFO:root:FL Epoch: 180 Done on worker:1444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :120
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 120 Train Epoch: 0 [0/201 (0%)]	Loss: 0.493686
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 120 Train Epoch: 1 [0/201 (0%)]	Loss: 0.444704
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 180 Norm Difference for worker 120 is 1.051535
INFO:root:FL Epoch: 180 Done on worker:120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :134
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.461324
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.372798
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 180 Norm Difference for worker 134 is 1.004884
INFO:root:FL Epoch: 180 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 134
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 180 Ends   ===================
INFO:root:Epoch:180 Global Model Test Loss:0.5513587856993956 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:180 Global Model Backdoor Test Loss:0.33847688386837643                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 181 Begins ===================
INFO:root:FL Epoch: 181 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 181 Workers Selected : [0, 1, 2, 869, 716, 1560, 623, 1018, 195, 1034]
INFO:root:FL Epoch: 181 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 181 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 181 Training on worker :0
INFO:root:FL Epoch: 181 Using Learning rate : 0.006974248725306764 
INFO:root:FL Epoch: 181 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358099
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309083
INFO:root:FL Epoch: 181 Worker: 0 Backdoor Test Loss: 0.23214556028445563 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 181 Worker: 0 Backdoor Train Loss: 0.29471379667520525 Backdoor Train Accuracy: 89.5
INFO:root:FL Epoch: 181 Norm Difference for worker 0 is 0.224127
INFO:root:FL Epoch: 181 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1
INFO:root:FL Epoch: 181 Using Learning rate : 0.006974248725306764 
INFO:root:FL Epoch: 181 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742152
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299380
INFO:root:FL Epoch: 181 Worker: 1 Backdoor Test Loss: 0.21709534029165903 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 181 Worker: 1 Backdoor Train Loss: 0.2941247418522835 Backdoor Train Accuracy: 89.5
INFO:root:FL Epoch: 181 Norm Difference for worker 1 is 0.244017
INFO:root:FL Epoch: 181 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :2
INFO:root:FL Epoch: 181 Using Learning rate : 0.006974248725306764 
INFO:root:FL Epoch: 181 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375029
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456844
INFO:root:FL Epoch: 181 Worker: 2 Backdoor Test Loss: 0.22301329672336578 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 181 Worker: 2 Backdoor Train Loss: 0.2934458151459694 Backdoor Train Accuracy: 90.0
INFO:root:FL Epoch: 181 Norm Difference for worker 2 is 0.237744
INFO:root:FL Epoch: 181 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :869
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548061
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309915
INFO:root:FL Epoch: 181 Norm Difference for worker 869 is 1.090076
INFO:root:FL Epoch: 181 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :716
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531718
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241996
INFO:root:FL Epoch: 181 Norm Difference for worker 716 is 1.102107
INFO:root:FL Epoch: 181 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1560
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722322
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672052
INFO:root:FL Epoch: 181 Norm Difference for worker 1560 is 1.111042
INFO:root:FL Epoch: 181 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :623
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569567
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.706657
INFO:root:FL Epoch: 181 Norm Difference for worker 623 is 1.268436
INFO:root:FL Epoch: 181 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1018
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579461
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681196
INFO:root:FL Epoch: 181 Norm Difference for worker 1018 is 1.248258
INFO:root:FL Epoch: 181 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :195
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611472
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.397240
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 181 Norm Difference for worker 195 is 1.253154
INFO:root:FL Epoch: 181 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1034
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547810
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307551
INFO:root:FL Epoch: 181 Norm Difference for worker 1034 is 1.209148
INFO:root:FL Epoch: 181 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 181 Ends   ===================
INFO:root:Epoch:181 Global Model Test Loss:0.5395191627390244 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:181 Global Model Backdoor Test Loss:0.22301329672336578                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 182 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 182 Workers Selected : [1201, 1052, 959, 1624, 825, 1782, 488, 507, 1078, 1849]
INFO:root:FL Epoch: 182 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 182 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 182 Training on worker :1201
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1201 Train Epoch: 0 [0/200 (0%)]	Loss: 1.076942
INFO:root:Worker: 1201 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441666
INFO:root:FL Epoch: 182 Norm Difference for worker 1201 is 1.185009
INFO:root:FL Epoch: 182 Done on worker:1201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1052
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482154
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489301
INFO:root:FL Epoch: 182 Norm Difference for worker 1052 is 1.189202
INFO:root:FL Epoch: 182 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :959
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485156
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511400
INFO:root:FL Epoch: 182 Norm Difference for worker 959 is 1.25939
INFO:root:FL Epoch: 182 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1624
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401857
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402493
INFO:root:FL Epoch: 182 Norm Difference for worker 1624 is 1.196344
INFO:root:FL Epoch: 182 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :825
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741396
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369621
INFO:root:FL Epoch: 182 Norm Difference for worker 825 is 1.139832
INFO:root:FL Epoch: 182 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1782
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721722
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266586
INFO:root:FL Epoch: 182 Norm Difference for worker 1782 is 1.228442
INFO:root:FL Epoch: 182 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :488
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690933
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338211
INFO:root:FL Epoch: 182 Norm Difference for worker 488 is 1.273157
INFO:root:FL Epoch: 182 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :507
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715675
INFO:root:Worker: 507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378339
INFO:root:FL Epoch: 182 Norm Difference for worker 507 is 1.267891
INFO:root:FL Epoch: 182 Done on worker:507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1078
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564402
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433563
INFO:root:FL Epoch: 182 Norm Difference for worker 1078 is 1.202621
INFO:root:FL Epoch: 182 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1849
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1849 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486523
INFO:root:Worker: 1849 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450005
INFO:root:FL Epoch: 182 Norm Difference for worker 1849 is 1.214471
INFO:root:FL Epoch: 182 Done on worker:1849
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 825
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 182 Ends   ===================
INFO:root:Epoch:182 Global Model Test Loss:0.5417245854349697 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:182 Global Model Backdoor Test Loss:0.24141057829062143                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 183 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 183 Workers Selected : [1215, 1520, 630, 563, 4, 1104, 1522, 1754, 48, 1604]
INFO:root:FL Epoch: 183 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 183 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 183 Training on worker :1215
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804438
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575146
INFO:root:FL Epoch: 183 Norm Difference for worker 1215 is 1.183827
INFO:root:FL Epoch: 183 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1520
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449600
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605828
INFO:root:FL Epoch: 183 Norm Difference for worker 1520 is 1.145356
INFO:root:FL Epoch: 183 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :630
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734216
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385109
INFO:root:FL Epoch: 183 Norm Difference for worker 630 is 1.167684
INFO:root:FL Epoch: 183 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :563
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376969
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638790
INFO:root:FL Epoch: 183 Norm Difference for worker 563 is 1.145645
INFO:root:FL Epoch: 183 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :4
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 4 Train Epoch: 0 [0/201 (0%)]	Loss: 0.474338
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 4 Train Epoch: 1 [0/201 (0%)]	Loss: 0.335768
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 183 Norm Difference for worker 4 is 1.098639
INFO:root:FL Epoch: 183 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1104
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.831231
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550577
INFO:root:FL Epoch: 183 Norm Difference for worker 1104 is 1.096054
INFO:root:FL Epoch: 183 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1522
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449997
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375113
INFO:root:FL Epoch: 183 Norm Difference for worker 1522 is 1.158313
INFO:root:FL Epoch: 183 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1754
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510808
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359568
INFO:root:FL Epoch: 183 Norm Difference for worker 1754 is 1.104046
INFO:root:FL Epoch: 183 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :48
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.605227
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.600036
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 183 Norm Difference for worker 48 is 1.071239
INFO:root:FL Epoch: 183 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1604
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796720
INFO:root:Worker: 1604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648771
INFO:root:FL Epoch: 183 Norm Difference for worker 1604 is 1.188148
INFO:root:FL Epoch: 183 Done on worker:1604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1754
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 183 Ends   ===================
INFO:root:Epoch:183 Global Model Test Loss:0.5354253947734833 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:183 Global Model Backdoor Test Loss:0.24845817188421884                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 184 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 184 Workers Selected : [1775, 1560, 1234, 1381, 1244, 1478, 1887, 825, 202, 471]
INFO:root:FL Epoch: 184 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 184 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 184 Training on worker :1775
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570445
INFO:root:Worker: 1775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610446
INFO:root:FL Epoch: 184 Norm Difference for worker 1775 is 0.958401
INFO:root:FL Epoch: 184 Done on worker:1775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1560
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413842
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462544
INFO:root:FL Epoch: 184 Norm Difference for worker 1560 is 0.973918
INFO:root:FL Epoch: 184 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1234
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532026
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567532
INFO:root:FL Epoch: 184 Norm Difference for worker 1234 is 1.069168
INFO:root:FL Epoch: 184 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1381
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526900
INFO:root:Worker: 1381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517027
INFO:root:FL Epoch: 184 Norm Difference for worker 1381 is 1.019326
INFO:root:FL Epoch: 184 Done on worker:1381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1244
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540432
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514531
INFO:root:FL Epoch: 184 Norm Difference for worker 1244 is 1.008031
INFO:root:FL Epoch: 184 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1478
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351147
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421982
INFO:root:FL Epoch: 184 Norm Difference for worker 1478 is 1.011121
INFO:root:FL Epoch: 184 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1887
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432412
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370976
INFO:root:FL Epoch: 184 Norm Difference for worker 1887 is 0.951545
INFO:root:FL Epoch: 184 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :825
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366667
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250401
INFO:root:FL Epoch: 184 Norm Difference for worker 825 is 1.016945
INFO:root:FL Epoch: 184 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :202
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.714796
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685536
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 184 Norm Difference for worker 202 is 1.095338
INFO:root:FL Epoch: 184 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :471
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592601
INFO:root:Worker: 471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532281
INFO:root:FL Epoch: 184 Norm Difference for worker 471 is 1.064335
INFO:root:FL Epoch: 184 Done on worker:471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1887
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 184 Ends   ===================
INFO:root:Epoch:184 Global Model Test Loss:0.5480581925195807 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:184 Global Model Backdoor Test Loss:0.2652162065108617                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 185 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 185 Workers Selected : [1656, 1518, 1088, 559, 487, 317, 1080, 65, 1146, 56]
INFO:root:FL Epoch: 185 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 185 Num points on workers: [200 200 200 200 200 201 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 185 Training on worker :1656
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468486
INFO:root:Worker: 1656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487414
INFO:root:FL Epoch: 185 Norm Difference for worker 1656 is 1.17754
INFO:root:FL Epoch: 185 Done on worker:1656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1518
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.329908
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334162
INFO:root:FL Epoch: 185 Norm Difference for worker 1518 is 1.131767
INFO:root:FL Epoch: 185 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1088
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479881
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322109
INFO:root:FL Epoch: 185 Norm Difference for worker 1088 is 1.010709
INFO:root:FL Epoch: 185 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :559
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642361
INFO:root:Worker: 559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531841
INFO:root:FL Epoch: 185 Norm Difference for worker 559 is 1.063741
INFO:root:FL Epoch: 185 Done on worker:559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :487
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410058
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461947
INFO:root:FL Epoch: 185 Norm Difference for worker 487 is 1.051793
INFO:root:FL Epoch: 185 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :317
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 317 Train Epoch: 0 [0/201 (0%)]	Loss: 0.501509
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 317 Train Epoch: 1 [0/201 (0%)]	Loss: 0.544357
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 317 is 1.190848
INFO:root:FL Epoch: 185 Done on worker:317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1080
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638124
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576350
INFO:root:FL Epoch: 185 Norm Difference for worker 1080 is 1.239498
INFO:root:FL Epoch: 185 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :65
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 65 Train Epoch: 0 [0/201 (0%)]	Loss: 0.502898
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 65 Train Epoch: 1 [0/201 (0%)]	Loss: 0.775994
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 65 is 1.133412
INFO:root:FL Epoch: 185 Done on worker:65
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1146
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1146 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415595
INFO:root:Worker: 1146 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492232
INFO:root:FL Epoch: 185 Norm Difference for worker 1146 is 1.126752
INFO:root:FL Epoch: 185 Done on worker:1146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :56
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.479883
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.442413
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 56 is 1.144173
INFO:root:FL Epoch: 185 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1088
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 185 Ends   ===================
INFO:root:Epoch:185 Global Model Test Loss:0.5427911562078139 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:185 Global Model Backdoor Test Loss:0.23571443557739258                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 186 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 186 Workers Selected : [888, 785, 663, 1530, 738, 128, 1070, 823, 385, 503]
INFO:root:FL Epoch: 186 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 186 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 186 Training on worker :888
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549490
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673311
INFO:root:FL Epoch: 186 Norm Difference for worker 888 is 1.395297
INFO:root:FL Epoch: 186 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :785
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.847069
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.744576
INFO:root:FL Epoch: 186 Norm Difference for worker 785 is 1.349214
INFO:root:FL Epoch: 186 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :663
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665172
INFO:root:Worker: 663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371148
INFO:root:FL Epoch: 186 Norm Difference for worker 663 is 1.306979
INFO:root:FL Epoch: 186 Done on worker:663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1530
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522242
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274604
INFO:root:FL Epoch: 186 Norm Difference for worker 1530 is 1.271162
INFO:root:FL Epoch: 186 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :738
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.798409
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364922
INFO:root:FL Epoch: 186 Norm Difference for worker 738 is 1.405554
INFO:root:FL Epoch: 186 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :128
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.682830
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.501721
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 186 Norm Difference for worker 128 is 1.371204
INFO:root:FL Epoch: 186 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1070
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.877568
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464817
INFO:root:FL Epoch: 186 Norm Difference for worker 1070 is 1.332938
INFO:root:FL Epoch: 186 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :823
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502076
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542907
INFO:root:FL Epoch: 186 Norm Difference for worker 823 is 1.357958
INFO:root:FL Epoch: 186 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :385
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801466
INFO:root:Worker: 385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537312
INFO:root:FL Epoch: 186 Norm Difference for worker 385 is 1.299463
INFO:root:FL Epoch: 186 Done on worker:385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :503
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501136
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378916
INFO:root:FL Epoch: 186 Norm Difference for worker 503 is 1.280507
INFO:root:FL Epoch: 186 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 663
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 186 Ends   ===================
INFO:root:Epoch:186 Global Model Test Loss:0.5356560068971971 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:186 Global Model Backdoor Test Loss:0.29911274711290997                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 187 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 187 Workers Selected : [301, 277, 269, 1198, 545, 1043, 766, 736, 458, 1218]
INFO:root:FL Epoch: 187 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 187 Num points on workers: [201 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 187 Training on worker :301
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693123
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.477206
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 301 is 1.014808
INFO:root:FL Epoch: 187 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :277
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.564954
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.599949
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 277 is 0.99383
INFO:root:FL Epoch: 187 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :269
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 269 Train Epoch: 0 [0/201 (0%)]	Loss: 0.428585
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 269 Train Epoch: 1 [0/201 (0%)]	Loss: 0.398876
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 269 is 0.990579
INFO:root:FL Epoch: 187 Done on worker:269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1198
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607794
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393071
INFO:root:FL Epoch: 187 Norm Difference for worker 1198 is 0.955364
INFO:root:FL Epoch: 187 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :545
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428411
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529933
INFO:root:FL Epoch: 187 Norm Difference for worker 545 is 0.97162
INFO:root:FL Epoch: 187 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1043
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1043 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727217
INFO:root:Worker: 1043 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594657
INFO:root:FL Epoch: 187 Norm Difference for worker 1043 is 1.06135
INFO:root:FL Epoch: 187 Done on worker:1043
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :766
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409930
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544111
INFO:root:FL Epoch: 187 Norm Difference for worker 766 is 0.950436
INFO:root:FL Epoch: 187 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :736
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663730
INFO:root:Worker: 736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508021
INFO:root:FL Epoch: 187 Norm Difference for worker 736 is 1.010477
INFO:root:FL Epoch: 187 Done on worker:736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :458
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387365
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670588
INFO:root:FL Epoch: 187 Norm Difference for worker 458 is 1.024245
INFO:root:FL Epoch: 187 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1218
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473948
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382953
INFO:root:FL Epoch: 187 Norm Difference for worker 1218 is 0.982737
INFO:root:FL Epoch: 187 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1198
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 187 Ends   ===================
INFO:root:Epoch:187 Global Model Test Loss:0.555511450066286 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:187 Global Model Backdoor Test Loss:0.3417329639196396                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 188 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 188 Workers Selected : [1848, 77, 1719, 49, 382, 721, 1690, 1774, 1927, 433]
INFO:root:FL Epoch: 188 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 188 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 188 Training on worker :1848
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581583
INFO:root:Worker: 1848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412531
INFO:root:FL Epoch: 188 Norm Difference for worker 1848 is 0.984474
INFO:root:FL Epoch: 188 Done on worker:1848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :77
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.624353
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.641574
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 188 Norm Difference for worker 77 is 0.99035
INFO:root:FL Epoch: 188 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1719
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556429
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580761
INFO:root:FL Epoch: 188 Norm Difference for worker 1719 is 1.008029
INFO:root:FL Epoch: 188 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :49
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 49 Train Epoch: 0 [0/201 (0%)]	Loss: 0.817502
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 49 Train Epoch: 1 [0/201 (0%)]	Loss: 0.551390
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 188 Norm Difference for worker 49 is 1.038967
INFO:root:FL Epoch: 188 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :382
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665824
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439078
INFO:root:FL Epoch: 188 Norm Difference for worker 382 is 0.96549
INFO:root:FL Epoch: 188 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :721
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701530
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580165
INFO:root:FL Epoch: 188 Norm Difference for worker 721 is 1.062376
INFO:root:FL Epoch: 188 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1690
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398932
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517936
INFO:root:FL Epoch: 188 Norm Difference for worker 1690 is 1.046769
INFO:root:FL Epoch: 188 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1774
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436492
INFO:root:Worker: 1774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690703
INFO:root:FL Epoch: 188 Norm Difference for worker 1774 is 0.997887
INFO:root:FL Epoch: 188 Done on worker:1774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1927
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750346
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541990
INFO:root:FL Epoch: 188 Norm Difference for worker 1927 is 1.002853
INFO:root:FL Epoch: 188 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :433
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762360
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572900
INFO:root:FL Epoch: 188 Norm Difference for worker 433 is 1.010122
INFO:root:FL Epoch: 188 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1848
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 188 Ends   ===================
INFO:root:Epoch:188 Global Model Test Loss:0.5260587545002208 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:188 Global Model Backdoor Test Loss:0.25451240688562393                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 189 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 189 Workers Selected : [486, 1170, 1606, 1307, 901, 556, 740, 927, 270, 488]
INFO:root:FL Epoch: 189 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 189 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 189 Training on worker :486
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439140
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468702
INFO:root:FL Epoch: 189 Norm Difference for worker 486 is 0.963658
INFO:root:FL Epoch: 189 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1170
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1170 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464310
INFO:root:Worker: 1170 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589372
INFO:root:FL Epoch: 189 Norm Difference for worker 1170 is 1.064687
INFO:root:FL Epoch: 189 Done on worker:1170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1606
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434672
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461337
INFO:root:FL Epoch: 189 Norm Difference for worker 1606 is 1.003339
INFO:root:FL Epoch: 189 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1307
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559372
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331498
INFO:root:FL Epoch: 189 Norm Difference for worker 1307 is 0.98966
INFO:root:FL Epoch: 189 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :901
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 901 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604274
INFO:root:Worker: 901 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522370
INFO:root:FL Epoch: 189 Norm Difference for worker 901 is 1.011646
INFO:root:FL Epoch: 189 Done on worker:901
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :556
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472156
INFO:root:Worker: 556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599084
INFO:root:FL Epoch: 189 Norm Difference for worker 556 is 1.014511
INFO:root:FL Epoch: 189 Done on worker:556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :740
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450093
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448524
INFO:root:FL Epoch: 189 Norm Difference for worker 740 is 1.037978
INFO:root:FL Epoch: 189 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :927
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460481
INFO:root:Worker: 927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517250
INFO:root:FL Epoch: 189 Norm Difference for worker 927 is 0.953282
INFO:root:FL Epoch: 189 Done on worker:927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :270
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.544747
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.459186
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 189 Norm Difference for worker 270 is 1.044846
INFO:root:FL Epoch: 189 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :488
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643004
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644898
INFO:root:FL Epoch: 189 Norm Difference for worker 488 is 1.090029
INFO:root:FL Epoch: 189 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 927
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 189 Ends   ===================
INFO:root:Epoch:189 Global Model Test Loss:0.5059397588757908 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:189 Global Model Backdoor Test Loss:0.19475872566302618                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 190 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 190 Workers Selected : [256, 751, 1156, 1330, 859, 257, 1432, 1824, 1730, 608]
INFO:root:FL Epoch: 190 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 190 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 190 Training on worker :256
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 256 Train Epoch: 0 [0/201 (0%)]	Loss: 0.421627
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 256 Train Epoch: 1 [0/201 (0%)]	Loss: 0.422659
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 190 Norm Difference for worker 256 is 1.194504
INFO:root:FL Epoch: 190 Done on worker:256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :751
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743199
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413540
INFO:root:FL Epoch: 190 Norm Difference for worker 751 is 1.108871
INFO:root:FL Epoch: 190 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1156
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655428
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571876
INFO:root:FL Epoch: 190 Norm Difference for worker 1156 is 1.229463
INFO:root:FL Epoch: 190 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1330
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613517
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366830
INFO:root:FL Epoch: 190 Norm Difference for worker 1330 is 1.231212
INFO:root:FL Epoch: 190 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :859
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803267
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369870
INFO:root:FL Epoch: 190 Norm Difference for worker 859 is 1.217297
INFO:root:FL Epoch: 190 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :257
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.439443
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.271486
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 190 Norm Difference for worker 257 is 1.244752
INFO:root:FL Epoch: 190 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1432
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532578
INFO:root:Worker: 1432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500974
INFO:root:FL Epoch: 190 Norm Difference for worker 1432 is 1.190849
INFO:root:FL Epoch: 190 Done on worker:1432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1824
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730126
INFO:root:Worker: 1824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.729347
INFO:root:FL Epoch: 190 Norm Difference for worker 1824 is 1.239586
INFO:root:FL Epoch: 190 Done on worker:1824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1730
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736197
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401390
INFO:root:FL Epoch: 190 Norm Difference for worker 1730 is 1.190056
INFO:root:FL Epoch: 190 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :608
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.964658
INFO:root:Worker: 608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561377
INFO:root:FL Epoch: 190 Norm Difference for worker 608 is 1.165335
INFO:root:FL Epoch: 190 Done on worker:608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 751
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 190 Ends   ===================
INFO:root:Epoch:190 Global Model Test Loss:0.5033257305622101 and Test Accuracy:75.0 
INFO:root:Epoch:190 Global Model Backdoor Test Loss:0.2969512691100438                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 191 Begins ===================
INFO:root:FL Epoch: 191 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 191 Workers Selected : [0, 1, 2, 1898, 555, 925, 113, 1363, 1837, 781]
INFO:root:FL Epoch: 191 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 191 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 191 Training on worker :0
INFO:root:FL Epoch: 191 Using Learning rate : 0.006836012443669737 
INFO:root:FL Epoch: 191 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.240104
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405222
INFO:root:FL Epoch: 191 Worker: 0 Backdoor Test Loss: 0.19285442680120468 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 191 Worker: 0 Backdoor Train Loss: 0.27995310723781586 Backdoor Train Accuracy: 89.0
INFO:root:FL Epoch: 191 Norm Difference for worker 0 is 0.223418
INFO:root:FL Epoch: 191 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1
INFO:root:FL Epoch: 191 Using Learning rate : 0.006836012443669737 
INFO:root:FL Epoch: 191 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675859
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438081
INFO:root:FL Epoch: 191 Worker: 1 Backdoor Test Loss: 0.1855476995309194 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 191 Worker: 1 Backdoor Train Loss: 0.2814880445599556 Backdoor Train Accuracy: 89.5
INFO:root:FL Epoch: 191 Norm Difference for worker 1 is 0.226968
INFO:root:FL Epoch: 191 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :2
INFO:root:FL Epoch: 191 Using Learning rate : 0.006836012443669737 
INFO:root:FL Epoch: 191 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.208648
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341582
INFO:root:FL Epoch: 191 Worker: 2 Backdoor Test Loss: 0.18828203777472177 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 191 Worker: 2 Backdoor Train Loss: 0.28076967895030974 Backdoor Train Accuracy: 89.0
INFO:root:FL Epoch: 191 Norm Difference for worker 2 is 0.222401
INFO:root:FL Epoch: 191 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1898
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570806
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531458
INFO:root:FL Epoch: 191 Norm Difference for worker 1898 is 1.121446
INFO:root:FL Epoch: 191 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :555
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592459
INFO:root:Worker: 555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493694
INFO:root:FL Epoch: 191 Norm Difference for worker 555 is 1.029756
INFO:root:FL Epoch: 191 Done on worker:555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :925
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374861
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425730
INFO:root:FL Epoch: 191 Norm Difference for worker 925 is 1.026114
INFO:root:FL Epoch: 191 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :113
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 113 Train Epoch: 0 [0/201 (0%)]	Loss: 0.445004
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 113 Train Epoch: 1 [0/201 (0%)]	Loss: 0.427251
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 191 Norm Difference for worker 113 is 0.951591
INFO:root:FL Epoch: 191 Done on worker:113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1363
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714371
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448605
INFO:root:FL Epoch: 191 Norm Difference for worker 1363 is 1.083561
INFO:root:FL Epoch: 191 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1837
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403327
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497452
INFO:root:FL Epoch: 191 Norm Difference for worker 1837 is 0.994044
INFO:root:FL Epoch: 191 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :781
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769886
INFO:root:Worker: 781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589940
INFO:root:FL Epoch: 191 Norm Difference for worker 781 is 1.024157
INFO:root:FL Epoch: 191 Done on worker:781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 191 Ends   ===================
INFO:root:Epoch:191 Global Model Test Loss:0.49795610413831826 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:191 Global Model Backdoor Test Loss:0.19285442680120468                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 192 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 192 Workers Selected : [562, 1742, 947, 406, 1259, 390, 1140, 1411, 66, 468]
INFO:root:FL Epoch: 192 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 192 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 192 Training on worker :562
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421359
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345720
INFO:root:FL Epoch: 192 Norm Difference for worker 562 is 1.154437
INFO:root:FL Epoch: 192 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1742
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536337
INFO:root:Worker: 1742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500861
INFO:root:FL Epoch: 192 Norm Difference for worker 1742 is 1.126235
INFO:root:FL Epoch: 192 Done on worker:1742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :947
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629672
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482238
INFO:root:FL Epoch: 192 Norm Difference for worker 947 is 1.090374
INFO:root:FL Epoch: 192 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :406
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562732
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583566
INFO:root:FL Epoch: 192 Norm Difference for worker 406 is 1.224748
INFO:root:FL Epoch: 192 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1259
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.907049
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480434
INFO:root:FL Epoch: 192 Norm Difference for worker 1259 is 1.088699
INFO:root:FL Epoch: 192 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :390
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594261
INFO:root:Worker: 390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536734
INFO:root:FL Epoch: 192 Norm Difference for worker 390 is 1.19566
INFO:root:FL Epoch: 192 Done on worker:390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1140
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 1.201461
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333017
INFO:root:FL Epoch: 192 Norm Difference for worker 1140 is 1.185856
INFO:root:FL Epoch: 192 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1411
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.821863
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587023
INFO:root:FL Epoch: 192 Norm Difference for worker 1411 is 1.09605
INFO:root:FL Epoch: 192 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :66
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.459882
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.389595
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 192 Norm Difference for worker 66 is 1.056168
INFO:root:FL Epoch: 192 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :468
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762871
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463773
INFO:root:FL Epoch: 192 Norm Difference for worker 468 is 1.113782
INFO:root:FL Epoch: 192 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1259
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 192 Ends   ===================
INFO:root:Epoch:192 Global Model Test Loss:0.5153965055942535 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:192 Global Model Backdoor Test Loss:0.32274559140205383                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 193 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 193 Workers Selected : [1614, 504, 1022, 580, 1730, 828, 1619, 1205, 511, 1270]
INFO:root:FL Epoch: 193 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 193 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 193 Training on worker :1614
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644806
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460461
INFO:root:FL Epoch: 193 Norm Difference for worker 1614 is 0.987181
INFO:root:FL Epoch: 193 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :504
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552803
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383931
INFO:root:FL Epoch: 193 Norm Difference for worker 504 is 0.912764
INFO:root:FL Epoch: 193 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1022
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684250
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452601
INFO:root:FL Epoch: 193 Norm Difference for worker 1022 is 0.905348
INFO:root:FL Epoch: 193 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :580
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636634
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379928
INFO:root:FL Epoch: 193 Norm Difference for worker 580 is 0.936672
INFO:root:FL Epoch: 193 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1730
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457267
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507001
INFO:root:FL Epoch: 193 Norm Difference for worker 1730 is 0.914658
INFO:root:FL Epoch: 193 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :828
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540869
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463050
INFO:root:FL Epoch: 193 Norm Difference for worker 828 is 1.044051
INFO:root:FL Epoch: 193 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1619
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757895
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535514
INFO:root:FL Epoch: 193 Norm Difference for worker 1619 is 0.932633
INFO:root:FL Epoch: 193 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1205
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677035
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528065
INFO:root:FL Epoch: 193 Norm Difference for worker 1205 is 0.915962
INFO:root:FL Epoch: 193 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :511
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540069
INFO:root:Worker: 511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565847
INFO:root:FL Epoch: 193 Norm Difference for worker 511 is 0.9099
INFO:root:FL Epoch: 193 Done on worker:511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1270
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475605
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424394
INFO:root:FL Epoch: 193 Norm Difference for worker 1270 is 0.869703
INFO:root:FL Epoch: 193 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1270
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 193 Ends   ===================
INFO:root:Epoch:193 Global Model Test Loss:0.5142467057003695 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:193 Global Model Backdoor Test Loss:0.20906242479880652                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 194 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 194 Workers Selected : [135, 1532, 1525, 103, 1790, 752, 784, 630, 1283, 1290]
INFO:root:FL Epoch: 194 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 194 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 194 Training on worker :135
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 135 Train Epoch: 0 [0/201 (0%)]	Loss: 0.501512
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 135 Train Epoch: 1 [0/201 (0%)]	Loss: 0.585983
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 194 Norm Difference for worker 135 is 1.079039
INFO:root:FL Epoch: 194 Done on worker:135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1532
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421224
INFO:root:Worker: 1532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487236
INFO:root:FL Epoch: 194 Norm Difference for worker 1532 is 1.014931
INFO:root:FL Epoch: 194 Done on worker:1532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1525
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705587
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506140
INFO:root:FL Epoch: 194 Norm Difference for worker 1525 is 1.08595
INFO:root:FL Epoch: 194 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :103
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.631520
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447759
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 194 Norm Difference for worker 103 is 1.117394
INFO:root:FL Epoch: 194 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1790
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633604
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393596
INFO:root:FL Epoch: 194 Norm Difference for worker 1790 is 1.041186
INFO:root:FL Epoch: 194 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :752
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396699
INFO:root:Worker: 752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702754
INFO:root:FL Epoch: 194 Norm Difference for worker 752 is 1.086202
INFO:root:FL Epoch: 194 Done on worker:752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :784
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481080
INFO:root:Worker: 784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387567
INFO:root:FL Epoch: 194 Norm Difference for worker 784 is 1.037468
INFO:root:FL Epoch: 194 Done on worker:784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :630
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736365
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704615
INFO:root:FL Epoch: 194 Norm Difference for worker 630 is 1.135219
INFO:root:FL Epoch: 194 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1283
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1283 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486473
INFO:root:Worker: 1283 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432222
INFO:root:FL Epoch: 194 Norm Difference for worker 1283 is 1.059894
INFO:root:FL Epoch: 194 Done on worker:1283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1290
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615477
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325424
INFO:root:FL Epoch: 194 Norm Difference for worker 1290 is 0.996049
INFO:root:FL Epoch: 194 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1290
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 194 Ends   ===================
INFO:root:Epoch:194 Global Model Test Loss:0.514086465625202 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:194 Global Model Backdoor Test Loss:0.18089352051417032                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 195 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 195 Workers Selected : [926, 191, 1426, 261, 874, 700, 7, 301, 502, 1471]
INFO:root:FL Epoch: 195 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.1002994
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 195 Num points on workers: [200 201 200 201 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 195 Training on worker :926
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385442
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464810
INFO:root:FL Epoch: 195 Norm Difference for worker 926 is 1.072838
INFO:root:FL Epoch: 195 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :191
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.922420
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.492819
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 191 is 1.134896
INFO:root:FL Epoch: 195 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :1426
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527271
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529809
INFO:root:FL Epoch: 195 Norm Difference for worker 1426 is 1.233301
INFO:root:FL Epoch: 195 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :261
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.673870
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.451139
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 261 is 1.079093
INFO:root:FL Epoch: 195 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :874
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572238
INFO:root:Worker: 874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501476
INFO:root:FL Epoch: 195 Norm Difference for worker 874 is 1.110999
INFO:root:FL Epoch: 195 Done on worker:874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :700
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738609
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386328
INFO:root:FL Epoch: 195 Norm Difference for worker 700 is 1.098421
INFO:root:FL Epoch: 195 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :7
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 7 Train Epoch: 0 [0/201 (0%)]	Loss: 0.588581
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 7 Train Epoch: 1 [0/201 (0%)]	Loss: 0.597874
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 7 is 1.128429
INFO:root:FL Epoch: 195 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :301
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.774121
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.456190
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 301 is 1.130811
INFO:root:FL Epoch: 195 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :502
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618329
INFO:root:Worker: 502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496628
INFO:root:FL Epoch: 195 Norm Difference for worker 502 is 1.040653
INFO:root:FL Epoch: 195 Done on worker:502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :1471
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626444
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465501
INFO:root:FL Epoch: 195 Norm Difference for worker 1471 is 1.102708
INFO:root:FL Epoch: 195 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 926
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 195 Ends   ===================
INFO:root:Epoch:195 Global Model Test Loss:0.5065562093959135 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:195 Global Model Backdoor Test Loss:0.24556190023819605                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 196 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 196 Workers Selected : [437, 91, 1524, 130, 478, 911, 1227, 1529, 1567, 633]
INFO:root:FL Epoch: 196 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 196 Num points on workers: [200 201 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 196 Training on worker :437
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636996
INFO:root:Worker: 437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438785
INFO:root:FL Epoch: 196 Norm Difference for worker 437 is 0.963203
INFO:root:FL Epoch: 196 Done on worker:437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :91
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.822319
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.452420
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 196 Norm Difference for worker 91 is 1.065722
INFO:root:FL Epoch: 196 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1524
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535903
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502149
INFO:root:FL Epoch: 196 Norm Difference for worker 1524 is 1.030319
INFO:root:FL Epoch: 196 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :130
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 130 Train Epoch: 0 [0/201 (0%)]	Loss: 0.709214
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 130 Train Epoch: 1 [0/201 (0%)]	Loss: 0.537868
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 196 Norm Difference for worker 130 is 1.018586
INFO:root:FL Epoch: 196 Done on worker:130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :478
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462521
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.780365
INFO:root:FL Epoch: 196 Norm Difference for worker 478 is 1.124995
INFO:root:FL Epoch: 196 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :911
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518988
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525409
INFO:root:FL Epoch: 196 Norm Difference for worker 911 is 1.043916
INFO:root:FL Epoch: 196 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1227
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1227 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472812
INFO:root:Worker: 1227 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378191
INFO:root:FL Epoch: 196 Norm Difference for worker 1227 is 1.046899
INFO:root:FL Epoch: 196 Done on worker:1227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1529
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759021
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436957
INFO:root:FL Epoch: 196 Norm Difference for worker 1529 is 1.029059
INFO:root:FL Epoch: 196 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1567
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718005
INFO:root:Worker: 1567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360090
INFO:root:FL Epoch: 196 Norm Difference for worker 1567 is 1.091262
INFO:root:FL Epoch: 196 Done on worker:1567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :633
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435016
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624116
INFO:root:FL Epoch: 196 Norm Difference for worker 633 is 0.953896
INFO:root:FL Epoch: 196 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 633
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 196 Ends   ===================
INFO:root:Epoch:196 Global Model Test Loss:0.5048918513690724 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:196 Global Model Backdoor Test Loss:0.2572648450732231                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 197 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 197 Workers Selected : [1836, 1738, 552, 80, 1244, 932, 1049, 1589, 208, 677]
INFO:root:FL Epoch: 197 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 197 Num points on workers: [200 200 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 197 Training on worker :1836
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479730
INFO:root:Worker: 1836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256073
INFO:root:FL Epoch: 197 Norm Difference for worker 1836 is 1.036474
INFO:root:FL Epoch: 197 Done on worker:1836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1738
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722987
INFO:root:Worker: 1738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.781226
INFO:root:FL Epoch: 197 Norm Difference for worker 1738 is 1.161765
INFO:root:FL Epoch: 197 Done on worker:1738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :552
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500017
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702803
INFO:root:FL Epoch: 197 Norm Difference for worker 552 is 1.069907
INFO:root:FL Epoch: 197 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :80
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.570182
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.703213
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 197 Norm Difference for worker 80 is 1.06348
INFO:root:FL Epoch: 197 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1244
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1244 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473668
INFO:root:Worker: 1244 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645891
INFO:root:FL Epoch: 197 Norm Difference for worker 1244 is 1.08609
INFO:root:FL Epoch: 197 Done on worker:1244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :932
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483350
INFO:root:Worker: 932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440412
INFO:root:FL Epoch: 197 Norm Difference for worker 932 is 1.085805
INFO:root:FL Epoch: 197 Done on worker:932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1049
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1049 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705437
INFO:root:Worker: 1049 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547286
INFO:root:FL Epoch: 197 Norm Difference for worker 1049 is 1.061751
INFO:root:FL Epoch: 197 Done on worker:1049
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1589
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757098
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447088
INFO:root:FL Epoch: 197 Norm Difference for worker 1589 is 1.122064
INFO:root:FL Epoch: 197 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :208
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.509772
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.353493
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 197 Norm Difference for worker 208 is 1.092163
INFO:root:FL Epoch: 197 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :677
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400491
INFO:root:Worker: 677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546309
INFO:root:FL Epoch: 197 Norm Difference for worker 677 is 1.0806
INFO:root:FL Epoch: 197 Done on worker:677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1049
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 197 Ends   ===================
INFO:root:Epoch:197 Global Model Test Loss:0.5121833541814018 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:197 Global Model Backdoor Test Loss:0.33251819759607315                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 198 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 198 Workers Selected : [1491, 1790, 1639, 1719, 448, 1768, 1077, 1215, 1640, 1128]
INFO:root:FL Epoch: 198 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 198 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 198 Training on worker :1491
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783196
INFO:root:Worker: 1491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431920
INFO:root:FL Epoch: 198 Norm Difference for worker 1491 is 0.999315
INFO:root:FL Epoch: 198 Done on worker:1491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1790
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393519
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502350
INFO:root:FL Epoch: 198 Norm Difference for worker 1790 is 0.980994
INFO:root:FL Epoch: 198 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1639
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557073
INFO:root:Worker: 1639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473111
INFO:root:FL Epoch: 198 Norm Difference for worker 1639 is 1.022031
INFO:root:FL Epoch: 198 Done on worker:1639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1719
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525004
INFO:root:Worker: 1719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384711
INFO:root:FL Epoch: 198 Norm Difference for worker 1719 is 1.004957
INFO:root:FL Epoch: 198 Done on worker:1719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :448
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802061
INFO:root:Worker: 448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563155
INFO:root:FL Epoch: 198 Norm Difference for worker 448 is 0.980677
INFO:root:FL Epoch: 198 Done on worker:448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1768
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499823
INFO:root:Worker: 1768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536700
INFO:root:FL Epoch: 198 Norm Difference for worker 1768 is 1.002399
INFO:root:FL Epoch: 198 Done on worker:1768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1077
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1077 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399098
INFO:root:Worker: 1077 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398581
INFO:root:FL Epoch: 198 Norm Difference for worker 1077 is 0.969145
INFO:root:FL Epoch: 198 Done on worker:1077
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1215
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374913
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449717
INFO:root:FL Epoch: 198 Norm Difference for worker 1215 is 0.974151
INFO:root:FL Epoch: 198 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1640
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384757
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504771
INFO:root:FL Epoch: 198 Norm Difference for worker 1640 is 1.024488
INFO:root:FL Epoch: 198 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1128
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460029
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453922
INFO:root:FL Epoch: 198 Norm Difference for worker 1128 is 1.001178
INFO:root:FL Epoch: 198 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1215
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 198 Ends   ===================
INFO:root:Epoch:198 Global Model Test Loss:0.5210816877729753 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:198 Global Model Backdoor Test Loss:0.2332971766591072                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 199 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 199 Workers Selected : [180, 1879, 1185, 280, 1055, 1690, 722, 933, 1874, 1457]
INFO:root:FL Epoch: 199 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 199 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 199 Training on worker :180
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.487277
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.336302
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 199 Norm Difference for worker 180 is 1.0174
INFO:root:FL Epoch: 199 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1879
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471769
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514758
INFO:root:FL Epoch: 199 Norm Difference for worker 1879 is 1.021524
INFO:root:FL Epoch: 199 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1185
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1185 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726917
INFO:root:Worker: 1185 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679825
INFO:root:FL Epoch: 199 Norm Difference for worker 1185 is 0.949546
INFO:root:FL Epoch: 199 Done on worker:1185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :280
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 280 Train Epoch: 0 [0/201 (0%)]	Loss: 0.479851
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 280 Train Epoch: 1 [0/201 (0%)]	Loss: 0.555483
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 199 Norm Difference for worker 280 is 0.951065
INFO:root:FL Epoch: 199 Done on worker:280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1055
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1055 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341568
INFO:root:Worker: 1055 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503743
INFO:root:FL Epoch: 199 Norm Difference for worker 1055 is 0.970756
INFO:root:FL Epoch: 199 Done on worker:1055
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1690
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592396
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614175
INFO:root:FL Epoch: 199 Norm Difference for worker 1690 is 1.016195
INFO:root:FL Epoch: 199 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :722
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.907384
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453852
INFO:root:FL Epoch: 199 Norm Difference for worker 722 is 0.968073
INFO:root:FL Epoch: 199 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :933
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 933 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534725
INFO:root:Worker: 933 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589397
INFO:root:FL Epoch: 199 Norm Difference for worker 933 is 0.996634
INFO:root:FL Epoch: 199 Done on worker:933
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1874
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428269
INFO:root:Worker: 1874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346478
INFO:root:FL Epoch: 199 Norm Difference for worker 1874 is 0.937111
INFO:root:FL Epoch: 199 Done on worker:1874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1457
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640708
INFO:root:Worker: 1457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466967
INFO:root:FL Epoch: 199 Norm Difference for worker 1457 is 0.992934
INFO:root:FL Epoch: 199 Done on worker:1457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1874
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 199 Ends   ===================
INFO:root:Epoch:199 Global Model Test Loss:0.5092555933138904 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:199 Global Model Backdoor Test Loss:0.20991571992635727                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 200 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 200 Workers Selected : [487, 707, 38, 996, 1140, 1706, 765, 1194, 1234, 1892]
INFO:root:FL Epoch: 200 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 200 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 200 Training on worker :487
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538748
INFO:root:Worker: 487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251580
INFO:root:FL Epoch: 200 Norm Difference for worker 487 is 0.939485
INFO:root:FL Epoch: 200 Done on worker:487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :707
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690828
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436168
INFO:root:FL Epoch: 200 Norm Difference for worker 707 is 1.049854
INFO:root:FL Epoch: 200 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :38
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.437416
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.306438
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 200 Norm Difference for worker 38 is 0.992032
INFO:root:FL Epoch: 200 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :996
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495338
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397072
INFO:root:FL Epoch: 200 Norm Difference for worker 996 is 1.033984
INFO:root:FL Epoch: 200 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1140
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452763
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.747830
INFO:root:FL Epoch: 200 Norm Difference for worker 1140 is 1.09326
INFO:root:FL Epoch: 200 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1706
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1706 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484276
INFO:root:Worker: 1706 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333278
INFO:root:FL Epoch: 200 Norm Difference for worker 1706 is 1.030833
INFO:root:FL Epoch: 200 Done on worker:1706
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :765
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462003
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670928
INFO:root:FL Epoch: 200 Norm Difference for worker 765 is 1.075218
INFO:root:FL Epoch: 200 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1194
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1194 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587419
INFO:root:Worker: 1194 Train Epoch: 1 [0/200 (0%)]	Loss: 0.800722
INFO:root:FL Epoch: 200 Norm Difference for worker 1194 is 1.20212
INFO:root:FL Epoch: 200 Done on worker:1194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1234
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606360
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358311
INFO:root:FL Epoch: 200 Norm Difference for worker 1234 is 1.074346
INFO:root:FL Epoch: 200 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1892
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.284894
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510257
INFO:root:FL Epoch: 200 Norm Difference for worker 1892 is 1.006391
INFO:root:FL Epoch: 200 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 487
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 200 Ends   ===================
INFO:root:Epoch:200 Global Model Test Loss:0.5086837603765375 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:200 Global Model Backdoor Test Loss:0.2394923468430837                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 201 Begins ===================
INFO:root:FL Epoch: 201 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 201 Workers Selected : [0, 1, 2, 1449, 1835, 1755, 22, 1640, 544, 122]
INFO:root:FL Epoch: 201 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 201 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 201 Training on worker :0
INFO:root:FL Epoch: 201 Using Learning rate : 0.006700516137378225 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.196366
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279955
INFO:root:FL Epoch: 201 Worker: 0 Backdoor Test Loss: 0.17408799876769385 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 201 Worker: 0 Backdoor Train Loss: 0.23070435523986815 Backdoor Train Accuracy: 93.0
INFO:root:FL Epoch: 201 Norm Difference for worker 0 is 0.210967
INFO:root:FL Epoch: 201 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1
INFO:root:FL Epoch: 201 Using Learning rate : 0.006700516137378225 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314276
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277372
INFO:root:FL Epoch: 201 Worker: 1 Backdoor Test Loss: 0.16530115654071173 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 201 Worker: 1 Backdoor Train Loss: 0.23119380995631217 Backdoor Train Accuracy: 93.0
INFO:root:FL Epoch: 201 Norm Difference for worker 1 is 0.214259
INFO:root:FL Epoch: 201 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :2
INFO:root:FL Epoch: 201 Using Learning rate : 0.006700516137378225 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391124
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205386
INFO:root:FL Epoch: 201 Worker: 2 Backdoor Test Loss: 0.17898151278495789 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 201 Worker: 2 Backdoor Train Loss: 0.23240791857242585 Backdoor Train Accuracy: 92.0
INFO:root:FL Epoch: 201 Norm Difference for worker 2 is 0.202331
INFO:root:FL Epoch: 201 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1449
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699692
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383326
INFO:root:FL Epoch: 201 Norm Difference for worker 1449 is 1.262826
INFO:root:FL Epoch: 201 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1835
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718013
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.800390
INFO:root:FL Epoch: 201 Norm Difference for worker 1835 is 1.271773
INFO:root:FL Epoch: 201 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1755
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559194
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314626
INFO:root:FL Epoch: 201 Norm Difference for worker 1755 is 1.141681
INFO:root:FL Epoch: 201 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :22
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 22 Train Epoch: 0 [0/201 (0%)]	Loss: 0.580364
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 22 Train Epoch: 1 [0/201 (0%)]	Loss: 0.372087
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 201 Norm Difference for worker 22 is 1.232562
INFO:root:FL Epoch: 201 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1640
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629756
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514550
INFO:root:FL Epoch: 201 Norm Difference for worker 1640 is 1.152718
INFO:root:FL Epoch: 201 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :544
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424041
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362328
INFO:root:FL Epoch: 201 Norm Difference for worker 544 is 1.172142
INFO:root:FL Epoch: 201 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :122
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.631299
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.304711
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 201 Norm Difference for worker 122 is 1.169219
INFO:root:FL Epoch: 201 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 201 Ends   ===================
INFO:root:Epoch:201 Global Model Test Loss:0.5125112954308005 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:201 Global Model Backdoor Test Loss:0.17898151278495789                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 202 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 202 Workers Selected : [1483, 377, 300, 982, 93, 1665, 1168, 351, 124, 1314]
INFO:root:FL Epoch: 202 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 202 Num points on workers: [200 200 201 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 202 Training on worker :1483
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492607
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499881
INFO:root:FL Epoch: 202 Norm Difference for worker 1483 is 1.200506
INFO:root:FL Epoch: 202 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :377
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505257
INFO:root:Worker: 377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558664
INFO:root:FL Epoch: 202 Norm Difference for worker 377 is 1.315752
INFO:root:FL Epoch: 202 Done on worker:377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :300
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.706515
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.443521
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 300 is 1.254993
INFO:root:FL Epoch: 202 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :982
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514053
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379174
INFO:root:FL Epoch: 202 Norm Difference for worker 982 is 1.272013
INFO:root:FL Epoch: 202 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :93
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 93 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593858
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 93 Train Epoch: 1 [0/201 (0%)]	Loss: 0.737574
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 93 is 1.283611
INFO:root:FL Epoch: 202 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1665
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673484
INFO:root:Worker: 1665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661645
INFO:root:FL Epoch: 202 Norm Difference for worker 1665 is 1.252527
INFO:root:FL Epoch: 202 Done on worker:1665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1168
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1168 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467038
INFO:root:Worker: 1168 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365585
INFO:root:FL Epoch: 202 Norm Difference for worker 1168 is 1.246615
INFO:root:FL Epoch: 202 Done on worker:1168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :351
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617945
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381831
INFO:root:FL Epoch: 202 Norm Difference for worker 351 is 1.270352
INFO:root:FL Epoch: 202 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :124
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.552534
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.257010
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 124 is 1.279939
INFO:root:FL Epoch: 202 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1314
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1314 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550153
INFO:root:Worker: 1314 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580410
INFO:root:FL Epoch: 202 Norm Difference for worker 1314 is 1.265782
INFO:root:FL Epoch: 202 Done on worker:1314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1314
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 202 Ends   ===================
INFO:root:Epoch:202 Global Model Test Loss:0.5420322733766892 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:202 Global Model Backdoor Test Loss:0.3767041464646657                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 203 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 203 Workers Selected : [1790, 1275, 1712, 594, 256, 1075, 1770, 1543, 483, 433]
INFO:root:FL Epoch: 203 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 203 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 203 Training on worker :1790
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454158
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432437
INFO:root:FL Epoch: 203 Norm Difference for worker 1790 is 0.91699
INFO:root:FL Epoch: 203 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1275
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475444
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519122
INFO:root:FL Epoch: 203 Norm Difference for worker 1275 is 0.985143
INFO:root:FL Epoch: 203 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1712
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757383
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455518
INFO:root:FL Epoch: 203 Norm Difference for worker 1712 is 0.900496
INFO:root:FL Epoch: 203 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :594
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612799
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572147
INFO:root:FL Epoch: 203 Norm Difference for worker 594 is 0.975292
INFO:root:FL Epoch: 203 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :256
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 256 Train Epoch: 0 [0/201 (0%)]	Loss: 0.370108
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 256 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428053
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 203 Norm Difference for worker 256 is 1.020247
INFO:root:FL Epoch: 203 Done on worker:256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1075
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461262
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544010
INFO:root:FL Epoch: 203 Norm Difference for worker 1075 is 1.027097
INFO:root:FL Epoch: 203 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1770
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570423
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415164
INFO:root:FL Epoch: 203 Norm Difference for worker 1770 is 0.948392
INFO:root:FL Epoch: 203 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1543
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538628
INFO:root:Worker: 1543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461291
INFO:root:FL Epoch: 203 Norm Difference for worker 1543 is 0.969779
INFO:root:FL Epoch: 203 Done on worker:1543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :483
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588487
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513287
INFO:root:FL Epoch: 203 Norm Difference for worker 483 is 0.996736
INFO:root:FL Epoch: 203 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :433
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376303
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508304
INFO:root:FL Epoch: 203 Norm Difference for worker 433 is 1.002427
INFO:root:FL Epoch: 203 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1712
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 203 Ends   ===================
INFO:root:Epoch:203 Global Model Test Loss:0.5215051665025598 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:203 Global Model Backdoor Test Loss:0.27456530928611755                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 204 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 204 Workers Selected : [643, 796, 1743, 1572, 644, 893, 307, 1460, 1890, 179]
INFO:root:FL Epoch: 204 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 204 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 204 Training on worker :643
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433458
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390290
INFO:root:FL Epoch: 204 Norm Difference for worker 643 is 0.996045
INFO:root:FL Epoch: 204 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :796
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646821
INFO:root:Worker: 796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347085
INFO:root:FL Epoch: 204 Norm Difference for worker 796 is 1.056254
INFO:root:FL Epoch: 204 Done on worker:796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1743
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504458
INFO:root:Worker: 1743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594940
INFO:root:FL Epoch: 204 Norm Difference for worker 1743 is 1.026208
INFO:root:FL Epoch: 204 Done on worker:1743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1572
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548267
INFO:root:Worker: 1572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248155
INFO:root:FL Epoch: 204 Norm Difference for worker 1572 is 0.958965
INFO:root:FL Epoch: 204 Done on worker:1572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :644
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516879
INFO:root:Worker: 644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526937
INFO:root:FL Epoch: 204 Norm Difference for worker 644 is 1.07257
INFO:root:FL Epoch: 204 Done on worker:644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :893
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664855
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489872
INFO:root:FL Epoch: 204 Norm Difference for worker 893 is 1.050801
INFO:root:FL Epoch: 204 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :307
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 307 Train Epoch: 0 [0/201 (0%)]	Loss: 0.933592
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 307 Train Epoch: 1 [0/201 (0%)]	Loss: 0.514382
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 204 Norm Difference for worker 307 is 1.059529
INFO:root:FL Epoch: 204 Done on worker:307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1460
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689913
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519612
INFO:root:FL Epoch: 204 Norm Difference for worker 1460 is 0.976956
INFO:root:FL Epoch: 204 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1890
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650109
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550413
INFO:root:FL Epoch: 204 Norm Difference for worker 1890 is 1.019381
INFO:root:FL Epoch: 204 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :179
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 179 Train Epoch: 0 [0/201 (0%)]	Loss: 0.317662
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 179 Train Epoch: 1 [0/201 (0%)]	Loss: 0.411094
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 204 Norm Difference for worker 179 is 1.079412
INFO:root:FL Epoch: 204 Done on worker:179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1572
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 204 Ends   ===================
INFO:root:Epoch:204 Global Model Test Loss:0.5275012377430411 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:204 Global Model Backdoor Test Loss:0.2564091930786769                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 205 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 205 Workers Selected : [1646, 45, 498, 132, 1171, 587, 1921, 1482, 230, 1399]
INFO:root:FL Epoch: 205 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 205 Num points on workers: [200 201 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 205 Training on worker :1646
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630049
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666857
INFO:root:FL Epoch: 205 Norm Difference for worker 1646 is 0.967989
INFO:root:FL Epoch: 205 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :45
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.528149
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.561152
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 45 is 1.01228
INFO:root:FL Epoch: 205 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :498
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568086
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461574
INFO:root:FL Epoch: 205 Norm Difference for worker 498 is 1.022808
INFO:root:FL Epoch: 205 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :132
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.506775
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.491298
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 132 is 1.012205
INFO:root:FL Epoch: 205 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1171
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1171 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520855
INFO:root:Worker: 1171 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542055
INFO:root:FL Epoch: 205 Norm Difference for worker 1171 is 1.038465
INFO:root:FL Epoch: 205 Done on worker:1171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :587
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735984
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430480
INFO:root:FL Epoch: 205 Norm Difference for worker 587 is 0.960323
INFO:root:FL Epoch: 205 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1921
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518081
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473782
INFO:root:FL Epoch: 205 Norm Difference for worker 1921 is 1.095561
INFO:root:FL Epoch: 205 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1482
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655167
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361648
INFO:root:FL Epoch: 205 Norm Difference for worker 1482 is 0.994687
INFO:root:FL Epoch: 205 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :230
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 230 Train Epoch: 0 [0/201 (0%)]	Loss: 0.880541
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 230 Train Epoch: 1 [0/201 (0%)]	Loss: 0.522880
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 230 is 1.00318
INFO:root:FL Epoch: 205 Done on worker:230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1399
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648691
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412701
INFO:root:FL Epoch: 205 Norm Difference for worker 1399 is 1.034691
INFO:root:FL Epoch: 205 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 587
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 205 Ends   ===================
INFO:root:Epoch:205 Global Model Test Loss:0.5299154257073122 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:205 Global Model Backdoor Test Loss:0.30500876158475876                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 206 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 206 Workers Selected : [118, 1272, 1114, 236, 1838, 1835, 460, 1482, 289, 329]
INFO:root:FL Epoch: 206 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 206 Num points on workers: [201 200 200 201 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 206 Training on worker :118
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 118 Train Epoch: 0 [0/201 (0%)]	Loss: 0.551208
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 118 Train Epoch: 1 [0/201 (0%)]	Loss: 0.526238
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 118 is 0.992473
INFO:root:FL Epoch: 206 Done on worker:118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1272
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1272 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597276
INFO:root:Worker: 1272 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475572
INFO:root:FL Epoch: 206 Norm Difference for worker 1272 is 1.008775
INFO:root:FL Epoch: 206 Done on worker:1272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1114
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493969
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381676
INFO:root:FL Epoch: 206 Norm Difference for worker 1114 is 1.001868
INFO:root:FL Epoch: 206 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :236
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 236 Train Epoch: 0 [0/201 (0%)]	Loss: 0.628122
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 236 Train Epoch: 1 [0/201 (0%)]	Loss: 0.539633
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 236 is 1.024182
INFO:root:FL Epoch: 206 Done on worker:236
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1838
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590811
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441402
INFO:root:FL Epoch: 206 Norm Difference for worker 1838 is 0.9987
INFO:root:FL Epoch: 206 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1835
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424809
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470315
INFO:root:FL Epoch: 206 Norm Difference for worker 1835 is 1.035062
INFO:root:FL Epoch: 206 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :460
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382961
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489119
INFO:root:FL Epoch: 206 Norm Difference for worker 460 is 0.996649
INFO:root:FL Epoch: 206 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1482
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496204
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457748
INFO:root:FL Epoch: 206 Norm Difference for worker 1482 is 0.962567
INFO:root:FL Epoch: 206 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :289
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.487371
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.560919
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 289 is 0.983663
INFO:root:FL Epoch: 206 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :329
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 329 Train Epoch: 0 [0/201 (0%)]	Loss: 0.530634
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 329 Train Epoch: 1 [0/201 (0%)]	Loss: 0.487695
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 206 Norm Difference for worker 329 is 0.963846
INFO:root:FL Epoch: 206 Done on worker:329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 329
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 206 Ends   ===================
INFO:root:Epoch:206 Global Model Test Loss:0.5342060695676243 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:206 Global Model Backdoor Test Loss:0.3384317308664322                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 207 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 207 Workers Selected : [1442, 1664, 483, 754, 166, 1570, 541, 1604, 800, 277]
INFO:root:FL Epoch: 207 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 207 Num points on workers: [200 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 207 Training on worker :1442
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575403
INFO:root:Worker: 1442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423313
INFO:root:FL Epoch: 207 Norm Difference for worker 1442 is 0.92833
INFO:root:FL Epoch: 207 Done on worker:1442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1664
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432231
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639365
INFO:root:FL Epoch: 207 Norm Difference for worker 1664 is 0.907156
INFO:root:FL Epoch: 207 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :483
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742752
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463857
INFO:root:FL Epoch: 207 Norm Difference for worker 483 is 0.959283
INFO:root:FL Epoch: 207 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :754
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500976
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369774
INFO:root:FL Epoch: 207 Norm Difference for worker 754 is 0.9892
INFO:root:FL Epoch: 207 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :166
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 166 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691648
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 166 Train Epoch: 1 [0/201 (0%)]	Loss: 0.390781
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 166 is 0.890164
INFO:root:FL Epoch: 207 Done on worker:166
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1570
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594874
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520702
INFO:root:FL Epoch: 207 Norm Difference for worker 1570 is 0.932503
INFO:root:FL Epoch: 207 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :541
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466143
INFO:root:Worker: 541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544932
INFO:root:FL Epoch: 207 Norm Difference for worker 541 is 0.874946
INFO:root:FL Epoch: 207 Done on worker:541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1604
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684276
INFO:root:Worker: 1604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373019
INFO:root:FL Epoch: 207 Norm Difference for worker 1604 is 0.892814
INFO:root:FL Epoch: 207 Done on worker:1604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :800
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569225
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496579
INFO:root:FL Epoch: 207 Norm Difference for worker 800 is 0.934833
INFO:root:FL Epoch: 207 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :277
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.429140
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.502339
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 277 is 0.952922
INFO:root:FL Epoch: 207 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 541
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 207 Ends   ===================
INFO:root:Epoch:207 Global Model Test Loss:0.5269834662184996 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:207 Global Model Backdoor Test Loss:0.328082799911499                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 208 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 208 Workers Selected : [1406, 774, 854, 1449, 741, 740, 1869, 1080, 1637, 1546]
INFO:root:FL Epoch: 208 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 208 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 208 Training on worker :1406
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732196
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525324
INFO:root:FL Epoch: 208 Norm Difference for worker 1406 is 0.928141
INFO:root:FL Epoch: 208 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :774
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646183
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642521
INFO:root:FL Epoch: 208 Norm Difference for worker 774 is 0.918972
INFO:root:FL Epoch: 208 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :854
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483101
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568788
INFO:root:FL Epoch: 208 Norm Difference for worker 854 is 0.985833
INFO:root:FL Epoch: 208 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1449
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613959
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424951
INFO:root:FL Epoch: 208 Norm Difference for worker 1449 is 0.987532
INFO:root:FL Epoch: 208 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :741
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772102
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.777837
INFO:root:FL Epoch: 208 Norm Difference for worker 741 is 0.9554
INFO:root:FL Epoch: 208 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :740
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597463
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392680
INFO:root:FL Epoch: 208 Norm Difference for worker 740 is 0.943088
INFO:root:FL Epoch: 208 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1869
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437408
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398600
INFO:root:FL Epoch: 208 Norm Difference for worker 1869 is 0.953664
INFO:root:FL Epoch: 208 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1080
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752895
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567282
INFO:root:FL Epoch: 208 Norm Difference for worker 1080 is 0.920426
INFO:root:FL Epoch: 208 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1637
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528878
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.849111
INFO:root:FL Epoch: 208 Norm Difference for worker 1637 is 0.92113
INFO:root:FL Epoch: 208 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1546
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.785689
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431351
INFO:root:FL Epoch: 208 Norm Difference for worker 1546 is 0.956266
INFO:root:FL Epoch: 208 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 774
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 208 Ends   ===================
INFO:root:Epoch:208 Global Model Test Loss:0.5277918752501992 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:208 Global Model Backdoor Test Loss:0.3039615775148074                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 209 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 209 Workers Selected : [1904, 1753, 1821, 1207, 9, 1378, 211, 883, 876, 812]
INFO:root:FL Epoch: 209 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 209 Num points on workers: [200 200 200 200 201 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 209 Training on worker :1904
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504434
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408156
INFO:root:FL Epoch: 209 Norm Difference for worker 1904 is 0.972147
INFO:root:FL Epoch: 209 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1753
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747536
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509867
INFO:root:FL Epoch: 209 Norm Difference for worker 1753 is 0.875226
INFO:root:FL Epoch: 209 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1821
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679532
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559414
INFO:root:FL Epoch: 209 Norm Difference for worker 1821 is 0.985248
INFO:root:FL Epoch: 209 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1207
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1207 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641595
INFO:root:Worker: 1207 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570862
INFO:root:FL Epoch: 209 Norm Difference for worker 1207 is 0.955431
INFO:root:FL Epoch: 209 Done on worker:1207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :9
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.579728
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447877
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 9 is 1.027074
INFO:root:FL Epoch: 209 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1378
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764260
INFO:root:Worker: 1378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425157
INFO:root:FL Epoch: 209 Norm Difference for worker 1378 is 1.034512
INFO:root:FL Epoch: 209 Done on worker:1378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :211
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.577972
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.509589
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 211 is 0.914455
INFO:root:FL Epoch: 209 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :883
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678673
INFO:root:Worker: 883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534928
INFO:root:FL Epoch: 209 Norm Difference for worker 883 is 0.978803
INFO:root:FL Epoch: 209 Done on worker:883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :876
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672767
INFO:root:Worker: 876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513955
INFO:root:FL Epoch: 209 Norm Difference for worker 876 is 0.941921
INFO:root:FL Epoch: 209 Done on worker:876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :812
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615292
INFO:root:Worker: 812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430471
INFO:root:FL Epoch: 209 Norm Difference for worker 812 is 0.94547
INFO:root:FL Epoch: 209 Done on worker:812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1753
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 209 Ends   ===================
INFO:root:Epoch:209 Global Model Test Loss:0.5382039757335887 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:209 Global Model Backdoor Test Loss:0.333643580476443                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 210 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 210 Workers Selected : [321, 758, 550, 1387, 1806, 760, 316, 1694, 937, 1178]
INFO:root:FL Epoch: 210 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 210 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 210 Training on worker :321
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.412131
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.336945
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 321 is 0.964492
INFO:root:FL Epoch: 210 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :758
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428320
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617664
INFO:root:FL Epoch: 210 Norm Difference for worker 758 is 0.931876
INFO:root:FL Epoch: 210 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :550
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535370
INFO:root:Worker: 550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601738
INFO:root:FL Epoch: 210 Norm Difference for worker 550 is 0.996883
INFO:root:FL Epoch: 210 Done on worker:550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1387
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1387 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498939
INFO:root:Worker: 1387 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384507
INFO:root:FL Epoch: 210 Norm Difference for worker 1387 is 1.01696
INFO:root:FL Epoch: 210 Done on worker:1387
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1806
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382044
INFO:root:Worker: 1806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410621
INFO:root:FL Epoch: 210 Norm Difference for worker 1806 is 0.937741
INFO:root:FL Epoch: 210 Done on worker:1806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :760
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622611
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484259
INFO:root:FL Epoch: 210 Norm Difference for worker 760 is 0.953882
INFO:root:FL Epoch: 210 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :316
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.572186
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.310698
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 316 is 0.971407
INFO:root:FL Epoch: 210 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1694
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545462
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351835
INFO:root:FL Epoch: 210 Norm Difference for worker 1694 is 0.998629
INFO:root:FL Epoch: 210 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :937
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372262
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317545
INFO:root:FL Epoch: 210 Norm Difference for worker 937 is 0.9627
INFO:root:FL Epoch: 210 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1178
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651422
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408558
INFO:root:FL Epoch: 210 Norm Difference for worker 1178 is 1.028749
INFO:root:FL Epoch: 210 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1806
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 210 Ends   ===================
INFO:root:Epoch:210 Global Model Test Loss:0.5226359016755048 and Test Accuracy:75.0 
INFO:root:Epoch:210 Global Model Backdoor Test Loss:0.30456507702668506                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 211 Begins ===================
INFO:root:FL Epoch: 211 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 211 Workers Selected : [0, 1, 2, 1428, 391, 1560, 1489, 106, 729, 1080]
INFO:root:FL Epoch: 211 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 211 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 211 Training on worker :0
INFO:root:FL Epoch: 211 Using Learning rate : 0.006567705497499687 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374982
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254680
INFO:root:FL Epoch: 211 Worker: 0 Backdoor Test Loss: 0.20088395227988562 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 211 Worker: 0 Backdoor Train Loss: 0.2760917514562607 Backdoor Train Accuracy: 91.5
INFO:root:FL Epoch: 211 Norm Difference for worker 0 is 0.217924
INFO:root:FL Epoch: 211 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1
INFO:root:FL Epoch: 211 Using Learning rate : 0.006567705497499687 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405293
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411603
INFO:root:FL Epoch: 211 Worker: 1 Backdoor Test Loss: 0.20105110853910446 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 211 Worker: 1 Backdoor Train Loss: 0.2740268737077713 Backdoor Train Accuracy: 91.5
INFO:root:FL Epoch: 211 Norm Difference for worker 1 is 0.224595
INFO:root:FL Epoch: 211 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :2
INFO:root:FL Epoch: 211 Using Learning rate : 0.006567705497499687 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463978
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266351
INFO:root:FL Epoch: 211 Worker: 2 Backdoor Test Loss: 0.20896006127198538 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 211 Worker: 2 Backdoor Train Loss: 0.27519886791706083 Backdoor Train Accuracy: 92.0
INFO:root:FL Epoch: 211 Norm Difference for worker 2 is 0.216454
INFO:root:FL Epoch: 211 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1428
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566896
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626279
INFO:root:FL Epoch: 211 Norm Difference for worker 1428 is 0.977833
INFO:root:FL Epoch: 211 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :391
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611335
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362823
INFO:root:FL Epoch: 211 Norm Difference for worker 391 is 0.993145
INFO:root:FL Epoch: 211 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1560
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623185
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386989
INFO:root:FL Epoch: 211 Norm Difference for worker 1560 is 0.905966
INFO:root:FL Epoch: 211 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1489
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1489 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451166
INFO:root:Worker: 1489 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626624
INFO:root:FL Epoch: 211 Norm Difference for worker 1489 is 1.006883
INFO:root:FL Epoch: 211 Done on worker:1489
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :106
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.659812
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.512632
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 211 Norm Difference for worker 106 is 0.954833
INFO:root:FL Epoch: 211 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :729
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513570
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635938
INFO:root:FL Epoch: 211 Norm Difference for worker 729 is 0.998904
INFO:root:FL Epoch: 211 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1080
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644646
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569221
INFO:root:FL Epoch: 211 Norm Difference for worker 1080 is 0.934149
INFO:root:FL Epoch: 211 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 211 Ends   ===================
INFO:root:Epoch:211 Global Model Test Loss:0.5185583076056313 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:211 Global Model Backdoor Test Loss:0.20088395227988562                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 212 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 212 Workers Selected : [850, 1190, 991, 137, 1175, 1765, 1107, 415, 1168, 123]
INFO:root:FL Epoch: 212 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 212 Num points on workers: [200 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 212 Training on worker :850
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600887
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475750
INFO:root:FL Epoch: 212 Norm Difference for worker 850 is 1.036156
INFO:root:FL Epoch: 212 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1190
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388254
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636083
INFO:root:FL Epoch: 212 Norm Difference for worker 1190 is 0.967309
INFO:root:FL Epoch: 212 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :991
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.869854
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557311
INFO:root:FL Epoch: 212 Norm Difference for worker 991 is 1.161261
INFO:root:FL Epoch: 212 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :137
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 137 Train Epoch: 0 [0/201 (0%)]	Loss: 0.621001
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 137 Train Epoch: 1 [0/201 (0%)]	Loss: 0.522997
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 212 Norm Difference for worker 137 is 1.082227
INFO:root:FL Epoch: 212 Done on worker:137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1175
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419962
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404742
INFO:root:FL Epoch: 212 Norm Difference for worker 1175 is 1.052134
INFO:root:FL Epoch: 212 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1765
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401619
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431850
INFO:root:FL Epoch: 212 Norm Difference for worker 1765 is 0.992324
INFO:root:FL Epoch: 212 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1107
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1107 Train Epoch: 0 [0/200 (0%)]	Loss: 0.777557
INFO:root:Worker: 1107 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364665
INFO:root:FL Epoch: 212 Norm Difference for worker 1107 is 1.032129
INFO:root:FL Epoch: 212 Done on worker:1107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :415
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548909
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574078
INFO:root:FL Epoch: 212 Norm Difference for worker 415 is 1.044657
INFO:root:FL Epoch: 212 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1168
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1168 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375374
INFO:root:Worker: 1168 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649668
INFO:root:FL Epoch: 212 Norm Difference for worker 1168 is 0.996107
INFO:root:FL Epoch: 212 Done on worker:1168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :123
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.414633
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.480649
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 212 Norm Difference for worker 123 is 1.054059
INFO:root:FL Epoch: 212 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1190
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 212 Ends   ===================
INFO:root:Epoch:212 Global Model Test Loss:0.5287229453816134 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:212 Global Model Backdoor Test Loss:0.1497320793569088                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 213 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 213 Workers Selected : [1125, 873, 1501, 1370, 1513, 744, 533, 1237, 1929, 1117]
INFO:root:FL Epoch: 213 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 213 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 213 Training on worker :1125
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590788
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614922
INFO:root:FL Epoch: 213 Norm Difference for worker 1125 is 1.120045
INFO:root:FL Epoch: 213 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :873
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605288
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435586
INFO:root:FL Epoch: 213 Norm Difference for worker 873 is 1.090881
INFO:root:FL Epoch: 213 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1501
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474527
INFO:root:Worker: 1501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530621
INFO:root:FL Epoch: 213 Norm Difference for worker 1501 is 1.139017
INFO:root:FL Epoch: 213 Done on worker:1501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1370
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451109
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392786
INFO:root:FL Epoch: 213 Norm Difference for worker 1370 is 1.091661
INFO:root:FL Epoch: 213 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1513
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779917
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353720
INFO:root:FL Epoch: 213 Norm Difference for worker 1513 is 1.039191
INFO:root:FL Epoch: 213 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :744
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492745
INFO:root:Worker: 744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554439
INFO:root:FL Epoch: 213 Norm Difference for worker 744 is 1.101616
INFO:root:FL Epoch: 213 Done on worker:744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :533
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.853418
INFO:root:Worker: 533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394523
INFO:root:FL Epoch: 213 Norm Difference for worker 533 is 1.105198
INFO:root:FL Epoch: 213 Done on worker:533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1237
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663014
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481347
INFO:root:FL Epoch: 213 Norm Difference for worker 1237 is 1.063223
INFO:root:FL Epoch: 213 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1929
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491682
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219789
INFO:root:FL Epoch: 213 Norm Difference for worker 1929 is 1.061315
INFO:root:FL Epoch: 213 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1117
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1117 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413701
INFO:root:Worker: 1117 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216365
INFO:root:FL Epoch: 213 Norm Difference for worker 1117 is 1.05926
INFO:root:FL Epoch: 213 Done on worker:1117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1513
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 213 Ends   ===================
INFO:root:Epoch:213 Global Model Test Loss:0.5218246035716113 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:213 Global Model Backdoor Test Loss:0.19661870102087656                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 214 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 214 Workers Selected : [1192, 1056, 257, 852, 1024, 1453, 1392, 1700, 203, 661]
INFO:root:FL Epoch: 214 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 214 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 214 Training on worker :1192
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652400
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574550
INFO:root:FL Epoch: 214 Norm Difference for worker 1192 is 1.134937
INFO:root:FL Epoch: 214 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1056
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531588
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503027
INFO:root:FL Epoch: 214 Norm Difference for worker 1056 is 1.110828
INFO:root:FL Epoch: 214 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :257
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.474031
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.469254
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 257 is 1.172122
INFO:root:FL Epoch: 214 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :852
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632892
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525356
INFO:root:FL Epoch: 214 Norm Difference for worker 852 is 1.166786
INFO:root:FL Epoch: 214 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1024
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586275
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434760
INFO:root:FL Epoch: 214 Norm Difference for worker 1024 is 1.047976
INFO:root:FL Epoch: 214 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1453
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486138
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416104
INFO:root:FL Epoch: 214 Norm Difference for worker 1453 is 1.082036
INFO:root:FL Epoch: 214 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1392
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470992
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333313
INFO:root:FL Epoch: 214 Norm Difference for worker 1392 is 1.052458
INFO:root:FL Epoch: 214 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1700
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415602
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404841
INFO:root:FL Epoch: 214 Norm Difference for worker 1700 is 0.985573
INFO:root:FL Epoch: 214 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :203
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.493669
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.393555
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 203 is 1.082406
INFO:root:FL Epoch: 214 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :661
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647567
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620557
INFO:root:FL Epoch: 214 Norm Difference for worker 661 is 1.110648
INFO:root:FL Epoch: 214 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1700
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 214 Ends   ===================
INFO:root:Epoch:214 Global Model Test Loss:0.5135922309230355 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:214 Global Model Backdoor Test Loss:0.17859416703383127                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 215 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 215 Workers Selected : [408, 1362, 158, 368, 468, 1463, 341, 1793, 609, 594]
INFO:root:FL Epoch: 215 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 215 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 215 Training on worker :408
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607180
INFO:root:Worker: 408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365290
INFO:root:FL Epoch: 215 Norm Difference for worker 408 is 1.146297
INFO:root:FL Epoch: 215 Done on worker:408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1362
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744254
INFO:root:Worker: 1362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478525
INFO:root:FL Epoch: 215 Norm Difference for worker 1362 is 1.127598
INFO:root:FL Epoch: 215 Done on worker:1362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :158
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517739
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488440
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 215 Norm Difference for worker 158 is 1.147164
INFO:root:FL Epoch: 215 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :368
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744586
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426723
INFO:root:FL Epoch: 215 Norm Difference for worker 368 is 1.12172
INFO:root:FL Epoch: 215 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :468
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695268
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559129
INFO:root:FL Epoch: 215 Norm Difference for worker 468 is 1.109254
INFO:root:FL Epoch: 215 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1463
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713137
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570097
INFO:root:FL Epoch: 215 Norm Difference for worker 1463 is 1.192279
INFO:root:FL Epoch: 215 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :341
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514229
INFO:root:Worker: 341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466218
INFO:root:FL Epoch: 215 Norm Difference for worker 341 is 1.201347
INFO:root:FL Epoch: 215 Done on worker:341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1793
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380787
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478012
INFO:root:FL Epoch: 215 Norm Difference for worker 1793 is 1.156727
INFO:root:FL Epoch: 215 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :609
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596005
INFO:root:Worker: 609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449963
INFO:root:FL Epoch: 215 Norm Difference for worker 609 is 1.170315
INFO:root:FL Epoch: 215 Done on worker:609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :594
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602802
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386142
INFO:root:FL Epoch: 215 Norm Difference for worker 594 is 1.224622
INFO:root:FL Epoch: 215 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 468
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 215 Ends   ===================
INFO:root:Epoch:215 Global Model Test Loss:0.5269436450565562 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:215 Global Model Backdoor Test Loss:0.2328848416606585                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 216 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 216 Workers Selected : [1256, 1698, 318, 1075, 427, 895, 1686, 939, 1008, 1785]
INFO:root:FL Epoch: 216 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 216 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 216 Training on worker :1256
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507610
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566396
INFO:root:FL Epoch: 216 Norm Difference for worker 1256 is 0.909453
INFO:root:FL Epoch: 216 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1698
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559443
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671249
INFO:root:FL Epoch: 216 Norm Difference for worker 1698 is 0.965681
INFO:root:FL Epoch: 216 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :318
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.502183
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.478821
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 216 Norm Difference for worker 318 is 0.977544
INFO:root:FL Epoch: 216 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1075
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510497
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394817
INFO:root:FL Epoch: 216 Norm Difference for worker 1075 is 0.948295
INFO:root:FL Epoch: 216 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :427
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.284265
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342879
INFO:root:FL Epoch: 216 Norm Difference for worker 427 is 0.939767
INFO:root:FL Epoch: 216 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :895
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424577
INFO:root:Worker: 895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370386
INFO:root:FL Epoch: 216 Norm Difference for worker 895 is 0.981422
INFO:root:FL Epoch: 216 Done on worker:895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1686
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494597
INFO:root:Worker: 1686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293482
INFO:root:FL Epoch: 216 Norm Difference for worker 1686 is 0.948691
INFO:root:FL Epoch: 216 Done on worker:1686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :939
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.838811
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544801
INFO:root:FL Epoch: 216 Norm Difference for worker 939 is 0.922658
INFO:root:FL Epoch: 216 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1008
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1008 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648098
INFO:root:Worker: 1008 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554276
INFO:root:FL Epoch: 216 Norm Difference for worker 1008 is 0.98366
INFO:root:FL Epoch: 216 Done on worker:1008
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1785
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579894
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410231
INFO:root:FL Epoch: 216 Norm Difference for worker 1785 is 0.947038
INFO:root:FL Epoch: 216 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1256
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 216 Ends   ===================
INFO:root:Epoch:216 Global Model Test Loss:0.5364089748438667 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:216 Global Model Backdoor Test Loss:0.3911229570706685                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 217 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 217 Workers Selected : [795, 1488, 830, 1412, 1025, 1652, 631, 1898, 872, 698]
INFO:root:FL Epoch: 217 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 217 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 217 Training on worker :795
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402014
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503150
INFO:root:FL Epoch: 217 Norm Difference for worker 795 is 0.866925
INFO:root:FL Epoch: 217 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1488
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519414
INFO:root:Worker: 1488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663265
INFO:root:FL Epoch: 217 Norm Difference for worker 1488 is 0.949171
INFO:root:FL Epoch: 217 Done on worker:1488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :830
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444273
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459332
INFO:root:FL Epoch: 217 Norm Difference for worker 830 is 0.968399
INFO:root:FL Epoch: 217 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1412
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1412 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506332
INFO:root:Worker: 1412 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471723
INFO:root:FL Epoch: 217 Norm Difference for worker 1412 is 0.940288
INFO:root:FL Epoch: 217 Done on worker:1412
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1025
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434933
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501397
INFO:root:FL Epoch: 217 Norm Difference for worker 1025 is 0.882645
INFO:root:FL Epoch: 217 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1652
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465947
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507256
INFO:root:FL Epoch: 217 Norm Difference for worker 1652 is 0.932383
INFO:root:FL Epoch: 217 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :631
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567873
INFO:root:Worker: 631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674997
INFO:root:FL Epoch: 217 Norm Difference for worker 631 is 0.891612
INFO:root:FL Epoch: 217 Done on worker:631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1898
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441097
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553758
INFO:root:FL Epoch: 217 Norm Difference for worker 1898 is 0.956312
INFO:root:FL Epoch: 217 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :872
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463199
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575257
INFO:root:FL Epoch: 217 Norm Difference for worker 872 is 0.967405
INFO:root:FL Epoch: 217 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :698
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707355
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.723411
INFO:root:FL Epoch: 217 Norm Difference for worker 698 is 0.936247
INFO:root:FL Epoch: 217 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 795
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 217 Ends   ===================
INFO:root:Epoch:217 Global Model Test Loss:0.563184578629101 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:217 Global Model Backdoor Test Loss:0.3683581401904424                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 218 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 218 Workers Selected : [1823, 16, 1683, 1802, 663, 1406, 1358, 240, 101, 1363]
INFO:root:FL Epoch: 218 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 218 Num points on workers: [200 201 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 218 Training on worker :1823
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527729
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461582
INFO:root:FL Epoch: 218 Norm Difference for worker 1823 is 1.077536
INFO:root:FL Epoch: 218 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :16
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 16 Train Epoch: 0 [0/201 (0%)]	Loss: 0.683466
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 16 Train Epoch: 1 [0/201 (0%)]	Loss: 0.556926
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 16 is 1.054881
INFO:root:FL Epoch: 218 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1683
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759702
INFO:root:Worker: 1683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429112
INFO:root:FL Epoch: 218 Norm Difference for worker 1683 is 1.068604
INFO:root:FL Epoch: 218 Done on worker:1683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1802
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696773
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426210
INFO:root:FL Epoch: 218 Norm Difference for worker 1802 is 1.053377
INFO:root:FL Epoch: 218 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :663
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.934850
INFO:root:Worker: 663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441214
INFO:root:FL Epoch: 218 Norm Difference for worker 663 is 0.974517
INFO:root:FL Epoch: 218 Done on worker:663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1406
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656076
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702604
INFO:root:FL Epoch: 218 Norm Difference for worker 1406 is 1.067109
INFO:root:FL Epoch: 218 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1358
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630181
INFO:root:Worker: 1358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504187
INFO:root:FL Epoch: 218 Norm Difference for worker 1358 is 1.052228
INFO:root:FL Epoch: 218 Done on worker:1358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :240
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 240 Train Epoch: 0 [0/201 (0%)]	Loss: 0.700314
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 240 Train Epoch: 1 [0/201 (0%)]	Loss: 0.526905
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 240 is 1.106519
INFO:root:FL Epoch: 218 Done on worker:240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :101
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.858604
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.460853
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 101 is 1.090863
INFO:root:FL Epoch: 218 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1363
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722259
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465109
INFO:root:FL Epoch: 218 Norm Difference for worker 1363 is 1.1463
INFO:root:FL Epoch: 218 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 663
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 218 Ends   ===================
INFO:root:Epoch:218 Global Model Test Loss:0.5348228286294376 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:218 Global Model Backdoor Test Loss:0.2946115384499232                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 219 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 219 Workers Selected : [185, 1693, 737, 1553, 560, 1190, 926, 912, 1477, 173]
INFO:root:FL Epoch: 219 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 219 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 219 Training on worker :185
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.549952
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.602842
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 219 Norm Difference for worker 185 is 1.011822
INFO:root:FL Epoch: 219 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1693
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469736
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301013
INFO:root:FL Epoch: 219 Norm Difference for worker 1693 is 0.974357
INFO:root:FL Epoch: 219 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :737
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533235
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375484
INFO:root:FL Epoch: 219 Norm Difference for worker 737 is 1.0064
INFO:root:FL Epoch: 219 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1553
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397398
INFO:root:Worker: 1553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592307
INFO:root:FL Epoch: 219 Norm Difference for worker 1553 is 1.019656
INFO:root:FL Epoch: 219 Done on worker:1553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :560
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582825
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345488
INFO:root:FL Epoch: 219 Norm Difference for worker 560 is 1.082605
INFO:root:FL Epoch: 219 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1190
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429656
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305960
INFO:root:FL Epoch: 219 Norm Difference for worker 1190 is 0.907174
INFO:root:FL Epoch: 219 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :926
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403434
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419522
INFO:root:FL Epoch: 219 Norm Difference for worker 926 is 0.977572
INFO:root:FL Epoch: 219 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :912
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550570
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491305
INFO:root:FL Epoch: 219 Norm Difference for worker 912 is 1.029364
INFO:root:FL Epoch: 219 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1477
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622042
INFO:root:Worker: 1477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512287
INFO:root:FL Epoch: 219 Norm Difference for worker 1477 is 1.031405
INFO:root:FL Epoch: 219 Done on worker:1477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :173
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.579985
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.472270
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 219 Norm Difference for worker 173 is 1.103787
INFO:root:FL Epoch: 219 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1190
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 219 Ends   ===================
INFO:root:Epoch:219 Global Model Test Loss:0.5487940591924331 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:219 Global Model Backdoor Test Loss:0.1334509737789631                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 220 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 220 Workers Selected : [1326, 919, 1829, 1536, 1533, 1562, 524, 652, 1778, 59]
INFO:root:FL Epoch: 220 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 220 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 220 Training on worker :1326
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656663
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511381
INFO:root:FL Epoch: 220 Norm Difference for worker 1326 is 1.392152
INFO:root:FL Epoch: 220 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :919
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478858
INFO:root:Worker: 919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432047
INFO:root:FL Epoch: 220 Norm Difference for worker 919 is 1.429616
INFO:root:FL Epoch: 220 Done on worker:919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1829
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612587
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637601
INFO:root:FL Epoch: 220 Norm Difference for worker 1829 is 1.261298
INFO:root:FL Epoch: 220 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1536
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471288
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508604
INFO:root:FL Epoch: 220 Norm Difference for worker 1536 is 1.458155
INFO:root:FL Epoch: 220 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1533
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729909
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411459
INFO:root:FL Epoch: 220 Norm Difference for worker 1533 is 1.431699
INFO:root:FL Epoch: 220 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1562
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740872
INFO:root:Worker: 1562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407679
INFO:root:FL Epoch: 220 Norm Difference for worker 1562 is 1.336433
INFO:root:FL Epoch: 220 Done on worker:1562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :524
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522197
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431757
INFO:root:FL Epoch: 220 Norm Difference for worker 524 is 1.295755
INFO:root:FL Epoch: 220 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :652
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571784
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331348
INFO:root:FL Epoch: 220 Norm Difference for worker 652 is 1.388792
INFO:root:FL Epoch: 220 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1778
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663719
INFO:root:Worker: 1778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469273
INFO:root:FL Epoch: 220 Norm Difference for worker 1778 is 1.407361
INFO:root:FL Epoch: 220 Done on worker:1778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :59
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.636473
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.302551
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 220 Norm Difference for worker 59 is 1.421327
INFO:root:FL Epoch: 220 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1829
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 220 Ends   ===================
INFO:root:Epoch:220 Global Model Test Loss:0.5499751304878908 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:220 Global Model Backdoor Test Loss:0.12735981370011965                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 221 Begins ===================
INFO:root:FL Epoch: 221 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 221 Workers Selected : [0, 1, 2, 316, 1143, 39, 451, 1522, 1199, 1403]
INFO:root:FL Epoch: 221 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 221 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 221 Training on worker :0
INFO:root:FL Epoch: 221 Using Learning rate : 0.006437527291556583 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438109
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263150
INFO:root:FL Epoch: 221 Worker: 0 Backdoor Test Loss: 0.119248462220033 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 221 Worker: 0 Backdoor Train Loss: 0.22878606468439103 Backdoor Train Accuracy: 94.0
INFO:root:FL Epoch: 221 Norm Difference for worker 0 is 0.205817
INFO:root:FL Epoch: 221 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1
INFO:root:FL Epoch: 221 Using Learning rate : 0.006437527291556583 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344661
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.252455
INFO:root:FL Epoch: 221 Worker: 1 Backdoor Test Loss: 0.1308142145474752 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 221 Worker: 1 Backdoor Train Loss: 0.22995275408029556 Backdoor Train Accuracy: 93.5
INFO:root:FL Epoch: 221 Norm Difference for worker 1 is 0.216993
INFO:root:FL Epoch: 221 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :2
INFO:root:FL Epoch: 221 Using Learning rate : 0.006437527291556583 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400808
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365134
INFO:root:FL Epoch: 221 Worker: 2 Backdoor Test Loss: 0.12349200497070949 Backdoor Test Accuracy: 100.0
INFO:root:FL Epoch: 221 Worker: 2 Backdoor Train Loss: 0.2308536984026432 Backdoor Train Accuracy: 94.0
INFO:root:FL Epoch: 221 Norm Difference for worker 2 is 0.196509
INFO:root:FL Epoch: 221 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :316
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.474845
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.439885
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 221 Norm Difference for worker 316 is 1.183186
INFO:root:FL Epoch: 221 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1143
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1143 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565208
INFO:root:Worker: 1143 Train Epoch: 1 [0/200 (0%)]	Loss: 0.766776
INFO:root:FL Epoch: 221 Norm Difference for worker 1143 is 1.213133
INFO:root:FL Epoch: 221 Done on worker:1143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :39
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 39 Train Epoch: 0 [0/201 (0%)]	Loss: 0.631794
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 39 Train Epoch: 1 [0/201 (0%)]	Loss: 0.652450
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 221 Norm Difference for worker 39 is 1.231991
INFO:root:FL Epoch: 221 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :451
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620164
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450373
INFO:root:FL Epoch: 221 Norm Difference for worker 451 is 1.132341
INFO:root:FL Epoch: 221 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1522
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493312
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533991
INFO:root:FL Epoch: 221 Norm Difference for worker 1522 is 1.092034
INFO:root:FL Epoch: 221 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1199
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597271
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523582
INFO:root:FL Epoch: 221 Norm Difference for worker 1199 is 1.178157
INFO:root:FL Epoch: 221 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1403
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438169
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465358
INFO:root:FL Epoch: 221 Norm Difference for worker 1403 is 1.166561
INFO:root:FL Epoch: 221 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 221 Ends   ===================
INFO:root:Epoch:221 Global Model Test Loss:0.5481915158383986 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:221 Global Model Backdoor Test Loss:0.12349200497070949                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 222 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 222 Workers Selected : [1432, 1879, 1374, 138, 1818, 1897, 1713, 1190, 804, 1704]
INFO:root:FL Epoch: 222 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 222 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 222 Training on worker :1432
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384432
INFO:root:Worker: 1432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557016
INFO:root:FL Epoch: 222 Norm Difference for worker 1432 is 1.256133
INFO:root:FL Epoch: 222 Done on worker:1432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1879
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537055
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463800
INFO:root:FL Epoch: 222 Norm Difference for worker 1879 is 1.264903
INFO:root:FL Epoch: 222 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1374
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594225
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392250
INFO:root:FL Epoch: 222 Norm Difference for worker 1374 is 1.168476
INFO:root:FL Epoch: 222 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :138
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.740906
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.493969
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 222 Norm Difference for worker 138 is 1.265925
INFO:root:FL Epoch: 222 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1818
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535615
INFO:root:Worker: 1818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335374
INFO:root:FL Epoch: 222 Norm Difference for worker 1818 is 1.236142
INFO:root:FL Epoch: 222 Done on worker:1818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1897
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626611
INFO:root:Worker: 1897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641327
INFO:root:FL Epoch: 222 Norm Difference for worker 1897 is 1.261297
INFO:root:FL Epoch: 222 Done on worker:1897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1713
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734060
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360295
INFO:root:FL Epoch: 222 Norm Difference for worker 1713 is 1.12206
INFO:root:FL Epoch: 222 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1190
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.265885
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207978
INFO:root:FL Epoch: 222 Norm Difference for worker 1190 is 0.827258
INFO:root:FL Epoch: 222 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :804
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.811950
INFO:root:Worker: 804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.724702
INFO:root:FL Epoch: 222 Norm Difference for worker 804 is 1.354051
INFO:root:FL Epoch: 222 Done on worker:804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1704
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526221
INFO:root:Worker: 1704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485601
INFO:root:FL Epoch: 222 Norm Difference for worker 1704 is 1.197046
INFO:root:FL Epoch: 222 Done on worker:1704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1190
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 222 Ends   ===================
INFO:root:Epoch:222 Global Model Test Loss:0.6216372304102954 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:222 Global Model Backdoor Test Loss:0.053397671629985176                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 223 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 223 Workers Selected : [270, 754, 153, 729, 1270, 198, 422, 357, 1197, 1215]
INFO:root:FL Epoch: 223 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 223 Num points on workers: [201 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 223 Training on worker :270
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.727189
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.377833
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 270 is 1.590117
INFO:root:FL Epoch: 223 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :754
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.942364
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587650
INFO:root:FL Epoch: 223 Norm Difference for worker 754 is 1.671274
INFO:root:FL Epoch: 223 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :153
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 1.185749
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.329620
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 153 is 1.748343
INFO:root:FL Epoch: 223 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :729
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 1.047978
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330156
INFO:root:FL Epoch: 223 Norm Difference for worker 729 is 1.581093
INFO:root:FL Epoch: 223 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1270
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677007
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331150
INFO:root:FL Epoch: 223 Norm Difference for worker 1270 is 1.320329
INFO:root:FL Epoch: 223 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :198
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.791616
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.393947
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 223 Norm Difference for worker 198 is 1.75826
INFO:root:FL Epoch: 223 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :422
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.947560
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496801
INFO:root:FL Epoch: 223 Norm Difference for worker 422 is 1.652704
INFO:root:FL Epoch: 223 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :357
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504799
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461257
INFO:root:FL Epoch: 223 Norm Difference for worker 357 is 1.634459
INFO:root:FL Epoch: 223 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1197
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737429
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594465
INFO:root:FL Epoch: 223 Norm Difference for worker 1197 is 1.765235
INFO:root:FL Epoch: 223 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1215
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.818559
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371616
INFO:root:FL Epoch: 223 Norm Difference for worker 1215 is 1.81319
INFO:root:FL Epoch: 223 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1270
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 223 Ends   ===================
INFO:root:Epoch:223 Global Model Test Loss:0.6004096602692324 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:223 Global Model Backdoor Test Loss:0.11470522731542587                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 224 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 224 Workers Selected : [1695, 1865, 1713, 297, 1928, 1649, 866, 1522, 950, 1672]
INFO:root:FL Epoch: 224 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 224 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 224 Training on worker :1695
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.881568
INFO:root:Worker: 1695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518132
INFO:root:FL Epoch: 224 Norm Difference for worker 1695 is 1.461432
INFO:root:FL Epoch: 224 Done on worker:1695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1865
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695364
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543865
INFO:root:FL Epoch: 224 Norm Difference for worker 1865 is 1.510857
INFO:root:FL Epoch: 224 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1713
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690221
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539523
INFO:root:FL Epoch: 224 Norm Difference for worker 1713 is 1.356387
INFO:root:FL Epoch: 224 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :297
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 297 Train Epoch: 0 [0/201 (0%)]	Loss: 0.544917
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 297 Train Epoch: 1 [0/201 (0%)]	Loss: 0.398053
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 224 Norm Difference for worker 297 is 1.398626
INFO:root:FL Epoch: 224 Done on worker:297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1928
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368277
INFO:root:Worker: 1928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609768
INFO:root:FL Epoch: 224 Norm Difference for worker 1928 is 1.415253
INFO:root:FL Epoch: 224 Done on worker:1928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1649
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808485
INFO:root:Worker: 1649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607565
INFO:root:FL Epoch: 224 Norm Difference for worker 1649 is 1.433593
INFO:root:FL Epoch: 224 Done on worker:1649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :866
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.902226
INFO:root:Worker: 866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374839
INFO:root:FL Epoch: 224 Norm Difference for worker 866 is 1.425207
INFO:root:FL Epoch: 224 Done on worker:866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1522
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739772
INFO:root:Worker: 1522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322463
INFO:root:FL Epoch: 224 Norm Difference for worker 1522 is 1.294237
INFO:root:FL Epoch: 224 Done on worker:1522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :950
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436496
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398268
INFO:root:FL Epoch: 224 Norm Difference for worker 950 is 1.365682
INFO:root:FL Epoch: 224 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1672
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379662
INFO:root:Worker: 1672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260221
INFO:root:FL Epoch: 224 Norm Difference for worker 1672 is 1.401188
INFO:root:FL Epoch: 224 Done on worker:1672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1713
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 224 Ends   ===================
INFO:root:Epoch:224 Global Model Test Loss:0.5787197386517244 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:224 Global Model Backdoor Test Loss:0.1607932671904564                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 225 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 225 Workers Selected : [772, 146, 483, 630, 1459, 1607, 1636, 1906, 1540, 320]
INFO:root:FL Epoch: 225 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 225 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 225 Training on worker :772
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638578
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610489
INFO:root:FL Epoch: 225 Norm Difference for worker 772 is 1.127098
INFO:root:FL Epoch: 225 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :146
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 146 Train Epoch: 0 [0/201 (0%)]	Loss: 0.468147
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 146 Train Epoch: 1 [0/201 (0%)]	Loss: 0.409794
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 225 Norm Difference for worker 146 is 1.28025
INFO:root:FL Epoch: 225 Done on worker:146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :483
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664117
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.741891
INFO:root:FL Epoch: 225 Norm Difference for worker 483 is 1.227516
INFO:root:FL Epoch: 225 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :630
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.914632
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421447
INFO:root:FL Epoch: 225 Norm Difference for worker 630 is 1.240537
INFO:root:FL Epoch: 225 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1459
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580675
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490777
INFO:root:FL Epoch: 225 Norm Difference for worker 1459 is 1.25454
INFO:root:FL Epoch: 225 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1607
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.945169
INFO:root:Worker: 1607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468699
INFO:root:FL Epoch: 225 Norm Difference for worker 1607 is 1.163563
INFO:root:FL Epoch: 225 Done on worker:1607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1636
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469661
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305727
INFO:root:FL Epoch: 225 Norm Difference for worker 1636 is 1.191623
INFO:root:FL Epoch: 225 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1906
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687521
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542252
INFO:root:FL Epoch: 225 Norm Difference for worker 1906 is 1.238196
INFO:root:FL Epoch: 225 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1540
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571337
INFO:root:Worker: 1540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648480
INFO:root:FL Epoch: 225 Norm Difference for worker 1540 is 1.148578
INFO:root:FL Epoch: 225 Done on worker:1540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :320
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.927736
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505987
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 225 Norm Difference for worker 320 is 1.173651
INFO:root:FL Epoch: 225 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 772
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 225 Ends   ===================
INFO:root:Epoch:225 Global Model Test Loss:0.5635694738696603 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:225 Global Model Backdoor Test Loss:0.1991590162118276                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 226 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 226 Workers Selected : [607, 1256, 305, 1249, 1338, 942, 1340, 822, 41, 1770]
INFO:root:FL Epoch: 226 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 226 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 226 Training on worker :607
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640095
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341601
INFO:root:FL Epoch: 226 Norm Difference for worker 607 is 1.09983
INFO:root:FL Epoch: 226 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1256
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436897
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341376
INFO:root:FL Epoch: 226 Norm Difference for worker 1256 is 0.959835
INFO:root:FL Epoch: 226 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :305
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.370414
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.606562
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 226 Norm Difference for worker 305 is 1.052876
INFO:root:FL Epoch: 226 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1249
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501752
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573306
INFO:root:FL Epoch: 226 Norm Difference for worker 1249 is 1.257966
INFO:root:FL Epoch: 226 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1338
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590529
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601596
INFO:root:FL Epoch: 226 Norm Difference for worker 1338 is 0.961702
INFO:root:FL Epoch: 226 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :942
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456519
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353221
INFO:root:FL Epoch: 226 Norm Difference for worker 942 is 1.040033
INFO:root:FL Epoch: 226 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1340
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.817501
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320146
INFO:root:FL Epoch: 226 Norm Difference for worker 1340 is 1.03587
INFO:root:FL Epoch: 226 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :822
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612579
INFO:root:Worker: 822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397765
INFO:root:FL Epoch: 226 Norm Difference for worker 822 is 1.075288
INFO:root:FL Epoch: 226 Done on worker:822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :41
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 41 Train Epoch: 0 [0/201 (0%)]	Loss: 0.394453
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 41 Train Epoch: 1 [0/201 (0%)]	Loss: 0.360402
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 226 Norm Difference for worker 41 is 1.068525
INFO:root:FL Epoch: 226 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1770
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740330
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542255
INFO:root:FL Epoch: 226 Norm Difference for worker 1770 is 1.091194
INFO:root:FL Epoch: 226 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1256
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 226 Ends   ===================
INFO:root:Epoch:226 Global Model Test Loss:0.5867921131498673 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:226 Global Model Backdoor Test Loss:0.21629451463619867                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 227 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 227 Workers Selected : [77, 907, 431, 1546, 1892, 70, 1513, 959, 274, 157]
INFO:root:FL Epoch: 227 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 227 Num points on workers: [201 200 200 200 200 201 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 227 Training on worker :77
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 77 Train Epoch: 0 [0/201 (0%)]	Loss: 0.438917
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 77 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450099
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 77 is 1.194725
INFO:root:FL Epoch: 227 Done on worker:77
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :907
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.957739
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.736820
INFO:root:FL Epoch: 227 Norm Difference for worker 907 is 1.285252
INFO:root:FL Epoch: 227 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :431
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481077
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.716410
INFO:root:FL Epoch: 227 Norm Difference for worker 431 is 1.319073
INFO:root:FL Epoch: 227 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1546
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.331585
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618801
INFO:root:FL Epoch: 227 Norm Difference for worker 1546 is 1.287928
INFO:root:FL Epoch: 227 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1892
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592163
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620748
INFO:root:FL Epoch: 227 Norm Difference for worker 1892 is 1.193628
INFO:root:FL Epoch: 227 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :70
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.207554
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.349142
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 70 is 1.182593
INFO:root:FL Epoch: 227 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1513
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423738
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330170
INFO:root:FL Epoch: 227 Norm Difference for worker 1513 is 1.00784
INFO:root:FL Epoch: 227 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :959
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358664
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455757
INFO:root:FL Epoch: 227 Norm Difference for worker 959 is 1.282481
INFO:root:FL Epoch: 227 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :274
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.371801
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.492457
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 274 is 1.240104
INFO:root:FL Epoch: 227 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :157
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.465519
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.289418
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 157 is 1.226364
INFO:root:FL Epoch: 227 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1513
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 227 Ends   ===================
INFO:root:Epoch:227 Global Model Test Loss:0.605037766344407 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:227 Global Model Backdoor Test Loss:0.17392648508151373                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 228 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 228 Workers Selected : [683, 1670, 1846, 949, 1749, 1722, 993, 1085, 948, 1414]
INFO:root:FL Epoch: 228 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 228 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 228 Training on worker :683
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626611
INFO:root:Worker: 683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315101
INFO:root:FL Epoch: 228 Norm Difference for worker 683 is 1.386642
INFO:root:FL Epoch: 228 Done on worker:683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1670
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508244
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279691
INFO:root:FL Epoch: 228 Norm Difference for worker 1670 is 1.266382
INFO:root:FL Epoch: 228 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1846
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669061
INFO:root:Worker: 1846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362943
INFO:root:FL Epoch: 228 Norm Difference for worker 1846 is 1.407485
INFO:root:FL Epoch: 228 Done on worker:1846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :949
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562633
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401598
INFO:root:FL Epoch: 228 Norm Difference for worker 949 is 1.503705
INFO:root:FL Epoch: 228 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1749
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1749 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741457
INFO:root:Worker: 1749 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370769
INFO:root:FL Epoch: 228 Norm Difference for worker 1749 is 1.374459
INFO:root:FL Epoch: 228 Done on worker:1749
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1722
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471905
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.253123
INFO:root:FL Epoch: 228 Norm Difference for worker 1722 is 1.416298
INFO:root:FL Epoch: 228 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :993
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 993 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592553
INFO:root:Worker: 993 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502969
INFO:root:FL Epoch: 228 Norm Difference for worker 993 is 1.401849
INFO:root:FL Epoch: 228 Done on worker:993
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1085
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527952
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628642
INFO:root:FL Epoch: 228 Norm Difference for worker 1085 is 1.493285
INFO:root:FL Epoch: 228 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :948
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 948 Train Epoch: 0 [0/200 (0%)]	Loss: 0.876679
INFO:root:Worker: 948 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472386
INFO:root:FL Epoch: 228 Norm Difference for worker 948 is 1.485122
INFO:root:FL Epoch: 228 Done on worker:948
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1414
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.921251
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289198
INFO:root:FL Epoch: 228 Norm Difference for worker 1414 is 1.363541
INFO:root:FL Epoch: 228 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1670
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 228 Ends   ===================
INFO:root:Epoch:228 Global Model Test Loss:0.6237418598988477 and Test Accuracy:69.11764705882354 
INFO:root:Epoch:228 Global Model Backdoor Test Loss:0.22537875920534134                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 229 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 229 Workers Selected : [958, 924, 923, 170, 1886, 71, 912, 1134, 1808, 1870]
INFO:root:FL Epoch: 229 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 229 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 229 Training on worker :958
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602399
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435825
INFO:root:FL Epoch: 229 Norm Difference for worker 958 is 1.447557
INFO:root:FL Epoch: 229 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :924
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510949
INFO:root:Worker: 924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554480
INFO:root:FL Epoch: 229 Norm Difference for worker 924 is 1.305501
INFO:root:FL Epoch: 229 Done on worker:924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :923
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436183
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535040
INFO:root:FL Epoch: 229 Norm Difference for worker 923 is 1.356818
INFO:root:FL Epoch: 229 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :170
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.802662
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.570406
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 229 Norm Difference for worker 170 is 1.332334
INFO:root:FL Epoch: 229 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1886
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621582
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355162
INFO:root:FL Epoch: 229 Norm Difference for worker 1886 is 1.407497
INFO:root:FL Epoch: 229 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :71
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.706839
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.451444
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 229 Norm Difference for worker 71 is 1.395481
INFO:root:FL Epoch: 229 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :912
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576183
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579797
INFO:root:FL Epoch: 229 Norm Difference for worker 912 is 1.335231
INFO:root:FL Epoch: 229 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1134
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1134 Train Epoch: 0 [0/200 (0%)]	Loss: 0.298889
INFO:root:Worker: 1134 Train Epoch: 1 [0/200 (0%)]	Loss: 0.215183
INFO:root:FL Epoch: 229 Norm Difference for worker 1134 is 1.208749
INFO:root:FL Epoch: 229 Done on worker:1134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1808
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.793514
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537256
INFO:root:FL Epoch: 229 Norm Difference for worker 1808 is 1.296023
INFO:root:FL Epoch: 229 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1870
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598753
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467075
INFO:root:FL Epoch: 229 Norm Difference for worker 1870 is 1.387095
INFO:root:FL Epoch: 229 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1134
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 229 Ends   ===================
INFO:root:Epoch:229 Global Model Test Loss:0.6216396058306974 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:229 Global Model Backdoor Test Loss:0.1935807541012764                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 230 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 230 Workers Selected : [1469, 582, 963, 936, 1610, 1285, 954, 660, 200, 238]
INFO:root:FL Epoch: 230 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 230 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 230 Training on worker :1469
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702550
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480217
INFO:root:FL Epoch: 230 Norm Difference for worker 1469 is 1.268451
INFO:root:FL Epoch: 230 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :582
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484814
INFO:root:Worker: 582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503068
INFO:root:FL Epoch: 230 Norm Difference for worker 582 is 1.18108
INFO:root:FL Epoch: 230 Done on worker:582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :963
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 963 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722996
INFO:root:Worker: 963 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681814
INFO:root:FL Epoch: 230 Norm Difference for worker 963 is 1.268048
INFO:root:FL Epoch: 230 Done on worker:963
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :936
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330440
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676985
INFO:root:FL Epoch: 230 Norm Difference for worker 936 is 1.314891
INFO:root:FL Epoch: 230 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1610
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660207
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603788
INFO:root:FL Epoch: 230 Norm Difference for worker 1610 is 1.271628
INFO:root:FL Epoch: 230 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1285
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544451
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365540
INFO:root:FL Epoch: 230 Norm Difference for worker 1285 is 1.155898
INFO:root:FL Epoch: 230 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :954
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 954 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539053
INFO:root:Worker: 954 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342451
INFO:root:FL Epoch: 230 Norm Difference for worker 954 is 1.154964
INFO:root:FL Epoch: 230 Done on worker:954
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :660
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552287
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482626
INFO:root:FL Epoch: 230 Norm Difference for worker 660 is 1.188654
INFO:root:FL Epoch: 230 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :200
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.824696
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.604119
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 200 is 1.282682
INFO:root:FL Epoch: 230 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :238
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 238 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494541
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 238 Train Epoch: 1 [0/201 (0%)]	Loss: 0.521416
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 238 is 1.264177
INFO:root:FL Epoch: 230 Done on worker:238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 582
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 230 Ends   ===================
INFO:root:Epoch:230 Global Model Test Loss:0.5923482284826391 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:230 Global Model Backdoor Test Loss:0.20428303380807242                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 231 Begins ===================
INFO:root:FL Epoch: 231 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 231 Workers Selected : [0, 1, 2, 182, 207, 1332, 956, 1616, 1364, 648]
INFO:root:FL Epoch: 231 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 231 Num points on workers: [200 200 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 231 Training on worker :0
INFO:root:FL Epoch: 231 Using Learning rate : 0.006309929342189997 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.279916
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315204
INFO:root:FL Epoch: 231 Worker: 0 Backdoor Test Loss: 0.16384334117174149 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 231 Worker: 0 Backdoor Train Loss: 0.2649874210357666 Backdoor Train Accuracy: 93.0
INFO:root:FL Epoch: 231 Norm Difference for worker 0 is 0.214345
INFO:root:FL Epoch: 231 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1
INFO:root:FL Epoch: 231 Using Learning rate : 0.006309929342189997 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.275255
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314588
INFO:root:FL Epoch: 231 Worker: 1 Backdoor Test Loss: 0.1697231282790502 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 231 Worker: 1 Backdoor Train Loss: 0.2663128525018692 Backdoor Train Accuracy: 93.0
INFO:root:FL Epoch: 231 Norm Difference for worker 1 is 0.210803
INFO:root:FL Epoch: 231 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :2
INFO:root:FL Epoch: 231 Using Learning rate : 0.006309929342189997 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.264297
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325170
INFO:root:FL Epoch: 231 Worker: 2 Backdoor Test Loss: 0.16424772391716638 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 231 Worker: 2 Backdoor Train Loss: 0.2668424040079117 Backdoor Train Accuracy: 93.5
INFO:root:FL Epoch: 231 Norm Difference for worker 2 is 0.205256
INFO:root:FL Epoch: 231 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :182
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.584478
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.371118
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 231 Norm Difference for worker 182 is 1.040477
INFO:root:FL Epoch: 231 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :207
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.622015
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.541972
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 231 Norm Difference for worker 207 is 1.059808
INFO:root:FL Epoch: 231 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1332
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.866627
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416890
INFO:root:FL Epoch: 231 Norm Difference for worker 1332 is 1.10233
INFO:root:FL Epoch: 231 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :956
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 956 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686807
INFO:root:Worker: 956 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636433
INFO:root:FL Epoch: 231 Norm Difference for worker 956 is 1.056541
INFO:root:FL Epoch: 231 Done on worker:956
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1616
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704027
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697077
INFO:root:FL Epoch: 231 Norm Difference for worker 1616 is 1.004074
INFO:root:FL Epoch: 231 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1364
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652835
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437235
INFO:root:FL Epoch: 231 Norm Difference for worker 1364 is 1.042834
INFO:root:FL Epoch: 231 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :648
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804791
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496993
INFO:root:FL Epoch: 231 Norm Difference for worker 648 is 1.100244
INFO:root:FL Epoch: 231 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 231 Ends   ===================
INFO:root:Epoch:231 Global Model Test Loss:0.5861258541836458 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:231 Global Model Backdoor Test Loss:0.1697231282790502                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 232 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 232 Workers Selected : [1755, 1533, 1003, 1514, 482, 38, 1305, 806, 1291, 1342]
INFO:root:FL Epoch: 232 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 232 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 232 Training on worker :1755
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590760
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569807
INFO:root:FL Epoch: 232 Norm Difference for worker 1755 is 1.045994
INFO:root:FL Epoch: 232 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1533
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.821010
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566437
INFO:root:FL Epoch: 232 Norm Difference for worker 1533 is 1.123411
INFO:root:FL Epoch: 232 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1003
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663304
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310095
INFO:root:FL Epoch: 232 Norm Difference for worker 1003 is 1.040173
INFO:root:FL Epoch: 232 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1514
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584949
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622140
INFO:root:FL Epoch: 232 Norm Difference for worker 1514 is 1.165833
INFO:root:FL Epoch: 232 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :482
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451438
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484971
INFO:root:FL Epoch: 232 Norm Difference for worker 482 is 1.085124
INFO:root:FL Epoch: 232 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :38
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.666169
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.406917
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 232 Norm Difference for worker 38 is 1.025304
INFO:root:FL Epoch: 232 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1305
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1305 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593525
INFO:root:Worker: 1305 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485056
INFO:root:FL Epoch: 232 Norm Difference for worker 1305 is 1.107443
INFO:root:FL Epoch: 232 Done on worker:1305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :806
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655846
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564405
INFO:root:FL Epoch: 232 Norm Difference for worker 806 is 1.160408
INFO:root:FL Epoch: 232 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1291
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1291 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771989
INFO:root:Worker: 1291 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544081
INFO:root:FL Epoch: 232 Norm Difference for worker 1291 is 1.038532
INFO:root:FL Epoch: 232 Done on worker:1291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1342
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657725
INFO:root:Worker: 1342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459452
INFO:root:FL Epoch: 232 Norm Difference for worker 1342 is 1.076906
INFO:root:FL Epoch: 232 Done on worker:1342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 38
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 232 Ends   ===================
INFO:root:Epoch:232 Global Model Test Loss:0.5818728506565094 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:232 Global Model Backdoor Test Loss:0.1438260649641355                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 233 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 233 Workers Selected : [1736, 1347, 965, 1370, 121, 1393, 456, 1814, 1922, 825]
INFO:root:FL Epoch: 233 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 233 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 233 Training on worker :1736
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595334
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542865
INFO:root:FL Epoch: 233 Norm Difference for worker 1736 is 1.141433
INFO:root:FL Epoch: 233 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1347
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431478
INFO:root:Worker: 1347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576381
INFO:root:FL Epoch: 233 Norm Difference for worker 1347 is 1.212661
INFO:root:FL Epoch: 233 Done on worker:1347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :965
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 965 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378843
INFO:root:Worker: 965 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410791
INFO:root:FL Epoch: 233 Norm Difference for worker 965 is 1.066936
INFO:root:FL Epoch: 233 Done on worker:965
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1370
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599278
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442475
INFO:root:FL Epoch: 233 Norm Difference for worker 1370 is 1.157536
INFO:root:FL Epoch: 233 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :121
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 121 Train Epoch: 0 [0/201 (0%)]	Loss: 0.484052
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 121 Train Epoch: 1 [0/201 (0%)]	Loss: 0.413531
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 233 Norm Difference for worker 121 is 1.090343
INFO:root:FL Epoch: 233 Done on worker:121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1393
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572046
INFO:root:Worker: 1393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520804
INFO:root:FL Epoch: 233 Norm Difference for worker 1393 is 1.098956
INFO:root:FL Epoch: 233 Done on worker:1393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :456
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717748
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.233511
INFO:root:FL Epoch: 233 Norm Difference for worker 456 is 1.16383
INFO:root:FL Epoch: 233 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1814
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466233
INFO:root:Worker: 1814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573614
INFO:root:FL Epoch: 233 Norm Difference for worker 1814 is 1.171714
INFO:root:FL Epoch: 233 Done on worker:1814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1922
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402887
INFO:root:Worker: 1922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.955262
INFO:root:FL Epoch: 233 Norm Difference for worker 1922 is 1.146123
INFO:root:FL Epoch: 233 Done on worker:1922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :825
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.322434
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260008
INFO:root:FL Epoch: 233 Norm Difference for worker 825 is 0.976538
INFO:root:FL Epoch: 233 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 825
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 233 Ends   ===================
INFO:root:Epoch:233 Global Model Test Loss:0.6101565431146061 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:233 Global Model Backdoor Test Loss:0.10993651424845059                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 234 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 234 Workers Selected : [1426, 1515, 1029, 1283, 292, 988, 434, 1197, 1772, 1338]
INFO:root:FL Epoch: 234 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 234 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 234 Training on worker :1426
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516052
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333492
INFO:root:FL Epoch: 234 Norm Difference for worker 1426 is 1.396755
INFO:root:FL Epoch: 234 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1515
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729277
INFO:root:Worker: 1515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556810
INFO:root:FL Epoch: 234 Norm Difference for worker 1515 is 1.339387
INFO:root:FL Epoch: 234 Done on worker:1515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1029
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1029 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734363
INFO:root:Worker: 1029 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459437
INFO:root:FL Epoch: 234 Norm Difference for worker 1029 is 1.306479
INFO:root:FL Epoch: 234 Done on worker:1029
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1283
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1283 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737133
INFO:root:Worker: 1283 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552798
INFO:root:FL Epoch: 234 Norm Difference for worker 1283 is 1.324165
INFO:root:FL Epoch: 234 Done on worker:1283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :292
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 292 Train Epoch: 0 [0/201 (0%)]	Loss: 0.476381
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 292 Train Epoch: 1 [0/201 (0%)]	Loss: 0.520421
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 234 Norm Difference for worker 292 is 1.344426
INFO:root:FL Epoch: 234 Done on worker:292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :988
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 988 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492180
INFO:root:Worker: 988 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417179
INFO:root:FL Epoch: 234 Norm Difference for worker 988 is 1.329044
INFO:root:FL Epoch: 234 Done on worker:988
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :434
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643177
INFO:root:Worker: 434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428978
INFO:root:FL Epoch: 234 Norm Difference for worker 434 is 1.280559
INFO:root:FL Epoch: 234 Done on worker:434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1197
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768902
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666800
INFO:root:FL Epoch: 234 Norm Difference for worker 1197 is 1.537959
INFO:root:FL Epoch: 234 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1772
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.850797
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668309
INFO:root:FL Epoch: 234 Norm Difference for worker 1772 is 1.327383
INFO:root:FL Epoch: 234 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1338
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743134
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458824
INFO:root:FL Epoch: 234 Norm Difference for worker 1338 is 1.433088
INFO:root:FL Epoch: 234 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1029
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 234 Ends   ===================
INFO:root:Epoch:234 Global Model Test Loss:0.5746328672941994 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:234 Global Model Backdoor Test Loss:0.18217733750740686                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 235 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 235 Workers Selected : [522, 1084, 794, 1467, 1794, 1935, 1180, 1316, 1029, 1087]
INFO:root:FL Epoch: 235 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 235 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 235 Training on worker :522
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416345
INFO:root:Worker: 522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467472
INFO:root:FL Epoch: 235 Norm Difference for worker 522 is 0.961272
INFO:root:FL Epoch: 235 Done on worker:522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1084
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558818
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458310
INFO:root:FL Epoch: 235 Norm Difference for worker 1084 is 1.04338
INFO:root:FL Epoch: 235 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :794
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462414
INFO:root:Worker: 794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416348
INFO:root:FL Epoch: 235 Norm Difference for worker 794 is 0.985786
INFO:root:FL Epoch: 235 Done on worker:794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1467
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540917
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390173
INFO:root:FL Epoch: 235 Norm Difference for worker 1467 is 0.959767
INFO:root:FL Epoch: 235 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1794
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627550
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507203
INFO:root:FL Epoch: 235 Norm Difference for worker 1794 is 1.049243
INFO:root:FL Epoch: 235 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1935
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491909
INFO:root:Worker: 1935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523720
INFO:root:FL Epoch: 235 Norm Difference for worker 1935 is 0.965496
INFO:root:FL Epoch: 235 Done on worker:1935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1180
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473024
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477511
INFO:root:FL Epoch: 235 Norm Difference for worker 1180 is 0.949331
INFO:root:FL Epoch: 235 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1316
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549422
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464086
INFO:root:FL Epoch: 235 Norm Difference for worker 1316 is 0.931222
INFO:root:FL Epoch: 235 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1029
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1029 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428273
INFO:root:Worker: 1029 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242735
INFO:root:FL Epoch: 235 Norm Difference for worker 1029 is 0.890484
INFO:root:FL Epoch: 235 Done on worker:1029
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1087
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594745
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671278
INFO:root:FL Epoch: 235 Norm Difference for worker 1087 is 1.014629
INFO:root:FL Epoch: 235 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1029
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 235 Ends   ===================
INFO:root:Epoch:235 Global Model Test Loss:0.6485094428062439 and Test Accuracy:67.6470588235294 
INFO:root:Epoch:235 Global Model Backdoor Test Loss:0.17628330240646997                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 236 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 236 Workers Selected : [1500, 1518, 1356, 1009, 923, 1137, 1947, 1178, 44, 161]
INFO:root:FL Epoch: 236 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 236 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 236 Training on worker :1500
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696914
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615214
INFO:root:FL Epoch: 236 Norm Difference for worker 1500 is 1.540742
INFO:root:FL Epoch: 236 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1518
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.273210
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616636
INFO:root:FL Epoch: 236 Norm Difference for worker 1518 is 1.450656
INFO:root:FL Epoch: 236 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1356
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579407
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389026
INFO:root:FL Epoch: 236 Norm Difference for worker 1356 is 1.449919
INFO:root:FL Epoch: 236 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1009
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714654
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569155
INFO:root:FL Epoch: 236 Norm Difference for worker 1009 is 1.357667
INFO:root:FL Epoch: 236 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :923
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730108
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 1.102050
INFO:root:FL Epoch: 236 Norm Difference for worker 923 is 1.418235
INFO:root:FL Epoch: 236 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1137
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782922
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580383
INFO:root:FL Epoch: 236 Norm Difference for worker 1137 is 1.474138
INFO:root:FL Epoch: 236 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1947
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741927
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357116
INFO:root:FL Epoch: 236 Norm Difference for worker 1947 is 1.286995
INFO:root:FL Epoch: 236 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1178
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549785
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307893
INFO:root:FL Epoch: 236 Norm Difference for worker 1178 is 1.416945
INFO:root:FL Epoch: 236 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :44
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 44 Train Epoch: 0 [0/201 (0%)]	Loss: 0.483236
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 44 Train Epoch: 1 [0/201 (0%)]	Loss: 0.338726
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 44 is 1.412028
INFO:root:FL Epoch: 236 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :161
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.521347
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.373759
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 161 is 1.302414
INFO:root:FL Epoch: 236 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 161
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 236 Ends   ===================
INFO:root:Epoch:236 Global Model Test Loss:0.5752053786726559 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:236 Global Model Backdoor Test Loss:0.15896855046351752                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 237 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 237 Workers Selected : [312, 1612, 1685, 582, 797, 600, 237, 1308, 534, 844]
INFO:root:FL Epoch: 237 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 237 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 237 Training on worker :312
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.519873
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698449
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 237 Norm Difference for worker 312 is 1.105192
INFO:root:FL Epoch: 237 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1612
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805033
INFO:root:Worker: 1612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250063
INFO:root:FL Epoch: 237 Norm Difference for worker 1612 is 1.243713
INFO:root:FL Epoch: 237 Done on worker:1612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1685
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.809443
INFO:root:Worker: 1685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590599
INFO:root:FL Epoch: 237 Norm Difference for worker 1685 is 1.135752
INFO:root:FL Epoch: 237 Done on worker:1685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :582
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.254345
INFO:root:Worker: 582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492013
INFO:root:FL Epoch: 237 Norm Difference for worker 582 is 1.009171
INFO:root:FL Epoch: 237 Done on worker:582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :797
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682469
INFO:root:Worker: 797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.705537
INFO:root:FL Epoch: 237 Norm Difference for worker 797 is 1.199643
INFO:root:FL Epoch: 237 Done on worker:797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :600
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597789
INFO:root:Worker: 600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326128
INFO:root:FL Epoch: 237 Norm Difference for worker 600 is 1.088908
INFO:root:FL Epoch: 237 Done on worker:600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :237
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 237 Train Epoch: 0 [0/201 (0%)]	Loss: 0.617670
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 237 Train Epoch: 1 [0/201 (0%)]	Loss: 0.463629
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 237 Norm Difference for worker 237 is 1.169024
INFO:root:FL Epoch: 237 Done on worker:237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1308
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541706
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374966
INFO:root:FL Epoch: 237 Norm Difference for worker 1308 is 1.257887
INFO:root:FL Epoch: 237 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :534
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604147
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505644
INFO:root:FL Epoch: 237 Norm Difference for worker 534 is 1.19199
INFO:root:FL Epoch: 237 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :844
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714076
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389877
INFO:root:FL Epoch: 237 Norm Difference for worker 844 is 1.155588
INFO:root:FL Epoch: 237 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 582
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 237 Ends   ===================
INFO:root:Epoch:237 Global Model Test Loss:0.5860355321098777 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:237 Global Model Backdoor Test Loss:0.1496549199024836                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 238 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 238 Workers Selected : [58, 859, 433, 1026, 994, 1506, 858, 763, 1007, 921]
INFO:root:FL Epoch: 238 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 238 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 238 Training on worker :58
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 58 Train Epoch: 0 [0/201 (0%)]	Loss: 0.763570
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 58 Train Epoch: 1 [0/201 (0%)]	Loss: 0.485837
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 238 Norm Difference for worker 58 is 1.265342
INFO:root:FL Epoch: 238 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :859
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715922
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434582
INFO:root:FL Epoch: 238 Norm Difference for worker 859 is 1.195715
INFO:root:FL Epoch: 238 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :433
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493421
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515951
INFO:root:FL Epoch: 238 Norm Difference for worker 433 is 1.261506
INFO:root:FL Epoch: 238 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1026
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1026 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454894
INFO:root:Worker: 1026 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483103
INFO:root:FL Epoch: 238 Norm Difference for worker 1026 is 1.235266
INFO:root:FL Epoch: 238 Done on worker:1026
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :994
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493001
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508405
INFO:root:FL Epoch: 238 Norm Difference for worker 994 is 1.203735
INFO:root:FL Epoch: 238 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1506
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614119
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659278
INFO:root:FL Epoch: 238 Norm Difference for worker 1506 is 1.120109
INFO:root:FL Epoch: 238 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :858
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470185
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436076
INFO:root:FL Epoch: 238 Norm Difference for worker 858 is 1.231463
INFO:root:FL Epoch: 238 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :763
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382652
INFO:root:Worker: 763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699965
INFO:root:FL Epoch: 238 Norm Difference for worker 763 is 1.275285
INFO:root:FL Epoch: 238 Done on worker:763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1007
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.786615
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465894
INFO:root:FL Epoch: 238 Norm Difference for worker 1007 is 1.197067
INFO:root:FL Epoch: 238 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :921
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.379593
INFO:root:Worker: 921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344643
INFO:root:FL Epoch: 238 Norm Difference for worker 921 is 1.246947
INFO:root:FL Epoch: 238 Done on worker:921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1506
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 238 Ends   ===================
INFO:root:Epoch:238 Global Model Test Loss:0.5619070091668297 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:238 Global Model Backdoor Test Loss:0.23502173771460852                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 239 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 239 Workers Selected : [1052, 845, 221, 456, 255, 587, 86, 1398, 451, 1030]
INFO:root:FL Epoch: 239 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 239 Num points on workers: [200 200 201 200 201 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 239 Training on worker :1052
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484274
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328938
INFO:root:FL Epoch: 239 Norm Difference for worker 1052 is 0.9901
INFO:root:FL Epoch: 239 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :845
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535395
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509019
INFO:root:FL Epoch: 239 Norm Difference for worker 845 is 1.035521
INFO:root:FL Epoch: 239 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :221
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 221 Train Epoch: 0 [0/201 (0%)]	Loss: 0.438447
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 221 Train Epoch: 1 [0/201 (0%)]	Loss: 0.477011
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 221 is 1.001158
INFO:root:FL Epoch: 239 Done on worker:221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :456
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562673
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421406
INFO:root:FL Epoch: 239 Norm Difference for worker 456 is 1.083206
INFO:root:FL Epoch: 239 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :255
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 255 Train Epoch: 0 [0/201 (0%)]	Loss: 0.534158
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 255 Train Epoch: 1 [0/201 (0%)]	Loss: 0.526769
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 255 is 1.044825
INFO:root:FL Epoch: 239 Done on worker:255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :587
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533105
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417048
INFO:root:FL Epoch: 239 Norm Difference for worker 587 is 1.000884
INFO:root:FL Epoch: 239 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :86
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 86 Train Epoch: 0 [0/201 (0%)]	Loss: 0.448249
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 86 Train Epoch: 1 [0/201 (0%)]	Loss: 0.333831
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 239 Norm Difference for worker 86 is 0.980157
INFO:root:FL Epoch: 239 Done on worker:86
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1398
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696755
INFO:root:Worker: 1398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383291
INFO:root:FL Epoch: 239 Norm Difference for worker 1398 is 1.066674
INFO:root:FL Epoch: 239 Done on worker:1398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :451
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714189
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483321
INFO:root:FL Epoch: 239 Norm Difference for worker 451 is 1.110202
INFO:root:FL Epoch: 239 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1030
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1030 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701361
INFO:root:Worker: 1030 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504515
INFO:root:FL Epoch: 239 Norm Difference for worker 1030 is 1.10817
INFO:root:FL Epoch: 239 Done on worker:1030
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 86
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 239 Ends   ===================
INFO:root:Epoch:239 Global Model Test Loss:0.5639959188068614 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:239 Global Model Backdoor Test Loss:0.2715134521325429                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 240 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 240 Workers Selected : [1503, 627, 1705, 1702, 1356, 22, 1709, 31, 42, 358]
INFO:root:FL Epoch: 240 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 240 Num points on workers: [200 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 240 Training on worker :1503
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743165
INFO:root:Worker: 1503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355648
INFO:root:FL Epoch: 240 Norm Difference for worker 1503 is 1.041744
INFO:root:FL Epoch: 240 Done on worker:1503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :627
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407439
INFO:root:Worker: 627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568620
INFO:root:FL Epoch: 240 Norm Difference for worker 627 is 1.076698
INFO:root:FL Epoch: 240 Done on worker:627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1705
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428808
INFO:root:Worker: 1705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508818
INFO:root:FL Epoch: 240 Norm Difference for worker 1705 is 1.138477
INFO:root:FL Epoch: 240 Done on worker:1705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1702
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581092
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416445
INFO:root:FL Epoch: 240 Norm Difference for worker 1702 is 1.098265
INFO:root:FL Epoch: 240 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1356
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.888675
INFO:root:Worker: 1356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642295
INFO:root:FL Epoch: 240 Norm Difference for worker 1356 is 1.208601
INFO:root:FL Epoch: 240 Done on worker:1356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :22
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 22 Train Epoch: 0 [0/201 (0%)]	Loss: 0.530673
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 22 Train Epoch: 1 [0/201 (0%)]	Loss: 0.560297
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 22 is 1.111705
INFO:root:FL Epoch: 240 Done on worker:22
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1709
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686252
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518502
INFO:root:FL Epoch: 240 Norm Difference for worker 1709 is 1.109496
INFO:root:FL Epoch: 240 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :31
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 31 Train Epoch: 0 [0/201 (0%)]	Loss: 0.475528
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 31 Train Epoch: 1 [0/201 (0%)]	Loss: 0.502643
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 31 is 1.031054
INFO:root:FL Epoch: 240 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :42
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.647185
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.276667
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 42 is 0.976713
INFO:root:FL Epoch: 240 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :358
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319721
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496741
INFO:root:FL Epoch: 240 Norm Difference for worker 358 is 1.091172
INFO:root:FL Epoch: 240 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 240 Ends   ===================
INFO:root:Epoch:240 Global Model Test Loss:0.5594612517777611 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:240 Global Model Backdoor Test Loss:0.25585562735795975                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 241 Begins ===================
INFO:root:FL Epoch: 241 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 241 Workers Selected : [0, 1, 2, 1593, 1631, 1647, 1726, 1002, 1907, 518]
INFO:root:FL Epoch: 241 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 241 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 241 Training on worker :0
INFO:root:FL Epoch: 241 Using Learning rate : 0.006184860506246187 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315315
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.201918
INFO:root:FL Epoch: 241 Worker: 0 Backdoor Test Loss: 0.1897244080901146 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 241 Worker: 0 Backdoor Train Loss: 0.2517759293317795 Backdoor Train Accuracy: 91.0
INFO:root:FL Epoch: 241 Norm Difference for worker 0 is 0.206017
INFO:root:FL Epoch: 241 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1
INFO:root:FL Epoch: 241 Using Learning rate : 0.006184860506246187 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363031
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405454
INFO:root:FL Epoch: 241 Worker: 1 Backdoor Test Loss: 0.1893404001990954 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 241 Worker: 1 Backdoor Train Loss: 0.2522657483816147 Backdoor Train Accuracy: 91.0
INFO:root:FL Epoch: 241 Norm Difference for worker 1 is 0.205545
INFO:root:FL Epoch: 241 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :2
INFO:root:FL Epoch: 241 Using Learning rate : 0.006184860506246187 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356546
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270916
INFO:root:FL Epoch: 241 Worker: 2 Backdoor Test Loss: 0.19454897940158844 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 241 Worker: 2 Backdoor Train Loss: 0.2522453054785728 Backdoor Train Accuracy: 91.0
INFO:root:FL Epoch: 241 Norm Difference for worker 2 is 0.205525
INFO:root:FL Epoch: 241 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1593
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568331
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347331
INFO:root:FL Epoch: 241 Norm Difference for worker 1593 is 0.958201
INFO:root:FL Epoch: 241 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1631
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732087
INFO:root:Worker: 1631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514326
INFO:root:FL Epoch: 241 Norm Difference for worker 1631 is 1.11497
INFO:root:FL Epoch: 241 Done on worker:1631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1647
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.785087
INFO:root:Worker: 1647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493855
INFO:root:FL Epoch: 241 Norm Difference for worker 1647 is 1.1071
INFO:root:FL Epoch: 241 Done on worker:1647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1726
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611991
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624297
INFO:root:FL Epoch: 241 Norm Difference for worker 1726 is 1.080609
INFO:root:FL Epoch: 241 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1002
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1002 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395344
INFO:root:Worker: 1002 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345417
INFO:root:FL Epoch: 241 Norm Difference for worker 1002 is 1.016039
INFO:root:FL Epoch: 241 Done on worker:1002
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1907
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462901
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582866
INFO:root:FL Epoch: 241 Norm Difference for worker 1907 is 1.054
INFO:root:FL Epoch: 241 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :518
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.852595
INFO:root:Worker: 518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521181
INFO:root:FL Epoch: 241 Norm Difference for worker 518 is 1.09717
INFO:root:FL Epoch: 241 Done on worker:518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 241 Ends   ===================
INFO:root:Epoch:241 Global Model Test Loss:0.5618306906784282 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:241 Global Model Backdoor Test Loss:0.1893404001990954                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 242 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 242 Workers Selected : [1813, 1657, 1921, 123, 56, 975, 1165, 380, 313, 1324]
INFO:root:FL Epoch: 242 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 242 Num points on workers: [200 200 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 242 Training on worker :1813
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.273752
INFO:root:Worker: 1813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617536
INFO:root:FL Epoch: 242 Norm Difference for worker 1813 is 1.134525
INFO:root:FL Epoch: 242 Done on worker:1813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1657
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439535
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491422
INFO:root:FL Epoch: 242 Norm Difference for worker 1657 is 1.093171
INFO:root:FL Epoch: 242 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1921
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662802
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480384
INFO:root:FL Epoch: 242 Norm Difference for worker 1921 is 1.201114
INFO:root:FL Epoch: 242 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :123
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.286817
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.475529
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 123 is 1.060234
INFO:root:FL Epoch: 242 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :56
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 56 Train Epoch: 0 [0/201 (0%)]	Loss: 0.371031
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 56 Train Epoch: 1 [0/201 (0%)]	Loss: 0.442739
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 56 is 1.129882
INFO:root:FL Epoch: 242 Done on worker:56
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :975
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655614
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448136
INFO:root:FL Epoch: 242 Norm Difference for worker 975 is 1.145531
INFO:root:FL Epoch: 242 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1165
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648668
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563344
INFO:root:FL Epoch: 242 Norm Difference for worker 1165 is 1.150727
INFO:root:FL Epoch: 242 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :380
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526500
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563224
INFO:root:FL Epoch: 242 Norm Difference for worker 380 is 1.14327
INFO:root:FL Epoch: 242 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :313
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.391291
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.321575
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 313 is 1.099832
INFO:root:FL Epoch: 242 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1324
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551218
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600092
INFO:root:FL Epoch: 242 Norm Difference for worker 1324 is 1.084401
INFO:root:FL Epoch: 242 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 123
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 242 Ends   ===================
INFO:root:Epoch:242 Global Model Test Loss:0.5587421375162461 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:242 Global Model Backdoor Test Loss:0.1649924690524737                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 243 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 243 Workers Selected : [1593, 1300, 642, 1371, 278, 562, 1220, 620, 885, 1473]
INFO:root:FL Epoch: 243 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 243 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 243 Training on worker :1593
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552437
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520476
INFO:root:FL Epoch: 243 Norm Difference for worker 1593 is 1.055396
INFO:root:FL Epoch: 243 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1300
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440405
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495836
INFO:root:FL Epoch: 243 Norm Difference for worker 1300 is 1.208056
INFO:root:FL Epoch: 243 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :642
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696481
INFO:root:Worker: 642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641837
INFO:root:FL Epoch: 243 Norm Difference for worker 642 is 1.226866
INFO:root:FL Epoch: 243 Done on worker:642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1371
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649097
INFO:root:Worker: 1371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420952
INFO:root:FL Epoch: 243 Norm Difference for worker 1371 is 1.14674
INFO:root:FL Epoch: 243 Done on worker:1371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :278
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611980
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.457437
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 243 Norm Difference for worker 278 is 1.161834
INFO:root:FL Epoch: 243 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :562
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643102
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465580
INFO:root:FL Epoch: 243 Norm Difference for worker 562 is 1.118575
INFO:root:FL Epoch: 243 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1220
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393105
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520474
INFO:root:FL Epoch: 243 Norm Difference for worker 1220 is 1.047961
INFO:root:FL Epoch: 243 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :620
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522325
INFO:root:Worker: 620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548001
INFO:root:FL Epoch: 243 Norm Difference for worker 620 is 1.157732
INFO:root:FL Epoch: 243 Done on worker:620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :885
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346574
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338824
INFO:root:FL Epoch: 243 Norm Difference for worker 885 is 1.13903
INFO:root:FL Epoch: 243 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1473
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542194
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694842
INFO:root:FL Epoch: 243 Norm Difference for worker 1473 is 1.303699
INFO:root:FL Epoch: 243 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1220
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 243 Ends   ===================
INFO:root:Epoch:243 Global Model Test Loss:0.5641014277935028 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:243 Global Model Backdoor Test Loss:0.18324265629053116                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 244 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 244 Workers Selected : [828, 1531, 942, 1585, 214, 1712, 760, 1577, 161, 872]
INFO:root:FL Epoch: 244 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 244 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 244 Training on worker :828
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758464
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651379
INFO:root:FL Epoch: 244 Norm Difference for worker 828 is 1.137748
INFO:root:FL Epoch: 244 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1531
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.843125
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537321
INFO:root:FL Epoch: 244 Norm Difference for worker 1531 is 1.052925
INFO:root:FL Epoch: 244 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :942
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455577
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414592
INFO:root:FL Epoch: 244 Norm Difference for worker 942 is 0.984347
INFO:root:FL Epoch: 244 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1585
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620881
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500621
INFO:root:FL Epoch: 244 Norm Difference for worker 1585 is 1.024577
INFO:root:FL Epoch: 244 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :214
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.813700
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.472693
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 214 is 0.996768
INFO:root:FL Epoch: 244 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1712
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557108
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694629
INFO:root:FL Epoch: 244 Norm Difference for worker 1712 is 0.956927
INFO:root:FL Epoch: 244 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :760
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636031
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450530
INFO:root:FL Epoch: 244 Norm Difference for worker 760 is 1.042706
INFO:root:FL Epoch: 244 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1577
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763218
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439950
INFO:root:FL Epoch: 244 Norm Difference for worker 1577 is 1.026905
INFO:root:FL Epoch: 244 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :161
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.288775
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.537494
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 161 is 0.902766
INFO:root:FL Epoch: 244 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :872
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443577
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381834
INFO:root:FL Epoch: 244 Norm Difference for worker 872 is 1.02396
INFO:root:FL Epoch: 244 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 161
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 244 Ends   ===================
INFO:root:Epoch:244 Global Model Test Loss:0.6032592286081875 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:244 Global Model Backdoor Test Loss:0.11620017637809117                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 245 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 245 Workers Selected : [42, 320, 1861, 965, 484, 884, 1238, 214, 1012, 674]
INFO:root:FL Epoch: 245 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 245 Num points on workers: [201 201 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 245 Training on worker :42
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.159092
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.480035
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 42 is 0.978134
INFO:root:FL Epoch: 245 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :320
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.605137
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.392395
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 320 is 1.329224
INFO:root:FL Epoch: 245 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1861
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378751
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558671
INFO:root:FL Epoch: 245 Norm Difference for worker 1861 is 1.326848
INFO:root:FL Epoch: 245 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :965
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 965 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383993
INFO:root:Worker: 965 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413550
INFO:root:FL Epoch: 245 Norm Difference for worker 965 is 1.202088
INFO:root:FL Epoch: 245 Done on worker:965
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :484
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531924
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.759413
INFO:root:FL Epoch: 245 Norm Difference for worker 484 is 1.288221
INFO:root:FL Epoch: 245 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :884
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304157
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547344
INFO:root:FL Epoch: 245 Norm Difference for worker 884 is 1.367036
INFO:root:FL Epoch: 245 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1238
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629194
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290012
INFO:root:FL Epoch: 245 Norm Difference for worker 1238 is 1.224784
INFO:root:FL Epoch: 245 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :214
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.395233
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.715879
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 245 Norm Difference for worker 214 is 1.25092
INFO:root:FL Epoch: 245 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1012
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536789
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509679
INFO:root:FL Epoch: 245 Norm Difference for worker 1012 is 1.173927
INFO:root:FL Epoch: 245 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :674
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531007
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446578
INFO:root:FL Epoch: 245 Norm Difference for worker 674 is 1.314856
INFO:root:FL Epoch: 245 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 245 Ends   ===================
INFO:root:Epoch:245 Global Model Test Loss:0.6068986812058617 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:245 Global Model Backdoor Test Loss:0.1276260701318582                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 246 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 246 Workers Selected : [501, 1726, 1606, 1903, 59, 1152, 944, 1138, 484, 1176]
INFO:root:FL Epoch: 246 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 246 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 246 Training on worker :501
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438658
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647768
INFO:root:FL Epoch: 246 Norm Difference for worker 501 is 1.251105
INFO:root:FL Epoch: 246 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1726
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559813
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378688
INFO:root:FL Epoch: 246 Norm Difference for worker 1726 is 1.365163
INFO:root:FL Epoch: 246 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1606
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575523
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447708
INFO:root:FL Epoch: 246 Norm Difference for worker 1606 is 1.302342
INFO:root:FL Epoch: 246 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1903
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.958748
INFO:root:Worker: 1903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336761
INFO:root:FL Epoch: 246 Norm Difference for worker 1903 is 1.381388
INFO:root:FL Epoch: 246 Done on worker:1903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :59
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.583948
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.531200
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 246 Norm Difference for worker 59 is 1.384589
INFO:root:FL Epoch: 246 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1152
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1152 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508366
INFO:root:Worker: 1152 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608725
INFO:root:FL Epoch: 246 Norm Difference for worker 1152 is 1.478915
INFO:root:FL Epoch: 246 Done on worker:1152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :944
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527195
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334553
INFO:root:FL Epoch: 246 Norm Difference for worker 944 is 1.376189
INFO:root:FL Epoch: 246 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1138
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 1.011884
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358409
INFO:root:FL Epoch: 246 Norm Difference for worker 1138 is 1.508828
INFO:root:FL Epoch: 246 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :484
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340979
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357426
INFO:root:FL Epoch: 246 Norm Difference for worker 484 is 1.344604
INFO:root:FL Epoch: 246 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1176
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553602
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443206
INFO:root:FL Epoch: 246 Norm Difference for worker 1176 is 1.377632
INFO:root:FL Epoch: 246 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 501
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 246 Ends   ===================
INFO:root:Epoch:246 Global Model Test Loss:0.5672545222675099 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:246 Global Model Backdoor Test Loss:0.25017596036195755                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 247 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 247 Workers Selected : [1188, 1113, 1084, 1606, 769, 829, 116, 544, 1566, 1301]
INFO:root:FL Epoch: 247 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 247 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 247 Training on worker :1188
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.989768
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.746319
INFO:root:FL Epoch: 247 Norm Difference for worker 1188 is 1.161813
INFO:root:FL Epoch: 247 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1113
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1113 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670978
INFO:root:Worker: 1113 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560974
INFO:root:FL Epoch: 247 Norm Difference for worker 1113 is 1.104946
INFO:root:FL Epoch: 247 Done on worker:1113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1084
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571454
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437919
INFO:root:FL Epoch: 247 Norm Difference for worker 1084 is 1.172453
INFO:root:FL Epoch: 247 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1606
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373217
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421987
INFO:root:FL Epoch: 247 Norm Difference for worker 1606 is 1.084458
INFO:root:FL Epoch: 247 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :769
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693508
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508228
INFO:root:FL Epoch: 247 Norm Difference for worker 769 is 1.124917
INFO:root:FL Epoch: 247 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :829
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593220
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581730
INFO:root:FL Epoch: 247 Norm Difference for worker 829 is 1.145601
INFO:root:FL Epoch: 247 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :116
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.564664
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428460
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 247 Norm Difference for worker 116 is 1.121199
INFO:root:FL Epoch: 247 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :544
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546936
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531480
INFO:root:FL Epoch: 247 Norm Difference for worker 544 is 1.09084
INFO:root:FL Epoch: 247 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1566
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.853131
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627172
INFO:root:FL Epoch: 247 Norm Difference for worker 1566 is 1.066653
INFO:root:FL Epoch: 247 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1301
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1301 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653391
INFO:root:Worker: 1301 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643689
INFO:root:FL Epoch: 247 Norm Difference for worker 1301 is 1.192079
INFO:root:FL Epoch: 247 Done on worker:1301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1566
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 247 Ends   ===================
INFO:root:Epoch:247 Global Model Test Loss:0.5627157828387093 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:247 Global Model Backdoor Test Loss:0.2405649572610855                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 248 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 248 Workers Selected : [36, 1147, 785, 826, 778, 373, 1904, 495, 501, 869]
INFO:root:FL Epoch: 248 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 248 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 248 Training on worker :36
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 36 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500221
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 36 Train Epoch: 1 [0/201 (0%)]	Loss: 0.454207
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 248 Norm Difference for worker 36 is 0.955884
INFO:root:FL Epoch: 248 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1147
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1147 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620326
INFO:root:Worker: 1147 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483049
INFO:root:FL Epoch: 248 Norm Difference for worker 1147 is 0.94645
INFO:root:FL Epoch: 248 Done on worker:1147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :785
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715199
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375382
INFO:root:FL Epoch: 248 Norm Difference for worker 785 is 0.989092
INFO:root:FL Epoch: 248 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :826
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504508
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522263
INFO:root:FL Epoch: 248 Norm Difference for worker 826 is 1.02711
INFO:root:FL Epoch: 248 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :778
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718562
INFO:root:Worker: 778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457547
INFO:root:FL Epoch: 248 Norm Difference for worker 778 is 0.982629
INFO:root:FL Epoch: 248 Done on worker:778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :373
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453343
INFO:root:Worker: 373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522028
INFO:root:FL Epoch: 248 Norm Difference for worker 373 is 1.008282
INFO:root:FL Epoch: 248 Done on worker:373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1904
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465469
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517985
INFO:root:FL Epoch: 248 Norm Difference for worker 1904 is 1.017615
INFO:root:FL Epoch: 248 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :495
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636096
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473353
INFO:root:FL Epoch: 248 Norm Difference for worker 495 is 0.979253
INFO:root:FL Epoch: 248 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :501
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330825
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370736
INFO:root:FL Epoch: 248 Norm Difference for worker 501 is 0.837462
INFO:root:FL Epoch: 248 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :869
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529260
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467263
INFO:root:FL Epoch: 248 Norm Difference for worker 869 is 0.926039
INFO:root:FL Epoch: 248 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 501
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 248 Ends   ===================
INFO:root:Epoch:248 Global Model Test Loss:0.5837529669789707 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:248 Global Model Backdoor Test Loss:0.18025194853544235                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 249 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 249 Workers Selected : [606, 1727, 935, 362, 666, 491, 80, 1533, 496, 290]
INFO:root:FL Epoch: 249 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 249 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 249 Training on worker :606
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463974
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424123
INFO:root:FL Epoch: 249 Norm Difference for worker 606 is 1.183332
INFO:root:FL Epoch: 249 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1727
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755779
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386053
INFO:root:FL Epoch: 249 Norm Difference for worker 1727 is 1.262886
INFO:root:FL Epoch: 249 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :935
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401739
INFO:root:Worker: 935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521614
INFO:root:FL Epoch: 249 Norm Difference for worker 935 is 1.27306
INFO:root:FL Epoch: 249 Done on worker:935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :362
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704103
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448174
INFO:root:FL Epoch: 249 Norm Difference for worker 362 is 1.281881
INFO:root:FL Epoch: 249 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :666
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533449
INFO:root:Worker: 666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531041
INFO:root:FL Epoch: 249 Norm Difference for worker 666 is 1.320443
INFO:root:FL Epoch: 249 Done on worker:666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :491
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396625
INFO:root:Worker: 491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466810
INFO:root:FL Epoch: 249 Norm Difference for worker 491 is 1.188631
INFO:root:FL Epoch: 249 Done on worker:491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :80
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691207
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.465337
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 249 Norm Difference for worker 80 is 1.198466
INFO:root:FL Epoch: 249 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1533
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727330
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597064
INFO:root:FL Epoch: 249 Norm Difference for worker 1533 is 1.355131
INFO:root:FL Epoch: 249 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :496
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.279518
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648031
INFO:root:FL Epoch: 249 Norm Difference for worker 496 is 1.209691
INFO:root:FL Epoch: 249 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :290
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.570383
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.341357
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 249 Norm Difference for worker 290 is 1.340895
INFO:root:FL Epoch: 249 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 606
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 249 Ends   ===================
INFO:root:Epoch:249 Global Model Test Loss:0.5651373898281771 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:249 Global Model Backdoor Test Loss:0.30143966029087704                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 250 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 250 Workers Selected : [78, 296, 1388, 169, 351, 1200, 1052, 729, 151, 1317]
INFO:root:FL Epoch: 250 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 250 Num points on workers: [201 201 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 250 Training on worker :78
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.365685
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.407351
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 78 is 1.056057
INFO:root:FL Epoch: 250 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :296
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 296 Train Epoch: 0 [0/201 (0%)]	Loss: 0.670468
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 296 Train Epoch: 1 [0/201 (0%)]	Loss: 0.472651
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 296 is 1.104691
INFO:root:FL Epoch: 250 Done on worker:296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1388
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592667
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432582
INFO:root:FL Epoch: 250 Norm Difference for worker 1388 is 1.097879
INFO:root:FL Epoch: 250 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :169
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.423717
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.506061
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 169 is 1.062287
INFO:root:FL Epoch: 250 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :351
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579777
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.762715
INFO:root:FL Epoch: 250 Norm Difference for worker 351 is 1.127843
INFO:root:FL Epoch: 250 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1200
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1200 Train Epoch: 0 [0/200 (0%)]	Loss: 0.933955
INFO:root:Worker: 1200 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501015
INFO:root:FL Epoch: 250 Norm Difference for worker 1200 is 1.117563
INFO:root:FL Epoch: 250 Done on worker:1200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1052
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.886327
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652772
INFO:root:FL Epoch: 250 Norm Difference for worker 1052 is 1.037968
INFO:root:FL Epoch: 250 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :729
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669292
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655240
INFO:root:FL Epoch: 250 Norm Difference for worker 729 is 1.167664
INFO:root:FL Epoch: 250 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :151
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.439868
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.477573
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 151 is 1.096863
INFO:root:FL Epoch: 250 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1317
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628930
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639803
INFO:root:FL Epoch: 250 Norm Difference for worker 1317 is 1.205434
INFO:root:FL Epoch: 250 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1052
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 250 Ends   ===================
INFO:root:Epoch:250 Global Model Test Loss:0.5379286005216486 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:250 Global Model Backdoor Test Loss:0.24228108674287796                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 251 Begins ===================
INFO:root:FL Epoch: 251 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 251 Workers Selected : [0, 1, 2, 764, 1000, 718, 697, 204, 1862, 913]
INFO:root:FL Epoch: 251 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 251 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 251 Training on worker :0
INFO:root:FL Epoch: 251 Using Learning rate : 0.0060622706542776406 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.311495
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443789
INFO:root:FL Epoch: 251 Worker: 0 Backdoor Test Loss: 0.18229064345359802 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 251 Worker: 0 Backdoor Train Loss: 0.24988666772842408 Backdoor Train Accuracy: 92.0
INFO:root:FL Epoch: 251 Norm Difference for worker 0 is 0.203803
INFO:root:FL Epoch: 251 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1
INFO:root:FL Epoch: 251 Using Learning rate : 0.0060622706542776406 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358011
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222982
INFO:root:FL Epoch: 251 Worker: 1 Backdoor Test Loss: 0.17904257526000342 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 251 Worker: 1 Backdoor Train Loss: 0.2510699167847633 Backdoor Train Accuracy: 92.5
INFO:root:FL Epoch: 251 Norm Difference for worker 1 is 0.200737
INFO:root:FL Epoch: 251 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :2
INFO:root:FL Epoch: 251 Using Learning rate : 0.0060622706542776406 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.237062
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265046
INFO:root:FL Epoch: 251 Worker: 2 Backdoor Test Loss: 0.18013823280731836 Backdoor Test Accuracy: 95.0
INFO:root:FL Epoch: 251 Worker: 2 Backdoor Train Loss: 0.24923716634511947 Backdoor Train Accuracy: 92.5
INFO:root:FL Epoch: 251 Norm Difference for worker 2 is 0.206238
INFO:root:FL Epoch: 251 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :764
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530666
INFO:root:Worker: 764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332905
INFO:root:FL Epoch: 251 Norm Difference for worker 764 is 0.981073
INFO:root:FL Epoch: 251 Done on worker:764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1000
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420678
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652729
INFO:root:FL Epoch: 251 Norm Difference for worker 1000 is 1.10436
INFO:root:FL Epoch: 251 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :718
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440239
INFO:root:Worker: 718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504168
INFO:root:FL Epoch: 251 Norm Difference for worker 718 is 1.012344
INFO:root:FL Epoch: 251 Done on worker:718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :697
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502124
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438902
INFO:root:FL Epoch: 251 Norm Difference for worker 697 is 1.064949
INFO:root:FL Epoch: 251 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :204
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490011
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.562006
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 251 Norm Difference for worker 204 is 1.068278
INFO:root:FL Epoch: 251 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1862
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627794
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499409
INFO:root:FL Epoch: 251 Norm Difference for worker 1862 is 1.061503
INFO:root:FL Epoch: 251 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :913
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552052
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499031
INFO:root:FL Epoch: 251 Norm Difference for worker 913 is 1.062332
INFO:root:FL Epoch: 251 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 251 Ends   ===================
INFO:root:Epoch:251 Global Model Test Loss:0.5385258320499869 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:251 Global Model Backdoor Test Loss:0.17904257526000342                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 252 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 252 Workers Selected : [1465, 1481, 1390, 1870, 755, 1728, 1074, 655, 1734, 1268]
INFO:root:FL Epoch: 252 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 252 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 252 Training on worker :1465
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.295363
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476197
INFO:root:FL Epoch: 252 Norm Difference for worker 1465 is 1.09845
INFO:root:FL Epoch: 252 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1481
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783043
INFO:root:Worker: 1481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494430
INFO:root:FL Epoch: 252 Norm Difference for worker 1481 is 1.16209
INFO:root:FL Epoch: 252 Done on worker:1481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1390
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520943
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500867
INFO:root:FL Epoch: 252 Norm Difference for worker 1390 is 1.110359
INFO:root:FL Epoch: 252 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1870
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525110
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585201
INFO:root:FL Epoch: 252 Norm Difference for worker 1870 is 1.086763
INFO:root:FL Epoch: 252 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :755
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446883
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395221
INFO:root:FL Epoch: 252 Norm Difference for worker 755 is 1.093705
INFO:root:FL Epoch: 252 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1728
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494553
INFO:root:Worker: 1728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541518
INFO:root:FL Epoch: 252 Norm Difference for worker 1728 is 1.10408
INFO:root:FL Epoch: 252 Done on worker:1728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1074
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1074 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486110
INFO:root:Worker: 1074 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455203
INFO:root:FL Epoch: 252 Norm Difference for worker 1074 is 1.120213
INFO:root:FL Epoch: 252 Done on worker:1074
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :655
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368155
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444114
INFO:root:FL Epoch: 252 Norm Difference for worker 655 is 1.042855
INFO:root:FL Epoch: 252 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1734
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685019
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421565
INFO:root:FL Epoch: 252 Norm Difference for worker 1734 is 1.039063
INFO:root:FL Epoch: 252 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1268
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386325
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328473
INFO:root:FL Epoch: 252 Norm Difference for worker 1268 is 1.02625
INFO:root:FL Epoch: 252 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1734
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 252 Ends   ===================
INFO:root:Epoch:252 Global Model Test Loss:0.5370213529642891 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:252 Global Model Backdoor Test Loss:0.22440939396619797                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 253 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 253 Workers Selected : [1274, 1234, 852, 1737, 1163, 213, 1350, 291, 800, 1016]
INFO:root:FL Epoch: 253 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 253 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 253 Training on worker :1274
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356963
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.747664
INFO:root:FL Epoch: 253 Norm Difference for worker 1274 is 1.123023
INFO:root:FL Epoch: 253 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1234
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522676
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.716294
INFO:root:FL Epoch: 253 Norm Difference for worker 1234 is 1.098443
INFO:root:FL Epoch: 253 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :852
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.765284
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507173
INFO:root:FL Epoch: 253 Norm Difference for worker 852 is 1.009881
INFO:root:FL Epoch: 253 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1737
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.806047
INFO:root:Worker: 1737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402672
INFO:root:FL Epoch: 253 Norm Difference for worker 1737 is 0.950815
INFO:root:FL Epoch: 253 Done on worker:1737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1163
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622404
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436932
INFO:root:FL Epoch: 253 Norm Difference for worker 1163 is 1.050584
INFO:root:FL Epoch: 253 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :213
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.475731
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.560652
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 253 Norm Difference for worker 213 is 0.983741
INFO:root:FL Epoch: 253 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1350
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.880821
INFO:root:Worker: 1350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491100
INFO:root:FL Epoch: 253 Norm Difference for worker 1350 is 0.986398
INFO:root:FL Epoch: 253 Done on worker:1350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :291
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.363756
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.303791
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 253 Norm Difference for worker 291 is 0.980131
INFO:root:FL Epoch: 253 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :800
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633717
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563821
INFO:root:FL Epoch: 253 Norm Difference for worker 800 is 0.993747
INFO:root:FL Epoch: 253 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1016
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.767402
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286627
INFO:root:FL Epoch: 253 Norm Difference for worker 1016 is 1.020829
INFO:root:FL Epoch: 253 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1737
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 253 Ends   ===================
INFO:root:Epoch:253 Global Model Test Loss:0.5293789015096777 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:253 Global Model Backdoor Test Loss:0.14973880971471468                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 254 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 254 Workers Selected : [1754, 1163, 896, 38, 1431, 945, 1882, 1311, 721, 844]
INFO:root:FL Epoch: 254 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 254 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 254 Training on worker :1754
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584222
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431678
INFO:root:FL Epoch: 254 Norm Difference for worker 1754 is 0.980339
INFO:root:FL Epoch: 254 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1163
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495645
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311023
INFO:root:FL Epoch: 254 Norm Difference for worker 1163 is 1.058354
INFO:root:FL Epoch: 254 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :896
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410940
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408069
INFO:root:FL Epoch: 254 Norm Difference for worker 896 is 1.04232
INFO:root:FL Epoch: 254 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :38
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.340586
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.289147
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 254 Norm Difference for worker 38 is 0.934365
INFO:root:FL Epoch: 254 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1431
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590221
INFO:root:Worker: 1431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367733
INFO:root:FL Epoch: 254 Norm Difference for worker 1431 is 1.037462
INFO:root:FL Epoch: 254 Done on worker:1431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :945
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568576
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411493
INFO:root:FL Epoch: 254 Norm Difference for worker 945 is 1.011291
INFO:root:FL Epoch: 254 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1882
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436619
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400352
INFO:root:FL Epoch: 254 Norm Difference for worker 1882 is 1.081443
INFO:root:FL Epoch: 254 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1311
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567730
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390701
INFO:root:FL Epoch: 254 Norm Difference for worker 1311 is 1.111518
INFO:root:FL Epoch: 254 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :721
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598291
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415689
INFO:root:FL Epoch: 254 Norm Difference for worker 721 is 1.087695
INFO:root:FL Epoch: 254 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :844
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459068
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544681
INFO:root:FL Epoch: 254 Norm Difference for worker 844 is 1.071288
INFO:root:FL Epoch: 254 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 38
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 254 Ends   ===================
INFO:root:Epoch:254 Global Model Test Loss:0.5483969818143284 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:254 Global Model Backdoor Test Loss:0.13060004264116287                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 255 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 255 Workers Selected : [1458, 415, 1593, 1941, 575, 1329, 88, 1317, 1582, 1124]
INFO:root:FL Epoch: 255 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 255 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 255 Training on worker :1458
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.795991
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559860
INFO:root:FL Epoch: 255 Norm Difference for worker 1458 is 1.267714
INFO:root:FL Epoch: 255 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :415
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562255
INFO:root:Worker: 415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686759
INFO:root:FL Epoch: 255 Norm Difference for worker 415 is 1.249449
INFO:root:FL Epoch: 255 Done on worker:415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1593
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719783
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468836
INFO:root:FL Epoch: 255 Norm Difference for worker 1593 is 1.172781
INFO:root:FL Epoch: 255 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1941
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492191
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473499
INFO:root:FL Epoch: 255 Norm Difference for worker 1941 is 1.240423
INFO:root:FL Epoch: 255 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :575
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.893983
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455195
INFO:root:FL Epoch: 255 Norm Difference for worker 575 is 1.427814
INFO:root:FL Epoch: 255 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1329
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716783
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624459
INFO:root:FL Epoch: 255 Norm Difference for worker 1329 is 1.173214
INFO:root:FL Epoch: 255 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :88
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 88 Train Epoch: 0 [0/201 (0%)]	Loss: 0.584474
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 88 Train Epoch: 1 [0/201 (0%)]	Loss: 0.468210
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 255 Norm Difference for worker 88 is 1.282414
INFO:root:FL Epoch: 255 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1317
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539974
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468938
INFO:root:FL Epoch: 255 Norm Difference for worker 1317 is 1.337312
INFO:root:FL Epoch: 255 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1582
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553650
INFO:root:Worker: 1582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.906049
INFO:root:FL Epoch: 255 Norm Difference for worker 1582 is 1.45282
INFO:root:FL Epoch: 255 Done on worker:1582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1124
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 1.095461
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636054
INFO:root:FL Epoch: 255 Norm Difference for worker 1124 is 1.346025
INFO:root:FL Epoch: 255 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1593
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 255 Ends   ===================
INFO:root:Epoch:255 Global Model Test Loss:0.5470598585465375 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:255 Global Model Backdoor Test Loss:0.19581652308503786                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 256 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 256 Workers Selected : [1806, 864, 1226, 325, 424, 1188, 1760, 100, 1464, 887]
INFO:root:FL Epoch: 256 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 256 Num points on workers: [200 200 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 256 Training on worker :1806
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650885
INFO:root:Worker: 1806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466902
INFO:root:FL Epoch: 256 Norm Difference for worker 1806 is 0.95625
INFO:root:FL Epoch: 256 Done on worker:1806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :864
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652519
INFO:root:Worker: 864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470058
INFO:root:FL Epoch: 256 Norm Difference for worker 864 is 1.004214
INFO:root:FL Epoch: 256 Done on worker:864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1226
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589304
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347315
INFO:root:FL Epoch: 256 Norm Difference for worker 1226 is 1.10574
INFO:root:FL Epoch: 256 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :325
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.525491
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.402056
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 256 Norm Difference for worker 325 is 1.048736
INFO:root:FL Epoch: 256 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :424
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564587
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510439
INFO:root:FL Epoch: 256 Norm Difference for worker 424 is 0.907986
INFO:root:FL Epoch: 256 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1188
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.852400
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602108
INFO:root:FL Epoch: 256 Norm Difference for worker 1188 is 1.011473
INFO:root:FL Epoch: 256 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1760
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781360
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591401
INFO:root:FL Epoch: 256 Norm Difference for worker 1760 is 1.103648
INFO:root:FL Epoch: 256 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :100
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.512441
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699951
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 256 Norm Difference for worker 100 is 1.040329
INFO:root:FL Epoch: 256 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1464
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481810
INFO:root:Worker: 1464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350251
INFO:root:FL Epoch: 256 Norm Difference for worker 1464 is 0.980174
INFO:root:FL Epoch: 256 Done on worker:1464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :887
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413476
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648108
INFO:root:FL Epoch: 256 Norm Difference for worker 887 is 1.02403
INFO:root:FL Epoch: 256 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 424
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 256 Ends   ===================
INFO:root:Epoch:256 Global Model Test Loss:0.5421611526433159 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:256 Global Model Backdoor Test Loss:0.1667496015628179                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 257 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 257 Workers Selected : [1443, 3, 324, 653, 780, 610, 309, 393, 1556, 602]
INFO:root:FL Epoch: 257 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 257 Num points on workers: [200 201 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 257 Training on worker :1443
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613777
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506039
INFO:root:FL Epoch: 257 Norm Difference for worker 1443 is 1.117133
INFO:root:FL Epoch: 257 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :3
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.433822
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.579033
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 3 is 1.093278
INFO:root:FL Epoch: 257 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :324
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.433698
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431624
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 324 is 1.022797
INFO:root:FL Epoch: 257 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :653
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484438
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451849
INFO:root:FL Epoch: 257 Norm Difference for worker 653 is 1.060885
INFO:root:FL Epoch: 257 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :780
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.829312
INFO:root:Worker: 780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353521
INFO:root:FL Epoch: 257 Norm Difference for worker 780 is 1.074263
INFO:root:FL Epoch: 257 Done on worker:780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :610
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353832
INFO:root:Worker: 610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647772
INFO:root:FL Epoch: 257 Norm Difference for worker 610 is 1.074681
INFO:root:FL Epoch: 257 Done on worker:610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :309
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 309 Train Epoch: 0 [0/201 (0%)]	Loss: 0.666239
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 309 Train Epoch: 1 [0/201 (0%)]	Loss: 0.626739
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 309 is 1.121501
INFO:root:FL Epoch: 257 Done on worker:309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :393
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531840
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379983
INFO:root:FL Epoch: 257 Norm Difference for worker 393 is 1.068602
INFO:root:FL Epoch: 257 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :1556
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641766
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472774
INFO:root:FL Epoch: 257 Norm Difference for worker 1556 is 1.030779
INFO:root:FL Epoch: 257 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :602
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449091
INFO:root:Worker: 602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389383
INFO:root:FL Epoch: 257 Norm Difference for worker 602 is 1.094854
INFO:root:FL Epoch: 257 Done on worker:602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 324
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 257 Ends   ===================
INFO:root:Epoch:257 Global Model Test Loss:0.5285365336081561 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:257 Global Model Backdoor Test Loss:0.1643194854259491                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 258 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 258 Workers Selected : [1162, 1887, 1228, 1028, 1657, 1687, 1086, 388, 429, 973]
INFO:root:FL Epoch: 258 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 258 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 258 Training on worker :1162
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1162 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511193
INFO:root:Worker: 1162 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540922
INFO:root:FL Epoch: 258 Norm Difference for worker 1162 is 1.158721
INFO:root:FL Epoch: 258 Done on worker:1162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1887
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587629
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503280
INFO:root:FL Epoch: 258 Norm Difference for worker 1887 is 0.925735
INFO:root:FL Epoch: 258 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1228
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1228 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430989
INFO:root:Worker: 1228 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490150
INFO:root:FL Epoch: 258 Norm Difference for worker 1228 is 0.994779
INFO:root:FL Epoch: 258 Done on worker:1228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1028
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528405
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513001
INFO:root:FL Epoch: 258 Norm Difference for worker 1028 is 1.046312
INFO:root:FL Epoch: 258 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1657
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417270
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535716
INFO:root:FL Epoch: 258 Norm Difference for worker 1657 is 1.039162
INFO:root:FL Epoch: 258 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1687
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595399
INFO:root:Worker: 1687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527138
INFO:root:FL Epoch: 258 Norm Difference for worker 1687 is 1.338178
INFO:root:FL Epoch: 258 Done on worker:1687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1086
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474536
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512117
INFO:root:FL Epoch: 258 Norm Difference for worker 1086 is 1.079395
INFO:root:FL Epoch: 258 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :388
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370559
INFO:root:Worker: 388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459588
INFO:root:FL Epoch: 258 Norm Difference for worker 388 is 1.248684
INFO:root:FL Epoch: 258 Done on worker:388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :429
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473959
INFO:root:Worker: 429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532460
INFO:root:FL Epoch: 258 Norm Difference for worker 429 is 0.982105
INFO:root:FL Epoch: 258 Done on worker:429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :973
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546040
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550726
INFO:root:FL Epoch: 258 Norm Difference for worker 973 is 1.027189
INFO:root:FL Epoch: 258 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1086
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 258 Ends   ===================
INFO:root:Epoch:258 Global Model Test Loss:0.5590671774219064 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:258 Global Model Backdoor Test Loss:0.39026794334252674                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 259 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 259 Workers Selected : [9, 1195, 213, 53, 147, 1859, 429, 1183, 1225, 1102]
INFO:root:FL Epoch: 259 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.1002994 0.1002994 0.1002994 0.0998004 0.0998004
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 259 Num points on workers: [201 200 201 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 259 Training on worker :9
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.499381
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.542981
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 9 is 0.889845
INFO:root:FL Epoch: 259 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1195
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768196
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613834
INFO:root:FL Epoch: 259 Norm Difference for worker 1195 is 0.876726
INFO:root:FL Epoch: 259 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :213
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.895549
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.779272
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 213 is 0.90992
INFO:root:FL Epoch: 259 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :53
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 53 Train Epoch: 0 [0/201 (0%)]	Loss: 0.429500
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 53 Train Epoch: 1 [0/201 (0%)]	Loss: 0.348144
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 53 is 0.809805
INFO:root:FL Epoch: 259 Done on worker:53
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :147
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.552552
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.363202
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 147 is 0.820596
INFO:root:FL Epoch: 259 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1859
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451256
INFO:root:Worker: 1859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519449
INFO:root:FL Epoch: 259 Norm Difference for worker 1859 is 0.812191
INFO:root:FL Epoch: 259 Done on worker:1859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :429
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426978
INFO:root:Worker: 429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553857
INFO:root:FL Epoch: 259 Norm Difference for worker 429 is 0.883599
INFO:root:FL Epoch: 259 Done on worker:429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1183
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1183 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606744
INFO:root:Worker: 1183 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578068
INFO:root:FL Epoch: 259 Norm Difference for worker 1183 is 0.899099
INFO:root:FL Epoch: 259 Done on worker:1183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1225
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1225 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746798
INFO:root:Worker: 1225 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553503
INFO:root:FL Epoch: 259 Norm Difference for worker 1225 is 0.872207
INFO:root:FL Epoch: 259 Done on worker:1225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1102
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428662
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485263
INFO:root:FL Epoch: 259 Norm Difference for worker 1102 is 0.972845
INFO:root:FL Epoch: 259 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 147
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 259 Ends   ===================
INFO:root:Epoch:259 Global Model Test Loss:0.5442820349160362 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:259 Global Model Backdoor Test Loss:0.2958305204908053                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 260 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 260 Workers Selected : [1793, 1652, 1184, 1482, 1085, 257, 1289, 1365, 864, 1611]
INFO:root:FL Epoch: 260 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 260 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 260 Training on worker :1793
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461519
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.719010
INFO:root:FL Epoch: 260 Norm Difference for worker 1793 is 0.859379
INFO:root:FL Epoch: 260 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1652
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.811731
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523906
INFO:root:FL Epoch: 260 Norm Difference for worker 1652 is 0.828142
INFO:root:FL Epoch: 260 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1184
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1184 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580751
INFO:root:Worker: 1184 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590688
INFO:root:FL Epoch: 260 Norm Difference for worker 1184 is 0.838967
INFO:root:FL Epoch: 260 Done on worker:1184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1482
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626455
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508635
INFO:root:FL Epoch: 260 Norm Difference for worker 1482 is 0.849428
INFO:root:FL Epoch: 260 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1085
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589290
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439385
INFO:root:FL Epoch: 260 Norm Difference for worker 1085 is 0.819037
INFO:root:FL Epoch: 260 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :257
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.574515
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.568936
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 260 Norm Difference for worker 257 is 0.957974
INFO:root:FL Epoch: 260 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1289
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1289 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560097
INFO:root:Worker: 1289 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589618
INFO:root:FL Epoch: 260 Norm Difference for worker 1289 is 0.830438
INFO:root:FL Epoch: 260 Done on worker:1289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1365
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575124
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433411
INFO:root:FL Epoch: 260 Norm Difference for worker 1365 is 0.836908
INFO:root:FL Epoch: 260 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :864
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648745
INFO:root:Worker: 864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668957
INFO:root:FL Epoch: 260 Norm Difference for worker 864 is 0.815432
INFO:root:FL Epoch: 260 Done on worker:864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1611
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683948
INFO:root:Worker: 1611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415613
INFO:root:FL Epoch: 260 Norm Difference for worker 1611 is 0.819793
INFO:root:FL Epoch: 260 Done on worker:1611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1289
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 260 Ends   ===================
INFO:root:Epoch:260 Global Model Test Loss:0.5515897624632892 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:260 Global Model Backdoor Test Loss:0.30352242787679035                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 261 Begins ===================
INFO:root:FL Epoch: 261 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 261 Workers Selected : [0, 1, 2, 947, 1647, 422, 127, 1270, 1475, 1332]
INFO:root:FL Epoch: 261 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 261 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 261 Training on worker :0
INFO:root:FL Epoch: 261 Using Learning rate : 0.005942110650450455 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.267508
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287342
INFO:root:FL Epoch: 261 Worker: 0 Backdoor Test Loss: 0.1991389145453771 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 261 Worker: 0 Backdoor Train Loss: 0.23990704715251923 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 261 Norm Difference for worker 0 is 0.211015
INFO:root:FL Epoch: 261 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1
INFO:root:FL Epoch: 261 Using Learning rate : 0.005942110650450455 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385682
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210861
INFO:root:FL Epoch: 261 Worker: 1 Backdoor Test Loss: 0.20496002833048502 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 261 Worker: 1 Backdoor Train Loss: 0.24147073924541473 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 261 Norm Difference for worker 1 is 0.203612
INFO:root:FL Epoch: 261 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :2
INFO:root:FL Epoch: 261 Using Learning rate : 0.005942110650450455 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.265152
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242832
INFO:root:FL Epoch: 261 Worker: 2 Backdoor Test Loss: 0.20692525058984756 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 261 Worker: 2 Backdoor Train Loss: 0.2422403149306774 Backdoor Train Accuracy: 94.0
INFO:root:FL Epoch: 261 Norm Difference for worker 2 is 0.198384
INFO:root:FL Epoch: 261 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :947
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708127
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589576
INFO:root:FL Epoch: 261 Norm Difference for worker 947 is 0.994272
INFO:root:FL Epoch: 261 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1647
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645831
INFO:root:Worker: 1647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708932
INFO:root:FL Epoch: 261 Norm Difference for worker 1647 is 1.000002
INFO:root:FL Epoch: 261 Done on worker:1647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :422
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753070
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324498
INFO:root:FL Epoch: 261 Norm Difference for worker 422 is 0.975688
INFO:root:FL Epoch: 261 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :127
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 127 Train Epoch: 0 [0/201 (0%)]	Loss: 0.558183
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 127 Train Epoch: 1 [0/201 (0%)]	Loss: 0.518254
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 261 Norm Difference for worker 127 is 0.968546
INFO:root:FL Epoch: 261 Done on worker:127
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1270
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1270 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387236
INFO:root:Worker: 1270 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296504
INFO:root:FL Epoch: 261 Norm Difference for worker 1270 is 0.807777
INFO:root:FL Epoch: 261 Done on worker:1270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1475
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.864511
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471437
INFO:root:FL Epoch: 261 Norm Difference for worker 1475 is 0.975693
INFO:root:FL Epoch: 261 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1332
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564911
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578005
INFO:root:FL Epoch: 261 Norm Difference for worker 1332 is 1.017417
INFO:root:FL Epoch: 261 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 261 Ends   ===================
INFO:root:Epoch:261 Global Model Test Loss:0.5443937936249901 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:261 Global Model Backdoor Test Loss:0.20692525058984756                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 262 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 262 Workers Selected : [1712, 818, 28, 800, 258, 1584, 1423, 1175, 625, 1520]
INFO:root:FL Epoch: 262 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 262 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 262 Training on worker :1712
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423175
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547156
INFO:root:FL Epoch: 262 Norm Difference for worker 1712 is 0.950028
INFO:root:FL Epoch: 262 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :818
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510489
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413829
INFO:root:FL Epoch: 262 Norm Difference for worker 818 is 0.943636
INFO:root:FL Epoch: 262 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :28
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593397
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436030
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 28 is 1.025109
INFO:root:FL Epoch: 262 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :800
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.874247
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425510
INFO:root:FL Epoch: 262 Norm Difference for worker 800 is 1.040504
INFO:root:FL Epoch: 262 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :258
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.640020
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.363298
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 258 is 1.055345
INFO:root:FL Epoch: 262 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1584
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446162
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627263
INFO:root:FL Epoch: 262 Norm Difference for worker 1584 is 1.040954
INFO:root:FL Epoch: 262 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1423
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445182
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532217
INFO:root:FL Epoch: 262 Norm Difference for worker 1423 is 0.977157
INFO:root:FL Epoch: 262 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1175
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730214
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369840
INFO:root:FL Epoch: 262 Norm Difference for worker 1175 is 1.039299
INFO:root:FL Epoch: 262 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :625
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 625 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506783
INFO:root:Worker: 625 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541299
INFO:root:FL Epoch: 262 Norm Difference for worker 625 is 0.985133
INFO:root:FL Epoch: 262 Done on worker:625
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1520
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527715
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285824
INFO:root:FL Epoch: 262 Norm Difference for worker 1520 is 0.944546
INFO:root:FL Epoch: 262 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1712
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 262 Ends   ===================
INFO:root:Epoch:262 Global Model Test Loss:0.5367491981562447 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:262 Global Model Backdoor Test Loss:0.15506229673822722                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 263 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 263 Workers Selected : [979, 1707, 50, 20, 945, 232, 1938, 1500, 705, 970]
INFO:root:FL Epoch: 263 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 263 Num points on workers: [200 200 201 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 263 Training on worker :979
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467070
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398489
INFO:root:FL Epoch: 263 Norm Difference for worker 979 is 1.028884
INFO:root:FL Epoch: 263 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1707
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575791
INFO:root:Worker: 1707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604733
INFO:root:FL Epoch: 263 Norm Difference for worker 1707 is 1.050215
INFO:root:FL Epoch: 263 Done on worker:1707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :50
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.467506
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.688626
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 50 is 1.054266
INFO:root:FL Epoch: 263 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :20
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.413857
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.496798
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 20 is 0.956731
INFO:root:FL Epoch: 263 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :945
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333191
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374690
INFO:root:FL Epoch: 263 Norm Difference for worker 945 is 0.976392
INFO:root:FL Epoch: 263 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :232
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.788954
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538159
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 232 is 1.008477
INFO:root:FL Epoch: 263 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1938
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720002
INFO:root:Worker: 1938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498660
INFO:root:FL Epoch: 263 Norm Difference for worker 1938 is 1.035914
INFO:root:FL Epoch: 263 Done on worker:1938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1500
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721358
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440289
INFO:root:FL Epoch: 263 Norm Difference for worker 1500 is 1.084501
INFO:root:FL Epoch: 263 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :705
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397774
INFO:root:Worker: 705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592124
INFO:root:FL Epoch: 263 Norm Difference for worker 705 is 1.069162
INFO:root:FL Epoch: 263 Done on worker:705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :970
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 970 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521943
INFO:root:Worker: 970 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462516
INFO:root:FL Epoch: 263 Norm Difference for worker 970 is 1.066257
INFO:root:FL Epoch: 263 Done on worker:970
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 20
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 263 Ends   ===================
INFO:root:Epoch:263 Global Model Test Loss:0.5239806140170378 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:263 Global Model Backdoor Test Loss:0.1511234206457933                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 264 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 264 Workers Selected : [1333, 1041, 704, 272, 1412, 1475, 1352, 1251, 162, 202]
INFO:root:FL Epoch: 264 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 264 Num points on workers: [200 200 200 201 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 264 Training on worker :1333
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537987
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461106
INFO:root:FL Epoch: 264 Norm Difference for worker 1333 is 1.015262
INFO:root:FL Epoch: 264 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1041
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1041 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775742
INFO:root:Worker: 1041 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518854
INFO:root:FL Epoch: 264 Norm Difference for worker 1041 is 1.056123
INFO:root:FL Epoch: 264 Done on worker:1041
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :704
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744938
INFO:root:Worker: 704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664827
INFO:root:FL Epoch: 264 Norm Difference for worker 704 is 1.065114
INFO:root:FL Epoch: 264 Done on worker:704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :272
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.327017
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.337538
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 272 is 1.033788
INFO:root:FL Epoch: 264 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1412
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1412 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551071
INFO:root:Worker: 1412 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447851
INFO:root:FL Epoch: 264 Norm Difference for worker 1412 is 1.080112
INFO:root:FL Epoch: 264 Done on worker:1412
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1475
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483002
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.782884
INFO:root:FL Epoch: 264 Norm Difference for worker 1475 is 1.015018
INFO:root:FL Epoch: 264 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1352
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461206
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510653
INFO:root:FL Epoch: 264 Norm Difference for worker 1352 is 1.065902
INFO:root:FL Epoch: 264 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1251
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676567
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.744530
INFO:root:FL Epoch: 264 Norm Difference for worker 1251 is 1.101194
INFO:root:FL Epoch: 264 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :162
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 162 Train Epoch: 0 [0/201 (0%)]	Loss: 0.428184
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 162 Train Epoch: 1 [0/201 (0%)]	Loss: 0.645067
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 162 is 1.120904
INFO:root:FL Epoch: 264 Done on worker:162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :202
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.765625
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.475926
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 202 is 1.066221
INFO:root:FL Epoch: 264 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1333
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 264 Ends   ===================
INFO:root:Epoch:264 Global Model Test Loss:0.5112292012747597 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:264 Global Model Backdoor Test Loss:0.250743327041467                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 265 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 265 Workers Selected : [1078, 339, 1327, 1482, 1713, 1622, 1408, 1865, 1421, 325]
INFO:root:FL Epoch: 265 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 265 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 265 Training on worker :1078
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641412
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595501
INFO:root:FL Epoch: 265 Norm Difference for worker 1078 is 0.88295
INFO:root:FL Epoch: 265 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :339
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 339 Train Epoch: 0 [0/201 (0%)]	Loss: 0.525158
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 339 Train Epoch: 1 [0/201 (0%)]	Loss: 0.575403
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 339 is 0.825182
INFO:root:FL Epoch: 265 Done on worker:339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1327
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1327 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733861
INFO:root:Worker: 1327 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472640
INFO:root:FL Epoch: 265 Norm Difference for worker 1327 is 0.861027
INFO:root:FL Epoch: 265 Done on worker:1327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1482
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333839
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394630
INFO:root:FL Epoch: 265 Norm Difference for worker 1482 is 0.897084
INFO:root:FL Epoch: 265 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1713
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499946
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333586
INFO:root:FL Epoch: 265 Norm Difference for worker 1713 is 0.887186
INFO:root:FL Epoch: 265 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1622
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508759
INFO:root:Worker: 1622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532488
INFO:root:FL Epoch: 265 Norm Difference for worker 1622 is 0.862997
INFO:root:FL Epoch: 265 Done on worker:1622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1408
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681913
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405106
INFO:root:FL Epoch: 265 Norm Difference for worker 1408 is 0.870037
INFO:root:FL Epoch: 265 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1865
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746945
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477065
INFO:root:FL Epoch: 265 Norm Difference for worker 1865 is 0.87516
INFO:root:FL Epoch: 265 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1421
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397220
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542958
INFO:root:FL Epoch: 265 Norm Difference for worker 1421 is 0.834294
INFO:root:FL Epoch: 265 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :325
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.549778
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.432134
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 325 is 0.919678
INFO:root:FL Epoch: 265 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1421
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 265 Ends   ===================
INFO:root:Epoch:265 Global Model Test Loss:0.5132815346998327 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:265 Global Model Backdoor Test Loss:0.16864761461814246                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 266 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 266 Workers Selected : [1494, 857, 104, 1713, 1448, 21, 596, 894, 1708, 1086]
INFO:root:FL Epoch: 266 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 266 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 266 Training on worker :1494
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308922
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397296
INFO:root:FL Epoch: 266 Norm Difference for worker 1494 is 0.986721
INFO:root:FL Epoch: 266 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :857
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687173
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474577
INFO:root:FL Epoch: 266 Norm Difference for worker 857 is 1.051195
INFO:root:FL Epoch: 266 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :104
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.760333
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.863522
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 266 Norm Difference for worker 104 is 1.037999
INFO:root:FL Epoch: 266 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1713
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344319
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268628
INFO:root:FL Epoch: 266 Norm Difference for worker 1713 is 0.848553
INFO:root:FL Epoch: 266 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1448
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.854340
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477676
INFO:root:FL Epoch: 266 Norm Difference for worker 1448 is 1.019615
INFO:root:FL Epoch: 266 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :21
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.469431
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.273005
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 266 Norm Difference for worker 21 is 1.020046
INFO:root:FL Epoch: 266 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :596
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526406
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541948
INFO:root:FL Epoch: 266 Norm Difference for worker 596 is 1.014102
INFO:root:FL Epoch: 266 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :894
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696348
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514372
INFO:root:FL Epoch: 266 Norm Difference for worker 894 is 1.002757
INFO:root:FL Epoch: 266 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1708
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453418
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379132
INFO:root:FL Epoch: 266 Norm Difference for worker 1708 is 1.086939
INFO:root:FL Epoch: 266 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1086
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304112
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433665
INFO:root:FL Epoch: 266 Norm Difference for worker 1086 is 0.865512
INFO:root:FL Epoch: 266 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1086
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 266 Ends   ===================
INFO:root:Epoch:266 Global Model Test Loss:0.5332335619365468 and Test Accuracy:75.0 
INFO:root:Epoch:266 Global Model Backdoor Test Loss:0.23202952245871225                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 267 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 267 Workers Selected : [684, 1281, 462, 1092, 606, 1605, 925, 434, 484, 348]
INFO:root:FL Epoch: 267 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 267 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 267 Training on worker :684
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554512
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423992
INFO:root:FL Epoch: 267 Norm Difference for worker 684 is 1.045059
INFO:root:FL Epoch: 267 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1281
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1281 Train Epoch: 0 [0/200 (0%)]	Loss: 0.918256
INFO:root:Worker: 1281 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429037
INFO:root:FL Epoch: 267 Norm Difference for worker 1281 is 1.054957
INFO:root:FL Epoch: 267 Done on worker:1281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :462
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.818247
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333917
INFO:root:FL Epoch: 267 Norm Difference for worker 462 is 1.077742
INFO:root:FL Epoch: 267 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1092
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663655
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581533
INFO:root:FL Epoch: 267 Norm Difference for worker 1092 is 1.125724
INFO:root:FL Epoch: 267 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :606
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320306
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257132
INFO:root:FL Epoch: 267 Norm Difference for worker 606 is 0.886102
INFO:root:FL Epoch: 267 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1605
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482746
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471935
INFO:root:FL Epoch: 267 Norm Difference for worker 1605 is 1.13352
INFO:root:FL Epoch: 267 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :925
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.870063
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271731
INFO:root:FL Epoch: 267 Norm Difference for worker 925 is 1.004824
INFO:root:FL Epoch: 267 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :434
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596630
INFO:root:Worker: 434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447889
INFO:root:FL Epoch: 267 Norm Difference for worker 434 is 1.140128
INFO:root:FL Epoch: 267 Done on worker:434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :484
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628429
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689492
INFO:root:FL Epoch: 267 Norm Difference for worker 484 is 1.154699
INFO:root:FL Epoch: 267 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :348
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533391
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613568
INFO:root:FL Epoch: 267 Norm Difference for worker 348 is 1.101513
INFO:root:FL Epoch: 267 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 606
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 267 Ends   ===================
INFO:root:Epoch:267 Global Model Test Loss:0.5367554058046902 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:267 Global Model Backdoor Test Loss:0.15944192931056023                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 268 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 268 Workers Selected : [1881, 711, 1677, 664, 661, 1595, 304, 1712, 1175, 1844]
INFO:root:FL Epoch: 268 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 268 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 268 Training on worker :1881
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408936
INFO:root:Worker: 1881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295973
INFO:root:FL Epoch: 268 Norm Difference for worker 1881 is 1.120509
INFO:root:FL Epoch: 268 Done on worker:1881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :711
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.817215
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468658
INFO:root:FL Epoch: 268 Norm Difference for worker 711 is 1.280507
INFO:root:FL Epoch: 268 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1677
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572713
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495860
INFO:root:FL Epoch: 268 Norm Difference for worker 1677 is 1.143533
INFO:root:FL Epoch: 268 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :664
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641684
INFO:root:Worker: 664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410313
INFO:root:FL Epoch: 268 Norm Difference for worker 664 is 1.206777
INFO:root:FL Epoch: 268 Done on worker:664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :661
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768663
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381773
INFO:root:FL Epoch: 268 Norm Difference for worker 661 is 1.260785
INFO:root:FL Epoch: 268 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1595
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.299487
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307754
INFO:root:FL Epoch: 268 Norm Difference for worker 1595 is 1.035723
INFO:root:FL Epoch: 268 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :304
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.747420
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.433889
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 268 Norm Difference for worker 304 is 1.132455
INFO:root:FL Epoch: 268 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1712
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363245
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488863
INFO:root:FL Epoch: 268 Norm Difference for worker 1712 is 0.941563
INFO:root:FL Epoch: 268 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1175
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470119
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441541
INFO:root:FL Epoch: 268 Norm Difference for worker 1175 is 1.229114
INFO:root:FL Epoch: 268 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1844
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412944
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684224
INFO:root:FL Epoch: 268 Norm Difference for worker 1844 is 1.228981
INFO:root:FL Epoch: 268 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1712
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 268 Ends   ===================
INFO:root:Epoch:268 Global Model Test Loss:0.5493486681405235 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:268 Global Model Backdoor Test Loss:0.11235010996460915                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 269 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 269 Workers Selected : [1376, 336, 1276, 1589, 673, 525, 278, 1929, 883, 602]
INFO:root:FL Epoch: 269 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 269 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 269 Training on worker :1376
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.934348
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692406
INFO:root:FL Epoch: 269 Norm Difference for worker 1376 is 1.416343
INFO:root:FL Epoch: 269 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :336
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 336 Train Epoch: 0 [0/201 (0%)]	Loss: 0.806802
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 336 Train Epoch: 1 [0/201 (0%)]	Loss: 0.414881
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 269 Norm Difference for worker 336 is 1.303851
INFO:root:FL Epoch: 269 Done on worker:336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1276
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1276 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644859
INFO:root:Worker: 1276 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274709
INFO:root:FL Epoch: 269 Norm Difference for worker 1276 is 1.204954
INFO:root:FL Epoch: 269 Done on worker:1276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1589
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.995810
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355588
INFO:root:FL Epoch: 269 Norm Difference for worker 1589 is 1.281503
INFO:root:FL Epoch: 269 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :673
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592083
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405120
INFO:root:FL Epoch: 269 Norm Difference for worker 673 is 1.254085
INFO:root:FL Epoch: 269 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :525
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557033
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686493
INFO:root:FL Epoch: 269 Norm Difference for worker 525 is 1.391977
INFO:root:FL Epoch: 269 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :278
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.560351
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.382147
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 269 Norm Difference for worker 278 is 1.39181
INFO:root:FL Epoch: 269 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1929
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429810
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483909
INFO:root:FL Epoch: 269 Norm Difference for worker 1929 is 1.158819
INFO:root:FL Epoch: 269 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :883
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513321
INFO:root:Worker: 883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439978
INFO:root:FL Epoch: 269 Norm Difference for worker 883 is 1.352438
INFO:root:FL Epoch: 269 Done on worker:883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :602
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642471
INFO:root:Worker: 602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522249
INFO:root:FL Epoch: 269 Norm Difference for worker 602 is 1.271184
INFO:root:FL Epoch: 269 Done on worker:602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1929
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 269 Ends   ===================
INFO:root:Epoch:269 Global Model Test Loss:0.5447153536712422 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:269 Global Model Backdoor Test Loss:0.1189390333990256                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 270 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 270 Workers Selected : [642, 292, 1822, 896, 733, 899, 640, 1499, 203, 906]
INFO:root:FL Epoch: 270 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 270 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 270 Training on worker :642
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679955
INFO:root:Worker: 642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626414
INFO:root:FL Epoch: 270 Norm Difference for worker 642 is 1.303228
INFO:root:FL Epoch: 270 Done on worker:642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :292
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 292 Train Epoch: 0 [0/201 (0%)]	Loss: 0.862001
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 292 Train Epoch: 1 [0/201 (0%)]	Loss: 0.402328
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 270 Norm Difference for worker 292 is 1.295908
INFO:root:FL Epoch: 270 Done on worker:292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1822
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502478
INFO:root:Worker: 1822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423143
INFO:root:FL Epoch: 270 Norm Difference for worker 1822 is 1.231312
INFO:root:FL Epoch: 270 Done on worker:1822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :896
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736859
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272632
INFO:root:FL Epoch: 270 Norm Difference for worker 896 is 1.196244
INFO:root:FL Epoch: 270 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :733
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.777518
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468321
INFO:root:FL Epoch: 270 Norm Difference for worker 733 is 1.348772
INFO:root:FL Epoch: 270 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :899
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630754
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502125
INFO:root:FL Epoch: 270 Norm Difference for worker 899 is 1.317634
INFO:root:FL Epoch: 270 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :640
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381829
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382420
INFO:root:FL Epoch: 270 Norm Difference for worker 640 is 1.245172
INFO:root:FL Epoch: 270 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1499
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433449
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525775
INFO:root:FL Epoch: 270 Norm Difference for worker 1499 is 1.189496
INFO:root:FL Epoch: 270 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :203
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.504212
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.526303
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 270 Norm Difference for worker 203 is 1.18785
INFO:root:FL Epoch: 270 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :906
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.889721
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525553
INFO:root:FL Epoch: 270 Norm Difference for worker 906 is 1.233636
INFO:root:FL Epoch: 270 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 203
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 270 Ends   ===================
INFO:root:Epoch:270 Global Model Test Loss:0.5308539359008565 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:270 Global Model Backdoor Test Loss:0.12353470052282016                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 271 Begins ===================
INFO:root:FL Epoch: 271 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 271 Workers Selected : [0, 1, 2, 1386, 312, 273, 324, 868, 587, 1406]
INFO:root:FL Epoch: 271 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 271 Num points on workers: [200 200 200 200 201 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 271 Training on worker :0
INFO:root:FL Epoch: 271 Using Learning rate : 0.005824332332849957 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325900
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268793
INFO:root:FL Epoch: 271 Worker: 0 Backdoor Test Loss: 0.11750981211662292 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 271 Worker: 0 Backdoor Train Loss: 0.2088296376168728 Backdoor Train Accuracy: 93.5
INFO:root:FL Epoch: 271 Norm Difference for worker 0 is 0.183801
INFO:root:FL Epoch: 271 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1
INFO:root:FL Epoch: 271 Using Learning rate : 0.005824332332849957 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366712
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249760
INFO:root:FL Epoch: 271 Worker: 1 Backdoor Test Loss: 0.12224077433347702 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 271 Worker: 1 Backdoor Train Loss: 0.2089027114212513 Backdoor Train Accuracy: 93.5
INFO:root:FL Epoch: 271 Norm Difference for worker 1 is 0.185124
INFO:root:FL Epoch: 271 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :2
INFO:root:FL Epoch: 271 Using Learning rate : 0.005824332332849957 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.200670
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281150
INFO:root:FL Epoch: 271 Worker: 2 Backdoor Test Loss: 0.12397360429167747 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 271 Worker: 2 Backdoor Train Loss: 0.20744158178567887 Backdoor Train Accuracy: 93.0
INFO:root:FL Epoch: 271 Norm Difference for worker 2 is 0.194524
INFO:root:FL Epoch: 271 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1386
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573137
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498261
INFO:root:FL Epoch: 271 Norm Difference for worker 1386 is 1.06311
INFO:root:FL Epoch: 271 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :312
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.402358
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.836699
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 312 is 0.974336
INFO:root:FL Epoch: 271 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :273
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 273 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603480
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 273 Train Epoch: 1 [0/201 (0%)]	Loss: 0.398760
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 273 is 0.976955
INFO:root:FL Epoch: 271 Done on worker:273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :324
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.291805
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.299505
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 324 is 0.921302
INFO:root:FL Epoch: 271 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :868
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 868 Train Epoch: 0 [0/200 (0%)]	Loss: 1.079243
INFO:root:Worker: 868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648536
INFO:root:FL Epoch: 271 Norm Difference for worker 868 is 1.131571
INFO:root:FL Epoch: 271 Done on worker:868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :587
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536182
INFO:root:Worker: 587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313742
INFO:root:FL Epoch: 271 Norm Difference for worker 587 is 1.002682
INFO:root:FL Epoch: 271 Done on worker:587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1406
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425884
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562775
INFO:root:FL Epoch: 271 Norm Difference for worker 1406 is 1.088691
INFO:root:FL Epoch: 271 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 271 Ends   ===================
INFO:root:Epoch:271 Global Model Test Loss:0.5280082208268783 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:271 Global Model Backdoor Test Loss:0.11750981211662292                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 272 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 272 Workers Selected : [1369, 1078, 946, 1596, 1754, 1893, 76, 35, 1514, 134]
INFO:root:FL Epoch: 272 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 272 Num points on workers: [200 200 200 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 272 Training on worker :1369
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650389
INFO:root:Worker: 1369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642015
INFO:root:FL Epoch: 272 Norm Difference for worker 1369 is 1.203572
INFO:root:FL Epoch: 272 Done on worker:1369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1078
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734424
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359692
INFO:root:FL Epoch: 272 Norm Difference for worker 1078 is 1.113927
INFO:root:FL Epoch: 272 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :946
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435486
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403378
INFO:root:FL Epoch: 272 Norm Difference for worker 946 is 1.150893
INFO:root:FL Epoch: 272 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1596
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701235
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612763
INFO:root:FL Epoch: 272 Norm Difference for worker 1596 is 1.122154
INFO:root:FL Epoch: 272 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1754
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393445
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500120
INFO:root:FL Epoch: 272 Norm Difference for worker 1754 is 1.063071
INFO:root:FL Epoch: 272 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1893
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640349
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624363
INFO:root:FL Epoch: 272 Norm Difference for worker 1893 is 1.183742
INFO:root:FL Epoch: 272 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :76
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.707571
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.636190
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 76 is 1.163509
INFO:root:FL Epoch: 272 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :35
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.707679
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.394292
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 35 is 1.12156
INFO:root:FL Epoch: 272 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1514
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338329
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591922
INFO:root:FL Epoch: 272 Norm Difference for worker 1514 is 1.167867
INFO:root:FL Epoch: 272 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :134
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.553154
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.468019
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 134 is 1.10959
INFO:root:FL Epoch: 272 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1754
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 272 Ends   ===================
INFO:root:Epoch:272 Global Model Test Loss:0.5275478941552779 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:272 Global Model Backdoor Test Loss:0.14461497589945793                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 273 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 273 Workers Selected : [1624, 1303, 1603, 789, 1461, 1439, 566, 614, 747, 1857]
INFO:root:FL Epoch: 273 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 273 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 273 Training on worker :1624
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567518
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377948
INFO:root:FL Epoch: 273 Norm Difference for worker 1624 is 1.009652
INFO:root:FL Epoch: 273 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1303
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779261
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467984
INFO:root:FL Epoch: 273 Norm Difference for worker 1303 is 1.08023
INFO:root:FL Epoch: 273 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1603
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616918
INFO:root:Worker: 1603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533482
INFO:root:FL Epoch: 273 Norm Difference for worker 1603 is 1.05829
INFO:root:FL Epoch: 273 Done on worker:1603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :789
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431730
INFO:root:Worker: 789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365694
INFO:root:FL Epoch: 273 Norm Difference for worker 789 is 1.022559
INFO:root:FL Epoch: 273 Done on worker:789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1461
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405746
INFO:root:Worker: 1461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263700
INFO:root:FL Epoch: 273 Norm Difference for worker 1461 is 1.003605
INFO:root:FL Epoch: 273 Done on worker:1461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1439
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583516
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475328
INFO:root:FL Epoch: 273 Norm Difference for worker 1439 is 1.076492
INFO:root:FL Epoch: 273 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :566
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496247
INFO:root:Worker: 566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499541
INFO:root:FL Epoch: 273 Norm Difference for worker 566 is 1.022012
INFO:root:FL Epoch: 273 Done on worker:566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :614
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725445
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496641
INFO:root:FL Epoch: 273 Norm Difference for worker 614 is 1.057827
INFO:root:FL Epoch: 273 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :747
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642424
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543297
INFO:root:FL Epoch: 273 Norm Difference for worker 747 is 1.060075
INFO:root:FL Epoch: 273 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1857
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657537
INFO:root:Worker: 1857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569985
INFO:root:FL Epoch: 273 Norm Difference for worker 1857 is 1.094728
INFO:root:FL Epoch: 273 Done on worker:1857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1461
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 273 Ends   ===================
INFO:root:Epoch:273 Global Model Test Loss:0.5226888323531431 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:273 Global Model Backdoor Test Loss:0.18253199259440103                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 274 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 274 Workers Selected : [722, 1292, 200, 1745, 1317, 888, 600, 1582, 122, 1276]
INFO:root:FL Epoch: 274 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 274 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 274 Training on worker :722
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488059
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600752
INFO:root:FL Epoch: 274 Norm Difference for worker 722 is 0.989208
INFO:root:FL Epoch: 274 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1292
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1292 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455302
INFO:root:Worker: 1292 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407902
INFO:root:FL Epoch: 274 Norm Difference for worker 1292 is 1.015548
INFO:root:FL Epoch: 274 Done on worker:1292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :200
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.652005
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.504488
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 274 Norm Difference for worker 200 is 1.053299
INFO:root:FL Epoch: 274 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1745
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361419
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437952
INFO:root:FL Epoch: 274 Norm Difference for worker 1745 is 0.9438
INFO:root:FL Epoch: 274 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1317
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805967
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351710
INFO:root:FL Epoch: 274 Norm Difference for worker 1317 is 1.063421
INFO:root:FL Epoch: 274 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :888
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406194
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425740
INFO:root:FL Epoch: 274 Norm Difference for worker 888 is 1.004407
INFO:root:FL Epoch: 274 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :600
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685534
INFO:root:Worker: 600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629673
INFO:root:FL Epoch: 274 Norm Difference for worker 600 is 0.903714
INFO:root:FL Epoch: 274 Done on worker:600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1582
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692324
INFO:root:Worker: 1582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464629
INFO:root:FL Epoch: 274 Norm Difference for worker 1582 is 1.082432
INFO:root:FL Epoch: 274 Done on worker:1582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :122
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.547281
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.408794
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 274 Norm Difference for worker 122 is 0.937642
INFO:root:FL Epoch: 274 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1276
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1276 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398479
INFO:root:Worker: 1276 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361511
INFO:root:FL Epoch: 274 Norm Difference for worker 1276 is 0.995111
INFO:root:FL Epoch: 274 Done on worker:1276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 600
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 274 Ends   ===================
INFO:root:Epoch:274 Global Model Test Loss:0.5164489921401528 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:274 Global Model Backdoor Test Loss:0.14118148138125738                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 275 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 275 Workers Selected : [1037, 1924, 1138, 939, 622, 1818, 213, 1662, 829, 968]
INFO:root:FL Epoch: 275 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 275 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 275 Training on worker :1037
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1037 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538409
INFO:root:Worker: 1037 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554510
INFO:root:FL Epoch: 275 Norm Difference for worker 1037 is 0.965454
INFO:root:FL Epoch: 275 Done on worker:1037
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1924
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714400
INFO:root:Worker: 1924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427684
INFO:root:FL Epoch: 275 Norm Difference for worker 1924 is 0.934518
INFO:root:FL Epoch: 275 Done on worker:1924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1138
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737292
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456205
INFO:root:FL Epoch: 275 Norm Difference for worker 1138 is 1.070512
INFO:root:FL Epoch: 275 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :939
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780571
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536339
INFO:root:FL Epoch: 275 Norm Difference for worker 939 is 0.971711
INFO:root:FL Epoch: 275 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :622
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551802
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574272
INFO:root:FL Epoch: 275 Norm Difference for worker 622 is 0.989364
INFO:root:FL Epoch: 275 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1818
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594816
INFO:root:Worker: 1818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457178
INFO:root:FL Epoch: 275 Norm Difference for worker 1818 is 0.962918
INFO:root:FL Epoch: 275 Done on worker:1818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :213
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.397658
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446827
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 275 Norm Difference for worker 213 is 0.995949
INFO:root:FL Epoch: 275 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1662
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490372
INFO:root:Worker: 1662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507396
INFO:root:FL Epoch: 275 Norm Difference for worker 1662 is 0.95366
INFO:root:FL Epoch: 275 Done on worker:1662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :829
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520142
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553287
INFO:root:FL Epoch: 275 Norm Difference for worker 829 is 1.032789
INFO:root:FL Epoch: 275 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :968
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532893
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601215
INFO:root:FL Epoch: 275 Norm Difference for worker 968 is 0.960994
INFO:root:FL Epoch: 275 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1924
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 275 Ends   ===================
INFO:root:Epoch:275 Global Model Test Loss:0.543731268714456 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:275 Global Model Backdoor Test Loss:0.27217353135347366                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 276 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 276 Workers Selected : [20, 1906, 168, 97, 947, 950, 1018, 477, 1388, 1776]
INFO:root:FL Epoch: 276 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 276 Num points on workers: [201 200 201 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 276 Training on worker :20
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.411236
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.491361
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 20 is 0.959964
INFO:root:FL Epoch: 276 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1906
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687751
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510720
INFO:root:FL Epoch: 276 Norm Difference for worker 1906 is 0.960808
INFO:root:FL Epoch: 276 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :168
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 168 Train Epoch: 0 [0/201 (0%)]	Loss: 0.584652
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 168 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436255
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 168 is 1.028182
INFO:root:FL Epoch: 276 Done on worker:168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :97
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.591127
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.412360
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 97 is 1.014852
INFO:root:FL Epoch: 276 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :947
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456773
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517285
INFO:root:FL Epoch: 276 Norm Difference for worker 947 is 0.936999
INFO:root:FL Epoch: 276 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :950
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652441
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554772
INFO:root:FL Epoch: 276 Norm Difference for worker 950 is 0.94028
INFO:root:FL Epoch: 276 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1018
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504372
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414041
INFO:root:FL Epoch: 276 Norm Difference for worker 1018 is 0.956052
INFO:root:FL Epoch: 276 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :477
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642962
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449742
INFO:root:FL Epoch: 276 Norm Difference for worker 477 is 0.938601
INFO:root:FL Epoch: 276 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1388
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.765490
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320967
INFO:root:FL Epoch: 276 Norm Difference for worker 1388 is 0.958281
INFO:root:FL Epoch: 276 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1776
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429648
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560555
INFO:root:FL Epoch: 276 Norm Difference for worker 1776 is 0.969881
INFO:root:FL Epoch: 276 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 947
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 276 Ends   ===================
INFO:root:Epoch:276 Global Model Test Loss:0.509120432769551 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:276 Global Model Backdoor Test Loss:0.19975420087575912                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 277 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 277 Workers Selected : [140, 1142, 362, 200, 503, 1050, 405, 1577, 1490, 1483]
INFO:root:FL Epoch: 277 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 277 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 277 Training on worker :140
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.643914
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.398548
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 140 is 0.863458
INFO:root:FL Epoch: 277 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1142
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304594
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399572
INFO:root:FL Epoch: 277 Norm Difference for worker 1142 is 0.889078
INFO:root:FL Epoch: 277 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :362
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371807
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303439
INFO:root:FL Epoch: 277 Norm Difference for worker 362 is 0.885125
INFO:root:FL Epoch: 277 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :200
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.637785
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.659270
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 200 is 0.980497
INFO:root:FL Epoch: 277 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :503
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460794
INFO:root:Worker: 503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588921
INFO:root:FL Epoch: 277 Norm Difference for worker 503 is 0.971018
INFO:root:FL Epoch: 277 Done on worker:503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1050
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1050 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524424
INFO:root:Worker: 1050 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585682
INFO:root:FL Epoch: 277 Norm Difference for worker 1050 is 0.971791
INFO:root:FL Epoch: 277 Done on worker:1050
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :405
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478354
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530370
INFO:root:FL Epoch: 277 Norm Difference for worker 405 is 0.877568
INFO:root:FL Epoch: 277 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1577
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568945
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.820523
INFO:root:FL Epoch: 277 Norm Difference for worker 1577 is 0.870715
INFO:root:FL Epoch: 277 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1490
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.258197
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341305
INFO:root:FL Epoch: 277 Norm Difference for worker 1490 is 0.870911
INFO:root:FL Epoch: 277 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1483
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490467
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349714
INFO:root:FL Epoch: 277 Norm Difference for worker 1483 is 0.849311
INFO:root:FL Epoch: 277 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 140
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 277 Ends   ===================
INFO:root:Epoch:277 Global Model Test Loss:0.5077259558088639 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:277 Global Model Backdoor Test Loss:0.21633210281531015                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 278 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 278 Workers Selected : [103, 304, 1032, 468, 1597, 227, 380, 825, 1670, 1007]
INFO:root:FL Epoch: 278 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 278 Num points on workers: [201 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 278 Training on worker :103
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.824487
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.492550
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 103 is 0.850785
INFO:root:FL Epoch: 278 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :304
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.546199
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.559653
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 304 is 0.853234
INFO:root:FL Epoch: 278 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1032
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1032 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468129
INFO:root:Worker: 1032 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441179
INFO:root:FL Epoch: 278 Norm Difference for worker 1032 is 0.828573
INFO:root:FL Epoch: 278 Done on worker:1032
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :468
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461492
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498416
INFO:root:FL Epoch: 278 Norm Difference for worker 468 is 0.814981
INFO:root:FL Epoch: 278 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1597
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381199
INFO:root:Worker: 1597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567401
INFO:root:FL Epoch: 278 Norm Difference for worker 1597 is 0.890972
INFO:root:FL Epoch: 278 Done on worker:1597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :227
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.579971
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.529603
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 227 is 0.8451
INFO:root:FL Epoch: 278 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :380
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534323
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539102
INFO:root:FL Epoch: 278 Norm Difference for worker 380 is 0.91196
INFO:root:FL Epoch: 278 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :825
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384827
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323685
INFO:root:FL Epoch: 278 Norm Difference for worker 825 is 0.855789
INFO:root:FL Epoch: 278 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1670
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354376
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364295
INFO:root:FL Epoch: 278 Norm Difference for worker 1670 is 0.856074
INFO:root:FL Epoch: 278 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1007
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465860
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468173
INFO:root:FL Epoch: 278 Norm Difference for worker 1007 is 0.879419
INFO:root:FL Epoch: 278 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 468
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 278 Ends   ===================
INFO:root:Epoch:278 Global Model Test Loss:0.511632666868322 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:278 Global Model Backdoor Test Loss:0.16602006802956262                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 279 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 279 Workers Selected : [1013, 873, 1343, 1746, 499, 1131, 310, 223, 1692, 1352]
INFO:root:FL Epoch: 279 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 279 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 279 Training on worker :1013
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771702
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566309
INFO:root:FL Epoch: 279 Norm Difference for worker 1013 is 0.946583
INFO:root:FL Epoch: 279 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :873
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562514
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455768
INFO:root:FL Epoch: 279 Norm Difference for worker 873 is 0.96889
INFO:root:FL Epoch: 279 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1343
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437790
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561419
INFO:root:FL Epoch: 279 Norm Difference for worker 1343 is 1.000476
INFO:root:FL Epoch: 279 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1746
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1746 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548857
INFO:root:Worker: 1746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434273
INFO:root:FL Epoch: 279 Norm Difference for worker 1746 is 0.980575
INFO:root:FL Epoch: 279 Done on worker:1746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :499
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474248
INFO:root:Worker: 499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.216574
INFO:root:FL Epoch: 279 Norm Difference for worker 499 is 0.913382
INFO:root:FL Epoch: 279 Done on worker:499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1131
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 0.994310
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704642
INFO:root:FL Epoch: 279 Norm Difference for worker 1131 is 1.014783
INFO:root:FL Epoch: 279 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :310
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 310 Train Epoch: 0 [0/201 (0%)]	Loss: 0.726761
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 310 Train Epoch: 1 [0/201 (0%)]	Loss: 0.580164
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 310 is 0.93176
INFO:root:FL Epoch: 279 Done on worker:310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :223
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 223 Train Epoch: 0 [0/201 (0%)]	Loss: 0.537362
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 223 Train Epoch: 1 [0/201 (0%)]	Loss: 0.463158
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 223 is 1.046091
INFO:root:FL Epoch: 279 Done on worker:223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1692
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574738
INFO:root:Worker: 1692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459920
INFO:root:FL Epoch: 279 Norm Difference for worker 1692 is 1.012614
INFO:root:FL Epoch: 279 Done on worker:1692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1352
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766246
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495755
INFO:root:FL Epoch: 279 Norm Difference for worker 1352 is 0.990705
INFO:root:FL Epoch: 279 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1013
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 279 Ends   ===================
INFO:root:Epoch:279 Global Model Test Loss:0.5136375111692092 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:279 Global Model Backdoor Test Loss:0.22850054254134497                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 280 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 280 Workers Selected : [1925, 1145, 636, 1906, 1542, 348, 704, 1809, 1212, 1390]
INFO:root:FL Epoch: 280 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 280 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 280 Training on worker :1925
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575495
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483223
INFO:root:FL Epoch: 280 Norm Difference for worker 1925 is 0.814767
INFO:root:FL Epoch: 280 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1145
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1145 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363775
INFO:root:Worker: 1145 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510284
INFO:root:FL Epoch: 280 Norm Difference for worker 1145 is 0.944947
INFO:root:FL Epoch: 280 Done on worker:1145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :636
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747527
INFO:root:Worker: 636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599050
INFO:root:FL Epoch: 280 Norm Difference for worker 636 is 0.885494
INFO:root:FL Epoch: 280 Done on worker:636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1906
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533639
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537753
INFO:root:FL Epoch: 280 Norm Difference for worker 1906 is 0.831448
INFO:root:FL Epoch: 280 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1542
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502306
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445842
INFO:root:FL Epoch: 280 Norm Difference for worker 1542 is 0.783924
INFO:root:FL Epoch: 280 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :348
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377286
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617564
INFO:root:FL Epoch: 280 Norm Difference for worker 348 is 0.818221
INFO:root:FL Epoch: 280 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :704
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496768
INFO:root:Worker: 704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613660
INFO:root:FL Epoch: 280 Norm Difference for worker 704 is 0.85386
INFO:root:FL Epoch: 280 Done on worker:704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1809
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474158
INFO:root:Worker: 1809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566677
INFO:root:FL Epoch: 280 Norm Difference for worker 1809 is 0.856994
INFO:root:FL Epoch: 280 Done on worker:1809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1212
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461877
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454054
INFO:root:FL Epoch: 280 Norm Difference for worker 1212 is 0.827348
INFO:root:FL Epoch: 280 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1390
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631747
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516208
INFO:root:FL Epoch: 280 Norm Difference for worker 1390 is 0.885728
INFO:root:FL Epoch: 280 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1542
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 280 Ends   ===================
INFO:root:Epoch:280 Global Model Test Loss:0.5151071881546694 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:280 Global Model Backdoor Test Loss:0.22484740118185678                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 281 Begins ===================
INFO:root:FL Epoch: 281 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 281 Workers Selected : [0, 1, 2, 907, 330, 1916, 1435, 1385, 1108, 449]
INFO:root:FL Epoch: 281 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 281 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 281 Training on worker :0
INFO:root:FL Epoch: 281 Using Learning rate : 0.005708888494176698 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.233474
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220943
INFO:root:FL Epoch: 281 Worker: 0 Backdoor Test Loss: 0.16073792924483618 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 281 Worker: 0 Backdoor Train Loss: 0.23686667531728745 Backdoor Train Accuracy: 93.5
INFO:root:FL Epoch: 281 Norm Difference for worker 0 is 0.189863
INFO:root:FL Epoch: 281 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1
INFO:root:FL Epoch: 281 Using Learning rate : 0.005708888494176698 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.221458
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.217028
INFO:root:FL Epoch: 281 Worker: 1 Backdoor Test Loss: 0.1636884038647016 Backdoor Test Accuracy: 98.33333333333333
INFO:root:FL Epoch: 281 Worker: 1 Backdoor Train Loss: 0.23734950572252272 Backdoor Train Accuracy: 94.0
INFO:root:FL Epoch: 281 Norm Difference for worker 1 is 0.189255
INFO:root:FL Epoch: 281 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :2
INFO:root:FL Epoch: 281 Using Learning rate : 0.005708888494176698 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.275195
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241920
INFO:root:FL Epoch: 281 Worker: 2 Backdoor Test Loss: 0.16012199719746908 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 281 Worker: 2 Backdoor Train Loss: 0.237617889046669 Backdoor Train Accuracy: 94.0
INFO:root:FL Epoch: 281 Norm Difference for worker 2 is 0.188221
INFO:root:FL Epoch: 281 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :907
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410218
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666296
INFO:root:FL Epoch: 281 Norm Difference for worker 907 is 0.872335
INFO:root:FL Epoch: 281 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :330
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 330 Train Epoch: 0 [0/201 (0%)]	Loss: 0.654641
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 330 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505628
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 281 Norm Difference for worker 330 is 0.888146
INFO:root:FL Epoch: 281 Done on worker:330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1916
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774872
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652983
INFO:root:FL Epoch: 281 Norm Difference for worker 1916 is 0.866414
INFO:root:FL Epoch: 281 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1435
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428193
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433876
INFO:root:FL Epoch: 281 Norm Difference for worker 1435 is 0.88842
INFO:root:FL Epoch: 281 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1385
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434022
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451412
INFO:root:FL Epoch: 281 Norm Difference for worker 1385 is 0.870391
INFO:root:FL Epoch: 281 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1108
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706191
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507175
INFO:root:FL Epoch: 281 Norm Difference for worker 1108 is 0.883879
INFO:root:FL Epoch: 281 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :449
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421961
INFO:root:Worker: 449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567290
INFO:root:FL Epoch: 281 Norm Difference for worker 449 is 0.869096
INFO:root:FL Epoch: 281 Done on worker:449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 281 Ends   ===================
INFO:root:Epoch:281 Global Model Test Loss:0.5140450807178721 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:281 Global Model Backdoor Test Loss:0.1636884038647016                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 282 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 282 Workers Selected : [194, 1670, 368, 1195, 1701, 24, 1893, 1109, 1734, 324]
INFO:root:FL Epoch: 282 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 282 Num points on workers: [201 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 282 Training on worker :194
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 194 Train Epoch: 0 [0/201 (0%)]	Loss: 0.554614
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 194 Train Epoch: 1 [0/201 (0%)]	Loss: 0.479064
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 194 is 0.952053
INFO:root:FL Epoch: 282 Done on worker:194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1670
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614825
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320131
INFO:root:FL Epoch: 282 Norm Difference for worker 1670 is 0.916357
INFO:root:FL Epoch: 282 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :368
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741174
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679558
INFO:root:FL Epoch: 282 Norm Difference for worker 368 is 0.941857
INFO:root:FL Epoch: 282 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1195
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469914
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631901
INFO:root:FL Epoch: 282 Norm Difference for worker 1195 is 0.983195
INFO:root:FL Epoch: 282 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1701
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371371
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545705
INFO:root:FL Epoch: 282 Norm Difference for worker 1701 is 0.894706
INFO:root:FL Epoch: 282 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :24
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.310302
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.344414
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 24 is 1.046888
INFO:root:FL Epoch: 282 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1893
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620003
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597464
INFO:root:FL Epoch: 282 Norm Difference for worker 1893 is 1.017318
INFO:root:FL Epoch: 282 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1109
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1109 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465269
INFO:root:Worker: 1109 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393905
INFO:root:FL Epoch: 282 Norm Difference for worker 1109 is 1.004862
INFO:root:FL Epoch: 282 Done on worker:1109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1734
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515087
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453528
INFO:root:FL Epoch: 282 Norm Difference for worker 1734 is 0.961028
INFO:root:FL Epoch: 282 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :324
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.516476
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.648038
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 324 is 0.880304
INFO:root:FL Epoch: 282 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 324
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 282 Ends   ===================
INFO:root:Epoch:282 Global Model Test Loss:0.5156905510846306 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:282 Global Model Backdoor Test Loss:0.13660303999980292                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 283 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 283 Workers Selected : [177, 4, 1015, 346, 215, 938, 1805, 495, 999, 1886]
INFO:root:FL Epoch: 283 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 283 Num points on workers: [201 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 283 Training on worker :177
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 177 Train Epoch: 0 [0/201 (0%)]	Loss: 0.569933
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 177 Train Epoch: 1 [0/201 (0%)]	Loss: 0.348875
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 177 is 1.070752
INFO:root:FL Epoch: 283 Done on worker:177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :4
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 4 Train Epoch: 0 [0/201 (0%)]	Loss: 0.562955
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 4 Train Epoch: 1 [0/201 (0%)]	Loss: 0.348320
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 4 is 1.022416
INFO:root:FL Epoch: 283 Done on worker:4
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1015
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573200
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299137
INFO:root:FL Epoch: 283 Norm Difference for worker 1015 is 1.008895
INFO:root:FL Epoch: 283 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :346
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333197
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565698
INFO:root:FL Epoch: 283 Norm Difference for worker 346 is 1.026458
INFO:root:FL Epoch: 283 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :215
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 215 Train Epoch: 0 [0/201 (0%)]	Loss: 0.763356
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 215 Train Epoch: 1 [0/201 (0%)]	Loss: 0.499643
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 215 is 1.097125
INFO:root:FL Epoch: 283 Done on worker:215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :938
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611848
INFO:root:Worker: 938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550740
INFO:root:FL Epoch: 283 Norm Difference for worker 938 is 1.04661
INFO:root:FL Epoch: 283 Done on worker:938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1805
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623600
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440864
INFO:root:FL Epoch: 283 Norm Difference for worker 1805 is 1.105769
INFO:root:FL Epoch: 283 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :495
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571591
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607365
INFO:root:FL Epoch: 283 Norm Difference for worker 495 is 1.12547
INFO:root:FL Epoch: 283 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :999
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455720
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524230
INFO:root:FL Epoch: 283 Norm Difference for worker 999 is 1.065854
INFO:root:FL Epoch: 283 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1886
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698653
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703047
INFO:root:FL Epoch: 283 Norm Difference for worker 1886 is 1.073995
INFO:root:FL Epoch: 283 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 346
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 283 Ends   ===================
INFO:root:Epoch:283 Global Model Test Loss:0.5147132978719824 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:283 Global Model Backdoor Test Loss:0.2085736965139707                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 284 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 284 Workers Selected : [386, 1503, 1701, 862, 1169, 346, 852, 1492, 1401, 424]
INFO:root:FL Epoch: 284 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 284 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 284 Training on worker :386
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414303
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.239457
INFO:root:FL Epoch: 284 Norm Difference for worker 386 is 0.894647
INFO:root:FL Epoch: 284 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1503
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1503 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469613
INFO:root:Worker: 1503 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437764
INFO:root:FL Epoch: 284 Norm Difference for worker 1503 is 0.914869
INFO:root:FL Epoch: 284 Done on worker:1503
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1701
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740888
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318617
INFO:root:FL Epoch: 284 Norm Difference for worker 1701 is 0.985474
INFO:root:FL Epoch: 284 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :862
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433652
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470017
INFO:root:FL Epoch: 284 Norm Difference for worker 862 is 1.001989
INFO:root:FL Epoch: 284 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1169
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481533
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450289
INFO:root:FL Epoch: 284 Norm Difference for worker 1169 is 0.997726
INFO:root:FL Epoch: 284 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :346
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.329157
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328137
INFO:root:FL Epoch: 284 Norm Difference for worker 346 is 0.78401
INFO:root:FL Epoch: 284 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :852
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551057
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.718533
INFO:root:FL Epoch: 284 Norm Difference for worker 852 is 0.988059
INFO:root:FL Epoch: 284 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1492
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501979
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508075
INFO:root:FL Epoch: 284 Norm Difference for worker 1492 is 1.045117
INFO:root:FL Epoch: 284 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1401
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618615
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466054
INFO:root:FL Epoch: 284 Norm Difference for worker 1401 is 0.975282
INFO:root:FL Epoch: 284 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :424
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.274649
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278095
INFO:root:FL Epoch: 284 Norm Difference for worker 424 is 0.777239
INFO:root:FL Epoch: 284 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 424
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 284 Ends   ===================
INFO:root:Epoch:284 Global Model Test Loss:0.5186427936834448 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:284 Global Model Backdoor Test Loss:0.14846774314840636                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 285 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 285 Workers Selected : [1837, 824, 1007, 253, 1875, 985, 1657, 468, 1548, 1947]
INFO:root:FL Epoch: 285 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 285 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 285 Training on worker :1837
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801553
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478662
INFO:root:FL Epoch: 285 Norm Difference for worker 1837 is 1.109978
INFO:root:FL Epoch: 285 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :824
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559863
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516642
INFO:root:FL Epoch: 285 Norm Difference for worker 824 is 0.980391
INFO:root:FL Epoch: 285 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1007
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498949
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577034
INFO:root:FL Epoch: 285 Norm Difference for worker 1007 is 1.004449
INFO:root:FL Epoch: 285 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :253
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517325
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.543188
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 285 Norm Difference for worker 253 is 1.099321
INFO:root:FL Epoch: 285 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1875
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1875 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455406
INFO:root:Worker: 1875 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426581
INFO:root:FL Epoch: 285 Norm Difference for worker 1875 is 1.076465
INFO:root:FL Epoch: 285 Done on worker:1875
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :985
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 985 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461321
INFO:root:Worker: 985 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278884
INFO:root:FL Epoch: 285 Norm Difference for worker 985 is 1.080099
INFO:root:FL Epoch: 285 Done on worker:985
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1657
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603771
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533474
INFO:root:FL Epoch: 285 Norm Difference for worker 1657 is 1.109681
INFO:root:FL Epoch: 285 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :468
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320080
INFO:root:Worker: 468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339054
INFO:root:FL Epoch: 285 Norm Difference for worker 468 is 0.889377
INFO:root:FL Epoch: 285 Done on worker:468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1548
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772844
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382478
INFO:root:FL Epoch: 285 Norm Difference for worker 1548 is 1.123171
INFO:root:FL Epoch: 285 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1947
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574997
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.245830
INFO:root:FL Epoch: 285 Norm Difference for worker 1947 is 0.963574
INFO:root:FL Epoch: 285 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 468
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 285 Ends   ===================
INFO:root:Epoch:285 Global Model Test Loss:0.5326425398097319 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:285 Global Model Backdoor Test Loss:0.11420939614375432                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 286 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 286 Workers Selected : [1275, 1599, 419, 900, 474, 471, 1727, 881, 697, 483]
INFO:root:FL Epoch: 286 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 286 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 286 Training on worker :1275
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452663
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.743663
INFO:root:FL Epoch: 286 Norm Difference for worker 1275 is 1.223725
INFO:root:FL Epoch: 286 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1599
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813311
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333521
INFO:root:FL Epoch: 286 Norm Difference for worker 1599 is 1.236083
INFO:root:FL Epoch: 286 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :419
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407385
INFO:root:Worker: 419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400904
INFO:root:FL Epoch: 286 Norm Difference for worker 419 is 1.200705
INFO:root:FL Epoch: 286 Done on worker:419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :900
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530658
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501088
INFO:root:FL Epoch: 286 Norm Difference for worker 900 is 1.22081
INFO:root:FL Epoch: 286 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :474
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.228749
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.845803
INFO:root:FL Epoch: 286 Norm Difference for worker 474 is 1.255018
INFO:root:FL Epoch: 286 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :471
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615158
INFO:root:Worker: 471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393290
INFO:root:FL Epoch: 286 Norm Difference for worker 471 is 1.187211
INFO:root:FL Epoch: 286 Done on worker:471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1727
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611108
INFO:root:Worker: 1727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536063
INFO:root:FL Epoch: 286 Norm Difference for worker 1727 is 1.155123
INFO:root:FL Epoch: 286 Done on worker:1727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :881
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752242
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462012
INFO:root:FL Epoch: 286 Norm Difference for worker 881 is 1.185318
INFO:root:FL Epoch: 286 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :697
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.810391
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630545
INFO:root:FL Epoch: 286 Norm Difference for worker 697 is 1.443298
INFO:root:FL Epoch: 286 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :483
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705898
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586149
INFO:root:FL Epoch: 286 Norm Difference for worker 483 is 1.286056
INFO:root:FL Epoch: 286 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1727
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 286 Ends   ===================
INFO:root:Epoch:286 Global Model Test Loss:0.5093001407735488 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:286 Global Model Backdoor Test Loss:0.1955835223197937                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 287 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 287 Workers Selected : [1262, 690, 59, 1825, 509, 444, 246, 841, 417, 1509]
INFO:root:FL Epoch: 287 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 287 Num points on workers: [200 200 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 287 Training on worker :1262
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1262 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560727
INFO:root:Worker: 1262 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455323
INFO:root:FL Epoch: 287 Norm Difference for worker 1262 is 0.954389
INFO:root:FL Epoch: 287 Done on worker:1262
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :690
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.956378
INFO:root:Worker: 690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427758
INFO:root:FL Epoch: 287 Norm Difference for worker 690 is 0.942141
INFO:root:FL Epoch: 287 Done on worker:690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :59
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.470714
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.241274
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 59 is 1.00264
INFO:root:FL Epoch: 287 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :1825
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429061
INFO:root:Worker: 1825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519238
INFO:root:FL Epoch: 287 Norm Difference for worker 1825 is 0.93911
INFO:root:FL Epoch: 287 Done on worker:1825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :509
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.262027
INFO:root:Worker: 509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467853
INFO:root:FL Epoch: 287 Norm Difference for worker 509 is 1.011893
INFO:root:FL Epoch: 287 Done on worker:509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :444
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744434
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598041
INFO:root:FL Epoch: 287 Norm Difference for worker 444 is 1.054232
INFO:root:FL Epoch: 287 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :246
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.549470
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.528245
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 246 is 0.951447
INFO:root:FL Epoch: 287 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :841
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625330
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437254
INFO:root:FL Epoch: 287 Norm Difference for worker 841 is 0.940454
INFO:root:FL Epoch: 287 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :417
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616899
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546918
INFO:root:FL Epoch: 287 Norm Difference for worker 417 is 0.936128
INFO:root:FL Epoch: 287 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :1509
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533682
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581394
INFO:root:FL Epoch: 287 Norm Difference for worker 1509 is 0.947115
INFO:root:FL Epoch: 287 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 417
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 287 Ends   ===================
INFO:root:Epoch:287 Global Model Test Loss:0.5151022129199084 and Test Accuracy:75.0 
INFO:root:Epoch:287 Global Model Backdoor Test Loss:0.16824365655581155                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 288 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 288 Workers Selected : [893, 133, 732, 912, 831, 1258, 1406, 510, 75, 1065]
INFO:root:FL Epoch: 288 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 288 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 288 Training on worker :893
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425768
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.781959
INFO:root:FL Epoch: 288 Norm Difference for worker 893 is 0.914156
INFO:root:FL Epoch: 288 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :133
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.496185
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.489900
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 288 Norm Difference for worker 133 is 0.927215
INFO:root:FL Epoch: 288 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :732
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483063
INFO:root:Worker: 732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471188
INFO:root:FL Epoch: 288 Norm Difference for worker 732 is 0.907898
INFO:root:FL Epoch: 288 Done on worker:732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :912
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505290
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373030
INFO:root:FL Epoch: 288 Norm Difference for worker 912 is 0.96075
INFO:root:FL Epoch: 288 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :831
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475903
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.140269
INFO:root:FL Epoch: 288 Norm Difference for worker 831 is 0.98114
INFO:root:FL Epoch: 288 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1258
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1258 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511223
INFO:root:Worker: 1258 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470379
INFO:root:FL Epoch: 288 Norm Difference for worker 1258 is 0.890169
INFO:root:FL Epoch: 288 Done on worker:1258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1406
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513116
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564099
INFO:root:FL Epoch: 288 Norm Difference for worker 1406 is 0.953758
INFO:root:FL Epoch: 288 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :510
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613949
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433816
INFO:root:FL Epoch: 288 Norm Difference for worker 510 is 0.955733
INFO:root:FL Epoch: 288 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :75
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 75 Train Epoch: 0 [0/201 (0%)]	Loss: 0.705505
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 75 Train Epoch: 1 [0/201 (0%)]	Loss: 0.315677
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 288 Norm Difference for worker 75 is 1.019658
INFO:root:FL Epoch: 288 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1065
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515679
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378618
INFO:root:FL Epoch: 288 Norm Difference for worker 1065 is 0.915497
INFO:root:FL Epoch: 288 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1258
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 288 Ends   ===================
INFO:root:Epoch:288 Global Model Test Loss:0.5168373444501091 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:288 Global Model Backdoor Test Loss:0.11742278933525085                             and Backdoor Test Accuracy:100.0 
INFO:root:=======================================================
INFO:root:================FL round 289 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 289 Workers Selected : [444, 1645, 199, 500, 917, 1421, 1485, 306, 638, 1471]
INFO:root:FL Epoch: 289 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 289 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 289 Training on worker :444
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442980
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605221
INFO:root:FL Epoch: 289 Norm Difference for worker 444 is 1.157069
INFO:root:FL Epoch: 289 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1645
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803578
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363109
INFO:root:FL Epoch: 289 Norm Difference for worker 1645 is 0.987824
INFO:root:FL Epoch: 289 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :199
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 199 Train Epoch: 0 [0/201 (0%)]	Loss: 0.633865
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 199 Train Epoch: 1 [0/201 (0%)]	Loss: 0.493626
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 199 is 1.052777
INFO:root:FL Epoch: 289 Done on worker:199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :500
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614729
INFO:root:Worker: 500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370190
INFO:root:FL Epoch: 289 Norm Difference for worker 500 is 0.951325
INFO:root:FL Epoch: 289 Done on worker:500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :917
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772030
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562627
INFO:root:FL Epoch: 289 Norm Difference for worker 917 is 1.012512
INFO:root:FL Epoch: 289 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1421
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344263
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301172
INFO:root:FL Epoch: 289 Norm Difference for worker 1421 is 0.897114
INFO:root:FL Epoch: 289 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1485
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314651
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433630
INFO:root:FL Epoch: 289 Norm Difference for worker 1485 is 1.038275
INFO:root:FL Epoch: 289 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :306
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690044
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.351528
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 306 is 0.99729
INFO:root:FL Epoch: 289 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :638
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491940
INFO:root:Worker: 638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540713
INFO:root:FL Epoch: 289 Norm Difference for worker 638 is 0.934102
INFO:root:FL Epoch: 289 Done on worker:638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1471
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622534
INFO:root:Worker: 1471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373905
INFO:root:FL Epoch: 289 Norm Difference for worker 1471 is 1.06623
INFO:root:FL Epoch: 289 Done on worker:1471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 638
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 289 Ends   ===================
INFO:root:Epoch:289 Global Model Test Loss:0.5052938110688153 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:289 Global Model Backdoor Test Loss:0.16692097981770834                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 290 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 290 Workers Selected : [1328, 498, 1566, 1908, 1688, 885, 907, 1256, 1058, 1876]
INFO:root:FL Epoch: 290 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 290 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 290 Training on worker :1328
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1328 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619676
INFO:root:Worker: 1328 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302109
INFO:root:FL Epoch: 290 Norm Difference for worker 1328 is 0.958499
INFO:root:FL Epoch: 290 Done on worker:1328
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :498
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.371537
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371069
INFO:root:FL Epoch: 290 Norm Difference for worker 498 is 0.890226
INFO:root:FL Epoch: 290 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1566
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404491
INFO:root:Worker: 1566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700595
INFO:root:FL Epoch: 290 Norm Difference for worker 1566 is 0.81416
INFO:root:FL Epoch: 290 Done on worker:1566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1908
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650943
INFO:root:Worker: 1908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358909
INFO:root:FL Epoch: 290 Norm Difference for worker 1908 is 0.903282
INFO:root:FL Epoch: 290 Done on worker:1908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1688
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581698
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400263
INFO:root:FL Epoch: 290 Norm Difference for worker 1688 is 0.932003
INFO:root:FL Epoch: 290 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :885
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584079
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455808
INFO:root:FL Epoch: 290 Norm Difference for worker 885 is 0.966771
INFO:root:FL Epoch: 290 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :907
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.243439
INFO:root:Worker: 907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529871
INFO:root:FL Epoch: 290 Norm Difference for worker 907 is 0.935789
INFO:root:FL Epoch: 290 Done on worker:907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1256
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332042
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246764
INFO:root:FL Epoch: 290 Norm Difference for worker 1256 is 0.861033
INFO:root:FL Epoch: 290 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1058
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1058 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388358
INFO:root:Worker: 1058 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422576
INFO:root:FL Epoch: 290 Norm Difference for worker 1058 is 0.98002
INFO:root:FL Epoch: 290 Done on worker:1058
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1876
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612792
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574019
INFO:root:FL Epoch: 290 Norm Difference for worker 1876 is 1.07817
INFO:root:FL Epoch: 290 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1566
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 290 Ends   ===================
INFO:root:Epoch:290 Global Model Test Loss:0.5216387405115015 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:290 Global Model Backdoor Test Loss:0.14744201178352037                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 291 Begins ===================
INFO:root:FL Epoch: 291 *** This is Attack Epoch *** 
INFO:root:[True, True, True, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 291 Workers Selected : [0, 1, 2, 1366, 1025, 1801, 1023, 476, 769, 1114]
INFO:root:FL Epoch: 291 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 291 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 291 Training on worker :0
INFO:root:FL Epoch: 291 Using Learning rate : 0.0055957328628250666 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.161187
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194165
INFO:root:FL Epoch: 291 Worker: 0 Backdoor Test Loss: 0.1327469932536284 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 291 Worker: 0 Backdoor Train Loss: 0.2159404896199703 Backdoor Train Accuracy: 94.0
INFO:root:FL Epoch: 291 Norm Difference for worker 0 is 0.193397
INFO:root:FL Epoch: 291 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1
INFO:root:FL Epoch: 291 Using Learning rate : 0.0055957328628250666 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 1 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336615
INFO:root:Worker: 1 Train Epoch: 1 [0/200 (0%)]	Loss: 0.219370
INFO:root:FL Epoch: 291 Worker: 1 Backdoor Test Loss: 0.13013737524549165 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 291 Worker: 1 Backdoor Train Loss: 0.21527148187160491 Backdoor Train Accuracy: 93.5
INFO:root:FL Epoch: 291 Norm Difference for worker 1 is 0.192599
INFO:root:FL Epoch: 291 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :2
INFO:root:FL Epoch: 291 Using Learning rate : 0.0055957328628250666 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 2 Train Epoch: 0 [0/200 (0%)]	Loss: 0.237019
INFO:root:Worker: 2 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261833
INFO:root:FL Epoch: 291 Worker: 2 Backdoor Test Loss: 0.12869041164716086 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 291 Worker: 2 Backdoor Train Loss: 0.2142089307308197 Backdoor Train Accuracy: 94.0
INFO:root:FL Epoch: 291 Norm Difference for worker 2 is 0.197653
INFO:root:FL Epoch: 291 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1366
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530443
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393281
INFO:root:FL Epoch: 291 Norm Difference for worker 1366 is 0.932767
INFO:root:FL Epoch: 291 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1025
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613449
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609702
INFO:root:FL Epoch: 291 Norm Difference for worker 1025 is 0.929745
INFO:root:FL Epoch: 291 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1801
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457586
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418645
INFO:root:FL Epoch: 291 Norm Difference for worker 1801 is 0.950886
INFO:root:FL Epoch: 291 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1023
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1023 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497570
INFO:root:Worker: 1023 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449069
INFO:root:FL Epoch: 291 Norm Difference for worker 1023 is 0.968278
INFO:root:FL Epoch: 291 Done on worker:1023
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :476
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753889
INFO:root:Worker: 476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435212
INFO:root:FL Epoch: 291 Norm Difference for worker 476 is 0.973204
INFO:root:FL Epoch: 291 Done on worker:476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :769
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704516
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575182
INFO:root:FL Epoch: 291 Norm Difference for worker 769 is 0.988065
INFO:root:FL Epoch: 291 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1114
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638661
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653412
INFO:root:FL Epoch: 291 Norm Difference for worker 1114 is 1.053087
INFO:root:FL Epoch: 291 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 291 Ends   ===================
INFO:root:Epoch:291 Global Model Test Loss:0.5210701840765336 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:291 Global Model Backdoor Test Loss:0.13013737524549165                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 292 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 292 Workers Selected : [1472, 1744, 373, 1755, 1251, 364, 894, 1005, 388, 1242]
INFO:root:FL Epoch: 292 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 292 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 292 Training on worker :1472
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796732
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471565
INFO:root:FL Epoch: 292 Norm Difference for worker 1472 is 1.040403
INFO:root:FL Epoch: 292 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1744
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449435
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352864
INFO:root:FL Epoch: 292 Norm Difference for worker 1744 is 1.045131
INFO:root:FL Epoch: 292 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :373
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553094
INFO:root:Worker: 373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657667
INFO:root:FL Epoch: 292 Norm Difference for worker 373 is 1.125115
INFO:root:FL Epoch: 292 Done on worker:373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1755
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674887
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582935
INFO:root:FL Epoch: 292 Norm Difference for worker 1755 is 1.006342
INFO:root:FL Epoch: 292 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1251
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519772
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538312
INFO:root:FL Epoch: 292 Norm Difference for worker 1251 is 1.029074
INFO:root:FL Epoch: 292 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :364
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519307
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552930
INFO:root:FL Epoch: 292 Norm Difference for worker 364 is 1.039137
INFO:root:FL Epoch: 292 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :894
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780962
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464749
INFO:root:FL Epoch: 292 Norm Difference for worker 894 is 1.025754
INFO:root:FL Epoch: 292 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1005
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1005 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489731
INFO:root:Worker: 1005 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455689
INFO:root:FL Epoch: 292 Norm Difference for worker 1005 is 1.026302
INFO:root:FL Epoch: 292 Done on worker:1005
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :388
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430705
INFO:root:Worker: 388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547237
INFO:root:FL Epoch: 292 Norm Difference for worker 388 is 1.018844
INFO:root:FL Epoch: 292 Done on worker:388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1242
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355262
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463805
INFO:root:FL Epoch: 292 Norm Difference for worker 1242 is 1.015637
INFO:root:FL Epoch: 292 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1251
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 292 Ends   ===================
INFO:root:Epoch:292 Global Model Test Loss:0.5349711302448722 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:292 Global Model Backdoor Test Loss:0.2450085481007894                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 293 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 293 Workers Selected : [1224, 983, 1414, 1763, 305, 650, 1660, 1700, 1483, 860]
INFO:root:FL Epoch: 293 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 293 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 293 Training on worker :1224
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1224 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600710
INFO:root:Worker: 1224 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558450
INFO:root:FL Epoch: 293 Norm Difference for worker 1224 is 0.822337
INFO:root:FL Epoch: 293 Done on worker:1224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :983
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697041
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490702
INFO:root:FL Epoch: 293 Norm Difference for worker 983 is 0.917981
INFO:root:FL Epoch: 293 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1414
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649736
INFO:root:Worker: 1414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565381
INFO:root:FL Epoch: 293 Norm Difference for worker 1414 is 0.876957
INFO:root:FL Epoch: 293 Done on worker:1414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1763
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584355
INFO:root:Worker: 1763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525298
INFO:root:FL Epoch: 293 Norm Difference for worker 1763 is 0.857148
INFO:root:FL Epoch: 293 Done on worker:1763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :305
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 305 Train Epoch: 0 [0/201 (0%)]	Loss: 0.563633
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 305 Train Epoch: 1 [0/201 (0%)]	Loss: 0.438996
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 293 Norm Difference for worker 305 is 0.806516
INFO:root:FL Epoch: 293 Done on worker:305
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :650
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521332
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559715
INFO:root:FL Epoch: 293 Norm Difference for worker 650 is 0.912135
INFO:root:FL Epoch: 293 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1660
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486692
INFO:root:Worker: 1660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534781
INFO:root:FL Epoch: 293 Norm Difference for worker 1660 is 0.844937
INFO:root:FL Epoch: 293 Done on worker:1660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1700
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557161
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307341
INFO:root:FL Epoch: 293 Norm Difference for worker 1700 is 0.8398
INFO:root:FL Epoch: 293 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1483
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409971
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350337
INFO:root:FL Epoch: 293 Norm Difference for worker 1483 is 0.851705
INFO:root:FL Epoch: 293 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :860
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812179
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501336
INFO:root:FL Epoch: 293 Norm Difference for worker 860 is 0.948911
INFO:root:FL Epoch: 293 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 305
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 293 Ends   ===================
INFO:root:Epoch:293 Global Model Test Loss:0.528744126067442 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:293 Global Model Backdoor Test Loss:0.15742717683315277                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 294 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 294 Workers Selected : [318, 1700, 951, 1022, 1087, 931, 653, 272, 1459, 1399]
INFO:root:FL Epoch: 294 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 294 Num points on workers: [201 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 294 Training on worker :318
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.336325
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.343962
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 318 is 0.896514
INFO:root:FL Epoch: 294 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1700
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430577
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338714
INFO:root:FL Epoch: 294 Norm Difference for worker 1700 is 0.843809
INFO:root:FL Epoch: 294 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :951
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571507
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653304
INFO:root:FL Epoch: 294 Norm Difference for worker 951 is 0.879997
INFO:root:FL Epoch: 294 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1022
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585757
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413045
INFO:root:FL Epoch: 294 Norm Difference for worker 1022 is 0.88113
INFO:root:FL Epoch: 294 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1087
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530955
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.768935
INFO:root:FL Epoch: 294 Norm Difference for worker 1087 is 0.948242
INFO:root:FL Epoch: 294 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :931
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530392
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498222
INFO:root:FL Epoch: 294 Norm Difference for worker 931 is 0.943415
INFO:root:FL Epoch: 294 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :653
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651354
INFO:root:Worker: 653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533503
INFO:root:FL Epoch: 294 Norm Difference for worker 653 is 0.876762
INFO:root:FL Epoch: 294 Done on worker:653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :272
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.656293
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.521895
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 272 is 0.848057
INFO:root:FL Epoch: 294 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1459
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689473
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589213
INFO:root:FL Epoch: 294 Norm Difference for worker 1459 is 0.923032
INFO:root:FL Epoch: 294 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1399
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696022
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518439
INFO:root:FL Epoch: 294 Norm Difference for worker 1399 is 0.903823
INFO:root:FL Epoch: 294 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 272
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 294 Ends   ===================
INFO:root:Epoch:294 Global Model Test Loss:0.5541004485943738 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:294 Global Model Backdoor Test Loss:0.20203960686922073                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 295 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 295 Workers Selected : [675, 1942, 1406, 1321, 443, 427, 1883, 918, 638, 1630]
INFO:root:FL Epoch: 295 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 295 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 295 Training on worker :675
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 675 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440082
INFO:root:Worker: 675 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398703
INFO:root:FL Epoch: 295 Norm Difference for worker 675 is 0.974581
INFO:root:FL Epoch: 295 Done on worker:675
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1942
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459099
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359549
INFO:root:FL Epoch: 295 Norm Difference for worker 1942 is 0.933774
INFO:root:FL Epoch: 295 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1406
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595585
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593741
INFO:root:FL Epoch: 295 Norm Difference for worker 1406 is 0.968929
INFO:root:FL Epoch: 295 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1321
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1321 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754730
INFO:root:Worker: 1321 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573262
INFO:root:FL Epoch: 295 Norm Difference for worker 1321 is 0.995463
INFO:root:FL Epoch: 295 Done on worker:1321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :443
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670594
INFO:root:Worker: 443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462903
INFO:root:FL Epoch: 295 Norm Difference for worker 443 is 0.9251
INFO:root:FL Epoch: 295 Done on worker:443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :427
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552618
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506904
INFO:root:FL Epoch: 295 Norm Difference for worker 427 is 0.93693
INFO:root:FL Epoch: 295 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1883
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635355
INFO:root:Worker: 1883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386834
INFO:root:FL Epoch: 295 Norm Difference for worker 1883 is 0.982755
INFO:root:FL Epoch: 295 Done on worker:1883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :918
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369007
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386521
INFO:root:FL Epoch: 295 Norm Difference for worker 918 is 0.954805
INFO:root:FL Epoch: 295 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :638
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.267589
INFO:root:Worker: 638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362955
INFO:root:FL Epoch: 295 Norm Difference for worker 638 is 0.810499
INFO:root:FL Epoch: 295 Done on worker:638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1630
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646708
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460543
INFO:root:FL Epoch: 295 Norm Difference for worker 1630 is 0.986671
INFO:root:FL Epoch: 295 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 638
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 295 Ends   ===================
INFO:root:Epoch:295 Global Model Test Loss:0.5509074786130119 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:295 Global Model Backdoor Test Loss:0.09425552934408188                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 296 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 296 Workers Selected : [1480, 79, 1343, 1312, 198, 1941, 975, 496, 1075, 1032]
INFO:root:FL Epoch: 296 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 296 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 296 Training on worker :1480
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566170
INFO:root:Worker: 1480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358265
INFO:root:FL Epoch: 296 Norm Difference for worker 1480 is 1.27333
INFO:root:FL Epoch: 296 Done on worker:1480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :79
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.710611
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.371399
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 79 is 1.157585
INFO:root:FL Epoch: 296 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1343
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622128
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372912
INFO:root:FL Epoch: 296 Norm Difference for worker 1343 is 1.129983
INFO:root:FL Epoch: 296 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1312
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.874334
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543827
INFO:root:FL Epoch: 296 Norm Difference for worker 1312 is 1.24359
INFO:root:FL Epoch: 296 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :198
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.829618
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.390498
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 198 is 1.24864
INFO:root:FL Epoch: 296 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1941
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.784422
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590729
INFO:root:FL Epoch: 296 Norm Difference for worker 1941 is 1.199867
INFO:root:FL Epoch: 296 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :975
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535679
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498507
INFO:root:FL Epoch: 296 Norm Difference for worker 975 is 1.241248
INFO:root:FL Epoch: 296 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :496
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375864
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384457
INFO:root:FL Epoch: 296 Norm Difference for worker 496 is 1.192377
INFO:root:FL Epoch: 296 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1075
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.767976
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410471
INFO:root:FL Epoch: 296 Norm Difference for worker 1075 is 1.194713
INFO:root:FL Epoch: 296 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1032
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1032 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451753
INFO:root:Worker: 1032 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360850
INFO:root:FL Epoch: 296 Norm Difference for worker 1032 is 1.143935
INFO:root:FL Epoch: 296 Done on worker:1032
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1032
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 296 Ends   ===================
INFO:root:Epoch:296 Global Model Test Loss:0.5244768840425155 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:296 Global Model Backdoor Test Loss:0.1296123812596003                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 297 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 297 Workers Selected : [1570, 1715, 1205, 1159, 1186, 734, 1461, 100, 989, 1614]
INFO:root:FL Epoch: 297 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 297 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 297 Training on worker :1570
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.318855
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424558
INFO:root:FL Epoch: 297 Norm Difference for worker 1570 is 1.079987
INFO:root:FL Epoch: 297 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1715
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.793891
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300191
INFO:root:FL Epoch: 297 Norm Difference for worker 1715 is 1.131474
INFO:root:FL Epoch: 297 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1205
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.876525
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357855
INFO:root:FL Epoch: 297 Norm Difference for worker 1205 is 1.007463
INFO:root:FL Epoch: 297 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1159
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1159 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664952
INFO:root:Worker: 1159 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418298
INFO:root:FL Epoch: 297 Norm Difference for worker 1159 is 1.003334
INFO:root:FL Epoch: 297 Done on worker:1159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1186
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696626
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505650
INFO:root:FL Epoch: 297 Norm Difference for worker 1186 is 1.100255
INFO:root:FL Epoch: 297 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :734
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509968
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630933
INFO:root:FL Epoch: 297 Norm Difference for worker 734 is 1.016476
INFO:root:FL Epoch: 297 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1461
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491454
INFO:root:Worker: 1461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291223
INFO:root:FL Epoch: 297 Norm Difference for worker 1461 is 0.873139
INFO:root:FL Epoch: 297 Done on worker:1461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :100
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.662790
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.571411
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 297 Norm Difference for worker 100 is 1.097002
INFO:root:FL Epoch: 297 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :989
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 989 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675949
INFO:root:Worker: 989 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493824
INFO:root:FL Epoch: 297 Norm Difference for worker 989 is 1.066723
INFO:root:FL Epoch: 297 Done on worker:989
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1614
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492250
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507449
INFO:root:FL Epoch: 297 Norm Difference for worker 1614 is 1.125747
INFO:root:FL Epoch: 297 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1461
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 297 Ends   ===================
INFO:root:Epoch:297 Global Model Test Loss:0.54078268829514 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:297 Global Model Backdoor Test Loss:0.19954333206017813                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 298 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 298 Workers Selected : [535, 268, 968, 728, 188, 1851, 1892, 580, 1226, 1003]
INFO:root:FL Epoch: 298 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 298 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 298 Training on worker :535
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771378
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636855
INFO:root:FL Epoch: 298 Norm Difference for worker 535 is 1.092745
INFO:root:FL Epoch: 298 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :268
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 268 Train Epoch: 0 [0/201 (0%)]	Loss: 0.649791
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 268 Train Epoch: 1 [0/201 (0%)]	Loss: 0.298182
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 298 Norm Difference for worker 268 is 1.1322
INFO:root:FL Epoch: 298 Done on worker:268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :968
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567616
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663514
INFO:root:FL Epoch: 298 Norm Difference for worker 968 is 1.085534
INFO:root:FL Epoch: 298 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :728
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344712
INFO:root:Worker: 728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.824447
INFO:root:FL Epoch: 298 Norm Difference for worker 728 is 1.208719
INFO:root:FL Epoch: 298 Done on worker:728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :188
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.489002
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.342117
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 298 Norm Difference for worker 188 is 1.042407
INFO:root:FL Epoch: 298 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1851
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716951
INFO:root:Worker: 1851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311897
INFO:root:FL Epoch: 298 Norm Difference for worker 1851 is 1.050488
INFO:root:FL Epoch: 298 Done on worker:1851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1892
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395909
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385866
INFO:root:FL Epoch: 298 Norm Difference for worker 1892 is 0.953866
INFO:root:FL Epoch: 298 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :580
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560486
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362676
INFO:root:FL Epoch: 298 Norm Difference for worker 580 is 1.054168
INFO:root:FL Epoch: 298 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1226
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572856
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452553
INFO:root:FL Epoch: 298 Norm Difference for worker 1226 is 1.063153
INFO:root:FL Epoch: 298 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1003
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540980
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346424
INFO:root:FL Epoch: 298 Norm Difference for worker 1003 is 1.064526
INFO:root:FL Epoch: 298 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1892
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 298 Ends   ===================
INFO:root:Epoch:298 Global Model Test Loss:0.5208333117120406 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:298 Global Model Backdoor Test Loss:0.18070616448918977                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 299 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 299 Workers Selected : [1318, 1648, 781, 1817, 648, 144, 1139, 1156, 598, 650]
INFO:root:FL Epoch: 299 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 299 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 299 Training on worker :1318
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440124
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543232
INFO:root:FL Epoch: 299 Norm Difference for worker 1318 is 1.028682
INFO:root:FL Epoch: 299 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1648
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397204
INFO:root:Worker: 1648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399460
INFO:root:FL Epoch: 299 Norm Difference for worker 1648 is 0.984827
INFO:root:FL Epoch: 299 Done on worker:1648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :781
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499847
INFO:root:Worker: 781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465099
INFO:root:FL Epoch: 299 Norm Difference for worker 781 is 1.050727
INFO:root:FL Epoch: 299 Done on worker:781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1817
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468994
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620498
INFO:root:FL Epoch: 299 Norm Difference for worker 1817 is 0.979629
INFO:root:FL Epoch: 299 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :648
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463413
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666496
INFO:root:FL Epoch: 299 Norm Difference for worker 648 is 1.00817
INFO:root:FL Epoch: 299 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :144
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.499734
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.583523
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 299 Norm Difference for worker 144 is 1.073116
INFO:root:FL Epoch: 299 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1139
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488717
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338777
INFO:root:FL Epoch: 299 Norm Difference for worker 1139 is 1.013186
INFO:root:FL Epoch: 299 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1156
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611791
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575667
INFO:root:FL Epoch: 299 Norm Difference for worker 1156 is 1.053705
INFO:root:FL Epoch: 299 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :598
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568126
INFO:root:Worker: 598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373164
INFO:root:FL Epoch: 299 Norm Difference for worker 598 is 1.011402
INFO:root:FL Epoch: 299 Done on worker:598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :650
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514126
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672566
INFO:root:FL Epoch: 299 Norm Difference for worker 650 is 1.035161
INFO:root:FL Epoch: 299 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1817
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 299 Ends   ===================
INFO:root:Epoch:299 Global Model Test Loss:0.5245156253085417 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:299 Global Model Backdoor Test Loss:0.22244937966267267                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 300 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 300 Workers Selected : [1467, 1937, 1312, 1780, 228, 852, 941, 1896, 414, 1088]
INFO:root:FL Epoch: 300 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 300 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 300 Training on worker :1467
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581817
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545845
INFO:root:FL Epoch: 300 Norm Difference for worker 1467 is 0.809589
INFO:root:FL Epoch: 300 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1937
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647436
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515210
INFO:root:FL Epoch: 300 Norm Difference for worker 1937 is 0.986283
INFO:root:FL Epoch: 300 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1312
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494879
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539902
INFO:root:FL Epoch: 300 Norm Difference for worker 1312 is 0.942527
INFO:root:FL Epoch: 300 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1780
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656368
INFO:root:Worker: 1780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549448
INFO:root:FL Epoch: 300 Norm Difference for worker 1780 is 0.933828
INFO:root:FL Epoch: 300 Done on worker:1780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :228
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.522713
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.457499
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 300 Norm Difference for worker 228 is 0.925065
INFO:root:FL Epoch: 300 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :852
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536239
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534841
INFO:root:FL Epoch: 300 Norm Difference for worker 852 is 0.908506
INFO:root:FL Epoch: 300 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :941
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518996
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454310
INFO:root:FL Epoch: 300 Norm Difference for worker 941 is 0.863678
INFO:root:FL Epoch: 300 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1896
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477215
INFO:root:Worker: 1896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682403
INFO:root:FL Epoch: 300 Norm Difference for worker 1896 is 0.955224
INFO:root:FL Epoch: 300 Done on worker:1896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :414
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504116
INFO:root:Worker: 414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625893
INFO:root:FL Epoch: 300 Norm Difference for worker 414 is 0.915225
INFO:root:FL Epoch: 300 Done on worker:414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1088
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479963
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354161
INFO:root:FL Epoch: 300 Norm Difference for worker 1088 is 0.875057
INFO:root:FL Epoch: 300 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1467
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 300 Ends   ===================
INFO:root:Epoch:300 Global Model Test Loss:0.5373332325149985 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:300 Global Model Backdoor Test Loss:0.2693640391031901                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:***** Done with FL Training, Saved the stats to file ./out/attack-strategies/epoch1//stats.csv ******
