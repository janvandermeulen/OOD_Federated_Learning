INFO:root:Backdoor type: single-character-attack
INFO:root: noDefense: False
INFO:root:Initialising training data for single character backdoor
INFO:root:Backdoor Train Size: 200 Backdoor Test Size: 120
INFO:root:size of test data 340
INFO:root:attack from epoch 101
INFO:root:Test Accuracy of loaded global Model is: 55.588235294117645
INFO:root:================FL round 1 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 1 Workers Selected : [1606, 1878, 862, 1182, 1092, 730, 1171, 786, 594, 622]
INFO:root:FL Epoch: 1 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 1 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 1 Training on worker :1606
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698303
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697776
INFO:root:FL Epoch: 1 Norm Difference for worker 1606 is 0.315865
INFO:root:FL Epoch: 1 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1878
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690026
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661391
INFO:root:FL Epoch: 1 Norm Difference for worker 1878 is 0.410548
INFO:root:FL Epoch: 1 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :862
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690099
INFO:root:Worker: 862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692415
INFO:root:FL Epoch: 1 Norm Difference for worker 862 is 0.311819
INFO:root:FL Epoch: 1 Done on worker:862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1182
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691611
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693252
INFO:root:FL Epoch: 1 Norm Difference for worker 1182 is 0.307113
INFO:root:FL Epoch: 1 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1092
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692119
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685201
INFO:root:FL Epoch: 1 Norm Difference for worker 1092 is 0.296813
INFO:root:FL Epoch: 1 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :730
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694413
INFO:root:Worker: 730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682774
INFO:root:FL Epoch: 1 Norm Difference for worker 730 is 0.295464
INFO:root:FL Epoch: 1 Done on worker:730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :1171
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 1171 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685938
INFO:root:Worker: 1171 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691727
INFO:root:FL Epoch: 1 Norm Difference for worker 1171 is 0.302236
INFO:root:FL Epoch: 1 Done on worker:1171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :786
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696200
INFO:root:Worker: 786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703516
INFO:root:FL Epoch: 1 Norm Difference for worker 786 is 0.28311
INFO:root:FL Epoch: 1 Done on worker:786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :594
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693030
INFO:root:Worker: 594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675873
INFO:root:FL Epoch: 1 Norm Difference for worker 594 is 0.348142
INFO:root:FL Epoch: 1 Done on worker:594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 1 Training on worker :622
INFO:root:FL Epoch: 1 Using Learning rate : 0.05 
INFO:root:FL Epoch: 1 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695827
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689992
INFO:root:FL Epoch: 1 Norm Difference for worker 622 is 0.364429
INFO:root:FL Epoch: 1 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1092
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 1 Ends   ===================
INFO:root:Epoch:1 Global Model Test Loss:0.6904877354117 and Test Accuracy:52.94117647058823 
INFO:root:Epoch:1 Global Model Backdoor Test Loss:0.6678750018278757                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 2 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 2 Workers Selected : [1014, 541, 1235, 1385, 766, 1091, 1598, 274, 205, 157]
INFO:root:FL Epoch: 2 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 2 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 2 Training on worker :1014
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688270
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690192
INFO:root:FL Epoch: 2 Norm Difference for worker 1014 is 0.293343
INFO:root:FL Epoch: 2 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :541
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697292
INFO:root:Worker: 541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686423
INFO:root:FL Epoch: 2 Norm Difference for worker 541 is 0.283175
INFO:root:FL Epoch: 2 Done on worker:541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1235
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1235 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699042
INFO:root:Worker: 1235 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679857
INFO:root:FL Epoch: 2 Norm Difference for worker 1235 is 0.355588
INFO:root:FL Epoch: 2 Done on worker:1235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1385
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683652
INFO:root:Worker: 1385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702759
INFO:root:FL Epoch: 2 Norm Difference for worker 1385 is 0.295346
INFO:root:FL Epoch: 2 Done on worker:1385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :766
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695212
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680198
INFO:root:FL Epoch: 2 Norm Difference for worker 766 is 0.363824
INFO:root:FL Epoch: 2 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1091
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1091 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687731
INFO:root:Worker: 1091 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695188
INFO:root:FL Epoch: 2 Norm Difference for worker 1091 is 0.292763
INFO:root:FL Epoch: 2 Done on worker:1091
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :1598
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700485
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699368
INFO:root:FL Epoch: 2 Norm Difference for worker 1598 is 0.34881
INFO:root:FL Epoch: 2 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :274
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.684162
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.693662
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 274 is 0.324434
INFO:root:FL Epoch: 2 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :205
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.677199
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.701673
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 205 is 0.332548
INFO:root:FL Epoch: 2 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 2 Training on worker :157
INFO:root:FL Epoch: 2 Using Learning rate : 0.0499 
INFO:root:FL Epoch: 2 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.696387
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690926
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 2 Norm Difference for worker 157 is 0.349797
INFO:root:FL Epoch: 2 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1091
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 2 Ends   ===================
INFO:root:Epoch:2 Global Model Test Loss:0.6873041286188013 and Test Accuracy:56.1764705882353 
INFO:root:Epoch:2 Global Model Backdoor Test Loss:0.6898849507172903                             and Backdoor Test Accuracy:71.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 3 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 3 Workers Selected : [519, 894, 617, 1462, 1278, 1505, 427, 1685, 1714, 1913]
INFO:root:FL Epoch: 3 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 3 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 3 Training on worker :519
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675287
INFO:root:Worker: 519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687964
INFO:root:FL Epoch: 3 Norm Difference for worker 519 is 0.325098
INFO:root:FL Epoch: 3 Done on worker:519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :894
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693719
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688630
INFO:root:FL Epoch: 3 Norm Difference for worker 894 is 0.322266
INFO:root:FL Epoch: 3 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :617
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685023
INFO:root:Worker: 617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658362
INFO:root:FL Epoch: 3 Norm Difference for worker 617 is 0.434134
INFO:root:FL Epoch: 3 Done on worker:617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1462
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680702
INFO:root:Worker: 1462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.715223
INFO:root:FL Epoch: 3 Norm Difference for worker 1462 is 0.418623
INFO:root:FL Epoch: 3 Done on worker:1462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1278
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689015
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657424
INFO:root:FL Epoch: 3 Norm Difference for worker 1278 is 0.328717
INFO:root:FL Epoch: 3 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1505
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673720
INFO:root:Worker: 1505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671090
INFO:root:FL Epoch: 3 Norm Difference for worker 1505 is 0.367225
INFO:root:FL Epoch: 3 Done on worker:1505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :427
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690807
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680410
INFO:root:FL Epoch: 3 Norm Difference for worker 427 is 0.318015
INFO:root:FL Epoch: 3 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1685
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681838
INFO:root:Worker: 1685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692472
INFO:root:FL Epoch: 3 Norm Difference for worker 1685 is 0.3096
INFO:root:FL Epoch: 3 Done on worker:1685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1714
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1714 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689839
INFO:root:Worker: 1714 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665922
INFO:root:FL Epoch: 3 Norm Difference for worker 1714 is 0.394681
INFO:root:FL Epoch: 3 Done on worker:1714
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 3 Training on worker :1913
INFO:root:FL Epoch: 3 Using Learning rate : 0.0498002 
INFO:root:FL Epoch: 3 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697197
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680728
INFO:root:FL Epoch: 3 Norm Difference for worker 1913 is 0.367458
INFO:root:FL Epoch: 3 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1278
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 3 Ends   ===================
INFO:root:Epoch:3 Global Model Test Loss:0.6835638600237229 and Test Accuracy:55.88235294117647 
INFO:root:Epoch:3 Global Model Backdoor Test Loss:0.7244651615619659                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 4 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 4 Workers Selected : [950, 1406, 1256, 1070, 1080, 1610, 532, 872, 619, 1157]
INFO:root:FL Epoch: 4 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 4 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 4 Training on worker :950
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693158
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695574
INFO:root:FL Epoch: 4 Norm Difference for worker 950 is 0.420743
INFO:root:FL Epoch: 4 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1406
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680650
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684730
INFO:root:FL Epoch: 4 Norm Difference for worker 1406 is 0.435952
INFO:root:FL Epoch: 4 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1256
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680475
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694189
INFO:root:FL Epoch: 4 Norm Difference for worker 1256 is 0.41708
INFO:root:FL Epoch: 4 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1070
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678631
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704725
INFO:root:FL Epoch: 4 Norm Difference for worker 1070 is 0.412219
INFO:root:FL Epoch: 4 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1080
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694687
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681909
INFO:root:FL Epoch: 4 Norm Difference for worker 1080 is 0.386024
INFO:root:FL Epoch: 4 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1610
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702770
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694707
INFO:root:FL Epoch: 4 Norm Difference for worker 1610 is 0.365404
INFO:root:FL Epoch: 4 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :532
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671502
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679865
INFO:root:FL Epoch: 4 Norm Difference for worker 532 is 0.365387
INFO:root:FL Epoch: 4 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :872
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715083
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674203
INFO:root:FL Epoch: 4 Norm Difference for worker 872 is 0.359627
INFO:root:FL Epoch: 4 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :619
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682464
INFO:root:Worker: 619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690347
INFO:root:FL Epoch: 4 Norm Difference for worker 619 is 0.354653
INFO:root:FL Epoch: 4 Done on worker:619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 4 Training on worker :1157
INFO:root:FL Epoch: 4 Using Learning rate : 0.049700599600000006 
INFO:root:FL Epoch: 4 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693386
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672336
INFO:root:FL Epoch: 4 Norm Difference for worker 1157 is 0.358723
INFO:root:FL Epoch: 4 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 872
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 4 Ends   ===================
INFO:root:Epoch:4 Global Model Test Loss:0.6808902270653668 and Test Accuracy:56.470588235294116 
INFO:root:Epoch:4 Global Model Backdoor Test Loss:0.7081344028313955                             and Backdoor Test Accuracy:46.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 5 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 5 Workers Selected : [1195, 749, 491, 1167, 1623, 1225, 1025, 1361, 552, 1010]
INFO:root:FL Epoch: 5 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 5 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 5 Training on worker :1195
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688112
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702013
INFO:root:FL Epoch: 5 Norm Difference for worker 1195 is 0.381491
INFO:root:FL Epoch: 5 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :749
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 749 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678915
INFO:root:Worker: 749 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666216
INFO:root:FL Epoch: 5 Norm Difference for worker 749 is 0.419416
INFO:root:FL Epoch: 5 Done on worker:749
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :491
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668493
INFO:root:Worker: 491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607064
INFO:root:FL Epoch: 5 Norm Difference for worker 491 is 0.473453
INFO:root:FL Epoch: 5 Done on worker:491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1167
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691964
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679230
INFO:root:FL Epoch: 5 Norm Difference for worker 1167 is 0.436478
INFO:root:FL Epoch: 5 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1623
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713713
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654386
INFO:root:FL Epoch: 5 Norm Difference for worker 1623 is 0.438007
INFO:root:FL Epoch: 5 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1225
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1225 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704647
INFO:root:Worker: 1225 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650474
INFO:root:FL Epoch: 5 Norm Difference for worker 1225 is 0.390061
INFO:root:FL Epoch: 5 Done on worker:1225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1025
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685034
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.706514
INFO:root:FL Epoch: 5 Norm Difference for worker 1025 is 0.398544
INFO:root:FL Epoch: 5 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1361
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698796
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666910
INFO:root:FL Epoch: 5 Norm Difference for worker 1361 is 0.39831
INFO:root:FL Epoch: 5 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :552
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655898
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672479
INFO:root:FL Epoch: 5 Norm Difference for worker 552 is 0.382206
INFO:root:FL Epoch: 5 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 5 Training on worker :1010
INFO:root:FL Epoch: 5 Using Learning rate : 0.0496011984008 
INFO:root:FL Epoch: 5 Normal Training
INFO:root:Worker: 1010 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685626
INFO:root:Worker: 1010 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661644
INFO:root:FL Epoch: 5 Norm Difference for worker 1010 is 0.401055
INFO:root:FL Epoch: 5 Done on worker:1010
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1195
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 5 Ends   ===================
INFO:root:Epoch:5 Global Model Test Loss:0.6800960477660684 and Test Accuracy:57.94117647058823 
INFO:root:Epoch:5 Global Model Backdoor Test Loss:0.6702512800693512                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 6 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 6 Workers Selected : [31, 1357, 315, 1846, 246, 622, 809, 1763, 1350, 1677]
INFO:root:FL Epoch: 6 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 6 Num points on workers: [201 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 6 Training on worker :31
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 31 Train Epoch: 0 [0/201 (0%)]	Loss: 0.673919
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 31 Train Epoch: 1 [0/201 (0%)]	Loss: 0.665771
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 6 Norm Difference for worker 31 is 0.463941
INFO:root:FL Epoch: 6 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1357
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672492
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630422
INFO:root:FL Epoch: 6 Norm Difference for worker 1357 is 0.429524
INFO:root:FL Epoch: 6 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :315
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687094
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.705956
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 6 Norm Difference for worker 315 is 0.447597
INFO:root:FL Epoch: 6 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1846
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652520
INFO:root:Worker: 1846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653338
INFO:root:FL Epoch: 6 Norm Difference for worker 1846 is 0.49554
INFO:root:FL Epoch: 6 Done on worker:1846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :246
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697708
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.674123
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 6 Norm Difference for worker 246 is 0.416872
INFO:root:FL Epoch: 6 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :622
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690243
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671184
INFO:root:FL Epoch: 6 Norm Difference for worker 622 is 0.535324
INFO:root:FL Epoch: 6 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :809
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678840
INFO:root:Worker: 809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671494
INFO:root:FL Epoch: 6 Norm Difference for worker 809 is 0.439261
INFO:root:FL Epoch: 6 Done on worker:809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1763
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677125
INFO:root:Worker: 1763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684787
INFO:root:FL Epoch: 6 Norm Difference for worker 1763 is 0.422239
INFO:root:FL Epoch: 6 Done on worker:1763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1350
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678017
INFO:root:Worker: 1350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676922
INFO:root:FL Epoch: 6 Norm Difference for worker 1350 is 0.429529
INFO:root:FL Epoch: 6 Done on worker:1350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 6 Training on worker :1677
INFO:root:FL Epoch: 6 Using Learning rate : 0.049501996003998405 
INFO:root:FL Epoch: 6 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689115
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712885
INFO:root:FL Epoch: 6 Norm Difference for worker 1677 is 0.389578
INFO:root:FL Epoch: 6 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1677
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 6 Ends   ===================
INFO:root:Epoch:6 Global Model Test Loss:0.6791893419097451 and Test Accuracy:59.411764705882355 
INFO:root:Epoch:6 Global Model Backdoor Test Loss:0.743030975262324                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 7 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 7 Workers Selected : [133, 1254, 1016, 294, 1554, 626, 129, 421, 349, 1823]
INFO:root:FL Epoch: 7 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 7 Num points on workers: [201 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 7 Training on worker :133
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.659314
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.695117
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 7 Norm Difference for worker 133 is 0.592525
INFO:root:FL Epoch: 7 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1254
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1254 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672263
INFO:root:Worker: 1254 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708007
INFO:root:FL Epoch: 7 Norm Difference for worker 1254 is 0.430365
INFO:root:FL Epoch: 7 Done on worker:1254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1016
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685157
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677568
INFO:root:FL Epoch: 7 Norm Difference for worker 1016 is 0.586352
INFO:root:FL Epoch: 7 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :294
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 294 Train Epoch: 0 [0/201 (0%)]	Loss: 0.713637
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 294 Train Epoch: 1 [0/201 (0%)]	Loss: 0.673295
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 7 Norm Difference for worker 294 is 0.51755
INFO:root:FL Epoch: 7 Done on worker:294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1554
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679752
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631606
INFO:root:FL Epoch: 7 Norm Difference for worker 1554 is 0.613193
INFO:root:FL Epoch: 7 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :626
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658054
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648782
INFO:root:FL Epoch: 7 Norm Difference for worker 626 is 0.470783
INFO:root:FL Epoch: 7 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :129
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 129 Train Epoch: 0 [0/201 (0%)]	Loss: 0.668064
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 129 Train Epoch: 1 [0/201 (0%)]	Loss: 0.720801
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 7 Norm Difference for worker 129 is 0.494063
INFO:root:FL Epoch: 7 Done on worker:129
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :421
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650343
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685247
INFO:root:FL Epoch: 7 Norm Difference for worker 421 is 0.544514
INFO:root:FL Epoch: 7 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :349
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678959
INFO:root:Worker: 349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674855
INFO:root:FL Epoch: 7 Norm Difference for worker 349 is 0.49836
INFO:root:FL Epoch: 7 Done on worker:349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 7 Training on worker :1823
INFO:root:FL Epoch: 7 Using Learning rate : 0.04940299201199041 
INFO:root:FL Epoch: 7 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674082
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669515
INFO:root:FL Epoch: 7 Norm Difference for worker 1823 is 0.457305
INFO:root:FL Epoch: 7 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 129
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 7 Ends   ===================
INFO:root:Epoch:7 Global Model Test Loss:0.6845992593204274 and Test Accuracy:55.0 
INFO:root:Epoch:7 Global Model Backdoor Test Loss:0.6057619651158651                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 8 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 8 Workers Selected : [1491, 829, 387, 923, 162, 1926, 1235, 474, 1585, 270]
INFO:root:FL Epoch: 8 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 8 Num points on workers: [200 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 8 Training on worker :1491
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1491 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711151
INFO:root:Worker: 1491 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649916
INFO:root:FL Epoch: 8 Norm Difference for worker 1491 is 0.496732
INFO:root:FL Epoch: 8 Done on worker:1491
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :829
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708140
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669169
INFO:root:FL Epoch: 8 Norm Difference for worker 829 is 0.590356
INFO:root:FL Epoch: 8 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :387
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 387 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710557
INFO:root:Worker: 387 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615421
INFO:root:FL Epoch: 8 Norm Difference for worker 387 is 0.678799
INFO:root:FL Epoch: 8 Done on worker:387
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :923
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700215
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695126
INFO:root:FL Epoch: 8 Norm Difference for worker 923 is 0.504445
INFO:root:FL Epoch: 8 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :162
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 162 Train Epoch: 0 [0/201 (0%)]	Loss: 0.672642
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 162 Train Epoch: 1 [0/201 (0%)]	Loss: 0.701148
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 8 Norm Difference for worker 162 is 0.48697
INFO:root:FL Epoch: 8 Done on worker:162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1926
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636471
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614123
INFO:root:FL Epoch: 8 Norm Difference for worker 1926 is 0.64234
INFO:root:FL Epoch: 8 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1235
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1235 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646957
INFO:root:Worker: 1235 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670595
INFO:root:FL Epoch: 8 Norm Difference for worker 1235 is 0.629064
INFO:root:FL Epoch: 8 Done on worker:1235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :474
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706656
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686926
INFO:root:FL Epoch: 8 Norm Difference for worker 474 is 0.504277
INFO:root:FL Epoch: 8 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :1585
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737924
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666208
INFO:root:FL Epoch: 8 Norm Difference for worker 1585 is 0.618062
INFO:root:FL Epoch: 8 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 8 Training on worker :270
INFO:root:FL Epoch: 8 Using Learning rate : 0.04930418602796643 
INFO:root:FL Epoch: 8 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.678858
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.671443
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 8 Norm Difference for worker 270 is 0.593042
INFO:root:FL Epoch: 8 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 474
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 8 Ends   ===================
INFO:root:Epoch:8 Global Model Test Loss:0.6763278947157019 and Test Accuracy:56.76470588235294 
INFO:root:Epoch:8 Global Model Backdoor Test Loss:0.7861734529336294                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 9 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 9 Workers Selected : [1241, 255, 1012, 1069, 1613, 633, 757, 656, 26, 342]
INFO:root:FL Epoch: 9 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 9 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 9 Training on worker :1241
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1241 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662751
INFO:root:Worker: 1241 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666862
INFO:root:FL Epoch: 9 Norm Difference for worker 1241 is 0.461566
INFO:root:FL Epoch: 9 Done on worker:1241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :255
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 255 Train Epoch: 0 [0/201 (0%)]	Loss: 0.709900
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 255 Train Epoch: 1 [0/201 (0%)]	Loss: 0.641387
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 255 is 0.516371
INFO:root:FL Epoch: 9 Done on worker:255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :1012
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631705
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662657
INFO:root:FL Epoch: 9 Norm Difference for worker 1012 is 0.525269
INFO:root:FL Epoch: 9 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :1069
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706726
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.723550
INFO:root:FL Epoch: 9 Norm Difference for worker 1069 is 0.548774
INFO:root:FL Epoch: 9 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :1613
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672571
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666181
INFO:root:FL Epoch: 9 Norm Difference for worker 1613 is 0.537465
INFO:root:FL Epoch: 9 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :633
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701924
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680043
INFO:root:FL Epoch: 9 Norm Difference for worker 633 is 0.476103
INFO:root:FL Epoch: 9 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :757
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719564
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667822
INFO:root:FL Epoch: 9 Norm Difference for worker 757 is 0.480098
INFO:root:FL Epoch: 9 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :656
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650350
INFO:root:Worker: 656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689619
INFO:root:FL Epoch: 9 Norm Difference for worker 656 is 0.487723
INFO:root:FL Epoch: 9 Done on worker:656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :26
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 26 Train Epoch: 0 [0/201 (0%)]	Loss: 0.646208
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 26 Train Epoch: 1 [0/201 (0%)]	Loss: 0.663214
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 9 Norm Difference for worker 26 is 0.491555
INFO:root:FL Epoch: 9 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 9 Training on worker :342
INFO:root:FL Epoch: 9 Using Learning rate : 0.04920557765591049 
INFO:root:FL Epoch: 9 Normal Training
INFO:root:Worker: 342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664635
INFO:root:Worker: 342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704288
INFO:root:FL Epoch: 9 Norm Difference for worker 342 is 0.483693
INFO:root:FL Epoch: 9 Done on worker:342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 342
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 9 Ends   ===================
INFO:root:Epoch:9 Global Model Test Loss:0.6707131967825049 and Test Accuracy:60.0 
INFO:root:Epoch:9 Global Model Backdoor Test Loss:0.740004817644755                             and Backdoor Test Accuracy:34.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 10 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 10 Workers Selected : [320, 1389, 1454, 771, 402, 1183, 714, 25, 534, 289]
INFO:root:FL Epoch: 10 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 10 Num points on workers: [201 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 10 Training on worker :320
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.668365
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.610543
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 320 is 0.597565
INFO:root:FL Epoch: 10 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1389
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692398
INFO:root:Worker: 1389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672887
INFO:root:FL Epoch: 10 Norm Difference for worker 1389 is 0.582813
INFO:root:FL Epoch: 10 Done on worker:1389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1454
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663377
INFO:root:Worker: 1454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649196
INFO:root:FL Epoch: 10 Norm Difference for worker 1454 is 0.575451
INFO:root:FL Epoch: 10 Done on worker:1454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :771
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 771 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674906
INFO:root:Worker: 771 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659812
INFO:root:FL Epoch: 10 Norm Difference for worker 771 is 0.567872
INFO:root:FL Epoch: 10 Done on worker:771
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :402
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 402 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682862
INFO:root:Worker: 402 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645416
INFO:root:FL Epoch: 10 Norm Difference for worker 402 is 0.594518
INFO:root:FL Epoch: 10 Done on worker:402
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :1183
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 1183 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660553
INFO:root:Worker: 1183 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667716
INFO:root:FL Epoch: 10 Norm Difference for worker 1183 is 0.601717
INFO:root:FL Epoch: 10 Done on worker:1183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :714
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 714 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719651
INFO:root:Worker: 714 Train Epoch: 1 [0/200 (0%)]	Loss: 0.719518
INFO:root:FL Epoch: 10 Norm Difference for worker 714 is 0.53675
INFO:root:FL Epoch: 10 Done on worker:714
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :25
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.639927
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.666024
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 25 is 0.548212
INFO:root:FL Epoch: 10 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :534
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678415
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670338
INFO:root:FL Epoch: 10 Norm Difference for worker 534 is 0.562953
INFO:root:FL Epoch: 10 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 10 Training on worker :289
INFO:root:FL Epoch: 10 Using Learning rate : 0.049107166500598674 
INFO:root:FL Epoch: 10 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.723367
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.644211
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 10 Norm Difference for worker 289 is 0.537703
INFO:root:FL Epoch: 10 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 289
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 10 Ends   ===================
INFO:root:Epoch:10 Global Model Test Loss:0.6682054680936477 and Test Accuracy:58.529411764705884 
INFO:root:Epoch:10 Global Model Backdoor Test Loss:0.8100231885910034                             and Backdoor Test Accuracy:20.0 
INFO:root:=======================================================
INFO:root:================FL round 11 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 11 Workers Selected : [897, 1516, 1771, 1392, 371, 1021, 1479, 1242, 95, 293]
INFO:root:FL Epoch: 11 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 11 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 11 Training on worker :897
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677632
INFO:root:Worker: 897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712199
INFO:root:FL Epoch: 11 Norm Difference for worker 897 is 0.598732
INFO:root:FL Epoch: 11 Done on worker:897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1516
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666731
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622793
INFO:root:FL Epoch: 11 Norm Difference for worker 1516 is 0.699413
INFO:root:FL Epoch: 11 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1771
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1771 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751801
INFO:root:Worker: 1771 Train Epoch: 1 [0/200 (0%)]	Loss: 0.723804
INFO:root:FL Epoch: 11 Norm Difference for worker 1771 is 0.628153
INFO:root:FL Epoch: 11 Done on worker:1771
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1392
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653414
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654344
INFO:root:FL Epoch: 11 Norm Difference for worker 1392 is 0.658027
INFO:root:FL Epoch: 11 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :371
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632979
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646524
INFO:root:FL Epoch: 11 Norm Difference for worker 371 is 0.625206
INFO:root:FL Epoch: 11 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1021
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671960
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569546
INFO:root:FL Epoch: 11 Norm Difference for worker 1021 is 0.684437
INFO:root:FL Epoch: 11 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1479
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679542
INFO:root:Worker: 1479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557976
INFO:root:FL Epoch: 11 Norm Difference for worker 1479 is 0.750861
INFO:root:FL Epoch: 11 Done on worker:1479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :1242
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643558
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657605
INFO:root:FL Epoch: 11 Norm Difference for worker 1242 is 0.694646
INFO:root:FL Epoch: 11 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :95
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 95 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693892
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 95 Train Epoch: 1 [0/201 (0%)]	Loss: 0.668018
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 11 Norm Difference for worker 95 is 0.673073
INFO:root:FL Epoch: 11 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 11 Training on worker :293
INFO:root:FL Epoch: 11 Using Learning rate : 0.04900895216759747 
INFO:root:FL Epoch: 11 Normal Training
INFO:root:Worker: 293 Train Epoch: 0 [0/201 (0%)]	Loss: 0.681827
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 293 Train Epoch: 1 [0/201 (0%)]	Loss: 0.677950
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 11 Norm Difference for worker 293 is 0.637116
INFO:root:FL Epoch: 11 Done on worker:293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 897
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 11 Ends   ===================
INFO:root:Epoch:11 Global Model Test Loss:0.6719137114637038 and Test Accuracy:60.588235294117645 
INFO:root:Epoch:11 Global Model Backdoor Test Loss:0.8210479517777761                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 12 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 12 Workers Selected : [1404, 1927, 378, 123, 800, 838, 1754, 1772, 687, 1641]
INFO:root:FL Epoch: 12 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 12 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 12 Training on worker :1404
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671942
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597792
INFO:root:FL Epoch: 12 Norm Difference for worker 1404 is 0.766461
INFO:root:FL Epoch: 12 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1927
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656490
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628906
INFO:root:FL Epoch: 12 Norm Difference for worker 1927 is 0.65828
INFO:root:FL Epoch: 12 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :378
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663870
INFO:root:Worker: 378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669462
INFO:root:FL Epoch: 12 Norm Difference for worker 378 is 0.628879
INFO:root:FL Epoch: 12 Done on worker:378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :123
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 123 Train Epoch: 0 [0/201 (0%)]	Loss: 0.656431
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 123 Train Epoch: 1 [0/201 (0%)]	Loss: 0.668006
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 12 Norm Difference for worker 123 is 0.68695
INFO:root:FL Epoch: 12 Done on worker:123
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :800
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685839
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684328
INFO:root:FL Epoch: 12 Norm Difference for worker 800 is 0.751732
INFO:root:FL Epoch: 12 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :838
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680380
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693271
INFO:root:FL Epoch: 12 Norm Difference for worker 838 is 0.685891
INFO:root:FL Epoch: 12 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1754
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596688
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599514
INFO:root:FL Epoch: 12 Norm Difference for worker 1754 is 0.750137
INFO:root:FL Epoch: 12 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1772
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651219
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614115
INFO:root:FL Epoch: 12 Norm Difference for worker 1772 is 0.631573
INFO:root:FL Epoch: 12 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :687
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701503
INFO:root:Worker: 687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630098
INFO:root:FL Epoch: 12 Norm Difference for worker 687 is 0.672358
INFO:root:FL Epoch: 12 Done on worker:687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 12 Training on worker :1641
INFO:root:FL Epoch: 12 Using Learning rate : 0.048910934263262276 
INFO:root:FL Epoch: 12 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640392
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590563
INFO:root:FL Epoch: 12 Norm Difference for worker 1641 is 0.636346
INFO:root:FL Epoch: 12 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1641
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 12 Ends   ===================
INFO:root:Epoch:12 Global Model Test Loss:0.6726871097789091 and Test Accuracy:55.588235294117645 
INFO:root:Epoch:12 Global Model Backdoor Test Loss:0.7252759834130605                             and Backdoor Test Accuracy:45.0 
INFO:root:=======================================================
INFO:root:================FL round 13 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 13 Workers Selected : [1902, 1208, 440, 230, 114, 200, 1579, 604, 1302, 1873]
INFO:root:FL Epoch: 13 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 13 Num points on workers: [200 200 200 201 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 13 Training on worker :1902
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686722
INFO:root:Worker: 1902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645202
INFO:root:FL Epoch: 13 Norm Difference for worker 1902 is 0.722339
INFO:root:FL Epoch: 13 Done on worker:1902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1208
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1208 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680390
INFO:root:Worker: 1208 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587982
INFO:root:FL Epoch: 13 Norm Difference for worker 1208 is 0.754557
INFO:root:FL Epoch: 13 Done on worker:1208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :440
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637242
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652189
INFO:root:FL Epoch: 13 Norm Difference for worker 440 is 0.739878
INFO:root:FL Epoch: 13 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :230
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 230 Train Epoch: 0 [0/201 (0%)]	Loss: 0.657671
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 230 Train Epoch: 1 [0/201 (0%)]	Loss: 0.657982
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 230 is 0.688962
INFO:root:FL Epoch: 13 Done on worker:230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :114
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 114 Train Epoch: 0 [0/201 (0%)]	Loss: 0.633583
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 114 Train Epoch: 1 [0/201 (0%)]	Loss: 0.700112
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 114 is 0.755093
INFO:root:FL Epoch: 13 Done on worker:114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :200
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.708275
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697803
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 13 Norm Difference for worker 200 is 0.798138
INFO:root:FL Epoch: 13 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1579
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596357
INFO:root:Worker: 1579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608341
INFO:root:FL Epoch: 13 Norm Difference for worker 1579 is 0.695241
INFO:root:FL Epoch: 13 Done on worker:1579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :604
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606078
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619737
INFO:root:FL Epoch: 13 Norm Difference for worker 604 is 0.80969
INFO:root:FL Epoch: 13 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1302
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1302 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677368
INFO:root:Worker: 1302 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673337
INFO:root:FL Epoch: 13 Norm Difference for worker 1302 is 0.736704
INFO:root:FL Epoch: 13 Done on worker:1302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 13 Training on worker :1873
INFO:root:FL Epoch: 13 Using Learning rate : 0.04881311239473576 
INFO:root:FL Epoch: 13 Normal Training
INFO:root:Worker: 1873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685032
INFO:root:Worker: 1873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611976
INFO:root:FL Epoch: 13 Norm Difference for worker 1873 is 0.813488
INFO:root:FL Epoch: 13 Done on worker:1873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 230
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 13 Ends   ===================
INFO:root:Epoch:13 Global Model Test Loss:0.6704866079723134 and Test Accuracy:57.64705882352941 
INFO:root:Epoch:13 Global Model Backdoor Test Loss:0.7976543009281158                             and Backdoor Test Accuracy:25.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 14 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 14 Workers Selected : [1162, 1274, 407, 1924, 602, 198, 549, 1399, 1588, 744]
INFO:root:FL Epoch: 14 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 14 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 14 Training on worker :1162
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1162 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677940
INFO:root:Worker: 1162 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615812
INFO:root:FL Epoch: 14 Norm Difference for worker 1162 is 0.809902
INFO:root:FL Epoch: 14 Done on worker:1162
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1274
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654778
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634431
INFO:root:FL Epoch: 14 Norm Difference for worker 1274 is 0.823429
INFO:root:FL Epoch: 14 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :407
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622072
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594373
INFO:root:FL Epoch: 14 Norm Difference for worker 407 is 0.8736
INFO:root:FL Epoch: 14 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1924
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720695
INFO:root:Worker: 1924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579511
INFO:root:FL Epoch: 14 Norm Difference for worker 1924 is 0.905818
INFO:root:FL Epoch: 14 Done on worker:1924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :602
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.730208
INFO:root:Worker: 602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605560
INFO:root:FL Epoch: 14 Norm Difference for worker 602 is 0.841605
INFO:root:FL Epoch: 14 Done on worker:602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :198
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.737050
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.653322
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 14 Norm Difference for worker 198 is 0.920126
INFO:root:FL Epoch: 14 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :549
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649997
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630379
INFO:root:FL Epoch: 14 Norm Difference for worker 549 is 0.816945
INFO:root:FL Epoch: 14 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1399
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722531
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636317
INFO:root:FL Epoch: 14 Norm Difference for worker 1399 is 0.841151
INFO:root:FL Epoch: 14 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :1588
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 1588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633115
INFO:root:Worker: 1588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569951
INFO:root:FL Epoch: 14 Norm Difference for worker 1588 is 0.890999
INFO:root:FL Epoch: 14 Done on worker:1588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 14 Training on worker :744
INFO:root:FL Epoch: 14 Using Learning rate : 0.04871548616994628 
INFO:root:FL Epoch: 14 Normal Training
INFO:root:Worker: 744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697813
INFO:root:Worker: 744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631804
INFO:root:FL Epoch: 14 Norm Difference for worker 744 is 0.879363
INFO:root:FL Epoch: 14 Done on worker:744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 407
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 14 Ends   ===================
INFO:root:Epoch:14 Global Model Test Loss:0.6998817254515255 and Test Accuracy:57.35294117647059 
INFO:root:Epoch:14 Global Model Backdoor Test Loss:1.3343117038408916                             and Backdoor Test Accuracy:3.3333333333333335 
INFO:root:=======================================================
INFO:root:================FL round 15 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 15 Workers Selected : [45, 447, 1156, 1595, 1797, 1888, 892, 546, 921, 350]
INFO:root:FL Epoch: 15 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 15 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 15 Training on worker :45
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.653307
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.610148
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 15 Norm Difference for worker 45 is 1.026634
INFO:root:FL Epoch: 15 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :447
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633978
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649710
INFO:root:FL Epoch: 15 Norm Difference for worker 447 is 1.00034
INFO:root:FL Epoch: 15 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1156
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571511
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529522
INFO:root:FL Epoch: 15 Norm Difference for worker 1156 is 1.032402
INFO:root:FL Epoch: 15 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1595
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681016
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521322
INFO:root:FL Epoch: 15 Norm Difference for worker 1595 is 1.057319
INFO:root:FL Epoch: 15 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1797
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796679
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634393
INFO:root:FL Epoch: 15 Norm Difference for worker 1797 is 1.096189
INFO:root:FL Epoch: 15 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :1888
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 1888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725822
INFO:root:Worker: 1888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530911
INFO:root:FL Epoch: 15 Norm Difference for worker 1888 is 0.947692
INFO:root:FL Epoch: 15 Done on worker:1888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :892
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772510
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.713690
INFO:root:FL Epoch: 15 Norm Difference for worker 892 is 0.966548
INFO:root:FL Epoch: 15 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :546
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808317
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663428
INFO:root:FL Epoch: 15 Norm Difference for worker 546 is 1.052759
INFO:root:FL Epoch: 15 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :921
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754232
INFO:root:Worker: 921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600910
INFO:root:FL Epoch: 15 Norm Difference for worker 921 is 1.00998
INFO:root:FL Epoch: 15 Done on worker:921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 15 Training on worker :350
INFO:root:FL Epoch: 15 Using Learning rate : 0.04861805519760639 
INFO:root:FL Epoch: 15 Normal Training
INFO:root:Worker: 350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794829
INFO:root:Worker: 350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596585
INFO:root:FL Epoch: 15 Norm Difference for worker 350 is 0.967375
INFO:root:FL Epoch: 15 Done on worker:350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1156
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 15 Ends   ===================
INFO:root:Epoch:15 Global Model Test Loss:0.6988154544549829 and Test Accuracy:52.05882352941177 
INFO:root:Epoch:15 Global Model Backdoor Test Loss:1.02682563662529                             and Backdoor Test Accuracy:17.5 
INFO:root:=======================================================
INFO:root:================FL round 16 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 16 Workers Selected : [637, 325, 501, 1108, 837, 470, 272, 479, 803, 1605]
INFO:root:FL Epoch: 16 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 16 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 16 Training on worker :637
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492239
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638770
INFO:root:FL Epoch: 16 Norm Difference for worker 637 is 1.09813
INFO:root:FL Epoch: 16 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :325
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.591060
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.518226
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 16 Norm Difference for worker 325 is 1.158363
INFO:root:FL Epoch: 16 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :501
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661383
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634180
INFO:root:FL Epoch: 16 Norm Difference for worker 501 is 1.168498
INFO:root:FL Epoch: 16 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :1108
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640356
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618618
INFO:root:FL Epoch: 16 Norm Difference for worker 1108 is 1.145948
INFO:root:FL Epoch: 16 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :837
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567844
INFO:root:Worker: 837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588315
INFO:root:FL Epoch: 16 Norm Difference for worker 837 is 1.217614
INFO:root:FL Epoch: 16 Done on worker:837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :470
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692161
INFO:root:Worker: 470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583198
INFO:root:FL Epoch: 16 Norm Difference for worker 470 is 1.112385
INFO:root:FL Epoch: 16 Done on worker:470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :272
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.625149
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.615241
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 16 Norm Difference for worker 272 is 1.038993
INFO:root:FL Epoch: 16 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :479
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683212
INFO:root:Worker: 479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658787
INFO:root:FL Epoch: 16 Norm Difference for worker 479 is 1.092606
INFO:root:FL Epoch: 16 Done on worker:479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :803
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669585
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671719
INFO:root:FL Epoch: 16 Norm Difference for worker 803 is 1.168002
INFO:root:FL Epoch: 16 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 16 Training on worker :1605
INFO:root:FL Epoch: 16 Using Learning rate : 0.048520819087211176 
INFO:root:FL Epoch: 16 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568547
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643678
INFO:root:FL Epoch: 16 Norm Difference for worker 1605 is 1.113759
INFO:root:FL Epoch: 16 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 272
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 16 Ends   ===================
INFO:root:Epoch:16 Global Model Test Loss:0.68178110964158 and Test Accuracy:58.8235294117647 
INFO:root:Epoch:16 Global Model Backdoor Test Loss:1.1368918617566426                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 17 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 17 Workers Selected : [945, 1614, 175, 624, 1869, 206, 764, 212, 1274, 1148]
INFO:root:FL Epoch: 17 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 17 Num points on workers: [200 200 201 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 17 Training on worker :945
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716685
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488955
INFO:root:FL Epoch: 17 Norm Difference for worker 945 is 1.101717
INFO:root:FL Epoch: 17 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1614
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615965
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563452
INFO:root:FL Epoch: 17 Norm Difference for worker 1614 is 1.091408
INFO:root:FL Epoch: 17 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :175
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 175 Train Epoch: 0 [0/201 (0%)]	Loss: 0.656091
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 175 Train Epoch: 1 [0/201 (0%)]	Loss: 0.449852
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 175 is 1.190746
INFO:root:FL Epoch: 17 Done on worker:175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :624
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591441
INFO:root:Worker: 624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636493
INFO:root:FL Epoch: 17 Norm Difference for worker 624 is 1.121548
INFO:root:FL Epoch: 17 Done on worker:624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1869
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595143
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592034
INFO:root:FL Epoch: 17 Norm Difference for worker 1869 is 1.174478
INFO:root:FL Epoch: 17 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :206
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.655345
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.564346
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 206 is 1.139373
INFO:root:FL Epoch: 17 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :764
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611141
INFO:root:Worker: 764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701008
INFO:root:FL Epoch: 17 Norm Difference for worker 764 is 1.111677
INFO:root:FL Epoch: 17 Done on worker:764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :212
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.803215
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.578138
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 17 Norm Difference for worker 212 is 1.123011
INFO:root:FL Epoch: 17 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1274
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756994
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508844
INFO:root:FL Epoch: 17 Norm Difference for worker 1274 is 1.104117
INFO:root:FL Epoch: 17 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 17 Training on worker :1148
INFO:root:FL Epoch: 17 Using Learning rate : 0.04842377744903675 
INFO:root:FL Epoch: 17 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616658
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659731
INFO:root:FL Epoch: 17 Norm Difference for worker 1148 is 1.119778
INFO:root:FL Epoch: 17 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 945
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 17 Ends   ===================
INFO:root:Epoch:17 Global Model Test Loss:0.6869141880203696 and Test Accuracy:59.11764705882353 
INFO:root:Epoch:17 Global Model Backdoor Test Loss:1.2077857454617817                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 18 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 18 Workers Selected : [506, 101, 40, 1474, 1851, 588, 1914, 1565, 478, 1809]
INFO:root:FL Epoch: 18 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 18 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 18 Training on worker :506
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518799
INFO:root:Worker: 506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.728305
INFO:root:FL Epoch: 18 Norm Difference for worker 506 is 1.312562
INFO:root:FL Epoch: 18 Done on worker:506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :101
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.647057
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.630753
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 18 Norm Difference for worker 101 is 1.349353
INFO:root:FL Epoch: 18 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :40
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 40 Train Epoch: 0 [0/201 (0%)]	Loss: 0.662227
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 40 Train Epoch: 1 [0/201 (0%)]	Loss: 0.576199
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 18 Norm Difference for worker 40 is 1.263682
INFO:root:FL Epoch: 18 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1474
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663678
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435316
INFO:root:FL Epoch: 18 Norm Difference for worker 1474 is 1.259095
INFO:root:FL Epoch: 18 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1851
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556966
INFO:root:Worker: 1851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550792
INFO:root:FL Epoch: 18 Norm Difference for worker 1851 is 1.277118
INFO:root:FL Epoch: 18 Done on worker:1851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :588
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611225
INFO:root:Worker: 588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665715
INFO:root:FL Epoch: 18 Norm Difference for worker 588 is 1.312631
INFO:root:FL Epoch: 18 Done on worker:588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1914
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724849
INFO:root:Worker: 1914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462985
INFO:root:FL Epoch: 18 Norm Difference for worker 1914 is 1.352187
INFO:root:FL Epoch: 18 Done on worker:1914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1565
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706580
INFO:root:Worker: 1565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550457
INFO:root:FL Epoch: 18 Norm Difference for worker 1565 is 1.322691
INFO:root:FL Epoch: 18 Done on worker:1565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :478
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563038
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704412
INFO:root:FL Epoch: 18 Norm Difference for worker 478 is 1.301789
INFO:root:FL Epoch: 18 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 18 Training on worker :1809
INFO:root:FL Epoch: 18 Using Learning rate : 0.04832692989413868 
INFO:root:FL Epoch: 18 Normal Training
INFO:root:Worker: 1809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794257
INFO:root:Worker: 1809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537521
INFO:root:FL Epoch: 18 Norm Difference for worker 1809 is 1.284581
INFO:root:FL Epoch: 18 Done on worker:1809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1809
INFO:root:Norm of Aggregated Model: 5154.98388671875
INFO:root:Aggregating After Defense
INFO:root:================FL round 18 Ends   ===================
INFO:root:Epoch:18 Global Model Test Loss:0.6582467538468978 and Test Accuracy:60.294117647058826 
INFO:root:Epoch:18 Global Model Backdoor Test Loss:1.1689762473106384                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 19 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 19 Workers Selected : [17, 321, 1662, 813, 1791, 1781, 1404, 1091, 1077, 1197]
INFO:root:FL Epoch: 19 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 19 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 19 Training on worker :17
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 17 Train Epoch: 0 [0/201 (0%)]	Loss: 0.601071
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 17 Train Epoch: 1 [0/201 (0%)]	Loss: 0.669233
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 17 is 1.232167
INFO:root:FL Epoch: 19 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :321
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.803309
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.724349
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 19 Norm Difference for worker 321 is 1.173137
INFO:root:FL Epoch: 19 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1662
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482669
INFO:root:Worker: 1662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580213
INFO:root:FL Epoch: 19 Norm Difference for worker 1662 is 1.112804
INFO:root:FL Epoch: 19 Done on worker:1662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :813
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589743
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641567
INFO:root:FL Epoch: 19 Norm Difference for worker 813 is 1.148392
INFO:root:FL Epoch: 19 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1791
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.818920
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621850
INFO:root:FL Epoch: 19 Norm Difference for worker 1791 is 1.15174
INFO:root:FL Epoch: 19 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1781
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658205
INFO:root:Worker: 1781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501497
INFO:root:FL Epoch: 19 Norm Difference for worker 1781 is 1.178345
INFO:root:FL Epoch: 19 Done on worker:1781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1404
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576222
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612663
INFO:root:FL Epoch: 19 Norm Difference for worker 1404 is 1.097948
INFO:root:FL Epoch: 19 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1091
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1091 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699778
INFO:root:Worker: 1091 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525933
INFO:root:FL Epoch: 19 Norm Difference for worker 1091 is 1.037611
INFO:root:FL Epoch: 19 Done on worker:1091
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1077
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1077 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650781
INFO:root:Worker: 1077 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654781
INFO:root:FL Epoch: 19 Norm Difference for worker 1077 is 1.189651
INFO:root:FL Epoch: 19 Done on worker:1077
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 19 Training on worker :1197
INFO:root:FL Epoch: 19 Using Learning rate : 0.0482302760343504 
INFO:root:FL Epoch: 19 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515537
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552535
INFO:root:FL Epoch: 19 Norm Difference for worker 1197 is 1.120344
INFO:root:FL Epoch: 19 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1091
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 19 Ends   ===================
INFO:root:Epoch:19 Global Model Test Loss:0.6630607142167932 and Test Accuracy:58.8235294117647 
INFO:root:Epoch:19 Global Model Backdoor Test Loss:1.0556546052296956                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 20 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 20 Workers Selected : [1500, 553, 1506, 437, 1362, 1482, 1583, 858, 1282, 333]
INFO:root:FL Epoch: 20 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 20 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 20 Training on worker :1500
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646690
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699773
INFO:root:FL Epoch: 20 Norm Difference for worker 1500 is 1.100562
INFO:root:FL Epoch: 20 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :553
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633739
INFO:root:Worker: 553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613016
INFO:root:FL Epoch: 20 Norm Difference for worker 553 is 1.102366
INFO:root:FL Epoch: 20 Done on worker:553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1506
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738802
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606678
INFO:root:FL Epoch: 20 Norm Difference for worker 1506 is 1.112451
INFO:root:FL Epoch: 20 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :437
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741891
INFO:root:Worker: 437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601944
INFO:root:FL Epoch: 20 Norm Difference for worker 437 is 1.092684
INFO:root:FL Epoch: 20 Done on worker:437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1362
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749700
INFO:root:Worker: 1362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617589
INFO:root:FL Epoch: 20 Norm Difference for worker 1362 is 1.065123
INFO:root:FL Epoch: 20 Done on worker:1362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1482
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596108
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561194
INFO:root:FL Epoch: 20 Norm Difference for worker 1482 is 1.076872
INFO:root:FL Epoch: 20 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1583
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770408
INFO:root:Worker: 1583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693762
INFO:root:FL Epoch: 20 Norm Difference for worker 1583 is 1.089859
INFO:root:FL Epoch: 20 Done on worker:1583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :858
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615039
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561507
INFO:root:FL Epoch: 20 Norm Difference for worker 858 is 1.099634
INFO:root:FL Epoch: 20 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :1282
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 1282 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699880
INFO:root:Worker: 1282 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536877
INFO:root:FL Epoch: 20 Norm Difference for worker 1282 is 1.135699
INFO:root:FL Epoch: 20 Done on worker:1282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 20 Training on worker :333
INFO:root:FL Epoch: 20 Using Learning rate : 0.048133815482281704 
INFO:root:FL Epoch: 20 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.790380
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.617614
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 20 Norm Difference for worker 333 is 1.089023
INFO:root:FL Epoch: 20 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 437
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 20 Ends   ===================
INFO:root:Epoch:20 Global Model Test Loss:0.6734892620759851 and Test Accuracy:59.411764705882355 
INFO:root:Epoch:20 Global Model Backdoor Test Loss:1.0550895134607952                             and Backdoor Test Accuracy:21.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 21 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 21 Workers Selected : [1105, 510, 149, 375, 917, 72, 1368, 1094, 986, 1252]
INFO:root:FL Epoch: 21 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 21 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 21 Training on worker :1105
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1105 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425889
INFO:root:Worker: 1105 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565566
INFO:root:FL Epoch: 21 Norm Difference for worker 1105 is 1.216561
INFO:root:FL Epoch: 21 Done on worker:1105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :510
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554092
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658112
INFO:root:FL Epoch: 21 Norm Difference for worker 510 is 1.153329
INFO:root:FL Epoch: 21 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :149
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 149 Train Epoch: 0 [0/201 (0%)]	Loss: 0.637877
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 149 Train Epoch: 1 [0/201 (0%)]	Loss: 0.579541
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 21 Norm Difference for worker 149 is 1.206697
INFO:root:FL Epoch: 21 Done on worker:149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :375
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685135
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660988
INFO:root:FL Epoch: 21 Norm Difference for worker 375 is 1.179329
INFO:root:FL Epoch: 21 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :917
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603752
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513682
INFO:root:FL Epoch: 21 Norm Difference for worker 917 is 1.200159
INFO:root:FL Epoch: 21 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :72
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.697152
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.433066
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 21 Norm Difference for worker 72 is 1.218478
INFO:root:FL Epoch: 21 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1368
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705437
INFO:root:Worker: 1368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515782
INFO:root:FL Epoch: 21 Norm Difference for worker 1368 is 1.132995
INFO:root:FL Epoch: 21 Done on worker:1368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1094
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1094 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579924
INFO:root:Worker: 1094 Train Epoch: 1 [0/200 (0%)]	Loss: 0.831385
INFO:root:FL Epoch: 21 Norm Difference for worker 1094 is 1.158562
INFO:root:FL Epoch: 21 Done on worker:1094
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :986
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698543
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606855
INFO:root:FL Epoch: 21 Norm Difference for worker 986 is 1.258886
INFO:root:FL Epoch: 21 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 21 Training on worker :1252
INFO:root:FL Epoch: 21 Using Learning rate : 0.04803754785131714 
INFO:root:FL Epoch: 21 Normal Training
INFO:root:Worker: 1252 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713642
INFO:root:Worker: 1252 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475988
INFO:root:FL Epoch: 21 Norm Difference for worker 1252 is 1.222806
INFO:root:FL Epoch: 21 Done on worker:1252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1368
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 21 Ends   ===================
INFO:root:Epoch:21 Global Model Test Loss:0.6651132457396564 and Test Accuracy:61.470588235294116 
INFO:root:Epoch:21 Global Model Backdoor Test Loss:1.038204550743103                             and Backdoor Test Accuracy:17.5 
INFO:root:=======================================================
INFO:root:================FL round 22 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 22 Workers Selected : [31, 1403, 1071, 168, 46, 35, 710, 110, 61, 690]
INFO:root:FL Epoch: 22 Fraction of points on each worker in this round: [0.1001994 0.0997009 0.0997009 0.1001994 0.1001994 0.1001994 0.0997009
 0.1001994 0.1001994 0.0997009]
INFO:root:FL Epoch: 22 Num points on workers: [201 200 200 201 201 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 22 Training on worker :31
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 31 Train Epoch: 0 [0/201 (0%)]	Loss: 0.734244
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 31 Train Epoch: 1 [0/201 (0%)]	Loss: 0.518204
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 31 is 1.146361
INFO:root:FL Epoch: 22 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1403
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514729
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.779547
INFO:root:FL Epoch: 22 Norm Difference for worker 1403 is 1.183113
INFO:root:FL Epoch: 22 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :1071
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 1071 Train Epoch: 0 [0/200 (0%)]	Loss: 0.814933
INFO:root:Worker: 1071 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611764
INFO:root:FL Epoch: 22 Norm Difference for worker 1071 is 1.172444
INFO:root:FL Epoch: 22 Done on worker:1071
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :168
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 168 Train Epoch: 0 [0/201 (0%)]	Loss: 0.571952
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 168 Train Epoch: 1 [0/201 (0%)]	Loss: 0.641873
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 168 is 1.231277
INFO:root:FL Epoch: 22 Done on worker:168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :46
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.545230
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538632
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 46 is 1.161974
INFO:root:FL Epoch: 22 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :35
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 35 Train Epoch: 0 [0/201 (0%)]	Loss: 0.678719
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 35 Train Epoch: 1 [0/201 (0%)]	Loss: 0.593731
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 35 is 1.187359
INFO:root:FL Epoch: 22 Done on worker:35
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :710
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.816998
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573991
INFO:root:FL Epoch: 22 Norm Difference for worker 710 is 1.137657
INFO:root:FL Epoch: 22 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :110
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 110 Train Epoch: 0 [0/201 (0%)]	Loss: 0.804764
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 110 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419036
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 110 is 1.204944
INFO:root:FL Epoch: 22 Done on worker:110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :61
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 61 Train Epoch: 0 [0/201 (0%)]	Loss: 0.673392
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 61 Train Epoch: 1 [0/201 (0%)]	Loss: 0.597921
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 22 Norm Difference for worker 61 is 1.188755
INFO:root:FL Epoch: 22 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 22 Training on worker :690
INFO:root:FL Epoch: 22 Using Learning rate : 0.0479414727556145 
INFO:root:FL Epoch: 22 Normal Training
INFO:root:Worker: 690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553868
INFO:root:Worker: 690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470860
INFO:root:FL Epoch: 22 Norm Difference for worker 690 is 1.148998
INFO:root:FL Epoch: 22 Done on worker:690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 110
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 22 Ends   ===================
INFO:root:Epoch:22 Global Model Test Loss:0.7061292809598586 and Test Accuracy:54.411764705882355 
INFO:root:Epoch:22 Global Model Backdoor Test Loss:1.2259091138839722                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 23 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 23 Workers Selected : [1050, 1151, 805, 1810, 1401, 1243, 1774, 293, 441, 1596]
INFO:root:FL Epoch: 23 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 23 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 23 Training on worker :1050
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1050 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631793
INFO:root:Worker: 1050 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646671
INFO:root:FL Epoch: 23 Norm Difference for worker 1050 is 1.00361
INFO:root:FL Epoch: 23 Done on worker:1050
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1151
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1151 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716501
INFO:root:Worker: 1151 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511945
INFO:root:FL Epoch: 23 Norm Difference for worker 1151 is 1.133224
INFO:root:FL Epoch: 23 Done on worker:1151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :805
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.867749
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634730
INFO:root:FL Epoch: 23 Norm Difference for worker 805 is 1.045415
INFO:root:FL Epoch: 23 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1810
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666264
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577010
INFO:root:FL Epoch: 23 Norm Difference for worker 1810 is 1.129441
INFO:root:FL Epoch: 23 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1401
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633805
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662529
INFO:root:FL Epoch: 23 Norm Difference for worker 1401 is 1.054562
INFO:root:FL Epoch: 23 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1243
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742216
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542319
INFO:root:FL Epoch: 23 Norm Difference for worker 1243 is 0.979432
INFO:root:FL Epoch: 23 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1774
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.777198
INFO:root:Worker: 1774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573130
INFO:root:FL Epoch: 23 Norm Difference for worker 1774 is 1.018004
INFO:root:FL Epoch: 23 Done on worker:1774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :293
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 293 Train Epoch: 0 [0/201 (0%)]	Loss: 0.753446
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 293 Train Epoch: 1 [0/201 (0%)]	Loss: 0.591068
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 23 Norm Difference for worker 293 is 1.153535
INFO:root:FL Epoch: 23 Done on worker:293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :441
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528746
INFO:root:Worker: 441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665739
INFO:root:FL Epoch: 23 Norm Difference for worker 441 is 1.035757
INFO:root:FL Epoch: 23 Done on worker:441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 23 Training on worker :1596
INFO:root:FL Epoch: 23 Using Learning rate : 0.04784558981010328 
INFO:root:FL Epoch: 23 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801747
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617974
INFO:root:FL Epoch: 23 Norm Difference for worker 1596 is 1.052021
INFO:root:FL Epoch: 23 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1774
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 23 Ends   ===================
INFO:root:Epoch:23 Global Model Test Loss:0.6566479732008541 and Test Accuracy:60.88235294117647 
INFO:root:Epoch:23 Global Model Backdoor Test Loss:1.1587581237157185                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 24 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 24 Workers Selected : [743, 1858, 866, 1917, 103, 104, 5, 887, 1903, 694]
INFO:root:FL Epoch: 24 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 24 Num points on workers: [200 200 200 200 201 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 24 Training on worker :743
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715041
INFO:root:Worker: 743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.657932
INFO:root:FL Epoch: 24 Norm Difference for worker 743 is 1.028236
INFO:root:FL Epoch: 24 Done on worker:743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1858
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.809179
INFO:root:Worker: 1858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507871
INFO:root:FL Epoch: 24 Norm Difference for worker 1858 is 1.044444
INFO:root:FL Epoch: 24 Done on worker:1858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :866
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659880
INFO:root:Worker: 866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573349
INFO:root:FL Epoch: 24 Norm Difference for worker 866 is 1.047595
INFO:root:FL Epoch: 24 Done on worker:866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1917
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542063
INFO:root:Worker: 1917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554824
INFO:root:FL Epoch: 24 Norm Difference for worker 1917 is 0.985833
INFO:root:FL Epoch: 24 Done on worker:1917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :103
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.646874
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.705388
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 103 is 1.051575
INFO:root:FL Epoch: 24 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :104
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576052
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.528151
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 104 is 1.006737
INFO:root:FL Epoch: 24 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :5
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 5 Train Epoch: 0 [0/201 (0%)]	Loss: 0.651762
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 5 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538108
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 24 Norm Difference for worker 5 is 0.998049
INFO:root:FL Epoch: 24 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :887
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604858
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667932
INFO:root:FL Epoch: 24 Norm Difference for worker 887 is 1.056084
INFO:root:FL Epoch: 24 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :1903
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 1903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659292
INFO:root:Worker: 1903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655136
INFO:root:FL Epoch: 24 Norm Difference for worker 1903 is 1.037391
INFO:root:FL Epoch: 24 Done on worker:1903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 24 Training on worker :694
INFO:root:FL Epoch: 24 Using Learning rate : 0.04774989863048307 
INFO:root:FL Epoch: 24 Normal Training
INFO:root:Worker: 694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598110
INFO:root:Worker: 694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495075
INFO:root:FL Epoch: 24 Norm Difference for worker 694 is 0.964512
INFO:root:FL Epoch: 24 Done on worker:694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 694
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 24 Ends   ===================
INFO:root:Epoch:24 Global Model Test Loss:0.6595098639235777 and Test Accuracy:59.411764705882355 
INFO:root:Epoch:24 Global Model Backdoor Test Loss:1.148825466632843                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 25 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 25 Workers Selected : [260, 1328, 1562, 1008, 1420, 1108, 1751, 1218, 692, 333]
INFO:root:FL Epoch: 25 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 25 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 25 Training on worker :260
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.622385
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.766399
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 260 is 1.069786
INFO:root:FL Epoch: 25 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1328
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1328 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563917
INFO:root:Worker: 1328 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614075
INFO:root:FL Epoch: 25 Norm Difference for worker 1328 is 1.1024
INFO:root:FL Epoch: 25 Done on worker:1328
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1562
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551751
INFO:root:Worker: 1562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555132
INFO:root:FL Epoch: 25 Norm Difference for worker 1562 is 1.107065
INFO:root:FL Epoch: 25 Done on worker:1562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1008
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1008 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588832
INFO:root:Worker: 1008 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622018
INFO:root:FL Epoch: 25 Norm Difference for worker 1008 is 1.098017
INFO:root:FL Epoch: 25 Done on worker:1008
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1420
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676619
INFO:root:Worker: 1420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512575
INFO:root:FL Epoch: 25 Norm Difference for worker 1420 is 1.137506
INFO:root:FL Epoch: 25 Done on worker:1420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1108
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.874990
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563750
INFO:root:FL Epoch: 25 Norm Difference for worker 1108 is 1.141032
INFO:root:FL Epoch: 25 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1751
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709944
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501883
INFO:root:FL Epoch: 25 Norm Difference for worker 1751 is 1.096608
INFO:root:FL Epoch: 25 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :1218
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805568
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571571
INFO:root:FL Epoch: 25 Norm Difference for worker 1218 is 1.165796
INFO:root:FL Epoch: 25 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :692
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542540
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508133
INFO:root:FL Epoch: 25 Norm Difference for worker 692 is 1.069152
INFO:root:FL Epoch: 25 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 25 Training on worker :333
INFO:root:FL Epoch: 25 Using Learning rate : 0.0476543988332221 
INFO:root:FL Epoch: 25 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.529007
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.603106
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 25 Norm Difference for worker 333 is 1.055342
INFO:root:FL Epoch: 25 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 260
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 25 Ends   ===================
INFO:root:Epoch:25 Global Model Test Loss:0.6603223997003892 and Test Accuracy:60.0 
INFO:root:Epoch:25 Global Model Backdoor Test Loss:1.233063797156016                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 26 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 26 Workers Selected : [439, 246, 362, 1679, 1362, 170, 1657, 1614, 1917, 1320]
INFO:root:FL Epoch: 26 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 26 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 26 Training on worker :439
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616645
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464681
INFO:root:FL Epoch: 26 Norm Difference for worker 439 is 1.111823
INFO:root:FL Epoch: 26 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :246
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.575881
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.678677
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 26 Norm Difference for worker 246 is 1.073833
INFO:root:FL Epoch: 26 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :362
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709982
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669509
INFO:root:FL Epoch: 26 Norm Difference for worker 362 is 1.152486
INFO:root:FL Epoch: 26 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1679
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608180
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689561
INFO:root:FL Epoch: 26 Norm Difference for worker 1679 is 1.117771
INFO:root:FL Epoch: 26 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1362
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698358
INFO:root:Worker: 1362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565446
INFO:root:FL Epoch: 26 Norm Difference for worker 1362 is 1.015662
INFO:root:FL Epoch: 26 Done on worker:1362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :170
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.708264
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.568707
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 26 Norm Difference for worker 170 is 1.141167
INFO:root:FL Epoch: 26 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1657
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444434
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620855
INFO:root:FL Epoch: 26 Norm Difference for worker 1657 is 1.145631
INFO:root:FL Epoch: 26 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1614
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661379
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.803386
INFO:root:FL Epoch: 26 Norm Difference for worker 1614 is 1.148122
INFO:root:FL Epoch: 26 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1917
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773306
INFO:root:Worker: 1917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641618
INFO:root:FL Epoch: 26 Norm Difference for worker 1917 is 1.03932
INFO:root:FL Epoch: 26 Done on worker:1917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 26 Training on worker :1320
INFO:root:FL Epoch: 26 Using Learning rate : 0.04755909003555566 
INFO:root:FL Epoch: 26 Normal Training
INFO:root:Worker: 1320 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597501
INFO:root:Worker: 1320 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591028
INFO:root:FL Epoch: 26 Norm Difference for worker 1320 is 1.098324
INFO:root:FL Epoch: 26 Done on worker:1320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1917
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 26 Ends   ===================
INFO:root:Epoch:26 Global Model Test Loss:0.6684038183268379 and Test Accuracy:60.588235294117645 
INFO:root:Epoch:26 Global Model Backdoor Test Loss:1.0151296854019165                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 27 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 27 Workers Selected : [1075, 267, 1663, 1839, 613, 438, 198, 37, 1913, 121]
INFO:root:FL Epoch: 27 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.0998004 0.1002994
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 27 Num points on workers: [200 201 200 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 27 Training on worker :1075
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698603
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579092
INFO:root:FL Epoch: 27 Norm Difference for worker 1075 is 1.015473
INFO:root:FL Epoch: 27 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :267
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 267 Train Epoch: 0 [0/201 (0%)]	Loss: 0.617958
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 267 Train Epoch: 1 [0/201 (0%)]	Loss: 0.517234
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 267 is 1.031505
INFO:root:FL Epoch: 27 Done on worker:267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1663
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684851
INFO:root:Worker: 1663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678955
INFO:root:FL Epoch: 27 Norm Difference for worker 1663 is 1.00035
INFO:root:FL Epoch: 27 Done on worker:1663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1839
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638237
INFO:root:Worker: 1839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619994
INFO:root:FL Epoch: 27 Norm Difference for worker 1839 is 1.019205
INFO:root:FL Epoch: 27 Done on worker:1839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :613
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603326
INFO:root:Worker: 613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575007
INFO:root:FL Epoch: 27 Norm Difference for worker 613 is 1.067471
INFO:root:FL Epoch: 27 Done on worker:613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :438
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754012
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622332
INFO:root:FL Epoch: 27 Norm Difference for worker 438 is 0.997124
INFO:root:FL Epoch: 27 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :198
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.679290
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.547835
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 198 is 1.088866
INFO:root:FL Epoch: 27 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :37
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 37 Train Epoch: 0 [0/201 (0%)]	Loss: 0.509733
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 37 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697605
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 37 is 1.040229
INFO:root:FL Epoch: 27 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :1913
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574691
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556712
INFO:root:FL Epoch: 27 Norm Difference for worker 1913 is 0.995644
INFO:root:FL Epoch: 27 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 27 Training on worker :121
INFO:root:FL Epoch: 27 Using Learning rate : 0.047463971855484545 
INFO:root:FL Epoch: 27 Normal Training
INFO:root:Worker: 121 Train Epoch: 0 [0/201 (0%)]	Loss: 0.660905
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 121 Train Epoch: 1 [0/201 (0%)]	Loss: 0.610238
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 27 Norm Difference for worker 121 is 1.050686
INFO:root:FL Epoch: 27 Done on worker:121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1663
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 27 Ends   ===================
INFO:root:Epoch:27 Global Model Test Loss:0.6693436959210564 and Test Accuracy:62.05882352941177 
INFO:root:Epoch:27 Global Model Backdoor Test Loss:1.0431442856788635                             and Backdoor Test Accuracy:20.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 28 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 28 Workers Selected : [1561, 1937, 1529, 127, 1679, 80, 524, 312, 421, 966]
INFO:root:FL Epoch: 28 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 28 Num points on workers: [200 200 200 201 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 28 Training on worker :1561
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639123
INFO:root:Worker: 1561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577767
INFO:root:FL Epoch: 28 Norm Difference for worker 1561 is 1.059877
INFO:root:FL Epoch: 28 Done on worker:1561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1937
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703843
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533650
INFO:root:FL Epoch: 28 Norm Difference for worker 1937 is 1.03975
INFO:root:FL Epoch: 28 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1529
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620894
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.709349
INFO:root:FL Epoch: 28 Norm Difference for worker 1529 is 1.021388
INFO:root:FL Epoch: 28 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :127
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 127 Train Epoch: 0 [0/201 (0%)]	Loss: 0.612309
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 127 Train Epoch: 1 [0/201 (0%)]	Loss: 0.532446
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 28 Norm Difference for worker 127 is 0.964327
INFO:root:FL Epoch: 28 Done on worker:127
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :1679
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649354
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662688
INFO:root:FL Epoch: 28 Norm Difference for worker 1679 is 0.999411
INFO:root:FL Epoch: 28 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :80
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581100
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.701432
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 28 Norm Difference for worker 80 is 1.044993
INFO:root:FL Epoch: 28 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :524
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668355
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593685
INFO:root:FL Epoch: 28 Norm Difference for worker 524 is 0.978527
INFO:root:FL Epoch: 28 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :312
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691610
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.568548
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 28 Norm Difference for worker 312 is 1.03045
INFO:root:FL Epoch: 28 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :421
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781642
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677441
INFO:root:FL Epoch: 28 Norm Difference for worker 421 is 1.008608
INFO:root:FL Epoch: 28 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 28 Training on worker :966
INFO:root:FL Epoch: 28 Using Learning rate : 0.04736904391177357 
INFO:root:FL Epoch: 28 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685376
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518666
INFO:root:FL Epoch: 28 Norm Difference for worker 966 is 1.049553
INFO:root:FL Epoch: 28 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 127
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 28 Ends   ===================
INFO:root:Epoch:28 Global Model Test Loss:0.6645120995886186 and Test Accuracy:61.1764705882353 
INFO:root:Epoch:28 Global Model Backdoor Test Loss:1.2016696333885193                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 29 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 29 Workers Selected : [1448, 333, 1222, 1427, 1658, 1546, 945, 1651, 1045, 1865]
INFO:root:FL Epoch: 29 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 29 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 29 Training on worker :1448
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691460
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696225
INFO:root:FL Epoch: 29 Norm Difference for worker 1448 is 0.95024
INFO:root:FL Epoch: 29 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :333
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.792155
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.618303
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 29 Norm Difference for worker 333 is 0.961236
INFO:root:FL Epoch: 29 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1222
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1222 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647126
INFO:root:Worker: 1222 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624004
INFO:root:FL Epoch: 29 Norm Difference for worker 1222 is 1.003136
INFO:root:FL Epoch: 29 Done on worker:1222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1427
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660167
INFO:root:Worker: 1427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.664527
INFO:root:FL Epoch: 29 Norm Difference for worker 1427 is 0.988624
INFO:root:FL Epoch: 29 Done on worker:1427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1658
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586575
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632552
INFO:root:FL Epoch: 29 Norm Difference for worker 1658 is 0.98003
INFO:root:FL Epoch: 29 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1546
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678299
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.760438
INFO:root:FL Epoch: 29 Norm Difference for worker 1546 is 0.965881
INFO:root:FL Epoch: 29 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :945
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685763
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511354
INFO:root:FL Epoch: 29 Norm Difference for worker 945 is 0.989445
INFO:root:FL Epoch: 29 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1651
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705456
INFO:root:Worker: 1651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535400
INFO:root:FL Epoch: 29 Norm Difference for worker 1651 is 1.023639
INFO:root:FL Epoch: 29 Done on worker:1651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1045
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637452
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542192
INFO:root:FL Epoch: 29 Norm Difference for worker 1045 is 1.021027
INFO:root:FL Epoch: 29 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 29 Training on worker :1865
INFO:root:FL Epoch: 29 Using Learning rate : 0.04727430582395003 
INFO:root:FL Epoch: 29 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574375
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528319
INFO:root:FL Epoch: 29 Norm Difference for worker 1865 is 1.007702
INFO:root:FL Epoch: 29 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1546
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 29 Ends   ===================
INFO:root:Epoch:29 Global Model Test Loss:0.6663744379492367 and Test Accuracy:59.11764705882353 
INFO:root:Epoch:29 Global Model Backdoor Test Loss:0.9220817486445109                             and Backdoor Test Accuracy:23.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 30 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 30 Workers Selected : [381, 268, 1769, 1867, 1392, 25, 1850, 1465, 1408, 1091]
INFO:root:FL Epoch: 30 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 30 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 30 Training on worker :381
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562738
INFO:root:Worker: 381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704661
INFO:root:FL Epoch: 30 Norm Difference for worker 381 is 0.958321
INFO:root:FL Epoch: 30 Done on worker:381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :268
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 268 Train Epoch: 0 [0/201 (0%)]	Loss: 0.723992
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 268 Train Epoch: 1 [0/201 (0%)]	Loss: 0.582171
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 268 is 0.929332
INFO:root:FL Epoch: 30 Done on worker:268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1769
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661549
INFO:root:Worker: 1769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599560
INFO:root:FL Epoch: 30 Norm Difference for worker 1769 is 0.947323
INFO:root:FL Epoch: 30 Done on worker:1769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1867
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568707
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653527
INFO:root:FL Epoch: 30 Norm Difference for worker 1867 is 0.974121
INFO:root:FL Epoch: 30 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1392
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559278
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548021
INFO:root:FL Epoch: 30 Norm Difference for worker 1392 is 0.918009
INFO:root:FL Epoch: 30 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :25
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.771474
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.574611
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 30 Norm Difference for worker 25 is 0.935872
INFO:root:FL Epoch: 30 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1850
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508413
INFO:root:Worker: 1850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448689
INFO:root:FL Epoch: 30 Norm Difference for worker 1850 is 0.998489
INFO:root:FL Epoch: 30 Done on worker:1850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1465
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636225
INFO:root:Worker: 1465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702593
INFO:root:FL Epoch: 30 Norm Difference for worker 1465 is 0.94923
INFO:root:FL Epoch: 30 Done on worker:1465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1408
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582498
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627121
INFO:root:FL Epoch: 30 Norm Difference for worker 1408 is 0.960007
INFO:root:FL Epoch: 30 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 30 Training on worker :1091
INFO:root:FL Epoch: 30 Using Learning rate : 0.04717975721230213 
INFO:root:FL Epoch: 30 Normal Training
INFO:root:Worker: 1091 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535669
INFO:root:Worker: 1091 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416829
INFO:root:FL Epoch: 30 Norm Difference for worker 1091 is 0.955727
INFO:root:FL Epoch: 30 Done on worker:1091
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1392
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 30 Ends   ===================
INFO:root:Epoch:30 Global Model Test Loss:0.662055979756748 and Test Accuracy:61.1764705882353 
INFO:root:Epoch:30 Global Model Backdoor Test Loss:1.1404373248418171                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 31 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 31 Workers Selected : [979, 185, 893, 382, 1260, 917, 835, 745, 146, 1473]
INFO:root:FL Epoch: 31 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 31 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 31 Training on worker :979
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535030
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.766399
INFO:root:FL Epoch: 31 Norm Difference for worker 979 is 1.036378
INFO:root:FL Epoch: 31 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :185
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 185 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691905
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 185 Train Epoch: 1 [0/201 (0%)]	Loss: 0.623036
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 31 Norm Difference for worker 185 is 1.019148
INFO:root:FL Epoch: 31 Done on worker:185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :893
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521923
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584240
INFO:root:FL Epoch: 31 Norm Difference for worker 893 is 1.113913
INFO:root:FL Epoch: 31 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :382
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599971
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696805
INFO:root:FL Epoch: 31 Norm Difference for worker 382 is 1.046984
INFO:root:FL Epoch: 31 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1260
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615977
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595427
INFO:root:FL Epoch: 31 Norm Difference for worker 1260 is 1.081928
INFO:root:FL Epoch: 31 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :917
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616093
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610959
INFO:root:FL Epoch: 31 Norm Difference for worker 917 is 1.044765
INFO:root:FL Epoch: 31 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :835
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640131
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.742947
INFO:root:FL Epoch: 31 Norm Difference for worker 835 is 1.059004
INFO:root:FL Epoch: 31 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :745
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526623
INFO:root:Worker: 745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526525
INFO:root:FL Epoch: 31 Norm Difference for worker 745 is 1.044027
INFO:root:FL Epoch: 31 Done on worker:745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :146
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 146 Train Epoch: 0 [0/201 (0%)]	Loss: 0.701441
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 146 Train Epoch: 1 [0/201 (0%)]	Loss: 0.595045
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 31 Norm Difference for worker 146 is 1.059258
INFO:root:FL Epoch: 31 Done on worker:146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 31 Training on worker :1473
INFO:root:FL Epoch: 31 Using Learning rate : 0.04708539769787753 
INFO:root:FL Epoch: 31 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631535
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462119
INFO:root:FL Epoch: 31 Norm Difference for worker 1473 is 1.035418
INFO:root:FL Epoch: 31 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 979
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 31 Ends   ===================
INFO:root:Epoch:31 Global Model Test Loss:0.6533656996839187 and Test Accuracy:60.588235294117645 
INFO:root:Epoch:31 Global Model Backdoor Test Loss:1.004404713710149                             and Backdoor Test Accuracy:18.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 32 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 32 Workers Selected : [430, 1490, 1654, 950, 795, 661, 372, 1915, 502, 682]
INFO:root:FL Epoch: 32 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 32 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 32 Training on worker :430
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560036
INFO:root:Worker: 430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.744707
INFO:root:FL Epoch: 32 Norm Difference for worker 430 is 1.029891
INFO:root:FL Epoch: 32 Done on worker:430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1490
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657060
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559175
INFO:root:FL Epoch: 32 Norm Difference for worker 1490 is 1.033189
INFO:root:FL Epoch: 32 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1654
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603720
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577389
INFO:root:FL Epoch: 32 Norm Difference for worker 1654 is 0.917997
INFO:root:FL Epoch: 32 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :950
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 950 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485586
INFO:root:Worker: 950 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487123
INFO:root:FL Epoch: 32 Norm Difference for worker 950 is 1.027824
INFO:root:FL Epoch: 32 Done on worker:950
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :795
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677776
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550687
INFO:root:FL Epoch: 32 Norm Difference for worker 795 is 1.031342
INFO:root:FL Epoch: 32 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :661
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635610
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637207
INFO:root:FL Epoch: 32 Norm Difference for worker 661 is 1.002439
INFO:root:FL Epoch: 32 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :372
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 372 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686776
INFO:root:Worker: 372 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590705
INFO:root:FL Epoch: 32 Norm Difference for worker 372 is 1.001614
INFO:root:FL Epoch: 32 Done on worker:372
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :1915
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676955
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467480
INFO:root:FL Epoch: 32 Norm Difference for worker 1915 is 0.925925
INFO:root:FL Epoch: 32 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :502
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688065
INFO:root:Worker: 502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701555
INFO:root:FL Epoch: 32 Norm Difference for worker 502 is 0.966024
INFO:root:FL Epoch: 32 Done on worker:502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 32 Training on worker :682
INFO:root:FL Epoch: 32 Using Learning rate : 0.046991226902481774 
INFO:root:FL Epoch: 32 Normal Training
INFO:root:Worker: 682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614296
INFO:root:Worker: 682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576059
INFO:root:FL Epoch: 32 Norm Difference for worker 682 is 0.979844
INFO:root:FL Epoch: 32 Done on worker:682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1654
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 32 Ends   ===================
INFO:root:Epoch:32 Global Model Test Loss:0.6322335145052742 and Test Accuracy:62.64705882352941 
INFO:root:Epoch:32 Global Model Backdoor Test Loss:1.1458825667699177                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 33 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 33 Workers Selected : [25, 1615, 467, 685, 756, 1670, 1137, 1785, 1287, 1377]
INFO:root:FL Epoch: 33 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 33 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 33 Training on worker :25
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587364
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.637297
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 33 Norm Difference for worker 25 is 1.020601
INFO:root:FL Epoch: 33 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1615
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1615 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489016
INFO:root:Worker: 1615 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504020
INFO:root:FL Epoch: 33 Norm Difference for worker 1615 is 1.002052
INFO:root:FL Epoch: 33 Done on worker:1615
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :467
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650462
INFO:root:Worker: 467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570920
INFO:root:FL Epoch: 33 Norm Difference for worker 467 is 0.968324
INFO:root:FL Epoch: 33 Done on worker:467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :685
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683364
INFO:root:Worker: 685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584822
INFO:root:FL Epoch: 33 Norm Difference for worker 685 is 1.035261
INFO:root:FL Epoch: 33 Done on worker:685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :756
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543079
INFO:root:Worker: 756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675633
INFO:root:FL Epoch: 33 Norm Difference for worker 756 is 1.025362
INFO:root:FL Epoch: 33 Done on worker:756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1670
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741678
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655153
INFO:root:FL Epoch: 33 Norm Difference for worker 1670 is 1.003975
INFO:root:FL Epoch: 33 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1137
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.820110
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.701770
INFO:root:FL Epoch: 33 Norm Difference for worker 1137 is 0.982578
INFO:root:FL Epoch: 33 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1785
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648326
INFO:root:Worker: 1785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442134
INFO:root:FL Epoch: 33 Norm Difference for worker 1785 is 0.976927
INFO:root:FL Epoch: 33 Done on worker:1785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1287
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1287 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620463
INFO:root:Worker: 1287 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626484
INFO:root:FL Epoch: 33 Norm Difference for worker 1287 is 0.987452
INFO:root:FL Epoch: 33 Done on worker:1287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 33 Training on worker :1377
INFO:root:FL Epoch: 33 Using Learning rate : 0.04689724444867681 
INFO:root:FL Epoch: 33 Normal Training
INFO:root:Worker: 1377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576366
INFO:root:Worker: 1377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598126
INFO:root:FL Epoch: 33 Norm Difference for worker 1377 is 1.017766
INFO:root:FL Epoch: 33 Done on worker:1377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 467
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 33 Ends   ===================
INFO:root:Epoch:33 Global Model Test Loss:0.643784843823489 and Test Accuracy:63.529411764705884 
INFO:root:Epoch:33 Global Model Backdoor Test Loss:1.3701194326082866                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 34 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 34 Workers Selected : [1113, 687, 148, 1934, 102, 561, 1239, 104, 1259, 182]
INFO:root:FL Epoch: 34 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 34 Num points on workers: [200 200 201 200 201 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 34 Training on worker :1113
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1113 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588423
INFO:root:Worker: 1113 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570151
INFO:root:FL Epoch: 34 Norm Difference for worker 1113 is 1.117615
INFO:root:FL Epoch: 34 Done on worker:1113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :687
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528595
INFO:root:Worker: 687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555699
INFO:root:FL Epoch: 34 Norm Difference for worker 687 is 1.081209
INFO:root:FL Epoch: 34 Done on worker:687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :148
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 148 Train Epoch: 0 [0/201 (0%)]	Loss: 0.759346
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 148 Train Epoch: 1 [0/201 (0%)]	Loss: 0.616235
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 34 Norm Difference for worker 148 is 1.033999
INFO:root:FL Epoch: 34 Done on worker:148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1934
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526931
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509105
INFO:root:FL Epoch: 34 Norm Difference for worker 1934 is 1.231915
INFO:root:FL Epoch: 34 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :102
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 102 Train Epoch: 0 [0/201 (0%)]	Loss: 0.660934
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 102 Train Epoch: 1 [0/201 (0%)]	Loss: 0.522921
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 34 Norm Difference for worker 102 is 1.102736
INFO:root:FL Epoch: 34 Done on worker:102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :561
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699654
INFO:root:Worker: 561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569476
INFO:root:FL Epoch: 34 Norm Difference for worker 561 is 1.152132
INFO:root:FL Epoch: 34 Done on worker:561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1239
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.799489
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704757
INFO:root:FL Epoch: 34 Norm Difference for worker 1239 is 1.138586
INFO:root:FL Epoch: 34 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :104
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.585796
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.746774
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 34 Norm Difference for worker 104 is 1.136389
INFO:root:FL Epoch: 34 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :1259
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637221
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660769
INFO:root:FL Epoch: 34 Norm Difference for worker 1259 is 1.046149
INFO:root:FL Epoch: 34 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 34 Training on worker :182
INFO:root:FL Epoch: 34 Using Learning rate : 0.046803449959779454 
INFO:root:FL Epoch: 34 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.877062
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.770442
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 34 Norm Difference for worker 182 is 1.116331
INFO:root:FL Epoch: 34 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 148
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 34 Ends   ===================
INFO:root:Epoch:34 Global Model Test Loss:0.6330001389279085 and Test Accuracy:62.35294117647059 
INFO:root:Epoch:34 Global Model Backdoor Test Loss:1.1375374992688496                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 35 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 35 Workers Selected : [1423, 343, 283, 1855, 33, 1681, 485, 1773, 655, 723]
INFO:root:FL Epoch: 35 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 35 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 35 Training on worker :1423
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573389
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563019
INFO:root:FL Epoch: 35 Norm Difference for worker 1423 is 1.05364
INFO:root:FL Epoch: 35 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :343
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.867279
INFO:root:Worker: 343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635164
INFO:root:FL Epoch: 35 Norm Difference for worker 343 is 0.956325
INFO:root:FL Epoch: 35 Done on worker:343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :283
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 283 Train Epoch: 0 [0/201 (0%)]	Loss: 0.658541
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 283 Train Epoch: 1 [0/201 (0%)]	Loss: 0.575717
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 283 is 1.05918
INFO:root:FL Epoch: 35 Done on worker:283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1855
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667378
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577286
INFO:root:FL Epoch: 35 Norm Difference for worker 1855 is 0.959364
INFO:root:FL Epoch: 35 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :33
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.536633
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.618492
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 35 Norm Difference for worker 33 is 0.981279
INFO:root:FL Epoch: 35 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1681
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662615
INFO:root:Worker: 1681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639166
INFO:root:FL Epoch: 35 Norm Difference for worker 1681 is 1.06829
INFO:root:FL Epoch: 35 Done on worker:1681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :485
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616695
INFO:root:Worker: 485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537035
INFO:root:FL Epoch: 35 Norm Difference for worker 485 is 1.006317
INFO:root:FL Epoch: 35 Done on worker:485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :1773
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643376
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642599
INFO:root:FL Epoch: 35 Norm Difference for worker 1773 is 1.035149
INFO:root:FL Epoch: 35 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :655
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663851
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.841216
INFO:root:FL Epoch: 35 Norm Difference for worker 655 is 1.064284
INFO:root:FL Epoch: 35 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 35 Training on worker :723
INFO:root:FL Epoch: 35 Using Learning rate : 0.046709843059859896 
INFO:root:FL Epoch: 35 Normal Training
INFO:root:Worker: 723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648328
INFO:root:Worker: 723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670739
INFO:root:FL Epoch: 35 Norm Difference for worker 723 is 1.039624
INFO:root:FL Epoch: 35 Done on worker:723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 343
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 35 Ends   ===================
INFO:root:Epoch:35 Global Model Test Loss:0.6431962847709656 and Test Accuracy:62.64705882352941 
INFO:root:Epoch:35 Global Model Backdoor Test Loss:1.1502277453740437                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 36 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 36 Workers Selected : [937, 20, 102, 1158, 1765, 1821, 393, 616, 1455, 329]
INFO:root:FL Epoch: 36 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 36 Num points on workers: [200 201 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 36 Training on worker :937
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561458
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.725410
INFO:root:FL Epoch: 36 Norm Difference for worker 937 is 1.070278
INFO:root:FL Epoch: 36 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :20
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.700816
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.559594
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 36 Norm Difference for worker 20 is 0.995236
INFO:root:FL Epoch: 36 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :102
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 102 Train Epoch: 0 [0/201 (0%)]	Loss: 0.504327
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 102 Train Epoch: 1 [0/201 (0%)]	Loss: 0.543019
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 36 Norm Difference for worker 102 is 1.042098
INFO:root:FL Epoch: 36 Done on worker:102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1158
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615889
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473500
INFO:root:FL Epoch: 36 Norm Difference for worker 1158 is 0.996124
INFO:root:FL Epoch: 36 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1765
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642315
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531783
INFO:root:FL Epoch: 36 Norm Difference for worker 1765 is 0.995393
INFO:root:FL Epoch: 36 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1821
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562244
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530450
INFO:root:FL Epoch: 36 Norm Difference for worker 1821 is 0.998927
INFO:root:FL Epoch: 36 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :393
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535269
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577036
INFO:root:FL Epoch: 36 Norm Difference for worker 393 is 1.006018
INFO:root:FL Epoch: 36 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :616
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.842511
INFO:root:Worker: 616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632583
INFO:root:FL Epoch: 36 Norm Difference for worker 616 is 0.958154
INFO:root:FL Epoch: 36 Done on worker:616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :1455
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 1455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639741
INFO:root:Worker: 1455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639280
INFO:root:FL Epoch: 36 Norm Difference for worker 1455 is 1.013096
INFO:root:FL Epoch: 36 Done on worker:1455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 36 Training on worker :329
INFO:root:FL Epoch: 36 Using Learning rate : 0.046616423373740175 
INFO:root:FL Epoch: 36 Normal Training
INFO:root:Worker: 329 Train Epoch: 0 [0/201 (0%)]	Loss: 0.615911
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 329 Train Epoch: 1 [0/201 (0%)]	Loss: 0.655808
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 36 Norm Difference for worker 329 is 0.982667
INFO:root:FL Epoch: 36 Done on worker:329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 329
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 36 Ends   ===================
INFO:root:Epoch:36 Global Model Test Loss:0.6523626955116496 and Test Accuracy:62.64705882352941 
INFO:root:Epoch:36 Global Model Backdoor Test Loss:1.2737103501955669                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 37 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 37 Workers Selected : [371, 1198, 1309, 530, 1091, 936, 68, 414, 1378, 1773]
INFO:root:FL Epoch: 37 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 37 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 37 Training on worker :371
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744757
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567450
INFO:root:FL Epoch: 37 Norm Difference for worker 371 is 1.074559
INFO:root:FL Epoch: 37 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1198
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586412
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656121
INFO:root:FL Epoch: 37 Norm Difference for worker 1198 is 1.13474
INFO:root:FL Epoch: 37 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1309
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1309 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513529
INFO:root:Worker: 1309 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491737
INFO:root:FL Epoch: 37 Norm Difference for worker 1309 is 1.099233
INFO:root:FL Epoch: 37 Done on worker:1309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :530
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752765
INFO:root:Worker: 530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500994
INFO:root:FL Epoch: 37 Norm Difference for worker 530 is 1.14494
INFO:root:FL Epoch: 37 Done on worker:530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1091
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1091 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696961
INFO:root:Worker: 1091 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554380
INFO:root:FL Epoch: 37 Norm Difference for worker 1091 is 1.089683
INFO:root:FL Epoch: 37 Done on worker:1091
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :936
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598452
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455685
INFO:root:FL Epoch: 37 Norm Difference for worker 936 is 1.110326
INFO:root:FL Epoch: 37 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :68
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 68 Train Epoch: 0 [0/201 (0%)]	Loss: 0.747232
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 68 Train Epoch: 1 [0/201 (0%)]	Loss: 0.730476
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 37 Norm Difference for worker 68 is 1.091313
INFO:root:FL Epoch: 37 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :414
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650446
INFO:root:Worker: 414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563773
INFO:root:FL Epoch: 37 Norm Difference for worker 414 is 1.113438
INFO:root:FL Epoch: 37 Done on worker:414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1378
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695722
INFO:root:Worker: 1378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567511
INFO:root:FL Epoch: 37 Norm Difference for worker 1378 is 1.167562
INFO:root:FL Epoch: 37 Done on worker:1378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 37 Training on worker :1773
INFO:root:FL Epoch: 37 Using Learning rate : 0.04652319052699269 
INFO:root:FL Epoch: 37 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679196
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581868
INFO:root:FL Epoch: 37 Norm Difference for worker 1773 is 1.12684
INFO:root:FL Epoch: 37 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 371
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 37 Ends   ===================
INFO:root:Epoch:37 Global Model Test Loss:0.653632731998668 and Test Accuracy:61.76470588235294 
INFO:root:Epoch:37 Global Model Backdoor Test Loss:1.281800369421641                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 38 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 38 Workers Selected : [501, 1868, 1606, 169, 1363, 1799, 1046, 1681, 1531, 798]
INFO:root:FL Epoch: 38 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 38 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 38 Training on worker :501
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648457
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539688
INFO:root:FL Epoch: 38 Norm Difference for worker 501 is 1.016005
INFO:root:FL Epoch: 38 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1868
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663939
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584059
INFO:root:FL Epoch: 38 Norm Difference for worker 1868 is 1.135016
INFO:root:FL Epoch: 38 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1606
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623177
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493988
INFO:root:FL Epoch: 38 Norm Difference for worker 1606 is 0.991306
INFO:root:FL Epoch: 38 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :169
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.506423
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.600463
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 38 Norm Difference for worker 169 is 0.97497
INFO:root:FL Epoch: 38 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1363
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565452
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529413
INFO:root:FL Epoch: 38 Norm Difference for worker 1363 is 1.0295
INFO:root:FL Epoch: 38 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1799
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653556
INFO:root:Worker: 1799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608747
INFO:root:FL Epoch: 38 Norm Difference for worker 1799 is 0.961021
INFO:root:FL Epoch: 38 Done on worker:1799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1046
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1046 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689563
INFO:root:Worker: 1046 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603854
INFO:root:FL Epoch: 38 Norm Difference for worker 1046 is 1.010258
INFO:root:FL Epoch: 38 Done on worker:1046
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1681
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625995
INFO:root:Worker: 1681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538839
INFO:root:FL Epoch: 38 Norm Difference for worker 1681 is 1.030112
INFO:root:FL Epoch: 38 Done on worker:1681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :1531
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657652
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605359
INFO:root:FL Epoch: 38 Norm Difference for worker 1531 is 1.034214
INFO:root:FL Epoch: 38 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 38 Training on worker :798
INFO:root:FL Epoch: 38 Using Learning rate : 0.04643014414593871 
INFO:root:FL Epoch: 38 Normal Training
INFO:root:Worker: 798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630645
INFO:root:Worker: 798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543719
INFO:root:FL Epoch: 38 Norm Difference for worker 798 is 1.033382
INFO:root:FL Epoch: 38 Done on worker:798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1606
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 38 Ends   ===================
INFO:root:Epoch:38 Global Model Test Loss:0.6494001080008114 and Test Accuracy:62.35294117647059 
INFO:root:Epoch:38 Global Model Backdoor Test Loss:1.1551021933555603                             and Backdoor Test Accuracy:22.5 
INFO:root:=======================================================
INFO:root:================FL round 39 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 39 Workers Selected : [544, 1317, 1425, 579, 945, 879, 886, 1359, 1849, 242]
INFO:root:FL Epoch: 39 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 39 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 39 Training on worker :544
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656006
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667034
INFO:root:FL Epoch: 39 Norm Difference for worker 544 is 1.109894
INFO:root:FL Epoch: 39 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1317
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618437
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490181
INFO:root:FL Epoch: 39 Norm Difference for worker 1317 is 1.171389
INFO:root:FL Epoch: 39 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1425
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651691
INFO:root:Worker: 1425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560033
INFO:root:FL Epoch: 39 Norm Difference for worker 1425 is 1.13304
INFO:root:FL Epoch: 39 Done on worker:1425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :579
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734748
INFO:root:Worker: 579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616306
INFO:root:FL Epoch: 39 Norm Difference for worker 579 is 1.134932
INFO:root:FL Epoch: 39 Done on worker:579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :945
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550181
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387518
INFO:root:FL Epoch: 39 Norm Difference for worker 945 is 1.152393
INFO:root:FL Epoch: 39 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :879
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638879
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640246
INFO:root:FL Epoch: 39 Norm Difference for worker 879 is 1.088196
INFO:root:FL Epoch: 39 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :886
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738925
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460331
INFO:root:FL Epoch: 39 Norm Difference for worker 886 is 1.059787
INFO:root:FL Epoch: 39 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1359
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641361
INFO:root:Worker: 1359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452386
INFO:root:FL Epoch: 39 Norm Difference for worker 1359 is 1.067802
INFO:root:FL Epoch: 39 Done on worker:1359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :1849
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 1849 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744573
INFO:root:Worker: 1849 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571784
INFO:root:FL Epoch: 39 Norm Difference for worker 1849 is 1.118205
INFO:root:FL Epoch: 39 Done on worker:1849
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 39 Training on worker :242
INFO:root:FL Epoch: 39 Using Learning rate : 0.04633728385764683 
INFO:root:FL Epoch: 39 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689057
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.485093
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 39 Norm Difference for worker 242 is 1.074051
INFO:root:FL Epoch: 39 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 886
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 39 Ends   ===================
INFO:root:Epoch:39 Global Model Test Loss:0.6671811394831714 and Test Accuracy:62.64705882352941 
INFO:root:Epoch:39 Global Model Backdoor Test Loss:1.3934402267138164                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 40 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 40 Workers Selected : [658, 768, 1228, 549, 850, 260, 1831, 1836, 459, 1298]
INFO:root:FL Epoch: 40 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 40 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 40 Training on worker :658
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604255
INFO:root:Worker: 658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614373
INFO:root:FL Epoch: 40 Norm Difference for worker 658 is 1.234505
INFO:root:FL Epoch: 40 Done on worker:658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :768
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478261
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420541
INFO:root:FL Epoch: 40 Norm Difference for worker 768 is 1.169
INFO:root:FL Epoch: 40 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1228
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1228 Train Epoch: 0 [0/200 (0%)]	Loss: 0.789921
INFO:root:Worker: 1228 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623461
INFO:root:FL Epoch: 40 Norm Difference for worker 1228 is 1.179066
INFO:root:FL Epoch: 40 Done on worker:1228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :549
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678380
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462626
INFO:root:FL Epoch: 40 Norm Difference for worker 549 is 1.181455
INFO:root:FL Epoch: 40 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :850
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648213
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697248
INFO:root:FL Epoch: 40 Norm Difference for worker 850 is 1.162567
INFO:root:FL Epoch: 40 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :260
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.591337
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.585472
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 40 Norm Difference for worker 260 is 1.169911
INFO:root:FL Epoch: 40 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1831
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566635
INFO:root:Worker: 1831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447776
INFO:root:FL Epoch: 40 Norm Difference for worker 1831 is 1.163853
INFO:root:FL Epoch: 40 Done on worker:1831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1836
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553963
INFO:root:Worker: 1836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597140
INFO:root:FL Epoch: 40 Norm Difference for worker 1836 is 1.145531
INFO:root:FL Epoch: 40 Done on worker:1836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :459
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495938
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512323
INFO:root:FL Epoch: 40 Norm Difference for worker 459 is 1.266991
INFO:root:FL Epoch: 40 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 40 Training on worker :1298
INFO:root:FL Epoch: 40 Using Learning rate : 0.046244609289931536 
INFO:root:FL Epoch: 40 Normal Training
INFO:root:Worker: 1298 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524488
INFO:root:Worker: 1298 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642981
INFO:root:FL Epoch: 40 Norm Difference for worker 1298 is 1.227533
INFO:root:FL Epoch: 40 Done on worker:1298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 260
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 40 Ends   ===================
INFO:root:Epoch:40 Global Model Test Loss:0.657322084202486 and Test Accuracy:63.8235294117647 
INFO:root:Epoch:40 Global Model Backdoor Test Loss:1.286134918530782                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 41 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 41 Workers Selected : [1267, 565, 477, 1012, 1492, 882, 1543, 1278, 1765, 900]
INFO:root:FL Epoch: 41 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 41 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 41 Training on worker :1267
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1267 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603986
INFO:root:Worker: 1267 Train Epoch: 1 [0/200 (0%)]	Loss: 0.715096
INFO:root:FL Epoch: 41 Norm Difference for worker 1267 is 1.148367
INFO:root:FL Epoch: 41 Done on worker:1267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :565
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630751
INFO:root:Worker: 565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516593
INFO:root:FL Epoch: 41 Norm Difference for worker 565 is 1.197679
INFO:root:FL Epoch: 41 Done on worker:565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :477
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692521
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679981
INFO:root:FL Epoch: 41 Norm Difference for worker 477 is 1.134721
INFO:root:FL Epoch: 41 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1012
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.836789
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467384
INFO:root:FL Epoch: 41 Norm Difference for worker 1012 is 1.123978
INFO:root:FL Epoch: 41 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1492
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614514
INFO:root:Worker: 1492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426638
INFO:root:FL Epoch: 41 Norm Difference for worker 1492 is 1.214612
INFO:root:FL Epoch: 41 Done on worker:1492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :882
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547814
INFO:root:Worker: 882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399516
INFO:root:FL Epoch: 41 Norm Difference for worker 882 is 1.100061
INFO:root:FL Epoch: 41 Done on worker:882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1543
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657784
INFO:root:Worker: 1543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491729
INFO:root:FL Epoch: 41 Norm Difference for worker 1543 is 1.157243
INFO:root:FL Epoch: 41 Done on worker:1543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1278
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517986
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.777891
INFO:root:FL Epoch: 41 Norm Difference for worker 1278 is 1.165341
INFO:root:FL Epoch: 41 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :1765
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546660
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.789827
INFO:root:FL Epoch: 41 Norm Difference for worker 1765 is 1.156913
INFO:root:FL Epoch: 41 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 41 Training on worker :900
INFO:root:FL Epoch: 41 Using Learning rate : 0.04615212007135167 
INFO:root:FL Epoch: 41 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690860
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601884
INFO:root:FL Epoch: 41 Norm Difference for worker 900 is 1.230035
INFO:root:FL Epoch: 41 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 882
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 41 Ends   ===================
INFO:root:Epoch:41 Global Model Test Loss:0.6341452125240775 and Test Accuracy:64.11764705882354 
INFO:root:Epoch:41 Global Model Backdoor Test Loss:1.0625088214874268                             and Backdoor Test Accuracy:22.5 
INFO:root:=======================================================
INFO:root:================FL round 42 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 42 Workers Selected : [1580, 1750, 1154, 1426, 1778, 887, 764, 1052, 396, 1099]
INFO:root:FL Epoch: 42 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 42 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 42 Training on worker :1580
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504846
INFO:root:Worker: 1580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373553
INFO:root:FL Epoch: 42 Norm Difference for worker 1580 is 1.092423
INFO:root:FL Epoch: 42 Done on worker:1580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1750
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532385
INFO:root:Worker: 1750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671430
INFO:root:FL Epoch: 42 Norm Difference for worker 1750 is 1.011437
INFO:root:FL Epoch: 42 Done on worker:1750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1154
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1154 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666543
INFO:root:Worker: 1154 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639550
INFO:root:FL Epoch: 42 Norm Difference for worker 1154 is 1.024173
INFO:root:FL Epoch: 42 Done on worker:1154
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1426
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641816
INFO:root:Worker: 1426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596608
INFO:root:FL Epoch: 42 Norm Difference for worker 1426 is 1.090303
INFO:root:FL Epoch: 42 Done on worker:1426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1778
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731332
INFO:root:Worker: 1778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656058
INFO:root:FL Epoch: 42 Norm Difference for worker 1778 is 1.048994
INFO:root:FL Epoch: 42 Done on worker:1778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :887
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710272
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708013
INFO:root:FL Epoch: 42 Norm Difference for worker 887 is 1.109326
INFO:root:FL Epoch: 42 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :764
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543500
INFO:root:Worker: 764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594379
INFO:root:FL Epoch: 42 Norm Difference for worker 764 is 1.048992
INFO:root:FL Epoch: 42 Done on worker:764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1052
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651353
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.805549
INFO:root:FL Epoch: 42 Norm Difference for worker 1052 is 0.985002
INFO:root:FL Epoch: 42 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :396
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674936
INFO:root:Worker: 396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598415
INFO:root:FL Epoch: 42 Norm Difference for worker 396 is 0.972664
INFO:root:FL Epoch: 42 Done on worker:396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 42 Training on worker :1099
INFO:root:FL Epoch: 42 Using Learning rate : 0.04605981583120897 
INFO:root:FL Epoch: 42 Normal Training
INFO:root:Worker: 1099 Train Epoch: 0 [0/200 (0%)]	Loss: 0.831747
INFO:root:Worker: 1099 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667084
INFO:root:FL Epoch: 42 Norm Difference for worker 1099 is 1.044643
INFO:root:FL Epoch: 42 Done on worker:1099
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1052
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 42 Ends   ===================
INFO:root:Epoch:42 Global Model Test Loss:0.6256902568480548 and Test Accuracy:63.8235294117647 
INFO:root:Epoch:42 Global Model Backdoor Test Loss:0.8269852300484976                             and Backdoor Test Accuracy:31.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 43 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 43 Workers Selected : [399, 1738, 751, 1462, 992, 1682, 957, 684, 1846, 1486]
INFO:root:FL Epoch: 43 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 43 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 43 Training on worker :399
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772205
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566479
INFO:root:FL Epoch: 43 Norm Difference for worker 399 is 0.939232
INFO:root:FL Epoch: 43 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1738
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744058
INFO:root:Worker: 1738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620567
INFO:root:FL Epoch: 43 Norm Difference for worker 1738 is 0.891942
INFO:root:FL Epoch: 43 Done on worker:1738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :751
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685412
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577357
INFO:root:FL Epoch: 43 Norm Difference for worker 751 is 0.995823
INFO:root:FL Epoch: 43 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1462
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653912
INFO:root:Worker: 1462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571858
INFO:root:FL Epoch: 43 Norm Difference for worker 1462 is 0.98442
INFO:root:FL Epoch: 43 Done on worker:1462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :992
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 992 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629508
INFO:root:Worker: 992 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511045
INFO:root:FL Epoch: 43 Norm Difference for worker 992 is 0.966483
INFO:root:FL Epoch: 43 Done on worker:992
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1682
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617424
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.706843
INFO:root:FL Epoch: 43 Norm Difference for worker 1682 is 0.902924
INFO:root:FL Epoch: 43 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :957
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 957 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562617
INFO:root:Worker: 957 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553009
INFO:root:FL Epoch: 43 Norm Difference for worker 957 is 0.90191
INFO:root:FL Epoch: 43 Done on worker:957
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :684
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519343
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606664
INFO:root:FL Epoch: 43 Norm Difference for worker 684 is 1.008367
INFO:root:FL Epoch: 43 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1846
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559191
INFO:root:Worker: 1846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580321
INFO:root:FL Epoch: 43 Norm Difference for worker 1846 is 0.956996
INFO:root:FL Epoch: 43 Done on worker:1846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 43 Training on worker :1486
INFO:root:FL Epoch: 43 Using Learning rate : 0.04596769619954655 
INFO:root:FL Epoch: 43 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652213
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612808
INFO:root:FL Epoch: 43 Norm Difference for worker 1486 is 0.911355
INFO:root:FL Epoch: 43 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1738
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 43 Ends   ===================
INFO:root:Epoch:43 Global Model Test Loss:0.6206016996327568 and Test Accuracy:65.29411764705883 
INFO:root:Epoch:43 Global Model Backdoor Test Loss:0.9588535726070404                             and Backdoor Test Accuracy:20.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 44 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 44 Workers Selected : [1342, 690, 1438, 42, 1408, 485, 1636, 160, 325, 1]
INFO:root:FL Epoch: 44 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.1002994 0.1002994 0.1002994]
INFO:root:FL Epoch: 44 Num points on workers: [200 200 200 201 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 44 Training on worker :1342
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600061
INFO:root:Worker: 1342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612732
INFO:root:FL Epoch: 44 Norm Difference for worker 1342 is 0.9482
INFO:root:FL Epoch: 44 Done on worker:1342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :690
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586118
INFO:root:Worker: 690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545242
INFO:root:FL Epoch: 44 Norm Difference for worker 690 is 0.946543
INFO:root:FL Epoch: 44 Done on worker:690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1438
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654474
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663130
INFO:root:FL Epoch: 44 Norm Difference for worker 1438 is 0.974272
INFO:root:FL Epoch: 44 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :42
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603937
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.641455
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 44 Norm Difference for worker 42 is 0.960416
INFO:root:FL Epoch: 44 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1408
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653215
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518692
INFO:root:FL Epoch: 44 Norm Difference for worker 1408 is 1.047196
INFO:root:FL Epoch: 44 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :485
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656209
INFO:root:Worker: 485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521399
INFO:root:FL Epoch: 44 Norm Difference for worker 485 is 1.031418
INFO:root:FL Epoch: 44 Done on worker:485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1636
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644525
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646045
INFO:root:FL Epoch: 44 Norm Difference for worker 1636 is 1.002224
INFO:root:FL Epoch: 44 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :160
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.665198
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.571287
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 44 Norm Difference for worker 160 is 0.963677
INFO:root:FL Epoch: 44 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :325
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526755
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.476059
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 44 Norm Difference for worker 325 is 1.0154
INFO:root:FL Epoch: 44 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 44 Training on worker :1
INFO:root:FL Epoch: 44 Using Learning rate : 0.04587576080714746 
INFO:root:FL Epoch: 44 Normal Training
INFO:root:Worker: 1 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596802
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 1 Train Epoch: 1 [0/201 (0%)]	Loss: 0.596823
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 44 Norm Difference for worker 1 is 0.928356
INFO:root:FL Epoch: 44 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 44 Ends   ===================
INFO:root:Epoch:44 Global Model Test Loss:0.6284186524503371 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:44 Global Model Backdoor Test Loss:1.083256979783376                             and Backdoor Test Accuracy:17.5 
INFO:root:=======================================================
INFO:root:================FL round 45 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 45 Workers Selected : [131, 1341, 630, 1813, 681, 1218, 590, 1927, 822, 1862]
INFO:root:FL Epoch: 45 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 45 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 45 Training on worker :131
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 131 Train Epoch: 0 [0/201 (0%)]	Loss: 0.673860
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 131 Train Epoch: 1 [0/201 (0%)]	Loss: 0.601695
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 45 Norm Difference for worker 131 is 1.070295
INFO:root:FL Epoch: 45 Done on worker:131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1341
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611247
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.753546
INFO:root:FL Epoch: 45 Norm Difference for worker 1341 is 1.026106
INFO:root:FL Epoch: 45 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :630
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764366
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.726340
INFO:root:FL Epoch: 45 Norm Difference for worker 630 is 1.062403
INFO:root:FL Epoch: 45 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1813
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644911
INFO:root:Worker: 1813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473154
INFO:root:FL Epoch: 45 Norm Difference for worker 1813 is 1.13613
INFO:root:FL Epoch: 45 Done on worker:1813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :681
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716159
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510409
INFO:root:FL Epoch: 45 Norm Difference for worker 681 is 1.071678
INFO:root:FL Epoch: 45 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1218
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675502
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600327
INFO:root:FL Epoch: 45 Norm Difference for worker 1218 is 1.041135
INFO:root:FL Epoch: 45 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :590
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.786924
INFO:root:Worker: 590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672113
INFO:root:FL Epoch: 45 Norm Difference for worker 590 is 1.047217
INFO:root:FL Epoch: 45 Done on worker:590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1927
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628757
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554989
INFO:root:FL Epoch: 45 Norm Difference for worker 1927 is 1.074836
INFO:root:FL Epoch: 45 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :822
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600971
INFO:root:Worker: 822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.741389
INFO:root:FL Epoch: 45 Norm Difference for worker 822 is 1.063604
INFO:root:FL Epoch: 45 Done on worker:822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 45 Training on worker :1862
INFO:root:FL Epoch: 45 Using Learning rate : 0.04578400928553317 
INFO:root:FL Epoch: 45 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572485
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578465
INFO:root:FL Epoch: 45 Norm Difference for worker 1862 is 1.165986
INFO:root:FL Epoch: 45 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1218
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 45 Ends   ===================
INFO:root:Epoch:45 Global Model Test Loss:0.6465364414102891 and Test Accuracy:63.529411764705884 
INFO:root:Epoch:45 Global Model Backdoor Test Loss:1.3238498767217                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 46 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 46 Workers Selected : [1070, 1321, 1933, 1737, 1799, 403, 1155, 409, 412, 248]
INFO:root:FL Epoch: 46 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 46 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 46 Training on worker :1070
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649305
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537664
INFO:root:FL Epoch: 46 Norm Difference for worker 1070 is 1.00265
INFO:root:FL Epoch: 46 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1321
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1321 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526023
INFO:root:Worker: 1321 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555911
INFO:root:FL Epoch: 46 Norm Difference for worker 1321 is 1.027153
INFO:root:FL Epoch: 46 Done on worker:1321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1933
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1933 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522824
INFO:root:Worker: 1933 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660078
INFO:root:FL Epoch: 46 Norm Difference for worker 1933 is 0.984487
INFO:root:FL Epoch: 46 Done on worker:1933
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1737
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612156
INFO:root:Worker: 1737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540799
INFO:root:FL Epoch: 46 Norm Difference for worker 1737 is 0.999929
INFO:root:FL Epoch: 46 Done on worker:1737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1799
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678532
INFO:root:Worker: 1799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598221
INFO:root:FL Epoch: 46 Norm Difference for worker 1799 is 0.944064
INFO:root:FL Epoch: 46 Done on worker:1799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :403
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641075
INFO:root:Worker: 403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547610
INFO:root:FL Epoch: 46 Norm Difference for worker 403 is 1.083805
INFO:root:FL Epoch: 46 Done on worker:403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :1155
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 1155 Train Epoch: 0 [0/200 (0%)]	Loss: 0.797829
INFO:root:Worker: 1155 Train Epoch: 1 [0/200 (0%)]	Loss: 0.770685
INFO:root:FL Epoch: 46 Norm Difference for worker 1155 is 0.996545
INFO:root:FL Epoch: 46 Done on worker:1155
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :409
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444516
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.732020
INFO:root:FL Epoch: 46 Norm Difference for worker 409 is 1.025909
INFO:root:FL Epoch: 46 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :412
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 412 Train Epoch: 0 [0/200 (0%)]	Loss: 0.983326
INFO:root:Worker: 412 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584293
INFO:root:FL Epoch: 46 Norm Difference for worker 412 is 0.947923
INFO:root:FL Epoch: 46 Done on worker:412
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 46 Training on worker :248
INFO:root:FL Epoch: 46 Using Learning rate : 0.0456924412669621 
INFO:root:FL Epoch: 46 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.514250
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.702986
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 46 Norm Difference for worker 248 is 0.985482
INFO:root:FL Epoch: 46 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1799
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 46 Ends   ===================
INFO:root:Epoch:46 Global Model Test Loss:0.6252629336188821 and Test Accuracy:65.58823529411765 
INFO:root:Epoch:46 Global Model Backdoor Test Loss:1.087238351504008                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 47 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 47 Workers Selected : [739, 156, 1756, 1742, 1575, 1917, 508, 601, 660, 808]
INFO:root:FL Epoch: 47 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 47 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 47 Training on worker :739
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 739 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726547
INFO:root:Worker: 739 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675969
INFO:root:FL Epoch: 47 Norm Difference for worker 739 is 1.055654
INFO:root:FL Epoch: 47 Done on worker:739
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :156
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 156 Train Epoch: 0 [0/201 (0%)]	Loss: 0.563298
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 156 Train Epoch: 1 [0/201 (0%)]	Loss: 0.600330
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 47 Norm Difference for worker 156 is 1.017424
INFO:root:FL Epoch: 47 Done on worker:156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1756
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636664
INFO:root:Worker: 1756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504656
INFO:root:FL Epoch: 47 Norm Difference for worker 1756 is 1.0308
INFO:root:FL Epoch: 47 Done on worker:1756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1742
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505466
INFO:root:Worker: 1742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563822
INFO:root:FL Epoch: 47 Norm Difference for worker 1742 is 0.977025
INFO:root:FL Epoch: 47 Done on worker:1742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1575
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597185
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530227
INFO:root:FL Epoch: 47 Norm Difference for worker 1575 is 1.103513
INFO:root:FL Epoch: 47 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :1917
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 1917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530424
INFO:root:Worker: 1917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454986
INFO:root:FL Epoch: 47 Norm Difference for worker 1917 is 1.013009
INFO:root:FL Epoch: 47 Done on worker:1917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :508
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587910
INFO:root:Worker: 508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521888
INFO:root:FL Epoch: 47 Norm Difference for worker 508 is 1.086089
INFO:root:FL Epoch: 47 Done on worker:508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :601
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562693
INFO:root:Worker: 601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582132
INFO:root:FL Epoch: 47 Norm Difference for worker 601 is 1.003755
INFO:root:FL Epoch: 47 Done on worker:601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :660
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517522
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521071
INFO:root:FL Epoch: 47 Norm Difference for worker 660 is 1.070389
INFO:root:FL Epoch: 47 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 47 Training on worker :808
INFO:root:FL Epoch: 47 Using Learning rate : 0.04560105638442818 
INFO:root:FL Epoch: 47 Normal Training
INFO:root:Worker: 808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485249
INFO:root:Worker: 808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409321
INFO:root:FL Epoch: 47 Norm Difference for worker 808 is 1.079078
INFO:root:FL Epoch: 47 Done on worker:808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 601
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 47 Ends   ===================
INFO:root:Epoch:47 Global Model Test Loss:0.6218318273039425 and Test Accuracy:67.94117647058823 
INFO:root:Epoch:47 Global Model Backdoor Test Loss:1.2381107409795125                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 48 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 48 Workers Selected : [954, 581, 763, 844, 1336, 81, 502, 151, 1637, 1185]
INFO:root:FL Epoch: 48 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 48 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 48 Training on worker :954
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 954 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555679
INFO:root:Worker: 954 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510460
INFO:root:FL Epoch: 48 Norm Difference for worker 954 is 1.130583
INFO:root:FL Epoch: 48 Done on worker:954
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :581
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623844
INFO:root:Worker: 581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556061
INFO:root:FL Epoch: 48 Norm Difference for worker 581 is 1.222191
INFO:root:FL Epoch: 48 Done on worker:581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :763
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605520
INFO:root:Worker: 763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580557
INFO:root:FL Epoch: 48 Norm Difference for worker 763 is 1.175634
INFO:root:FL Epoch: 48 Done on worker:763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :844
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476850
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624754
INFO:root:FL Epoch: 48 Norm Difference for worker 844 is 1.090099
INFO:root:FL Epoch: 48 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1336
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1336 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632360
INFO:root:Worker: 1336 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527593
INFO:root:FL Epoch: 48 Norm Difference for worker 1336 is 1.159196
INFO:root:FL Epoch: 48 Done on worker:1336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :81
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.461887
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.680674
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 48 Norm Difference for worker 81 is 1.178631
INFO:root:FL Epoch: 48 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :502
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727017
INFO:root:Worker: 502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539522
INFO:root:FL Epoch: 48 Norm Difference for worker 502 is 1.119045
INFO:root:FL Epoch: 48 Done on worker:502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :151
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.543182
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.612689
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 48 Norm Difference for worker 151 is 1.137863
INFO:root:FL Epoch: 48 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1637
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604329
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610831
INFO:root:FL Epoch: 48 Norm Difference for worker 1637 is 1.066956
INFO:root:FL Epoch: 48 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 48 Training on worker :1185
INFO:root:FL Epoch: 48 Using Learning rate : 0.04550985427165932 
INFO:root:FL Epoch: 48 Normal Training
INFO:root:Worker: 1185 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656416
INFO:root:Worker: 1185 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586026
INFO:root:FL Epoch: 48 Norm Difference for worker 1185 is 1.151786
INFO:root:FL Epoch: 48 Done on worker:1185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1637
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 48 Ends   ===================
INFO:root:Epoch:48 Global Model Test Loss:0.6237185071496403 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:48 Global Model Backdoor Test Loss:1.1782489816347759                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 49 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 49 Workers Selected : [463, 1158, 831, 944, 813, 289, 1379, 161, 82, 997]
INFO:root:FL Epoch: 49 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 49 Num points on workers: [200 200 200 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 49 Training on worker :463
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655560
INFO:root:Worker: 463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423266
INFO:root:FL Epoch: 49 Norm Difference for worker 463 is 0.987635
INFO:root:FL Epoch: 49 Done on worker:463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1158
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509831
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686410
INFO:root:FL Epoch: 49 Norm Difference for worker 1158 is 1.04231
INFO:root:FL Epoch: 49 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :831
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525059
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546894
INFO:root:FL Epoch: 49 Norm Difference for worker 831 is 1.090378
INFO:root:FL Epoch: 49 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :944
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580437
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.787763
INFO:root:FL Epoch: 49 Norm Difference for worker 944 is 1.0126
INFO:root:FL Epoch: 49 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :813
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546824
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565573
INFO:root:FL Epoch: 49 Norm Difference for worker 813 is 1.001092
INFO:root:FL Epoch: 49 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :289
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 289 Train Epoch: 0 [0/201 (0%)]	Loss: 0.690340
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 289 Train Epoch: 1 [0/201 (0%)]	Loss: 0.498695
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 289 is 1.000569
INFO:root:FL Epoch: 49 Done on worker:289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :1379
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 1379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606091
INFO:root:Worker: 1379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628009
INFO:root:FL Epoch: 49 Norm Difference for worker 1379 is 1.040122
INFO:root:FL Epoch: 49 Done on worker:1379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :161
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 161 Train Epoch: 0 [0/201 (0%)]	Loss: 0.512511
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 161 Train Epoch: 1 [0/201 (0%)]	Loss: 0.558190
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 161 is 1.02396
INFO:root:FL Epoch: 49 Done on worker:161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :82
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 82 Train Epoch: 0 [0/201 (0%)]	Loss: 0.577240
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 82 Train Epoch: 1 [0/201 (0%)]	Loss: 0.640583
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 49 Norm Difference for worker 82 is 0.983297
INFO:root:FL Epoch: 49 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 49 Training on worker :997
INFO:root:FL Epoch: 49 Using Learning rate : 0.045418834563115996 
INFO:root:FL Epoch: 49 Normal Training
INFO:root:Worker: 997 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558851
INFO:root:Worker: 997 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540941
INFO:root:FL Epoch: 49 Norm Difference for worker 997 is 1.093499
INFO:root:FL Epoch: 49 Done on worker:997
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 289
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 49 Ends   ===================
INFO:root:Epoch:49 Global Model Test Loss:0.618901804966085 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:49 Global Model Backdoor Test Loss:1.263566513856252                             and Backdoor Test Accuracy:20.0 
INFO:root:=======================================================
INFO:root:================FL round 50 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 50 Workers Selected : [545, 1346, 1144, 1831, 1069, 1333, 1751, 277, 248, 960]
INFO:root:FL Epoch: 50 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.1003996 0.0999001]
INFO:root:FL Epoch: 50 Num points on workers: [200 200 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 50 Training on worker :545
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522022
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433524
INFO:root:FL Epoch: 50 Norm Difference for worker 545 is 1.190298
INFO:root:FL Epoch: 50 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1346
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727562
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471174
INFO:root:FL Epoch: 50 Norm Difference for worker 1346 is 1.233355
INFO:root:FL Epoch: 50 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1144
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1144 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681461
INFO:root:Worker: 1144 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643413
INFO:root:FL Epoch: 50 Norm Difference for worker 1144 is 1.185787
INFO:root:FL Epoch: 50 Done on worker:1144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1831
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597132
INFO:root:Worker: 1831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562802
INFO:root:FL Epoch: 50 Norm Difference for worker 1831 is 1.250146
INFO:root:FL Epoch: 50 Done on worker:1831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1069
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731610
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408454
INFO:root:FL Epoch: 50 Norm Difference for worker 1069 is 1.290657
INFO:root:FL Epoch: 50 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1333
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625837
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509866
INFO:root:FL Epoch: 50 Norm Difference for worker 1333 is 1.188692
INFO:root:FL Epoch: 50 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :1751
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619007
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541634
INFO:root:FL Epoch: 50 Norm Difference for worker 1751 is 1.233741
INFO:root:FL Epoch: 50 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :277
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.624438
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.417272
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 50 Norm Difference for worker 277 is 1.239257
INFO:root:FL Epoch: 50 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :248
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518149
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381124
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 50 Norm Difference for worker 248 is 1.164635
INFO:root:FL Epoch: 50 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 50 Training on worker :960
INFO:root:FL Epoch: 50 Using Learning rate : 0.045327996893989767 
INFO:root:FL Epoch: 50 Normal Training
INFO:root:Worker: 960 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651369
INFO:root:Worker: 960 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451837
INFO:root:FL Epoch: 50 Norm Difference for worker 960 is 1.190432
INFO:root:FL Epoch: 50 Done on worker:960
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 960
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 50 Ends   ===================
INFO:root:Epoch:50 Global Model Test Loss:0.6376679662395927 and Test Accuracy:65.88235294117646 
INFO:root:Epoch:50 Global Model Backdoor Test Loss:1.3424703478813171                             and Backdoor Test Accuracy:17.5 
INFO:root:=======================================================
INFO:root:================FL round 51 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 51 Workers Selected : [754, 1419, 117, 1887, 1834, 1663, 652, 75, 1343, 430]
INFO:root:FL Epoch: 51 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 51 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 51 Training on worker :754
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726901
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411184
INFO:root:FL Epoch: 51 Norm Difference for worker 754 is 1.373952
INFO:root:FL Epoch: 51 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1419
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506776
INFO:root:Worker: 1419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.735834
INFO:root:FL Epoch: 51 Norm Difference for worker 1419 is 1.346341
INFO:root:FL Epoch: 51 Done on worker:1419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :117
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.895087
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.633384
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 117 is 1.29849
INFO:root:FL Epoch: 51 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1887
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794566
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571293
INFO:root:FL Epoch: 51 Norm Difference for worker 1887 is 1.28108
INFO:root:FL Epoch: 51 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1834
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.814695
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317800
INFO:root:FL Epoch: 51 Norm Difference for worker 1834 is 1.384963
INFO:root:FL Epoch: 51 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1663
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614366
INFO:root:Worker: 1663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287524
INFO:root:FL Epoch: 51 Norm Difference for worker 1663 is 1.242698
INFO:root:FL Epoch: 51 Done on worker:1663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :652
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519143
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607723
INFO:root:FL Epoch: 51 Norm Difference for worker 652 is 1.25177
INFO:root:FL Epoch: 51 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :75
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 75 Train Epoch: 0 [0/201 (0%)]	Loss: 0.887875
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 75 Train Epoch: 1 [0/201 (0%)]	Loss: 0.441891
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 51 Norm Difference for worker 75 is 1.322682
INFO:root:FL Epoch: 51 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :1343
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428182
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592085
INFO:root:FL Epoch: 51 Norm Difference for worker 1343 is 1.331583
INFO:root:FL Epoch: 51 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 51 Training on worker :430
INFO:root:FL Epoch: 51 Using Learning rate : 0.04523734090020179 
INFO:root:FL Epoch: 51 Normal Training
INFO:root:Worker: 430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526865
INFO:root:Worker: 430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342495
INFO:root:FL Epoch: 51 Norm Difference for worker 430 is 1.370846
INFO:root:FL Epoch: 51 Done on worker:430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 652
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 51 Ends   ===================
INFO:root:Epoch:51 Global Model Test Loss:0.676704515429104 and Test Accuracy:64.41176470588235 
INFO:root:Epoch:51 Global Model Backdoor Test Loss:1.0542092820008595                             and Backdoor Test Accuracy:40.0 
INFO:root:=======================================================
INFO:root:================FL round 52 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 52 Workers Selected : [1016, 1103, 1780, 427, 69, 939, 1927, 85, 1377, 1541]
INFO:root:FL Epoch: 52 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 52 Num points on workers: [200 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 52 Training on worker :1016
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587368
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482865
INFO:root:FL Epoch: 52 Norm Difference for worker 1016 is 1.517443
INFO:root:FL Epoch: 52 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1103
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1103 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650577
INFO:root:Worker: 1103 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456308
INFO:root:FL Epoch: 52 Norm Difference for worker 1103 is 1.377339
INFO:root:FL Epoch: 52 Done on worker:1103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1780
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515486
INFO:root:Worker: 1780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632094
INFO:root:FL Epoch: 52 Norm Difference for worker 1780 is 1.33137
INFO:root:FL Epoch: 52 Done on worker:1780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :427
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.704907
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438200
INFO:root:FL Epoch: 52 Norm Difference for worker 427 is 1.425611
INFO:root:FL Epoch: 52 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :69
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 69 Train Epoch: 0 [0/201 (0%)]	Loss: 0.599207
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 69 Train Epoch: 1 [0/201 (0%)]	Loss: 0.785625
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 52 Norm Difference for worker 69 is 1.454665
INFO:root:FL Epoch: 52 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :939
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628804
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.715687
INFO:root:FL Epoch: 52 Norm Difference for worker 939 is 1.488319
INFO:root:FL Epoch: 52 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1927
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702472
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452493
INFO:root:FL Epoch: 52 Norm Difference for worker 1927 is 1.431648
INFO:root:FL Epoch: 52 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :85
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 85 Train Epoch: 0 [0/201 (0%)]	Loss: 1.082561
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 85 Train Epoch: 1 [0/201 (0%)]	Loss: 0.548126
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 52 Norm Difference for worker 85 is 1.372417
INFO:root:FL Epoch: 52 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1377
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.857188
INFO:root:Worker: 1377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481867
INFO:root:FL Epoch: 52 Norm Difference for worker 1377 is 1.428492
INFO:root:FL Epoch: 52 Done on worker:1377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 52 Training on worker :1541
INFO:root:FL Epoch: 52 Using Learning rate : 0.04514686621840139 
INFO:root:FL Epoch: 52 Normal Training
INFO:root:Worker: 1541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.825510
INFO:root:Worker: 1541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510107
INFO:root:FL Epoch: 52 Norm Difference for worker 1541 is 1.387287
INFO:root:FL Epoch: 52 Done on worker:1541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 69
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 52 Ends   ===================
INFO:root:Epoch:52 Global Model Test Loss:0.6234106281224419 and Test Accuracy:64.41176470588235 
INFO:root:Epoch:52 Global Model Backdoor Test Loss:0.8610526621341705                             and Backdoor Test Accuracy:33.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 53 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 53 Workers Selected : [976, 865, 1416, 613, 1084, 1287, 1590, 1517, 1751, 112]
INFO:root:FL Epoch: 53 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 53 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 53 Training on worker :976
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 976 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655221
INFO:root:Worker: 976 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521210
INFO:root:FL Epoch: 53 Norm Difference for worker 976 is 0.898612
INFO:root:FL Epoch: 53 Done on worker:976
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :865
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641252
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650673
INFO:root:FL Epoch: 53 Norm Difference for worker 865 is 0.865939
INFO:root:FL Epoch: 53 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1416
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577090
INFO:root:Worker: 1416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530345
INFO:root:FL Epoch: 53 Norm Difference for worker 1416 is 0.976193
INFO:root:FL Epoch: 53 Done on worker:1416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :613
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643506
INFO:root:Worker: 613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542007
INFO:root:FL Epoch: 53 Norm Difference for worker 613 is 0.834186
INFO:root:FL Epoch: 53 Done on worker:613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1084
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605255
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480442
INFO:root:FL Epoch: 53 Norm Difference for worker 1084 is 0.931342
INFO:root:FL Epoch: 53 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1287
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1287 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618524
INFO:root:Worker: 1287 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536181
INFO:root:FL Epoch: 53 Norm Difference for worker 1287 is 0.86325
INFO:root:FL Epoch: 53 Done on worker:1287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1590
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737099
INFO:root:Worker: 1590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647968
INFO:root:FL Epoch: 53 Norm Difference for worker 1590 is 0.872857
INFO:root:FL Epoch: 53 Done on worker:1590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1517
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627244
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488202
INFO:root:FL Epoch: 53 Norm Difference for worker 1517 is 0.906488
INFO:root:FL Epoch: 53 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :1751
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 1751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608711
INFO:root:Worker: 1751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521051
INFO:root:FL Epoch: 53 Norm Difference for worker 1751 is 0.897711
INFO:root:FL Epoch: 53 Done on worker:1751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 53 Training on worker :112
INFO:root:FL Epoch: 53 Using Learning rate : 0.045056572485964584 
INFO:root:FL Epoch: 53 Normal Training
INFO:root:Worker: 112 Train Epoch: 0 [0/201 (0%)]	Loss: 0.602219
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 112 Train Epoch: 1 [0/201 (0%)]	Loss: 0.673610
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 53 Norm Difference for worker 112 is 0.883863
INFO:root:FL Epoch: 53 Done on worker:112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 865
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 53 Ends   ===================
INFO:root:Epoch:53 Global Model Test Loss:0.6305475568070131 and Test Accuracy:63.23529411764706 
INFO:root:Epoch:53 Global Model Backdoor Test Loss:1.218471646308899                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 54 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 54 Workers Selected : [431, 348, 1481, 759, 1869, 1192, 866, 1576, 1330, 622]
INFO:root:FL Epoch: 54 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 54 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 54 Training on worker :431
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803172
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469242
INFO:root:FL Epoch: 54 Norm Difference for worker 431 is 0.913633
INFO:root:FL Epoch: 54 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :348
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659196
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565368
INFO:root:FL Epoch: 54 Norm Difference for worker 348 is 0.964416
INFO:root:FL Epoch: 54 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :1481
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608621
INFO:root:Worker: 1481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.719489
INFO:root:FL Epoch: 54 Norm Difference for worker 1481 is 0.987563
INFO:root:FL Epoch: 54 Done on worker:1481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :759
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 759 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585296
INFO:root:Worker: 759 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544647
INFO:root:FL Epoch: 54 Norm Difference for worker 759 is 0.937786
INFO:root:FL Epoch: 54 Done on worker:759
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :1869
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584743
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.713517
INFO:root:FL Epoch: 54 Norm Difference for worker 1869 is 1.011827
INFO:root:FL Epoch: 54 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :1192
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565432
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653543
INFO:root:FL Epoch: 54 Norm Difference for worker 1192 is 0.935394
INFO:root:FL Epoch: 54 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :866
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618794
INFO:root:Worker: 866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540799
INFO:root:FL Epoch: 54 Norm Difference for worker 866 is 0.985451
INFO:root:FL Epoch: 54 Done on worker:866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :1576
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647466
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597715
INFO:root:FL Epoch: 54 Norm Difference for worker 1576 is 0.985812
INFO:root:FL Epoch: 54 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :1330
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537506
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626569
INFO:root:FL Epoch: 54 Norm Difference for worker 1330 is 1.009835
INFO:root:FL Epoch: 54 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 54 Training on worker :622
INFO:root:FL Epoch: 54 Using Learning rate : 0.04496645934099265 
INFO:root:FL Epoch: 54 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465659
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376949
INFO:root:FL Epoch: 54 Norm Difference for worker 622 is 0.964984
INFO:root:FL Epoch: 54 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 431
INFO:root:Norm of Aggregated Model: 5154.98486328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 54 Ends   ===================
INFO:root:Epoch:54 Global Model Test Loss:0.6104963141329148 and Test Accuracy:65.88235294117646 
INFO:root:Epoch:54 Global Model Backdoor Test Loss:1.1542301177978516                             and Backdoor Test Accuracy:18.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 55 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 55 Workers Selected : [1830, 398, 216, 479, 1655, 1161, 1239, 183, 871, 332]
INFO:root:FL Epoch: 55 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 55 Num points on workers: [200 200 201 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 55 Training on worker :1830
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584027
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550149
INFO:root:FL Epoch: 55 Norm Difference for worker 1830 is 1.065649
INFO:root:FL Epoch: 55 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :398
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578574
INFO:root:Worker: 398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635792
INFO:root:FL Epoch: 55 Norm Difference for worker 398 is 1.055616
INFO:root:FL Epoch: 55 Done on worker:398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :216
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 216 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603559
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 216 Train Epoch: 1 [0/201 (0%)]	Loss: 0.547686
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 55 Norm Difference for worker 216 is 1.080899
INFO:root:FL Epoch: 55 Done on worker:216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :479
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656660
INFO:root:Worker: 479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623655
INFO:root:FL Epoch: 55 Norm Difference for worker 479 is 1.086657
INFO:root:FL Epoch: 55 Done on worker:479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1655
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664824
INFO:root:Worker: 1655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543106
INFO:root:FL Epoch: 55 Norm Difference for worker 1655 is 1.016532
INFO:root:FL Epoch: 55 Done on worker:1655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1161
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1161 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680803
INFO:root:Worker: 1161 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601197
INFO:root:FL Epoch: 55 Norm Difference for worker 1161 is 1.05706
INFO:root:FL Epoch: 55 Done on worker:1161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :1239
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752633
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695681
INFO:root:FL Epoch: 55 Norm Difference for worker 1239 is 1.022621
INFO:root:FL Epoch: 55 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :183
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 183 Train Epoch: 0 [0/201 (0%)]	Loss: 0.814652
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 183 Train Epoch: 1 [0/201 (0%)]	Loss: 0.510006
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 55 Norm Difference for worker 183 is 1.05134
INFO:root:FL Epoch: 55 Done on worker:183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :871
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545994
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674193
INFO:root:FL Epoch: 55 Norm Difference for worker 871 is 1.088529
INFO:root:FL Epoch: 55 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 55 Training on worker :332
INFO:root:FL Epoch: 55 Using Learning rate : 0.044876526422310666 
INFO:root:FL Epoch: 55 Normal Training
INFO:root:Worker: 332 Train Epoch: 0 [0/201 (0%)]	Loss: 0.787481
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 332 Train Epoch: 1 [0/201 (0%)]	Loss: 0.458016
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 55 Norm Difference for worker 332 is 1.093628
INFO:root:FL Epoch: 55 Done on worker:332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1239
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 55 Ends   ===================
INFO:root:Epoch:55 Global Model Test Loss:0.6192236858255723 and Test Accuracy:63.529411764705884 
INFO:root:Epoch:55 Global Model Backdoor Test Loss:1.0411757330099742                             and Backdoor Test Accuracy:23.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 56 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 56 Workers Selected : [674, 74, 1352, 1659, 212, 122, 1086, 878, 248, 576]
INFO:root:FL Epoch: 56 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.0998004 0.1002994 0.1002994 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 56 Num points on workers: [200 201 200 200 201 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 56 Training on worker :674
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652349
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514881
INFO:root:FL Epoch: 56 Norm Difference for worker 674 is 0.946794
INFO:root:FL Epoch: 56 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :74
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.597225
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.476580
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 74 is 0.971719
INFO:root:FL Epoch: 56 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1352
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567676
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366911
INFO:root:FL Epoch: 56 Norm Difference for worker 1352 is 1.048189
INFO:root:FL Epoch: 56 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1659
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542703
INFO:root:Worker: 1659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510857
INFO:root:FL Epoch: 56 Norm Difference for worker 1659 is 1.036719
INFO:root:FL Epoch: 56 Done on worker:1659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :212
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.851479
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.514549
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 212 is 0.999794
INFO:root:FL Epoch: 56 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :122
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.542237
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.427954
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 122 is 0.971021
INFO:root:FL Epoch: 56 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :1086
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554322
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596796
INFO:root:FL Epoch: 56 Norm Difference for worker 1086 is 0.926306
INFO:root:FL Epoch: 56 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :878
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563727
INFO:root:Worker: 878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562117
INFO:root:FL Epoch: 56 Norm Difference for worker 878 is 0.978001
INFO:root:FL Epoch: 56 Done on worker:878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :248
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629196
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436509
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 56 Norm Difference for worker 248 is 0.965256
INFO:root:FL Epoch: 56 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 56 Training on worker :576
INFO:root:FL Epoch: 56 Using Learning rate : 0.04478677336946604 
INFO:root:FL Epoch: 56 Normal Training
INFO:root:Worker: 576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553134
INFO:root:Worker: 576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494727
INFO:root:FL Epoch: 56 Norm Difference for worker 576 is 1.003114
INFO:root:FL Epoch: 56 Done on worker:576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1086
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 56 Ends   ===================
INFO:root:Epoch:56 Global Model Test Loss:0.6313769642044517 and Test Accuracy:65.29411764705883 
INFO:root:Epoch:56 Global Model Backdoor Test Loss:1.3362389206886292                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 57 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 57 Workers Selected : [437, 630, 260, 935, 1139, 670, 1528, 1262, 1155, 857]
INFO:root:FL Epoch: 57 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 57 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 57 Training on worker :437
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456718
INFO:root:Worker: 437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459595
INFO:root:FL Epoch: 57 Norm Difference for worker 437 is 1.079578
INFO:root:FL Epoch: 57 Done on worker:437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :630
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678248
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560208
INFO:root:FL Epoch: 57 Norm Difference for worker 630 is 1.112174
INFO:root:FL Epoch: 57 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :260
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 260 Train Epoch: 0 [0/201 (0%)]	Loss: 0.505503
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 260 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419682
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 57 Norm Difference for worker 260 is 1.041384
INFO:root:FL Epoch: 57 Done on worker:260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :935
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576888
INFO:root:Worker: 935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564058
INFO:root:FL Epoch: 57 Norm Difference for worker 935 is 1.076219
INFO:root:FL Epoch: 57 Done on worker:935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1139
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616240
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.781012
INFO:root:FL Epoch: 57 Norm Difference for worker 1139 is 1.027302
INFO:root:FL Epoch: 57 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :670
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683130
INFO:root:Worker: 670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651720
INFO:root:FL Epoch: 57 Norm Difference for worker 670 is 1.045087
INFO:root:FL Epoch: 57 Done on worker:670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1528
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630611
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538439
INFO:root:FL Epoch: 57 Norm Difference for worker 1528 is 1.084771
INFO:root:FL Epoch: 57 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1262
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1262 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742954
INFO:root:Worker: 1262 Train Epoch: 1 [0/200 (0%)]	Loss: 0.734812
INFO:root:FL Epoch: 57 Norm Difference for worker 1262 is 1.032998
INFO:root:FL Epoch: 57 Done on worker:1262
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :1155
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 1155 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695763
INFO:root:Worker: 1155 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507135
INFO:root:FL Epoch: 57 Norm Difference for worker 1155 is 1.090626
INFO:root:FL Epoch: 57 Done on worker:1155
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 57 Training on worker :857
INFO:root:FL Epoch: 57 Using Learning rate : 0.04469719982272711 
INFO:root:FL Epoch: 57 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766967
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617929
INFO:root:FL Epoch: 57 Norm Difference for worker 857 is 1.056308
INFO:root:FL Epoch: 57 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1139
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 57 Ends   ===================
INFO:root:Epoch:57 Global Model Test Loss:0.6168861336567822 and Test Accuracy:66.76470588235294 
INFO:root:Epoch:57 Global Model Backdoor Test Loss:1.0257106324036915                             and Backdoor Test Accuracy:29.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 58 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 58 Workers Selected : [1099, 1643, 652, 1647, 1401, 970, 202, 340, 737, 424]
INFO:root:FL Epoch: 58 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 58 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 58 Training on worker :1099
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1099 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735055
INFO:root:Worker: 1099 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676777
INFO:root:FL Epoch: 58 Norm Difference for worker 1099 is 1.092936
INFO:root:FL Epoch: 58 Done on worker:1099
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1643
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426614
INFO:root:Worker: 1643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656850
INFO:root:FL Epoch: 58 Norm Difference for worker 1643 is 1.082914
INFO:root:FL Epoch: 58 Done on worker:1643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :652
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332107
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372195
INFO:root:FL Epoch: 58 Norm Difference for worker 652 is 1.128765
INFO:root:FL Epoch: 58 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1647
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656598
INFO:root:Worker: 1647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632052
INFO:root:FL Epoch: 58 Norm Difference for worker 1647 is 1.158301
INFO:root:FL Epoch: 58 Done on worker:1647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :1401
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508417
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631188
INFO:root:FL Epoch: 58 Norm Difference for worker 1401 is 1.058294
INFO:root:FL Epoch: 58 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :970
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 970 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585836
INFO:root:Worker: 970 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413714
INFO:root:FL Epoch: 58 Norm Difference for worker 970 is 1.078251
INFO:root:FL Epoch: 58 Done on worker:970
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :202
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.873798
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.652275
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 58 Norm Difference for worker 202 is 1.081711
INFO:root:FL Epoch: 58 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :340
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447221
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644070
INFO:root:FL Epoch: 58 Norm Difference for worker 340 is 1.045057
INFO:root:FL Epoch: 58 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :737
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706213
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620627
INFO:root:FL Epoch: 58 Norm Difference for worker 737 is 1.039663
INFO:root:FL Epoch: 58 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 58 Training on worker :424
INFO:root:FL Epoch: 58 Using Learning rate : 0.04460780542308165 
INFO:root:FL Epoch: 58 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567987
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671441
INFO:root:FL Epoch: 58 Norm Difference for worker 424 is 1.043952
INFO:root:FL Epoch: 58 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 424
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 58 Ends   ===================
INFO:root:Epoch:58 Global Model Test Loss:0.6093903306652518 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:58 Global Model Backdoor Test Loss:1.1104120810826619                             and Backdoor Test Accuracy:20.0 
INFO:root:=======================================================
INFO:root:================FL round 59 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 59 Workers Selected : [1518, 393, 1939, 1829, 1332, 626, 515, 190, 432, 872]
INFO:root:FL Epoch: 59 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 59 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 59 Training on worker :1518
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598324
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650041
INFO:root:FL Epoch: 59 Norm Difference for worker 1518 is 1.057373
INFO:root:FL Epoch: 59 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :393
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647397
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.715548
INFO:root:FL Epoch: 59 Norm Difference for worker 393 is 1.034302
INFO:root:FL Epoch: 59 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1939
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698244
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596498
INFO:root:FL Epoch: 59 Norm Difference for worker 1939 is 1.091561
INFO:root:FL Epoch: 59 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1829
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768866
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485331
INFO:root:FL Epoch: 59 Norm Difference for worker 1829 is 1.024696
INFO:root:FL Epoch: 59 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :1332
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.960032
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483414
INFO:root:FL Epoch: 59 Norm Difference for worker 1332 is 1.025501
INFO:root:FL Epoch: 59 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :626
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599496
INFO:root:Worker: 626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631516
INFO:root:FL Epoch: 59 Norm Difference for worker 626 is 1.041768
INFO:root:FL Epoch: 59 Done on worker:626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :515
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807778
INFO:root:Worker: 515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435800
INFO:root:FL Epoch: 59 Norm Difference for worker 515 is 1.049032
INFO:root:FL Epoch: 59 Done on worker:515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :190
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 190 Train Epoch: 0 [0/201 (0%)]	Loss: 0.854060
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 190 Train Epoch: 1 [0/201 (0%)]	Loss: 0.500262
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 59 Norm Difference for worker 190 is 1.051725
INFO:root:FL Epoch: 59 Done on worker:190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :432
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669108
INFO:root:Worker: 432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495810
INFO:root:FL Epoch: 59 Norm Difference for worker 432 is 0.999749
INFO:root:FL Epoch: 59 Done on worker:432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 59 Training on worker :872
INFO:root:FL Epoch: 59 Using Learning rate : 0.0445185898122355 
INFO:root:FL Epoch: 59 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541444
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529611
INFO:root:FL Epoch: 59 Norm Difference for worker 872 is 1.073217
INFO:root:FL Epoch: 59 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 432
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 59 Ends   ===================
INFO:root:Epoch:59 Global Model Test Loss:0.6142713813220754 and Test Accuracy:64.70588235294117 
INFO:root:Epoch:59 Global Model Backdoor Test Loss:1.3712262908617656                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 60 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 60 Workers Selected : [1539, 874, 994, 1205, 1214, 1221, 130, 141, 1627, 1921]
INFO:root:FL Epoch: 60 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 60 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 60 Training on worker :1539
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485218
INFO:root:Worker: 1539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522431
INFO:root:FL Epoch: 60 Norm Difference for worker 1539 is 1.143608
INFO:root:FL Epoch: 60 Done on worker:1539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :874
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749941
INFO:root:Worker: 874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488386
INFO:root:FL Epoch: 60 Norm Difference for worker 874 is 1.102342
INFO:root:FL Epoch: 60 Done on worker:874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :994
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717420
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507054
INFO:root:FL Epoch: 60 Norm Difference for worker 994 is 1.149297
INFO:root:FL Epoch: 60 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1205
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705455
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623966
INFO:root:FL Epoch: 60 Norm Difference for worker 1205 is 1.10483
INFO:root:FL Epoch: 60 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1214
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1214 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509974
INFO:root:Worker: 1214 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642425
INFO:root:FL Epoch: 60 Norm Difference for worker 1214 is 1.100696
INFO:root:FL Epoch: 60 Done on worker:1214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1221
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1221 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650038
INFO:root:Worker: 1221 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573123
INFO:root:FL Epoch: 60 Norm Difference for worker 1221 is 1.065172
INFO:root:FL Epoch: 60 Done on worker:1221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :130
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 130 Train Epoch: 0 [0/201 (0%)]	Loss: 0.570287
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 130 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419921
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 60 Norm Difference for worker 130 is 1.095373
INFO:root:FL Epoch: 60 Done on worker:130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :141
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 141 Train Epoch: 0 [0/201 (0%)]	Loss: 0.714840
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 141 Train Epoch: 1 [0/201 (0%)]	Loss: 0.519563
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 60 Norm Difference for worker 141 is 1.10145
INFO:root:FL Epoch: 60 Done on worker:141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1627
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.785178
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551159
INFO:root:FL Epoch: 60 Norm Difference for worker 1627 is 1.039554
INFO:root:FL Epoch: 60 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 60 Training on worker :1921
INFO:root:FL Epoch: 60 Using Learning rate : 0.04442955263261102 
INFO:root:FL Epoch: 60 Normal Training
INFO:root:Worker: 1921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.814647
INFO:root:Worker: 1921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547795
INFO:root:FL Epoch: 60 Norm Difference for worker 1921 is 1.06364
INFO:root:FL Epoch: 60 Done on worker:1921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1627
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 60 Ends   ===================
INFO:root:Epoch:60 Global Model Test Loss:0.6311567513381734 and Test Accuracy:65.58823529411765 
INFO:root:Epoch:60 Global Model Backdoor Test Loss:1.337949514389038                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 61 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 61 Workers Selected : [572, 974, 551, 1386, 1163, 792, 1056, 409, 1340, 935]
INFO:root:FL Epoch: 61 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 61 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 61 Training on worker :572
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763144
INFO:root:Worker: 572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438304
INFO:root:FL Epoch: 61 Norm Difference for worker 572 is 1.099648
INFO:root:FL Epoch: 61 Done on worker:572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :974
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 974 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374544
INFO:root:Worker: 974 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472094
INFO:root:FL Epoch: 61 Norm Difference for worker 974 is 1.07771
INFO:root:FL Epoch: 61 Done on worker:974
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :551
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646694
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621961
INFO:root:FL Epoch: 61 Norm Difference for worker 551 is 0.988658
INFO:root:FL Epoch: 61 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1386
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443209
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602474
INFO:root:FL Epoch: 61 Norm Difference for worker 1386 is 1.050858
INFO:root:FL Epoch: 61 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1163
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577744
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473383
INFO:root:FL Epoch: 61 Norm Difference for worker 1163 is 1.106773
INFO:root:FL Epoch: 61 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :792
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449365
INFO:root:Worker: 792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519980
INFO:root:FL Epoch: 61 Norm Difference for worker 792 is 1.030726
INFO:root:FL Epoch: 61 Done on worker:792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1056
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484267
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576722
INFO:root:FL Epoch: 61 Norm Difference for worker 1056 is 1.032751
INFO:root:FL Epoch: 61 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :409
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547874
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576150
INFO:root:FL Epoch: 61 Norm Difference for worker 409 is 1.058082
INFO:root:FL Epoch: 61 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :1340
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663070
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570653
INFO:root:FL Epoch: 61 Norm Difference for worker 1340 is 1.039297
INFO:root:FL Epoch: 61 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 61 Training on worker :935
INFO:root:FL Epoch: 61 Using Learning rate : 0.0443406935273458 
INFO:root:FL Epoch: 61 Normal Training
INFO:root:Worker: 935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567159
INFO:root:Worker: 935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533186
INFO:root:FL Epoch: 61 Norm Difference for worker 935 is 1.106155
INFO:root:FL Epoch: 61 Done on worker:935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 551
INFO:root:Norm of Aggregated Model: 5154.9853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 61 Ends   ===================
INFO:root:Epoch:61 Global Model Test Loss:0.6128082450698403 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:61 Global Model Backdoor Test Loss:1.2733933329582214                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 62 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 62 Workers Selected : [1088, 1241, 1200, 596, 397, 1394, 1498, 1026, 1826, 145]
INFO:root:FL Epoch: 62 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 62 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 62 Training on worker :1088
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1088 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521127
INFO:root:Worker: 1088 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510997
INFO:root:FL Epoch: 62 Norm Difference for worker 1088 is 1.010213
INFO:root:FL Epoch: 62 Done on worker:1088
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1241
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1241 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606658
INFO:root:Worker: 1241 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567848
INFO:root:FL Epoch: 62 Norm Difference for worker 1241 is 1.028668
INFO:root:FL Epoch: 62 Done on worker:1241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1200
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1200 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579768
INFO:root:Worker: 1200 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674400
INFO:root:FL Epoch: 62 Norm Difference for worker 1200 is 1.032962
INFO:root:FL Epoch: 62 Done on worker:1200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :596
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535882
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554682
INFO:root:FL Epoch: 62 Norm Difference for worker 596 is 1.073958
INFO:root:FL Epoch: 62 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :397
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725617
INFO:root:Worker: 397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549317
INFO:root:FL Epoch: 62 Norm Difference for worker 397 is 1.053853
INFO:root:FL Epoch: 62 Done on worker:397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1394
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768013
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536874
INFO:root:FL Epoch: 62 Norm Difference for worker 1394 is 1.185053
INFO:root:FL Epoch: 62 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1498
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560742
INFO:root:Worker: 1498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630996
INFO:root:FL Epoch: 62 Norm Difference for worker 1498 is 1.043246
INFO:root:FL Epoch: 62 Done on worker:1498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1026
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1026 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519240
INFO:root:Worker: 1026 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399668
INFO:root:FL Epoch: 62 Norm Difference for worker 1026 is 1.103458
INFO:root:FL Epoch: 62 Done on worker:1026
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :1826
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380339
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529794
INFO:root:FL Epoch: 62 Norm Difference for worker 1826 is 1.090157
INFO:root:FL Epoch: 62 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 62 Training on worker :145
INFO:root:FL Epoch: 62 Using Learning rate : 0.04425201214029111 
INFO:root:FL Epoch: 62 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.717129
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.487137
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 62 Norm Difference for worker 145 is 1.061075
INFO:root:FL Epoch: 62 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1200
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 62 Ends   ===================
INFO:root:Epoch:62 Global Model Test Loss:0.5982680671355304 and Test Accuracy:67.6470588235294 
INFO:root:Epoch:62 Global Model Backdoor Test Loss:1.0403173466523488                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 63 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 63 Workers Selected : [1129, 1047, 1125, 1528, 898, 459, 643, 1100, 1870, 1812]
INFO:root:FL Epoch: 63 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 63 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 63 Training on worker :1129
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1129 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753772
INFO:root:Worker: 1129 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630857
INFO:root:FL Epoch: 63 Norm Difference for worker 1129 is 0.894327
INFO:root:FL Epoch: 63 Done on worker:1129
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1047
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1047 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733557
INFO:root:Worker: 1047 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496927
INFO:root:FL Epoch: 63 Norm Difference for worker 1047 is 0.919982
INFO:root:FL Epoch: 63 Done on worker:1047
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1125
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566415
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561741
INFO:root:FL Epoch: 63 Norm Difference for worker 1125 is 0.929732
INFO:root:FL Epoch: 63 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1528
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505452
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400924
INFO:root:FL Epoch: 63 Norm Difference for worker 1528 is 1.050184
INFO:root:FL Epoch: 63 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :898
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526378
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504353
INFO:root:FL Epoch: 63 Norm Difference for worker 898 is 0.986715
INFO:root:FL Epoch: 63 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :459
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644958
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479593
INFO:root:FL Epoch: 63 Norm Difference for worker 459 is 1.030486
INFO:root:FL Epoch: 63 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :643
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597538
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672535
INFO:root:FL Epoch: 63 Norm Difference for worker 643 is 0.900152
INFO:root:FL Epoch: 63 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1100
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1100 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729471
INFO:root:Worker: 1100 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446506
INFO:root:FL Epoch: 63 Norm Difference for worker 1100 is 0.963457
INFO:root:FL Epoch: 63 Done on worker:1100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1870
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620499
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463275
INFO:root:FL Epoch: 63 Norm Difference for worker 1870 is 0.950497
INFO:root:FL Epoch: 63 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 63 Training on worker :1812
INFO:root:FL Epoch: 63 Using Learning rate : 0.044163508116010525 
INFO:root:FL Epoch: 63 Normal Training
INFO:root:Worker: 1812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624322
INFO:root:Worker: 1812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553886
INFO:root:FL Epoch: 63 Norm Difference for worker 1812 is 0.967851
INFO:root:FL Epoch: 63 Done on worker:1812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1129
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 63 Ends   ===================
INFO:root:Epoch:63 Global Model Test Loss:0.5899533138555639 and Test Accuracy:70.0 
INFO:root:Epoch:63 Global Model Backdoor Test Loss:1.0429975986480713                             and Backdoor Test Accuracy:20.0 
INFO:root:=======================================================
INFO:root:================FL round 64 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 64 Workers Selected : [1467, 284, 1291, 998, 1682, 1945, 870, 1113, 566, 1021]
INFO:root:FL Epoch: 64 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 64 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 64 Training on worker :1467
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756800
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521215
INFO:root:FL Epoch: 64 Norm Difference for worker 1467 is 0.93868
INFO:root:FL Epoch: 64 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :284
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.725077
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.526100
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 64 Norm Difference for worker 284 is 1.029188
INFO:root:FL Epoch: 64 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1291
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1291 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585689
INFO:root:Worker: 1291 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431432
INFO:root:FL Epoch: 64 Norm Difference for worker 1291 is 0.990664
INFO:root:FL Epoch: 64 Done on worker:1291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :998
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 998 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617040
INFO:root:Worker: 998 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511269
INFO:root:FL Epoch: 64 Norm Difference for worker 998 is 1.025214
INFO:root:FL Epoch: 64 Done on worker:998
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1682
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656133
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380841
INFO:root:FL Epoch: 64 Norm Difference for worker 1682 is 1.016114
INFO:root:FL Epoch: 64 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1945
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659758
INFO:root:Worker: 1945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565725
INFO:root:FL Epoch: 64 Norm Difference for worker 1945 is 0.962611
INFO:root:FL Epoch: 64 Done on worker:1945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :870
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744579
INFO:root:Worker: 870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.720626
INFO:root:FL Epoch: 64 Norm Difference for worker 870 is 1.001245
INFO:root:FL Epoch: 64 Done on worker:870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1113
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1113 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651258
INFO:root:Worker: 1113 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580470
INFO:root:FL Epoch: 64 Norm Difference for worker 1113 is 1.002151
INFO:root:FL Epoch: 64 Done on worker:1113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :566
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639008
INFO:root:Worker: 566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.720765
INFO:root:FL Epoch: 64 Norm Difference for worker 566 is 1.027694
INFO:root:FL Epoch: 64 Done on worker:566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 64 Training on worker :1021
INFO:root:FL Epoch: 64 Using Learning rate : 0.04407518109977851 
INFO:root:FL Epoch: 64 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478080
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547362
INFO:root:FL Epoch: 64 Norm Difference for worker 1021 is 0.982226
INFO:root:FL Epoch: 64 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1945
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 64 Ends   ===================
INFO:root:Epoch:64 Global Model Test Loss:0.5785126423134523 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:64 Global Model Backdoor Test Loss:0.9869601428508759                             and Backdoor Test Accuracy:30.0 
INFO:root:=======================================================
INFO:root:================FL round 65 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 65 Workers Selected : [784, 1044, 1724, 1263, 1314, 1313, 1783, 1779, 38, 1632]
INFO:root:FL Epoch: 65 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 65 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 65 Training on worker :784
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450593
INFO:root:Worker: 784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557677
INFO:root:FL Epoch: 65 Norm Difference for worker 784 is 1.050483
INFO:root:FL Epoch: 65 Done on worker:784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1044
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1044 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632469
INFO:root:Worker: 1044 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565708
INFO:root:FL Epoch: 65 Norm Difference for worker 1044 is 1.042453
INFO:root:FL Epoch: 65 Done on worker:1044
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1724
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660336
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651531
INFO:root:FL Epoch: 65 Norm Difference for worker 1724 is 1.100399
INFO:root:FL Epoch: 65 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1263
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1263 Train Epoch: 0 [0/200 (0%)]	Loss: 0.784613
INFO:root:Worker: 1263 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675973
INFO:root:FL Epoch: 65 Norm Difference for worker 1263 is 1.073157
INFO:root:FL Epoch: 65 Done on worker:1263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1314
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1314 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526385
INFO:root:Worker: 1314 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418864
INFO:root:FL Epoch: 65 Norm Difference for worker 1314 is 1.086655
INFO:root:FL Epoch: 65 Done on worker:1314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1313
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579838
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313913
INFO:root:FL Epoch: 65 Norm Difference for worker 1313 is 1.137054
INFO:root:FL Epoch: 65 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1783
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664532
INFO:root:Worker: 1783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524577
INFO:root:FL Epoch: 65 Norm Difference for worker 1783 is 1.133312
INFO:root:FL Epoch: 65 Done on worker:1783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1779
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655831
INFO:root:Worker: 1779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498377
INFO:root:FL Epoch: 65 Norm Difference for worker 1779 is 1.063185
INFO:root:FL Epoch: 65 Done on worker:1779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :38
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.624511
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.501164
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 65 Norm Difference for worker 38 is 1.008667
INFO:root:FL Epoch: 65 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 65 Training on worker :1632
INFO:root:FL Epoch: 65 Using Learning rate : 0.04398703073757895 
INFO:root:FL Epoch: 65 Normal Training
INFO:root:Worker: 1632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562377
INFO:root:Worker: 1632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480715
INFO:root:FL Epoch: 65 Norm Difference for worker 1632 is 1.077788
INFO:root:FL Epoch: 65 Done on worker:1632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 38
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 65 Ends   ===================
INFO:root:Epoch:65 Global Model Test Loss:0.5767682124586666 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:65 Global Model Backdoor Test Loss:1.000604122877121                             and Backdoor Test Accuracy:31.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 66 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 66 Workers Selected : [1180, 1592, 1737, 1220, 1283, 1538, 1700, 1300, 70, 804]
INFO:root:FL Epoch: 66 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 66 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 66 Training on worker :1180
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614284
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667124
INFO:root:FL Epoch: 66 Norm Difference for worker 1180 is 1.045997
INFO:root:FL Epoch: 66 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1592
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613447
INFO:root:Worker: 1592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.725220
INFO:root:FL Epoch: 66 Norm Difference for worker 1592 is 1.185941
INFO:root:FL Epoch: 66 Done on worker:1592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1737
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543343
INFO:root:Worker: 1737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570039
INFO:root:FL Epoch: 66 Norm Difference for worker 1737 is 1.0958
INFO:root:FL Epoch: 66 Done on worker:1737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1220
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574136
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564894
INFO:root:FL Epoch: 66 Norm Difference for worker 1220 is 1.070563
INFO:root:FL Epoch: 66 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1283
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1283 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512957
INFO:root:Worker: 1283 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458061
INFO:root:FL Epoch: 66 Norm Difference for worker 1283 is 1.099006
INFO:root:FL Epoch: 66 Done on worker:1283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1538
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.777202
INFO:root:Worker: 1538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537790
INFO:root:FL Epoch: 66 Norm Difference for worker 1538 is 1.088279
INFO:root:FL Epoch: 66 Done on worker:1538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1700
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753537
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342710
INFO:root:FL Epoch: 66 Norm Difference for worker 1700 is 1.043285
INFO:root:FL Epoch: 66 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :1300
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 1300 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712724
INFO:root:Worker: 1300 Train Epoch: 1 [0/200 (0%)]	Loss: 0.705061
INFO:root:FL Epoch: 66 Norm Difference for worker 1300 is 1.116632
INFO:root:FL Epoch: 66 Done on worker:1300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :70
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.879280
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.424475
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 66 Norm Difference for worker 70 is 1.001717
INFO:root:FL Epoch: 66 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 66 Training on worker :804
INFO:root:FL Epoch: 66 Using Learning rate : 0.04389905667610379 
INFO:root:FL Epoch: 66 Normal Training
INFO:root:Worker: 804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656567
INFO:root:Worker: 804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559398
INFO:root:FL Epoch: 66 Norm Difference for worker 804 is 1.122517
INFO:root:FL Epoch: 66 Done on worker:804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 70
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 66 Ends   ===================
INFO:root:Epoch:66 Global Model Test Loss:0.5927952212445876 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:66 Global Model Backdoor Test Loss:1.4573636849721272                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 67 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 67 Workers Selected : [433, 575, 1720, 570, 1195, 1406, 224, 445, 836, 1877]
INFO:root:FL Epoch: 67 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 67 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 67 Training on worker :433
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550068
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488736
INFO:root:FL Epoch: 67 Norm Difference for worker 433 is 1.187672
INFO:root:FL Epoch: 67 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :575
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703249
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638790
INFO:root:FL Epoch: 67 Norm Difference for worker 575 is 1.200818
INFO:root:FL Epoch: 67 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1720
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1720 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593624
INFO:root:Worker: 1720 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566448
INFO:root:FL Epoch: 67 Norm Difference for worker 1720 is 1.098855
INFO:root:FL Epoch: 67 Done on worker:1720
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :570
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706683
INFO:root:Worker: 570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643515
INFO:root:FL Epoch: 67 Norm Difference for worker 570 is 1.110114
INFO:root:FL Epoch: 67 Done on worker:570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1195
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609668
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492249
INFO:root:FL Epoch: 67 Norm Difference for worker 1195 is 1.137527
INFO:root:FL Epoch: 67 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1406
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.863279
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555266
INFO:root:FL Epoch: 67 Norm Difference for worker 1406 is 1.246084
INFO:root:FL Epoch: 67 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :224
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 224 Train Epoch: 0 [0/201 (0%)]	Loss: 0.557580
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 224 Train Epoch: 1 [0/201 (0%)]	Loss: 0.323888
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 67 Norm Difference for worker 224 is 1.192485
INFO:root:FL Epoch: 67 Done on worker:224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :445
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782964
INFO:root:Worker: 445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628848
INFO:root:FL Epoch: 67 Norm Difference for worker 445 is 1.204809
INFO:root:FL Epoch: 67 Done on worker:445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :836
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725367
INFO:root:Worker: 836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665086
INFO:root:FL Epoch: 67 Norm Difference for worker 836 is 1.127996
INFO:root:FL Epoch: 67 Done on worker:836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 67 Training on worker :1877
INFO:root:FL Epoch: 67 Using Learning rate : 0.04381125856275159 
INFO:root:FL Epoch: 67 Normal Training
INFO:root:Worker: 1877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563948
INFO:root:Worker: 1877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442258
INFO:root:FL Epoch: 67 Norm Difference for worker 1877 is 1.208462
INFO:root:FL Epoch: 67 Done on worker:1877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 570
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 67 Ends   ===================
INFO:root:Epoch:67 Global Model Test Loss:0.5689967274665833 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:67 Global Model Backdoor Test Loss:1.3085246284802754                             and Backdoor Test Accuracy:14.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 68 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 68 Workers Selected : [54, 1863, 712, 1378, 1204, 903, 1564, 1772, 1873, 1227]
INFO:root:FL Epoch: 68 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 68 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 68 Training on worker :54
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 54 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629341
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 54 Train Epoch: 1 [0/201 (0%)]	Loss: 0.596768
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 68 Norm Difference for worker 54 is 1.086035
INFO:root:FL Epoch: 68 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1863
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515518
INFO:root:Worker: 1863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425522
INFO:root:FL Epoch: 68 Norm Difference for worker 1863 is 1.035511
INFO:root:FL Epoch: 68 Done on worker:1863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :712
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367213
INFO:root:Worker: 712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633090
INFO:root:FL Epoch: 68 Norm Difference for worker 712 is 1.160463
INFO:root:FL Epoch: 68 Done on worker:712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1378
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660582
INFO:root:Worker: 1378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431816
INFO:root:FL Epoch: 68 Norm Difference for worker 1378 is 1.103591
INFO:root:FL Epoch: 68 Done on worker:1378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1204
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.822789
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468554
INFO:root:FL Epoch: 68 Norm Difference for worker 1204 is 1.07426
INFO:root:FL Epoch: 68 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :903
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735763
INFO:root:Worker: 903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478858
INFO:root:FL Epoch: 68 Norm Difference for worker 903 is 1.020776
INFO:root:FL Epoch: 68 Done on worker:903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1564
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537459
INFO:root:Worker: 1564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617350
INFO:root:FL Epoch: 68 Norm Difference for worker 1564 is 1.111476
INFO:root:FL Epoch: 68 Done on worker:1564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1772
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706388
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590707
INFO:root:FL Epoch: 68 Norm Difference for worker 1772 is 1.057113
INFO:root:FL Epoch: 68 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1873
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587517
INFO:root:Worker: 1873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433015
INFO:root:FL Epoch: 68 Norm Difference for worker 1873 is 1.133783
INFO:root:FL Epoch: 68 Done on worker:1873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 68 Training on worker :1227
INFO:root:FL Epoch: 68 Using Learning rate : 0.04372363604562608 
INFO:root:FL Epoch: 68 Normal Training
INFO:root:Worker: 1227 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574545
INFO:root:Worker: 1227 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610219
INFO:root:FL Epoch: 68 Norm Difference for worker 1227 is 1.094912
INFO:root:FL Epoch: 68 Done on worker:1227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1863
INFO:root:Norm of Aggregated Model: 5154.98583984375
INFO:root:Aggregating After Defense
INFO:root:================FL round 68 Ends   ===================
INFO:root:Epoch:68 Global Model Test Loss:0.5841712601044599 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:68 Global Model Backdoor Test Loss:1.4563050667444866                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 69 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 69 Workers Selected : [368, 1628, 73, 1261, 608, 1478, 809, 1325, 1306, 1354]
INFO:root:FL Epoch: 69 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 69 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 69 Training on worker :368
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571541
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461513
INFO:root:FL Epoch: 69 Norm Difference for worker 368 is 1.212361
INFO:root:FL Epoch: 69 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1628
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594230
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562611
INFO:root:FL Epoch: 69 Norm Difference for worker 1628 is 1.111295
INFO:root:FL Epoch: 69 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :73
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676854
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.409485
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 69 Norm Difference for worker 73 is 1.138593
INFO:root:FL Epoch: 69 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1261
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1261 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592789
INFO:root:Worker: 1261 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531477
INFO:root:FL Epoch: 69 Norm Difference for worker 1261 is 1.193581
INFO:root:FL Epoch: 69 Done on worker:1261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :608
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551132
INFO:root:Worker: 608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615322
INFO:root:FL Epoch: 69 Norm Difference for worker 608 is 1.153355
INFO:root:FL Epoch: 69 Done on worker:608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1478
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524552
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483277
INFO:root:FL Epoch: 69 Norm Difference for worker 1478 is 1.099323
INFO:root:FL Epoch: 69 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :809
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524430
INFO:root:Worker: 809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502537
INFO:root:FL Epoch: 69 Norm Difference for worker 809 is 1.181779
INFO:root:FL Epoch: 69 Done on worker:809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1325
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1325 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493651
INFO:root:Worker: 1325 Train Epoch: 1 [0/200 (0%)]	Loss: 0.689674
INFO:root:FL Epoch: 69 Norm Difference for worker 1325 is 1.185382
INFO:root:FL Epoch: 69 Done on worker:1325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1306
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1306 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676896
INFO:root:Worker: 1306 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404965
INFO:root:FL Epoch: 69 Norm Difference for worker 1306 is 1.201439
INFO:root:FL Epoch: 69 Done on worker:1306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 69 Training on worker :1354
INFO:root:FL Epoch: 69 Using Learning rate : 0.043636188773534826 
INFO:root:FL Epoch: 69 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532457
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423661
INFO:root:FL Epoch: 69 Norm Difference for worker 1354 is 1.23294
INFO:root:FL Epoch: 69 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 809
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 69 Ends   ===================
INFO:root:Epoch:69 Global Model Test Loss:0.5829544347875258 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:69 Global Model Backdoor Test Loss:1.331117033958435                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 70 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 70 Workers Selected : [2, 1106, 795, 898, 1082, 59, 191, 1322, 1608, 937]
INFO:root:FL Epoch: 70 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 70 Num points on workers: [201 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 70 Training on worker :2
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 2 Train Epoch: 0 [0/201 (0%)]	Loss: 0.712007
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 2 Train Epoch: 1 [0/201 (0%)]	Loss: 0.609758
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 70 Norm Difference for worker 2 is 1.001129
INFO:root:FL Epoch: 70 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1106
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1106 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632253
INFO:root:Worker: 1106 Train Epoch: 1 [0/200 (0%)]	Loss: 0.736601
INFO:root:FL Epoch: 70 Norm Difference for worker 1106 is 1.08017
INFO:root:FL Epoch: 70 Done on worker:1106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :795
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532403
INFO:root:Worker: 795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527167
INFO:root:FL Epoch: 70 Norm Difference for worker 795 is 1.045653
INFO:root:FL Epoch: 70 Done on worker:795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :898
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634792
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494018
INFO:root:FL Epoch: 70 Norm Difference for worker 898 is 1.072108
INFO:root:FL Epoch: 70 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1082
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1082 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623562
INFO:root:Worker: 1082 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581357
INFO:root:FL Epoch: 70 Norm Difference for worker 1082 is 1.051324
INFO:root:FL Epoch: 70 Done on worker:1082
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :59
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.464553
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.680121
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 70 Norm Difference for worker 59 is 1.062825
INFO:root:FL Epoch: 70 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :191
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.631948
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.497934
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 70 Norm Difference for worker 191 is 1.140241
INFO:root:FL Epoch: 70 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1322
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1322 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626761
INFO:root:Worker: 1322 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653643
INFO:root:FL Epoch: 70 Norm Difference for worker 1322 is 1.046919
INFO:root:FL Epoch: 70 Done on worker:1322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :1608
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587212
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401090
INFO:root:FL Epoch: 70 Norm Difference for worker 1608 is 1.084149
INFO:root:FL Epoch: 70 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 70 Training on worker :937
INFO:root:FL Epoch: 70 Using Learning rate : 0.04354891639598776 
INFO:root:FL Epoch: 70 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512809
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480072
INFO:root:FL Epoch: 70 Norm Difference for worker 937 is 1.09665
INFO:root:FL Epoch: 70 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 2
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 70 Ends   ===================
INFO:root:Epoch:70 Global Model Test Loss:0.5731035102816189 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:70 Global Model Backdoor Test Loss:1.3549032807350159                             and Backdoor Test Accuracy:16.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 71 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 71 Workers Selected : [466, 984, 1232, 1937, 1000, 1729, 1353, 607, 194, 1226]
INFO:root:FL Epoch: 71 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 71 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 71 Training on worker :466
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451907
INFO:root:Worker: 466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385630
INFO:root:FL Epoch: 71 Norm Difference for worker 466 is 1.092887
INFO:root:FL Epoch: 71 Done on worker:466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :984
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 984 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655760
INFO:root:Worker: 984 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469726
INFO:root:FL Epoch: 71 Norm Difference for worker 984 is 1.088202
INFO:root:FL Epoch: 71 Done on worker:984
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1232
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1232 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600181
INFO:root:Worker: 1232 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623111
INFO:root:FL Epoch: 71 Norm Difference for worker 1232 is 1.144988
INFO:root:FL Epoch: 71 Done on worker:1232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1937
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406865
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686476
INFO:root:FL Epoch: 71 Norm Difference for worker 1937 is 1.193652
INFO:root:FL Epoch: 71 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1000
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732611
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605498
INFO:root:FL Epoch: 71 Norm Difference for worker 1000 is 1.14812
INFO:root:FL Epoch: 71 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1729
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625700
INFO:root:Worker: 1729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666737
INFO:root:FL Epoch: 71 Norm Difference for worker 1729 is 1.215772
INFO:root:FL Epoch: 71 Done on worker:1729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1353
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579127
INFO:root:Worker: 1353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492621
INFO:root:FL Epoch: 71 Norm Difference for worker 1353 is 1.134405
INFO:root:FL Epoch: 71 Done on worker:1353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :607
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429265
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473888
INFO:root:FL Epoch: 71 Norm Difference for worker 607 is 1.05095
INFO:root:FL Epoch: 71 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :194
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 194 Train Epoch: 0 [0/201 (0%)]	Loss: 0.549866
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 194 Train Epoch: 1 [0/201 (0%)]	Loss: 0.621696
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 71 Norm Difference for worker 194 is 1.152351
INFO:root:FL Epoch: 71 Done on worker:194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 71 Training on worker :1226
INFO:root:FL Epoch: 71 Using Learning rate : 0.04346181856319578 
INFO:root:FL Epoch: 71 Normal Training
INFO:root:Worker: 1226 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592120
INFO:root:Worker: 1226 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502462
INFO:root:FL Epoch: 71 Norm Difference for worker 1226 is 1.166379
INFO:root:FL Epoch: 71 Done on worker:1226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 607
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 71 Ends   ===================
INFO:root:Epoch:71 Global Model Test Loss:0.5772236936232623 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:71 Global Model Backdoor Test Loss:1.3814117908477783                             and Backdoor Test Accuracy:17.5 
INFO:root:=======================================================
INFO:root:================FL round 72 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 72 Workers Selected : [1054, 1316, 269, 1086, 1222, 881, 1886, 649, 1904, 331]
INFO:root:FL Epoch: 72 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 72 Num points on workers: [200 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 72 Training on worker :1054
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1054 Train Epoch: 0 [0/200 (0%)]	Loss: 1.049223
INFO:root:Worker: 1054 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408588
INFO:root:FL Epoch: 72 Norm Difference for worker 1054 is 1.150872
INFO:root:FL Epoch: 72 Done on worker:1054
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1316
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707956
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435712
INFO:root:FL Epoch: 72 Norm Difference for worker 1316 is 1.106382
INFO:root:FL Epoch: 72 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :269
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 269 Train Epoch: 0 [0/201 (0%)]	Loss: 0.556369
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 269 Train Epoch: 1 [0/201 (0%)]	Loss: 0.495673
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 269 is 1.154258
INFO:root:FL Epoch: 72 Done on worker:269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1086
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459422
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510136
INFO:root:FL Epoch: 72 Norm Difference for worker 1086 is 1.122677
INFO:root:FL Epoch: 72 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1222
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1222 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686667
INFO:root:Worker: 1222 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421702
INFO:root:FL Epoch: 72 Norm Difference for worker 1222 is 1.142324
INFO:root:FL Epoch: 72 Done on worker:1222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :881
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479131
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543427
INFO:root:FL Epoch: 72 Norm Difference for worker 881 is 1.160911
INFO:root:FL Epoch: 72 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1886
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481072
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625149
INFO:root:FL Epoch: 72 Norm Difference for worker 1886 is 1.266769
INFO:root:FL Epoch: 72 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :649
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388854
INFO:root:Worker: 649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.716168
INFO:root:FL Epoch: 72 Norm Difference for worker 649 is 1.305101
INFO:root:FL Epoch: 72 Done on worker:649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :1904
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483674
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365309
INFO:root:FL Epoch: 72 Norm Difference for worker 1904 is 1.185151
INFO:root:FL Epoch: 72 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 72 Training on worker :331
INFO:root:FL Epoch: 72 Using Learning rate : 0.04337489492606939 
INFO:root:FL Epoch: 72 Normal Training
INFO:root:Worker: 331 Train Epoch: 0 [0/201 (0%)]	Loss: 0.501593
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 331 Train Epoch: 1 [0/201 (0%)]	Loss: 0.534846
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 72 Norm Difference for worker 331 is 1.158653
INFO:root:FL Epoch: 72 Done on worker:331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1316
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 72 Ends   ===================
INFO:root:Epoch:72 Global Model Test Loss:0.5888525107327629 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:72 Global Model Backdoor Test Loss:0.9603647192319235                             and Backdoor Test Accuracy:28.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 73 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 73 Workers Selected : [1915, 303, 1819, 1410, 1455, 1359, 699, 1199, 411, 1733]
INFO:root:FL Epoch: 73 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 73 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 73 Training on worker :1915
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779800
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607802
INFO:root:FL Epoch: 73 Norm Difference for worker 1915 is 0.917002
INFO:root:FL Epoch: 73 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :303
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 303 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581580
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 303 Train Epoch: 1 [0/201 (0%)]	Loss: 0.631509
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 73 Norm Difference for worker 303 is 0.977938
INFO:root:FL Epoch: 73 Done on worker:303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1819
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1819 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729976
INFO:root:Worker: 1819 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698490
INFO:root:FL Epoch: 73 Norm Difference for worker 1819 is 0.975075
INFO:root:FL Epoch: 73 Done on worker:1819
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1410
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520377
INFO:root:Worker: 1410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584483
INFO:root:FL Epoch: 73 Norm Difference for worker 1410 is 1.005935
INFO:root:FL Epoch: 73 Done on worker:1410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1455
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628550
INFO:root:Worker: 1455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542976
INFO:root:FL Epoch: 73 Norm Difference for worker 1455 is 0.945611
INFO:root:FL Epoch: 73 Done on worker:1455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1359
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673106
INFO:root:Worker: 1359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488753
INFO:root:FL Epoch: 73 Norm Difference for worker 1359 is 0.968838
INFO:root:FL Epoch: 73 Done on worker:1359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :699
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 699 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623247
INFO:root:Worker: 699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630360
INFO:root:FL Epoch: 73 Norm Difference for worker 699 is 0.959144
INFO:root:FL Epoch: 73 Done on worker:699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1199
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681536
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611660
INFO:root:FL Epoch: 73 Norm Difference for worker 1199 is 0.948454
INFO:root:FL Epoch: 73 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :411
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643708
INFO:root:Worker: 411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648426
INFO:root:FL Epoch: 73 Norm Difference for worker 411 is 0.992187
INFO:root:FL Epoch: 73 Done on worker:411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 73 Training on worker :1733
INFO:root:FL Epoch: 73 Using Learning rate : 0.04328814513621725 
INFO:root:FL Epoch: 73 Normal Training
INFO:root:Worker: 1733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679101
INFO:root:Worker: 1733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569426
INFO:root:FL Epoch: 73 Norm Difference for worker 1733 is 0.947566
INFO:root:FL Epoch: 73 Done on worker:1733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1915
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 73 Ends   ===================
INFO:root:Epoch:73 Global Model Test Loss:0.605772465467453 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:73 Global Model Backdoor Test Loss:0.9893878996372223                             and Backdoor Test Accuracy:28.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 74 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 74 Workers Selected : [1061, 1487, 1898, 1943, 1731, 366, 513, 1048, 675, 1126]
INFO:root:FL Epoch: 74 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 74 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 74 Training on worker :1061
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553923
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464642
INFO:root:FL Epoch: 74 Norm Difference for worker 1061 is 0.996565
INFO:root:FL Epoch: 74 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1487
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519833
INFO:root:Worker: 1487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427620
INFO:root:FL Epoch: 74 Norm Difference for worker 1487 is 1.074134
INFO:root:FL Epoch: 74 Done on worker:1487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1898
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484923
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560011
INFO:root:FL Epoch: 74 Norm Difference for worker 1898 is 1.01933
INFO:root:FL Epoch: 74 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1943
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589040
INFO:root:Worker: 1943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424576
INFO:root:FL Epoch: 74 Norm Difference for worker 1943 is 0.997202
INFO:root:FL Epoch: 74 Done on worker:1943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1731
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700489
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595997
INFO:root:FL Epoch: 74 Norm Difference for worker 1731 is 0.992088
INFO:root:FL Epoch: 74 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :366
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526997
INFO:root:Worker: 366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542596
INFO:root:FL Epoch: 74 Norm Difference for worker 366 is 1.062478
INFO:root:FL Epoch: 74 Done on worker:366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :513
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609590
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.720362
INFO:root:FL Epoch: 74 Norm Difference for worker 513 is 1.038192
INFO:root:FL Epoch: 74 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1048
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1048 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802306
INFO:root:Worker: 1048 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625836
INFO:root:FL Epoch: 74 Norm Difference for worker 1048 is 1.076586
INFO:root:FL Epoch: 74 Done on worker:1048
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :675
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 675 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528525
INFO:root:Worker: 675 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598965
INFO:root:FL Epoch: 74 Norm Difference for worker 675 is 1.074661
INFO:root:FL Epoch: 74 Done on worker:675
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 74 Training on worker :1126
INFO:root:FL Epoch: 74 Using Learning rate : 0.04320156884594482 
INFO:root:FL Epoch: 74 Normal Training
INFO:root:Worker: 1126 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681430
INFO:root:Worker: 1126 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583826
INFO:root:FL Epoch: 74 Norm Difference for worker 1126 is 1.007509
INFO:root:FL Epoch: 74 Done on worker:1126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1731
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 74 Ends   ===================
INFO:root:Epoch:74 Global Model Test Loss:0.6051636127864614 and Test Accuracy:67.05882352941177 
INFO:root:Epoch:74 Global Model Backdoor Test Loss:1.5581153233846028                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 75 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 75 Workers Selected : [1138, 802, 1838, 1483, 532, 1411, 1237, 1598, 977, 885]
INFO:root:FL Epoch: 75 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 75 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 75 Training on worker :1138
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698305
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482329
INFO:root:FL Epoch: 75 Norm Difference for worker 1138 is 1.117645
INFO:root:FL Epoch: 75 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :802
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501693
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668347
INFO:root:FL Epoch: 75 Norm Difference for worker 802 is 1.085179
INFO:root:FL Epoch: 75 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1838
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631475
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420166
INFO:root:FL Epoch: 75 Norm Difference for worker 1838 is 1.023524
INFO:root:FL Epoch: 75 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1483
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553836
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.700674
INFO:root:FL Epoch: 75 Norm Difference for worker 1483 is 1.081299
INFO:root:FL Epoch: 75 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :532
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.860101
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527119
INFO:root:FL Epoch: 75 Norm Difference for worker 532 is 1.09157
INFO:root:FL Epoch: 75 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1411
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691151
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634997
INFO:root:FL Epoch: 75 Norm Difference for worker 1411 is 1.057491
INFO:root:FL Epoch: 75 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1237
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697541
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.738418
INFO:root:FL Epoch: 75 Norm Difference for worker 1237 is 1.079798
INFO:root:FL Epoch: 75 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :1598
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.856907
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514451
INFO:root:FL Epoch: 75 Norm Difference for worker 1598 is 1.019386
INFO:root:FL Epoch: 75 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :977
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593817
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595552
INFO:root:FL Epoch: 75 Norm Difference for worker 977 is 1.102111
INFO:root:FL Epoch: 75 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 75 Training on worker :885
INFO:root:FL Epoch: 75 Using Learning rate : 0.043115165708252925 
INFO:root:FL Epoch: 75 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534870
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.825441
INFO:root:FL Epoch: 75 Norm Difference for worker 885 is 1.117407
INFO:root:FL Epoch: 75 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1838
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 75 Ends   ===================
INFO:root:Epoch:75 Global Model Test Loss:0.5904427766799927 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:75 Global Model Backdoor Test Loss:1.1357674797375996                             and Backdoor Test Accuracy:25.0 
INFO:root:=======================================================
INFO:root:================FL round 76 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 76 Workers Selected : [15, 357, 96, 634, 641, 1474, 219, 1205, 225, 1260]
INFO:root:FL Epoch: 76 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 76 Num points on workers: [201 200 201 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 76 Training on worker :15
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.455600
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.545791
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 15 is 1.100079
INFO:root:FL Epoch: 76 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :357
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534547
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465084
INFO:root:FL Epoch: 76 Norm Difference for worker 357 is 1.022637
INFO:root:FL Epoch: 76 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :96
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 96 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687852
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 96 Train Epoch: 1 [0/201 (0%)]	Loss: 0.528260
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 96 is 1.108199
INFO:root:FL Epoch: 76 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :634
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554601
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535336
INFO:root:FL Epoch: 76 Norm Difference for worker 634 is 1.103159
INFO:root:FL Epoch: 76 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :641
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577854
INFO:root:Worker: 641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549554
INFO:root:FL Epoch: 76 Norm Difference for worker 641 is 1.165399
INFO:root:FL Epoch: 76 Done on worker:641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1474
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615340
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662421
INFO:root:FL Epoch: 76 Norm Difference for worker 1474 is 1.081426
INFO:root:FL Epoch: 76 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :219
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 219 Train Epoch: 0 [0/201 (0%)]	Loss: 0.649454
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 219 Train Epoch: 1 [0/201 (0%)]	Loss: 0.474530
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 219 is 1.042201
INFO:root:FL Epoch: 76 Done on worker:219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1205
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1205 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439230
INFO:root:Worker: 1205 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527536
INFO:root:FL Epoch: 76 Norm Difference for worker 1205 is 1.088686
INFO:root:FL Epoch: 76 Done on worker:1205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :225
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 225 Train Epoch: 0 [0/201 (0%)]	Loss: 0.609641
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 225 Train Epoch: 1 [0/201 (0%)]	Loss: 0.514208
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 76 Norm Difference for worker 225 is 1.115402
INFO:root:FL Epoch: 76 Done on worker:225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 76 Training on worker :1260
INFO:root:FL Epoch: 76 Using Learning rate : 0.04302893537683642 
INFO:root:FL Epoch: 76 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538605
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476135
INFO:root:FL Epoch: 76 Norm Difference for worker 1260 is 1.096825
INFO:root:FL Epoch: 76 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 357
INFO:root:Norm of Aggregated Model: 5154.986328125
INFO:root:Aggregating After Defense
INFO:root:================FL round 76 Ends   ===================
INFO:root:Epoch:76 Global Model Test Loss:0.5786815145436455 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:76 Global Model Backdoor Test Loss:1.2889635761578877                             and Backdoor Test Accuracy:18.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 77 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 77 Workers Selected : [1079, 1470, 301, 1255, 958, 201, 293, 180, 79, 1407]
INFO:root:FL Epoch: 77 Fraction of points on each worker in this round: [0.09975062 0.09975062 0.10024938 0.09975062 0.09975062 0.10024938
 0.10024938 0.10024938 0.10024938 0.09975062]
INFO:root:FL Epoch: 77 Num points on workers: [200 200 201 200 200 201 201 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 77 Training on worker :1079
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1079 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618342
INFO:root:Worker: 1079 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566496
INFO:root:FL Epoch: 77 Norm Difference for worker 1079 is 1.034405
INFO:root:FL Epoch: 77 Done on worker:1079
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1470
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450054
INFO:root:Worker: 1470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635102
INFO:root:FL Epoch: 77 Norm Difference for worker 1470 is 1.013698
INFO:root:FL Epoch: 77 Done on worker:1470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :301
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.736899
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.440520
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 301 is 1.021633
INFO:root:FL Epoch: 77 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1255
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455289
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542152
INFO:root:FL Epoch: 77 Norm Difference for worker 1255 is 1.080474
INFO:root:FL Epoch: 77 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :958
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603472
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639308
INFO:root:FL Epoch: 77 Norm Difference for worker 958 is 1.043262
INFO:root:FL Epoch: 77 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :201
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.468522
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.464534
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 201 is 0.98821
INFO:root:FL Epoch: 77 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :293
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 293 Train Epoch: 0 [0/201 (0%)]	Loss: 0.739977
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 293 Train Epoch: 1 [0/201 (0%)]	Loss: 0.600852
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 293 is 1.041056
INFO:root:FL Epoch: 77 Done on worker:293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :180
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.538508
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.585114
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 180 is 1.073455
INFO:root:FL Epoch: 77 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :79
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.551965
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.427631
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 77 Norm Difference for worker 79 is 0.979895
INFO:root:FL Epoch: 77 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 77 Training on worker :1407
INFO:root:FL Epoch: 77 Using Learning rate : 0.04294287750608275 
INFO:root:FL Epoch: 77 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597292
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448585
INFO:root:FL Epoch: 77 Norm Difference for worker 1407 is 0.998162
INFO:root:FL Epoch: 77 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1470
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 77 Ends   ===================
INFO:root:Epoch:77 Global Model Test Loss:0.5828477635103113 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:77 Global Model Backdoor Test Loss:1.3444640040397644                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 78 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 78 Workers Selected : [725, 1725, 1451, 1094, 739, 661, 346, 708, 1322, 129]
INFO:root:FL Epoch: 78 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 78 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 78 Training on worker :725
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689116
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562940
INFO:root:FL Epoch: 78 Norm Difference for worker 725 is 1.107696
INFO:root:FL Epoch: 78 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1725
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549973
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618837
INFO:root:FL Epoch: 78 Norm Difference for worker 1725 is 1.14655
INFO:root:FL Epoch: 78 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1451
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615777
INFO:root:Worker: 1451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471697
INFO:root:FL Epoch: 78 Norm Difference for worker 1451 is 1.099451
INFO:root:FL Epoch: 78 Done on worker:1451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1094
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1094 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805321
INFO:root:Worker: 1094 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610205
INFO:root:FL Epoch: 78 Norm Difference for worker 1094 is 1.02277
INFO:root:FL Epoch: 78 Done on worker:1094
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :739
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 739 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582373
INFO:root:Worker: 739 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671400
INFO:root:FL Epoch: 78 Norm Difference for worker 739 is 1.11231
INFO:root:FL Epoch: 78 Done on worker:739
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :661
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 661 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576401
INFO:root:Worker: 661 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531251
INFO:root:FL Epoch: 78 Norm Difference for worker 661 is 1.15501
INFO:root:FL Epoch: 78 Done on worker:661
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :346
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462220
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556943
INFO:root:FL Epoch: 78 Norm Difference for worker 346 is 1.124071
INFO:root:FL Epoch: 78 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :708
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552186
INFO:root:Worker: 708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499436
INFO:root:FL Epoch: 78 Norm Difference for worker 708 is 1.079996
INFO:root:FL Epoch: 78 Done on worker:708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :1322
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 1322 Train Epoch: 0 [0/200 (0%)]	Loss: 0.964720
INFO:root:Worker: 1322 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610563
INFO:root:FL Epoch: 78 Norm Difference for worker 1322 is 1.094832
INFO:root:FL Epoch: 78 Done on worker:1322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 78 Training on worker :129
INFO:root:FL Epoch: 78 Using Learning rate : 0.042856991751070585 
INFO:root:FL Epoch: 78 Normal Training
INFO:root:Worker: 129 Train Epoch: 0 [0/201 (0%)]	Loss: 0.613734
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 129 Train Epoch: 1 [0/201 (0%)]	Loss: 0.516507
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 78 Norm Difference for worker 129 is 1.074264
INFO:root:FL Epoch: 78 Done on worker:129
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1094
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 78 Ends   ===================
INFO:root:Epoch:78 Global Model Test Loss:0.6023405281936421 and Test Accuracy:67.05882352941177 
INFO:root:Epoch:78 Global Model Backdoor Test Loss:1.355672001838684                             and Backdoor Test Accuracy:7.5 
INFO:root:=======================================================
INFO:root:================FL round 79 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 79 Workers Selected : [1714, 1307, 230, 892, 725, 1049, 1303, 511, 1853, 442]
INFO:root:FL Epoch: 79 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 79 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 79 Training on worker :1714
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1714 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527987
INFO:root:Worker: 1714 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524291
INFO:root:FL Epoch: 79 Norm Difference for worker 1714 is 1.005962
INFO:root:FL Epoch: 79 Done on worker:1714
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1307
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653620
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614985
INFO:root:FL Epoch: 79 Norm Difference for worker 1307 is 0.953403
INFO:root:FL Epoch: 79 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :230
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 230 Train Epoch: 0 [0/201 (0%)]	Loss: 0.547507
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 230 Train Epoch: 1 [0/201 (0%)]	Loss: 0.549788
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 79 Norm Difference for worker 230 is 0.938899
INFO:root:FL Epoch: 79 Done on worker:230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :892
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554607
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587656
INFO:root:FL Epoch: 79 Norm Difference for worker 892 is 0.903752
INFO:root:FL Epoch: 79 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :725
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626768
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584380
INFO:root:FL Epoch: 79 Norm Difference for worker 725 is 0.931525
INFO:root:FL Epoch: 79 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1049
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1049 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611293
INFO:root:Worker: 1049 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575701
INFO:root:FL Epoch: 79 Norm Difference for worker 1049 is 0.871125
INFO:root:FL Epoch: 79 Done on worker:1049
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1303
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569027
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530783
INFO:root:FL Epoch: 79 Norm Difference for worker 1303 is 0.990795
INFO:root:FL Epoch: 79 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :511
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543383
INFO:root:Worker: 511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454137
INFO:root:FL Epoch: 79 Norm Difference for worker 511 is 0.994501
INFO:root:FL Epoch: 79 Done on worker:511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :1853
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557901
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540480
INFO:root:FL Epoch: 79 Norm Difference for worker 1853 is 0.952673
INFO:root:FL Epoch: 79 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 79 Training on worker :442
INFO:root:FL Epoch: 79 Using Learning rate : 0.04277127776756844 
INFO:root:FL Epoch: 79 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560545
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596532
INFO:root:FL Epoch: 79 Norm Difference for worker 442 is 0.930953
INFO:root:FL Epoch: 79 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1049
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 79 Ends   ===================
INFO:root:Epoch:79 Global Model Test Loss:0.5847804861910203 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:79 Global Model Backdoor Test Loss:1.3975139458974202                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 80 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 80 Workers Selected : [611, 1586, 1335, 1086, 217, 1761, 1610, 551, 268, 1838]
INFO:root:FL Epoch: 80 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 80 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 80 Training on worker :611
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.765278
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620167
INFO:root:FL Epoch: 80 Norm Difference for worker 611 is 1.050089
INFO:root:FL Epoch: 80 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1586
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490836
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502093
INFO:root:FL Epoch: 80 Norm Difference for worker 1586 is 1.045134
INFO:root:FL Epoch: 80 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1335
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709992
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552848
INFO:root:FL Epoch: 80 Norm Difference for worker 1335 is 1.040237
INFO:root:FL Epoch: 80 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1086
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1086 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546984
INFO:root:Worker: 1086 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456922
INFO:root:FL Epoch: 80 Norm Difference for worker 1086 is 1.003785
INFO:root:FL Epoch: 80 Done on worker:1086
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :217
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 217 Train Epoch: 0 [0/201 (0%)]	Loss: 0.664174
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 217 Train Epoch: 1 [0/201 (0%)]	Loss: 0.398901
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 80 Norm Difference for worker 217 is 1.061863
INFO:root:FL Epoch: 80 Done on worker:217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1761
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659463
INFO:root:Worker: 1761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515610
INFO:root:FL Epoch: 80 Norm Difference for worker 1761 is 1.138408
INFO:root:FL Epoch: 80 Done on worker:1761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1610
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725514
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673610
INFO:root:FL Epoch: 80 Norm Difference for worker 1610 is 1.016921
INFO:root:FL Epoch: 80 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :551
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394263
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626558
INFO:root:FL Epoch: 80 Norm Difference for worker 551 is 0.983655
INFO:root:FL Epoch: 80 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :268
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 268 Train Epoch: 0 [0/201 (0%)]	Loss: 0.621844
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 268 Train Epoch: 1 [0/201 (0%)]	Loss: 0.517894
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 80 Norm Difference for worker 268 is 0.990615
INFO:root:FL Epoch: 80 Done on worker:268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 80 Training on worker :1838
INFO:root:FL Epoch: 80 Using Learning rate : 0.04268573521203331 
INFO:root:FL Epoch: 80 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374765
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475213
INFO:root:FL Epoch: 80 Norm Difference for worker 1838 is 1.002228
INFO:root:FL Epoch: 80 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 268
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 80 Ends   ===================
INFO:root:Epoch:80 Global Model Test Loss:0.5919871978900012 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:80 Global Model Backdoor Test Loss:1.3001830577850342                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 81 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 81 Workers Selected : [1186, 1816, 1050, 105, 190, 1693, 1897, 405, 673, 155]
INFO:root:FL Epoch: 81 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 81 Num points on workers: [200 200 200 201 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 81 Training on worker :1186
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.824219
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506682
INFO:root:FL Epoch: 81 Norm Difference for worker 1186 is 1.016876
INFO:root:FL Epoch: 81 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1816
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578606
INFO:root:Worker: 1816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.761495
INFO:root:FL Epoch: 81 Norm Difference for worker 1816 is 1.016453
INFO:root:FL Epoch: 81 Done on worker:1816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1050
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1050 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433814
INFO:root:Worker: 1050 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612183
INFO:root:FL Epoch: 81 Norm Difference for worker 1050 is 1.031253
INFO:root:FL Epoch: 81 Done on worker:1050
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :105
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.658138
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.590243
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 81 Norm Difference for worker 105 is 1.048275
INFO:root:FL Epoch: 81 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :190
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 190 Train Epoch: 0 [0/201 (0%)]	Loss: 0.755715
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 190 Train Epoch: 1 [0/201 (0%)]	Loss: 0.635656
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 81 Norm Difference for worker 190 is 1.05687
INFO:root:FL Epoch: 81 Done on worker:190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1693
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678711
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562459
INFO:root:FL Epoch: 81 Norm Difference for worker 1693 is 1.037603
INFO:root:FL Epoch: 81 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :1897
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 1897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594972
INFO:root:Worker: 1897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588371
INFO:root:FL Epoch: 81 Norm Difference for worker 1897 is 1.049973
INFO:root:FL Epoch: 81 Done on worker:1897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :405
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553366
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399096
INFO:root:FL Epoch: 81 Norm Difference for worker 405 is 1.024518
INFO:root:FL Epoch: 81 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :673
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570974
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.746606
INFO:root:FL Epoch: 81 Norm Difference for worker 673 is 1.066351
INFO:root:FL Epoch: 81 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 81 Training on worker :155
INFO:root:FL Epoch: 81 Using Learning rate : 0.04260036374160924 
INFO:root:FL Epoch: 81 Normal Training
INFO:root:Worker: 155 Train Epoch: 0 [0/201 (0%)]	Loss: 0.502239
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 155 Train Epoch: 1 [0/201 (0%)]	Loss: 0.471176
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 81 Norm Difference for worker 155 is 1.055515
INFO:root:FL Epoch: 81 Done on worker:155
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1186
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 81 Ends   ===================
INFO:root:Epoch:81 Global Model Test Loss:0.5782712417490342 and Test Accuracy:70.0 
INFO:root:Epoch:81 Global Model Backdoor Test Loss:1.437925636768341                             and Backdoor Test Accuracy:8.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 82 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 82 Workers Selected : [1486, 1071, 1840, 542, 212, 1019, 1135, 336, 455, 1920]
INFO:root:FL Epoch: 82 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 82 Num points on workers: [200 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 82 Training on worker :1486
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633486
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619631
INFO:root:FL Epoch: 82 Norm Difference for worker 1486 is 1.053166
INFO:root:FL Epoch: 82 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1071
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1071 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614577
INFO:root:Worker: 1071 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581304
INFO:root:FL Epoch: 82 Norm Difference for worker 1071 is 1.070217
INFO:root:FL Epoch: 82 Done on worker:1071
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1840
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643590
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.779858
INFO:root:FL Epoch: 82 Norm Difference for worker 1840 is 1.008978
INFO:root:FL Epoch: 82 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :542
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515492
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407303
INFO:root:FL Epoch: 82 Norm Difference for worker 542 is 1.059246
INFO:root:FL Epoch: 82 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :212
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.716018
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.586003
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 212 is 1.10538
INFO:root:FL Epoch: 82 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1019
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1019 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596459
INFO:root:Worker: 1019 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567140
INFO:root:FL Epoch: 82 Norm Difference for worker 1019 is 1.04498
INFO:root:FL Epoch: 82 Done on worker:1019
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1135
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1135 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678068
INFO:root:Worker: 1135 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680556
INFO:root:FL Epoch: 82 Norm Difference for worker 1135 is 1.051945
INFO:root:FL Epoch: 82 Done on worker:1135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :336
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 336 Train Epoch: 0 [0/201 (0%)]	Loss: 0.510075
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 336 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446917
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 82 Norm Difference for worker 336 is 0.985091
INFO:root:FL Epoch: 82 Done on worker:336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :455
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697689
INFO:root:Worker: 455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598756
INFO:root:FL Epoch: 82 Norm Difference for worker 455 is 1.084813
INFO:root:FL Epoch: 82 Done on worker:455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 82 Training on worker :1920
INFO:root:FL Epoch: 82 Using Learning rate : 0.04251516301412602 
INFO:root:FL Epoch: 82 Normal Training
INFO:root:Worker: 1920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535184
INFO:root:Worker: 1920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640998
INFO:root:FL Epoch: 82 Norm Difference for worker 1920 is 1.005671
INFO:root:FL Epoch: 82 Done on worker:1920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 336
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 82 Ends   ===================
INFO:root:Epoch:82 Global Model Test Loss:0.5847971562077018 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:82 Global Model Backdoor Test Loss:1.4760158856709797                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 83 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 83 Workers Selected : [1047, 481, 1351, 1279, 927, 433, 1581, 1292, 78, 1551]
INFO:root:FL Epoch: 83 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 83 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 83 Training on worker :1047
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1047 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757208
INFO:root:Worker: 1047 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536264
INFO:root:FL Epoch: 83 Norm Difference for worker 1047 is 1.215454
INFO:root:FL Epoch: 83 Done on worker:1047
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :481
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601330
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525143
INFO:root:FL Epoch: 83 Norm Difference for worker 481 is 1.236903
INFO:root:FL Epoch: 83 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1351
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813482
INFO:root:Worker: 1351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.876764
INFO:root:FL Epoch: 83 Norm Difference for worker 1351 is 1.155328
INFO:root:FL Epoch: 83 Done on worker:1351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1279
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1279 Train Epoch: 0 [0/200 (0%)]	Loss: 0.864754
INFO:root:Worker: 1279 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455238
INFO:root:FL Epoch: 83 Norm Difference for worker 1279 is 1.159636
INFO:root:FL Epoch: 83 Done on worker:1279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :927
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613995
INFO:root:Worker: 927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460257
INFO:root:FL Epoch: 83 Norm Difference for worker 927 is 1.161224
INFO:root:FL Epoch: 83 Done on worker:927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :433
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710135
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494522
INFO:root:FL Epoch: 83 Norm Difference for worker 433 is 1.255277
INFO:root:FL Epoch: 83 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1581
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676601
INFO:root:Worker: 1581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389699
INFO:root:FL Epoch: 83 Norm Difference for worker 1581 is 1.231923
INFO:root:FL Epoch: 83 Done on worker:1581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1292
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1292 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669961
INFO:root:Worker: 1292 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532481
INFO:root:FL Epoch: 83 Norm Difference for worker 1292 is 1.204679
INFO:root:FL Epoch: 83 Done on worker:1292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :78
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.416767
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.491581
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 83 Norm Difference for worker 78 is 1.129134
INFO:root:FL Epoch: 83 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 83 Training on worker :1551
INFO:root:FL Epoch: 83 Using Learning rate : 0.04243013268809777 
INFO:root:FL Epoch: 83 Normal Training
INFO:root:Worker: 1551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544247
INFO:root:Worker: 1551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612301
INFO:root:FL Epoch: 83 Norm Difference for worker 1551 is 1.192197
INFO:root:FL Epoch: 83 Done on worker:1551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 78
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 83 Ends   ===================
INFO:root:Epoch:83 Global Model Test Loss:0.5998337444137124 and Test Accuracy:67.6470588235294 
INFO:root:Epoch:83 Global Model Backdoor Test Loss:1.4241379499435425                             and Backdoor Test Accuracy:10.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 84 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 84 Workers Selected : [1748, 1571, 1610, 1107, 1165, 138, 1307, 528, 210, 1354]
INFO:root:FL Epoch: 84 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 84 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 84 Training on worker :1748
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630298
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589405
INFO:root:FL Epoch: 84 Norm Difference for worker 1748 is 1.058672
INFO:root:FL Epoch: 84 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1571
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736886
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479783
INFO:root:FL Epoch: 84 Norm Difference for worker 1571 is 1.043139
INFO:root:FL Epoch: 84 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1610
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715926
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526036
INFO:root:FL Epoch: 84 Norm Difference for worker 1610 is 1.077353
INFO:root:FL Epoch: 84 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1107
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1107 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463739
INFO:root:Worker: 1107 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454116
INFO:root:FL Epoch: 84 Norm Difference for worker 1107 is 1.126465
INFO:root:FL Epoch: 84 Done on worker:1107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1165
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508845
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444153
INFO:root:FL Epoch: 84 Norm Difference for worker 1165 is 1.100402
INFO:root:FL Epoch: 84 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :138
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603979
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.549971
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 138 is 1.039974
INFO:root:FL Epoch: 84 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1307
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566677
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708862
INFO:root:FL Epoch: 84 Norm Difference for worker 1307 is 1.074581
INFO:root:FL Epoch: 84 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :528
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515995
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665263
INFO:root:FL Epoch: 84 Norm Difference for worker 528 is 1.074328
INFO:root:FL Epoch: 84 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :210
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 210 Train Epoch: 0 [0/201 (0%)]	Loss: 0.586471
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 210 Train Epoch: 1 [0/201 (0%)]	Loss: 0.652326
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 84 Norm Difference for worker 210 is 1.017516
INFO:root:FL Epoch: 84 Done on worker:210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 84 Training on worker :1354
INFO:root:FL Epoch: 84 Using Learning rate : 0.04234527242272157 
INFO:root:FL Epoch: 84 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640067
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579102
INFO:root:FL Epoch: 84 Norm Difference for worker 1354 is 1.038177
INFO:root:FL Epoch: 84 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 138
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 84 Ends   ===================
INFO:root:Epoch:84 Global Model Test Loss:0.5987609694985783 and Test Accuracy:66.76470588235294 
INFO:root:Epoch:84 Global Model Backdoor Test Loss:1.181862711906433                             and Backdoor Test Accuracy:20.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 85 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 85 Workers Selected : [1331, 211, 1476, 1318, 749, 1936, 1164, 247, 878, 856]
INFO:root:FL Epoch: 85 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 85 Num points on workers: [200 201 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 85 Training on worker :1331
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1331 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664392
INFO:root:Worker: 1331 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589539
INFO:root:FL Epoch: 85 Norm Difference for worker 1331 is 0.989664
INFO:root:FL Epoch: 85 Done on worker:1331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :211
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.552196
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.685376
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 85 Norm Difference for worker 211 is 1.023956
INFO:root:FL Epoch: 85 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1476
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634979
INFO:root:Worker: 1476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587444
INFO:root:FL Epoch: 85 Norm Difference for worker 1476 is 0.993975
INFO:root:FL Epoch: 85 Done on worker:1476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1318
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592077
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681851
INFO:root:FL Epoch: 85 Norm Difference for worker 1318 is 1.108001
INFO:root:FL Epoch: 85 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :749
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 749 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495566
INFO:root:Worker: 749 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472155
INFO:root:FL Epoch: 85 Norm Difference for worker 749 is 1.023112
INFO:root:FL Epoch: 85 Done on worker:749
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1936
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448148
INFO:root:Worker: 1936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531142
INFO:root:FL Epoch: 85 Norm Difference for worker 1936 is 0.997061
INFO:root:FL Epoch: 85 Done on worker:1936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :1164
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 1164 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711428
INFO:root:Worker: 1164 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512502
INFO:root:FL Epoch: 85 Norm Difference for worker 1164 is 1.024797
INFO:root:FL Epoch: 85 Done on worker:1164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :247
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.521272
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.471068
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 85 Norm Difference for worker 247 is 1.002691
INFO:root:FL Epoch: 85 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :878
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698103
INFO:root:Worker: 878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640750
INFO:root:FL Epoch: 85 Norm Difference for worker 878 is 1.008995
INFO:root:FL Epoch: 85 Done on worker:878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 85 Training on worker :856
INFO:root:FL Epoch: 85 Using Learning rate : 0.042260581877876124 
INFO:root:FL Epoch: 85 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608960
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551039
INFO:root:FL Epoch: 85 Norm Difference for worker 856 is 1.009503
INFO:root:FL Epoch: 85 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1936
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 85 Ends   ===================
INFO:root:Epoch:85 Global Model Test Loss:0.5991613268852234 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:85 Global Model Backdoor Test Loss:1.4081381956736247                             and Backdoor Test Accuracy:17.5 
INFO:root:=======================================================
INFO:root:================FL round 86 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 86 Workers Selected : [1250, 726, 513, 1657, 767, 1017, 793, 1475, 1148, 166]
INFO:root:FL Epoch: 86 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 86 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 86 Training on worker :1250
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1250 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450802
INFO:root:Worker: 1250 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500296
INFO:root:FL Epoch: 86 Norm Difference for worker 1250 is 1.162227
INFO:root:FL Epoch: 86 Done on worker:1250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :726
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587839
INFO:root:Worker: 726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481314
INFO:root:FL Epoch: 86 Norm Difference for worker 726 is 1.19866
INFO:root:FL Epoch: 86 Done on worker:726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :513
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781643
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537196
INFO:root:FL Epoch: 86 Norm Difference for worker 513 is 1.197835
INFO:root:FL Epoch: 86 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1657
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684356
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418919
INFO:root:FL Epoch: 86 Norm Difference for worker 1657 is 1.21626
INFO:root:FL Epoch: 86 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :767
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563602
INFO:root:Worker: 767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.724349
INFO:root:FL Epoch: 86 Norm Difference for worker 767 is 1.171746
INFO:root:FL Epoch: 86 Done on worker:767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1017
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1017 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747202
INFO:root:Worker: 1017 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581079
INFO:root:FL Epoch: 86 Norm Difference for worker 1017 is 1.109759
INFO:root:FL Epoch: 86 Done on worker:1017
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :793
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515589
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623422
INFO:root:FL Epoch: 86 Norm Difference for worker 793 is 1.185189
INFO:root:FL Epoch: 86 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1475
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607235
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615344
INFO:root:FL Epoch: 86 Norm Difference for worker 1475 is 1.206911
INFO:root:FL Epoch: 86 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :1148
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557104
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601483
INFO:root:FL Epoch: 86 Norm Difference for worker 1148 is 1.110211
INFO:root:FL Epoch: 86 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 86 Training on worker :166
INFO:root:FL Epoch: 86 Using Learning rate : 0.042176060714120375 
INFO:root:FL Epoch: 86 Normal Training
INFO:root:Worker: 166 Train Epoch: 0 [0/201 (0%)]	Loss: 0.767136
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 166 Train Epoch: 1 [0/201 (0%)]	Loss: 0.573073
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 86 Norm Difference for worker 166 is 1.169093
INFO:root:FL Epoch: 86 Done on worker:166
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1017
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 86 Ends   ===================
INFO:root:Epoch:86 Global Model Test Loss:0.5838437220629524 and Test Accuracy:70.58823529411765 
INFO:root:Epoch:86 Global Model Backdoor Test Loss:1.4525576829910278                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 87 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 87 Workers Selected : [1748, 78, 1370, 513, 444, 929, 782, 1466, 476, 183]
INFO:root:FL Epoch: 87 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 87 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 87 Training on worker :1748
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558823
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.716342
INFO:root:FL Epoch: 87 Norm Difference for worker 1748 is 1.020815
INFO:root:FL Epoch: 87 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :78
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 78 Train Epoch: 0 [0/201 (0%)]	Loss: 0.419520
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 78 Train Epoch: 1 [0/201 (0%)]	Loss: 0.353040
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 87 Norm Difference for worker 78 is 0.957497
INFO:root:FL Epoch: 87 Done on worker:78
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1370
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584907
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630105
INFO:root:FL Epoch: 87 Norm Difference for worker 1370 is 1.069852
INFO:root:FL Epoch: 87 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :513
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623629
INFO:root:Worker: 513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687161
INFO:root:FL Epoch: 87 Norm Difference for worker 513 is 1.021319
INFO:root:FL Epoch: 87 Done on worker:513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :444
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643454
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470142
INFO:root:FL Epoch: 87 Norm Difference for worker 444 is 1.053914
INFO:root:FL Epoch: 87 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :929
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556700
INFO:root:Worker: 929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514880
INFO:root:FL Epoch: 87 Norm Difference for worker 929 is 0.941196
INFO:root:FL Epoch: 87 Done on worker:929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :782
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510690
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479616
INFO:root:FL Epoch: 87 Norm Difference for worker 782 is 0.991224
INFO:root:FL Epoch: 87 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :1466
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 1466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638939
INFO:root:Worker: 1466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540308
INFO:root:FL Epoch: 87 Norm Difference for worker 1466 is 1.015407
INFO:root:FL Epoch: 87 Done on worker:1466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :476
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646675
INFO:root:Worker: 476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365576
INFO:root:FL Epoch: 87 Norm Difference for worker 476 is 0.975407
INFO:root:FL Epoch: 87 Done on worker:476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 87 Training on worker :183
INFO:root:FL Epoch: 87 Using Learning rate : 0.04209170859269214 
INFO:root:FL Epoch: 87 Normal Training
INFO:root:Worker: 183 Train Epoch: 0 [0/201 (0%)]	Loss: 0.630775
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 183 Train Epoch: 1 [0/201 (0%)]	Loss: 0.674814
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 87 Norm Difference for worker 183 is 1.023345
INFO:root:FL Epoch: 87 Done on worker:183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 929
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 87 Ends   ===================
INFO:root:Epoch:87 Global Model Test Loss:0.5918564761386198 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:87 Global Model Backdoor Test Loss:1.1553133726119995                             and Backdoor Test Accuracy:16.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 88 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 88 Workers Selected : [638, 214, 67, 401, 119, 258, 1308, 523, 527, 1093]
INFO:root:FL Epoch: 88 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.1002994 0.0998004 0.1002994 0.1002994 0.0998004
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 88 Num points on workers: [200 201 201 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 88 Training on worker :638
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671893
INFO:root:Worker: 638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454758
INFO:root:FL Epoch: 88 Norm Difference for worker 638 is 0.952512
INFO:root:FL Epoch: 88 Done on worker:638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :214
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.673844
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.608435
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 88 Norm Difference for worker 214 is 1.012059
INFO:root:FL Epoch: 88 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :67
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 67 Train Epoch: 0 [0/201 (0%)]	Loss: 0.514922
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 67 Train Epoch: 1 [0/201 (0%)]	Loss: 0.582133
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 88 Norm Difference for worker 67 is 1.001181
INFO:root:FL Epoch: 88 Done on worker:67
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :401
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638201
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547093
INFO:root:FL Epoch: 88 Norm Difference for worker 401 is 1.007427
INFO:root:FL Epoch: 88 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :119
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.660538
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.486306
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 88 Norm Difference for worker 119 is 0.994023
INFO:root:FL Epoch: 88 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :258
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603173
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.639537
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 88 Norm Difference for worker 258 is 0.963369
INFO:root:FL Epoch: 88 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1308
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763195
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576039
INFO:root:FL Epoch: 88 Norm Difference for worker 1308 is 1.001763
INFO:root:FL Epoch: 88 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :523
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741371
INFO:root:Worker: 523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628668
INFO:root:FL Epoch: 88 Norm Difference for worker 523 is 0.954943
INFO:root:FL Epoch: 88 Done on worker:523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :527
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634349
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550047
INFO:root:FL Epoch: 88 Norm Difference for worker 527 is 0.925541
INFO:root:FL Epoch: 88 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 88 Training on worker :1093
INFO:root:FL Epoch: 88 Using Learning rate : 0.04200752517550675 
INFO:root:FL Epoch: 88 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584712
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445709
INFO:root:FL Epoch: 88 Norm Difference for worker 1093 is 0.967638
INFO:root:FL Epoch: 88 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 638
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 88 Ends   ===================
INFO:root:Epoch:88 Global Model Test Loss:0.5928058238590465 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:88 Global Model Backdoor Test Loss:1.632493754227956                             and Backdoor Test Accuracy:13.333333333333334 
INFO:root:=======================================================
INFO:root:================FL round 89 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 89 Workers Selected : [1784, 190, 103, 1411, 1762, 166, 1110, 1334, 554, 1792]
INFO:root:FL Epoch: 89 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 89 Num points on workers: [200 201 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 89 Training on worker :1784
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604426
INFO:root:Worker: 1784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494224
INFO:root:FL Epoch: 89 Norm Difference for worker 1784 is 1.256009
INFO:root:FL Epoch: 89 Done on worker:1784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :190
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 190 Train Epoch: 0 [0/201 (0%)]	Loss: 0.597818
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 190 Train Epoch: 1 [0/201 (0%)]	Loss: 0.569870
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 190 is 1.284437
INFO:root:FL Epoch: 89 Done on worker:190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :103
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 103 Train Epoch: 0 [0/201 (0%)]	Loss: 0.488705
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 103 Train Epoch: 1 [0/201 (0%)]	Loss: 0.453786
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 103 is 1.15294
INFO:root:FL Epoch: 89 Done on worker:103
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1411
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596524
INFO:root:Worker: 1411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457066
INFO:root:FL Epoch: 89 Norm Difference for worker 1411 is 1.167412
INFO:root:FL Epoch: 89 Done on worker:1411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1762
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1762 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506806
INFO:root:Worker: 1762 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611917
INFO:root:FL Epoch: 89 Norm Difference for worker 1762 is 1.125672
INFO:root:FL Epoch: 89 Done on worker:1762
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :166
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 166 Train Epoch: 0 [0/201 (0%)]	Loss: 0.657502
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 166 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415530
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 89 Norm Difference for worker 166 is 1.246777
INFO:root:FL Epoch: 89 Done on worker:166
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1110
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1110 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572259
INFO:root:Worker: 1110 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582967
INFO:root:FL Epoch: 89 Norm Difference for worker 1110 is 1.22349
INFO:root:FL Epoch: 89 Done on worker:1110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1334
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405143
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484469
INFO:root:FL Epoch: 89 Norm Difference for worker 1334 is 1.24077
INFO:root:FL Epoch: 89 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :554
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646733
INFO:root:Worker: 554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498164
INFO:root:FL Epoch: 89 Norm Difference for worker 554 is 1.236434
INFO:root:FL Epoch: 89 Done on worker:554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 89 Training on worker :1792
INFO:root:FL Epoch: 89 Using Learning rate : 0.04192351012515574 
INFO:root:FL Epoch: 89 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796378
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391450
INFO:root:FL Epoch: 89 Norm Difference for worker 1792 is 1.151917
INFO:root:FL Epoch: 89 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1762
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 89 Ends   ===================
INFO:root:Epoch:89 Global Model Test Loss:0.6144445433336145 and Test Accuracy:67.94117647058823 
INFO:root:Epoch:89 Global Model Backdoor Test Loss:1.7572268048922222                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 90 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 90 Workers Selected : [51, 896, 1855, 1459, 1389, 1093, 57, 1572, 209, 660]
INFO:root:FL Epoch: 90 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 90 Num points on workers: [201 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 90 Training on worker :51
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 51 Train Epoch: 0 [0/201 (0%)]	Loss: 0.651248
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 51 Train Epoch: 1 [0/201 (0%)]	Loss: 0.433476
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 90 Norm Difference for worker 51 is 1.166706
INFO:root:FL Epoch: 90 Done on worker:51
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :896
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.847775
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612473
INFO:root:FL Epoch: 90 Norm Difference for worker 896 is 1.168359
INFO:root:FL Epoch: 90 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1855
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629411
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462224
INFO:root:FL Epoch: 90 Norm Difference for worker 1855 is 1.203363
INFO:root:FL Epoch: 90 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1459
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615954
INFO:root:Worker: 1459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662831
INFO:root:FL Epoch: 90 Norm Difference for worker 1459 is 1.227447
INFO:root:FL Epoch: 90 Done on worker:1459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1389
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498383
INFO:root:Worker: 1389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487431
INFO:root:FL Epoch: 90 Norm Difference for worker 1389 is 1.237637
INFO:root:FL Epoch: 90 Done on worker:1389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1093
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606235
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643901
INFO:root:FL Epoch: 90 Norm Difference for worker 1093 is 1.137361
INFO:root:FL Epoch: 90 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :57
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 57 Train Epoch: 0 [0/201 (0%)]	Loss: 0.577297
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 57 Train Epoch: 1 [0/201 (0%)]	Loss: 0.650493
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 90 Norm Difference for worker 57 is 1.058432
INFO:root:FL Epoch: 90 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :1572
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 1572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693294
INFO:root:Worker: 1572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636744
INFO:root:FL Epoch: 90 Norm Difference for worker 1572 is 1.090837
INFO:root:FL Epoch: 90 Done on worker:1572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :209
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 209 Train Epoch: 0 [0/201 (0%)]	Loss: 0.671705
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 209 Train Epoch: 1 [0/201 (0%)]	Loss: 0.400363
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 90 Norm Difference for worker 209 is 1.192853
INFO:root:FL Epoch: 90 Done on worker:209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 90 Training on worker :660
INFO:root:FL Epoch: 90 Using Learning rate : 0.041839663104905424 
INFO:root:FL Epoch: 90 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650940
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453286
INFO:root:FL Epoch: 90 Norm Difference for worker 660 is 1.18197
INFO:root:FL Epoch: 90 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 57
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 90 Ends   ===================
INFO:root:Epoch:90 Global Model Test Loss:0.5988919577177834 and Test Accuracy:67.6470588235294 
INFO:root:Epoch:90 Global Model Backdoor Test Loss:1.1787515878677368                             and Backdoor Test Accuracy:24.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 91 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 91 Workers Selected : [966, 54, 1094, 543, 1563, 555, 607, 840, 187, 1896]
INFO:root:FL Epoch: 91 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 91 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 91 Training on worker :966
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595693
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659551
INFO:root:FL Epoch: 91 Norm Difference for worker 966 is 1.138754
INFO:root:FL Epoch: 91 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :54
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 54 Train Epoch: 0 [0/201 (0%)]	Loss: 0.515232
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 54 Train Epoch: 1 [0/201 (0%)]	Loss: 0.572872
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 91 Norm Difference for worker 54 is 1.075731
INFO:root:FL Epoch: 91 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1094
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1094 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493572
INFO:root:Worker: 1094 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562826
INFO:root:FL Epoch: 91 Norm Difference for worker 1094 is 1.026979
INFO:root:FL Epoch: 91 Done on worker:1094
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :543
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564089
INFO:root:Worker: 543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469826
INFO:root:FL Epoch: 91 Norm Difference for worker 543 is 1.151886
INFO:root:FL Epoch: 91 Done on worker:543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1563
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658827
INFO:root:Worker: 1563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506869
INFO:root:FL Epoch: 91 Norm Difference for worker 1563 is 1.139343
INFO:root:FL Epoch: 91 Done on worker:1563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :555
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671846
INFO:root:Worker: 555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615491
INFO:root:FL Epoch: 91 Norm Difference for worker 555 is 1.15522
INFO:root:FL Epoch: 91 Done on worker:555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :607
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581438
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452714
INFO:root:FL Epoch: 91 Norm Difference for worker 607 is 1.109461
INFO:root:FL Epoch: 91 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :840
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630626
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574655
INFO:root:FL Epoch: 91 Norm Difference for worker 840 is 1.146799
INFO:root:FL Epoch: 91 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :187
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 187 Train Epoch: 0 [0/201 (0%)]	Loss: 0.610444
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 187 Train Epoch: 1 [0/201 (0%)]	Loss: 0.499654
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 91 Norm Difference for worker 187 is 1.104879
INFO:root:FL Epoch: 91 Done on worker:187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 91 Training on worker :1896
INFO:root:FL Epoch: 91 Using Learning rate : 0.04175598377869562 
INFO:root:FL Epoch: 91 Normal Training
INFO:root:Worker: 1896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485139
INFO:root:Worker: 1896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628581
INFO:root:FL Epoch: 91 Norm Difference for worker 1896 is 1.115334
INFO:root:FL Epoch: 91 Done on worker:1896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1094
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 91 Ends   ===================
INFO:root:Epoch:91 Global Model Test Loss:0.6149002050652224 and Test Accuracy:65.88235294117646 
INFO:root:Epoch:91 Global Model Backdoor Test Loss:1.5329333742459614                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 92 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 92 Workers Selected : [98, 1528, 667, 1166, 637, 1209, 1450, 520, 1658, 1641]
INFO:root:FL Epoch: 92 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 92 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 92 Training on worker :98
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676295
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.503768
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 92 Norm Difference for worker 98 is 1.190036
INFO:root:FL Epoch: 92 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1528
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.299360
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396735
INFO:root:FL Epoch: 92 Norm Difference for worker 1528 is 1.138323
INFO:root:FL Epoch: 92 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :667
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689800
INFO:root:Worker: 667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527490
INFO:root:FL Epoch: 92 Norm Difference for worker 667 is 1.137523
INFO:root:FL Epoch: 92 Done on worker:667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1166
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1166 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805361
INFO:root:Worker: 1166 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591287
INFO:root:FL Epoch: 92 Norm Difference for worker 1166 is 1.120314
INFO:root:FL Epoch: 92 Done on worker:1166
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :637
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702325
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563630
INFO:root:FL Epoch: 92 Norm Difference for worker 637 is 1.190308
INFO:root:FL Epoch: 92 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1209
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1209 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611277
INFO:root:Worker: 1209 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583581
INFO:root:FL Epoch: 92 Norm Difference for worker 1209 is 1.173753
INFO:root:FL Epoch: 92 Done on worker:1209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1450
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743394
INFO:root:Worker: 1450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498105
INFO:root:FL Epoch: 92 Norm Difference for worker 1450 is 1.234827
INFO:root:FL Epoch: 92 Done on worker:1450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :520
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701061
INFO:root:Worker: 520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579885
INFO:root:FL Epoch: 92 Norm Difference for worker 520 is 1.212326
INFO:root:FL Epoch: 92 Done on worker:520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1658
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482454
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509407
INFO:root:FL Epoch: 92 Norm Difference for worker 1658 is 1.170359
INFO:root:FL Epoch: 92 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 92 Training on worker :1641
INFO:root:FL Epoch: 92 Using Learning rate : 0.04167247181113823 
INFO:root:FL Epoch: 92 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611039
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667253
INFO:root:FL Epoch: 92 Norm Difference for worker 1641 is 1.115878
INFO:root:FL Epoch: 92 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 667
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 92 Ends   ===================
INFO:root:Epoch:92 Global Model Test Loss:0.6187864296576556 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:92 Global Model Backdoor Test Loss:1.628547688325246                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 93 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 93 Workers Selected : [678, 1468, 966, 1866, 1529, 1048, 450, 243, 995, 1303]
INFO:root:FL Epoch: 93 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 93 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 93 Training on worker :678
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617705
INFO:root:Worker: 678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546063
INFO:root:FL Epoch: 93 Norm Difference for worker 678 is 1.248235
INFO:root:FL Epoch: 93 Done on worker:678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1468
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666784
INFO:root:Worker: 1468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695606
INFO:root:FL Epoch: 93 Norm Difference for worker 1468 is 1.376185
INFO:root:FL Epoch: 93 Done on worker:1468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :966
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485636
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627044
INFO:root:FL Epoch: 93 Norm Difference for worker 966 is 1.290598
INFO:root:FL Epoch: 93 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1866
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579679
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560923
INFO:root:FL Epoch: 93 Norm Difference for worker 1866 is 1.303801
INFO:root:FL Epoch: 93 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1529
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540079
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539495
INFO:root:FL Epoch: 93 Norm Difference for worker 1529 is 1.29732
INFO:root:FL Epoch: 93 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1048
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1048 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568123
INFO:root:Worker: 1048 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527511
INFO:root:FL Epoch: 93 Norm Difference for worker 1048 is 1.366761
INFO:root:FL Epoch: 93 Done on worker:1048
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :450
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673310
INFO:root:Worker: 450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677985
INFO:root:FL Epoch: 93 Norm Difference for worker 450 is 1.252846
INFO:root:FL Epoch: 93 Done on worker:450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :243
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.575606
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447735
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 93 Norm Difference for worker 243 is 1.263865
INFO:root:FL Epoch: 93 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :995
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 995 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617798
INFO:root:Worker: 995 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491787
INFO:root:FL Epoch: 93 Norm Difference for worker 995 is 1.272945
INFO:root:FL Epoch: 93 Done on worker:995
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 93 Training on worker :1303
INFO:root:FL Epoch: 93 Using Learning rate : 0.04158912686751595 
INFO:root:FL Epoch: 93 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545313
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.767611
INFO:root:FL Epoch: 93 Norm Difference for worker 1303 is 1.300413
INFO:root:FL Epoch: 93 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 450
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 93 Ends   ===================
INFO:root:Epoch:93 Global Model Test Loss:0.6072986686930937 and Test Accuracy:64.41176470588235 
INFO:root:Epoch:93 Global Model Backdoor Test Loss:1.254538893699646                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 94 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 94 Workers Selected : [1760, 296, 14, 157, 132, 495, 1052, 1804, 1057, 391]
INFO:root:FL Epoch: 94 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.1002994 0.1002994 0.1002994 0.0998004 0.0998004
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 94 Num points on workers: [200 201 201 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 94 Training on worker :1760
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701618
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494757
INFO:root:FL Epoch: 94 Norm Difference for worker 1760 is 1.067739
INFO:root:FL Epoch: 94 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :296
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 296 Train Epoch: 0 [0/201 (0%)]	Loss: 0.724926
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 296 Train Epoch: 1 [0/201 (0%)]	Loss: 0.630563
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 296 is 0.996241
INFO:root:FL Epoch: 94 Done on worker:296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :14
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.563099
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.518599
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 14 is 1.001367
INFO:root:FL Epoch: 94 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :157
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526898
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.439475
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 157 is 1.027643
INFO:root:FL Epoch: 94 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :132
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 132 Train Epoch: 0 [0/201 (0%)]	Loss: 0.511558
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 132 Train Epoch: 1 [0/201 (0%)]	Loss: 0.549579
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 94 Norm Difference for worker 132 is 1.08528
INFO:root:FL Epoch: 94 Done on worker:132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :495
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608168
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483572
INFO:root:FL Epoch: 94 Norm Difference for worker 495 is 0.991883
INFO:root:FL Epoch: 94 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1052
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552049
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470502
INFO:root:FL Epoch: 94 Norm Difference for worker 1052 is 0.979476
INFO:root:FL Epoch: 94 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1804
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660885
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681646
INFO:root:FL Epoch: 94 Norm Difference for worker 1804 is 1.010276
INFO:root:FL Epoch: 94 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :1057
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 1057 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726754
INFO:root:Worker: 1057 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524489
INFO:root:FL Epoch: 94 Norm Difference for worker 1057 is 0.976184
INFO:root:FL Epoch: 94 Done on worker:1057
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 94 Training on worker :391
INFO:root:FL Epoch: 94 Using Learning rate : 0.041505948613780916 
INFO:root:FL Epoch: 94 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567928
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512207
INFO:root:FL Epoch: 94 Norm Difference for worker 391 is 1.037152
INFO:root:FL Epoch: 94 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1057
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 94 Ends   ===================
INFO:root:Epoch:94 Global Model Test Loss:0.5970808863639832 and Test Accuracy:66.47058823529412 
INFO:root:Epoch:94 Global Model Backdoor Test Loss:1.1541246175765991                             and Backdoor Test Accuracy:23.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 95 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 95 Workers Selected : [427, 742, 1673, 395, 361, 760, 936, 1811, 160, 1178]
INFO:root:FL Epoch: 95 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 95 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 95 Training on worker :427
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527068
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463424
INFO:root:FL Epoch: 95 Norm Difference for worker 427 is 1.034021
INFO:root:FL Epoch: 95 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :742
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618119
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458703
INFO:root:FL Epoch: 95 Norm Difference for worker 742 is 1.067734
INFO:root:FL Epoch: 95 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1673
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602863
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543000
INFO:root:FL Epoch: 95 Norm Difference for worker 1673 is 1.044984
INFO:root:FL Epoch: 95 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :395
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657556
INFO:root:Worker: 395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342791
INFO:root:FL Epoch: 95 Norm Difference for worker 395 is 1.077104
INFO:root:FL Epoch: 95 Done on worker:395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :361
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591795
INFO:root:Worker: 361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497626
INFO:root:FL Epoch: 95 Norm Difference for worker 361 is 1.035733
INFO:root:FL Epoch: 95 Done on worker:361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :760
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627782
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534188
INFO:root:FL Epoch: 95 Norm Difference for worker 760 is 1.022446
INFO:root:FL Epoch: 95 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :936
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678647
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557243
INFO:root:FL Epoch: 95 Norm Difference for worker 936 is 1.091727
INFO:root:FL Epoch: 95 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1811
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1811 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604856
INFO:root:Worker: 1811 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560910
INFO:root:FL Epoch: 95 Norm Difference for worker 1811 is 1.103525
INFO:root:FL Epoch: 95 Done on worker:1811
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :160
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.860422
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.547263
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 95 Norm Difference for worker 160 is 1.060356
INFO:root:FL Epoch: 95 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 95 Training on worker :1178
INFO:root:FL Epoch: 95 Using Learning rate : 0.04142293671655335 
INFO:root:FL Epoch: 95 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542199
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538476
INFO:root:FL Epoch: 95 Norm Difference for worker 1178 is 1.132884
INFO:root:FL Epoch: 95 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 361
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 95 Ends   ===================
INFO:root:Epoch:95 Global Model Test Loss:0.593233758912367 and Test Accuracy:66.76470588235294 
INFO:root:Epoch:95 Global Model Backdoor Test Loss:1.4143250783284504                             and Backdoor Test Accuracy:12.5 
INFO:root:=======================================================
INFO:root:================FL round 96 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 96 Workers Selected : [1315, 1289, 1805, 618, 157, 322, 603, 549, 1199, 717]
INFO:root:FL Epoch: 96 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 96 Num points on workers: [200 200 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 96 Training on worker :1315
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597547
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572748
INFO:root:FL Epoch: 96 Norm Difference for worker 1315 is 1.06803
INFO:root:FL Epoch: 96 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1289
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1289 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539768
INFO:root:Worker: 1289 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461234
INFO:root:FL Epoch: 96 Norm Difference for worker 1289 is 1.042383
INFO:root:FL Epoch: 96 Done on worker:1289
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1805
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508123
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551247
INFO:root:FL Epoch: 96 Norm Difference for worker 1805 is 1.138038
INFO:root:FL Epoch: 96 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :618
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557151
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425680
INFO:root:FL Epoch: 96 Norm Difference for worker 618 is 1.121113
INFO:root:FL Epoch: 96 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :157
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.717826
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.513421
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 157 is 1.074333
INFO:root:FL Epoch: 96 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :322
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 322 Train Epoch: 0 [0/201 (0%)]	Loss: 0.768155
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 322 Train Epoch: 1 [0/201 (0%)]	Loss: 0.466736
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 96 Norm Difference for worker 322 is 1.130031
INFO:root:FL Epoch: 96 Done on worker:322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :603
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708905
INFO:root:Worker: 603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564452
INFO:root:FL Epoch: 96 Norm Difference for worker 603 is 1.080767
INFO:root:FL Epoch: 96 Done on worker:603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :549
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581889
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678056
INFO:root:FL Epoch: 96 Norm Difference for worker 549 is 1.092546
INFO:root:FL Epoch: 96 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :1199
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573970
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671831
INFO:root:FL Epoch: 96 Norm Difference for worker 1199 is 1.074005
INFO:root:FL Epoch: 96 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 96 Training on worker :717
INFO:root:FL Epoch: 96 Using Learning rate : 0.04134009084312024 
INFO:root:FL Epoch: 96 Normal Training
INFO:root:Worker: 717 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448370
INFO:root:Worker: 717 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596093
INFO:root:FL Epoch: 96 Norm Difference for worker 717 is 1.012778
INFO:root:FL Epoch: 96 Done on worker:717
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 717
INFO:root:Norm of Aggregated Model: 5154.98681640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 96 Ends   ===================
INFO:root:Epoch:96 Global Model Test Loss:0.5919770212734446 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:96 Global Model Backdoor Test Loss:1.4312638839085896                             and Backdoor Test Accuracy:11.666666666666666 
INFO:root:=======================================================
INFO:root:================FL round 97 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 97 Workers Selected : [908, 47, 426, 160, 1728, 173, 1789, 991, 1563, 990]
INFO:root:FL Epoch: 97 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 97 Num points on workers: [200 201 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 97 Training on worker :908
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347971
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405296
INFO:root:FL Epoch: 97 Norm Difference for worker 908 is 1.044937
INFO:root:FL Epoch: 97 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :47
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 47 Train Epoch: 0 [0/201 (0%)]	Loss: 0.465965
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 47 Train Epoch: 1 [0/201 (0%)]	Loss: 0.601778
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 47 is 1.182204
INFO:root:FL Epoch: 97 Done on worker:47
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :426
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754914
INFO:root:Worker: 426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421064
INFO:root:FL Epoch: 97 Norm Difference for worker 426 is 1.019606
INFO:root:FL Epoch: 97 Done on worker:426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :160
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.687940
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.628724
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 160 is 1.068507
INFO:root:FL Epoch: 97 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1728
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691222
INFO:root:Worker: 1728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.744270
INFO:root:FL Epoch: 97 Norm Difference for worker 1728 is 1.02287
INFO:root:FL Epoch: 97 Done on worker:1728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :173
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 173 Train Epoch: 0 [0/201 (0%)]	Loss: 0.672018
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 173 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431207
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 97 Norm Difference for worker 173 is 1.059291
INFO:root:FL Epoch: 97 Done on worker:173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1789
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735355
INFO:root:Worker: 1789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658547
INFO:root:FL Epoch: 97 Norm Difference for worker 1789 is 1.033108
INFO:root:FL Epoch: 97 Done on worker:1789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :991
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664312
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422332
INFO:root:FL Epoch: 97 Norm Difference for worker 991 is 1.001347
INFO:root:FL Epoch: 97 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :1563
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 1563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520521
INFO:root:Worker: 1563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.763448
INFO:root:FL Epoch: 97 Norm Difference for worker 1563 is 1.102901
INFO:root:FL Epoch: 97 Done on worker:1563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 97 Training on worker :990
INFO:root:FL Epoch: 97 Using Learning rate : 0.041257410661434006 
INFO:root:FL Epoch: 97 Normal Training
INFO:root:Worker: 990 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510723
INFO:root:Worker: 990 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543321
INFO:root:FL Epoch: 97 Norm Difference for worker 990 is 1.084016
INFO:root:FL Epoch: 97 Done on worker:990
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 991
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 97 Ends   ===================
INFO:root:Epoch:97 Global Model Test Loss:0.5863733011133531 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:97 Global Model Backdoor Test Loss:1.1941880981127422                             and Backdoor Test Accuracy:15.833333333333334 
INFO:root:=======================================================
INFO:root:================FL round 98 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 98 Workers Selected : [1601, 1878, 1839, 710, 196, 722, 617, 62, 845, 1053]
INFO:root:FL Epoch: 98 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 98 Num points on workers: [200 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 98 Training on worker :1601
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576036
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528211
INFO:root:FL Epoch: 98 Norm Difference for worker 1601 is 0.997437
INFO:root:FL Epoch: 98 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1878
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481557
INFO:root:Worker: 1878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417324
INFO:root:FL Epoch: 98 Norm Difference for worker 1878 is 0.991226
INFO:root:FL Epoch: 98 Done on worker:1878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1839
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594217
INFO:root:Worker: 1839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648204
INFO:root:FL Epoch: 98 Norm Difference for worker 1839 is 0.95873
INFO:root:FL Epoch: 98 Done on worker:1839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :710
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591724
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469160
INFO:root:FL Epoch: 98 Norm Difference for worker 710 is 0.998227
INFO:root:FL Epoch: 98 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :196
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.538037
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.608263
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 98 Norm Difference for worker 196 is 1.02208
INFO:root:FL Epoch: 98 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :722
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508887
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568879
INFO:root:FL Epoch: 98 Norm Difference for worker 722 is 1.005104
INFO:root:FL Epoch: 98 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :617
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527192
INFO:root:Worker: 617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549374
INFO:root:FL Epoch: 98 Norm Difference for worker 617 is 1.064084
INFO:root:FL Epoch: 98 Done on worker:617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :62
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.560716
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.540457
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 98 Norm Difference for worker 62 is 1.004929
INFO:root:FL Epoch: 98 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :845
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640508
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461419
INFO:root:FL Epoch: 98 Norm Difference for worker 845 is 1.055313
INFO:root:FL Epoch: 98 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 98 Training on worker :1053
INFO:root:FL Epoch: 98 Using Learning rate : 0.041174895840111136 
INFO:root:FL Epoch: 98 Normal Training
INFO:root:Worker: 1053 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450566
INFO:root:Worker: 1053 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503842
INFO:root:FL Epoch: 98 Norm Difference for worker 1053 is 0.932303
INFO:root:FL Epoch: 98 Done on worker:1053
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1053
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 98 Ends   ===================
INFO:root:Epoch:98 Global Model Test Loss:0.5948699554976296 and Test Accuracy:69.11764705882354 
INFO:root:Epoch:98 Global Model Backdoor Test Loss:1.361415942509969                             and Backdoor Test Accuracy:15.0 
INFO:root:=======================================================
INFO:root:================FL round 99 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 99 Workers Selected : [1560, 286, 1639, 216, 1333, 1207, 1190, 927, 1900, 255]
INFO:root:FL Epoch: 99 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 99 Num points on workers: [200 201 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 99 Training on worker :1560
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544807
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668204
INFO:root:FL Epoch: 99 Norm Difference for worker 1560 is 1.166527
INFO:root:FL Epoch: 99 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :286
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 286 Train Epoch: 0 [0/201 (0%)]	Loss: 0.557302
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 286 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415557
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 99 Norm Difference for worker 286 is 1.078711
INFO:root:FL Epoch: 99 Done on worker:286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1639
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681725
INFO:root:Worker: 1639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509047
INFO:root:FL Epoch: 99 Norm Difference for worker 1639 is 1.183977
INFO:root:FL Epoch: 99 Done on worker:1639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :216
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 216 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576232
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 216 Train Epoch: 1 [0/201 (0%)]	Loss: 0.426792
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 99 Norm Difference for worker 216 is 1.140877
INFO:root:FL Epoch: 99 Done on worker:216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1333
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669049
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570175
INFO:root:FL Epoch: 99 Norm Difference for worker 1333 is 1.192492
INFO:root:FL Epoch: 99 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1207
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1207 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591503
INFO:root:Worker: 1207 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633658
INFO:root:FL Epoch: 99 Norm Difference for worker 1207 is 1.135276
INFO:root:FL Epoch: 99 Done on worker:1207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1190
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669131
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556457
INFO:root:FL Epoch: 99 Norm Difference for worker 1190 is 1.138485
INFO:root:FL Epoch: 99 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :927
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488426
INFO:root:Worker: 927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383688
INFO:root:FL Epoch: 99 Norm Difference for worker 927 is 1.132887
INFO:root:FL Epoch: 99 Done on worker:927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :1900
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 1900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.867235
INFO:root:Worker: 1900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516470
INFO:root:FL Epoch: 99 Norm Difference for worker 1900 is 1.152023
INFO:root:FL Epoch: 99 Done on worker:1900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 99 Training on worker :255
INFO:root:FL Epoch: 99 Using Learning rate : 0.04109254604843091 
INFO:root:FL Epoch: 99 Normal Training
INFO:root:Worker: 255 Train Epoch: 0 [0/201 (0%)]	Loss: 0.577353
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 255 Train Epoch: 1 [0/201 (0%)]	Loss: 0.515229
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 99 Norm Difference for worker 255 is 1.153355
INFO:root:FL Epoch: 99 Done on worker:255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 286
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 99 Ends   ===================
INFO:root:Epoch:99 Global Model Test Loss:0.6030350152183982 and Test Accuracy:67.3529411764706 
INFO:root:Epoch:99 Global Model Backdoor Test Loss:1.6422539154688518                             and Backdoor Test Accuracy:9.166666666666666 
INFO:root:=======================================================
INFO:root:================FL round 100 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 100 Workers Selected : [566, 397, 958, 1124, 1705, 489, 549, 677, 727, 1192]
INFO:root:FL Epoch: 100 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 100 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 100 Training on worker :566
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670806
INFO:root:Worker: 566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574683
INFO:root:FL Epoch: 100 Norm Difference for worker 566 is 1.251921
INFO:root:FL Epoch: 100 Done on worker:566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :397
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.838890
INFO:root:Worker: 397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626627
INFO:root:FL Epoch: 100 Norm Difference for worker 397 is 1.182779
INFO:root:FL Epoch: 100 Done on worker:397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :958
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 958 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553735
INFO:root:Worker: 958 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655532
INFO:root:FL Epoch: 100 Norm Difference for worker 958 is 1.201292
INFO:root:FL Epoch: 100 Done on worker:958
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1124
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617955
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523025
INFO:root:FL Epoch: 100 Norm Difference for worker 1124 is 1.243864
INFO:root:FL Epoch: 100 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1705
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618434
INFO:root:Worker: 1705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541076
INFO:root:FL Epoch: 100 Norm Difference for worker 1705 is 1.234554
INFO:root:FL Epoch: 100 Done on worker:1705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :489
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 489 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555467
INFO:root:Worker: 489 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435863
INFO:root:FL Epoch: 100 Norm Difference for worker 489 is 1.200034
INFO:root:FL Epoch: 100 Done on worker:489
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :549
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631796
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536139
INFO:root:FL Epoch: 100 Norm Difference for worker 549 is 1.254251
INFO:root:FL Epoch: 100 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :677
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616356
INFO:root:Worker: 677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436623
INFO:root:FL Epoch: 100 Norm Difference for worker 677 is 1.188295
INFO:root:FL Epoch: 100 Done on worker:677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :727
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673481
INFO:root:Worker: 727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523593
INFO:root:FL Epoch: 100 Norm Difference for worker 727 is 1.171695
INFO:root:FL Epoch: 100 Done on worker:727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 100 Training on worker :1192
INFO:root:FL Epoch: 100 Using Learning rate : 0.041010360956334056 
INFO:root:FL Epoch: 100 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613567
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579607
INFO:root:FL Epoch: 100 Norm Difference for worker 1192 is 1.270452
INFO:root:FL Epoch: 100 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 397
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 100 Ends   ===================
INFO:root:Epoch:100 Global Model Test Loss:0.5908514717045952 and Test Accuracy:67.05882352941177 
INFO:root:Epoch:100 Global Model Backdoor Test Loss:1.4082686305046082                             and Backdoor Test Accuracy:10.0 
INFO:root:=======================================================
INFO:root:================FL round 101 Begins ===================
INFO:root:FL Epoch: 101 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 101 Workers Selected : [0, 725, 428, 1389, 1077, 878, 883, 1482, 266, 174]
INFO:root:FL Epoch: 101 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 101 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 101 Training on worker :0
INFO:root:FL Epoch: 101 Using Learning rate : 0.008185668046884278 
INFO:root:FL Epoch: 101 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.793005
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.898396
INFO:root:FL Epoch: 101 Worker: 0 Backdoor Test Loss: 0.5797388255596161 Backdoor Test Accuracy: 72.5
INFO:root:FL Epoch: 101 Worker: 0 Backdoor Train Loss: 0.5917906701564789 Backdoor Train Accuracy: 65.0
INFO:root:FL Epoch: 101 Norm Difference for worker 0 is 0.532674
INFO:root:FL Epoch: 101 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :725
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633084
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459900
INFO:root:FL Epoch: 101 Norm Difference for worker 725 is 0.990004
INFO:root:FL Epoch: 101 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :428
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719320
INFO:root:Worker: 428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479985
INFO:root:FL Epoch: 101 Norm Difference for worker 428 is 1.061767
INFO:root:FL Epoch: 101 Done on worker:428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1389
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751688
INFO:root:Worker: 1389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618958
INFO:root:FL Epoch: 101 Norm Difference for worker 1389 is 1.135584
INFO:root:FL Epoch: 101 Done on worker:1389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1077
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1077 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590091
INFO:root:Worker: 1077 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514748
INFO:root:FL Epoch: 101 Norm Difference for worker 1077 is 1.045912
INFO:root:FL Epoch: 101 Done on worker:1077
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :878
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743281
INFO:root:Worker: 878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590686
INFO:root:FL Epoch: 101 Norm Difference for worker 878 is 1.023302
INFO:root:FL Epoch: 101 Done on worker:878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :883
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 883 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571420
INFO:root:Worker: 883 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490005
INFO:root:FL Epoch: 101 Norm Difference for worker 883 is 1.080626
INFO:root:FL Epoch: 101 Done on worker:883
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :1482
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671518
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525551
INFO:root:FL Epoch: 101 Norm Difference for worker 1482 is 0.99173
INFO:root:FL Epoch: 101 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :266
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 266 Train Epoch: 0 [0/201 (0%)]	Loss: 0.657613
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 266 Train Epoch: 1 [0/201 (0%)]	Loss: 0.581028
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 101 Norm Difference for worker 266 is 1.031254
INFO:root:FL Epoch: 101 Done on worker:266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 101 Training on worker :174
INFO:root:FL Epoch: 101 Using Learning rate : 0.040928340234421386 
INFO:root:FL Epoch: 101 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593601
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.490275
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 101 Norm Difference for worker 174 is 0.965848
INFO:root:FL Epoch: 101 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 101 Ends   ===================
INFO:root:Epoch:101 Global Model Test Loss:0.6172989887349746 and Test Accuracy:65.0 
INFO:root:Epoch:101 Global Model Backdoor Test Loss:0.5797388255596161                             and Backdoor Test Accuracy:72.5 
INFO:root:=======================================================
INFO:root:================FL round 102 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 102 Workers Selected : [1266, 1803, 1221, 1111, 1533, 1766, 251, 315, 923, 163]
INFO:root:FL Epoch: 102 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.10034948 0.09985022 0.10034948]
INFO:root:FL Epoch: 102 Num points on workers: [200 200 200 200 200 200 201 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 102 Training on worker :1266
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1266 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545832
INFO:root:Worker: 1266 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644537
INFO:root:FL Epoch: 102 Norm Difference for worker 1266 is 0.919335
INFO:root:FL Epoch: 102 Done on worker:1266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1803
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677112
INFO:root:Worker: 1803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542051
INFO:root:FL Epoch: 102 Norm Difference for worker 1803 is 0.994604
INFO:root:FL Epoch: 102 Done on worker:1803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1221
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1221 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726654
INFO:root:Worker: 1221 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548582
INFO:root:FL Epoch: 102 Norm Difference for worker 1221 is 0.883786
INFO:root:FL Epoch: 102 Done on worker:1221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1111
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1111 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729929
INFO:root:Worker: 1111 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581855
INFO:root:FL Epoch: 102 Norm Difference for worker 1111 is 0.916742
INFO:root:FL Epoch: 102 Done on worker:1111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1533
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518177
INFO:root:Worker: 1533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548695
INFO:root:FL Epoch: 102 Norm Difference for worker 1533 is 0.921765
INFO:root:FL Epoch: 102 Done on worker:1533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :1766
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 1766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723864
INFO:root:Worker: 1766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540573
INFO:root:FL Epoch: 102 Norm Difference for worker 1766 is 0.914577
INFO:root:FL Epoch: 102 Done on worker:1766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :251
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 251 Train Epoch: 0 [0/201 (0%)]	Loss: 0.686090
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 251 Train Epoch: 1 [0/201 (0%)]	Loss: 0.535365
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 102 Norm Difference for worker 251 is 0.96404
INFO:root:FL Epoch: 102 Done on worker:251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :315
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.661532
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.658871
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 102 Norm Difference for worker 315 is 0.944034
INFO:root:FL Epoch: 102 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :923
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586924
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479916
INFO:root:FL Epoch: 102 Norm Difference for worker 923 is 0.913236
INFO:root:FL Epoch: 102 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 102 Training on worker :163
INFO:root:FL Epoch: 102 Using Learning rate : 0.04084648355395254 
INFO:root:FL Epoch: 102 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526991
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.506948
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 102 Norm Difference for worker 163 is 0.96856
INFO:root:FL Epoch: 102 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1221
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 102 Ends   ===================
INFO:root:Epoch:102 Global Model Test Loss:0.5893909598098082 and Test Accuracy:69.70588235294117 
INFO:root:Epoch:102 Global Model Backdoor Test Loss:0.8657217522462209                             and Backdoor Test Accuracy:29.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 103 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 103 Workers Selected : [1108, 1054, 832, 2, 733, 259, 1609, 492, 805, 252]
INFO:root:FL Epoch: 103 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 103 Num points on workers: [200 200 200 201 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 103 Training on worker :1108
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711992
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610363
INFO:root:FL Epoch: 103 Norm Difference for worker 1108 is 0.965463
INFO:root:FL Epoch: 103 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1054
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1054 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640887
INFO:root:Worker: 1054 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628221
INFO:root:FL Epoch: 103 Norm Difference for worker 1054 is 0.984134
INFO:root:FL Epoch: 103 Done on worker:1054
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :832
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672965
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497667
INFO:root:FL Epoch: 103 Norm Difference for worker 832 is 0.957067
INFO:root:FL Epoch: 103 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :2
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 2 Train Epoch: 0 [0/201 (0%)]	Loss: 0.599915
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 2 Train Epoch: 1 [0/201 (0%)]	Loss: 0.524995
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 103 Norm Difference for worker 2 is 0.995639
INFO:root:FL Epoch: 103 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :733
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706975
INFO:root:Worker: 733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508209
INFO:root:FL Epoch: 103 Norm Difference for worker 733 is 0.921081
INFO:root:FL Epoch: 103 Done on worker:733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :259
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 259 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500659
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 259 Train Epoch: 1 [0/201 (0%)]	Loss: 0.544468
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 103 Norm Difference for worker 259 is 0.959048
INFO:root:FL Epoch: 103 Done on worker:259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :1609
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551023
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473908
INFO:root:FL Epoch: 103 Norm Difference for worker 1609 is 1.01514
INFO:root:FL Epoch: 103 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :492
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554334
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504806
INFO:root:FL Epoch: 103 Norm Difference for worker 492 is 0.992613
INFO:root:FL Epoch: 103 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :805
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583623
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487172
INFO:root:FL Epoch: 103 Norm Difference for worker 805 is 0.943939
INFO:root:FL Epoch: 103 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 103 Training on worker :252
INFO:root:FL Epoch: 103 Using Learning rate : 0.04076479058684464 
INFO:root:FL Epoch: 103 Normal Training
INFO:root:Worker: 252 Train Epoch: 0 [0/201 (0%)]	Loss: 0.594554
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 252 Train Epoch: 1 [0/201 (0%)]	Loss: 0.545422
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 103 Norm Difference for worker 252 is 0.945466
INFO:root:FL Epoch: 103 Done on worker:252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 259
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 103 Ends   ===================
INFO:root:Epoch:103 Global Model Test Loss:0.569483196034151 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:103 Global Model Backdoor Test Loss:0.8671637972195944                             and Backdoor Test Accuracy:34.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 104 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 104 Workers Selected : [1654, 1521, 939, 1926, 1651, 121, 1704, 1306, 1357, 1334]
INFO:root:FL Epoch: 104 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 104 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 104 Training on worker :1654
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564618
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515863
INFO:root:FL Epoch: 104 Norm Difference for worker 1654 is 0.987548
INFO:root:FL Epoch: 104 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1521
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.322536
INFO:root:Worker: 1521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548306
INFO:root:FL Epoch: 104 Norm Difference for worker 1521 is 1.005775
INFO:root:FL Epoch: 104 Done on worker:1521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :939
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494043
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601262
INFO:root:FL Epoch: 104 Norm Difference for worker 939 is 1.050988
INFO:root:FL Epoch: 104 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1926
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706001
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377946
INFO:root:FL Epoch: 104 Norm Difference for worker 1926 is 1.063177
INFO:root:FL Epoch: 104 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1651
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508692
INFO:root:Worker: 1651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688594
INFO:root:FL Epoch: 104 Norm Difference for worker 1651 is 1.076074
INFO:root:FL Epoch: 104 Done on worker:1651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :121
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 121 Train Epoch: 0 [0/201 (0%)]	Loss: 0.498838
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 121 Train Epoch: 1 [0/201 (0%)]	Loss: 0.663773
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 104 Norm Difference for worker 121 is 1.031715
INFO:root:FL Epoch: 104 Done on worker:121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1704
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465834
INFO:root:Worker: 1704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619934
INFO:root:FL Epoch: 104 Norm Difference for worker 1704 is 1.094501
INFO:root:FL Epoch: 104 Done on worker:1704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1306
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1306 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553295
INFO:root:Worker: 1306 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503527
INFO:root:FL Epoch: 104 Norm Difference for worker 1306 is 1.003359
INFO:root:FL Epoch: 104 Done on worker:1306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1357
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527940
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588325
INFO:root:FL Epoch: 104 Norm Difference for worker 1357 is 1.041392
INFO:root:FL Epoch: 104 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 104 Training on worker :1334
INFO:root:FL Epoch: 104 Using Learning rate : 0.04068326100567095 
INFO:root:FL Epoch: 104 Normal Training
INFO:root:Worker: 1334 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542926
INFO:root:Worker: 1334 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603464
INFO:root:FL Epoch: 104 Norm Difference for worker 1334 is 1.080768
INFO:root:FL Epoch: 104 Done on worker:1334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1306
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 104 Ends   ===================
INFO:root:Epoch:104 Global Model Test Loss:0.5651469809167525 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:104 Global Model Backdoor Test Loss:1.0478658477465312                             and Backdoor Test Accuracy:25.0 
INFO:root:=======================================================
INFO:root:================FL round 105 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 105 Workers Selected : [1569, 1401, 1376, 1073, 575, 304, 1838, 1556, 614, 446]
INFO:root:FL Epoch: 105 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 105 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 105 Training on worker :1569
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478378
INFO:root:Worker: 1569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626052
INFO:root:FL Epoch: 105 Norm Difference for worker 1569 is 1.122812
INFO:root:FL Epoch: 105 Done on worker:1569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1401
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420118
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420834
INFO:root:FL Epoch: 105 Norm Difference for worker 1401 is 1.029782
INFO:root:FL Epoch: 105 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1376
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598668
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521015
INFO:root:FL Epoch: 105 Norm Difference for worker 1376 is 1.085721
INFO:root:FL Epoch: 105 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1073
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1073 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608238
INFO:root:Worker: 1073 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612068
INFO:root:FL Epoch: 105 Norm Difference for worker 1073 is 1.060883
INFO:root:FL Epoch: 105 Done on worker:1073
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :575
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.816958
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621827
INFO:root:FL Epoch: 105 Norm Difference for worker 575 is 1.107327
INFO:root:FL Epoch: 105 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :304
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.656155
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.622965
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 105 Norm Difference for worker 304 is 1.027296
INFO:root:FL Epoch: 105 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1838
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545217
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458212
INFO:root:FL Epoch: 105 Norm Difference for worker 1838 is 1.042997
INFO:root:FL Epoch: 105 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :1556
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518109
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537256
INFO:root:FL Epoch: 105 Norm Difference for worker 1556 is 1.049342
INFO:root:FL Epoch: 105 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :614
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659904
INFO:root:Worker: 614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401042
INFO:root:FL Epoch: 105 Norm Difference for worker 614 is 1.041657
INFO:root:FL Epoch: 105 Done on worker:614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 105 Training on worker :446
INFO:root:FL Epoch: 105 Using Learning rate : 0.04060189448365961 
INFO:root:FL Epoch: 105 Normal Training
INFO:root:Worker: 446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497828
INFO:root:Worker: 446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572587
INFO:root:FL Epoch: 105 Norm Difference for worker 446 is 1.074568
INFO:root:FL Epoch: 105 Done on worker:446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1838
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 105 Ends   ===================
INFO:root:Epoch:105 Global Model Test Loss:0.5646507126443526 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:105 Global Model Backdoor Test Loss:1.1729777057965596                             and Backdoor Test Accuracy:25.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 106 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 106 Workers Selected : [1679, 1739, 199, 1440, 338, 699, 1806, 1265, 516, 1472]
INFO:root:FL Epoch: 106 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 106 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 106 Training on worker :1679
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.821206
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.741824
INFO:root:FL Epoch: 106 Norm Difference for worker 1679 is 1.258128
INFO:root:FL Epoch: 106 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1739
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1739 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617232
INFO:root:Worker: 1739 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596144
INFO:root:FL Epoch: 106 Norm Difference for worker 1739 is 1.170494
INFO:root:FL Epoch: 106 Done on worker:1739
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :199
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 199 Train Epoch: 0 [0/201 (0%)]	Loss: 0.877842
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 199 Train Epoch: 1 [0/201 (0%)]	Loss: 0.518438
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 106 Norm Difference for worker 199 is 1.283135
INFO:root:FL Epoch: 106 Done on worker:199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1440
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805027
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595013
INFO:root:FL Epoch: 106 Norm Difference for worker 1440 is 1.280346
INFO:root:FL Epoch: 106 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :338
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 338 Train Epoch: 0 [0/201 (0%)]	Loss: 0.396513
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 338 Train Epoch: 1 [0/201 (0%)]	Loss: 0.591009
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 106 Norm Difference for worker 338 is 1.179223
INFO:root:FL Epoch: 106 Done on worker:338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :699
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 699 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625008
INFO:root:Worker: 699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508205
INFO:root:FL Epoch: 106 Norm Difference for worker 699 is 1.218455
INFO:root:FL Epoch: 106 Done on worker:699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1806
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666540
INFO:root:Worker: 1806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651180
INFO:root:FL Epoch: 106 Norm Difference for worker 1806 is 1.205152
INFO:root:FL Epoch: 106 Done on worker:1806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1265
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432345
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507914
INFO:root:FL Epoch: 106 Norm Difference for worker 1265 is 1.221514
INFO:root:FL Epoch: 106 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :516
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502763
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546892
INFO:root:FL Epoch: 106 Norm Difference for worker 516 is 1.245715
INFO:root:FL Epoch: 106 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 106 Training on worker :1472
INFO:root:FL Epoch: 106 Using Learning rate : 0.04052069069469229 
INFO:root:FL Epoch: 106 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444839
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479946
INFO:root:FL Epoch: 106 Norm Difference for worker 1472 is 1.316109
INFO:root:FL Epoch: 106 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1739
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 106 Ends   ===================
INFO:root:Epoch:106 Global Model Test Loss:0.5656546512070824 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:106 Global Model Backdoor Test Loss:1.0794330437978108                             and Backdoor Test Accuracy:28.333333333333332 
INFO:root:=======================================================
INFO:root:================FL round 107 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 107 Workers Selected : [1758, 1210, 1336, 877, 940, 1896, 1774, 858, 102, 589]
INFO:root:FL Epoch: 107 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 107 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 107 Training on worker :1758
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354784
INFO:root:Worker: 1758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434732
INFO:root:FL Epoch: 107 Norm Difference for worker 1758 is 1.068678
INFO:root:FL Epoch: 107 Done on worker:1758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1210
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1210 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770530
INFO:root:Worker: 1210 Train Epoch: 1 [0/200 (0%)]	Loss: 0.872833
INFO:root:FL Epoch: 107 Norm Difference for worker 1210 is 1.058804
INFO:root:FL Epoch: 107 Done on worker:1210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1336
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1336 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555703
INFO:root:Worker: 1336 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473398
INFO:root:FL Epoch: 107 Norm Difference for worker 1336 is 1.077122
INFO:root:FL Epoch: 107 Done on worker:1336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :877
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762558
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499158
INFO:root:FL Epoch: 107 Norm Difference for worker 877 is 1.121477
INFO:root:FL Epoch: 107 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :940
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654534
INFO:root:Worker: 940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498093
INFO:root:FL Epoch: 107 Norm Difference for worker 940 is 1.117802
INFO:root:FL Epoch: 107 Done on worker:940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1896
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741967
INFO:root:Worker: 1896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.718048
INFO:root:FL Epoch: 107 Norm Difference for worker 1896 is 1.127311
INFO:root:FL Epoch: 107 Done on worker:1896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :1774
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 1774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530574
INFO:root:Worker: 1774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507064
INFO:root:FL Epoch: 107 Norm Difference for worker 1774 is 1.08773
INFO:root:FL Epoch: 107 Done on worker:1774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :858
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599920
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509687
INFO:root:FL Epoch: 107 Norm Difference for worker 858 is 1.168725
INFO:root:FL Epoch: 107 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :102
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 102 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693593
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 102 Train Epoch: 1 [0/201 (0%)]	Loss: 0.749686
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 107 Norm Difference for worker 102 is 1.057681
INFO:root:FL Epoch: 107 Done on worker:102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 107 Training on worker :589
INFO:root:FL Epoch: 107 Using Learning rate : 0.040439649313302906 
INFO:root:FL Epoch: 107 Normal Training
INFO:root:Worker: 589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547351
INFO:root:Worker: 589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608818
INFO:root:FL Epoch: 107 Norm Difference for worker 589 is 1.047603
INFO:root:FL Epoch: 107 Done on worker:589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 589
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 107 Ends   ===================
INFO:root:Epoch:107 Global Model Test Loss:0.5823880609344033 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:107 Global Model Backdoor Test Loss:1.2859079639116924                             and Backdoor Test Accuracy:20.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 108 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 108 Workers Selected : [725, 585, 470, 1893, 1475, 1098, 1823, 421, 55, 1106]
INFO:root:FL Epoch: 108 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 108 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 108 Training on worker :725
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532340
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525760
INFO:root:FL Epoch: 108 Norm Difference for worker 725 is 1.045789
INFO:root:FL Epoch: 108 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :585
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529960
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587457
INFO:root:FL Epoch: 108 Norm Difference for worker 585 is 1.052724
INFO:root:FL Epoch: 108 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :470
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.909275
INFO:root:Worker: 470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573338
INFO:root:FL Epoch: 108 Norm Difference for worker 470 is 1.048354
INFO:root:FL Epoch: 108 Done on worker:470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1893
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654894
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562621
INFO:root:FL Epoch: 108 Norm Difference for worker 1893 is 1.046528
INFO:root:FL Epoch: 108 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1475
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638303
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535789
INFO:root:FL Epoch: 108 Norm Difference for worker 1475 is 1.113696
INFO:root:FL Epoch: 108 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1098
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572139
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329416
INFO:root:FL Epoch: 108 Norm Difference for worker 1098 is 1.106908
INFO:root:FL Epoch: 108 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1823
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551978
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.827533
INFO:root:FL Epoch: 108 Norm Difference for worker 1823 is 1.078122
INFO:root:FL Epoch: 108 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :421
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620825
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328358
INFO:root:FL Epoch: 108 Norm Difference for worker 421 is 1.038757
INFO:root:FL Epoch: 108 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :55
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.588543
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.471858
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 108 Norm Difference for worker 55 is 1.068114
INFO:root:FL Epoch: 108 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 108 Training on worker :1106
INFO:root:FL Epoch: 108 Using Learning rate : 0.0403587700146763 
INFO:root:FL Epoch: 108 Normal Training
INFO:root:Worker: 1106 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574617
INFO:root:Worker: 1106 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536504
INFO:root:FL Epoch: 108 Norm Difference for worker 1106 is 0.997626
INFO:root:FL Epoch: 108 Done on worker:1106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1106
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 108 Ends   ===================
INFO:root:Epoch:108 Global Model Test Loss:0.5613703780314502 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:108 Global Model Backdoor Test Loss:0.9064828952153524                             and Backdoor Test Accuracy:34.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 109 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 109 Workers Selected : [242, 843, 368, 459, 1173, 1797, 1209, 458, 219, 48]
INFO:root:FL Epoch: 109 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 109 Num points on workers: [201 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 109 Training on worker :242
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.508805
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.487492
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 242 is 1.052904
INFO:root:FL Epoch: 109 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :843
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743517
INFO:root:Worker: 843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571639
INFO:root:FL Epoch: 109 Norm Difference for worker 843 is 1.05016
INFO:root:FL Epoch: 109 Done on worker:843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :368
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671367
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624761
INFO:root:FL Epoch: 109 Norm Difference for worker 368 is 1.05934
INFO:root:FL Epoch: 109 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :459
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700560
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459290
INFO:root:FL Epoch: 109 Norm Difference for worker 459 is 1.110651
INFO:root:FL Epoch: 109 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1173
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495834
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477251
INFO:root:FL Epoch: 109 Norm Difference for worker 1173 is 1.030183
INFO:root:FL Epoch: 109 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1797
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668623
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457774
INFO:root:FL Epoch: 109 Norm Difference for worker 1797 is 1.072469
INFO:root:FL Epoch: 109 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :1209
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 1209 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577654
INFO:root:Worker: 1209 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467860
INFO:root:FL Epoch: 109 Norm Difference for worker 1209 is 1.100161
INFO:root:FL Epoch: 109 Done on worker:1209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :458
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461009
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534002
INFO:root:FL Epoch: 109 Norm Difference for worker 458 is 1.080631
INFO:root:FL Epoch: 109 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :219
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 219 Train Epoch: 0 [0/201 (0%)]	Loss: 0.555405
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 219 Train Epoch: 1 [0/201 (0%)]	Loss: 0.587888
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 219 is 1.029474
INFO:root:FL Epoch: 109 Done on worker:219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 109 Training on worker :48
INFO:root:FL Epoch: 109 Using Learning rate : 0.04027805247464694 
INFO:root:FL Epoch: 109 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.463924
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.513799
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 109 Norm Difference for worker 48 is 1.04605
INFO:root:FL Epoch: 109 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1173
INFO:root:Norm of Aggregated Model: 5154.9873046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 109 Ends   ===================
INFO:root:Epoch:109 Global Model Test Loss:0.5685822192360374 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:109 Global Model Backdoor Test Loss:1.0153578917185466                             and Backdoor Test Accuracy:31.666666666666668 
INFO:root:=======================================================
INFO:root:================FL round 110 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 110 Workers Selected : [1081, 1684, 197, 1630, 248, 75, 321, 1551, 1279, 1870]
INFO:root:FL Epoch: 110 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.1002994 0.1002994 0.1002994
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 110 Num points on workers: [200 200 201 200 201 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 110 Training on worker :1081
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759468
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676610
INFO:root:FL Epoch: 110 Norm Difference for worker 1081 is 1.178446
INFO:root:FL Epoch: 110 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1684
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450612
INFO:root:Worker: 1684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513786
INFO:root:FL Epoch: 110 Norm Difference for worker 1684 is 1.182374
INFO:root:FL Epoch: 110 Done on worker:1684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :197
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 197 Train Epoch: 0 [0/201 (0%)]	Loss: 0.542697
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 197 Train Epoch: 1 [0/201 (0%)]	Loss: 0.481512
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 197 is 1.129344
INFO:root:FL Epoch: 110 Done on worker:197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1630
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584583
INFO:root:Worker: 1630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423887
INFO:root:FL Epoch: 110 Norm Difference for worker 1630 is 1.217265
INFO:root:FL Epoch: 110 Done on worker:1630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :248
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.716034
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.426561
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 248 is 1.095757
INFO:root:FL Epoch: 110 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :75
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 75 Train Epoch: 0 [0/201 (0%)]	Loss: 0.490763
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 75 Train Epoch: 1 [0/201 (0%)]	Loss: 0.451402
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 75 is 1.131351
INFO:root:FL Epoch: 110 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :321
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.418452
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.676518
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 110 Norm Difference for worker 321 is 1.150492
INFO:root:FL Epoch: 110 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1551
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576963
INFO:root:Worker: 1551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617771
INFO:root:FL Epoch: 110 Norm Difference for worker 1551 is 1.110964
INFO:root:FL Epoch: 110 Done on worker:1551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1279
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1279 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598186
INFO:root:Worker: 1279 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495494
INFO:root:FL Epoch: 110 Norm Difference for worker 1279 is 1.113746
INFO:root:FL Epoch: 110 Done on worker:1279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 110 Training on worker :1870
INFO:root:FL Epoch: 110 Using Learning rate : 0.040197496369697654 
INFO:root:FL Epoch: 110 Normal Training
INFO:root:Worker: 1870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517025
INFO:root:Worker: 1870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479889
INFO:root:FL Epoch: 110 Norm Difference for worker 1870 is 1.203194
INFO:root:FL Epoch: 110 Done on worker:1870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 321
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 110 Ends   ===================
INFO:root:Epoch:110 Global Model Test Loss:0.5809188344899345 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:110 Global Model Backdoor Test Loss:1.2093625664710999                             and Backdoor Test Accuracy:19.166666666666668 
INFO:root:=======================================================
INFO:root:================FL round 111 Begins ===================
INFO:root:FL Epoch: 111 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 111 Workers Selected : [0, 1066, 1282, 1638, 316, 667, 38, 1787, 333, 20]
INFO:root:FL Epoch: 111 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 111 Num points on workers: [200 200 200 200 201 200 201 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 111 Training on worker :0
INFO:root:FL Epoch: 111 Using Learning rate : 0.00802342027539165 
INFO:root:FL Epoch: 111 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.832755
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528902
INFO:root:FL Epoch: 111 Worker: 0 Backdoor Test Loss: 0.48640580972035724 Backdoor Test Accuracy: 83.33333333333333
INFO:root:FL Epoch: 111 Worker: 0 Backdoor Train Loss: 0.5292674422264099 Backdoor Train Accuracy: 74.0
INFO:root:FL Epoch: 111 Norm Difference for worker 0 is 0.497955
INFO:root:FL Epoch: 111 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1066
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1066 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778297
INFO:root:Worker: 1066 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579661
INFO:root:FL Epoch: 111 Norm Difference for worker 1066 is 1.10697
INFO:root:FL Epoch: 111 Done on worker:1066
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1282
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1282 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518406
INFO:root:Worker: 1282 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552741
INFO:root:FL Epoch: 111 Norm Difference for worker 1282 is 0.994461
INFO:root:FL Epoch: 111 Done on worker:1282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1638
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618741
INFO:root:Worker: 1638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601881
INFO:root:FL Epoch: 111 Norm Difference for worker 1638 is 1.105941
INFO:root:FL Epoch: 111 Done on worker:1638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :316
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 316 Train Epoch: 0 [0/201 (0%)]	Loss: 0.512281
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 316 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450509
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 316 is 1.047967
INFO:root:FL Epoch: 111 Done on worker:316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :667
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420703
INFO:root:Worker: 667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436048
INFO:root:FL Epoch: 111 Norm Difference for worker 667 is 1.039978
INFO:root:FL Epoch: 111 Done on worker:667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :38
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.584368
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.458747
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 38 is 1.029602
INFO:root:FL Epoch: 111 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :1787
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 1787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688905
INFO:root:Worker: 1787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.709252
INFO:root:FL Epoch: 111 Norm Difference for worker 1787 is 1.011523
INFO:root:FL Epoch: 111 Done on worker:1787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :333
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.560365
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.442021
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 333 is 0.988831
INFO:root:FL Epoch: 111 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 111 Training on worker :20
INFO:root:FL Epoch: 111 Using Learning rate : 0.04011710137695826 
INFO:root:FL Epoch: 111 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.650696
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.522598
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 111 Norm Difference for worker 20 is 1.00163
INFO:root:FL Epoch: 111 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 111 Ends   ===================
INFO:root:Epoch:111 Global Model Test Loss:0.5914063120589537 and Test Accuracy:67.05882352941177 
INFO:root:Epoch:111 Global Model Backdoor Test Loss:0.48640580972035724                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 112 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 112 Workers Selected : [1888, 879, 1707, 336, 860, 1709, 480, 1097, 1609, 1665]
INFO:root:FL Epoch: 112 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 112 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 112 Training on worker :1888
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480329
INFO:root:Worker: 1888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571541
INFO:root:FL Epoch: 112 Norm Difference for worker 1888 is 0.951866
INFO:root:FL Epoch: 112 Done on worker:1888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :879
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614438
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647551
INFO:root:FL Epoch: 112 Norm Difference for worker 879 is 0.974483
INFO:root:FL Epoch: 112 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1707
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432486
INFO:root:Worker: 1707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580743
INFO:root:FL Epoch: 112 Norm Difference for worker 1707 is 0.974881
INFO:root:FL Epoch: 112 Done on worker:1707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :336
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 336 Train Epoch: 0 [0/201 (0%)]	Loss: 0.411599
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 336 Train Epoch: 1 [0/201 (0%)]	Loss: 0.357721
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 112 Norm Difference for worker 336 is 1.062994
INFO:root:FL Epoch: 112 Done on worker:336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :860
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.752250
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539396
INFO:root:FL Epoch: 112 Norm Difference for worker 860 is 0.972885
INFO:root:FL Epoch: 112 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1709
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575062
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584312
INFO:root:FL Epoch: 112 Norm Difference for worker 1709 is 0.966544
INFO:root:FL Epoch: 112 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :480
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587563
INFO:root:Worker: 480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555959
INFO:root:FL Epoch: 112 Norm Difference for worker 480 is 1.05208
INFO:root:FL Epoch: 112 Done on worker:480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1097
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1097 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510292
INFO:root:Worker: 1097 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546090
INFO:root:FL Epoch: 112 Norm Difference for worker 1097 is 0.967196
INFO:root:FL Epoch: 112 Done on worker:1097
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1609
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616529
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567545
INFO:root:FL Epoch: 112 Norm Difference for worker 1609 is 1.0496
INFO:root:FL Epoch: 112 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 112 Training on worker :1665
INFO:root:FL Epoch: 112 Using Learning rate : 0.04003686717420434 
INFO:root:FL Epoch: 112 Normal Training
INFO:root:Worker: 1665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689711
INFO:root:Worker: 1665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494279
INFO:root:FL Epoch: 112 Norm Difference for worker 1665 is 0.968338
INFO:root:FL Epoch: 112 Done on worker:1665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1665
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 112 Ends   ===================
INFO:root:Epoch:112 Global Model Test Loss:0.5663176459424636 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:112 Global Model Backdoor Test Loss:0.6352396011352539                             and Backdoor Test Accuracy:62.5 
INFO:root:=======================================================
INFO:root:================FL round 113 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 113 Workers Selected : [634, 1413, 1175, 359, 95, 1125, 1027, 1076, 1642, 138]
INFO:root:FL Epoch: 113 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 113 Num points on workers: [200 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 113 Training on worker :634
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714717
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460563
INFO:root:FL Epoch: 113 Norm Difference for worker 634 is 0.992911
INFO:root:FL Epoch: 113 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1413
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485462
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498151
INFO:root:FL Epoch: 113 Norm Difference for worker 1413 is 1.065741
INFO:root:FL Epoch: 113 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1175
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556466
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489318
INFO:root:FL Epoch: 113 Norm Difference for worker 1175 is 1.077969
INFO:root:FL Epoch: 113 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :359
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456923
INFO:root:Worker: 359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473053
INFO:root:FL Epoch: 113 Norm Difference for worker 359 is 0.955199
INFO:root:FL Epoch: 113 Done on worker:359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :95
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 95 Train Epoch: 0 [0/201 (0%)]	Loss: 0.586920
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 95 Train Epoch: 1 [0/201 (0%)]	Loss: 0.398694
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 113 Norm Difference for worker 95 is 1.005291
INFO:root:FL Epoch: 113 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1125
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385815
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368271
INFO:root:FL Epoch: 113 Norm Difference for worker 1125 is 1.020988
INFO:root:FL Epoch: 113 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1027
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1027 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525304
INFO:root:Worker: 1027 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549425
INFO:root:FL Epoch: 113 Norm Difference for worker 1027 is 1.050828
INFO:root:FL Epoch: 113 Done on worker:1027
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1076
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1076 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493051
INFO:root:Worker: 1076 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674527
INFO:root:FL Epoch: 113 Norm Difference for worker 1076 is 1.02825
INFO:root:FL Epoch: 113 Done on worker:1076
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :1642
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 1642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635032
INFO:root:Worker: 1642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396582
INFO:root:FL Epoch: 113 Norm Difference for worker 1642 is 1.049098
INFO:root:FL Epoch: 113 Done on worker:1642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 113 Training on worker :138
INFO:root:FL Epoch: 113 Using Learning rate : 0.03995679343985593 
INFO:root:FL Epoch: 113 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.535606
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.623687
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 113 Norm Difference for worker 138 is 1.007065
INFO:root:FL Epoch: 113 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 359
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 113 Ends   ===================
INFO:root:Epoch:113 Global Model Test Loss:0.5639719612458173 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:113 Global Model Backdoor Test Loss:0.5751089006662369                             and Backdoor Test Accuracy:70.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 114 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 114 Workers Selected : [1012, 1480, 1792, 1122, 1644, 523, 1858, 1147, 1021, 1124]
INFO:root:FL Epoch: 114 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 114 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 114 Training on worker :1012
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662719
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608406
INFO:root:FL Epoch: 114 Norm Difference for worker 1012 is 0.864178
INFO:root:FL Epoch: 114 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1480
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671482
INFO:root:Worker: 1480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597295
INFO:root:FL Epoch: 114 Norm Difference for worker 1480 is 0.952308
INFO:root:FL Epoch: 114 Done on worker:1480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1792
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506177
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444597
INFO:root:FL Epoch: 114 Norm Difference for worker 1792 is 0.950962
INFO:root:FL Epoch: 114 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1122
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1122 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666267
INFO:root:Worker: 1122 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621364
INFO:root:FL Epoch: 114 Norm Difference for worker 1122 is 0.956117
INFO:root:FL Epoch: 114 Done on worker:1122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1644
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632653
INFO:root:Worker: 1644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490892
INFO:root:FL Epoch: 114 Norm Difference for worker 1644 is 0.921227
INFO:root:FL Epoch: 114 Done on worker:1644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :523
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507592
INFO:root:Worker: 523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618295
INFO:root:FL Epoch: 114 Norm Difference for worker 523 is 0.97845
INFO:root:FL Epoch: 114 Done on worker:523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1858
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632552
INFO:root:Worker: 1858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.790781
INFO:root:FL Epoch: 114 Norm Difference for worker 1858 is 0.962426
INFO:root:FL Epoch: 114 Done on worker:1858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1147
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1147 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726129
INFO:root:Worker: 1147 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423694
INFO:root:FL Epoch: 114 Norm Difference for worker 1147 is 0.96088
INFO:root:FL Epoch: 114 Done on worker:1147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1021
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610365
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586201
INFO:root:FL Epoch: 114 Norm Difference for worker 1021 is 0.904363
INFO:root:FL Epoch: 114 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 114 Training on worker :1124
INFO:root:FL Epoch: 114 Using Learning rate : 0.03987687985297622 
INFO:root:FL Epoch: 114 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544597
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472431
INFO:root:FL Epoch: 114 Norm Difference for worker 1124 is 0.992131
INFO:root:FL Epoch: 114 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1012
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 114 Ends   ===================
INFO:root:Epoch:114 Global Model Test Loss:0.5639111557427574 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:114 Global Model Backdoor Test Loss:0.6538961629072825                             and Backdoor Test Accuracy:60.0 
INFO:root:=======================================================
INFO:root:================FL round 115 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 115 Workers Selected : [248, 840, 1124, 1314, 1212, 896, 678, 1863, 1090, 1413]
INFO:root:FL Epoch: 115 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 115 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 115 Training on worker :248
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.622468
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.533629
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 115 Norm Difference for worker 248 is 0.944754
INFO:root:FL Epoch: 115 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :840
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415314
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597764
INFO:root:FL Epoch: 115 Norm Difference for worker 840 is 0.999121
INFO:root:FL Epoch: 115 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1124
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1124 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525803
INFO:root:Worker: 1124 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628209
INFO:root:FL Epoch: 115 Norm Difference for worker 1124 is 1.020546
INFO:root:FL Epoch: 115 Done on worker:1124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1314
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1314 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602150
INFO:root:Worker: 1314 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521428
INFO:root:FL Epoch: 115 Norm Difference for worker 1314 is 1.077961
INFO:root:FL Epoch: 115 Done on worker:1314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1212
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397880
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535202
INFO:root:FL Epoch: 115 Norm Difference for worker 1212 is 0.989007
INFO:root:FL Epoch: 115 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :896
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504348
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527919
INFO:root:FL Epoch: 115 Norm Difference for worker 896 is 1.003223
INFO:root:FL Epoch: 115 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :678
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 678 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584751
INFO:root:Worker: 678 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472035
INFO:root:FL Epoch: 115 Norm Difference for worker 678 is 0.995784
INFO:root:FL Epoch: 115 Done on worker:678
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1863
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501155
INFO:root:Worker: 1863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365434
INFO:root:FL Epoch: 115 Norm Difference for worker 1863 is 1.030348
INFO:root:FL Epoch: 115 Done on worker:1863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1090
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615486
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350059
INFO:root:FL Epoch: 115 Norm Difference for worker 1090 is 0.987361
INFO:root:FL Epoch: 115 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 115 Training on worker :1413
INFO:root:FL Epoch: 115 Using Learning rate : 0.03979712609327027 
INFO:root:FL Epoch: 115 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614747
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448293
INFO:root:FL Epoch: 115 Norm Difference for worker 1413 is 0.992969
INFO:root:FL Epoch: 115 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 248
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 115 Ends   ===================
INFO:root:Epoch:115 Global Model Test Loss:0.6003516702090993 and Test Accuracy:67.3529411764706 
INFO:root:Epoch:115 Global Model Backdoor Test Loss:1.0304905374844868                             and Backdoor Test Accuracy:33.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 116 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 116 Workers Selected : [730, 263, 1165, 1753, 705, 111, 1410, 1513, 966, 1146]
INFO:root:FL Epoch: 116 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 116 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 116 Training on worker :730
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585411
INFO:root:Worker: 730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507095
INFO:root:FL Epoch: 116 Norm Difference for worker 730 is 1.143005
INFO:root:FL Epoch: 116 Done on worker:730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :263
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 263 Train Epoch: 0 [0/201 (0%)]	Loss: 0.622005
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 263 Train Epoch: 1 [0/201 (0%)]	Loss: 0.656469
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 263 is 1.075019
INFO:root:FL Epoch: 116 Done on worker:263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1165
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516804
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605082
INFO:root:FL Epoch: 116 Norm Difference for worker 1165 is 1.114871
INFO:root:FL Epoch: 116 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1753
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548847
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483703
INFO:root:FL Epoch: 116 Norm Difference for worker 1753 is 1.034995
INFO:root:FL Epoch: 116 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :705
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644636
INFO:root:Worker: 705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432428
INFO:root:FL Epoch: 116 Norm Difference for worker 705 is 1.028267
INFO:root:FL Epoch: 116 Done on worker:705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :111
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 111 Train Epoch: 0 [0/201 (0%)]	Loss: 0.714813
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 111 Train Epoch: 1 [0/201 (0%)]	Loss: 0.652016
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 116 Norm Difference for worker 111 is 1.138821
INFO:root:FL Epoch: 116 Done on worker:111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1410
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570924
INFO:root:Worker: 1410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501475
INFO:root:FL Epoch: 116 Norm Difference for worker 1410 is 1.123886
INFO:root:FL Epoch: 116 Done on worker:1410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1513
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496832
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512990
INFO:root:FL Epoch: 116 Norm Difference for worker 1513 is 1.1012
INFO:root:FL Epoch: 116 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :966
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449273
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539489
INFO:root:FL Epoch: 116 Norm Difference for worker 966 is 1.051953
INFO:root:FL Epoch: 116 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 116 Training on worker :1146
INFO:root:FL Epoch: 116 Using Learning rate : 0.039717531841083724 
INFO:root:FL Epoch: 116 Normal Training
INFO:root:Worker: 1146 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607704
INFO:root:Worker: 1146 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439936
INFO:root:FL Epoch: 116 Norm Difference for worker 1146 is 1.060544
INFO:root:FL Epoch: 116 Done on worker:1146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1753
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 116 Ends   ===================
INFO:root:Epoch:116 Global Model Test Loss:0.5969758384367999 and Test Accuracy:65.58823529411765 
INFO:root:Epoch:116 Global Model Backdoor Test Loss:1.0118231773376465                             and Backdoor Test Accuracy:34.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 117 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 117 Workers Selected : [1472, 984, 91, 1939, 66, 1773, 1521, 1260, 996, 1015]
INFO:root:FL Epoch: 117 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 117 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 117 Training on worker :1472
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601384
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544742
INFO:root:FL Epoch: 117 Norm Difference for worker 1472 is 1.171846
INFO:root:FL Epoch: 117 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :984
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 984 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558218
INFO:root:Worker: 984 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558920
INFO:root:FL Epoch: 117 Norm Difference for worker 984 is 1.069431
INFO:root:FL Epoch: 117 Done on worker:984
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :91
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 91 Train Epoch: 0 [0/201 (0%)]	Loss: 0.336091
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 91 Train Epoch: 1 [0/201 (0%)]	Loss: 0.502337
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 91 is 1.075628
INFO:root:FL Epoch: 117 Done on worker:91
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1939
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563474
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.765321
INFO:root:FL Epoch: 117 Norm Difference for worker 1939 is 1.134497
INFO:root:FL Epoch: 117 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :66
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.566608
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.344050
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 117 Norm Difference for worker 66 is 1.139721
INFO:root:FL Epoch: 117 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1773
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545040
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539270
INFO:root:FL Epoch: 117 Norm Difference for worker 1773 is 1.110311
INFO:root:FL Epoch: 117 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1521
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720215
INFO:root:Worker: 1521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425402
INFO:root:FL Epoch: 117 Norm Difference for worker 1521 is 1.07348
INFO:root:FL Epoch: 117 Done on worker:1521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1260
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550111
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458845
INFO:root:FL Epoch: 117 Norm Difference for worker 1260 is 1.09654
INFO:root:FL Epoch: 117 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :996
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500993
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444948
INFO:root:FL Epoch: 117 Norm Difference for worker 996 is 1.118459
INFO:root:FL Epoch: 117 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 117 Training on worker :1015
INFO:root:FL Epoch: 117 Using Learning rate : 0.03963809677740156 
INFO:root:FL Epoch: 117 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443526
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451379
INFO:root:FL Epoch: 117 Norm Difference for worker 1015 is 1.06604
INFO:root:FL Epoch: 117 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1521
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 117 Ends   ===================
INFO:root:Epoch:117 Global Model Test Loss:0.5688147404614616 and Test Accuracy:70.0 
INFO:root:Epoch:117 Global Model Backdoor Test Loss:0.8672221799691519                             and Backdoor Test Accuracy:45.0 
INFO:root:=======================================================
INFO:root:================FL round 118 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 118 Workers Selected : [1758, 1659, 759, 39, 1657, 1084, 1143, 1784, 353, 1176]
INFO:root:FL Epoch: 118 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 118 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 118 Training on worker :1758
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601235
INFO:root:Worker: 1758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536041
INFO:root:FL Epoch: 118 Norm Difference for worker 1758 is 0.966875
INFO:root:FL Epoch: 118 Done on worker:1758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1659
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649528
INFO:root:Worker: 1659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587879
INFO:root:FL Epoch: 118 Norm Difference for worker 1659 is 1.133587
INFO:root:FL Epoch: 118 Done on worker:1659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :759
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 759 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521624
INFO:root:Worker: 759 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550071
INFO:root:FL Epoch: 118 Norm Difference for worker 759 is 1.009201
INFO:root:FL Epoch: 118 Done on worker:759
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :39
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 39 Train Epoch: 0 [0/201 (0%)]	Loss: 0.554990
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 39 Train Epoch: 1 [0/201 (0%)]	Loss: 0.561787
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 118 Norm Difference for worker 39 is 1.071915
INFO:root:FL Epoch: 118 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1657
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551674
INFO:root:Worker: 1657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464782
INFO:root:FL Epoch: 118 Norm Difference for worker 1657 is 1.081756
INFO:root:FL Epoch: 118 Done on worker:1657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1084
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671542
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403132
INFO:root:FL Epoch: 118 Norm Difference for worker 1084 is 1.012876
INFO:root:FL Epoch: 118 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1143
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1143 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663545
INFO:root:Worker: 1143 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527956
INFO:root:FL Epoch: 118 Norm Difference for worker 1143 is 1.050645
INFO:root:FL Epoch: 118 Done on worker:1143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1784
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499597
INFO:root:Worker: 1784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582141
INFO:root:FL Epoch: 118 Norm Difference for worker 1784 is 1.066227
INFO:root:FL Epoch: 118 Done on worker:1784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :353
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662601
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496738
INFO:root:FL Epoch: 118 Norm Difference for worker 353 is 1.144796
INFO:root:FL Epoch: 118 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 118 Training on worker :1176
INFO:root:FL Epoch: 118 Using Learning rate : 0.03955882058384675 
INFO:root:FL Epoch: 118 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437761
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547495
INFO:root:FL Epoch: 118 Norm Difference for worker 1176 is 1.010014
INFO:root:FL Epoch: 118 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1758
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 118 Ends   ===================
INFO:root:Epoch:118 Global Model Test Loss:0.5891197288737577 and Test Accuracy:67.05882352941177 
INFO:root:Epoch:118 Global Model Backdoor Test Loss:1.0718705157438915                             and Backdoor Test Accuracy:30.0 
INFO:root:=======================================================
INFO:root:================FL round 119 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 119 Workers Selected : [511, 1924, 870, 831, 1279, 1748, 1797, 1553, 8, 1941]
INFO:root:FL Epoch: 119 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 119 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 119 Training on worker :511
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514782
INFO:root:Worker: 511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616747
INFO:root:FL Epoch: 119 Norm Difference for worker 511 is 1.091913
INFO:root:FL Epoch: 119 Done on worker:511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1924
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553838
INFO:root:Worker: 1924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525901
INFO:root:FL Epoch: 119 Norm Difference for worker 1924 is 1.001065
INFO:root:FL Epoch: 119 Done on worker:1924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :870
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605769
INFO:root:Worker: 870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422280
INFO:root:FL Epoch: 119 Norm Difference for worker 870 is 1.02213
INFO:root:FL Epoch: 119 Done on worker:870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :831
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 831 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471385
INFO:root:Worker: 831 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455386
INFO:root:FL Epoch: 119 Norm Difference for worker 831 is 1.075901
INFO:root:FL Epoch: 119 Done on worker:831
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1279
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1279 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633789
INFO:root:Worker: 1279 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433063
INFO:root:FL Epoch: 119 Norm Difference for worker 1279 is 0.985639
INFO:root:FL Epoch: 119 Done on worker:1279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1748
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438900
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473347
INFO:root:FL Epoch: 119 Norm Difference for worker 1748 is 1.060298
INFO:root:FL Epoch: 119 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1797
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481750
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548739
INFO:root:FL Epoch: 119 Norm Difference for worker 1797 is 1.076069
INFO:root:FL Epoch: 119 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1553
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696373
INFO:root:Worker: 1553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444465
INFO:root:FL Epoch: 119 Norm Difference for worker 1553 is 1.044704
INFO:root:FL Epoch: 119 Done on worker:1553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :8
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.854859
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.426878
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 119 Norm Difference for worker 8 is 1.024379
INFO:root:FL Epoch: 119 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 119 Training on worker :1941
INFO:root:FL Epoch: 119 Using Learning rate : 0.03947970294267906 
INFO:root:FL Epoch: 119 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679500
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467070
INFO:root:FL Epoch: 119 Norm Difference for worker 1941 is 0.98903
INFO:root:FL Epoch: 119 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1279
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 119 Ends   ===================
INFO:root:Epoch:119 Global Model Test Loss:0.6011384217178121 and Test Accuracy:68.23529411764706 
INFO:root:Epoch:119 Global Model Backdoor Test Loss:1.1512359380722046                             and Backdoor Test Accuracy:25.0 
INFO:root:=======================================================
INFO:root:================FL round 120 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 120 Workers Selected : [743, 607, 1234, 1221, 401, 218, 803, 392, 1307, 1344]
INFO:root:FL Epoch: 120 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 120 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 120 Training on worker :743
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563853
INFO:root:Worker: 743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498459
INFO:root:FL Epoch: 120 Norm Difference for worker 743 is 1.014947
INFO:root:FL Epoch: 120 Done on worker:743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :607
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 607 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542501
INFO:root:Worker: 607 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333963
INFO:root:FL Epoch: 120 Norm Difference for worker 607 is 1.018444
INFO:root:FL Epoch: 120 Done on worker:607
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1234
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609865
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686609
INFO:root:FL Epoch: 120 Norm Difference for worker 1234 is 1.045981
INFO:root:FL Epoch: 120 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1221
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1221 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608547
INFO:root:Worker: 1221 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449347
INFO:root:FL Epoch: 120 Norm Difference for worker 1221 is 1.033424
INFO:root:FL Epoch: 120 Done on worker:1221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :401
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557191
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554233
INFO:root:FL Epoch: 120 Norm Difference for worker 401 is 1.061989
INFO:root:FL Epoch: 120 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :218
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.612719
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.612562
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 120 Norm Difference for worker 218 is 1.03003
INFO:root:FL Epoch: 120 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :803
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663547
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444320
INFO:root:FL Epoch: 120 Norm Difference for worker 803 is 1.096283
INFO:root:FL Epoch: 120 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :392
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590665
INFO:root:Worker: 392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289911
INFO:root:FL Epoch: 120 Norm Difference for worker 392 is 0.998228
INFO:root:FL Epoch: 120 Done on worker:392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1307
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565650
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505510
INFO:root:FL Epoch: 120 Norm Difference for worker 1307 is 1.073986
INFO:root:FL Epoch: 120 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 120 Training on worker :1344
INFO:root:FL Epoch: 120 Using Learning rate : 0.0394007435367937 
INFO:root:FL Epoch: 120 Normal Training
INFO:root:Worker: 1344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.786002
INFO:root:Worker: 1344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514606
INFO:root:FL Epoch: 120 Norm Difference for worker 1344 is 1.008355
INFO:root:FL Epoch: 120 Done on worker:1344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1344
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 120 Ends   ===================
INFO:root:Epoch:120 Global Model Test Loss:0.5933723116622251 and Test Accuracy:69.41176470588235 
INFO:root:Epoch:120 Global Model Backdoor Test Loss:1.169495662053426                             and Backdoor Test Accuracy:25.833333333333332 
INFO:root:=======================================================
INFO:root:================FL round 121 Begins ===================
INFO:root:FL Epoch: 121 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 121 Workers Selected : [0, 1395, 1368, 368, 396, 473, 540, 277, 806, 1218]
INFO:root:FL Epoch: 121 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 121 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 121 Training on worker :0
INFO:root:FL Epoch: 121 Using Learning rate : 0.007864388409944021 
INFO:root:FL Epoch: 121 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619938
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663631
INFO:root:FL Epoch: 121 Worker: 0 Backdoor Test Loss: 0.42830292383829754 Backdoor Test Accuracy: 88.33333333333333
INFO:root:FL Epoch: 121 Worker: 0 Backdoor Train Loss: 0.5112056404352188 Backdoor Train Accuracy: 73.5
INFO:root:FL Epoch: 121 Norm Difference for worker 0 is 0.516289
INFO:root:FL Epoch: 121 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1395
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.843842
INFO:root:Worker: 1395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684176
INFO:root:FL Epoch: 121 Norm Difference for worker 1395 is 1.082768
INFO:root:FL Epoch: 121 Done on worker:1395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1368
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438907
INFO:root:Worker: 1368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635191
INFO:root:FL Epoch: 121 Norm Difference for worker 1368 is 0.999125
INFO:root:FL Epoch: 121 Done on worker:1368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :368
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653757
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696686
INFO:root:FL Epoch: 121 Norm Difference for worker 368 is 1.101897
INFO:root:FL Epoch: 121 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :396
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630877
INFO:root:Worker: 396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644626
INFO:root:FL Epoch: 121 Norm Difference for worker 396 is 1.11376
INFO:root:FL Epoch: 121 Done on worker:396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :473
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493324
INFO:root:Worker: 473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397071
INFO:root:FL Epoch: 121 Norm Difference for worker 473 is 1.13194
INFO:root:FL Epoch: 121 Done on worker:473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :540
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710133
INFO:root:Worker: 540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421753
INFO:root:FL Epoch: 121 Norm Difference for worker 540 is 1.109195
INFO:root:FL Epoch: 121 Done on worker:540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :277
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 277 Train Epoch: 0 [0/201 (0%)]	Loss: 0.433621
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 277 Train Epoch: 1 [0/201 (0%)]	Loss: 0.427523
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 121 Norm Difference for worker 277 is 1.063593
INFO:root:FL Epoch: 121 Done on worker:277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :806
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685826
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523934
INFO:root:FL Epoch: 121 Norm Difference for worker 806 is 1.129429
INFO:root:FL Epoch: 121 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 121 Training on worker :1218
INFO:root:FL Epoch: 121 Using Learning rate : 0.039321942049720116 
INFO:root:FL Epoch: 121 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504920
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650284
INFO:root:FL Epoch: 121 Norm Difference for worker 1218 is 1.117343
INFO:root:FL Epoch: 121 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 121 Ends   ===================
INFO:root:Epoch:121 Global Model Test Loss:0.5936921466799343 and Test Accuracy:68.52941176470588 
INFO:root:Epoch:121 Global Model Backdoor Test Loss:0.42830292383829754                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 122 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 122 Workers Selected : [664, 1830, 514, 538, 321, 841, 425, 413, 188, 881]
INFO:root:FL Epoch: 122 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 122 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 122 Training on worker :664
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637928
INFO:root:Worker: 664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563696
INFO:root:FL Epoch: 122 Norm Difference for worker 664 is 1.005962
INFO:root:FL Epoch: 122 Done on worker:664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :1830
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476158
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469436
INFO:root:FL Epoch: 122 Norm Difference for worker 1830 is 1.039146
INFO:root:FL Epoch: 122 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :514
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506912
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547480
INFO:root:FL Epoch: 122 Norm Difference for worker 514 is 1.050861
INFO:root:FL Epoch: 122 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :538
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.767839
INFO:root:Worker: 538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562414
INFO:root:FL Epoch: 122 Norm Difference for worker 538 is 1.013194
INFO:root:FL Epoch: 122 Done on worker:538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :321
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.553553
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.443584
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 321 is 1.006819
INFO:root:FL Epoch: 122 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :841
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 841 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671100
INFO:root:Worker: 841 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592140
INFO:root:FL Epoch: 122 Norm Difference for worker 841 is 1.086831
INFO:root:FL Epoch: 122 Done on worker:841
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :425
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544055
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520007
INFO:root:FL Epoch: 122 Norm Difference for worker 425 is 1.008286
INFO:root:FL Epoch: 122 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :413
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709431
INFO:root:Worker: 413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471057
INFO:root:FL Epoch: 122 Norm Difference for worker 413 is 1.00236
INFO:root:FL Epoch: 122 Done on worker:413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :188
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 188 Train Epoch: 0 [0/201 (0%)]	Loss: 0.595765
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 188 Train Epoch: 1 [0/201 (0%)]	Loss: 0.527964
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 122 Norm Difference for worker 188 is 1.047772
INFO:root:FL Epoch: 122 Done on worker:188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 122 Training on worker :881
INFO:root:FL Epoch: 122 Using Learning rate : 0.03924329816562067 
INFO:root:FL Epoch: 122 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383551
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548183
INFO:root:FL Epoch: 122 Norm Difference for worker 881 is 1.028666
INFO:root:FL Epoch: 122 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 413
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 122 Ends   ===================
INFO:root:Epoch:122 Global Model Test Loss:0.5788852660094991 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:122 Global Model Backdoor Test Loss:0.5204573174317678                             and Backdoor Test Accuracy:75.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 123 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 123 Workers Selected : [312, 525, 894, 284, 917, 167, 874, 1446, 104, 1604]
INFO:root:FL Epoch: 123 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 123 Num points on workers: [201 200 200 201 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 123 Training on worker :312
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.746819
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.408434
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 312 is 1.171541
INFO:root:FL Epoch: 123 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :525
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559627
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.723838
INFO:root:FL Epoch: 123 Norm Difference for worker 525 is 1.156471
INFO:root:FL Epoch: 123 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :894
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520350
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305301
INFO:root:FL Epoch: 123 Norm Difference for worker 894 is 1.088877
INFO:root:FL Epoch: 123 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :284
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685251
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.541064
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 284 is 1.120113
INFO:root:FL Epoch: 123 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :917
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508152
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483311
INFO:root:FL Epoch: 123 Norm Difference for worker 917 is 1.137327
INFO:root:FL Epoch: 123 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :167
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 167 Train Epoch: 0 [0/201 (0%)]	Loss: 0.774901
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 167 Train Epoch: 1 [0/201 (0%)]	Loss: 0.392569
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 167 is 1.041008
INFO:root:FL Epoch: 123 Done on worker:167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :874
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.874217
INFO:root:Worker: 874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611792
INFO:root:FL Epoch: 123 Norm Difference for worker 874 is 1.130705
INFO:root:FL Epoch: 123 Done on worker:874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1446
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668788
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572018
INFO:root:FL Epoch: 123 Norm Difference for worker 1446 is 1.144977
INFO:root:FL Epoch: 123 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :104
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.547890
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.440621
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 123 Norm Difference for worker 104 is 1.126678
INFO:root:FL Epoch: 123 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 123 Training on worker :1604
INFO:root:FL Epoch: 123 Using Learning rate : 0.039164811569289436 
INFO:root:FL Epoch: 123 Normal Training
INFO:root:Worker: 1604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659343
INFO:root:Worker: 1604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482618
INFO:root:FL Epoch: 123 Norm Difference for worker 1604 is 1.107011
INFO:root:FL Epoch: 123 Done on worker:1604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 167
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 123 Ends   ===================
INFO:root:Epoch:123 Global Model Test Loss:0.5537927659118876 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:123 Global Model Backdoor Test Loss:0.6635197401046753                             and Backdoor Test Accuracy:60.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 124 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 124 Workers Selected : [419, 166, 1182, 1563, 761, 145, 642, 44, 546, 896]
INFO:root:FL Epoch: 124 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 124 Num points on workers: [200 201 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 124 Training on worker :419
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530130
INFO:root:Worker: 419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672452
INFO:root:FL Epoch: 124 Norm Difference for worker 419 is 0.994632
INFO:root:FL Epoch: 124 Done on worker:419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :166
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 166 Train Epoch: 0 [0/201 (0%)]	Loss: 0.488895
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 166 Train Epoch: 1 [0/201 (0%)]	Loss: 0.497839
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 124 Norm Difference for worker 166 is 1.049126
INFO:root:FL Epoch: 124 Done on worker:166
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1182
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315290
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548759
INFO:root:FL Epoch: 124 Norm Difference for worker 1182 is 1.021402
INFO:root:FL Epoch: 124 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :1563
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 1563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768888
INFO:root:Worker: 1563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524970
INFO:root:FL Epoch: 124 Norm Difference for worker 1563 is 1.054502
INFO:root:FL Epoch: 124 Done on worker:1563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :761
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682246
INFO:root:Worker: 761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454573
INFO:root:FL Epoch: 124 Norm Difference for worker 761 is 1.139026
INFO:root:FL Epoch: 124 Done on worker:761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :145
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.522189
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.575005
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 124 Norm Difference for worker 145 is 1.005612
INFO:root:FL Epoch: 124 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :642
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613719
INFO:root:Worker: 642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571100
INFO:root:FL Epoch: 124 Norm Difference for worker 642 is 1.079084
INFO:root:FL Epoch: 124 Done on worker:642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :44
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 44 Train Epoch: 0 [0/201 (0%)]	Loss: 0.531341
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 44 Train Epoch: 1 [0/201 (0%)]	Loss: 0.686093
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 124 Norm Difference for worker 44 is 1.050726
INFO:root:FL Epoch: 124 Done on worker:44
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :546
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577386
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392757
INFO:root:FL Epoch: 124 Norm Difference for worker 546 is 1.073737
INFO:root:FL Epoch: 124 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 124 Training on worker :896
INFO:root:FL Epoch: 124 Using Learning rate : 0.03908648194615086 
INFO:root:FL Epoch: 124 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630297
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436293
INFO:root:FL Epoch: 124 Norm Difference for worker 896 is 1.036573
INFO:root:FL Epoch: 124 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 419
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 124 Ends   ===================
INFO:root:Epoch:124 Global Model Test Loss:0.5330978404073154 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:124 Global Model Backdoor Test Loss:0.6311701635519663                             and Backdoor Test Accuracy:64.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 125 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 125 Workers Selected : [8, 627, 1067, 1695, 482, 1524, 1627, 330, 266, 821]
INFO:root:FL Epoch: 125 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 125 Num points on workers: [201 200 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 125 Training on worker :8
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.567540
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.559140
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 125 Norm Difference for worker 8 is 1.066659
INFO:root:FL Epoch: 125 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :627
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411648
INFO:root:Worker: 627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584531
INFO:root:FL Epoch: 125 Norm Difference for worker 627 is 1.051015
INFO:root:FL Epoch: 125 Done on worker:627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1067
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1067 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634686
INFO:root:Worker: 1067 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500112
INFO:root:FL Epoch: 125 Norm Difference for worker 1067 is 1.046822
INFO:root:FL Epoch: 125 Done on worker:1067
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1695
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391662
INFO:root:Worker: 1695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573748
INFO:root:FL Epoch: 125 Norm Difference for worker 1695 is 1.07284
INFO:root:FL Epoch: 125 Done on worker:1695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :482
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405197
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426467
INFO:root:FL Epoch: 125 Norm Difference for worker 482 is 1.025586
INFO:root:FL Epoch: 125 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1524
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425584
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.736521
INFO:root:FL Epoch: 125 Norm Difference for worker 1524 is 1.123411
INFO:root:FL Epoch: 125 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :1627
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603172
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454513
INFO:root:FL Epoch: 125 Norm Difference for worker 1627 is 1.051232
INFO:root:FL Epoch: 125 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :330
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 330 Train Epoch: 0 [0/201 (0%)]	Loss: 0.522808
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 330 Train Epoch: 1 [0/201 (0%)]	Loss: 0.498978
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 125 Norm Difference for worker 330 is 1.03807
INFO:root:FL Epoch: 125 Done on worker:330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :266
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 266 Train Epoch: 0 [0/201 (0%)]	Loss: 0.723343
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 266 Train Epoch: 1 [0/201 (0%)]	Loss: 0.602518
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 125 Norm Difference for worker 266 is 1.035171
INFO:root:FL Epoch: 125 Done on worker:266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 125 Training on worker :821
INFO:root:FL Epoch: 125 Using Learning rate : 0.03900830898225855 
INFO:root:FL Epoch: 125 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663315
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444622
INFO:root:FL Epoch: 125 Norm Difference for worker 821 is 1.117586
INFO:root:FL Epoch: 125 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1627
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 125 Ends   ===================
INFO:root:Epoch:125 Global Model Test Loss:0.5481696672299329 and Test Accuracy:70.0 
INFO:root:Epoch:125 Global Model Backdoor Test Loss:0.7443745533625284                             and Backdoor Test Accuracy:52.5 
INFO:root:=======================================================
INFO:root:================FL round 126 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 126 Workers Selected : [1913, 9, 272, 1804, 1551, 514, 110, 1379, 1400, 85]
INFO:root:FL Epoch: 126 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994
 0.0998004 0.0998004 0.1002994]
INFO:root:FL Epoch: 126 Num points on workers: [200 201 201 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 126 Training on worker :1913
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537200
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583848
INFO:root:FL Epoch: 126 Norm Difference for worker 1913 is 1.142257
INFO:root:FL Epoch: 126 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :9
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.747216
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.377121
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 126 Norm Difference for worker 9 is 1.177961
INFO:root:FL Epoch: 126 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :272
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.387814
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.298373
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 126 Norm Difference for worker 272 is 1.100834
INFO:root:FL Epoch: 126 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1804
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525551
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526877
INFO:root:FL Epoch: 126 Norm Difference for worker 1804 is 1.129503
INFO:root:FL Epoch: 126 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1551
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642821
INFO:root:Worker: 1551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421872
INFO:root:FL Epoch: 126 Norm Difference for worker 1551 is 1.113038
INFO:root:FL Epoch: 126 Done on worker:1551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :514
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406484
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425873
INFO:root:FL Epoch: 126 Norm Difference for worker 514 is 1.075148
INFO:root:FL Epoch: 126 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :110
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 110 Train Epoch: 0 [0/201 (0%)]	Loss: 0.673563
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 110 Train Epoch: 1 [0/201 (0%)]	Loss: 0.485099
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 126 Norm Difference for worker 110 is 1.227016
INFO:root:FL Epoch: 126 Done on worker:110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1379
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.825230
INFO:root:Worker: 1379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425004
INFO:root:FL Epoch: 126 Norm Difference for worker 1379 is 1.203098
INFO:root:FL Epoch: 126 Done on worker:1379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :1400
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 1400 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539321
INFO:root:Worker: 1400 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504164
INFO:root:FL Epoch: 126 Norm Difference for worker 1400 is 1.188956
INFO:root:FL Epoch: 126 Done on worker:1400
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 126 Training on worker :85
INFO:root:FL Epoch: 126 Using Learning rate : 0.03893029236429404 
INFO:root:FL Epoch: 126 Normal Training
INFO:root:Worker: 85 Train Epoch: 0 [0/201 (0%)]	Loss: 0.609857
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 85 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428516
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 126 Norm Difference for worker 85 is 1.142286
INFO:root:FL Epoch: 126 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1551
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 126 Ends   ===================
INFO:root:Epoch:126 Global Model Test Loss:0.5540455509634579 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:126 Global Model Backdoor Test Loss:0.6530690093835195                             and Backdoor Test Accuracy:61.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 127 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 127 Workers Selected : [1298, 816, 924, 1183, 1636, 1734, 973, 568, 208, 1198]
INFO:root:FL Epoch: 127 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 127 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 127 Training on worker :1298
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1298 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574269
INFO:root:Worker: 1298 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416566
INFO:root:FL Epoch: 127 Norm Difference for worker 1298 is 1.07737
INFO:root:FL Epoch: 127 Done on worker:1298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :816
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516857
INFO:root:Worker: 816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491065
INFO:root:FL Epoch: 127 Norm Difference for worker 816 is 1.025283
INFO:root:FL Epoch: 127 Done on worker:816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :924
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661569
INFO:root:Worker: 924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512896
INFO:root:FL Epoch: 127 Norm Difference for worker 924 is 1.076227
INFO:root:FL Epoch: 127 Done on worker:924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1183
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1183 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571045
INFO:root:Worker: 1183 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602514
INFO:root:FL Epoch: 127 Norm Difference for worker 1183 is 1.009179
INFO:root:FL Epoch: 127 Done on worker:1183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1636
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616195
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.761776
INFO:root:FL Epoch: 127 Norm Difference for worker 1636 is 1.104655
INFO:root:FL Epoch: 127 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1734
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567100
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527213
INFO:root:FL Epoch: 127 Norm Difference for worker 1734 is 1.077691
INFO:root:FL Epoch: 127 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :973
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 973 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631471
INFO:root:Worker: 973 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513926
INFO:root:FL Epoch: 127 Norm Difference for worker 973 is 1.108312
INFO:root:FL Epoch: 127 Done on worker:973
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :568
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 568 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761361
INFO:root:Worker: 568 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595322
INFO:root:FL Epoch: 127 Norm Difference for worker 568 is 1.149579
INFO:root:FL Epoch: 127 Done on worker:568
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :208
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.562635
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.383664
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 127 Norm Difference for worker 208 is 1.077182
INFO:root:FL Epoch: 127 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 127 Training on worker :1198
INFO:root:FL Epoch: 127 Using Learning rate : 0.03885243177956545 
INFO:root:FL Epoch: 127 Normal Training
INFO:root:Worker: 1198 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583077
INFO:root:Worker: 1198 Train Epoch: 1 [0/200 (0%)]	Loss: 0.737841
INFO:root:FL Epoch: 127 Norm Difference for worker 1198 is 1.070059
INFO:root:FL Epoch: 127 Done on worker:1198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1183
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 127 Ends   ===================
INFO:root:Epoch:127 Global Model Test Loss:0.5467083892401527 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:127 Global Model Backdoor Test Loss:0.6525329152743021                             and Backdoor Test Accuracy:65.0 
INFO:root:=======================================================
INFO:root:================FL round 128 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 128 Workers Selected : [1235, 477, 1755, 725, 1827, 1674, 181, 893, 1386, 1499]
INFO:root:FL Epoch: 128 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 128 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 128 Training on worker :1235
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1235 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614167
INFO:root:Worker: 1235 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469191
INFO:root:FL Epoch: 128 Norm Difference for worker 1235 is 1.06192
INFO:root:FL Epoch: 128 Done on worker:1235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :477
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669635
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491598
INFO:root:FL Epoch: 128 Norm Difference for worker 477 is 1.074756
INFO:root:FL Epoch: 128 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1755
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419966
INFO:root:Worker: 1755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612968
INFO:root:FL Epoch: 128 Norm Difference for worker 1755 is 1.085516
INFO:root:FL Epoch: 128 Done on worker:1755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :725
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444717
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397268
INFO:root:FL Epoch: 128 Norm Difference for worker 725 is 1.057454
INFO:root:FL Epoch: 128 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1827
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705212
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459089
INFO:root:FL Epoch: 128 Norm Difference for worker 1827 is 1.056394
INFO:root:FL Epoch: 128 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1674
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562712
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402955
INFO:root:FL Epoch: 128 Norm Difference for worker 1674 is 1.058749
INFO:root:FL Epoch: 128 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :181
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 181 Train Epoch: 0 [0/201 (0%)]	Loss: 0.581437
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 181 Train Epoch: 1 [0/201 (0%)]	Loss: 0.576830
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 128 Norm Difference for worker 181 is 1.113295
INFO:root:FL Epoch: 128 Done on worker:181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :893
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603845
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618902
INFO:root:FL Epoch: 128 Norm Difference for worker 893 is 1.056599
INFO:root:FL Epoch: 128 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1386
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547752
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350074
INFO:root:FL Epoch: 128 Norm Difference for worker 1386 is 1.080692
INFO:root:FL Epoch: 128 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 128 Training on worker :1499
INFO:root:FL Epoch: 128 Using Learning rate : 0.038774726916006315 
INFO:root:FL Epoch: 128 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404129
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584905
INFO:root:FL Epoch: 128 Norm Difference for worker 1499 is 1.109164
INFO:root:FL Epoch: 128 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1674
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 128 Ends   ===================
INFO:root:Epoch:128 Global Model Test Loss:0.5369085739640629 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:128 Global Model Backdoor Test Loss:0.7162452240784963                             and Backdoor Test Accuracy:55.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 129 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 129 Workers Selected : [806, 1278, 766, 1914, 909, 1075, 395, 1556, 444, 966]
INFO:root:FL Epoch: 129 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 129 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 129 Training on worker :806
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.898986
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575916
INFO:root:FL Epoch: 129 Norm Difference for worker 806 is 1.101634
INFO:root:FL Epoch: 129 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1278
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516234
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524188
INFO:root:FL Epoch: 129 Norm Difference for worker 1278 is 1.115064
INFO:root:FL Epoch: 129 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :766
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518323
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352788
INFO:root:FL Epoch: 129 Norm Difference for worker 766 is 1.088951
INFO:root:FL Epoch: 129 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1914
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506767
INFO:root:Worker: 1914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322244
INFO:root:FL Epoch: 129 Norm Difference for worker 1914 is 1.115358
INFO:root:FL Epoch: 129 Done on worker:1914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :909
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506889
INFO:root:Worker: 909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595546
INFO:root:FL Epoch: 129 Norm Difference for worker 909 is 1.082329
INFO:root:FL Epoch: 129 Done on worker:909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1075
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599745
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583000
INFO:root:FL Epoch: 129 Norm Difference for worker 1075 is 1.193206
INFO:root:FL Epoch: 129 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :395
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714356
INFO:root:Worker: 395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481407
INFO:root:FL Epoch: 129 Norm Difference for worker 395 is 1.20034
INFO:root:FL Epoch: 129 Done on worker:395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :1556
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 1556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350869
INFO:root:Worker: 1556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427011
INFO:root:FL Epoch: 129 Norm Difference for worker 1556 is 1.194968
INFO:root:FL Epoch: 129 Done on worker:1556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :444
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492903
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525449
INFO:root:FL Epoch: 129 Norm Difference for worker 444 is 1.113322
INFO:root:FL Epoch: 129 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 129 Training on worker :966
INFO:root:FL Epoch: 129 Using Learning rate : 0.0386971774621743 
INFO:root:FL Epoch: 129 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572718
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646443
INFO:root:FL Epoch: 129 Norm Difference for worker 966 is 1.141362
INFO:root:FL Epoch: 129 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 766
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 129 Ends   ===================
INFO:root:Epoch:129 Global Model Test Loss:0.5270581280483919 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:129 Global Model Backdoor Test Loss:0.755262553691864                             and Backdoor Test Accuracy:59.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 130 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 130 Workers Selected : [435, 881, 1615, 458, 1746, 1167, 187, 536, 1890, 785]
INFO:root:FL Epoch: 130 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 130 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 130 Training on worker :435
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661250
INFO:root:Worker: 435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423637
INFO:root:FL Epoch: 130 Norm Difference for worker 435 is 1.341824
INFO:root:FL Epoch: 130 Done on worker:435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :881
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495566
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380676
INFO:root:FL Epoch: 130 Norm Difference for worker 881 is 1.191438
INFO:root:FL Epoch: 130 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1615
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1615 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399255
INFO:root:Worker: 1615 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479922
INFO:root:FL Epoch: 130 Norm Difference for worker 1615 is 1.326724
INFO:root:FL Epoch: 130 Done on worker:1615
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :458
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649069
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568083
INFO:root:FL Epoch: 130 Norm Difference for worker 458 is 1.276767
INFO:root:FL Epoch: 130 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1746
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1746 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624531
INFO:root:Worker: 1746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378936
INFO:root:FL Epoch: 130 Norm Difference for worker 1746 is 1.292116
INFO:root:FL Epoch: 130 Done on worker:1746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1167
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.879922
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508060
INFO:root:FL Epoch: 130 Norm Difference for worker 1167 is 1.290585
INFO:root:FL Epoch: 130 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :187
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 187 Train Epoch: 0 [0/201 (0%)]	Loss: 0.445231
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 187 Train Epoch: 1 [0/201 (0%)]	Loss: 0.442072
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 130 Norm Difference for worker 187 is 1.260071
INFO:root:FL Epoch: 130 Done on worker:187
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :536
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320406
INFO:root:Worker: 536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495618
INFO:root:FL Epoch: 130 Norm Difference for worker 536 is 1.235738
INFO:root:FL Epoch: 130 Done on worker:536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :1890
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756139
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453606
INFO:root:FL Epoch: 130 Norm Difference for worker 1890 is 1.327135
INFO:root:FL Epoch: 130 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 130 Training on worker :785
INFO:root:FL Epoch: 130 Using Learning rate : 0.03861978310724995 
INFO:root:FL Epoch: 130 Normal Training
INFO:root:Worker: 785 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610237
INFO:root:Worker: 785 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602048
INFO:root:FL Epoch: 130 Norm Difference for worker 785 is 1.336229
INFO:root:FL Epoch: 130 Done on worker:785
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 881
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 130 Ends   ===================
INFO:root:Epoch:130 Global Model Test Loss:0.5406059675356921 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:130 Global Model Backdoor Test Loss:0.9824998875459036                             and Backdoor Test Accuracy:42.5 
INFO:root:=======================================================
INFO:root:================FL round 131 Begins ===================
INFO:root:FL Epoch: 131 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 131 Workers Selected : [0, 222, 1626, 1476, 962, 1666, 210, 446, 110, 1185]
INFO:root:FL Epoch: 131 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 131 Num points on workers: [200 201 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 131 Training on worker :0
INFO:root:FL Epoch: 131 Using Learning rate : 0.00770850870820709 
INFO:root:FL Epoch: 131 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812670
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626123
INFO:root:FL Epoch: 131 Worker: 0 Backdoor Test Loss: 0.30741818497578305 Backdoor Test Accuracy: 90.0
INFO:root:FL Epoch: 131 Worker: 0 Backdoor Train Loss: 0.4638798415660858 Backdoor Train Accuracy: 81.5
INFO:root:FL Epoch: 131 Norm Difference for worker 0 is 0.502718
INFO:root:FL Epoch: 131 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :222
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.379754
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.518028
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 131 Norm Difference for worker 222 is 1.183956
INFO:root:FL Epoch: 131 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1626
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.784605
INFO:root:Worker: 1626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580582
INFO:root:FL Epoch: 131 Norm Difference for worker 1626 is 1.207929
INFO:root:FL Epoch: 131 Done on worker:1626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1476
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710768
INFO:root:Worker: 1476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464246
INFO:root:FL Epoch: 131 Norm Difference for worker 1476 is 1.292308
INFO:root:FL Epoch: 131 Done on worker:1476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :962
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535887
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707804
INFO:root:FL Epoch: 131 Norm Difference for worker 962 is 1.244121
INFO:root:FL Epoch: 131 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1666
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672880
INFO:root:Worker: 1666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.748108
INFO:root:FL Epoch: 131 Norm Difference for worker 1666 is 1.344517
INFO:root:FL Epoch: 131 Done on worker:1666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :210
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 210 Train Epoch: 0 [0/201 (0%)]	Loss: 0.724754
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 210 Train Epoch: 1 [0/201 (0%)]	Loss: 0.481025
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 131 Norm Difference for worker 210 is 1.253223
INFO:root:FL Epoch: 131 Done on worker:210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :446
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446062
INFO:root:Worker: 446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550592
INFO:root:FL Epoch: 131 Norm Difference for worker 446 is 1.23988
INFO:root:FL Epoch: 131 Done on worker:446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :110
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 110 Train Epoch: 0 [0/201 (0%)]	Loss: 0.498695
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 110 Train Epoch: 1 [0/201 (0%)]	Loss: 0.516833
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 131 Norm Difference for worker 110 is 1.291207
INFO:root:FL Epoch: 131 Done on worker:110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 131 Training on worker :1185
INFO:root:FL Epoch: 131 Using Learning rate : 0.03854254354103545 
INFO:root:FL Epoch: 131 Normal Training
INFO:root:Worker: 1185 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807156
INFO:root:Worker: 1185 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466891
INFO:root:FL Epoch: 131 Norm Difference for worker 1185 is 1.210521
INFO:root:FL Epoch: 131 Done on worker:1185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.98779296875
INFO:root:Aggregating After Defense
INFO:root:================FL round 131 Ends   ===================
INFO:root:Epoch:131 Global Model Test Loss:0.5351541165043326 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:131 Global Model Backdoor Test Loss:0.30741818497578305                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 132 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 132 Workers Selected : [134, 1676, 1771, 154, 166, 1747, 1906, 1574, 226, 1601]
INFO:root:FL Epoch: 132 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.1002994 0.1002994 0.0998004 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 132 Num points on workers: [201 200 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 132 Training on worker :134
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 134 Train Epoch: 0 [0/201 (0%)]	Loss: 0.656887
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 134 Train Epoch: 1 [0/201 (0%)]	Loss: 0.335623
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 134 is 1.15545
INFO:root:FL Epoch: 132 Done on worker:134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1676
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475467
INFO:root:Worker: 1676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529297
INFO:root:FL Epoch: 132 Norm Difference for worker 1676 is 1.148592
INFO:root:FL Epoch: 132 Done on worker:1676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1771
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1771 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639199
INFO:root:Worker: 1771 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464331
INFO:root:FL Epoch: 132 Norm Difference for worker 1771 is 1.188671
INFO:root:FL Epoch: 132 Done on worker:1771
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :154
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 154 Train Epoch: 0 [0/201 (0%)]	Loss: 0.847867
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 154 Train Epoch: 1 [0/201 (0%)]	Loss: 0.484018
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 154 is 1.19653
INFO:root:FL Epoch: 132 Done on worker:154
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :166
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 166 Train Epoch: 0 [0/201 (0%)]	Loss: 0.513589
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 166 Train Epoch: 1 [0/201 (0%)]	Loss: 0.628490
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 166 is 1.193504
INFO:root:FL Epoch: 132 Done on worker:166
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1747
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557219
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472211
INFO:root:FL Epoch: 132 Norm Difference for worker 1747 is 1.213152
INFO:root:FL Epoch: 132 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1906
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.934296
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597032
INFO:root:FL Epoch: 132 Norm Difference for worker 1906 is 1.192664
INFO:root:FL Epoch: 132 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1574
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580551
INFO:root:Worker: 1574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496550
INFO:root:FL Epoch: 132 Norm Difference for worker 1574 is 1.228967
INFO:root:FL Epoch: 132 Done on worker:1574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :226
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.688699
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.496641
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 132 Norm Difference for worker 226 is 1.233776
INFO:root:FL Epoch: 132 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 132 Training on worker :1601
INFO:root:FL Epoch: 132 Using Learning rate : 0.03846545845395338 
INFO:root:FL Epoch: 132 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580016
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487845
INFO:root:FL Epoch: 132 Norm Difference for worker 1601 is 1.217292
INFO:root:FL Epoch: 132 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1906
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 132 Ends   ===================
INFO:root:Epoch:132 Global Model Test Loss:0.5234900204574361 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:132 Global Model Backdoor Test Loss:0.5592938512563705                             and Backdoor Test Accuracy:74.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 133 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 133 Workers Selected : [259, 1700, 1731, 1307, 1926, 196, 1034, 1663, 681, 1912]
INFO:root:FL Epoch: 133 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 133 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 133 Training on worker :259
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 259 Train Epoch: 0 [0/201 (0%)]	Loss: 0.443953
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 259 Train Epoch: 1 [0/201 (0%)]	Loss: 0.474908
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 133 Norm Difference for worker 259 is 0.985732
INFO:root:FL Epoch: 133 Done on worker:259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1700
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573275
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462901
INFO:root:FL Epoch: 133 Norm Difference for worker 1700 is 0.978045
INFO:root:FL Epoch: 133 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1731
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532021
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425105
INFO:root:FL Epoch: 133 Norm Difference for worker 1731 is 0.899714
INFO:root:FL Epoch: 133 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1307
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1307 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565246
INFO:root:Worker: 1307 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564617
INFO:root:FL Epoch: 133 Norm Difference for worker 1307 is 0.960894
INFO:root:FL Epoch: 133 Done on worker:1307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1926
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393820
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502971
INFO:root:FL Epoch: 133 Norm Difference for worker 1926 is 1.055139
INFO:root:FL Epoch: 133 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :196
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.488159
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.645677
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 133 Norm Difference for worker 196 is 0.995273
INFO:root:FL Epoch: 133 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1034
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1034 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587513
INFO:root:Worker: 1034 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506762
INFO:root:FL Epoch: 133 Norm Difference for worker 1034 is 0.944158
INFO:root:FL Epoch: 133 Done on worker:1034
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1663
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546657
INFO:root:Worker: 1663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463609
INFO:root:FL Epoch: 133 Norm Difference for worker 1663 is 0.954674
INFO:root:FL Epoch: 133 Done on worker:1663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :681
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788846
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568261
INFO:root:FL Epoch: 133 Norm Difference for worker 681 is 0.934754
INFO:root:FL Epoch: 133 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 133 Training on worker :1912
INFO:root:FL Epoch: 133 Using Learning rate : 0.038388527537045476 
INFO:root:FL Epoch: 133 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491015
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528164
INFO:root:FL Epoch: 133 Norm Difference for worker 1912 is 0.974873
INFO:root:FL Epoch: 133 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1731
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 133 Ends   ===================
INFO:root:Epoch:133 Global Model Test Loss:0.5165939856978023 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:133 Global Model Backdoor Test Loss:0.5606751541296641                             and Backdoor Test Accuracy:68.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 134 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 134 Workers Selected : [1762, 1215, 45, 1845, 286, 1365, 1646, 1010, 1553, 844]
INFO:root:FL Epoch: 134 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 134 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 134 Training on worker :1762
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1762 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447687
INFO:root:Worker: 1762 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321563
INFO:root:FL Epoch: 134 Norm Difference for worker 1762 is 0.997463
INFO:root:FL Epoch: 134 Done on worker:1762
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1215
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484152
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567637
INFO:root:FL Epoch: 134 Norm Difference for worker 1215 is 1.054127
INFO:root:FL Epoch: 134 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :45
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.795246
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.586178
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 134 Norm Difference for worker 45 is 1.123682
INFO:root:FL Epoch: 134 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1845
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723036
INFO:root:Worker: 1845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569860
INFO:root:FL Epoch: 134 Norm Difference for worker 1845 is 1.153245
INFO:root:FL Epoch: 134 Done on worker:1845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :286
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 286 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587204
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 286 Train Epoch: 1 [0/201 (0%)]	Loss: 0.524671
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 134 Norm Difference for worker 286 is 1.044042
INFO:root:FL Epoch: 134 Done on worker:286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1365
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538389
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540244
INFO:root:FL Epoch: 134 Norm Difference for worker 1365 is 1.089707
INFO:root:FL Epoch: 134 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1646
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1646 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483140
INFO:root:Worker: 1646 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420518
INFO:root:FL Epoch: 134 Norm Difference for worker 1646 is 1.031394
INFO:root:FL Epoch: 134 Done on worker:1646
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1010
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1010 Train Epoch: 0 [0/200 (0%)]	Loss: 1.063894
INFO:root:Worker: 1010 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583520
INFO:root:FL Epoch: 134 Norm Difference for worker 1010 is 0.993269
INFO:root:FL Epoch: 134 Done on worker:1010
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :1553
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 1553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334470
INFO:root:Worker: 1553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540415
INFO:root:FL Epoch: 134 Norm Difference for worker 1553 is 1.040098
INFO:root:FL Epoch: 134 Done on worker:1553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 134 Training on worker :844
INFO:root:FL Epoch: 134 Using Learning rate : 0.038311750481971385 
INFO:root:FL Epoch: 134 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621002
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481908
INFO:root:FL Epoch: 134 Norm Difference for worker 844 is 1.035803
INFO:root:FL Epoch: 134 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1762
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 134 Ends   ===================
INFO:root:Epoch:134 Global Model Test Loss:0.5240669916657841 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:134 Global Model Backdoor Test Loss:0.6047384242216746                             and Backdoor Test Accuracy:65.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 135 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 135 Workers Selected : [1923, 1447, 270, 798, 544, 980, 460, 1745, 163, 154]
INFO:root:FL Epoch: 135 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 135 Num points on workers: [200 200 201 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 135 Training on worker :1923
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776805
INFO:root:Worker: 1923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513797
INFO:root:FL Epoch: 135 Norm Difference for worker 1923 is 1.27594
INFO:root:FL Epoch: 135 Done on worker:1923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1447
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720601
INFO:root:Worker: 1447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487100
INFO:root:FL Epoch: 135 Norm Difference for worker 1447 is 1.192794
INFO:root:FL Epoch: 135 Done on worker:1447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :270
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.530869
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436413
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 270 is 1.24723
INFO:root:FL Epoch: 135 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :798
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638878
INFO:root:Worker: 798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483399
INFO:root:FL Epoch: 135 Norm Difference for worker 798 is 1.218528
INFO:root:FL Epoch: 135 Done on worker:798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :544
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470546
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.833097
INFO:root:FL Epoch: 135 Norm Difference for worker 544 is 1.272135
INFO:root:FL Epoch: 135 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :980
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 980 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749485
INFO:root:Worker: 980 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475569
INFO:root:FL Epoch: 135 Norm Difference for worker 980 is 1.193831
INFO:root:FL Epoch: 135 Done on worker:980
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :460
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637566
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453749
INFO:root:FL Epoch: 135 Norm Difference for worker 460 is 1.355759
INFO:root:FL Epoch: 135 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :1745
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615851
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422924
INFO:root:FL Epoch: 135 Norm Difference for worker 1745 is 1.198899
INFO:root:FL Epoch: 135 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :163
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.597131
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.375772
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 163 is 1.25836
INFO:root:FL Epoch: 135 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 135 Training on worker :154
INFO:root:FL Epoch: 135 Using Learning rate : 0.03823512698100744 
INFO:root:FL Epoch: 135 Normal Training
INFO:root:Worker: 154 Train Epoch: 0 [0/201 (0%)]	Loss: 0.524283
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 154 Train Epoch: 1 [0/201 (0%)]	Loss: 0.551343
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 135 Norm Difference for worker 154 is 1.34638
INFO:root:FL Epoch: 135 Done on worker:154
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1745
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 135 Ends   ===================
INFO:root:Epoch:135 Global Model Test Loss:0.5173984397860134 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:135 Global Model Backdoor Test Loss:0.6413063704967499                             and Backdoor Test Accuracy:61.666666666666664 
INFO:root:=======================================================
INFO:root:================FL round 136 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 136 Workers Selected : [279, 1641, 891, 1730, 629, 33, 1866, 1168, 116, 768]
INFO:root:FL Epoch: 136 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 136 Num points on workers: [201 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 136 Training on worker :279
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 279 Train Epoch: 0 [0/201 (0%)]	Loss: 0.572315
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 279 Train Epoch: 1 [0/201 (0%)]	Loss: 0.577923
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 279 is 1.07738
INFO:root:FL Epoch: 136 Done on worker:279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1641
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741341
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569027
INFO:root:FL Epoch: 136 Norm Difference for worker 1641 is 1.152408
INFO:root:FL Epoch: 136 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :891
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526239
INFO:root:Worker: 891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661553
INFO:root:FL Epoch: 136 Norm Difference for worker 891 is 1.164825
INFO:root:FL Epoch: 136 Done on worker:891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1730
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398402
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537680
INFO:root:FL Epoch: 136 Norm Difference for worker 1730 is 1.131797
INFO:root:FL Epoch: 136 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :629
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721484
INFO:root:Worker: 629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317528
INFO:root:FL Epoch: 136 Norm Difference for worker 629 is 1.138904
INFO:root:FL Epoch: 136 Done on worker:629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :33
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.636628
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.543399
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 33 is 1.162802
INFO:root:FL Epoch: 136 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1866
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788989
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638253
INFO:root:FL Epoch: 136 Norm Difference for worker 1866 is 1.128225
INFO:root:FL Epoch: 136 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :1168
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 1168 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492200
INFO:root:Worker: 1168 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560737
INFO:root:FL Epoch: 136 Norm Difference for worker 1168 is 1.031465
INFO:root:FL Epoch: 136 Done on worker:1168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :116
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.705470
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.490716
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 136 Norm Difference for worker 116 is 1.1597
INFO:root:FL Epoch: 136 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 136 Training on worker :768
INFO:root:FL Epoch: 136 Using Learning rate : 0.03815865672704543 
INFO:root:FL Epoch: 136 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725324
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435113
INFO:root:FL Epoch: 136 Norm Difference for worker 768 is 1.087313
INFO:root:FL Epoch: 136 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1168
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 136 Ends   ===================
INFO:root:Epoch:136 Global Model Test Loss:0.508187869015862 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:136 Global Model Backdoor Test Loss:0.6242710202932358                             and Backdoor Test Accuracy:69.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 137 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 137 Workers Selected : [1360, 906, 174, 354, 57, 1402, 694, 1585, 751, 225]
INFO:root:FL Epoch: 137 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 137 Num points on workers: [200 200 201 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 137 Training on worker :1360
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377089
INFO:root:Worker: 1360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.714749
INFO:root:FL Epoch: 137 Norm Difference for worker 1360 is 1.204057
INFO:root:FL Epoch: 137 Done on worker:1360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :906
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551470
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515054
INFO:root:FL Epoch: 137 Norm Difference for worker 906 is 1.179615
INFO:root:FL Epoch: 137 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :174
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 0.627867
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.467336
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 137 Norm Difference for worker 174 is 1.118887
INFO:root:FL Epoch: 137 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :354
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585727
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621725
INFO:root:FL Epoch: 137 Norm Difference for worker 354 is 1.151174
INFO:root:FL Epoch: 137 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :57
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 57 Train Epoch: 0 [0/201 (0%)]	Loss: 0.641942
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 57 Train Epoch: 1 [0/201 (0%)]	Loss: 0.741926
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 137 Norm Difference for worker 57 is 1.086537
INFO:root:FL Epoch: 137 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1402
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1402 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658784
INFO:root:Worker: 1402 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472863
INFO:root:FL Epoch: 137 Norm Difference for worker 1402 is 1.138799
INFO:root:FL Epoch: 137 Done on worker:1402
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :694
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546415
INFO:root:Worker: 694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475390
INFO:root:FL Epoch: 137 Norm Difference for worker 694 is 1.117996
INFO:root:FL Epoch: 137 Done on worker:694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :1585
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421104
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435393
INFO:root:FL Epoch: 137 Norm Difference for worker 1585 is 1.248765
INFO:root:FL Epoch: 137 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :751
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.819023
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222028
INFO:root:FL Epoch: 137 Norm Difference for worker 751 is 1.128935
INFO:root:FL Epoch: 137 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 137 Training on worker :225
INFO:root:FL Epoch: 137 Using Learning rate : 0.03808233941359134 
INFO:root:FL Epoch: 137 Normal Training
INFO:root:Worker: 225 Train Epoch: 0 [0/201 (0%)]	Loss: 0.570929
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 225 Train Epoch: 1 [0/201 (0%)]	Loss: 0.592946
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 137 Norm Difference for worker 225 is 1.211536
INFO:root:FL Epoch: 137 Done on worker:225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 751
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 137 Ends   ===================
INFO:root:Epoch:137 Global Model Test Loss:0.5057926370817072 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:137 Global Model Backdoor Test Loss:0.7867649098237356                             and Backdoor Test Accuracy:52.5 
INFO:root:=======================================================
INFO:root:================FL round 138 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 138 Workers Selected : [278, 1091, 1259, 475, 72, 827, 1604, 738, 263, 818]
INFO:root:FL Epoch: 138 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 138 Num points on workers: [201 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 138 Training on worker :278
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.713136
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.564721
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 278 is 1.206667
INFO:root:FL Epoch: 138 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1091
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1091 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570454
INFO:root:Worker: 1091 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520243
INFO:root:FL Epoch: 138 Norm Difference for worker 1091 is 1.138035
INFO:root:FL Epoch: 138 Done on worker:1091
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1259
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544569
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625725
INFO:root:FL Epoch: 138 Norm Difference for worker 1259 is 1.146449
INFO:root:FL Epoch: 138 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :475
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670964
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430900
INFO:root:FL Epoch: 138 Norm Difference for worker 475 is 1.112369
INFO:root:FL Epoch: 138 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :72
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.392397
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.441853
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 72 is 1.147399
INFO:root:FL Epoch: 138 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :827
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736176
INFO:root:Worker: 827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650626
INFO:root:FL Epoch: 138 Norm Difference for worker 827 is 1.21343
INFO:root:FL Epoch: 138 Done on worker:827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :1604
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 1604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711445
INFO:root:Worker: 1604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582362
INFO:root:FL Epoch: 138 Norm Difference for worker 1604 is 1.238618
INFO:root:FL Epoch: 138 Done on worker:1604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :738
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646210
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615949
INFO:root:FL Epoch: 138 Norm Difference for worker 738 is 1.107046
INFO:root:FL Epoch: 138 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :263
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 263 Train Epoch: 0 [0/201 (0%)]	Loss: 0.555828
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 263 Train Epoch: 1 [0/201 (0%)]	Loss: 0.291831
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 138 Norm Difference for worker 263 is 1.140557
INFO:root:FL Epoch: 138 Done on worker:263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 138 Training on worker :818
INFO:root:FL Epoch: 138 Using Learning rate : 0.038006174734764156 
INFO:root:FL Epoch: 138 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717006
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.736574
INFO:root:FL Epoch: 138 Norm Difference for worker 818 is 1.179188
INFO:root:FL Epoch: 138 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1259
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 138 Ends   ===================
INFO:root:Epoch:138 Global Model Test Loss:0.5246151790899389 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:138 Global Model Backdoor Test Loss:0.6575270891189575                             and Backdoor Test Accuracy:64.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 139 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 139 Workers Selected : [1104, 1882, 211, 1240, 589, 1791, 931, 314, 1652, 1945]
INFO:root:FL Epoch: 139 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 139 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 139 Training on worker :1104
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564120
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654120
INFO:root:FL Epoch: 139 Norm Difference for worker 1104 is 0.908314
INFO:root:FL Epoch: 139 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1882
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463469
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443832
INFO:root:FL Epoch: 139 Norm Difference for worker 1882 is 0.914107
INFO:root:FL Epoch: 139 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :211
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.603349
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.522932
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 139 Norm Difference for worker 211 is 0.924545
INFO:root:FL Epoch: 139 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1240
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1240 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685476
INFO:root:Worker: 1240 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586375
INFO:root:FL Epoch: 139 Norm Difference for worker 1240 is 0.937683
INFO:root:FL Epoch: 139 Done on worker:1240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :589
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.777121
INFO:root:Worker: 589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539482
INFO:root:FL Epoch: 139 Norm Difference for worker 589 is 0.907318
INFO:root:FL Epoch: 139 Done on worker:589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1791
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771612
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635714
INFO:root:FL Epoch: 139 Norm Difference for worker 1791 is 0.93619
INFO:root:FL Epoch: 139 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :931
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582733
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464774
INFO:root:FL Epoch: 139 Norm Difference for worker 931 is 0.963259
INFO:root:FL Epoch: 139 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :314
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 314 Train Epoch: 0 [0/201 (0%)]	Loss: 0.797062
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 314 Train Epoch: 1 [0/201 (0%)]	Loss: 0.625379
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 139 Norm Difference for worker 314 is 0.949
INFO:root:FL Epoch: 139 Done on worker:314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1652
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.732432
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552081
INFO:root:FL Epoch: 139 Norm Difference for worker 1652 is 0.915772
INFO:root:FL Epoch: 139 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 139 Training on worker :1945
INFO:root:FL Epoch: 139 Using Learning rate : 0.037930162385294626 
INFO:root:FL Epoch: 139 Normal Training
INFO:root:Worker: 1945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567742
INFO:root:Worker: 1945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411077
INFO:root:FL Epoch: 139 Norm Difference for worker 1945 is 0.932411
INFO:root:FL Epoch: 139 Done on worker:1945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 589
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 139 Ends   ===================
INFO:root:Epoch:139 Global Model Test Loss:0.5110598171458525 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:139 Global Model Backdoor Test Loss:0.8132237394650778                             and Backdoor Test Accuracy:45.0 
INFO:root:=======================================================
INFO:root:================FL round 140 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 140 Workers Selected : [112, 969, 1814, 1150, 986, 1819, 48, 650, 117, 1216]
INFO:root:FL Epoch: 140 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 140 Num points on workers: [201 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 140 Training on worker :112
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 112 Train Epoch: 0 [0/201 (0%)]	Loss: 0.493484
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 112 Train Epoch: 1 [0/201 (0%)]	Loss: 0.326041
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 140 Norm Difference for worker 112 is 1.001621
INFO:root:FL Epoch: 140 Done on worker:112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :969
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 969 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380706
INFO:root:Worker: 969 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396150
INFO:root:FL Epoch: 140 Norm Difference for worker 969 is 0.999257
INFO:root:FL Epoch: 140 Done on worker:969
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1814
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664424
INFO:root:Worker: 1814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384167
INFO:root:FL Epoch: 140 Norm Difference for worker 1814 is 1.012507
INFO:root:FL Epoch: 140 Done on worker:1814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1150
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1150 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583465
INFO:root:Worker: 1150 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698935
INFO:root:FL Epoch: 140 Norm Difference for worker 1150 is 1.026282
INFO:root:FL Epoch: 140 Done on worker:1150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :986
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.953114
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608991
INFO:root:FL Epoch: 140 Norm Difference for worker 986 is 1.031483
INFO:root:FL Epoch: 140 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1819
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1819 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602858
INFO:root:Worker: 1819 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629264
INFO:root:FL Epoch: 140 Norm Difference for worker 1819 is 0.995913
INFO:root:FL Epoch: 140 Done on worker:1819
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :48
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.555552
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450487
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 140 Norm Difference for worker 48 is 0.981224
INFO:root:FL Epoch: 140 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :650
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693474
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488393
INFO:root:FL Epoch: 140 Norm Difference for worker 650 is 1.033121
INFO:root:FL Epoch: 140 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :117
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.625178
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.532531
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 140 Norm Difference for worker 117 is 0.985937
INFO:root:FL Epoch: 140 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 140 Training on worker :1216
INFO:root:FL Epoch: 140 Using Learning rate : 0.03785430206052404 
INFO:root:FL Epoch: 140 Normal Training
INFO:root:Worker: 1216 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687071
INFO:root:Worker: 1216 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506310
INFO:root:FL Epoch: 140 Norm Difference for worker 1216 is 1.080648
INFO:root:FL Epoch: 140 Done on worker:1216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 112
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 140 Ends   ===================
INFO:root:Epoch:140 Global Model Test Loss:0.5042384424630333 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:140 Global Model Backdoor Test Loss:0.7555238902568817                             and Backdoor Test Accuracy:52.5 
INFO:root:=======================================================
INFO:root:================FL round 141 Begins ===================
INFO:root:FL Epoch: 141 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 141 Workers Selected : [0, 847, 348, 1203, 1247, 1752, 1077, 630, 852, 549]
INFO:root:FL Epoch: 141 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 141 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 141 Training on worker :0
INFO:root:FL Epoch: 141 Using Learning rate : 0.007555718691280597 
INFO:root:FL Epoch: 141 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491154
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599271
INFO:root:FL Epoch: 141 Worker: 0 Backdoor Test Loss: 0.4644620070854823 Backdoor Test Accuracy: 80.83333333333333
INFO:root:FL Epoch: 141 Worker: 0 Backdoor Train Loss: 0.46348483860492706 Backdoor Train Accuracy: 80.0
INFO:root:FL Epoch: 141 Norm Difference for worker 0 is 0.320637
INFO:root:FL Epoch: 141 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :847
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505594
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539331
INFO:root:FL Epoch: 141 Norm Difference for worker 847 is 0.978132
INFO:root:FL Epoch: 141 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :348
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706516
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572315
INFO:root:FL Epoch: 141 Norm Difference for worker 348 is 1.04014
INFO:root:FL Epoch: 141 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1203
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1203 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568711
INFO:root:Worker: 1203 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603027
INFO:root:FL Epoch: 141 Norm Difference for worker 1203 is 1.061408
INFO:root:FL Epoch: 141 Done on worker:1203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1247
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675572
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569480
INFO:root:FL Epoch: 141 Norm Difference for worker 1247 is 1.020125
INFO:root:FL Epoch: 141 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1752
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695224
INFO:root:Worker: 1752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340834
INFO:root:FL Epoch: 141 Norm Difference for worker 1752 is 1.058986
INFO:root:FL Epoch: 141 Done on worker:1752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :1077
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 1077 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454021
INFO:root:Worker: 1077 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324376
INFO:root:FL Epoch: 141 Norm Difference for worker 1077 is 1.045964
INFO:root:FL Epoch: 141 Done on worker:1077
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :630
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684104
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527691
INFO:root:FL Epoch: 141 Norm Difference for worker 630 is 1.047583
INFO:root:FL Epoch: 141 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :852
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527424
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467965
INFO:root:FL Epoch: 141 Norm Difference for worker 852 is 1.03785
INFO:root:FL Epoch: 141 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 141 Training on worker :549
INFO:root:FL Epoch: 141 Using Learning rate : 0.03777859345640299 
INFO:root:FL Epoch: 141 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664895
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583259
INFO:root:FL Epoch: 141 Norm Difference for worker 549 is 1.086854
INFO:root:FL Epoch: 141 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 141 Ends   ===================
INFO:root:Epoch:141 Global Model Test Loss:0.5056367516517639 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:141 Global Model Backdoor Test Loss:0.4644620070854823                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 142 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 142 Workers Selected : [752, 1148, 735, 1623, 1295, 1134, 466, 1667, 1130, 1538]
INFO:root:FL Epoch: 142 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 142 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 142 Training on worker :752
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679240
INFO:root:Worker: 752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524953
INFO:root:FL Epoch: 142 Norm Difference for worker 752 is 1.040365
INFO:root:FL Epoch: 142 Done on worker:752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1148
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554829
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371056
INFO:root:FL Epoch: 142 Norm Difference for worker 1148 is 1.002368
INFO:root:FL Epoch: 142 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :735
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 735 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631907
INFO:root:Worker: 735 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546514
INFO:root:FL Epoch: 142 Norm Difference for worker 735 is 1.018781
INFO:root:FL Epoch: 142 Done on worker:735
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1623
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521668
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461371
INFO:root:FL Epoch: 142 Norm Difference for worker 1623 is 0.981412
INFO:root:FL Epoch: 142 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1295
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671998
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458628
INFO:root:FL Epoch: 142 Norm Difference for worker 1295 is 1.013931
INFO:root:FL Epoch: 142 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1134
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1134 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436798
INFO:root:Worker: 1134 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405403
INFO:root:FL Epoch: 142 Norm Difference for worker 1134 is 1.144047
INFO:root:FL Epoch: 142 Done on worker:1134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :466
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 466 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552046
INFO:root:Worker: 466 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554654
INFO:root:FL Epoch: 142 Norm Difference for worker 466 is 0.982314
INFO:root:FL Epoch: 142 Done on worker:466
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1667
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688826
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613615
INFO:root:FL Epoch: 142 Norm Difference for worker 1667 is 1.044397
INFO:root:FL Epoch: 142 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1130
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1130 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386962
INFO:root:Worker: 1130 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502596
INFO:root:FL Epoch: 142 Norm Difference for worker 1130 is 1.076425
INFO:root:FL Epoch: 142 Done on worker:1130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 142 Training on worker :1538
INFO:root:FL Epoch: 142 Using Learning rate : 0.03770303626949018 
INFO:root:FL Epoch: 142 Normal Training
INFO:root:Worker: 1538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648157
INFO:root:Worker: 1538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503455
INFO:root:FL Epoch: 142 Norm Difference for worker 1538 is 0.994427
INFO:root:FL Epoch: 142 Done on worker:1538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 466
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 142 Ends   ===================
INFO:root:Epoch:142 Global Model Test Loss:0.4914744391160853 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:142 Global Model Backdoor Test Loss:0.44686583677927655                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 143 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 143 Workers Selected : [1147, 69, 638, 1747, 1518, 692, 1267, 1754, 1756, 821]
INFO:root:FL Epoch: 143 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 143 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 143 Training on worker :1147
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1147 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597438
INFO:root:Worker: 1147 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627021
INFO:root:FL Epoch: 143 Norm Difference for worker 1147 is 1.279503
INFO:root:FL Epoch: 143 Done on worker:1147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :69
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 69 Train Epoch: 0 [0/201 (0%)]	Loss: 0.644680
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 69 Train Epoch: 1 [0/201 (0%)]	Loss: 0.433539
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 143 Norm Difference for worker 69 is 1.142614
INFO:root:FL Epoch: 143 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :638
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526601
INFO:root:Worker: 638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329075
INFO:root:FL Epoch: 143 Norm Difference for worker 638 is 1.082021
INFO:root:FL Epoch: 143 Done on worker:638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1747
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525871
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515943
INFO:root:FL Epoch: 143 Norm Difference for worker 1747 is 1.278906
INFO:root:FL Epoch: 143 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1518
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655280
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285420
INFO:root:FL Epoch: 143 Norm Difference for worker 1518 is 1.295762
INFO:root:FL Epoch: 143 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :692
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433551
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536080
INFO:root:FL Epoch: 143 Norm Difference for worker 692 is 1.203057
INFO:root:FL Epoch: 143 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1267
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1267 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403955
INFO:root:Worker: 1267 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477483
INFO:root:FL Epoch: 143 Norm Difference for worker 1267 is 1.159957
INFO:root:FL Epoch: 143 Done on worker:1267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1754
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536092
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707107
INFO:root:FL Epoch: 143 Norm Difference for worker 1754 is 1.107781
INFO:root:FL Epoch: 143 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :1756
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 1756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530227
INFO:root:Worker: 1756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535151
INFO:root:FL Epoch: 143 Norm Difference for worker 1756 is 1.240409
INFO:root:FL Epoch: 143 Done on worker:1756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 143 Training on worker :821
INFO:root:FL Epoch: 143 Using Learning rate : 0.0376276301969512 
INFO:root:FL Epoch: 143 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512174
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590702
INFO:root:FL Epoch: 143 Norm Difference for worker 821 is 1.205666
INFO:root:FL Epoch: 143 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 638
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 143 Ends   ===================
INFO:root:Epoch:143 Global Model Test Loss:0.5152105846825767 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:143 Global Model Backdoor Test Loss:0.4222881148258845                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 144 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 144 Workers Selected : [1610, 1581, 1101, 1061, 1350, 1109, 903, 792, 1408, 639]
INFO:root:FL Epoch: 144 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 144 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 144 Training on worker :1610
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1610 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436854
INFO:root:Worker: 1610 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465679
INFO:root:FL Epoch: 144 Norm Difference for worker 1610 is 1.387329
INFO:root:FL Epoch: 144 Done on worker:1610
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1581
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745758
INFO:root:Worker: 1581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.667150
INFO:root:FL Epoch: 144 Norm Difference for worker 1581 is 1.354028
INFO:root:FL Epoch: 144 Done on worker:1581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1101
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1101 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701360
INFO:root:Worker: 1101 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442398
INFO:root:FL Epoch: 144 Norm Difference for worker 1101 is 1.271818
INFO:root:FL Epoch: 144 Done on worker:1101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1061
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673850
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625129
INFO:root:FL Epoch: 144 Norm Difference for worker 1061 is 1.311991
INFO:root:FL Epoch: 144 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1350
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657843
INFO:root:Worker: 1350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471395
INFO:root:FL Epoch: 144 Norm Difference for worker 1350 is 1.323316
INFO:root:FL Epoch: 144 Done on worker:1350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1109
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1109 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635579
INFO:root:Worker: 1109 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602909
INFO:root:FL Epoch: 144 Norm Difference for worker 1109 is 1.354965
INFO:root:FL Epoch: 144 Done on worker:1109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :903
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514398
INFO:root:Worker: 903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511651
INFO:root:FL Epoch: 144 Norm Difference for worker 903 is 1.260875
INFO:root:FL Epoch: 144 Done on worker:903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :792
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.804737
INFO:root:Worker: 792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399332
INFO:root:FL Epoch: 144 Norm Difference for worker 792 is 1.298916
INFO:root:FL Epoch: 144 Done on worker:792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :1408
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689001
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462532
INFO:root:FL Epoch: 144 Norm Difference for worker 1408 is 1.320709
INFO:root:FL Epoch: 144 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 144 Training on worker :639
INFO:root:FL Epoch: 144 Using Learning rate : 0.0375523749365573 
INFO:root:FL Epoch: 144 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407164
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406978
INFO:root:FL Epoch: 144 Norm Difference for worker 639 is 1.203688
INFO:root:FL Epoch: 144 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 639
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 144 Ends   ===================
INFO:root:Epoch:144 Global Model Test Loss:0.5048762559890747 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:144 Global Model Backdoor Test Loss:0.7010086377461752                             and Backdoor Test Accuracy:59.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 145 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 145 Workers Selected : [593, 1441, 1324, 718, 641, 611, 1429, 657, 840, 1004]
INFO:root:FL Epoch: 145 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 145 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 145 Training on worker :593
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551131
INFO:root:Worker: 593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415940
INFO:root:FL Epoch: 145 Norm Difference for worker 593 is 1.346373
INFO:root:FL Epoch: 145 Done on worker:593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1441
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386628
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640744
INFO:root:FL Epoch: 145 Norm Difference for worker 1441 is 1.227808
INFO:root:FL Epoch: 145 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1324
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479232
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479316
INFO:root:FL Epoch: 145 Norm Difference for worker 1324 is 1.297751
INFO:root:FL Epoch: 145 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :718
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614234
INFO:root:Worker: 718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547408
INFO:root:FL Epoch: 145 Norm Difference for worker 718 is 1.28008
INFO:root:FL Epoch: 145 Done on worker:718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :641
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558220
INFO:root:Worker: 641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.787219
INFO:root:FL Epoch: 145 Norm Difference for worker 641 is 1.415935
INFO:root:FL Epoch: 145 Done on worker:641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :611
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621956
INFO:root:Worker: 611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417399
INFO:root:FL Epoch: 145 Norm Difference for worker 611 is 1.30086
INFO:root:FL Epoch: 145 Done on worker:611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1429
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796957
INFO:root:Worker: 1429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438475
INFO:root:FL Epoch: 145 Norm Difference for worker 1429 is 1.245147
INFO:root:FL Epoch: 145 Done on worker:1429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :657
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663108
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569023
INFO:root:FL Epoch: 145 Norm Difference for worker 657 is 1.224278
INFO:root:FL Epoch: 145 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :840
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595825
INFO:root:Worker: 840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565552
INFO:root:FL Epoch: 145 Norm Difference for worker 840 is 1.226106
INFO:root:FL Epoch: 145 Done on worker:840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 145 Training on worker :1004
INFO:root:FL Epoch: 145 Using Learning rate : 0.03747727018668418 
INFO:root:FL Epoch: 145 Normal Training
INFO:root:Worker: 1004 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672541
INFO:root:Worker: 1004 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513498
INFO:root:FL Epoch: 145 Norm Difference for worker 1004 is 1.30161
INFO:root:FL Epoch: 145 Done on worker:1004
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1429
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 145 Ends   ===================
INFO:root:Epoch:145 Global Model Test Loss:0.5131049611989189 and Test Accuracy:75.0 
INFO:root:Epoch:145 Global Model Backdoor Test Loss:0.558587059378624                             and Backdoor Test Accuracy:72.5 
INFO:root:=======================================================
INFO:root:================FL round 146 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 146 Workers Selected : [210, 25, 20, 407, 1117, 1625, 609, 799, 24, 823]
INFO:root:FL Epoch: 146 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.1002994 0.0998004 0.0998004 0.0998004 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 146 Num points on workers: [201 201 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 146 Training on worker :210
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 210 Train Epoch: 0 [0/201 (0%)]	Loss: 0.654267
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 210 Train Epoch: 1 [0/201 (0%)]	Loss: 0.509553
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 146 Norm Difference for worker 210 is 1.071544
INFO:root:FL Epoch: 146 Done on worker:210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :25
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.416948
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.583707
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 146 Norm Difference for worker 25 is 1.030284
INFO:root:FL Epoch: 146 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :20
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.624663
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.542484
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 146 Norm Difference for worker 20 is 1.059266
INFO:root:FL Epoch: 146 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :407
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624927
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455318
INFO:root:FL Epoch: 146 Norm Difference for worker 407 is 1.016474
INFO:root:FL Epoch: 146 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :1117
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1117 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475751
INFO:root:Worker: 1117 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518194
INFO:root:FL Epoch: 146 Norm Difference for worker 1117 is 1.051067
INFO:root:FL Epoch: 146 Done on worker:1117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :1625
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 1625 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700934
INFO:root:Worker: 1625 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451733
INFO:root:FL Epoch: 146 Norm Difference for worker 1625 is 1.046462
INFO:root:FL Epoch: 146 Done on worker:1625
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :609
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513705
INFO:root:Worker: 609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504010
INFO:root:FL Epoch: 146 Norm Difference for worker 609 is 1.108325
INFO:root:FL Epoch: 146 Done on worker:609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :799
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568572
INFO:root:Worker: 799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464286
INFO:root:FL Epoch: 146 Norm Difference for worker 799 is 1.04852
INFO:root:FL Epoch: 146 Done on worker:799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :24
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.634418
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.438790
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 146 Norm Difference for worker 24 is 1.089504
INFO:root:FL Epoch: 146 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 146 Training on worker :823
INFO:root:FL Epoch: 146 Using Learning rate : 0.037402315646310816 
INFO:root:FL Epoch: 146 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402332
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476321
INFO:root:FL Epoch: 146 Norm Difference for worker 823 is 1.100667
INFO:root:FL Epoch: 146 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 407
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 146 Ends   ===================
INFO:root:Epoch:146 Global Model Test Loss:0.5197374592809116 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:146 Global Model Backdoor Test Loss:0.7875465651353201                             and Backdoor Test Accuracy:50.0 
INFO:root:=======================================================
INFO:root:================FL round 147 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 147 Workers Selected : [416, 1, 880, 409, 510, 1701, 1033, 1133, 696, 163]
INFO:root:FL Epoch: 147 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 147 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 147 Training on worker :416
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705799
INFO:root:Worker: 416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379343
INFO:root:FL Epoch: 147 Norm Difference for worker 416 is 1.084482
INFO:root:FL Epoch: 147 Done on worker:416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1 Train Epoch: 0 [0/201 (0%)]	Loss: 0.905268
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 1 Train Epoch: 1 [0/201 (0%)]	Loss: 0.609202
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 147 Norm Difference for worker 1 is 1.021027
INFO:root:FL Epoch: 147 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :880
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544635
INFO:root:Worker: 880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493455
INFO:root:FL Epoch: 147 Norm Difference for worker 880 is 1.034414
INFO:root:FL Epoch: 147 Done on worker:880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :409
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512290
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540018
INFO:root:FL Epoch: 147 Norm Difference for worker 409 is 1.09522
INFO:root:FL Epoch: 147 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :510
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647403
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640439
INFO:root:FL Epoch: 147 Norm Difference for worker 510 is 1.088435
INFO:root:FL Epoch: 147 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1701
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612559
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399017
INFO:root:FL Epoch: 147 Norm Difference for worker 1701 is 0.990771
INFO:root:FL Epoch: 147 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1033
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1033 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619529
INFO:root:Worker: 1033 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462230
INFO:root:FL Epoch: 147 Norm Difference for worker 1033 is 1.000588
INFO:root:FL Epoch: 147 Done on worker:1033
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :1133
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 1133 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753554
INFO:root:Worker: 1133 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425921
INFO:root:FL Epoch: 147 Norm Difference for worker 1133 is 1.080016
INFO:root:FL Epoch: 147 Done on worker:1133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :696
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665496
INFO:root:Worker: 696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465567
INFO:root:FL Epoch: 147 Norm Difference for worker 696 is 1.083731
INFO:root:FL Epoch: 147 Done on worker:696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 147 Training on worker :163
INFO:root:FL Epoch: 147 Using Learning rate : 0.037327511015018196 
INFO:root:FL Epoch: 147 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.585766
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.434234
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 147 Norm Difference for worker 163 is 1.061789
INFO:root:FL Epoch: 147 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1033
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 147 Ends   ===================
INFO:root:Epoch:147 Global Model Test Loss:0.5047258962603176 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:147 Global Model Backdoor Test Loss:0.6269653936227163                             and Backdoor Test Accuracy:65.0 
INFO:root:=======================================================
INFO:root:================FL round 148 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 148 Workers Selected : [942, 781, 1222, 801, 823, 334, 916, 602, 101, 553]
INFO:root:FL Epoch: 148 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 148 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 148 Training on worker :942
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646350
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503494
INFO:root:FL Epoch: 148 Norm Difference for worker 942 is 1.117129
INFO:root:FL Epoch: 148 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :781
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490307
INFO:root:Worker: 781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587813
INFO:root:FL Epoch: 148 Norm Difference for worker 781 is 1.154438
INFO:root:FL Epoch: 148 Done on worker:781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :1222
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 1222 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430090
INFO:root:Worker: 1222 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445495
INFO:root:FL Epoch: 148 Norm Difference for worker 1222 is 1.100483
INFO:root:FL Epoch: 148 Done on worker:1222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :801
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320717
INFO:root:Worker: 801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285352
INFO:root:FL Epoch: 148 Norm Difference for worker 801 is 1.075146
INFO:root:FL Epoch: 148 Done on worker:801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :823
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569007
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433214
INFO:root:FL Epoch: 148 Norm Difference for worker 823 is 1.139668
INFO:root:FL Epoch: 148 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :334
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503256
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.398460
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 148 Norm Difference for worker 334 is 1.130629
INFO:root:FL Epoch: 148 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :916
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540293
INFO:root:Worker: 916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527708
INFO:root:FL Epoch: 148 Norm Difference for worker 916 is 1.124597
INFO:root:FL Epoch: 148 Done on worker:916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :602
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554972
INFO:root:Worker: 602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438043
INFO:root:FL Epoch: 148 Norm Difference for worker 602 is 1.133025
INFO:root:FL Epoch: 148 Done on worker:602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :101
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.479707
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.665156
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 148 Norm Difference for worker 101 is 1.125861
INFO:root:FL Epoch: 148 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 148 Training on worker :553
INFO:root:FL Epoch: 148 Using Learning rate : 0.03725285599298816 
INFO:root:FL Epoch: 148 Normal Training
INFO:root:Worker: 553 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489345
INFO:root:Worker: 553 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483721
INFO:root:FL Epoch: 148 Norm Difference for worker 553 is 1.074038
INFO:root:FL Epoch: 148 Done on worker:553
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 801
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 148 Ends   ===================
INFO:root:Epoch:148 Global Model Test Loss:0.5042364790159113 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:148 Global Model Backdoor Test Loss:0.7753627697626749                             and Backdoor Test Accuracy:55.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 149 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 149 Workers Selected : [574, 350, 747, 196, 505, 561, 379, 1777, 689, 1396]
INFO:root:FL Epoch: 149 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 149 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 149 Training on worker :574
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599221
INFO:root:Worker: 574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573183
INFO:root:FL Epoch: 149 Norm Difference for worker 574 is 1.249145
INFO:root:FL Epoch: 149 Done on worker:574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :350
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 350 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702852
INFO:root:Worker: 350 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699467
INFO:root:FL Epoch: 149 Norm Difference for worker 350 is 1.269314
INFO:root:FL Epoch: 149 Done on worker:350
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :747
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534900
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446017
INFO:root:FL Epoch: 149 Norm Difference for worker 747 is 1.225532
INFO:root:FL Epoch: 149 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :196
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.557416
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.502807
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 149 Norm Difference for worker 196 is 1.240402
INFO:root:FL Epoch: 149 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :505
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576919
INFO:root:Worker: 505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425317
INFO:root:FL Epoch: 149 Norm Difference for worker 505 is 1.206848
INFO:root:FL Epoch: 149 Done on worker:505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :561
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.799308
INFO:root:Worker: 561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533087
INFO:root:FL Epoch: 149 Norm Difference for worker 561 is 1.286624
INFO:root:FL Epoch: 149 Done on worker:561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :379
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536377
INFO:root:Worker: 379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358414
INFO:root:FL Epoch: 149 Norm Difference for worker 379 is 1.255773
INFO:root:FL Epoch: 149 Done on worker:379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1777
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466559
INFO:root:Worker: 1777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552691
INFO:root:FL Epoch: 149 Norm Difference for worker 1777 is 1.226555
INFO:root:FL Epoch: 149 Done on worker:1777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :689
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546908
INFO:root:Worker: 689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578205
INFO:root:FL Epoch: 149 Norm Difference for worker 689 is 1.280854
INFO:root:FL Epoch: 149 Done on worker:689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 149 Training on worker :1396
INFO:root:FL Epoch: 149 Using Learning rate : 0.037178350281002186 
INFO:root:FL Epoch: 149 Normal Training
INFO:root:Worker: 1396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758841
INFO:root:Worker: 1396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408456
INFO:root:FL Epoch: 149 Norm Difference for worker 1396 is 1.182504
INFO:root:FL Epoch: 149 Done on worker:1396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 505
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 149 Ends   ===================
INFO:root:Epoch:149 Global Model Test Loss:0.5125514829860014 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:149 Global Model Backdoor Test Loss:0.7421214779218038                             and Backdoor Test Accuracy:55.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 150 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 150 Workers Selected : [1265, 1756, 1912, 1934, 307, 422, 297, 1150, 1736, 501]
INFO:root:FL Epoch: 150 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 150 Num points on workers: [200 200 200 200 201 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 150 Training on worker :1265
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496693
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628557
INFO:root:FL Epoch: 150 Norm Difference for worker 1265 is 1.04198
INFO:root:FL Epoch: 150 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1756
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669552
INFO:root:Worker: 1756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419752
INFO:root:FL Epoch: 150 Norm Difference for worker 1756 is 1.016835
INFO:root:FL Epoch: 150 Done on worker:1756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1912
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512404
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335599
INFO:root:FL Epoch: 150 Norm Difference for worker 1912 is 1.019992
INFO:root:FL Epoch: 150 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1934
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447952
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414079
INFO:root:FL Epoch: 150 Norm Difference for worker 1934 is 1.068614
INFO:root:FL Epoch: 150 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :307
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 307 Train Epoch: 0 [0/201 (0%)]	Loss: 0.705723
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 307 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446690
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 307 is 1.016545
INFO:root:FL Epoch: 150 Done on worker:307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :422
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536785
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420622
INFO:root:FL Epoch: 150 Norm Difference for worker 422 is 1.035372
INFO:root:FL Epoch: 150 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :297
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 297 Train Epoch: 0 [0/201 (0%)]	Loss: 0.545574
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 297 Train Epoch: 1 [0/201 (0%)]	Loss: 0.360737
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 150 Norm Difference for worker 297 is 1.077526
INFO:root:FL Epoch: 150 Done on worker:297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1150
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1150 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555271
INFO:root:Worker: 1150 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471702
INFO:root:FL Epoch: 150 Norm Difference for worker 1150 is 1.001507
INFO:root:FL Epoch: 150 Done on worker:1150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :1736
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508854
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527361
INFO:root:FL Epoch: 150 Norm Difference for worker 1736 is 1.008855
INFO:root:FL Epoch: 150 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 150 Training on worker :501
INFO:root:FL Epoch: 150 Using Learning rate : 0.03710399358044018 
INFO:root:FL Epoch: 150 Normal Training
INFO:root:Worker: 501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590987
INFO:root:Worker: 501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473954
INFO:root:FL Epoch: 150 Norm Difference for worker 501 is 1.029524
INFO:root:FL Epoch: 150 Done on worker:501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1150
INFO:root:Norm of Aggregated Model: 5154.98828125
INFO:root:Aggregating After Defense
INFO:root:================FL round 150 Ends   ===================
INFO:root:Epoch:150 Global Model Test Loss:0.5152714988764595 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:150 Global Model Backdoor Test Loss:0.9414820075035095                             and Backdoor Test Accuracy:39.166666666666664 
INFO:root:=======================================================
INFO:root:================FL round 151 Begins ===================
INFO:root:FL Epoch: 151 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 151 Workers Selected : [0, 1062, 746, 880, 211, 125, 1337, 847, 1578, 1047]
INFO:root:FL Epoch: 151 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 151 Num points on workers: [200 200 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 151 Training on worker :0
INFO:root:FL Epoch: 151 Using Learning rate : 0.00740595711865586 
INFO:root:FL Epoch: 151 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574217
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408152
INFO:root:FL Epoch: 151 Worker: 0 Backdoor Test Loss: 0.3828074832757314 Backdoor Test Accuracy: 86.66666666666667
INFO:root:FL Epoch: 151 Worker: 0 Backdoor Train Loss: 0.45281524062156675 Backdoor Train Accuracy: 76.5
INFO:root:FL Epoch: 151 Norm Difference for worker 0 is 0.396783
INFO:root:FL Epoch: 151 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1062
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1062 Train Epoch: 0 [0/200 (0%)]	Loss: 0.882455
INFO:root:Worker: 1062 Train Epoch: 1 [0/200 (0%)]	Loss: 0.755264
INFO:root:FL Epoch: 151 Norm Difference for worker 1062 is 1.056614
INFO:root:FL Epoch: 151 Done on worker:1062
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :746
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 746 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567005
INFO:root:Worker: 746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562654
INFO:root:FL Epoch: 151 Norm Difference for worker 746 is 1.011771
INFO:root:FL Epoch: 151 Done on worker:746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :880
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655660
INFO:root:Worker: 880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532845
INFO:root:FL Epoch: 151 Norm Difference for worker 880 is 1.029596
INFO:root:FL Epoch: 151 Done on worker:880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :211
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.776046
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.472982
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 151 Norm Difference for worker 211 is 1.052593
INFO:root:FL Epoch: 151 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :125
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.483442
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.407205
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 151 Norm Difference for worker 125 is 0.991425
INFO:root:FL Epoch: 151 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1337
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1337 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561512
INFO:root:Worker: 1337 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699757
INFO:root:FL Epoch: 151 Norm Difference for worker 1337 is 1.007973
INFO:root:FL Epoch: 151 Done on worker:1337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :847
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410398
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698366
INFO:root:FL Epoch: 151 Norm Difference for worker 847 is 1.038888
INFO:root:FL Epoch: 151 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1578
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553269
INFO:root:Worker: 1578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377034
INFO:root:FL Epoch: 151 Norm Difference for worker 1578 is 0.948299
INFO:root:FL Epoch: 151 Done on worker:1578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 151 Training on worker :1047
INFO:root:FL Epoch: 151 Using Learning rate : 0.037029785593279296 
INFO:root:FL Epoch: 151 Normal Training
INFO:root:Worker: 1047 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646440
INFO:root:Worker: 1047 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542611
INFO:root:FL Epoch: 151 Norm Difference for worker 1047 is 1.027136
INFO:root:FL Epoch: 151 Done on worker:1047
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 151 Ends   ===================
INFO:root:Epoch:151 Global Model Test Loss:0.5097304494941935 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:151 Global Model Backdoor Test Loss:0.3828074832757314                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 152 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 152 Workers Selected : [1645, 723, 1486, 636, 239, 17, 61, 1600, 1273, 742]
INFO:root:FL Epoch: 152 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 152 Num points on workers: [200 200 200 200 201 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 152 Training on worker :1645
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505073
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426587
INFO:root:FL Epoch: 152 Norm Difference for worker 1645 is 1.045319
INFO:root:FL Epoch: 152 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :723
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348552
INFO:root:Worker: 723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524761
INFO:root:FL Epoch: 152 Norm Difference for worker 723 is 1.047431
INFO:root:FL Epoch: 152 Done on worker:723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :1486
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692113
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646466
INFO:root:FL Epoch: 152 Norm Difference for worker 1486 is 1.10745
INFO:root:FL Epoch: 152 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :636
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559245
INFO:root:Worker: 636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676336
INFO:root:FL Epoch: 152 Norm Difference for worker 636 is 1.062426
INFO:root:FL Epoch: 152 Done on worker:636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :239
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 239 Train Epoch: 0 [0/201 (0%)]	Loss: 0.859270
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 239 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415401
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 152 Norm Difference for worker 239 is 1.112231
INFO:root:FL Epoch: 152 Done on worker:239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :17
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 17 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692175
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 17 Train Epoch: 1 [0/201 (0%)]	Loss: 0.700784
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 152 Norm Difference for worker 17 is 1.053222
INFO:root:FL Epoch: 152 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :61
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 61 Train Epoch: 0 [0/201 (0%)]	Loss: 0.754002
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 61 Train Epoch: 1 [0/201 (0%)]	Loss: 0.665944
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 152 Norm Difference for worker 61 is 1.101352
INFO:root:FL Epoch: 152 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :1600
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647632
INFO:root:Worker: 1600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658366
INFO:root:FL Epoch: 152 Norm Difference for worker 1600 is 1.171355
INFO:root:FL Epoch: 152 Done on worker:1600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :1273
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 1273 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447732
INFO:root:Worker: 1273 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604010
INFO:root:FL Epoch: 152 Norm Difference for worker 1273 is 1.090713
INFO:root:FL Epoch: 152 Done on worker:1273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 152 Training on worker :742
INFO:root:FL Epoch: 152 Using Learning rate : 0.03695572602209274 
INFO:root:FL Epoch: 152 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488522
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562824
INFO:root:FL Epoch: 152 Norm Difference for worker 742 is 1.06373
INFO:root:FL Epoch: 152 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 723
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 152 Ends   ===================
INFO:root:Epoch:152 Global Model Test Loss:0.5204315132954541 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:152 Global Model Backdoor Test Loss:0.5101615836222967                             and Backdoor Test Accuracy:73.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 153 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 153 Workers Selected : [1336, 356, 514, 71, 511, 1668, 1694, 1746, 159, 534]
INFO:root:FL Epoch: 153 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 153 Num points on workers: [200 200 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 153 Training on worker :1336
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1336 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747463
INFO:root:Worker: 1336 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433594
INFO:root:FL Epoch: 153 Norm Difference for worker 1336 is 0.932559
INFO:root:FL Epoch: 153 Done on worker:1336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :356
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536346
INFO:root:Worker: 356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.727957
INFO:root:FL Epoch: 153 Norm Difference for worker 356 is 0.930861
INFO:root:FL Epoch: 153 Done on worker:356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :514
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534360
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.668459
INFO:root:FL Epoch: 153 Norm Difference for worker 514 is 0.9451
INFO:root:FL Epoch: 153 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :71
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 71 Train Epoch: 0 [0/201 (0%)]	Loss: 0.418844
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 71 Train Epoch: 1 [0/201 (0%)]	Loss: 0.454371
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 71 is 0.936738
INFO:root:FL Epoch: 153 Done on worker:71
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :511
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698884
INFO:root:Worker: 511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511523
INFO:root:FL Epoch: 153 Norm Difference for worker 511 is 0.942811
INFO:root:FL Epoch: 153 Done on worker:511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1668
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1668 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479233
INFO:root:Worker: 1668 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345001
INFO:root:FL Epoch: 153 Norm Difference for worker 1668 is 0.930671
INFO:root:FL Epoch: 153 Done on worker:1668
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1694
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760364
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620426
INFO:root:FL Epoch: 153 Norm Difference for worker 1694 is 0.975108
INFO:root:FL Epoch: 153 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :1746
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 1746 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552856
INFO:root:Worker: 1746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578637
INFO:root:FL Epoch: 153 Norm Difference for worker 1746 is 1.006909
INFO:root:FL Epoch: 153 Done on worker:1746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :159
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.511205
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.476326
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 153 Norm Difference for worker 159 is 0.913487
INFO:root:FL Epoch: 153 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 153 Training on worker :534
INFO:root:FL Epoch: 153 Using Learning rate : 0.03688181457004855 
INFO:root:FL Epoch: 153 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711337
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412831
INFO:root:FL Epoch: 153 Norm Difference for worker 534 is 0.955905
INFO:root:FL Epoch: 153 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 159
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 153 Ends   ===================
INFO:root:Epoch:153 Global Model Test Loss:0.5362452706869911 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:153 Global Model Backdoor Test Loss:0.7022251188755035                             and Backdoor Test Accuracy:58.333333333333336 
INFO:root:=======================================================
INFO:root:================FL round 154 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 154 Workers Selected : [913, 1139, 497, 1501, 1753, 486, 765, 1484, 806, 227]
INFO:root:FL Epoch: 154 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 154 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 154 Training on worker :913
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660131
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686763
INFO:root:FL Epoch: 154 Norm Difference for worker 913 is 1.054087
INFO:root:FL Epoch: 154 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1139
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620861
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396430
INFO:root:FL Epoch: 154 Norm Difference for worker 1139 is 0.957004
INFO:root:FL Epoch: 154 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :497
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555564
INFO:root:Worker: 497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426068
INFO:root:FL Epoch: 154 Norm Difference for worker 497 is 0.938298
INFO:root:FL Epoch: 154 Done on worker:497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1501
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1501 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520574
INFO:root:Worker: 1501 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480043
INFO:root:FL Epoch: 154 Norm Difference for worker 1501 is 0.966339
INFO:root:FL Epoch: 154 Done on worker:1501
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1753
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533073
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393851
INFO:root:FL Epoch: 154 Norm Difference for worker 1753 is 0.903956
INFO:root:FL Epoch: 154 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :486
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522030
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539367
INFO:root:FL Epoch: 154 Norm Difference for worker 486 is 0.920591
INFO:root:FL Epoch: 154 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :765
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557246
INFO:root:Worker: 765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502198
INFO:root:FL Epoch: 154 Norm Difference for worker 765 is 1.019786
INFO:root:FL Epoch: 154 Done on worker:765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :1484
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 1484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744934
INFO:root:Worker: 1484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492877
INFO:root:FL Epoch: 154 Norm Difference for worker 1484 is 0.939243
INFO:root:FL Epoch: 154 Done on worker:1484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :806
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528903
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666409
INFO:root:FL Epoch: 154 Norm Difference for worker 806 is 0.971427
INFO:root:FL Epoch: 154 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 154 Training on worker :227
INFO:root:FL Epoch: 154 Using Learning rate : 0.03680805094090846 
INFO:root:FL Epoch: 154 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.554930
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.590640
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 154 Norm Difference for worker 227 is 0.952302
INFO:root:FL Epoch: 154 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1753
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 154 Ends   ===================
INFO:root:Epoch:154 Global Model Test Loss:0.5422693263081944 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:154 Global Model Backdoor Test Loss:0.6873672107855479                             and Backdoor Test Accuracy:60.833333333333336 
INFO:root:=======================================================
INFO:root:================FL round 155 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 155 Workers Selected : [578, 1140, 516, 1456, 1074, 131, 1204, 1321, 461, 1448]
INFO:root:FL Epoch: 155 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 155 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 155 Training on worker :578
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.767845
INFO:root:Worker: 578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518717
INFO:root:FL Epoch: 155 Norm Difference for worker 578 is 1.030385
INFO:root:FL Epoch: 155 Done on worker:578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1140
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1140 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715286
INFO:root:Worker: 1140 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365309
INFO:root:FL Epoch: 155 Norm Difference for worker 1140 is 1.0597
INFO:root:FL Epoch: 155 Done on worker:1140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :516
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685912
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395299
INFO:root:FL Epoch: 155 Norm Difference for worker 516 is 1.079427
INFO:root:FL Epoch: 155 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1456
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774715
INFO:root:Worker: 1456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570202
INFO:root:FL Epoch: 155 Norm Difference for worker 1456 is 1.071594
INFO:root:FL Epoch: 155 Done on worker:1456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1074
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1074 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507328
INFO:root:Worker: 1074 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630872
INFO:root:FL Epoch: 155 Norm Difference for worker 1074 is 1.114149
INFO:root:FL Epoch: 155 Done on worker:1074
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :131
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 131 Train Epoch: 0 [0/201 (0%)]	Loss: 0.485110
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 131 Train Epoch: 1 [0/201 (0%)]	Loss: 0.368648
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 155 Norm Difference for worker 131 is 1.068306
INFO:root:FL Epoch: 155 Done on worker:131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1204
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543712
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624006
INFO:root:FL Epoch: 155 Norm Difference for worker 1204 is 1.225017
INFO:root:FL Epoch: 155 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1321
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1321 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574113
INFO:root:Worker: 1321 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433878
INFO:root:FL Epoch: 155 Norm Difference for worker 1321 is 1.165071
INFO:root:FL Epoch: 155 Done on worker:1321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :461
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.749958
INFO:root:Worker: 461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580920
INFO:root:FL Epoch: 155 Norm Difference for worker 461 is 1.084543
INFO:root:FL Epoch: 155 Done on worker:461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 155 Training on worker :1448
INFO:root:FL Epoch: 155 Using Learning rate : 0.036734434839026636 
INFO:root:FL Epoch: 155 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593898
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609325
INFO:root:FL Epoch: 155 Norm Difference for worker 1448 is 1.136253
INFO:root:FL Epoch: 155 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 578
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 155 Ends   ===================
INFO:root:Epoch:155 Global Model Test Loss:0.5417991403271171 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:155 Global Model Backdoor Test Loss:0.6508162419001261                             and Backdoor Test Accuracy:65.0 
INFO:root:=======================================================
INFO:root:================FL round 156 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 156 Workers Selected : [696, 1797, 656, 1869, 1172, 58, 1684, 1548, 455, 393]
INFO:root:FL Epoch: 156 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 156 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 156 Training on worker :696
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501211
INFO:root:Worker: 696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415008
INFO:root:FL Epoch: 156 Norm Difference for worker 696 is 1.05473
INFO:root:FL Epoch: 156 Done on worker:696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1797
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624444
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616131
INFO:root:FL Epoch: 156 Norm Difference for worker 1797 is 1.129109
INFO:root:FL Epoch: 156 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :656
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423112
INFO:root:Worker: 656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545624
INFO:root:FL Epoch: 156 Norm Difference for worker 656 is 1.081864
INFO:root:FL Epoch: 156 Done on worker:656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1869
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493530
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382116
INFO:root:FL Epoch: 156 Norm Difference for worker 1869 is 1.079745
INFO:root:FL Epoch: 156 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1172
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1172 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672820
INFO:root:Worker: 1172 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603699
INFO:root:FL Epoch: 156 Norm Difference for worker 1172 is 1.099614
INFO:root:FL Epoch: 156 Done on worker:1172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :58
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 58 Train Epoch: 0 [0/201 (0%)]	Loss: 0.610882
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 58 Train Epoch: 1 [0/201 (0%)]	Loss: 0.591073
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 156 Norm Difference for worker 58 is 1.059302
INFO:root:FL Epoch: 156 Done on worker:58
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1684
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689026
INFO:root:Worker: 1684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578429
INFO:root:FL Epoch: 156 Norm Difference for worker 1684 is 1.121861
INFO:root:FL Epoch: 156 Done on worker:1684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :1548
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599941
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.859320
INFO:root:FL Epoch: 156 Norm Difference for worker 1548 is 1.04379
INFO:root:FL Epoch: 156 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :455
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788935
INFO:root:Worker: 455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564766
INFO:root:FL Epoch: 156 Norm Difference for worker 455 is 1.111129
INFO:root:FL Epoch: 156 Done on worker:455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 156 Training on worker :393
INFO:root:FL Epoch: 156 Using Learning rate : 0.036660965969348584 
INFO:root:FL Epoch: 156 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572536
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534934
INFO:root:FL Epoch: 156 Norm Difference for worker 393 is 1.065774
INFO:root:FL Epoch: 156 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1548
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 156 Ends   ===================
INFO:root:Epoch:156 Global Model Test Loss:0.5240525638355928 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:156 Global Model Backdoor Test Loss:0.46821176012357074                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 157 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 157 Workers Selected : [119, 1745, 975, 1803, 569, 507, 827, 1363, 1405, 731]
INFO:root:FL Epoch: 157 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 157 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 157 Training on worker :119
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.619252
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.616838
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 157 Norm Difference for worker 119 is 0.95346
INFO:root:FL Epoch: 157 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1745
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432767
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440707
INFO:root:FL Epoch: 157 Norm Difference for worker 1745 is 0.931233
INFO:root:FL Epoch: 157 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :975
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607696
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493302
INFO:root:FL Epoch: 157 Norm Difference for worker 975 is 1.036672
INFO:root:FL Epoch: 157 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1803
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657618
INFO:root:Worker: 1803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704029
INFO:root:FL Epoch: 157 Norm Difference for worker 1803 is 0.92254
INFO:root:FL Epoch: 157 Done on worker:1803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :569
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515525
INFO:root:Worker: 569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593797
INFO:root:FL Epoch: 157 Norm Difference for worker 569 is 0.956049
INFO:root:FL Epoch: 157 Done on worker:569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :507
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690002
INFO:root:Worker: 507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395525
INFO:root:FL Epoch: 157 Norm Difference for worker 507 is 0.919882
INFO:root:FL Epoch: 157 Done on worker:507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :827
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554739
INFO:root:Worker: 827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426431
INFO:root:FL Epoch: 157 Norm Difference for worker 827 is 0.92916
INFO:root:FL Epoch: 157 Done on worker:827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1363
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.820715
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536399
INFO:root:FL Epoch: 157 Norm Difference for worker 1363 is 0.991243
INFO:root:FL Epoch: 157 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :1405
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 1405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.824259
INFO:root:Worker: 1405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317655
INFO:root:FL Epoch: 157 Norm Difference for worker 1405 is 0.960773
INFO:root:FL Epoch: 157 Done on worker:1405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 157 Training on worker :731
INFO:root:FL Epoch: 157 Using Learning rate : 0.03658764403740988 
INFO:root:FL Epoch: 157 Normal Training
INFO:root:Worker: 731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762307
INFO:root:Worker: 731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423561
INFO:root:FL Epoch: 157 Norm Difference for worker 731 is 0.956984
INFO:root:FL Epoch: 157 Done on worker:731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1745
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 157 Ends   ===================
INFO:root:Epoch:157 Global Model Test Loss:0.514903212294859 and Test Accuracy:75.0 
INFO:root:Epoch:157 Global Model Backdoor Test Loss:0.49291110535462695                             and Backdoor Test Accuracy:75.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 158 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 158 Workers Selected : [13, 1353, 116, 1208, 1857, 461, 1534, 301, 826, 574]
INFO:root:FL Epoch: 158 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 158 Num points on workers: [201 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 158 Training on worker :13
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 13 Train Epoch: 0 [0/201 (0%)]	Loss: 0.523842
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 13 Train Epoch: 1 [0/201 (0%)]	Loss: 0.362033
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 13 is 1.129206
INFO:root:FL Epoch: 158 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1353
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549278
INFO:root:Worker: 1353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405734
INFO:root:FL Epoch: 158 Norm Difference for worker 1353 is 1.022869
INFO:root:FL Epoch: 158 Done on worker:1353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :116
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.585698
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.605977
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 116 is 1.111433
INFO:root:FL Epoch: 158 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1208
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1208 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406104
INFO:root:Worker: 1208 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561981
INFO:root:FL Epoch: 158 Norm Difference for worker 1208 is 1.079984
INFO:root:FL Epoch: 158 Done on worker:1208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1857
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574255
INFO:root:Worker: 1857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466119
INFO:root:FL Epoch: 158 Norm Difference for worker 1857 is 1.088854
INFO:root:FL Epoch: 158 Done on worker:1857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :461
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457399
INFO:root:Worker: 461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493186
INFO:root:FL Epoch: 158 Norm Difference for worker 461 is 1.042999
INFO:root:FL Epoch: 158 Done on worker:461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :1534
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398108
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359464
INFO:root:FL Epoch: 158 Norm Difference for worker 1534 is 1.145103
INFO:root:FL Epoch: 158 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :301
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.681094
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.599526
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 158 Norm Difference for worker 301 is 1.124069
INFO:root:FL Epoch: 158 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :826
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674007
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418213
INFO:root:FL Epoch: 158 Norm Difference for worker 826 is 1.045959
INFO:root:FL Epoch: 158 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 158 Training on worker :574
INFO:root:FL Epoch: 158 Using Learning rate : 0.03651446874933507 
INFO:root:FL Epoch: 158 Normal Training
INFO:root:Worker: 574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529506
INFO:root:Worker: 574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.555894
INFO:root:FL Epoch: 158 Norm Difference for worker 574 is 1.146577
INFO:root:FL Epoch: 158 Done on worker:574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 461
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 158 Ends   ===================
INFO:root:Epoch:158 Global Model Test Loss:0.5256143247379976 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:158 Global Model Backdoor Test Loss:0.5576243003209432                             and Backdoor Test Accuracy:72.5 
INFO:root:=======================================================
INFO:root:================FL round 159 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 159 Workers Selected : [1009, 1163, 526, 1612, 1699, 1879, 1255, 1793, 790, 1663]
INFO:root:FL Epoch: 159 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 159 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 159 Training on worker :1009
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401799
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504371
INFO:root:FL Epoch: 159 Norm Difference for worker 1009 is 1.314488
INFO:root:FL Epoch: 159 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1163
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1163 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611001
INFO:root:Worker: 1163 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311109
INFO:root:FL Epoch: 159 Norm Difference for worker 1163 is 1.228022
INFO:root:FL Epoch: 159 Done on worker:1163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :526
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477005
INFO:root:Worker: 526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.728327
INFO:root:FL Epoch: 159 Norm Difference for worker 526 is 1.230126
INFO:root:FL Epoch: 159 Done on worker:526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1612
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.921871
INFO:root:Worker: 1612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556208
INFO:root:FL Epoch: 159 Norm Difference for worker 1612 is 1.192472
INFO:root:FL Epoch: 159 Done on worker:1612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1699
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1699 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400658
INFO:root:Worker: 1699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333069
INFO:root:FL Epoch: 159 Norm Difference for worker 1699 is 1.189164
INFO:root:FL Epoch: 159 Done on worker:1699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1879
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684313
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422644
INFO:root:FL Epoch: 159 Norm Difference for worker 1879 is 1.175932
INFO:root:FL Epoch: 159 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1255
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657386
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570518
INFO:root:FL Epoch: 159 Norm Difference for worker 1255 is 1.168215
INFO:root:FL Epoch: 159 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1793
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774216
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449692
INFO:root:FL Epoch: 159 Norm Difference for worker 1793 is 1.215122
INFO:root:FL Epoch: 159 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :790
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598012
INFO:root:Worker: 790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522008
INFO:root:FL Epoch: 159 Norm Difference for worker 790 is 1.261304
INFO:root:FL Epoch: 159 Done on worker:790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 159 Training on worker :1663
INFO:root:FL Epoch: 159 Using Learning rate : 0.036441439811836396 
INFO:root:FL Epoch: 159 Normal Training
INFO:root:Worker: 1663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524433
INFO:root:Worker: 1663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537175
INFO:root:FL Epoch: 159 Norm Difference for worker 1663 is 1.152938
INFO:root:FL Epoch: 159 Done on worker:1663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1663
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 159 Ends   ===================
INFO:root:Epoch:159 Global Model Test Loss:0.5261825025081635 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:159 Global Model Backdoor Test Loss:0.4918145736058553                             and Backdoor Test Accuracy:80.0 
INFO:root:=======================================================
INFO:root:================FL round 160 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 160 Workers Selected : [285, 1202, 1057, 1346, 158, 334, 869, 1252, 1342, 599]
INFO:root:FL Epoch: 160 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 160 Num points on workers: [201 200 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 160 Training on worker :285
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 285 Train Epoch: 0 [0/201 (0%)]	Loss: 0.643118
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 285 Train Epoch: 1 [0/201 (0%)]	Loss: 0.502387
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 285 is 1.089351
INFO:root:FL Epoch: 160 Done on worker:285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1202
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1202 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609296
INFO:root:Worker: 1202 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515575
INFO:root:FL Epoch: 160 Norm Difference for worker 1202 is 1.004101
INFO:root:FL Epoch: 160 Done on worker:1202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1057
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1057 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443944
INFO:root:Worker: 1057 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339830
INFO:root:FL Epoch: 160 Norm Difference for worker 1057 is 0.986061
INFO:root:FL Epoch: 160 Done on worker:1057
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1346
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571187
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323389
INFO:root:FL Epoch: 160 Norm Difference for worker 1346 is 1.055986
INFO:root:FL Epoch: 160 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :158
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.546743
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.530521
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 158 is 1.14389
INFO:root:FL Epoch: 160 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :334
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 334 Train Epoch: 0 [0/201 (0%)]	Loss: 0.751512
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 334 Train Epoch: 1 [0/201 (0%)]	Loss: 0.623655
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 160 Norm Difference for worker 334 is 1.10253
INFO:root:FL Epoch: 160 Done on worker:334
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :869
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423556
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408401
INFO:root:FL Epoch: 160 Norm Difference for worker 869 is 1.06668
INFO:root:FL Epoch: 160 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1252
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1252 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727404
INFO:root:Worker: 1252 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467473
INFO:root:FL Epoch: 160 Norm Difference for worker 1252 is 1.12242
INFO:root:FL Epoch: 160 Done on worker:1252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :1342
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 1342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657407
INFO:root:Worker: 1342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449179
INFO:root:FL Epoch: 160 Norm Difference for worker 1342 is 1.125297
INFO:root:FL Epoch: 160 Done on worker:1342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 160 Training on worker :599
INFO:root:FL Epoch: 160 Using Learning rate : 0.03636855693221273 
INFO:root:FL Epoch: 160 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399308
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512544
INFO:root:FL Epoch: 160 Norm Difference for worker 599 is 1.110187
INFO:root:FL Epoch: 160 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1202
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 160 Ends   ===================
INFO:root:Epoch:160 Global Model Test Loss:0.5205821429981905 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:160 Global Model Backdoor Test Loss:0.4477734218041102                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 161 Begins ===================
INFO:root:FL Epoch: 161 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 161 Workers Selected : [0, 496, 947, 946, 124, 357, 1821, 1167, 1106, 1890]
INFO:root:FL Epoch: 161 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 161 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 161 Training on worker :0
INFO:root:FL Epoch: 161 Using Learning rate : 0.00725916396366966 
INFO:root:FL Epoch: 161 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374962
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420935
INFO:root:FL Epoch: 161 Worker: 0 Backdoor Test Loss: 0.3870341281096141 Backdoor Test Accuracy: 84.16666666666667
INFO:root:FL Epoch: 161 Worker: 0 Backdoor Train Loss: 0.38720187842845916 Backdoor Train Accuracy: 85.0
INFO:root:FL Epoch: 161 Norm Difference for worker 0 is 0.247866
INFO:root:FL Epoch: 161 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :496
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563421
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565280
INFO:root:FL Epoch: 161 Norm Difference for worker 496 is 1.130715
INFO:root:FL Epoch: 161 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :947
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713159
INFO:root:Worker: 947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.717788
INFO:root:FL Epoch: 161 Norm Difference for worker 947 is 1.111317
INFO:root:FL Epoch: 161 Done on worker:947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :946
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512288
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451802
INFO:root:FL Epoch: 161 Norm Difference for worker 946 is 1.14531
INFO:root:FL Epoch: 161 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :124
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 1.099721
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.490443
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 161 Norm Difference for worker 124 is 1.180099
INFO:root:FL Epoch: 161 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :357
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506726
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444542
INFO:root:FL Epoch: 161 Norm Difference for worker 357 is 1.095078
INFO:root:FL Epoch: 161 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1821
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523262
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588529
INFO:root:FL Epoch: 161 Norm Difference for worker 1821 is 1.118744
INFO:root:FL Epoch: 161 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1167
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355942
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497529
INFO:root:FL Epoch: 161 Norm Difference for worker 1167 is 1.132524
INFO:root:FL Epoch: 161 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1106
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1106 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438085
INFO:root:Worker: 1106 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358705
INFO:root:FL Epoch: 161 Norm Difference for worker 1106 is 1.144278
INFO:root:FL Epoch: 161 Done on worker:1106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 161 Training on worker :1890
INFO:root:FL Epoch: 161 Using Learning rate : 0.0362958198183483 
INFO:root:FL Epoch: 161 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496474
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564033
INFO:root:FL Epoch: 161 Norm Difference for worker 1890 is 1.096355
INFO:root:FL Epoch: 161 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 161 Ends   ===================
INFO:root:Epoch:161 Global Model Test Loss:0.5191400804940391 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:161 Global Model Backdoor Test Loss:0.3870341281096141                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 162 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 162 Workers Selected : [1195, 447, 382, 542, 1541, 1857, 1401, 959, 353, 639]
INFO:root:FL Epoch: 162 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 162 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 162 Training on worker :1195
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1195 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731275
INFO:root:Worker: 1195 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432153
INFO:root:FL Epoch: 162 Norm Difference for worker 1195 is 1.146864
INFO:root:FL Epoch: 162 Done on worker:1195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :447
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585847
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472927
INFO:root:FL Epoch: 162 Norm Difference for worker 447 is 1.193821
INFO:root:FL Epoch: 162 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :382
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509048
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607949
INFO:root:FL Epoch: 162 Norm Difference for worker 382 is 1.282072
INFO:root:FL Epoch: 162 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :542
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399616
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358074
INFO:root:FL Epoch: 162 Norm Difference for worker 542 is 1.09241
INFO:root:FL Epoch: 162 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1541
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644002
INFO:root:Worker: 1541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398236
INFO:root:FL Epoch: 162 Norm Difference for worker 1541 is 1.183457
INFO:root:FL Epoch: 162 Done on worker:1541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1857
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550407
INFO:root:Worker: 1857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377142
INFO:root:FL Epoch: 162 Norm Difference for worker 1857 is 1.16354
INFO:root:FL Epoch: 162 Done on worker:1857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :1401
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636145
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528252
INFO:root:FL Epoch: 162 Norm Difference for worker 1401 is 1.208698
INFO:root:FL Epoch: 162 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :959
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443418
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.687129
INFO:root:FL Epoch: 162 Norm Difference for worker 959 is 1.247014
INFO:root:FL Epoch: 162 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :353
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422783
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507683
INFO:root:FL Epoch: 162 Norm Difference for worker 353 is 1.22335
INFO:root:FL Epoch: 162 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 162 Training on worker :639
INFO:root:FL Epoch: 162 Using Learning rate : 0.036223228178711604 
INFO:root:FL Epoch: 162 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403610
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395937
INFO:root:FL Epoch: 162 Norm Difference for worker 639 is 1.062212
INFO:root:FL Epoch: 162 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1195
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 162 Ends   ===================
INFO:root:Epoch:162 Global Model Test Loss:0.5169500761172351 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:162 Global Model Backdoor Test Loss:0.473999485373497                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 163 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 163 Workers Selected : [1039, 1302, 1461, 1694, 369, 370, 1333, 149, 1393, 1591]
INFO:root:FL Epoch: 163 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 163 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 163 Training on worker :1039
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1039 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438305
INFO:root:Worker: 1039 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599930
INFO:root:FL Epoch: 163 Norm Difference for worker 1039 is 1.016223
INFO:root:FL Epoch: 163 Done on worker:1039
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1302
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1302 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717284
INFO:root:Worker: 1302 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355829
INFO:root:FL Epoch: 163 Norm Difference for worker 1302 is 0.965174
INFO:root:FL Epoch: 163 Done on worker:1302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1461
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501755
INFO:root:Worker: 1461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527906
INFO:root:FL Epoch: 163 Norm Difference for worker 1461 is 0.982904
INFO:root:FL Epoch: 163 Done on worker:1461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1694
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686143
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521586
INFO:root:FL Epoch: 163 Norm Difference for worker 1694 is 0.964147
INFO:root:FL Epoch: 163 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :369
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545358
INFO:root:Worker: 369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318525
INFO:root:FL Epoch: 163 Norm Difference for worker 369 is 0.935619
INFO:root:FL Epoch: 163 Done on worker:369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :370
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485827
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614149
INFO:root:FL Epoch: 163 Norm Difference for worker 370 is 0.965118
INFO:root:FL Epoch: 163 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1333
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564076
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599053
INFO:root:FL Epoch: 163 Norm Difference for worker 1333 is 0.998168
INFO:root:FL Epoch: 163 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :149
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 149 Train Epoch: 0 [0/201 (0%)]	Loss: 0.354852
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 149 Train Epoch: 1 [0/201 (0%)]	Loss: 0.552635
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 163 Norm Difference for worker 149 is 0.984941
INFO:root:FL Epoch: 163 Done on worker:149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1393
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688423
INFO:root:Worker: 1393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518483
INFO:root:FL Epoch: 163 Norm Difference for worker 1393 is 0.90394
INFO:root:FL Epoch: 163 Done on worker:1393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 163 Training on worker :1591
INFO:root:FL Epoch: 163 Using Learning rate : 0.036150781722354176 
INFO:root:FL Epoch: 163 Normal Training
INFO:root:Worker: 1591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547137
INFO:root:Worker: 1591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452644
INFO:root:FL Epoch: 163 Norm Difference for worker 1591 is 0.986213
INFO:root:FL Epoch: 163 Done on worker:1591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1393
INFO:root:Norm of Aggregated Model: 5154.98876953125
INFO:root:Aggregating After Defense
INFO:root:================FL round 163 Ends   ===================
INFO:root:Epoch:163 Global Model Test Loss:0.5104980836896336 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:163 Global Model Backdoor Test Loss:0.40276703735192615                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 164 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 164 Workers Selected : [1395, 106, 70, 481, 1703, 1708, 239, 768, 1573, 942]
INFO:root:FL Epoch: 164 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 164 Num points on workers: [200 201 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 164 Training on worker :1395
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718322
INFO:root:Worker: 1395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418578
INFO:root:FL Epoch: 164 Norm Difference for worker 1395 is 0.972192
INFO:root:FL Epoch: 164 Done on worker:1395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :106
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.439690
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.522710
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 106 is 1.009281
INFO:root:FL Epoch: 164 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :70
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517715
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.512720
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 70 is 0.934273
INFO:root:FL Epoch: 164 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :481
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545829
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513159
INFO:root:FL Epoch: 164 Norm Difference for worker 481 is 1.022955
INFO:root:FL Epoch: 164 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1703
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694669
INFO:root:Worker: 1703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577280
INFO:root:FL Epoch: 164 Norm Difference for worker 1703 is 0.975353
INFO:root:FL Epoch: 164 Done on worker:1703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1708
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553611
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550405
INFO:root:FL Epoch: 164 Norm Difference for worker 1708 is 0.989023
INFO:root:FL Epoch: 164 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :239
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 239 Train Epoch: 0 [0/201 (0%)]	Loss: 0.493371
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 239 Train Epoch: 1 [0/201 (0%)]	Loss: 0.376020
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 164 Norm Difference for worker 239 is 1.035134
INFO:root:FL Epoch: 164 Done on worker:239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :768
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664423
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530680
INFO:root:FL Epoch: 164 Norm Difference for worker 768 is 0.963384
INFO:root:FL Epoch: 164 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :1573
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 1573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500650
INFO:root:Worker: 1573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504074
INFO:root:FL Epoch: 164 Norm Difference for worker 1573 is 0.975992
INFO:root:FL Epoch: 164 Done on worker:1573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 164 Training on worker :942
INFO:root:FL Epoch: 164 Using Learning rate : 0.03607848015890947 
INFO:root:FL Epoch: 164 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684052
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635034
INFO:root:FL Epoch: 164 Norm Difference for worker 942 is 0.988704
INFO:root:FL Epoch: 164 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 70
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 164 Ends   ===================
INFO:root:Epoch:164 Global Model Test Loss:0.5056600623271045 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:164 Global Model Backdoor Test Loss:0.4110218683878581                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 165 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 165 Workers Selected : [96, 658, 45, 672, 465, 437, 165, 1430, 931, 554]
INFO:root:FL Epoch: 165 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 165 Num points on workers: [201 200 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 165 Training on worker :96
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 96 Train Epoch: 0 [0/201 (0%)]	Loss: 0.444969
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 96 Train Epoch: 1 [0/201 (0%)]	Loss: 0.692162
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 96 is 1.043335
INFO:root:FL Epoch: 165 Done on worker:96
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :658
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557556
INFO:root:Worker: 658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630169
INFO:root:FL Epoch: 165 Norm Difference for worker 658 is 1.153156
INFO:root:FL Epoch: 165 Done on worker:658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :45
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.729384
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699267
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 45 is 1.10062
INFO:root:FL Epoch: 165 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :672
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622165
INFO:root:Worker: 672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492855
INFO:root:FL Epoch: 165 Norm Difference for worker 672 is 1.008616
INFO:root:FL Epoch: 165 Done on worker:672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :465
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581862
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559542
INFO:root:FL Epoch: 165 Norm Difference for worker 465 is 1.039423
INFO:root:FL Epoch: 165 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :437
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522151
INFO:root:Worker: 437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428025
INFO:root:FL Epoch: 165 Norm Difference for worker 437 is 0.985029
INFO:root:FL Epoch: 165 Done on worker:437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :165
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 165 Train Epoch: 0 [0/201 (0%)]	Loss: 0.801604
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 165 Train Epoch: 1 [0/201 (0%)]	Loss: 0.515031
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 165 Norm Difference for worker 165 is 1.078151
INFO:root:FL Epoch: 165 Done on worker:165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :1430
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 1430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596343
INFO:root:Worker: 1430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467943
INFO:root:FL Epoch: 165 Norm Difference for worker 1430 is 1.085523
INFO:root:FL Epoch: 165 Done on worker:1430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :931
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685912
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534483
INFO:root:FL Epoch: 165 Norm Difference for worker 931 is 1.137121
INFO:root:FL Epoch: 165 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 165 Training on worker :554
INFO:root:FL Epoch: 165 Using Learning rate : 0.03600632319859165 
INFO:root:FL Epoch: 165 Normal Training
INFO:root:Worker: 554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619332
INFO:root:Worker: 554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561054
INFO:root:FL Epoch: 165 Norm Difference for worker 554 is 1.019932
INFO:root:FL Epoch: 165 Done on worker:554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 672
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 165 Ends   ===================
INFO:root:Epoch:165 Global Model Test Loss:0.49368859213941235 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:165 Global Model Backdoor Test Loss:0.42596669495105743                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 166 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 166 Workers Selected : [1360, 1418, 1882, 1505, 1902, 1525, 1059, 1776, 1019, 1636]
INFO:root:FL Epoch: 166 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 166 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 166 Training on worker :1360
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520442
INFO:root:Worker: 1360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326837
INFO:root:FL Epoch: 166 Norm Difference for worker 1360 is 0.972413
INFO:root:FL Epoch: 166 Done on worker:1360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1418
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510335
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482609
INFO:root:FL Epoch: 166 Norm Difference for worker 1418 is 0.990882
INFO:root:FL Epoch: 166 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1882
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632641
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452164
INFO:root:FL Epoch: 166 Norm Difference for worker 1882 is 0.975778
INFO:root:FL Epoch: 166 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1505
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531618
INFO:root:Worker: 1505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456185
INFO:root:FL Epoch: 166 Norm Difference for worker 1505 is 0.977932
INFO:root:FL Epoch: 166 Done on worker:1505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1902
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422475
INFO:root:Worker: 1902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569198
INFO:root:FL Epoch: 166 Norm Difference for worker 1902 is 0.960503
INFO:root:FL Epoch: 166 Done on worker:1902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1525
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649083
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481588
INFO:root:FL Epoch: 166 Norm Difference for worker 1525 is 0.97489
INFO:root:FL Epoch: 166 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1059
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517878
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521499
INFO:root:FL Epoch: 166 Norm Difference for worker 1059 is 1.00426
INFO:root:FL Epoch: 166 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1776
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543597
INFO:root:Worker: 1776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650545
INFO:root:FL Epoch: 166 Norm Difference for worker 1776 is 0.932635
INFO:root:FL Epoch: 166 Done on worker:1776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1019
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1019 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734605
INFO:root:Worker: 1019 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623834
INFO:root:FL Epoch: 166 Norm Difference for worker 1019 is 0.96815
INFO:root:FL Epoch: 166 Done on worker:1019
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 166 Training on worker :1636
INFO:root:FL Epoch: 166 Using Learning rate : 0.03593431055219447 
INFO:root:FL Epoch: 166 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549176
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547647
INFO:root:FL Epoch: 166 Norm Difference for worker 1636 is 1.03114
INFO:root:FL Epoch: 166 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1776
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 166 Ends   ===================
INFO:root:Epoch:166 Global Model Test Loss:0.4793654855559854 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:166 Global Model Backdoor Test Loss:0.4634215086698532                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 167 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 167 Workers Selected : [340, 1624, 673, 1586, 1285, 1451, 825, 217, 181, 847]
INFO:root:FL Epoch: 167 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.1003996 0.0999001]
INFO:root:FL Epoch: 167 Num points on workers: [200 200 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 167 Training on worker :340
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395060
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397842
INFO:root:FL Epoch: 167 Norm Difference for worker 340 is 1.014437
INFO:root:FL Epoch: 167 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1624
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534777
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479012
INFO:root:FL Epoch: 167 Norm Difference for worker 1624 is 1.035023
INFO:root:FL Epoch: 167 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :673
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407871
INFO:root:Worker: 673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385466
INFO:root:FL Epoch: 167 Norm Difference for worker 673 is 1.04711
INFO:root:FL Epoch: 167 Done on worker:673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1586
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1586 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609863
INFO:root:Worker: 1586 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562116
INFO:root:FL Epoch: 167 Norm Difference for worker 1586 is 1.03176
INFO:root:FL Epoch: 167 Done on worker:1586
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1285
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1285 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464004
INFO:root:Worker: 1285 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570695
INFO:root:FL Epoch: 167 Norm Difference for worker 1285 is 1.052702
INFO:root:FL Epoch: 167 Done on worker:1285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :1451
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 1451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407741
INFO:root:Worker: 1451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441519
INFO:root:FL Epoch: 167 Norm Difference for worker 1451 is 1.016742
INFO:root:FL Epoch: 167 Done on worker:1451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :825
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502968
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502247
INFO:root:FL Epoch: 167 Norm Difference for worker 825 is 0.959556
INFO:root:FL Epoch: 167 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :217
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 217 Train Epoch: 0 [0/201 (0%)]	Loss: 0.604872
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 217 Train Epoch: 1 [0/201 (0%)]	Loss: 0.389365
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 167 Norm Difference for worker 217 is 1.043501
INFO:root:FL Epoch: 167 Done on worker:217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :181
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 181 Train Epoch: 0 [0/201 (0%)]	Loss: 0.505822
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 181 Train Epoch: 1 [0/201 (0%)]	Loss: 0.473855
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 167 Norm Difference for worker 181 is 1.030815
INFO:root:FL Epoch: 167 Done on worker:181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 167 Training on worker :847
INFO:root:FL Epoch: 167 Using Learning rate : 0.03586244193109008 
INFO:root:FL Epoch: 167 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794317
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535152
INFO:root:FL Epoch: 167 Norm Difference for worker 847 is 0.945851
INFO:root:FL Epoch: 167 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 825
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 167 Ends   ===================
INFO:root:Epoch:167 Global Model Test Loss:0.48167313197079825 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:167 Global Model Backdoor Test Loss:0.42779213686784107                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 168 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 168 Workers Selected : [959, 1158, 1033, 500, 266, 1200, 1552, 1623, 469, 1340]
INFO:root:FL Epoch: 168 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 168 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 168 Training on worker :959
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.741285
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519594
INFO:root:FL Epoch: 168 Norm Difference for worker 959 is 1.107472
INFO:root:FL Epoch: 168 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1158
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632067
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302555
INFO:root:FL Epoch: 168 Norm Difference for worker 1158 is 0.963945
INFO:root:FL Epoch: 168 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1033
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1033 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368898
INFO:root:Worker: 1033 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412856
INFO:root:FL Epoch: 168 Norm Difference for worker 1033 is 0.95954
INFO:root:FL Epoch: 168 Done on worker:1033
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :500
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576973
INFO:root:Worker: 500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379535
INFO:root:FL Epoch: 168 Norm Difference for worker 500 is 1.039458
INFO:root:FL Epoch: 168 Done on worker:500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :266
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 266 Train Epoch: 0 [0/201 (0%)]	Loss: 0.751032
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 266 Train Epoch: 1 [0/201 (0%)]	Loss: 0.551524
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 168 Norm Difference for worker 266 is 1.036368
INFO:root:FL Epoch: 168 Done on worker:266
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1200
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1200 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513527
INFO:root:Worker: 1200 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570523
INFO:root:FL Epoch: 168 Norm Difference for worker 1200 is 1.031279
INFO:root:FL Epoch: 168 Done on worker:1200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1552
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612006
INFO:root:Worker: 1552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376743
INFO:root:FL Epoch: 168 Norm Difference for worker 1552 is 1.02939
INFO:root:FL Epoch: 168 Done on worker:1552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1623
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.719849
INFO:root:Worker: 1623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581505
INFO:root:FL Epoch: 168 Norm Difference for worker 1623 is 1.050738
INFO:root:FL Epoch: 168 Done on worker:1623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :469
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566344
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362060
INFO:root:FL Epoch: 168 Norm Difference for worker 469 is 1.017331
INFO:root:FL Epoch: 168 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 168 Training on worker :1340
INFO:root:FL Epoch: 168 Using Learning rate : 0.0357907170472279 
INFO:root:FL Epoch: 168 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537112
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430993
INFO:root:FL Epoch: 168 Norm Difference for worker 1340 is 1.01013
INFO:root:FL Epoch: 168 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1033
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 168 Ends   ===================
INFO:root:Epoch:168 Global Model Test Loss:0.4643881548853481 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:168 Global Model Backdoor Test Loss:0.4174436579147975                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 169 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 169 Workers Selected : [1348, 723, 116, 142, 1660, 361, 1637, 1511, 73, 426]
INFO:root:FL Epoch: 169 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 169 Num points on workers: [200 200 201 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 169 Training on worker :1348
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773557
INFO:root:Worker: 1348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565770
INFO:root:FL Epoch: 169 Norm Difference for worker 1348 is 1.211694
INFO:root:FL Epoch: 169 Done on worker:1348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :723
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407619
INFO:root:Worker: 723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308328
INFO:root:FL Epoch: 169 Norm Difference for worker 723 is 1.144217
INFO:root:FL Epoch: 169 Done on worker:723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :116
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.645014
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.749286
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 116 is 1.247256
INFO:root:FL Epoch: 169 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :142
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 142 Train Epoch: 0 [0/201 (0%)]	Loss: 0.502784
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 142 Train Epoch: 1 [0/201 (0%)]	Loss: 0.343936
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 142 is 1.244046
INFO:root:FL Epoch: 169 Done on worker:142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1660
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565784
INFO:root:Worker: 1660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544271
INFO:root:FL Epoch: 169 Norm Difference for worker 1660 is 1.232887
INFO:root:FL Epoch: 169 Done on worker:1660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :361
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660667
INFO:root:Worker: 361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365184
INFO:root:FL Epoch: 169 Norm Difference for worker 361 is 1.301353
INFO:root:FL Epoch: 169 Done on worker:361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1637
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491416
INFO:root:Worker: 1637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536848
INFO:root:FL Epoch: 169 Norm Difference for worker 1637 is 1.168938
INFO:root:FL Epoch: 169 Done on worker:1637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :1511
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524709
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609110
INFO:root:FL Epoch: 169 Norm Difference for worker 1511 is 1.347796
INFO:root:FL Epoch: 169 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :73
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 73 Train Epoch: 0 [0/201 (0%)]	Loss: 0.588470
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 73 Train Epoch: 1 [0/201 (0%)]	Loss: 0.636234
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 169 Norm Difference for worker 73 is 1.30551
INFO:root:FL Epoch: 169 Done on worker:73
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 169 Training on worker :426
INFO:root:FL Epoch: 169 Using Learning rate : 0.03571913561313344 
INFO:root:FL Epoch: 169 Normal Training
INFO:root:Worker: 426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354661
INFO:root:Worker: 426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502067
INFO:root:FL Epoch: 169 Norm Difference for worker 426 is 1.130577
INFO:root:FL Epoch: 169 Done on worker:426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 426
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 169 Ends   ===================
INFO:root:Epoch:169 Global Model Test Loss:0.49163510518915515 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:169 Global Model Backdoor Test Loss:0.35223934054374695                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 170 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 170 Workers Selected : [1482, 1232, 977, 1512, 1577, 632, 1062, 906, 240, 497]
INFO:root:FL Epoch: 170 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 170 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 170 Training on worker :1482
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.835810
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639288
INFO:root:FL Epoch: 170 Norm Difference for worker 1482 is 1.163869
INFO:root:FL Epoch: 170 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1232
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1232 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410254
INFO:root:Worker: 1232 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647737
INFO:root:FL Epoch: 170 Norm Difference for worker 1232 is 1.169784
INFO:root:FL Epoch: 170 Done on worker:1232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :977
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453665
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430846
INFO:root:FL Epoch: 170 Norm Difference for worker 977 is 1.165985
INFO:root:FL Epoch: 170 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1512
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509033
INFO:root:Worker: 1512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492114
INFO:root:FL Epoch: 170 Norm Difference for worker 1512 is 1.150276
INFO:root:FL Epoch: 170 Done on worker:1512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1577
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764249
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640015
INFO:root:FL Epoch: 170 Norm Difference for worker 1577 is 1.184502
INFO:root:FL Epoch: 170 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :632
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.799919
INFO:root:Worker: 632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629331
INFO:root:FL Epoch: 170 Norm Difference for worker 632 is 1.131941
INFO:root:FL Epoch: 170 Done on worker:632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :1062
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 1062 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428324
INFO:root:Worker: 1062 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560135
INFO:root:FL Epoch: 170 Norm Difference for worker 1062 is 1.206132
INFO:root:FL Epoch: 170 Done on worker:1062
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :906
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681083
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465473
INFO:root:FL Epoch: 170 Norm Difference for worker 906 is 1.147802
INFO:root:FL Epoch: 170 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :240
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 240 Train Epoch: 0 [0/201 (0%)]	Loss: 0.798398
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 240 Train Epoch: 1 [0/201 (0%)]	Loss: 0.417488
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 170 Norm Difference for worker 240 is 1.191376
INFO:root:FL Epoch: 170 Done on worker:240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 170 Training on worker :497
INFO:root:FL Epoch: 170 Using Learning rate : 0.035647697341907175 
INFO:root:FL Epoch: 170 Normal Training
INFO:root:Worker: 497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535118
INFO:root:Worker: 497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.159729
INFO:root:FL Epoch: 170 Norm Difference for worker 497 is 1.047708
INFO:root:FL Epoch: 170 Done on worker:497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 497
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 170 Ends   ===================
INFO:root:Epoch:170 Global Model Test Loss:0.4866026306853575 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:170 Global Model Backdoor Test Loss:0.44863856335481006                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 171 Begins ===================
INFO:root:FL Epoch: 171 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 171 Workers Selected : [0, 1128, 743, 313, 1429, 358, 102, 504, 23, 1606]
INFO:root:FL Epoch: 171 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 171 Num points on workers: [200 200 200 201 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 171 Training on worker :0
INFO:root:FL Epoch: 171 Using Learning rate : 0.0071152803894446726 
INFO:root:FL Epoch: 171 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577804
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324976
INFO:root:FL Epoch: 171 Worker: 0 Backdoor Test Loss: 0.40998441477616626 Backdoor Test Accuracy: 85.83333333333333
INFO:root:FL Epoch: 171 Worker: 0 Backdoor Train Loss: 0.36955839991569517 Backdoor Train Accuracy: 85.5
INFO:root:FL Epoch: 171 Norm Difference for worker 0 is 0.244239
INFO:root:FL Epoch: 171 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1128
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569316
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507272
INFO:root:FL Epoch: 171 Norm Difference for worker 1128 is 1.091788
INFO:root:FL Epoch: 171 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :743
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544158
INFO:root:Worker: 743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377836
INFO:root:FL Epoch: 171 Norm Difference for worker 743 is 1.088181
INFO:root:FL Epoch: 171 Done on worker:743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :313
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.430683
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436552
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 171 Norm Difference for worker 313 is 1.162745
INFO:root:FL Epoch: 171 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1429
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366279
INFO:root:Worker: 1429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303508
INFO:root:FL Epoch: 171 Norm Difference for worker 1429 is 1.066845
INFO:root:FL Epoch: 171 Done on worker:1429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :358
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458804
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501251
INFO:root:FL Epoch: 171 Norm Difference for worker 358 is 1.073551
INFO:root:FL Epoch: 171 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :102
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 102 Train Epoch: 0 [0/201 (0%)]	Loss: 0.510860
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 102 Train Epoch: 1 [0/201 (0%)]	Loss: 0.524592
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 171 Norm Difference for worker 102 is 1.10033
INFO:root:FL Epoch: 171 Done on worker:102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :504
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453098
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325740
INFO:root:FL Epoch: 171 Norm Difference for worker 504 is 1.104957
INFO:root:FL Epoch: 171 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :23
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 23 Train Epoch: 0 [0/201 (0%)]	Loss: 0.762421
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 23 Train Epoch: 1 [0/201 (0%)]	Loss: 0.565281
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 171 Norm Difference for worker 23 is 1.147692
INFO:root:FL Epoch: 171 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 171 Training on worker :1606
INFO:root:FL Epoch: 171 Using Learning rate : 0.03557640194722336 
INFO:root:FL Epoch: 171 Normal Training
INFO:root:Worker: 1606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547931
INFO:root:Worker: 1606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475982
INFO:root:FL Epoch: 171 Norm Difference for worker 1606 is 1.079291
INFO:root:FL Epoch: 171 Done on worker:1606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 171 Ends   ===================
INFO:root:Epoch:171 Global Model Test Loss:0.48469531711410074 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:171 Global Model Backdoor Test Loss:0.40998441477616626                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 172 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 172 Workers Selected : [952, 783, 280, 515, 1479, 19, 1030, 117, 1085, 1083]
INFO:root:FL Epoch: 172 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 172 Num points on workers: [200 200 201 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 172 Training on worker :952
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452838
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593068
INFO:root:FL Epoch: 172 Norm Difference for worker 952 is 1.210793
INFO:root:FL Epoch: 172 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :783
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724799
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549995
INFO:root:FL Epoch: 172 Norm Difference for worker 783 is 1.147918
INFO:root:FL Epoch: 172 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :280
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 280 Train Epoch: 0 [0/201 (0%)]	Loss: 0.483994
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 280 Train Epoch: 1 [0/201 (0%)]	Loss: 0.397979
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 172 Norm Difference for worker 280 is 1.094092
INFO:root:FL Epoch: 172 Done on worker:280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :515
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537294
INFO:root:Worker: 515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553743
INFO:root:FL Epoch: 172 Norm Difference for worker 515 is 1.146375
INFO:root:FL Epoch: 172 Done on worker:515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1479
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603527
INFO:root:Worker: 1479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602379
INFO:root:FL Epoch: 172 Norm Difference for worker 1479 is 1.166987
INFO:root:FL Epoch: 172 Done on worker:1479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :19
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.714012
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.534950
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 172 Norm Difference for worker 19 is 1.169585
INFO:root:FL Epoch: 172 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1030
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1030 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768916
INFO:root:Worker: 1030 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380966
INFO:root:FL Epoch: 172 Norm Difference for worker 1030 is 1.228747
INFO:root:FL Epoch: 172 Done on worker:1030
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :117
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.424399
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.509885
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 172 Norm Difference for worker 117 is 1.121251
INFO:root:FL Epoch: 172 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1085
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1085 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685998
INFO:root:Worker: 1085 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615184
INFO:root:FL Epoch: 172 Norm Difference for worker 1085 is 1.113969
INFO:root:FL Epoch: 172 Done on worker:1085
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 172 Training on worker :1083
INFO:root:FL Epoch: 172 Using Learning rate : 0.035505249143328914 
INFO:root:FL Epoch: 172 Normal Training
INFO:root:Worker: 1083 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731093
INFO:root:Worker: 1083 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498288
INFO:root:FL Epoch: 172 Norm Difference for worker 1083 is 1.194858
INFO:root:FL Epoch: 172 Done on worker:1083
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1085
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 172 Ends   ===================
INFO:root:Epoch:172 Global Model Test Loss:0.5023359253126032 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:172 Global Model Backdoor Test Loss:0.4656185458103816                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 173 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 173 Workers Selected : [1628, 979, 254, 531, 878, 811, 754, 483, 335, 446]
INFO:root:FL Epoch: 173 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 173 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 173 Training on worker :1628
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 1628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514583
INFO:root:Worker: 1628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621147
INFO:root:FL Epoch: 173 Norm Difference for worker 1628 is 0.962216
INFO:root:FL Epoch: 173 Done on worker:1628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :979
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 979 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646688
INFO:root:Worker: 979 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507588
INFO:root:FL Epoch: 173 Norm Difference for worker 979 is 1.021181
INFO:root:FL Epoch: 173 Done on worker:979
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :254
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 254 Train Epoch: 0 [0/201 (0%)]	Loss: 0.472032
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 254 Train Epoch: 1 [0/201 (0%)]	Loss: 0.573134
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 173 Norm Difference for worker 254 is 0.916445
INFO:root:FL Epoch: 173 Done on worker:254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :531
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583254
INFO:root:Worker: 531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566676
INFO:root:FL Epoch: 173 Norm Difference for worker 531 is 0.982779
INFO:root:FL Epoch: 173 Done on worker:531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :878
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677422
INFO:root:Worker: 878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.759724
INFO:root:FL Epoch: 173 Norm Difference for worker 878 is 1.010873
INFO:root:FL Epoch: 173 Done on worker:878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :811
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 811 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440241
INFO:root:Worker: 811 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529614
INFO:root:FL Epoch: 173 Norm Difference for worker 811 is 1.076478
INFO:root:FL Epoch: 173 Done on worker:811
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :754
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655446
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420477
INFO:root:FL Epoch: 173 Norm Difference for worker 754 is 1.000889
INFO:root:FL Epoch: 173 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :483
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602513
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366020
INFO:root:FL Epoch: 173 Norm Difference for worker 483 is 0.975913
INFO:root:FL Epoch: 173 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :335
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.511975
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431096
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 173 Norm Difference for worker 335 is 1.039177
INFO:root:FL Epoch: 173 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 173 Training on worker :446
INFO:root:FL Epoch: 173 Using Learning rate : 0.035434238645042256 
INFO:root:FL Epoch: 173 Normal Training
INFO:root:Worker: 446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464567
INFO:root:Worker: 446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365915
INFO:root:FL Epoch: 173 Norm Difference for worker 446 is 1.009539
INFO:root:FL Epoch: 173 Done on worker:446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 254
INFO:root:Norm of Aggregated Model: 5154.9892578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 173 Ends   ===================
INFO:root:Epoch:173 Global Model Test Loss:0.4988203855121837 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:173 Global Model Backdoor Test Loss:0.3971291979153951                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 174 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 174 Workers Selected : [236, 1367, 1538, 385, 191, 300, 1040, 1714, 235, 1351]
INFO:root:FL Epoch: 174 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.1002994 0.1002994 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 174 Num points on workers: [201 200 200 200 201 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 174 Training on worker :236
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 236 Train Epoch: 0 [0/201 (0%)]	Loss: 0.600285
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 236 Train Epoch: 1 [0/201 (0%)]	Loss: 0.331889
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 174 Norm Difference for worker 236 is 1.131911
INFO:root:FL Epoch: 174 Done on worker:236
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1367
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635650
INFO:root:Worker: 1367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573954
INFO:root:FL Epoch: 174 Norm Difference for worker 1367 is 1.250048
INFO:root:FL Epoch: 174 Done on worker:1367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1538
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623043
INFO:root:Worker: 1538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510147
INFO:root:FL Epoch: 174 Norm Difference for worker 1538 is 1.172382
INFO:root:FL Epoch: 174 Done on worker:1538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :385
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620318
INFO:root:Worker: 385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544429
INFO:root:FL Epoch: 174 Norm Difference for worker 385 is 1.067384
INFO:root:FL Epoch: 174 Done on worker:385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :191
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 191 Train Epoch: 0 [0/201 (0%)]	Loss: 0.681636
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 191 Train Epoch: 1 [0/201 (0%)]	Loss: 0.423894
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 174 Norm Difference for worker 191 is 1.136444
INFO:root:FL Epoch: 174 Done on worker:191
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :300
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 300 Train Epoch: 0 [0/201 (0%)]	Loss: 0.658940
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 300 Train Epoch: 1 [0/201 (0%)]	Loss: 0.363195
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 174 Norm Difference for worker 300 is 1.108211
INFO:root:FL Epoch: 174 Done on worker:300
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1040
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394800
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395407
INFO:root:FL Epoch: 174 Norm Difference for worker 1040 is 1.126634
INFO:root:FL Epoch: 174 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1714
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1714 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682622
INFO:root:Worker: 1714 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641354
INFO:root:FL Epoch: 174 Norm Difference for worker 1714 is 1.109575
INFO:root:FL Epoch: 174 Done on worker:1714
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :235
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 235 Train Epoch: 0 [0/201 (0%)]	Loss: 0.678443
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 235 Train Epoch: 1 [0/201 (0%)]	Loss: 0.558099
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 174 Norm Difference for worker 235 is 1.095076
INFO:root:FL Epoch: 174 Done on worker:235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 174 Training on worker :1351
INFO:root:FL Epoch: 174 Using Learning rate : 0.03536337016775217 
INFO:root:FL Epoch: 174 Normal Training
INFO:root:Worker: 1351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664954
INFO:root:Worker: 1351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430697
INFO:root:FL Epoch: 174 Norm Difference for worker 1351 is 1.129672
INFO:root:FL Epoch: 174 Done on worker:1351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 385
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 174 Ends   ===================
INFO:root:Epoch:174 Global Model Test Loss:0.49873834147172813 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:174 Global Model Backdoor Test Loss:0.4296921292940776                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 175 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 175 Workers Selected : [1337, 806, 575, 1105, 1160, 274, 1608, 1054, 242, 1760]
INFO:root:FL Epoch: 175 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 175 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 175 Training on worker :1337
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1337 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437064
INFO:root:Worker: 1337 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500907
INFO:root:FL Epoch: 175 Norm Difference for worker 1337 is 0.93942
INFO:root:FL Epoch: 175 Done on worker:1337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :806
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748338
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594948
INFO:root:FL Epoch: 175 Norm Difference for worker 806 is 1.042739
INFO:root:FL Epoch: 175 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :575
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744227
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600144
INFO:root:FL Epoch: 175 Norm Difference for worker 575 is 1.087507
INFO:root:FL Epoch: 175 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1105
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1105 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506533
INFO:root:Worker: 1105 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408863
INFO:root:FL Epoch: 175 Norm Difference for worker 1105 is 1.013281
INFO:root:FL Epoch: 175 Done on worker:1105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1160
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1160 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431471
INFO:root:Worker: 1160 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678273
INFO:root:FL Epoch: 175 Norm Difference for worker 1160 is 1.03613
INFO:root:FL Epoch: 175 Done on worker:1160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :274
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.671660
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.518324
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 175 Norm Difference for worker 274 is 0.998413
INFO:root:FL Epoch: 175 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1608
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574061
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471786
INFO:root:FL Epoch: 175 Norm Difference for worker 1608 is 1.081999
INFO:root:FL Epoch: 175 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1054
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1054 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416487
INFO:root:Worker: 1054 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440904
INFO:root:FL Epoch: 175 Norm Difference for worker 1054 is 1.008871
INFO:root:FL Epoch: 175 Done on worker:1054
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :242
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.622993
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470175
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 175 Norm Difference for worker 242 is 0.98707
INFO:root:FL Epoch: 175 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 175 Training on worker :1760
INFO:root:FL Epoch: 175 Using Learning rate : 0.03529264342741666 
INFO:root:FL Epoch: 175 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649804
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539323
INFO:root:FL Epoch: 175 Norm Difference for worker 1760 is 1.045595
INFO:root:FL Epoch: 175 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1337
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 175 Ends   ===================
INFO:root:Epoch:175 Global Model Test Loss:0.5047025838318993 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:175 Global Model Backdoor Test Loss:0.39095018804073334                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 176 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 176 Workers Selected : [1247, 1290, 1658, 1782, 576, 1064, 527, 1179, 401, 1717]
INFO:root:FL Epoch: 176 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 176 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 176 Training on worker :1247
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.810862
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595249
INFO:root:FL Epoch: 176 Norm Difference for worker 1247 is 0.988808
INFO:root:FL Epoch: 176 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1290
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617321
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.725485
INFO:root:FL Epoch: 176 Norm Difference for worker 1290 is 0.996312
INFO:root:FL Epoch: 176 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1658
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547966
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386413
INFO:root:FL Epoch: 176 Norm Difference for worker 1658 is 0.995982
INFO:root:FL Epoch: 176 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1782
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608266
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351876
INFO:root:FL Epoch: 176 Norm Difference for worker 1782 is 1.047727
INFO:root:FL Epoch: 176 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :576
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592836
INFO:root:Worker: 576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317344
INFO:root:FL Epoch: 176 Norm Difference for worker 576 is 0.976295
INFO:root:FL Epoch: 176 Done on worker:576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1064
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1064 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506289
INFO:root:Worker: 1064 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484351
INFO:root:FL Epoch: 176 Norm Difference for worker 1064 is 0.95414
INFO:root:FL Epoch: 176 Done on worker:1064
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :527
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627933
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508364
INFO:root:FL Epoch: 176 Norm Difference for worker 527 is 0.936469
INFO:root:FL Epoch: 176 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1179
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1179 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465000
INFO:root:Worker: 1179 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497544
INFO:root:FL Epoch: 176 Norm Difference for worker 1179 is 0.998996
INFO:root:FL Epoch: 176 Done on worker:1179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :401
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578995
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604122
INFO:root:FL Epoch: 176 Norm Difference for worker 401 is 0.979536
INFO:root:FL Epoch: 176 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 176 Training on worker :1717
INFO:root:FL Epoch: 176 Using Learning rate : 0.035222058140561834 
INFO:root:FL Epoch: 176 Normal Training
INFO:root:Worker: 1717 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495326
INFO:root:Worker: 1717 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590268
INFO:root:FL Epoch: 176 Norm Difference for worker 1717 is 1.004438
INFO:root:FL Epoch: 176 Done on worker:1717
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 527
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 176 Ends   ===================
INFO:root:Epoch:176 Global Model Test Loss:0.4989478693288915 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:176 Global Model Backdoor Test Loss:0.41710033516089123                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 177 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 177 Workers Selected : [1431, 149, 1817, 8, 1203, 231, 630, 1409, 1281, 880]
INFO:root:FL Epoch: 177 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 177 Num points on workers: [200 201 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 177 Training on worker :1431
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469370
INFO:root:Worker: 1431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355691
INFO:root:FL Epoch: 177 Norm Difference for worker 1431 is 0.979137
INFO:root:FL Epoch: 177 Done on worker:1431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :149
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 149 Train Epoch: 0 [0/201 (0%)]	Loss: 0.473350
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 149 Train Epoch: 1 [0/201 (0%)]	Loss: 0.594613
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 149 is 0.996561
INFO:root:FL Epoch: 177 Done on worker:149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1817
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585808
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504260
INFO:root:FL Epoch: 177 Norm Difference for worker 1817 is 1.004401
INFO:root:FL Epoch: 177 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :8
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.615545
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.522233
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 8 is 0.943159
INFO:root:FL Epoch: 177 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1203
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1203 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494218
INFO:root:Worker: 1203 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662722
INFO:root:FL Epoch: 177 Norm Difference for worker 1203 is 0.974084
INFO:root:FL Epoch: 177 Done on worker:1203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :231
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 231 Train Epoch: 0 [0/201 (0%)]	Loss: 0.510258
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 231 Train Epoch: 1 [0/201 (0%)]	Loss: 0.411112
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 177 Norm Difference for worker 231 is 0.944283
INFO:root:FL Epoch: 177 Done on worker:231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :630
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 630 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541964
INFO:root:Worker: 630 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654564
INFO:root:FL Epoch: 177 Norm Difference for worker 630 is 0.967168
INFO:root:FL Epoch: 177 Done on worker:630
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1409
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512423
INFO:root:Worker: 1409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506106
INFO:root:FL Epoch: 177 Norm Difference for worker 1409 is 0.995622
INFO:root:FL Epoch: 177 Done on worker:1409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :1281
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 1281 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609734
INFO:root:Worker: 1281 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290186
INFO:root:FL Epoch: 177 Norm Difference for worker 1281 is 0.959988
INFO:root:FL Epoch: 177 Done on worker:1281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 177 Training on worker :880
INFO:root:FL Epoch: 177 Using Learning rate : 0.03515161402428071 
INFO:root:FL Epoch: 177 Normal Training
INFO:root:Worker: 880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763815
INFO:root:Worker: 880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543843
INFO:root:FL Epoch: 177 Norm Difference for worker 880 is 0.95939
INFO:root:FL Epoch: 177 Done on worker:880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 231
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 177 Ends   ===================
INFO:root:Epoch:177 Global Model Test Loss:0.4892295686637654 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:177 Global Model Backdoor Test Loss:0.37489918371041614                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 178 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 178 Workers Selected : [666, 1812, 1517, 1854, 1567, 1906, 1580, 1065, 1576, 561]
INFO:root:FL Epoch: 178 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 178 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 178 Training on worker :666
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599386
INFO:root:Worker: 666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378982
INFO:root:FL Epoch: 178 Norm Difference for worker 666 is 1.148738
INFO:root:FL Epoch: 178 Done on worker:666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1812
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1812 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372872
INFO:root:Worker: 1812 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400276
INFO:root:FL Epoch: 178 Norm Difference for worker 1812 is 1.167806
INFO:root:FL Epoch: 178 Done on worker:1812
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1517
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743837
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426247
INFO:root:FL Epoch: 178 Norm Difference for worker 1517 is 1.149223
INFO:root:FL Epoch: 178 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1854
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720117
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435740
INFO:root:FL Epoch: 178 Norm Difference for worker 1854 is 1.24134
INFO:root:FL Epoch: 178 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1567
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.809271
INFO:root:Worker: 1567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420237
INFO:root:FL Epoch: 178 Norm Difference for worker 1567 is 1.215233
INFO:root:FL Epoch: 178 Done on worker:1567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1906
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449018
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.730788
INFO:root:FL Epoch: 178 Norm Difference for worker 1906 is 1.151968
INFO:root:FL Epoch: 178 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1580
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356676
INFO:root:Worker: 1580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327091
INFO:root:FL Epoch: 178 Norm Difference for worker 1580 is 1.11735
INFO:root:FL Epoch: 178 Done on worker:1580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1065
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613055
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569388
INFO:root:FL Epoch: 178 Norm Difference for worker 1065 is 1.247411
INFO:root:FL Epoch: 178 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :1576
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642797
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307911
INFO:root:FL Epoch: 178 Norm Difference for worker 1576 is 1.191958
INFO:root:FL Epoch: 178 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 178 Training on worker :561
INFO:root:FL Epoch: 178 Using Learning rate : 0.03508131079623215 
INFO:root:FL Epoch: 178 Normal Training
INFO:root:Worker: 561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.934193
INFO:root:Worker: 561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641322
INFO:root:FL Epoch: 178 Norm Difference for worker 561 is 1.23418
INFO:root:FL Epoch: 178 Done on worker:561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1906
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 178 Ends   ===================
INFO:root:Epoch:178 Global Model Test Loss:0.4993688306387733 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:178 Global Model Backdoor Test Loss:0.41160330673058826                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 179 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 179 Workers Selected : [1007, 528, 1736, 577, 987, 560, 843, 1494, 775, 1667]
INFO:root:FL Epoch: 179 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 179 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 179 Training on worker :1007
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383445
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475951
INFO:root:FL Epoch: 179 Norm Difference for worker 1007 is 1.04609
INFO:root:FL Epoch: 179 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :528
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696711
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492011
INFO:root:FL Epoch: 179 Norm Difference for worker 528 is 0.997915
INFO:root:FL Epoch: 179 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1736
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616418
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359487
INFO:root:FL Epoch: 179 Norm Difference for worker 1736 is 1.018545
INFO:root:FL Epoch: 179 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :577
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529083
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488911
INFO:root:FL Epoch: 179 Norm Difference for worker 577 is 0.984803
INFO:root:FL Epoch: 179 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :987
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 987 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554407
INFO:root:Worker: 987 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438472
INFO:root:FL Epoch: 179 Norm Difference for worker 987 is 1.061749
INFO:root:FL Epoch: 179 Done on worker:987
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :560
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512148
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532806
INFO:root:FL Epoch: 179 Norm Difference for worker 560 is 1.015
INFO:root:FL Epoch: 179 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :843
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.835227
INFO:root:Worker: 843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475460
INFO:root:FL Epoch: 179 Norm Difference for worker 843 is 1.045359
INFO:root:FL Epoch: 179 Done on worker:843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1494
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.848652
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406235
INFO:root:FL Epoch: 179 Norm Difference for worker 1494 is 0.980178
INFO:root:FL Epoch: 179 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :775
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545192
INFO:root:Worker: 775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.810143
INFO:root:FL Epoch: 179 Norm Difference for worker 775 is 1.057659
INFO:root:FL Epoch: 179 Done on worker:775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 179 Training on worker :1667
INFO:root:FL Epoch: 179 Using Learning rate : 0.035011148174639684 
INFO:root:FL Epoch: 179 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561788
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508024
INFO:root:FL Epoch: 179 Norm Difference for worker 1667 is 1.053218
INFO:root:FL Epoch: 179 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 577
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 179 Ends   ===================
INFO:root:Epoch:179 Global Model Test Loss:0.4987133741378784 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:179 Global Model Backdoor Test Loss:0.5174771199623743                             and Backdoor Test Accuracy:76.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 180 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 180 Workers Selected : [1715, 892, 1248, 640, 407, 1291, 747, 82, 1125, 395]
INFO:root:FL Epoch: 180 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 180 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 180 Training on worker :1715
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1715 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538635
INFO:root:Worker: 1715 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509178
INFO:root:FL Epoch: 180 Norm Difference for worker 1715 is 1.053338
INFO:root:FL Epoch: 180 Done on worker:1715
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :892
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600031
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541906
INFO:root:FL Epoch: 180 Norm Difference for worker 892 is 0.989712
INFO:root:FL Epoch: 180 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1248
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680958
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588135
INFO:root:FL Epoch: 180 Norm Difference for worker 1248 is 1.025093
INFO:root:FL Epoch: 180 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :640
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656727
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573686
INFO:root:FL Epoch: 180 Norm Difference for worker 640 is 1.044728
INFO:root:FL Epoch: 180 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :407
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501982
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404454
INFO:root:FL Epoch: 180 Norm Difference for worker 407 is 0.992371
INFO:root:FL Epoch: 180 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1291
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1291 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623083
INFO:root:Worker: 1291 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423230
INFO:root:FL Epoch: 180 Norm Difference for worker 1291 is 0.942465
INFO:root:FL Epoch: 180 Done on worker:1291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :747
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518112
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451588
INFO:root:FL Epoch: 180 Norm Difference for worker 747 is 0.986043
INFO:root:FL Epoch: 180 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :82
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 82 Train Epoch: 0 [0/201 (0%)]	Loss: 0.605764
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 82 Train Epoch: 1 [0/201 (0%)]	Loss: 0.454027
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 180 Norm Difference for worker 82 is 0.963068
INFO:root:FL Epoch: 180 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :1125
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478713
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506718
INFO:root:FL Epoch: 180 Norm Difference for worker 1125 is 0.980111
INFO:root:FL Epoch: 180 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 180 Training on worker :395
INFO:root:FL Epoch: 180 Using Learning rate : 0.0349411258782904 
INFO:root:FL Epoch: 180 Normal Training
INFO:root:Worker: 395 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630195
INFO:root:Worker: 395 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415495
INFO:root:FL Epoch: 180 Norm Difference for worker 395 is 1.005085
INFO:root:FL Epoch: 180 Done on worker:395
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 82
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 180 Ends   ===================
INFO:root:Epoch:180 Global Model Test Loss:0.5147210622535032 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:180 Global Model Backdoor Test Loss:0.5650799920161566                             and Backdoor Test Accuracy:74.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 181 Begins ===================
INFO:root:FL Epoch: 181 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 181 Workers Selected : [0, 28, 1729, 475, 301, 21, 1428, 1065, 1257, 1472]
INFO:root:FL Epoch: 181 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 181 Num points on workers: [200 201 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 181 Training on worker :0
INFO:root:FL Epoch: 181 Using Learning rate : 0.006974248725306764 
INFO:root:FL Epoch: 181 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474036
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400208
INFO:root:FL Epoch: 181 Worker: 0 Backdoor Test Loss: 0.3818378895521164 Backdoor Test Accuracy: 87.5
INFO:root:FL Epoch: 181 Worker: 0 Backdoor Train Loss: 0.35261489599943163 Backdoor Train Accuracy: 89.0
INFO:root:FL Epoch: 181 Norm Difference for worker 0 is 0.265092
INFO:root:FL Epoch: 181 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :28
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.380958
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.377228
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 181 Norm Difference for worker 28 is 0.906861
INFO:root:FL Epoch: 181 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1729
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487167
INFO:root:Worker: 1729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569319
INFO:root:FL Epoch: 181 Norm Difference for worker 1729 is 0.983357
INFO:root:FL Epoch: 181 Done on worker:1729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :475
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570017
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361395
INFO:root:FL Epoch: 181 Norm Difference for worker 475 is 0.961218
INFO:root:FL Epoch: 181 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :301
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.484936
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.666150
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 181 Norm Difference for worker 301 is 0.984085
INFO:root:FL Epoch: 181 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :21
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 21 Train Epoch: 0 [0/201 (0%)]	Loss: 0.568822
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 21 Train Epoch: 1 [0/201 (0%)]	Loss: 0.624483
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 181 Norm Difference for worker 21 is 0.993993
INFO:root:FL Epoch: 181 Done on worker:21
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1428
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651536
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568916
INFO:root:FL Epoch: 181 Norm Difference for worker 1428 is 0.998313
INFO:root:FL Epoch: 181 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1065
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.810734
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621324
INFO:root:FL Epoch: 181 Norm Difference for worker 1065 is 0.994959
INFO:root:FL Epoch: 181 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1257
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1257 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596063
INFO:root:Worker: 1257 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562926
INFO:root:FL Epoch: 181 Norm Difference for worker 1257 is 0.985419
INFO:root:FL Epoch: 181 Done on worker:1257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 181 Training on worker :1472
INFO:root:FL Epoch: 181 Using Learning rate : 0.03487124362653382 
INFO:root:FL Epoch: 181 Normal Training
INFO:root:Worker: 1472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586751
INFO:root:Worker: 1472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489848
INFO:root:FL Epoch: 181 Norm Difference for worker 1472 is 1.026847
INFO:root:FL Epoch: 181 Done on worker:1472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 181 Ends   ===================
INFO:root:Epoch:181 Global Model Test Loss:0.49954012737554665 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:181 Global Model Backdoor Test Loss:0.3818378895521164                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 182 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 182 Workers Selected : [1214, 290, 152, 33, 404, 856, 222, 1685, 218, 373]
INFO:root:FL Epoch: 182 Fraction of points on each worker in this round: [0.09975062 0.10024938 0.10024938 0.10024938 0.09975062 0.09975062
 0.10024938 0.09975062 0.10024938 0.09975062]
INFO:root:FL Epoch: 182 Num points on workers: [200 201 201 201 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 182 Training on worker :1214
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1214 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521710
INFO:root:Worker: 1214 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495289
INFO:root:FL Epoch: 182 Norm Difference for worker 1214 is 1.019229
INFO:root:FL Epoch: 182 Done on worker:1214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :290
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.653186
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488608
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 182 Norm Difference for worker 290 is 1.012125
INFO:root:FL Epoch: 182 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :152
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 152 Train Epoch: 0 [0/201 (0%)]	Loss: 0.549435
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 152 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419339
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 182 Norm Difference for worker 152 is 0.983003
INFO:root:FL Epoch: 182 Done on worker:152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :33
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 33 Train Epoch: 0 [0/201 (0%)]	Loss: 0.572265
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 33 Train Epoch: 1 [0/201 (0%)]	Loss: 0.556444
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 182 Norm Difference for worker 33 is 1.056604
INFO:root:FL Epoch: 182 Done on worker:33
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :404
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.930489
INFO:root:Worker: 404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467223
INFO:root:FL Epoch: 182 Norm Difference for worker 404 is 1.035078
INFO:root:FL Epoch: 182 Done on worker:404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :856
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435808
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504621
INFO:root:FL Epoch: 182 Norm Difference for worker 856 is 1.123253
INFO:root:FL Epoch: 182 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :222
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.484939
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.458415
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 182 Norm Difference for worker 222 is 0.993203
INFO:root:FL Epoch: 182 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :1685
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 1685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506355
INFO:root:Worker: 1685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638812
INFO:root:FL Epoch: 182 Norm Difference for worker 1685 is 1.004143
INFO:root:FL Epoch: 182 Done on worker:1685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :218
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 218 Train Epoch: 0 [0/201 (0%)]	Loss: 0.607758
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 218 Train Epoch: 1 [0/201 (0%)]	Loss: 0.445679
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 182 Norm Difference for worker 218 is 1.019372
INFO:root:FL Epoch: 182 Done on worker:218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 182 Training on worker :373
INFO:root:FL Epoch: 182 Using Learning rate : 0.03480150113928076 
INFO:root:FL Epoch: 182 Normal Training
INFO:root:Worker: 373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495331
INFO:root:Worker: 373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391325
INFO:root:FL Epoch: 182 Norm Difference for worker 373 is 1.026387
INFO:root:FL Epoch: 182 Done on worker:373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 222
INFO:root:Norm of Aggregated Model: 5154.98974609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 182 Ends   ===================
INFO:root:Epoch:182 Global Model Test Loss:0.5151491691084469 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:182 Global Model Backdoor Test Loss:0.39587952693303424                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 183 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 183 Workers Selected : [1540, 853, 194, 931, 971, 892, 514, 287, 1467, 1603]
INFO:root:FL Epoch: 183 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 183 Num points on workers: [200 200 201 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 183 Training on worker :1540
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478299
INFO:root:Worker: 1540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.647471
INFO:root:FL Epoch: 183 Norm Difference for worker 1540 is 1.182915
INFO:root:FL Epoch: 183 Done on worker:1540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :853
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409808
INFO:root:Worker: 853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.726480
INFO:root:FL Epoch: 183 Norm Difference for worker 853 is 1.180313
INFO:root:FL Epoch: 183 Done on worker:853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :194
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 194 Train Epoch: 0 [0/201 (0%)]	Loss: 0.774223
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 194 Train Epoch: 1 [0/201 (0%)]	Loss: 0.365753
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 183 Norm Difference for worker 194 is 1.142495
INFO:root:FL Epoch: 183 Done on worker:194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :931
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575832
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461446
INFO:root:FL Epoch: 183 Norm Difference for worker 931 is 1.22532
INFO:root:FL Epoch: 183 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :971
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 971 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451138
INFO:root:Worker: 971 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433043
INFO:root:FL Epoch: 183 Norm Difference for worker 971 is 1.107256
INFO:root:FL Epoch: 183 Done on worker:971
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :892
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558918
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430578
INFO:root:FL Epoch: 183 Norm Difference for worker 892 is 1.132419
INFO:root:FL Epoch: 183 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :514
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615850
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396615
INFO:root:FL Epoch: 183 Norm Difference for worker 514 is 1.12285
INFO:root:FL Epoch: 183 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :287
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 287 Train Epoch: 0 [0/201 (0%)]	Loss: 0.772116
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 287 Train Epoch: 1 [0/201 (0%)]	Loss: 0.546351
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 183 Norm Difference for worker 287 is 1.207587
INFO:root:FL Epoch: 183 Done on worker:287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1467
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567668
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.719950
INFO:root:FL Epoch: 183 Norm Difference for worker 1467 is 1.175914
INFO:root:FL Epoch: 183 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 183 Training on worker :1603
INFO:root:FL Epoch: 183 Using Learning rate : 0.03473189813700219 
INFO:root:FL Epoch: 183 Normal Training
INFO:root:Worker: 1603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805264
INFO:root:Worker: 1603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570784
INFO:root:FL Epoch: 183 Norm Difference for worker 1603 is 1.120386
INFO:root:FL Epoch: 183 Done on worker:1603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 971
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 183 Ends   ===================
INFO:root:Epoch:183 Global Model Test Loss:0.5133691219722524 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:183 Global Model Backdoor Test Loss:0.3975656032562256                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 184 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 184 Workers Selected : [1810, 158, 999, 464, 1856, 1267, 1872, 1777, 1932, 540]
INFO:root:FL Epoch: 184 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 184 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 184 Training on worker :1810
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700920
INFO:root:Worker: 1810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521803
INFO:root:FL Epoch: 184 Norm Difference for worker 1810 is 1.055417
INFO:root:FL Epoch: 184 Done on worker:1810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :158
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.373180
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.650762
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 184 Norm Difference for worker 158 is 1.11335
INFO:root:FL Epoch: 184 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :999
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.385997
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476138
INFO:root:FL Epoch: 184 Norm Difference for worker 999 is 1.125603
INFO:root:FL Epoch: 184 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :464
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489705
INFO:root:Worker: 464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580284
INFO:root:FL Epoch: 184 Norm Difference for worker 464 is 1.064018
INFO:root:FL Epoch: 184 Done on worker:464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1856
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531403
INFO:root:Worker: 1856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367610
INFO:root:FL Epoch: 184 Norm Difference for worker 1856 is 1.100777
INFO:root:FL Epoch: 184 Done on worker:1856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1267
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1267 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617489
INFO:root:Worker: 1267 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520899
INFO:root:FL Epoch: 184 Norm Difference for worker 1267 is 1.064841
INFO:root:FL Epoch: 184 Done on worker:1267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1872
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458216
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578130
INFO:root:FL Epoch: 184 Norm Difference for worker 1872 is 1.046708
INFO:root:FL Epoch: 184 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1777
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511597
INFO:root:Worker: 1777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450622
INFO:root:FL Epoch: 184 Norm Difference for worker 1777 is 1.110971
INFO:root:FL Epoch: 184 Done on worker:1777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :1932
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 1932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415586
INFO:root:Worker: 1932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438627
INFO:root:FL Epoch: 184 Norm Difference for worker 1932 is 1.032152
INFO:root:FL Epoch: 184 Done on worker:1932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 184 Training on worker :540
INFO:root:FL Epoch: 184 Using Learning rate : 0.03466243434072819 
INFO:root:FL Epoch: 184 Normal Training
INFO:root:Worker: 540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679096
INFO:root:Worker: 540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612985
INFO:root:FL Epoch: 184 Norm Difference for worker 540 is 1.087951
INFO:root:FL Epoch: 184 Done on worker:540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1872
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 184 Ends   ===================
INFO:root:Epoch:184 Global Model Test Loss:0.4879728327779209 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:184 Global Model Backdoor Test Loss:0.3248772496978442                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 185 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 185 Workers Selected : [1888, 1190, 1127, 991, 1603, 1478, 816, 1268, 1558, 234]
INFO:root:FL Epoch: 185 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 185 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 185 Training on worker :1888
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523425
INFO:root:Worker: 1888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321344
INFO:root:FL Epoch: 185 Norm Difference for worker 1888 is 1.073527
INFO:root:FL Epoch: 185 Done on worker:1888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1190
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750163
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277198
INFO:root:FL Epoch: 185 Norm Difference for worker 1190 is 1.019885
INFO:root:FL Epoch: 185 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1127
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1127 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720169
INFO:root:Worker: 1127 Train Epoch: 1 [0/200 (0%)]	Loss: 0.702353
INFO:root:FL Epoch: 185 Norm Difference for worker 1127 is 1.047452
INFO:root:FL Epoch: 185 Done on worker:1127
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :991
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398055
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369336
INFO:root:FL Epoch: 185 Norm Difference for worker 991 is 1.062649
INFO:root:FL Epoch: 185 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1603
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574396
INFO:root:Worker: 1603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.727727
INFO:root:FL Epoch: 185 Norm Difference for worker 1603 is 1.02481
INFO:root:FL Epoch: 185 Done on worker:1603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1478
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513216
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417604
INFO:root:FL Epoch: 185 Norm Difference for worker 1478 is 0.985348
INFO:root:FL Epoch: 185 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :816
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 816 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675048
INFO:root:Worker: 816 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415670
INFO:root:FL Epoch: 185 Norm Difference for worker 816 is 1.13622
INFO:root:FL Epoch: 185 Done on worker:816
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1268
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486253
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559871
INFO:root:FL Epoch: 185 Norm Difference for worker 1268 is 1.071756
INFO:root:FL Epoch: 185 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :1558
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 1558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527858
INFO:root:Worker: 1558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546308
INFO:root:FL Epoch: 185 Norm Difference for worker 1558 is 1.076262
INFO:root:FL Epoch: 185 Done on worker:1558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 185 Training on worker :234
INFO:root:FL Epoch: 185 Using Learning rate : 0.03459310947204674 
INFO:root:FL Epoch: 185 Normal Training
INFO:root:Worker: 234 Train Epoch: 0 [0/201 (0%)]	Loss: 0.625666
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 234 Train Epoch: 1 [0/201 (0%)]	Loss: 0.499143
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 185 Norm Difference for worker 234 is 1.174247
INFO:root:FL Epoch: 185 Done on worker:234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1478
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 185 Ends   ===================
INFO:root:Epoch:185 Global Model Test Loss:0.5230680984609267 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:185 Global Model Backdoor Test Loss:0.4469681630531947                             and Backdoor Test Accuracy:79.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 186 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 186 Workers Selected : [87, 1215, 923, 1875, 888, 1441, 1942, 138, 725, 1833]
INFO:root:FL Epoch: 186 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 186 Num points on workers: [201 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 186 Training on worker :87
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 87 Train Epoch: 0 [0/201 (0%)]	Loss: 0.900320
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 87 Train Epoch: 1 [0/201 (0%)]	Loss: 0.523443
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 186 Norm Difference for worker 87 is 1.430689
INFO:root:FL Epoch: 186 Done on worker:87
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1215
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637318
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363360
INFO:root:FL Epoch: 186 Norm Difference for worker 1215 is 1.345738
INFO:root:FL Epoch: 186 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :923
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698648
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423887
INFO:root:FL Epoch: 186 Norm Difference for worker 923 is 1.205631
INFO:root:FL Epoch: 186 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1875
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1875 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436244
INFO:root:Worker: 1875 Train Epoch: 1 [0/200 (0%)]	Loss: 0.678242
INFO:root:FL Epoch: 186 Norm Difference for worker 1875 is 1.322087
INFO:root:FL Epoch: 186 Done on worker:1875
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :888
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737660
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496311
INFO:root:FL Epoch: 186 Norm Difference for worker 888 is 1.331267
INFO:root:FL Epoch: 186 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1441
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667385
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367288
INFO:root:FL Epoch: 186 Norm Difference for worker 1441 is 1.344093
INFO:root:FL Epoch: 186 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1942
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591683
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535665
INFO:root:FL Epoch: 186 Norm Difference for worker 1942 is 1.51598
INFO:root:FL Epoch: 186 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :138
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.431103
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.594247
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 186 Norm Difference for worker 138 is 1.345478
INFO:root:FL Epoch: 186 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :725
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713164
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332678
INFO:root:FL Epoch: 186 Norm Difference for worker 725 is 1.33061
INFO:root:FL Epoch: 186 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 186 Training on worker :1833
INFO:root:FL Epoch: 186 Using Learning rate : 0.03452392325310264 
INFO:root:FL Epoch: 186 Normal Training
INFO:root:Worker: 1833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595807
INFO:root:Worker: 1833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565825
INFO:root:FL Epoch: 186 Norm Difference for worker 1833 is 1.222073
INFO:root:FL Epoch: 186 Done on worker:1833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 923
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 186 Ends   ===================
INFO:root:Epoch:186 Global Model Test Loss:0.5008738461662742 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:186 Global Model Backdoor Test Loss:0.4276811828215917                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 187 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 187 Workers Selected : [829, 1030, 1117, 581, 1213, 254, 1260, 925, 1813, 1619]
INFO:root:FL Epoch: 187 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 187 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 187 Training on worker :829
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744661
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559494
INFO:root:FL Epoch: 187 Norm Difference for worker 829 is 1.06283
INFO:root:FL Epoch: 187 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1030
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1030 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600100
INFO:root:Worker: 1030 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453787
INFO:root:FL Epoch: 187 Norm Difference for worker 1030 is 1.097697
INFO:root:FL Epoch: 187 Done on worker:1030
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1117
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1117 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545356
INFO:root:Worker: 1117 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340422
INFO:root:FL Epoch: 187 Norm Difference for worker 1117 is 1.044539
INFO:root:FL Epoch: 187 Done on worker:1117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :581
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606496
INFO:root:Worker: 581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487943
INFO:root:FL Epoch: 187 Norm Difference for worker 581 is 1.141714
INFO:root:FL Epoch: 187 Done on worker:581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1213
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1213 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563386
INFO:root:Worker: 1213 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500972
INFO:root:FL Epoch: 187 Norm Difference for worker 1213 is 1.062345
INFO:root:FL Epoch: 187 Done on worker:1213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :254
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 254 Train Epoch: 0 [0/201 (0%)]	Loss: 0.431328
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 254 Train Epoch: 1 [0/201 (0%)]	Loss: 0.424541
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 187 Norm Difference for worker 254 is 0.954142
INFO:root:FL Epoch: 187 Done on worker:254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1260
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598313
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591711
INFO:root:FL Epoch: 187 Norm Difference for worker 1260 is 1.059632
INFO:root:FL Epoch: 187 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :925
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478747
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352014
INFO:root:FL Epoch: 187 Norm Difference for worker 925 is 0.970402
INFO:root:FL Epoch: 187 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1813
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602602
INFO:root:Worker: 1813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559315
INFO:root:FL Epoch: 187 Norm Difference for worker 1813 is 1.022446
INFO:root:FL Epoch: 187 Done on worker:1813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 187 Training on worker :1619
INFO:root:FL Epoch: 187 Using Learning rate : 0.03445487540659644 
INFO:root:FL Epoch: 187 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539271
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638039
INFO:root:FL Epoch: 187 Norm Difference for worker 1619 is 1.067012
INFO:root:FL Epoch: 187 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 925
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 187 Ends   ===================
INFO:root:Epoch:187 Global Model Test Loss:0.5234806783059064 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:187 Global Model Backdoor Test Loss:0.58794833223025                             and Backdoor Test Accuracy:67.5 
INFO:root:=======================================================
INFO:root:================FL round 188 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 188 Workers Selected : [225, 1689, 881, 1886, 860, 409, 1241, 686, 360, 231]
INFO:root:FL Epoch: 188 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 188 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 188 Training on worker :225
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 225 Train Epoch: 0 [0/201 (0%)]	Loss: 0.549240
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 225 Train Epoch: 1 [0/201 (0%)]	Loss: 0.643289
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 188 Norm Difference for worker 225 is 1.028864
INFO:root:FL Epoch: 188 Done on worker:225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1689
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556374
INFO:root:Worker: 1689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.734247
INFO:root:FL Epoch: 188 Norm Difference for worker 1689 is 1.019976
INFO:root:FL Epoch: 188 Done on worker:1689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :881
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500947
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501103
INFO:root:FL Epoch: 188 Norm Difference for worker 881 is 0.99047
INFO:root:FL Epoch: 188 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1886
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569204
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313488
INFO:root:FL Epoch: 188 Norm Difference for worker 1886 is 0.980389
INFO:root:FL Epoch: 188 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :860
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531804
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.765679
INFO:root:FL Epoch: 188 Norm Difference for worker 860 is 1.104038
INFO:root:FL Epoch: 188 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :409
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 409 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781409
INFO:root:Worker: 409 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595613
INFO:root:FL Epoch: 188 Norm Difference for worker 409 is 1.043957
INFO:root:FL Epoch: 188 Done on worker:409
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :1241
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 1241 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631944
INFO:root:Worker: 1241 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493055
INFO:root:FL Epoch: 188 Norm Difference for worker 1241 is 1.013046
INFO:root:FL Epoch: 188 Done on worker:1241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :686
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652635
INFO:root:Worker: 686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591169
INFO:root:FL Epoch: 188 Norm Difference for worker 686 is 1.051815
INFO:root:FL Epoch: 188 Done on worker:686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :360
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.921852
INFO:root:Worker: 360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544037
INFO:root:FL Epoch: 188 Norm Difference for worker 360 is 1.060023
INFO:root:FL Epoch: 188 Done on worker:360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 188 Training on worker :231
INFO:root:FL Epoch: 188 Using Learning rate : 0.034385965655783245 
INFO:root:FL Epoch: 188 Normal Training
INFO:root:Worker: 231 Train Epoch: 0 [0/201 (0%)]	Loss: 0.633607
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 231 Train Epoch: 1 [0/201 (0%)]	Loss: 0.384505
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 188 Norm Difference for worker 231 is 0.910866
INFO:root:FL Epoch: 188 Done on worker:231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 231
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 188 Ends   ===================
INFO:root:Epoch:188 Global Model Test Loss:0.49664168410441456 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:188 Global Model Backdoor Test Loss:0.4410543292760849                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 189 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 189 Workers Selected : [941, 108, 1146, 935, 1362, 1694, 880, 193, 1326, 1581]
INFO:root:FL Epoch: 189 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 189 Num points on workers: [200 201 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 189 Training on worker :941
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460937
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494919
INFO:root:FL Epoch: 189 Norm Difference for worker 941 is 1.167004
INFO:root:FL Epoch: 189 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :108
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 108 Train Epoch: 0 [0/201 (0%)]	Loss: 0.708815
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 108 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470725
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 189 Norm Difference for worker 108 is 1.088573
INFO:root:FL Epoch: 189 Done on worker:108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1146
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1146 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487574
INFO:root:Worker: 1146 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413330
INFO:root:FL Epoch: 189 Norm Difference for worker 1146 is 1.240254
INFO:root:FL Epoch: 189 Done on worker:1146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :935
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612114
INFO:root:Worker: 935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372556
INFO:root:FL Epoch: 189 Norm Difference for worker 935 is 1.269688
INFO:root:FL Epoch: 189 Done on worker:935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1362
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743209
INFO:root:Worker: 1362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597286
INFO:root:FL Epoch: 189 Norm Difference for worker 1362 is 1.190906
INFO:root:FL Epoch: 189 Done on worker:1362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1694
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505712
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586334
INFO:root:FL Epoch: 189 Norm Difference for worker 1694 is 1.229475
INFO:root:FL Epoch: 189 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :880
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531926
INFO:root:Worker: 880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452370
INFO:root:FL Epoch: 189 Norm Difference for worker 880 is 1.204514
INFO:root:FL Epoch: 189 Done on worker:880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :193
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 193 Train Epoch: 0 [0/201 (0%)]	Loss: 0.664933
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 193 Train Epoch: 1 [0/201 (0%)]	Loss: 0.629261
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 189 Norm Difference for worker 193 is 1.34838
INFO:root:FL Epoch: 189 Done on worker:193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1326
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 1.162970
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565344
INFO:root:FL Epoch: 189 Norm Difference for worker 1326 is 1.223961
INFO:root:FL Epoch: 189 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 189 Training on worker :1581
INFO:root:FL Epoch: 189 Using Learning rate : 0.03431719372447167 
INFO:root:FL Epoch: 189 Normal Training
INFO:root:Worker: 1581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588012
INFO:root:Worker: 1581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455028
INFO:root:FL Epoch: 189 Norm Difference for worker 1581 is 1.253946
INFO:root:FL Epoch: 189 Done on worker:1581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 108
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 189 Ends   ===================
INFO:root:Epoch:189 Global Model Test Loss:0.4940318053259569 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:189 Global Model Backdoor Test Loss:0.42230868836243945                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 190 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 190 Workers Selected : [1025, 1038, 99, 1766, 821, 741, 1366, 1215, 1823, 1722]
INFO:root:FL Epoch: 190 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 190 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 190 Training on worker :1025
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1025 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634531
INFO:root:Worker: 1025 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517159
INFO:root:FL Epoch: 190 Norm Difference for worker 1025 is 1.077708
INFO:root:FL Epoch: 190 Done on worker:1025
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1038
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1038 Train Epoch: 0 [0/200 (0%)]	Loss: 0.790234
INFO:root:Worker: 1038 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568456
INFO:root:FL Epoch: 190 Norm Difference for worker 1038 is 1.178597
INFO:root:FL Epoch: 190 Done on worker:1038
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :99
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 99 Train Epoch: 0 [0/201 (0%)]	Loss: 0.579853
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 99 Train Epoch: 1 [0/201 (0%)]	Loss: 0.444211
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 190 Norm Difference for worker 99 is 1.096134
INFO:root:FL Epoch: 190 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1766
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403691
INFO:root:Worker: 1766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411466
INFO:root:FL Epoch: 190 Norm Difference for worker 1766 is 1.188356
INFO:root:FL Epoch: 190 Done on worker:1766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :821
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433767
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.743311
INFO:root:FL Epoch: 190 Norm Difference for worker 821 is 1.159657
INFO:root:FL Epoch: 190 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :741
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633455
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641111
INFO:root:FL Epoch: 190 Norm Difference for worker 741 is 1.19707
INFO:root:FL Epoch: 190 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1366
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1366 Train Epoch: 0 [0/200 (0%)]	Loss: 0.820818
INFO:root:Worker: 1366 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591378
INFO:root:FL Epoch: 190 Norm Difference for worker 1366 is 1.175568
INFO:root:FL Epoch: 190 Done on worker:1366
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1215
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526603
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.887020
INFO:root:FL Epoch: 190 Norm Difference for worker 1215 is 1.204511
INFO:root:FL Epoch: 190 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1823
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441646
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553012
INFO:root:FL Epoch: 190 Norm Difference for worker 1823 is 1.322457
INFO:root:FL Epoch: 190 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 190 Training on worker :1722
INFO:root:FL Epoch: 190 Using Learning rate : 0.034248559337022734 
INFO:root:FL Epoch: 190 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611532
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431697
INFO:root:FL Epoch: 190 Norm Difference for worker 1722 is 1.184255
INFO:root:FL Epoch: 190 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 99
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 190 Ends   ===================
INFO:root:Epoch:190 Global Model Test Loss:0.5060898153220906 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:190 Global Model Backdoor Test Loss:0.4759717583656311                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 191 Begins ===================
INFO:root:FL Epoch: 191 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 191 Workers Selected : [0, 917, 911, 990, 1301, 347, 546, 1428, 550, 452]
INFO:root:FL Epoch: 191 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 191 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 191 Training on worker :0
INFO:root:FL Epoch: 191 Using Learning rate : 0.006836012443669737 
INFO:root:FL Epoch: 191 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419099
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372485
INFO:root:FL Epoch: 191 Worker: 0 Backdoor Test Loss: 0.3855668356021245 Backdoor Test Accuracy: 87.5
INFO:root:FL Epoch: 191 Worker: 0 Backdoor Train Loss: 0.3351821884512901 Backdoor Train Accuracy: 88.5
INFO:root:FL Epoch: 191 Norm Difference for worker 0 is 0.241099
INFO:root:FL Epoch: 191 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :917
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650158
INFO:root:Worker: 917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367590
INFO:root:FL Epoch: 191 Norm Difference for worker 917 is 1.066499
INFO:root:FL Epoch: 191 Done on worker:917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :911
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740810
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477422
INFO:root:FL Epoch: 191 Norm Difference for worker 911 is 1.065094
INFO:root:FL Epoch: 191 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :990
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 990 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541766
INFO:root:Worker: 990 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688055
INFO:root:FL Epoch: 191 Norm Difference for worker 990 is 1.183363
INFO:root:FL Epoch: 191 Done on worker:990
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1301
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1301 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633952
INFO:root:Worker: 1301 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551387
INFO:root:FL Epoch: 191 Norm Difference for worker 1301 is 1.143277
INFO:root:FL Epoch: 191 Done on worker:1301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :347
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614680
INFO:root:Worker: 347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704881
INFO:root:FL Epoch: 191 Norm Difference for worker 347 is 1.134174
INFO:root:FL Epoch: 191 Done on worker:347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :546
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453343
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480796
INFO:root:FL Epoch: 191 Norm Difference for worker 546 is 1.117145
INFO:root:FL Epoch: 191 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :1428
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546755
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363239
INFO:root:FL Epoch: 191 Norm Difference for worker 1428 is 1.051054
INFO:root:FL Epoch: 191 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :550
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407306
INFO:root:Worker: 550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508833
INFO:root:FL Epoch: 191 Norm Difference for worker 550 is 1.127603
INFO:root:FL Epoch: 191 Done on worker:550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 191 Training on worker :452
INFO:root:FL Epoch: 191 Using Learning rate : 0.034180062218348684 
INFO:root:FL Epoch: 191 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574690
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525499
INFO:root:FL Epoch: 191 Norm Difference for worker 452 is 1.008264
INFO:root:FL Epoch: 191 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 191 Ends   ===================
INFO:root:Epoch:191 Global Model Test Loss:0.5050516759648043 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:191 Global Model Backdoor Test Loss:0.3855668356021245                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 192 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 192 Workers Selected : [881, 1359, 460, 768, 1825, 1861, 1170, 1923, 174, 1013]
INFO:root:FL Epoch: 192 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 192 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 192 Training on worker :881
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.236002
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384260
INFO:root:FL Epoch: 192 Norm Difference for worker 881 is 0.995595
INFO:root:FL Epoch: 192 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1359
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.812102
INFO:root:Worker: 1359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.736291
INFO:root:FL Epoch: 192 Norm Difference for worker 1359 is 1.12417
INFO:root:FL Epoch: 192 Done on worker:1359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :460
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.852860
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504691
INFO:root:FL Epoch: 192 Norm Difference for worker 460 is 1.164375
INFO:root:FL Epoch: 192 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :768
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532694
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496258
INFO:root:FL Epoch: 192 Norm Difference for worker 768 is 1.104053
INFO:root:FL Epoch: 192 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1825
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.811272
INFO:root:Worker: 1825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546265
INFO:root:FL Epoch: 192 Norm Difference for worker 1825 is 1.089422
INFO:root:FL Epoch: 192 Done on worker:1825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1861
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585601
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377216
INFO:root:FL Epoch: 192 Norm Difference for worker 1861 is 1.060267
INFO:root:FL Epoch: 192 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1170
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1170 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713884
INFO:root:Worker: 1170 Train Epoch: 1 [0/200 (0%)]	Loss: 0.721685
INFO:root:FL Epoch: 192 Norm Difference for worker 1170 is 1.205421
INFO:root:FL Epoch: 192 Done on worker:1170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1923
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321041
INFO:root:Worker: 1923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690284
INFO:root:FL Epoch: 192 Norm Difference for worker 1923 is 1.15077
INFO:root:FL Epoch: 192 Done on worker:1923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :174
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 0.593282
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.641689
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 192 Norm Difference for worker 174 is 1.10079
INFO:root:FL Epoch: 192 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 192 Training on worker :1013
INFO:root:FL Epoch: 192 Using Learning rate : 0.03411170209391199 
INFO:root:FL Epoch: 192 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643494
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437428
INFO:root:FL Epoch: 192 Norm Difference for worker 1013 is 1.10163
INFO:root:FL Epoch: 192 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 881
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 192 Ends   ===================
INFO:root:Epoch:192 Global Model Test Loss:0.4863358665915096 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:192 Global Model Backdoor Test Loss:0.3376329764723778                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 193 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 193 Workers Selected : [856, 1080, 734, 1781, 1228, 855, 596, 1509, 238, 1468]
INFO:root:FL Epoch: 193 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 193 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 193 Training on worker :856
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 1.081768
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.746886
INFO:root:FL Epoch: 193 Norm Difference for worker 856 is 1.384521
INFO:root:FL Epoch: 193 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1080
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706295
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554705
INFO:root:FL Epoch: 193 Norm Difference for worker 1080 is 1.24786
INFO:root:FL Epoch: 193 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :734
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675547
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598726
INFO:root:FL Epoch: 193 Norm Difference for worker 734 is 1.243641
INFO:root:FL Epoch: 193 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1781
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433032
INFO:root:Worker: 1781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417382
INFO:root:FL Epoch: 193 Norm Difference for worker 1781 is 1.29685
INFO:root:FL Epoch: 193 Done on worker:1781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1228
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1228 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808610
INFO:root:Worker: 1228 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574953
INFO:root:FL Epoch: 193 Norm Difference for worker 1228 is 1.223038
INFO:root:FL Epoch: 193 Done on worker:1228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :855
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552560
INFO:root:Worker: 855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391548
INFO:root:FL Epoch: 193 Norm Difference for worker 855 is 1.313877
INFO:root:FL Epoch: 193 Done on worker:855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :596
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523941
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.717264
INFO:root:FL Epoch: 193 Norm Difference for worker 596 is 1.3075
INFO:root:FL Epoch: 193 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1509
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705006
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656930
INFO:root:FL Epoch: 193 Norm Difference for worker 1509 is 1.372546
INFO:root:FL Epoch: 193 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :238
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 238 Train Epoch: 0 [0/201 (0%)]	Loss: 0.578880
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 238 Train Epoch: 1 [0/201 (0%)]	Loss: 0.592008
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 193 Norm Difference for worker 238 is 1.240412
INFO:root:FL Epoch: 193 Done on worker:238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 193 Training on worker :1468
INFO:root:FL Epoch: 193 Using Learning rate : 0.03404347868972417 
INFO:root:FL Epoch: 193 Normal Training
INFO:root:Worker: 1468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698335
INFO:root:Worker: 1468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644756
INFO:root:FL Epoch: 193 Norm Difference for worker 1468 is 1.459854
INFO:root:FL Epoch: 193 Done on worker:1468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1080
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 193 Ends   ===================
INFO:root:Epoch:193 Global Model Test Loss:0.49210407804040346 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:193 Global Model Backdoor Test Loss:0.4333811899026235                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 194 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 194 Workers Selected : [321, 1229, 315, 1652, 1339, 834, 150, 448, 650, 1218]
INFO:root:FL Epoch: 194 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 194 Num points on workers: [201 200 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 194 Training on worker :321
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.349725
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.459580
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 194 Norm Difference for worker 321 is 0.949568
INFO:root:FL Epoch: 194 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1229
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1229 Train Epoch: 0 [0/200 (0%)]	Loss: 0.713015
INFO:root:Worker: 1229 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492444
INFO:root:FL Epoch: 194 Norm Difference for worker 1229 is 0.918014
INFO:root:FL Epoch: 194 Done on worker:1229
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :315
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.569572
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.788045
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 194 Norm Difference for worker 315 is 0.908966
INFO:root:FL Epoch: 194 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1652
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410162
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529174
INFO:root:FL Epoch: 194 Norm Difference for worker 1652 is 0.912177
INFO:root:FL Epoch: 194 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1339
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1339 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554915
INFO:root:Worker: 1339 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464457
INFO:root:FL Epoch: 194 Norm Difference for worker 1339 is 0.908503
INFO:root:FL Epoch: 194 Done on worker:1339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :834
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558231
INFO:root:Worker: 834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682247
INFO:root:FL Epoch: 194 Norm Difference for worker 834 is 0.910484
INFO:root:FL Epoch: 194 Done on worker:834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :150
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 150 Train Epoch: 0 [0/201 (0%)]	Loss: 0.529429
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 150 Train Epoch: 1 [0/201 (0%)]	Loss: 0.417980
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 194 Norm Difference for worker 150 is 0.951819
INFO:root:FL Epoch: 194 Done on worker:150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :448
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537724
INFO:root:Worker: 448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577351
INFO:root:FL Epoch: 194 Norm Difference for worker 448 is 0.864333
INFO:root:FL Epoch: 194 Done on worker:448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :650
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566738
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588376
INFO:root:FL Epoch: 194 Norm Difference for worker 650 is 0.926557
INFO:root:FL Epoch: 194 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 194 Training on worker :1218
INFO:root:FL Epoch: 194 Using Learning rate : 0.03397539173234472 
INFO:root:FL Epoch: 194 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615011
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488059
INFO:root:FL Epoch: 194 Norm Difference for worker 1218 is 0.946911
INFO:root:FL Epoch: 194 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 448
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 194 Ends   ===================
INFO:root:Epoch:194 Global Model Test Loss:0.49935564574073343 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:194 Global Model Backdoor Test Loss:0.47290301819642383                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 195 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 195 Workers Selected : [617, 318, 431, 448, 881, 1109, 472, 639, 1209, 703]
INFO:root:FL Epoch: 195 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 195 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 195 Training on worker :617
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633374
INFO:root:Worker: 617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419549
INFO:root:FL Epoch: 195 Norm Difference for worker 617 is 0.973349
INFO:root:FL Epoch: 195 Done on worker:617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :318
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.635335
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.424886
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 195 Norm Difference for worker 318 is 0.887536
INFO:root:FL Epoch: 195 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :431
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581231
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417151
INFO:root:FL Epoch: 195 Norm Difference for worker 431 is 0.924725
INFO:root:FL Epoch: 195 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :448
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422336
INFO:root:Worker: 448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567505
INFO:root:FL Epoch: 195 Norm Difference for worker 448 is 0.783584
INFO:root:FL Epoch: 195 Done on worker:448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :881
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401333
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459066
INFO:root:FL Epoch: 195 Norm Difference for worker 881 is 0.947014
INFO:root:FL Epoch: 195 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :1109
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 1109 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495573
INFO:root:Worker: 1109 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427621
INFO:root:FL Epoch: 195 Norm Difference for worker 1109 is 0.870895
INFO:root:FL Epoch: 195 Done on worker:1109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :472
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674367
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387208
INFO:root:FL Epoch: 195 Norm Difference for worker 472 is 0.917759
INFO:root:FL Epoch: 195 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :639
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653857
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493612
INFO:root:FL Epoch: 195 Norm Difference for worker 639 is 0.892781
INFO:root:FL Epoch: 195 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :1209
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 1209 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594879
INFO:root:Worker: 1209 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497751
INFO:root:FL Epoch: 195 Norm Difference for worker 1209 is 0.909306
INFO:root:FL Epoch: 195 Done on worker:1209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 195 Training on worker :703
INFO:root:FL Epoch: 195 Using Learning rate : 0.03390744094888003 
INFO:root:FL Epoch: 195 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480389
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607321
INFO:root:FL Epoch: 195 Norm Difference for worker 703 is 0.925362
INFO:root:FL Epoch: 195 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 448
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 195 Ends   ===================
INFO:root:Epoch:195 Global Model Test Loss:0.48749741298310895 and Test Accuracy:75.0 
INFO:root:Epoch:195 Global Model Backdoor Test Loss:0.4703512241442998                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 196 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 196 Workers Selected : [845, 1016, 1464, 84, 564, 253, 1499, 830, 1654, 1787]
INFO:root:FL Epoch: 196 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 196 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 196 Training on worker :845
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649055
INFO:root:Worker: 845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533941
INFO:root:FL Epoch: 196 Norm Difference for worker 845 is 1.190219
INFO:root:FL Epoch: 196 Done on worker:845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1016
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612676
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526765
INFO:root:FL Epoch: 196 Norm Difference for worker 1016 is 1.174722
INFO:root:FL Epoch: 196 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1464
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403803
INFO:root:Worker: 1464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372304
INFO:root:FL Epoch: 196 Norm Difference for worker 1464 is 1.133574
INFO:root:FL Epoch: 196 Done on worker:1464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :84
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 84 Train Epoch: 0 [0/201 (0%)]	Loss: 0.695120
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 84 Train Epoch: 1 [0/201 (0%)]	Loss: 0.404521
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 196 Norm Difference for worker 84 is 1.174791
INFO:root:FL Epoch: 196 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :564
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431234
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564161
INFO:root:FL Epoch: 196 Norm Difference for worker 564 is 1.1839
INFO:root:FL Epoch: 196 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :253
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 253 Train Epoch: 0 [0/201 (0%)]	Loss: 0.262571
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 253 Train Epoch: 1 [0/201 (0%)]	Loss: 0.484621
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 196 Norm Difference for worker 253 is 1.15241
INFO:root:FL Epoch: 196 Done on worker:253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1499
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778989
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455392
INFO:root:FL Epoch: 196 Norm Difference for worker 1499 is 1.173292
INFO:root:FL Epoch: 196 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :830
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436368
INFO:root:Worker: 830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470162
INFO:root:FL Epoch: 196 Norm Difference for worker 830 is 1.158677
INFO:root:FL Epoch: 196 Done on worker:830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1654
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537780
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615898
INFO:root:FL Epoch: 196 Norm Difference for worker 1654 is 1.164682
INFO:root:FL Epoch: 196 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 196 Training on worker :1787
INFO:root:FL Epoch: 196 Using Learning rate : 0.033839626066982265 
INFO:root:FL Epoch: 196 Normal Training
INFO:root:Worker: 1787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578290
INFO:root:Worker: 1787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437865
INFO:root:FL Epoch: 196 Norm Difference for worker 1787 is 1.112224
INFO:root:FL Epoch: 196 Done on worker:1787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1787
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 196 Ends   ===================
INFO:root:Epoch:196 Global Model Test Loss:0.48934028955066905 and Test Accuracy:75.0 
INFO:root:Epoch:196 Global Model Backdoor Test Loss:0.5489111791054407                             and Backdoor Test Accuracy:76.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 197 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 197 Workers Selected : [1309, 1133, 1254, 1673, 364, 1942, 685, 1660, 1463, 436]
INFO:root:FL Epoch: 197 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 197 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 197 Training on worker :1309
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1309 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497725
INFO:root:Worker: 1309 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502975
INFO:root:FL Epoch: 197 Norm Difference for worker 1309 is 1.023491
INFO:root:FL Epoch: 197 Done on worker:1309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1133
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1133 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549182
INFO:root:Worker: 1133 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564915
INFO:root:FL Epoch: 197 Norm Difference for worker 1133 is 1.096308
INFO:root:FL Epoch: 197 Done on worker:1133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1254
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1254 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635359
INFO:root:Worker: 1254 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526054
INFO:root:FL Epoch: 197 Norm Difference for worker 1254 is 1.037558
INFO:root:FL Epoch: 197 Done on worker:1254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1673
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.824191
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578314
INFO:root:FL Epoch: 197 Norm Difference for worker 1673 is 1.049756
INFO:root:FL Epoch: 197 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :364
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.673441
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557219
INFO:root:FL Epoch: 197 Norm Difference for worker 364 is 1.104958
INFO:root:FL Epoch: 197 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1942
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709917
INFO:root:Worker: 1942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418179
INFO:root:FL Epoch: 197 Norm Difference for worker 1942 is 1.102171
INFO:root:FL Epoch: 197 Done on worker:1942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :685
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477387
INFO:root:Worker: 685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491978
INFO:root:FL Epoch: 197 Norm Difference for worker 685 is 1.071574
INFO:root:FL Epoch: 197 Done on worker:685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1660
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436255
INFO:root:Worker: 1660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323643
INFO:root:FL Epoch: 197 Norm Difference for worker 1660 is 1.021366
INFO:root:FL Epoch: 197 Done on worker:1660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :1463
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558315
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535414
INFO:root:FL Epoch: 197 Norm Difference for worker 1463 is 1.184731
INFO:root:FL Epoch: 197 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 197 Training on worker :436
INFO:root:FL Epoch: 197 Using Learning rate : 0.033771946814848304 
INFO:root:FL Epoch: 197 Normal Training
INFO:root:Worker: 436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516856
INFO:root:Worker: 436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579221
INFO:root:FL Epoch: 197 Norm Difference for worker 436 is 1.025668
INFO:root:FL Epoch: 197 Done on worker:436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1660
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 197 Ends   ===================
INFO:root:Epoch:197 Global Model Test Loss:0.4884059323984034 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:197 Global Model Backdoor Test Loss:0.4654575188954671                             and Backdoor Test Accuracy:80.0 
INFO:root:=======================================================
INFO:root:================FL round 198 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 198 Workers Selected : [842, 787, 125, 204, 231, 293, 419, 770, 397, 1052]
INFO:root:FL Epoch: 198 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.1002994 0.1002994 0.1002994 0.0998004
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 198 Num points on workers: [200 200 201 201 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 198 Training on worker :842
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 842 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518492
INFO:root:Worker: 842 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485521
INFO:root:FL Epoch: 198 Norm Difference for worker 842 is 1.019156
INFO:root:FL Epoch: 198 Done on worker:842
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :787
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775576
INFO:root:Worker: 787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532996
INFO:root:FL Epoch: 198 Norm Difference for worker 787 is 1.098208
INFO:root:FL Epoch: 198 Done on worker:787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :125
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 125 Train Epoch: 0 [0/201 (0%)]	Loss: 0.638326
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 125 Train Epoch: 1 [0/201 (0%)]	Loss: 0.418434
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 198 Norm Difference for worker 125 is 1.032121
INFO:root:FL Epoch: 198 Done on worker:125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :204
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.594271
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.858368
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 198 Norm Difference for worker 204 is 1.071204
INFO:root:FL Epoch: 198 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :231
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 231 Train Epoch: 0 [0/201 (0%)]	Loss: 0.246888
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 231 Train Epoch: 1 [0/201 (0%)]	Loss: 0.249297
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 198 Norm Difference for worker 231 is 0.901656
INFO:root:FL Epoch: 198 Done on worker:231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :293
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 293 Train Epoch: 0 [0/201 (0%)]	Loss: 0.375564
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 293 Train Epoch: 1 [0/201 (0%)]	Loss: 0.434259
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 198 Norm Difference for worker 293 is 1.006691
INFO:root:FL Epoch: 198 Done on worker:293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :419
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557751
INFO:root:Worker: 419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586758
INFO:root:FL Epoch: 198 Norm Difference for worker 419 is 0.973083
INFO:root:FL Epoch: 198 Done on worker:419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :770
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551311
INFO:root:Worker: 770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521942
INFO:root:FL Epoch: 198 Norm Difference for worker 770 is 1.077517
INFO:root:FL Epoch: 198 Done on worker:770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :397
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664812
INFO:root:Worker: 397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528855
INFO:root:FL Epoch: 198 Norm Difference for worker 397 is 1.094007
INFO:root:FL Epoch: 198 Done on worker:397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 198 Training on worker :1052
INFO:root:FL Epoch: 198 Using Learning rate : 0.03370440292121861 
INFO:root:FL Epoch: 198 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608120
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469121
INFO:root:FL Epoch: 198 Norm Difference for worker 1052 is 1.01672
INFO:root:FL Epoch: 198 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 231
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 198 Ends   ===================
INFO:root:Epoch:198 Global Model Test Loss:0.47950678099604216 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:198 Global Model Backdoor Test Loss:0.39288536707560223                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 199 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 199 Workers Selected : [913, 870, 912, 1774, 844, 1428, 1445, 1451, 881, 1753]
INFO:root:FL Epoch: 199 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 199 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 199 Training on worker :913
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582872
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651838
INFO:root:FL Epoch: 199 Norm Difference for worker 913 is 1.587157
INFO:root:FL Epoch: 199 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :870
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 870 Train Epoch: 0 [0/200 (0%)]	Loss: 1.096595
INFO:root:Worker: 870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380304
INFO:root:FL Epoch: 199 Norm Difference for worker 870 is 1.568797
INFO:root:FL Epoch: 199 Done on worker:870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :912
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734996
INFO:root:Worker: 912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367548
INFO:root:FL Epoch: 199 Norm Difference for worker 912 is 1.492195
INFO:root:FL Epoch: 199 Done on worker:912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1774
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575297
INFO:root:Worker: 1774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473861
INFO:root:FL Epoch: 199 Norm Difference for worker 1774 is 1.265722
INFO:root:FL Epoch: 199 Done on worker:1774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :844
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738920
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589790
INFO:root:FL Epoch: 199 Norm Difference for worker 844 is 1.354686
INFO:root:FL Epoch: 199 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1428
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 1.003136
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477493
INFO:root:FL Epoch: 199 Norm Difference for worker 1428 is 1.528122
INFO:root:FL Epoch: 199 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1445
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735690
INFO:root:Worker: 1445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356945
INFO:root:FL Epoch: 199 Norm Difference for worker 1445 is 1.496363
INFO:root:FL Epoch: 199 Done on worker:1445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1451
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340485
INFO:root:Worker: 1451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373195
INFO:root:FL Epoch: 199 Norm Difference for worker 1451 is 1.430881
INFO:root:FL Epoch: 199 Done on worker:1451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :881
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.151280
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.154512
INFO:root:FL Epoch: 199 Norm Difference for worker 881 is 0.991993
INFO:root:FL Epoch: 199 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 199 Training on worker :1753
INFO:root:FL Epoch: 199 Using Learning rate : 0.03363699411537617 
INFO:root:FL Epoch: 199 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664980
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291339
INFO:root:FL Epoch: 199 Norm Difference for worker 1753 is 1.213364
INFO:root:FL Epoch: 199 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 881
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 199 Ends   ===================
INFO:root:Epoch:199 Global Model Test Loss:0.5129056984887403 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:199 Global Model Backdoor Test Loss:0.4891163806120555                             and Backdoor Test Accuracy:75.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 200 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 200 Workers Selected : [819, 826, 1484, 701, 1698, 763, 1089, 214, 1866, 1460]
INFO:root:FL Epoch: 200 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 200 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 200 Training on worker :819
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 819 Train Epoch: 0 [0/200 (0%)]	Loss: 0.928149
INFO:root:Worker: 819 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580085
INFO:root:FL Epoch: 200 Norm Difference for worker 819 is 1.573299
INFO:root:FL Epoch: 200 Done on worker:819
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :826
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.271235
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537050
INFO:root:FL Epoch: 200 Norm Difference for worker 826 is 1.679392
INFO:root:FL Epoch: 200 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1484
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690516
INFO:root:Worker: 1484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.780377
INFO:root:FL Epoch: 200 Norm Difference for worker 1484 is 1.626779
INFO:root:FL Epoch: 200 Done on worker:1484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :701
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580905
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472562
INFO:root:FL Epoch: 200 Norm Difference for worker 701 is 1.631126
INFO:root:FL Epoch: 200 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1698
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691104
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610645
INFO:root:FL Epoch: 200 Norm Difference for worker 1698 is 1.694344
INFO:root:FL Epoch: 200 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :763
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431021
INFO:root:Worker: 763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.675531
INFO:root:FL Epoch: 200 Norm Difference for worker 763 is 1.748621
INFO:root:FL Epoch: 200 Done on worker:763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1089
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1089 Train Epoch: 0 [0/200 (0%)]	Loss: 0.873565
INFO:root:Worker: 1089 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419572
INFO:root:FL Epoch: 200 Norm Difference for worker 1089 is 1.538156
INFO:root:FL Epoch: 200 Done on worker:1089
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :214
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 214 Train Epoch: 0 [0/201 (0%)]	Loss: 0.860325
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 214 Train Epoch: 1 [0/201 (0%)]	Loss: 0.416225
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 200 Norm Difference for worker 214 is 1.692581
INFO:root:FL Epoch: 200 Done on worker:214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1866
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430653
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390306
INFO:root:FL Epoch: 200 Norm Difference for worker 1866 is 1.504298
INFO:root:FL Epoch: 200 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 200 Training on worker :1460
INFO:root:FL Epoch: 200 Using Learning rate : 0.03356972012714542 
INFO:root:FL Epoch: 200 Normal Training
INFO:root:Worker: 1460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758237
INFO:root:Worker: 1460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419375
INFO:root:FL Epoch: 200 Norm Difference for worker 1460 is 1.458514
INFO:root:FL Epoch: 200 Done on worker:1460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1460
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 200 Ends   ===================
INFO:root:Epoch:200 Global Model Test Loss:0.49585432340117064 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:200 Global Model Backdoor Test Loss:0.4109609971443812                             and Backdoor Test Accuracy:82.5 
INFO:root:=======================================================
INFO:root:================FL round 201 Begins ===================
INFO:root:FL Epoch: 201 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 201 Workers Selected : [0, 430, 1591, 1204, 550, 1376, 13, 1342, 989, 1929]
INFO:root:FL Epoch: 201 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 201 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 201 Training on worker :0
INFO:root:FL Epoch: 201 Using Learning rate : 0.006700516137378225 
INFO:root:FL Epoch: 201 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381193
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325928
INFO:root:FL Epoch: 201 Worker: 0 Backdoor Test Loss: 0.2948054373264313 Backdoor Test Accuracy: 90.83333333333333
INFO:root:FL Epoch: 201 Worker: 0 Backdoor Train Loss: 0.29764086902141573 Backdoor Train Accuracy: 90.0
INFO:root:FL Epoch: 201 Norm Difference for worker 0 is 0.270425
INFO:root:FL Epoch: 201 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :430
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363085
INFO:root:Worker: 430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615320
INFO:root:FL Epoch: 201 Norm Difference for worker 430 is 1.358801
INFO:root:FL Epoch: 201 Done on worker:430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1591
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406905
INFO:root:Worker: 1591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403526
INFO:root:FL Epoch: 201 Norm Difference for worker 1591 is 1.322642
INFO:root:FL Epoch: 201 Done on worker:1591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1204
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594753
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483476
INFO:root:FL Epoch: 201 Norm Difference for worker 1204 is 1.337633
INFO:root:FL Epoch: 201 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :550
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460040
INFO:root:Worker: 550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503600
INFO:root:FL Epoch: 201 Norm Difference for worker 550 is 1.229867
INFO:root:FL Epoch: 201 Done on worker:550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1376
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596823
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353646
INFO:root:FL Epoch: 201 Norm Difference for worker 1376 is 1.256986
INFO:root:FL Epoch: 201 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :13
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 13 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629483
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 13 Train Epoch: 1 [0/201 (0%)]	Loss: 0.650555
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 201 Norm Difference for worker 13 is 1.257863
INFO:root:FL Epoch: 201 Done on worker:13
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1342
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734955
INFO:root:Worker: 1342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399062
INFO:root:FL Epoch: 201 Norm Difference for worker 1342 is 1.208235
INFO:root:FL Epoch: 201 Done on worker:1342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :989
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 989 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803580
INFO:root:Worker: 989 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447192
INFO:root:FL Epoch: 201 Norm Difference for worker 989 is 1.308767
INFO:root:FL Epoch: 201 Done on worker:989
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 201 Training on worker :1929
INFO:root:FL Epoch: 201 Using Learning rate : 0.033502580686891124 
INFO:root:FL Epoch: 201 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.318090
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501757
INFO:root:FL Epoch: 201 Norm Difference for worker 1929 is 1.216189
INFO:root:FL Epoch: 201 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 201 Ends   ===================
INFO:root:Epoch:201 Global Model Test Loss:0.49338148096028495 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:201 Global Model Backdoor Test Loss:0.2948054373264313                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 202 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 202 Workers Selected : [228, 63, 1185, 217, 46, 1390, 1242, 1500, 222, 1611]
INFO:root:FL Epoch: 202 Fraction of points on each worker in this round: [0.10024938 0.10024938 0.09975062 0.10024938 0.10024938 0.09975062
 0.09975062 0.09975062 0.10024938 0.09975062]
INFO:root:FL Epoch: 202 Num points on workers: [201 201 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 202 Training on worker :228
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 228 Train Epoch: 0 [0/201 (0%)]	Loss: 0.406083
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 228 Train Epoch: 1 [0/201 (0%)]	Loss: 0.258753
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 228 is 1.257775
INFO:root:FL Epoch: 202 Done on worker:228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :63
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 63 Train Epoch: 0 [0/201 (0%)]	Loss: 0.446188
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 63 Train Epoch: 1 [0/201 (0%)]	Loss: 0.439654
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 63 is 1.359616
INFO:root:FL Epoch: 202 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1185
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1185 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509261
INFO:root:Worker: 1185 Train Epoch: 1 [0/200 (0%)]	Loss: 0.742462
INFO:root:FL Epoch: 202 Norm Difference for worker 1185 is 1.388977
INFO:root:FL Epoch: 202 Done on worker:1185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :217
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 217 Train Epoch: 0 [0/201 (0%)]	Loss: 0.813248
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 217 Train Epoch: 1 [0/201 (0%)]	Loss: 0.190840
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 217 is 1.313706
INFO:root:FL Epoch: 202 Done on worker:217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :46
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.459053
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.425469
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 46 is 1.283034
INFO:root:FL Epoch: 202 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1390
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399246
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243561
INFO:root:FL Epoch: 202 Norm Difference for worker 1390 is 1.36809
INFO:root:FL Epoch: 202 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1242
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740092
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538028
INFO:root:FL Epoch: 202 Norm Difference for worker 1242 is 1.290848
INFO:root:FL Epoch: 202 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1500
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621663
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490072
INFO:root:FL Epoch: 202 Norm Difference for worker 1500 is 1.31417
INFO:root:FL Epoch: 202 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :222
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.366146
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.348713
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 202 Norm Difference for worker 222 is 1.172476
INFO:root:FL Epoch: 202 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 202 Training on worker :1611
INFO:root:FL Epoch: 202 Using Learning rate : 0.03343557552551734 
INFO:root:FL Epoch: 202 Normal Training
INFO:root:Worker: 1611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431809
INFO:root:Worker: 1611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345782
INFO:root:FL Epoch: 202 Norm Difference for worker 1611 is 1.324124
INFO:root:FL Epoch: 202 Done on worker:1611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 222
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 202 Ends   ===================
INFO:root:Epoch:202 Global Model Test Loss:0.5511335826971951 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:202 Global Model Backdoor Test Loss:0.2951137647032738                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 203 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 203 Workers Selected : [1931, 1445, 1591, 1204, 659, 1551, 1020, 143, 496, 149]
INFO:root:FL Epoch: 203 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.1003996]
INFO:root:FL Epoch: 203 Num points on workers: [200 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 203 Training on worker :1931
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.219535
INFO:root:Worker: 1931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387811
INFO:root:FL Epoch: 203 Norm Difference for worker 1931 is 1.667529
INFO:root:FL Epoch: 203 Done on worker:1931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1445
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.832484
INFO:root:Worker: 1445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472467
INFO:root:FL Epoch: 203 Norm Difference for worker 1445 is 1.753809
INFO:root:FL Epoch: 203 Done on worker:1445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1591
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569282
INFO:root:Worker: 1591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612576
INFO:root:FL Epoch: 203 Norm Difference for worker 1591 is 1.593135
INFO:root:FL Epoch: 203 Done on worker:1591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1204
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.981396
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.997093
INFO:root:FL Epoch: 203 Norm Difference for worker 1204 is 1.779703
INFO:root:FL Epoch: 203 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :659
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558683
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 1.109335
INFO:root:FL Epoch: 203 Norm Difference for worker 659 is 1.774575
INFO:root:FL Epoch: 203 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1551
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.826923
INFO:root:Worker: 1551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324805
INFO:root:FL Epoch: 203 Norm Difference for worker 1551 is 1.528396
INFO:root:FL Epoch: 203 Done on worker:1551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :1020
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 1020 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531498
INFO:root:Worker: 1020 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333338
INFO:root:FL Epoch: 203 Norm Difference for worker 1020 is 1.757703
INFO:root:FL Epoch: 203 Done on worker:1020
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :143
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 143 Train Epoch: 0 [0/201 (0%)]	Loss: 0.601560
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 143 Train Epoch: 1 [0/201 (0%)]	Loss: 0.407257
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 203 Norm Difference for worker 143 is 1.630505
INFO:root:FL Epoch: 203 Done on worker:143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :496
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.942207
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331609
INFO:root:FL Epoch: 203 Norm Difference for worker 496 is 1.601452
INFO:root:FL Epoch: 203 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 203 Training on worker :149
INFO:root:FL Epoch: 203 Using Learning rate : 0.03336870437446631 
INFO:root:FL Epoch: 203 Normal Training
INFO:root:Worker: 149 Train Epoch: 0 [0/201 (0%)]	Loss: 0.399659
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 149 Train Epoch: 1 [0/201 (0%)]	Loss: 0.463358
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 203 Norm Difference for worker 149 is 1.609057
INFO:root:FL Epoch: 203 Done on worker:149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 496
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 203 Ends   ===================
INFO:root:Epoch:203 Global Model Test Loss:0.5116413884303149 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:203 Global Model Backdoor Test Loss:0.39646489918231964                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 204 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 204 Workers Selected : [1199, 1247, 793, 1840, 1242, 1130, 355, 1325, 417, 66]
INFO:root:FL Epoch: 204 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 204 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 204 Training on worker :1199
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611370
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541971
INFO:root:FL Epoch: 204 Norm Difference for worker 1199 is 1.162996
INFO:root:FL Epoch: 204 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1247
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631153
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712412
INFO:root:FL Epoch: 204 Norm Difference for worker 1247 is 1.19995
INFO:root:FL Epoch: 204 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :793
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489406
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382953
INFO:root:FL Epoch: 204 Norm Difference for worker 793 is 1.179763
INFO:root:FL Epoch: 204 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1840
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638077
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502125
INFO:root:FL Epoch: 204 Norm Difference for worker 1840 is 1.158388
INFO:root:FL Epoch: 204 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1242
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.777752
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336481
INFO:root:FL Epoch: 204 Norm Difference for worker 1242 is 1.114679
INFO:root:FL Epoch: 204 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1130
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1130 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434599
INFO:root:Worker: 1130 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441717
INFO:root:FL Epoch: 204 Norm Difference for worker 1130 is 1.308327
INFO:root:FL Epoch: 204 Done on worker:1130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :355
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523545
INFO:root:Worker: 355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650385
INFO:root:FL Epoch: 204 Norm Difference for worker 355 is 1.159371
INFO:root:FL Epoch: 204 Done on worker:355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :1325
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 1325 Train Epoch: 0 [0/200 (0%)]	Loss: 0.791034
INFO:root:Worker: 1325 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411849
INFO:root:FL Epoch: 204 Norm Difference for worker 1325 is 1.220139
INFO:root:FL Epoch: 204 Done on worker:1325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :417
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598871
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506052
INFO:root:FL Epoch: 204 Norm Difference for worker 417 is 1.163404
INFO:root:FL Epoch: 204 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 204 Training on worker :66
INFO:root:FL Epoch: 204 Using Learning rate : 0.033301966965717376 
INFO:root:FL Epoch: 204 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.610882
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.389910
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 204 Norm Difference for worker 66 is 1.173459
INFO:root:FL Epoch: 204 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1242
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 204 Ends   ===================
INFO:root:Epoch:204 Global Model Test Loss:0.5208864089320687 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:204 Global Model Backdoor Test Loss:0.4285905063152313                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 205 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 205 Workers Selected : [1885, 524, 171, 743, 3, 1407, 231, 431, 57, 1021]
INFO:root:FL Epoch: 205 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.1002994 0.0998004 0.1002994
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 205 Num points on workers: [200 200 201 200 201 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 205 Training on worker :1885
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453666
INFO:root:Worker: 1885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475699
INFO:root:FL Epoch: 205 Norm Difference for worker 1885 is 1.039438
INFO:root:FL Epoch: 205 Done on worker:1885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :524
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349050
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511204
INFO:root:FL Epoch: 205 Norm Difference for worker 524 is 1.006878
INFO:root:FL Epoch: 205 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :171
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.523344
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.332027
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 171 is 1.034831
INFO:root:FL Epoch: 205 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :743
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376831
INFO:root:Worker: 743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411889
INFO:root:FL Epoch: 205 Norm Difference for worker 743 is 1.059868
INFO:root:FL Epoch: 205 Done on worker:743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :3
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.344580
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.666722
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 3 is 1.096172
INFO:root:FL Epoch: 205 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1407
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417754
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364597
INFO:root:FL Epoch: 205 Norm Difference for worker 1407 is 1.084518
INFO:root:FL Epoch: 205 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :231
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 231 Train Epoch: 0 [0/201 (0%)]	Loss: 0.216536
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 231 Train Epoch: 1 [0/201 (0%)]	Loss: 0.399617
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 231 is 0.94498
INFO:root:FL Epoch: 205 Done on worker:231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :431
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526628
INFO:root:Worker: 431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387208
INFO:root:FL Epoch: 205 Norm Difference for worker 431 is 1.00721
INFO:root:FL Epoch: 205 Done on worker:431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :57
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 57 Train Epoch: 0 [0/201 (0%)]	Loss: 0.412624
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 57 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415923
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 205 Norm Difference for worker 57 is 1.041995
INFO:root:FL Epoch: 205 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 205 Training on worker :1021
INFO:root:FL Epoch: 205 Using Learning rate : 0.033235363031785946 
INFO:root:FL Epoch: 205 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574236
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503309
INFO:root:FL Epoch: 205 Norm Difference for worker 1021 is 1.029356
INFO:root:FL Epoch: 205 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 231
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 205 Ends   ===================
INFO:root:Epoch:205 Global Model Test Loss:0.5225254016764024 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:205 Global Model Backdoor Test Loss:0.26118815193573636                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 206 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 206 Workers Selected : [982, 838, 1325, 1699, 1536, 1723, 1578, 459, 1517, 555]
INFO:root:FL Epoch: 206 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 206 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 206 Training on worker :982
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564235
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387714
INFO:root:FL Epoch: 206 Norm Difference for worker 982 is 1.447123
INFO:root:FL Epoch: 206 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :838
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 1.395845
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402206
INFO:root:FL Epoch: 206 Norm Difference for worker 838 is 1.509195
INFO:root:FL Epoch: 206 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1325
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1325 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633106
INFO:root:Worker: 1325 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643417
INFO:root:FL Epoch: 206 Norm Difference for worker 1325 is 1.496777
INFO:root:FL Epoch: 206 Done on worker:1325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1699
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1699 Train Epoch: 0 [0/200 (0%)]	Loss: 0.960765
INFO:root:Worker: 1699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309810
INFO:root:FL Epoch: 206 Norm Difference for worker 1699 is 1.530849
INFO:root:FL Epoch: 206 Done on worker:1699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1536
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314661
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266695
INFO:root:FL Epoch: 206 Norm Difference for worker 1536 is 1.461369
INFO:root:FL Epoch: 206 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1723
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550896
INFO:root:Worker: 1723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548273
INFO:root:FL Epoch: 206 Norm Difference for worker 1723 is 1.437729
INFO:root:FL Epoch: 206 Done on worker:1723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1578
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687236
INFO:root:Worker: 1578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538052
INFO:root:FL Epoch: 206 Norm Difference for worker 1578 is 1.230894
INFO:root:FL Epoch: 206 Done on worker:1578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :459
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623713
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472827
INFO:root:FL Epoch: 206 Norm Difference for worker 459 is 1.42335
INFO:root:FL Epoch: 206 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :1517
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.859376
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483961
INFO:root:FL Epoch: 206 Norm Difference for worker 1517 is 1.464342
INFO:root:FL Epoch: 206 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 206 Training on worker :555
INFO:root:FL Epoch: 206 Using Learning rate : 0.03316889230572237 
INFO:root:FL Epoch: 206 Normal Training
INFO:root:Worker: 555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794320
INFO:root:Worker: 555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353757
INFO:root:FL Epoch: 206 Norm Difference for worker 555 is 1.354418
INFO:root:FL Epoch: 206 Done on worker:555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1578
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 206 Ends   ===================
INFO:root:Epoch:206 Global Model Test Loss:0.5316295781556297 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:206 Global Model Backdoor Test Loss:0.38968925674756366                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 207 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 207 Workers Selected : [1024, 1479, 1906, 856, 1319, 693, 140, 527, 1531, 394]
INFO:root:FL Epoch: 207 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 207 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 207 Training on worker :1024
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.793777
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512565
INFO:root:FL Epoch: 207 Norm Difference for worker 1024 is 1.249848
INFO:root:FL Epoch: 207 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1479
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1479 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357125
INFO:root:Worker: 1479 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502832
INFO:root:FL Epoch: 207 Norm Difference for worker 1479 is 1.285109
INFO:root:FL Epoch: 207 Done on worker:1479
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1906
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.282659
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324992
INFO:root:FL Epoch: 207 Norm Difference for worker 1906 is 1.194355
INFO:root:FL Epoch: 207 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :856
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.897060
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411121
INFO:root:FL Epoch: 207 Norm Difference for worker 856 is 1.371972
INFO:root:FL Epoch: 207 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1319
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656094
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688935
INFO:root:FL Epoch: 207 Norm Difference for worker 1319 is 1.330338
INFO:root:FL Epoch: 207 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :693
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549603
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516846
INFO:root:FL Epoch: 207 Norm Difference for worker 693 is 1.208219
INFO:root:FL Epoch: 207 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :140
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 140 Train Epoch: 0 [0/201 (0%)]	Loss: 0.591264
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 140 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488970
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 207 Norm Difference for worker 140 is 1.302524
INFO:root:FL Epoch: 207 Done on worker:140
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :527
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679754
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518680
INFO:root:FL Epoch: 207 Norm Difference for worker 527 is 1.213091
INFO:root:FL Epoch: 207 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :1531
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.820517
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586676
INFO:root:FL Epoch: 207 Norm Difference for worker 1531 is 1.360351
INFO:root:FL Epoch: 207 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 207 Training on worker :394
INFO:root:FL Epoch: 207 Using Learning rate : 0.033102554521110925 
INFO:root:FL Epoch: 207 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.842606
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443175
INFO:root:FL Epoch: 207 Norm Difference for worker 394 is 1.302517
INFO:root:FL Epoch: 207 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 693
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 207 Ends   ===================
INFO:root:Epoch:207 Global Model Test Loss:0.5425354873432833 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:207 Global Model Backdoor Test Loss:0.4717347671588262                             and Backdoor Test Accuracy:79.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 208 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 208 Workers Selected : [1071, 265, 40, 783, 244, 310, 1634, 1042, 1666, 462]
INFO:root:FL Epoch: 208 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.1002994 0.0998004 0.1002994 0.1002994 0.0998004
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 208 Num points on workers: [200 201 201 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 208 Training on worker :1071
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1071 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775042
INFO:root:Worker: 1071 Train Epoch: 1 [0/200 (0%)]	Loss: 0.623780
INFO:root:FL Epoch: 208 Norm Difference for worker 1071 is 1.172868
INFO:root:FL Epoch: 208 Done on worker:1071
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :265
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 265 Train Epoch: 0 [0/201 (0%)]	Loss: 0.924113
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 265 Train Epoch: 1 [0/201 (0%)]	Loss: 0.682456
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 208 Norm Difference for worker 265 is 1.216641
INFO:root:FL Epoch: 208 Done on worker:265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :40
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 40 Train Epoch: 0 [0/201 (0%)]	Loss: 0.394512
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 40 Train Epoch: 1 [0/201 (0%)]	Loss: 0.639415
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 208 Norm Difference for worker 40 is 1.187101
INFO:root:FL Epoch: 208 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :783
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.908408
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607161
INFO:root:FL Epoch: 208 Norm Difference for worker 783 is 1.174081
INFO:root:FL Epoch: 208 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :244
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 244 Train Epoch: 0 [0/201 (0%)]	Loss: 0.632972
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 244 Train Epoch: 1 [0/201 (0%)]	Loss: 0.629576
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 208 Norm Difference for worker 244 is 1.120403
INFO:root:FL Epoch: 208 Done on worker:244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :310
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 310 Train Epoch: 0 [0/201 (0%)]	Loss: 0.667236
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 310 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538176
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 208 Norm Difference for worker 310 is 1.20611
INFO:root:FL Epoch: 208 Done on worker:310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1634
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738479
INFO:root:Worker: 1634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447402
INFO:root:FL Epoch: 208 Norm Difference for worker 1634 is 1.201003
INFO:root:FL Epoch: 208 Done on worker:1634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1042
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711561
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338950
INFO:root:FL Epoch: 208 Norm Difference for worker 1042 is 1.171192
INFO:root:FL Epoch: 208 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :1666
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 1666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644432
INFO:root:Worker: 1666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587827
INFO:root:FL Epoch: 208 Norm Difference for worker 1666 is 1.122382
INFO:root:FL Epoch: 208 Done on worker:1666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 208 Training on worker :462
INFO:root:FL Epoch: 208 Using Learning rate : 0.0330363494120687 
INFO:root:FL Epoch: 208 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686151
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550217
INFO:root:FL Epoch: 208 Norm Difference for worker 462 is 1.205054
INFO:root:FL Epoch: 208 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 244
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 208 Ends   ===================
INFO:root:Epoch:208 Global Model Test Loss:0.5430856329553267 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:208 Global Model Backdoor Test Loss:0.3617643713951111                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 209 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 209 Workers Selected : [307, 20, 991, 110, 278, 1633, 1786, 701, 1348, 329]
INFO:root:FL Epoch: 209 Fraction of points on each worker in this round: [0.10024938 0.10024938 0.09975062 0.10024938 0.10024938 0.09975062
 0.09975062 0.09975062 0.09975062 0.10024938]
INFO:root:FL Epoch: 209 Num points on workers: [201 201 200 201 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 209 Training on worker :307
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 307 Train Epoch: 0 [0/201 (0%)]	Loss: 0.608658
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 307 Train Epoch: 1 [0/201 (0%)]	Loss: 0.704718
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 307 is 1.117146
INFO:root:FL Epoch: 209 Done on worker:307
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :20
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 20 Train Epoch: 0 [0/201 (0%)]	Loss: 0.627243
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 20 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446118
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 20 is 1.030535
INFO:root:FL Epoch: 209 Done on worker:20
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :991
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 991 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497440
INFO:root:Worker: 991 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486336
INFO:root:FL Epoch: 209 Norm Difference for worker 991 is 1.034882
INFO:root:FL Epoch: 209 Done on worker:991
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :110
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 110 Train Epoch: 0 [0/201 (0%)]	Loss: 0.421528
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 110 Train Epoch: 1 [0/201 (0%)]	Loss: 0.379814
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 110 is 1.104379
INFO:root:FL Epoch: 209 Done on worker:110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :278
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.700903
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.720004
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 278 is 1.112664
INFO:root:FL Epoch: 209 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1633
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753708
INFO:root:Worker: 1633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670857
INFO:root:FL Epoch: 209 Norm Difference for worker 1633 is 1.08463
INFO:root:FL Epoch: 209 Done on worker:1633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1786
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499772
INFO:root:Worker: 1786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463413
INFO:root:FL Epoch: 209 Norm Difference for worker 1786 is 1.103394
INFO:root:FL Epoch: 209 Done on worker:1786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :701
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597455
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532574
INFO:root:FL Epoch: 209 Norm Difference for worker 701 is 1.068425
INFO:root:FL Epoch: 209 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :1348
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 1348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.959089
INFO:root:Worker: 1348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293478
INFO:root:FL Epoch: 209 Norm Difference for worker 1348 is 1.040753
INFO:root:FL Epoch: 209 Done on worker:1348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 209 Training on worker :329
INFO:root:FL Epoch: 209 Using Learning rate : 0.03297027671324456 
INFO:root:FL Epoch: 209 Normal Training
INFO:root:Worker: 329 Train Epoch: 0 [0/201 (0%)]	Loss: 0.647866
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 329 Train Epoch: 1 [0/201 (0%)]	Loss: 0.352919
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 209 Norm Difference for worker 329 is 1.022071
INFO:root:FL Epoch: 209 Done on worker:329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1348
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 209 Ends   ===================
INFO:root:Epoch:209 Global Model Test Loss:0.5331646151402417 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:209 Global Model Backdoor Test Loss:0.5759992400805155                             and Backdoor Test Accuracy:69.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 210 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 210 Workers Selected : [1204, 154, 1655, 1760, 595, 999, 1871, 200, 248, 1641]
INFO:root:FL Epoch: 210 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 210 Num points on workers: [200 201 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 210 Training on worker :1204
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436514
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494344
INFO:root:FL Epoch: 210 Norm Difference for worker 1204 is 1.04539
INFO:root:FL Epoch: 210 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :154
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 154 Train Epoch: 0 [0/201 (0%)]	Loss: 0.455833
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 154 Train Epoch: 1 [0/201 (0%)]	Loss: 0.574492
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 154 is 0.993872
INFO:root:FL Epoch: 210 Done on worker:154
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1655
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517766
INFO:root:Worker: 1655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417863
INFO:root:FL Epoch: 210 Norm Difference for worker 1655 is 1.090885
INFO:root:FL Epoch: 210 Done on worker:1655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1760
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510516
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469888
INFO:root:FL Epoch: 210 Norm Difference for worker 1760 is 1.168214
INFO:root:FL Epoch: 210 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :595
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728414
INFO:root:Worker: 595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493269
INFO:root:FL Epoch: 210 Norm Difference for worker 595 is 1.053073
INFO:root:FL Epoch: 210 Done on worker:595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :999
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598221
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354203
INFO:root:FL Epoch: 210 Norm Difference for worker 999 is 1.05218
INFO:root:FL Epoch: 210 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1871
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685771
INFO:root:Worker: 1871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352974
INFO:root:FL Epoch: 210 Norm Difference for worker 1871 is 1.068833
INFO:root:FL Epoch: 210 Done on worker:1871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :200
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 200 Train Epoch: 0 [0/201 (0%)]	Loss: 0.491569
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 200 Train Epoch: 1 [0/201 (0%)]	Loss: 0.419275
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 200 is 1.002213
INFO:root:FL Epoch: 210 Done on worker:200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :248
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.429755
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.613129
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 210 Norm Difference for worker 248 is 0.985866
INFO:root:FL Epoch: 210 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 210 Training on worker :1641
INFO:root:FL Epoch: 210 Using Learning rate : 0.032904336159818075 
INFO:root:FL Epoch: 210 Normal Training
INFO:root:Worker: 1641 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501936
INFO:root:Worker: 1641 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428543
INFO:root:FL Epoch: 210 Norm Difference for worker 1641 is 1.005615
INFO:root:FL Epoch: 210 Done on worker:1641
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 248
INFO:root:Norm of Aggregated Model: 5154.990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 210 Ends   ===================
INFO:root:Epoch:210 Global Model Test Loss:0.5253466946237227 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:210 Global Model Backdoor Test Loss:0.5917874823013941                             and Backdoor Test Accuracy:70.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 211 Begins ===================
INFO:root:FL Epoch: 211 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 211 Workers Selected : [0, 153, 580, 204, 80, 531, 769, 399, 1316, 923]
INFO:root:FL Epoch: 211 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 211 Num points on workers: [200 201 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 211 Training on worker :0
INFO:root:FL Epoch: 211 Using Learning rate : 0.006567705497499687 
INFO:root:FL Epoch: 211 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333447
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298794
INFO:root:FL Epoch: 211 Worker: 0 Backdoor Test Loss: 0.2835415005683899 Backdoor Test Accuracy: 90.83333333333333
INFO:root:FL Epoch: 211 Worker: 0 Backdoor Train Loss: 0.295796662569046 Backdoor Train Accuracy: 89.5
INFO:root:FL Epoch: 211 Norm Difference for worker 0 is 0.309374
INFO:root:FL Epoch: 211 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :153
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.242118
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.383658
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 211 Norm Difference for worker 153 is 0.926823
INFO:root:FL Epoch: 211 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :580
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494116
INFO:root:Worker: 580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437929
INFO:root:FL Epoch: 211 Norm Difference for worker 580 is 1.04259
INFO:root:FL Epoch: 211 Done on worker:580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :204
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.566370
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.712991
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 211 Norm Difference for worker 204 is 1.017321
INFO:root:FL Epoch: 211 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :80
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.625200
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.489892
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 211 Norm Difference for worker 80 is 0.999576
INFO:root:FL Epoch: 211 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :531
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.773810
INFO:root:Worker: 531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560020
INFO:root:FL Epoch: 211 Norm Difference for worker 531 is 0.973285
INFO:root:FL Epoch: 211 Done on worker:531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :769
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546034
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558422
INFO:root:FL Epoch: 211 Norm Difference for worker 769 is 1.054202
INFO:root:FL Epoch: 211 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :399
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589021
INFO:root:Worker: 399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370883
INFO:root:FL Epoch: 211 Norm Difference for worker 399 is 1.023433
INFO:root:FL Epoch: 211 Done on worker:399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :1316
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571992
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550954
INFO:root:FL Epoch: 211 Norm Difference for worker 1316 is 0.983927
INFO:root:FL Epoch: 211 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 211 Training on worker :923
INFO:root:FL Epoch: 211 Using Learning rate : 0.03283852748749844 
INFO:root:FL Epoch: 211 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697396
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434230
INFO:root:FL Epoch: 211 Norm Difference for worker 923 is 0.972005
INFO:root:FL Epoch: 211 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 211 Ends   ===================
INFO:root:Epoch:211 Global Model Test Loss:0.5171461824108573 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:211 Global Model Backdoor Test Loss:0.2835415005683899                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 212 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 212 Workers Selected : [806, 758, 1499, 509, 448, 1242, 1500, 1347, 1376, 1643]
INFO:root:FL Epoch: 212 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 212 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 212 Training on worker :806
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487600
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.610735
INFO:root:FL Epoch: 212 Norm Difference for worker 806 is 1.12223
INFO:root:FL Epoch: 212 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :758
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432651
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398103
INFO:root:FL Epoch: 212 Norm Difference for worker 758 is 1.018483
INFO:root:FL Epoch: 212 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1499
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571158
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505798
INFO:root:FL Epoch: 212 Norm Difference for worker 1499 is 1.03577
INFO:root:FL Epoch: 212 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :509
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.912304
INFO:root:Worker: 509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347598
INFO:root:FL Epoch: 212 Norm Difference for worker 509 is 1.121725
INFO:root:FL Epoch: 212 Done on worker:509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :448
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489701
INFO:root:Worker: 448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503751
INFO:root:FL Epoch: 212 Norm Difference for worker 448 is 0.969666
INFO:root:FL Epoch: 212 Done on worker:448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1242
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296801
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321685
INFO:root:FL Epoch: 212 Norm Difference for worker 1242 is 0.929692
INFO:root:FL Epoch: 212 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1500
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519719
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576196
INFO:root:FL Epoch: 212 Norm Difference for worker 1500 is 1.088096
INFO:root:FL Epoch: 212 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1347
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591918
INFO:root:Worker: 1347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638012
INFO:root:FL Epoch: 212 Norm Difference for worker 1347 is 1.142041
INFO:root:FL Epoch: 212 Done on worker:1347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1376
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463354
INFO:root:Worker: 1376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350410
INFO:root:FL Epoch: 212 Norm Difference for worker 1376 is 1.081169
INFO:root:FL Epoch: 212 Done on worker:1376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 212 Training on worker :1643
INFO:root:FL Epoch: 212 Using Learning rate : 0.03277285043252345 
INFO:root:FL Epoch: 212 Normal Training
INFO:root:Worker: 1643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647730
INFO:root:Worker: 1643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501884
INFO:root:FL Epoch: 212 Norm Difference for worker 1643 is 1.054691
INFO:root:FL Epoch: 212 Done on worker:1643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 448
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 212 Ends   ===================
INFO:root:Epoch:212 Global Model Test Loss:0.5238762410248027 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:212 Global Model Backdoor Test Loss:0.3239542519052823                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 213 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 213 Workers Selected : [246, 1067, 718, 1531, 146, 179, 1881, 1016, 1818, 1901]
INFO:root:FL Epoch: 213 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 213 Num points on workers: [201 200 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 213 Training on worker :246
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.759748
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.460779
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 213 Norm Difference for worker 246 is 1.246289
INFO:root:FL Epoch: 213 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1067
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1067 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583572
INFO:root:Worker: 1067 Train Epoch: 1 [0/200 (0%)]	Loss: 0.724846
INFO:root:FL Epoch: 213 Norm Difference for worker 1067 is 1.320282
INFO:root:FL Epoch: 213 Done on worker:1067
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :718
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.968341
INFO:root:Worker: 718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345614
INFO:root:FL Epoch: 213 Norm Difference for worker 718 is 1.22561
INFO:root:FL Epoch: 213 Done on worker:718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1531
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577008
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.858760
INFO:root:FL Epoch: 213 Norm Difference for worker 1531 is 1.361203
INFO:root:FL Epoch: 213 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :146
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 146 Train Epoch: 0 [0/201 (0%)]	Loss: 0.671702
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 146 Train Epoch: 1 [0/201 (0%)]	Loss: 0.469647
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 213 Norm Difference for worker 146 is 1.388782
INFO:root:FL Epoch: 213 Done on worker:146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :179
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 179 Train Epoch: 0 [0/201 (0%)]	Loss: 0.619362
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 179 Train Epoch: 1 [0/201 (0%)]	Loss: 0.420418
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 213 Norm Difference for worker 179 is 1.29071
INFO:root:FL Epoch: 213 Done on worker:179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1881
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547521
INFO:root:Worker: 1881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407886
INFO:root:FL Epoch: 213 Norm Difference for worker 1881 is 1.27824
INFO:root:FL Epoch: 213 Done on worker:1881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1016
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553776
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699469
INFO:root:FL Epoch: 213 Norm Difference for worker 1016 is 1.295227
INFO:root:FL Epoch: 213 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1818
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411359
INFO:root:Worker: 1818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424956
INFO:root:FL Epoch: 213 Norm Difference for worker 1818 is 1.208158
INFO:root:FL Epoch: 213 Done on worker:1818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 213 Training on worker :1901
INFO:root:FL Epoch: 213 Using Learning rate : 0.03270730473165839 
INFO:root:FL Epoch: 213 Normal Training
INFO:root:Worker: 1901 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712734
INFO:root:Worker: 1901 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578191
INFO:root:FL Epoch: 213 Norm Difference for worker 1901 is 1.239274
INFO:root:FL Epoch: 213 Done on worker:1901
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 718
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 213 Ends   ===================
INFO:root:Epoch:213 Global Model Test Loss:0.5136011014966404 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:213 Global Model Backdoor Test Loss:0.3655535529057185                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 214 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 214 Workers Selected : [1193, 52, 1029, 1165, 652, 79, 223, 1090, 625, 1403]
INFO:root:FL Epoch: 214 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 214 Num points on workers: [200 201 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 214 Training on worker :1193
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1193 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490884
INFO:root:Worker: 1193 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526446
INFO:root:FL Epoch: 214 Norm Difference for worker 1193 is 1.039888
INFO:root:FL Epoch: 214 Done on worker:1193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :52
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 52 Train Epoch: 0 [0/201 (0%)]	Loss: 0.492089
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 52 Train Epoch: 1 [0/201 (0%)]	Loss: 0.409523
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 52 is 1.052147
INFO:root:FL Epoch: 214 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1029
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1029 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598261
INFO:root:Worker: 1029 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408101
INFO:root:FL Epoch: 214 Norm Difference for worker 1029 is 1.091174
INFO:root:FL Epoch: 214 Done on worker:1029
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1165
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1165 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701712
INFO:root:Worker: 1165 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576628
INFO:root:FL Epoch: 214 Norm Difference for worker 1165 is 1.096893
INFO:root:FL Epoch: 214 Done on worker:1165
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :652
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531403
INFO:root:Worker: 652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284690
INFO:root:FL Epoch: 214 Norm Difference for worker 652 is 1.016771
INFO:root:FL Epoch: 214 Done on worker:652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :79
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.641575
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.491940
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 79 is 1.023891
INFO:root:FL Epoch: 214 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :223
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 223 Train Epoch: 0 [0/201 (0%)]	Loss: 0.575834
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 223 Train Epoch: 1 [0/201 (0%)]	Loss: 0.469056
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 214 Norm Difference for worker 223 is 1.051095
INFO:root:FL Epoch: 214 Done on worker:223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1090
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1090 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472966
INFO:root:Worker: 1090 Train Epoch: 1 [0/200 (0%)]	Loss: 0.755171
INFO:root:FL Epoch: 214 Norm Difference for worker 1090 is 1.10833
INFO:root:FL Epoch: 214 Done on worker:1090
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :625
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 625 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456751
INFO:root:Worker: 625 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593072
INFO:root:FL Epoch: 214 Norm Difference for worker 625 is 0.987712
INFO:root:FL Epoch: 214 Done on worker:625
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 214 Training on worker :1403
INFO:root:FL Epoch: 214 Using Learning rate : 0.03264189012219508 
INFO:root:FL Epoch: 214 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555773
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586682
INFO:root:FL Epoch: 214 Norm Difference for worker 1403 is 1.050619
INFO:root:FL Epoch: 214 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 625
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 214 Ends   ===================
INFO:root:Epoch:214 Global Model Test Loss:0.5090852730414447 and Test Accuracy:75.0 
INFO:root:Epoch:214 Global Model Backdoor Test Loss:0.3067114055156708                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 215 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 215 Workers Selected : [545, 1605, 1807, 1863, 325, 1338, 1902, 352, 1473, 926]
INFO:root:FL Epoch: 215 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 215 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 215 Training on worker :545
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639547
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510796
INFO:root:FL Epoch: 215 Norm Difference for worker 545 is 1.03357
INFO:root:FL Epoch: 215 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1605
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626303
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506295
INFO:root:FL Epoch: 215 Norm Difference for worker 1605 is 0.993011
INFO:root:FL Epoch: 215 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1807
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544698
INFO:root:Worker: 1807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454095
INFO:root:FL Epoch: 215 Norm Difference for worker 1807 is 0.992627
INFO:root:FL Epoch: 215 Done on worker:1807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1863
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518974
INFO:root:Worker: 1863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323984
INFO:root:FL Epoch: 215 Norm Difference for worker 1863 is 0.998762
INFO:root:FL Epoch: 215 Done on worker:1863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :325
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.583979
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.669827
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 215 Norm Difference for worker 325 is 1.057201
INFO:root:FL Epoch: 215 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1338
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1338 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585654
INFO:root:Worker: 1338 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531877
INFO:root:FL Epoch: 215 Norm Difference for worker 1338 is 1.031425
INFO:root:FL Epoch: 215 Done on worker:1338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1902
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463200
INFO:root:Worker: 1902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353354
INFO:root:FL Epoch: 215 Norm Difference for worker 1902 is 1.007644
INFO:root:FL Epoch: 215 Done on worker:1902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :352
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595456
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381259
INFO:root:FL Epoch: 215 Norm Difference for worker 352 is 1.032895
INFO:root:FL Epoch: 215 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :1473
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 1473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664200
INFO:root:Worker: 1473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442050
INFO:root:FL Epoch: 215 Norm Difference for worker 1473 is 1.092474
INFO:root:FL Epoch: 215 Done on worker:1473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 215 Training on worker :926
INFO:root:FL Epoch: 215 Using Learning rate : 0.03257660634195069 
INFO:root:FL Epoch: 215 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685890
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513020
INFO:root:FL Epoch: 215 Norm Difference for worker 926 is 1.004908
INFO:root:FL Epoch: 215 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1807
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 215 Ends   ===================
INFO:root:Epoch:215 Global Model Test Loss:0.5534801763646743 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:215 Global Model Backdoor Test Loss:0.49070901175340015                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 216 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 216 Workers Selected : [5, 177, 1455, 536, 1109, 460, 844, 1487, 620, 1413]
INFO:root:FL Epoch: 216 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 216 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 216 Training on worker :5
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 5 Train Epoch: 0 [0/201 (0%)]	Loss: 0.659430
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 5 Train Epoch: 1 [0/201 (0%)]	Loss: 0.588786
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 216 Norm Difference for worker 5 is 1.102276
INFO:root:FL Epoch: 216 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :177
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 177 Train Epoch: 0 [0/201 (0%)]	Loss: 0.480889
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 177 Train Epoch: 1 [0/201 (0%)]	Loss: 0.390436
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 216 Norm Difference for worker 177 is 1.142175
INFO:root:FL Epoch: 216 Done on worker:177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1455
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484926
INFO:root:Worker: 1455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464824
INFO:root:FL Epoch: 216 Norm Difference for worker 1455 is 1.076862
INFO:root:FL Epoch: 216 Done on worker:1455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :536
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508971
INFO:root:Worker: 536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390999
INFO:root:FL Epoch: 216 Norm Difference for worker 536 is 1.002984
INFO:root:FL Epoch: 216 Done on worker:536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1109
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1109 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506831
INFO:root:Worker: 1109 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547836
INFO:root:FL Epoch: 216 Norm Difference for worker 1109 is 1.042941
INFO:root:FL Epoch: 216 Done on worker:1109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :460
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599606
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628157
INFO:root:FL Epoch: 216 Norm Difference for worker 460 is 1.044046
INFO:root:FL Epoch: 216 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :844
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589462
INFO:root:Worker: 844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542568
INFO:root:FL Epoch: 216 Norm Difference for worker 844 is 1.021974
INFO:root:FL Epoch: 216 Done on worker:844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1487
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449724
INFO:root:Worker: 1487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389269
INFO:root:FL Epoch: 216 Norm Difference for worker 1487 is 1.088323
INFO:root:FL Epoch: 216 Done on worker:1487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :620
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701466
INFO:root:Worker: 620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546100
INFO:root:FL Epoch: 216 Norm Difference for worker 620 is 1.01179
INFO:root:FL Epoch: 216 Done on worker:620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 216 Training on worker :1413
INFO:root:FL Epoch: 216 Using Learning rate : 0.03251145312926679 
INFO:root:FL Epoch: 216 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643974
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501363
INFO:root:FL Epoch: 216 Norm Difference for worker 1413 is 1.038615
INFO:root:FL Epoch: 216 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 844
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 216 Ends   ===================
INFO:root:Epoch:216 Global Model Test Loss:0.5393738869358512 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:216 Global Model Backdoor Test Loss:0.4804709752400716                             and Backdoor Test Accuracy:80.0 
INFO:root:=======================================================
INFO:root:================FL round 217 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 217 Workers Selected : [443, 449, 385, 1602, 764, 1149, 1077, 381, 1067, 5]
INFO:root:FL Epoch: 217 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 217 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 217 Training on worker :443
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523266
INFO:root:Worker: 443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544347
INFO:root:FL Epoch: 217 Norm Difference for worker 443 is 0.980477
INFO:root:FL Epoch: 217 Done on worker:443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :449
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588151
INFO:root:Worker: 449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487988
INFO:root:FL Epoch: 217 Norm Difference for worker 449 is 0.92032
INFO:root:FL Epoch: 217 Done on worker:449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :385
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421217
INFO:root:Worker: 385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587830
INFO:root:FL Epoch: 217 Norm Difference for worker 385 is 0.916844
INFO:root:FL Epoch: 217 Done on worker:385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1602
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656911
INFO:root:Worker: 1602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454683
INFO:root:FL Epoch: 217 Norm Difference for worker 1602 is 0.997422
INFO:root:FL Epoch: 217 Done on worker:1602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :764
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624464
INFO:root:Worker: 764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558058
INFO:root:FL Epoch: 217 Norm Difference for worker 764 is 0.947636
INFO:root:FL Epoch: 217 Done on worker:764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1149
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1149 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551840
INFO:root:Worker: 1149 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492619
INFO:root:FL Epoch: 217 Norm Difference for worker 1149 is 0.969962
INFO:root:FL Epoch: 217 Done on worker:1149
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1077
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1077 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431452
INFO:root:Worker: 1077 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399244
INFO:root:FL Epoch: 217 Norm Difference for worker 1077 is 0.924409
INFO:root:FL Epoch: 217 Done on worker:1077
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :381
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602581
INFO:root:Worker: 381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310843
INFO:root:FL Epoch: 217 Norm Difference for worker 381 is 0.949856
INFO:root:FL Epoch: 217 Done on worker:381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :1067
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 1067 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689699
INFO:root:Worker: 1067 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432341
INFO:root:FL Epoch: 217 Norm Difference for worker 1067 is 0.971067
INFO:root:FL Epoch: 217 Done on worker:1067
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 217 Training on worker :5
INFO:root:FL Epoch: 217 Using Learning rate : 0.032446430223008256 
INFO:root:FL Epoch: 217 Normal Training
INFO:root:Worker: 5 Train Epoch: 0 [0/201 (0%)]	Loss: 0.602732
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 5 Train Epoch: 1 [0/201 (0%)]	Loss: 0.493202
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 217 Norm Difference for worker 5 is 0.965637
INFO:root:FL Epoch: 217 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1077
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 217 Ends   ===================
INFO:root:Epoch:217 Global Model Test Loss:0.567662635270287 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:217 Global Model Backdoor Test Loss:0.4976026813189189                             and Backdoor Test Accuracy:74.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 218 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 218 Workers Selected : [1206, 1292, 1674, 942, 925, 757, 820, 216, 898, 1576]
INFO:root:FL Epoch: 218 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 218 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 218 Training on worker :1206
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1206 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621134
INFO:root:Worker: 1206 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460041
INFO:root:FL Epoch: 218 Norm Difference for worker 1206 is 1.038256
INFO:root:FL Epoch: 218 Done on worker:1206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1292
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1292 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611632
INFO:root:Worker: 1292 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491594
INFO:root:FL Epoch: 218 Norm Difference for worker 1292 is 1.13901
INFO:root:FL Epoch: 218 Done on worker:1292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1674
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324544
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430334
INFO:root:FL Epoch: 218 Norm Difference for worker 1674 is 1.091679
INFO:root:FL Epoch: 218 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :942
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 942 Train Epoch: 0 [0/200 (0%)]	Loss: 0.797764
INFO:root:Worker: 942 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548334
INFO:root:FL Epoch: 218 Norm Difference for worker 942 is 1.108467
INFO:root:FL Epoch: 218 Done on worker:942
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :925
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501771
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362176
INFO:root:FL Epoch: 218 Norm Difference for worker 925 is 0.960684
INFO:root:FL Epoch: 218 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :757
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546128
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459114
INFO:root:FL Epoch: 218 Norm Difference for worker 757 is 1.096978
INFO:root:FL Epoch: 218 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :820
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712875
INFO:root:Worker: 820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393363
INFO:root:FL Epoch: 218 Norm Difference for worker 820 is 1.062526
INFO:root:FL Epoch: 218 Done on worker:820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :216
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 216 Train Epoch: 0 [0/201 (0%)]	Loss: 0.553248
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 216 Train Epoch: 1 [0/201 (0%)]	Loss: 0.378323
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 218 Norm Difference for worker 216 is 1.099769
INFO:root:FL Epoch: 218 Done on worker:216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :898
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540439
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525533
INFO:root:FL Epoch: 218 Norm Difference for worker 898 is 1.077375
INFO:root:FL Epoch: 218 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 218 Training on worker :1576
INFO:root:FL Epoch: 218 Using Learning rate : 0.03238153736256224 
INFO:root:FL Epoch: 218 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734510
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652154
INFO:root:FL Epoch: 218 Norm Difference for worker 1576 is 1.05525
INFO:root:FL Epoch: 218 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 925
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 218 Ends   ===================
INFO:root:Epoch:218 Global Model Test Loss:0.5747578091481153 and Test Accuracy:68.82352941176471 
INFO:root:Epoch:218 Global Model Backdoor Test Loss:0.5566569219032923                             and Backdoor Test Accuracy:71.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 219 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 219 Workers Selected : [1667, 119, 810, 493, 1696, 180, 766, 1036, 836, 477]
INFO:root:FL Epoch: 219 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 219 Num points on workers: [200 201 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 219 Training on worker :1667
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.232543
INFO:root:Worker: 1667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529359
INFO:root:FL Epoch: 219 Norm Difference for worker 1667 is 1.186329
INFO:root:FL Epoch: 219 Done on worker:1667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :119
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.478664
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.358137
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 219 Norm Difference for worker 119 is 1.215749
INFO:root:FL Epoch: 219 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :810
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627786
INFO:root:Worker: 810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450052
INFO:root:FL Epoch: 219 Norm Difference for worker 810 is 1.208845
INFO:root:FL Epoch: 219 Done on worker:810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :493
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 493 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475819
INFO:root:Worker: 493 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616961
INFO:root:FL Epoch: 219 Norm Difference for worker 493 is 1.245593
INFO:root:FL Epoch: 219 Done on worker:493
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1696
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.362462
INFO:root:Worker: 1696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271980
INFO:root:FL Epoch: 219 Norm Difference for worker 1696 is 1.039597
INFO:root:FL Epoch: 219 Done on worker:1696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :180
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 180 Train Epoch: 0 [0/201 (0%)]	Loss: 0.489984
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 180 Train Epoch: 1 [0/201 (0%)]	Loss: 0.448948
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 219 Norm Difference for worker 180 is 1.130803
INFO:root:FL Epoch: 219 Done on worker:180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :766
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375148
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372996
INFO:root:FL Epoch: 219 Norm Difference for worker 766 is 1.110078
INFO:root:FL Epoch: 219 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :1036
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648677
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475383
INFO:root:FL Epoch: 219 Norm Difference for worker 1036 is 1.239138
INFO:root:FL Epoch: 219 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :836
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510911
INFO:root:Worker: 836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297220
INFO:root:FL Epoch: 219 Norm Difference for worker 836 is 1.128986
INFO:root:FL Epoch: 219 Done on worker:836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 219 Training on worker :477
INFO:root:FL Epoch: 219 Using Learning rate : 0.032316774287837115 
INFO:root:FL Epoch: 219 Normal Training
INFO:root:Worker: 477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408430
INFO:root:Worker: 477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660130
INFO:root:FL Epoch: 219 Norm Difference for worker 477 is 1.223835
INFO:root:FL Epoch: 219 Done on worker:477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1696
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 219 Ends   ===================
INFO:root:Epoch:219 Global Model Test Loss:0.5569746318985435 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:219 Global Model Backdoor Test Loss:0.44231946766376495                             and Backdoor Test Accuracy:78.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 220 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 220 Workers Selected : [983, 828, 933, 37, 1000, 793, 879, 504, 458, 1665]
INFO:root:FL Epoch: 220 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 220 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 220 Training on worker :983
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.955207
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332214
INFO:root:FL Epoch: 220 Norm Difference for worker 983 is 1.366056
INFO:root:FL Epoch: 220 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :828
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.793765
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370895
INFO:root:FL Epoch: 220 Norm Difference for worker 828 is 1.415173
INFO:root:FL Epoch: 220 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :933
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 933 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611242
INFO:root:Worker: 933 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510246
INFO:root:FL Epoch: 220 Norm Difference for worker 933 is 1.347447
INFO:root:FL Epoch: 220 Done on worker:933
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :37
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 37 Train Epoch: 0 [0/201 (0%)]	Loss: 0.719599
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 37 Train Epoch: 1 [0/201 (0%)]	Loss: 0.541765
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 220 Norm Difference for worker 37 is 1.360584
INFO:root:FL Epoch: 220 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1000
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1000 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775103
INFO:root:Worker: 1000 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497191
INFO:root:FL Epoch: 220 Norm Difference for worker 1000 is 1.421278
INFO:root:FL Epoch: 220 Done on worker:1000
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :793
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369131
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353827
INFO:root:FL Epoch: 220 Norm Difference for worker 793 is 1.296725
INFO:root:FL Epoch: 220 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :879
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.778505
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553062
INFO:root:FL Epoch: 220 Norm Difference for worker 879 is 1.349436
INFO:root:FL Epoch: 220 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :504
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722393
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550691
INFO:root:FL Epoch: 220 Norm Difference for worker 504 is 1.308187
INFO:root:FL Epoch: 220 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :458
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420135
INFO:root:Worker: 458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335176
INFO:root:FL Epoch: 220 Norm Difference for worker 458 is 1.320498
INFO:root:FL Epoch: 220 Done on worker:458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 220 Training on worker :1665
INFO:root:FL Epoch: 220 Using Learning rate : 0.032252140739261435 
INFO:root:FL Epoch: 220 Normal Training
INFO:root:Worker: 1665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388307
INFO:root:Worker: 1665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401307
INFO:root:FL Epoch: 220 Norm Difference for worker 1665 is 1.234968
INFO:root:FL Epoch: 220 Done on worker:1665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1665
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 220 Ends   ===================
INFO:root:Epoch:220 Global Model Test Loss:0.5178349666735705 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:220 Global Model Backdoor Test Loss:0.327432781457901                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 221 Begins ===================
INFO:root:FL Epoch: 221 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 221 Workers Selected : [0, 1618, 1494, 1021, 910, 591, 1561, 1638, 1423, 1772]
INFO:root:FL Epoch: 221 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 221 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 221 Training on worker :0
INFO:root:FL Epoch: 221 Using Learning rate : 0.006437527291556583 
INFO:root:FL Epoch: 221 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.249134
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308285
INFO:root:FL Epoch: 221 Worker: 0 Backdoor Test Loss: 0.30960073073705036 Backdoor Test Accuracy: 88.33333333333333
INFO:root:FL Epoch: 221 Worker: 0 Backdoor Train Loss: 0.26859828531742097 Backdoor Train Accuracy: 91.5
INFO:root:FL Epoch: 221 Norm Difference for worker 0 is 0.223843
INFO:root:FL Epoch: 221 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1618
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499529
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535997
INFO:root:FL Epoch: 221 Norm Difference for worker 1618 is 1.11962
INFO:root:FL Epoch: 221 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1494
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486760
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435496
INFO:root:FL Epoch: 221 Norm Difference for worker 1494 is 1.121617
INFO:root:FL Epoch: 221 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1021
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1021 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622209
INFO:root:Worker: 1021 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381063
INFO:root:FL Epoch: 221 Norm Difference for worker 1021 is 1.078553
INFO:root:FL Epoch: 221 Done on worker:1021
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :910
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414405
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416263
INFO:root:FL Epoch: 221 Norm Difference for worker 910 is 1.186994
INFO:root:FL Epoch: 221 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :591
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 591 Train Epoch: 0 [0/200 (0%)]	Loss: 1.007699
INFO:root:Worker: 591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489852
INFO:root:FL Epoch: 221 Norm Difference for worker 591 is 1.189148
INFO:root:FL Epoch: 221 Done on worker:591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1561
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442980
INFO:root:Worker: 1561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441369
INFO:root:FL Epoch: 221 Norm Difference for worker 1561 is 1.165764
INFO:root:FL Epoch: 221 Done on worker:1561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1638
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528545
INFO:root:Worker: 1638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473602
INFO:root:FL Epoch: 221 Norm Difference for worker 1638 is 1.136241
INFO:root:FL Epoch: 221 Done on worker:1638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1423
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576883
INFO:root:Worker: 1423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429208
INFO:root:FL Epoch: 221 Norm Difference for worker 1423 is 1.078111
INFO:root:FL Epoch: 221 Done on worker:1423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 221 Training on worker :1772
INFO:root:FL Epoch: 221 Using Learning rate : 0.032187636457782914 
INFO:root:FL Epoch: 221 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599739
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.771623
INFO:root:FL Epoch: 221 Norm Difference for worker 1772 is 1.171361
INFO:root:FL Epoch: 221 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 221 Ends   ===================
INFO:root:Epoch:221 Global Model Test Loss:0.5279786516638363 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:221 Global Model Backdoor Test Loss:0.30960073073705036                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 222 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 222 Workers Selected : [470, 797, 198, 456, 966, 100, 371, 847, 1564, 804]
INFO:root:FL Epoch: 222 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 222 Num points on workers: [200 200 201 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 222 Training on worker :470
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.793444
INFO:root:Worker: 470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468128
INFO:root:FL Epoch: 222 Norm Difference for worker 470 is 1.194756
INFO:root:FL Epoch: 222 Done on worker:470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :797
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.906686
INFO:root:Worker: 797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482886
INFO:root:FL Epoch: 222 Norm Difference for worker 797 is 1.164967
INFO:root:FL Epoch: 222 Done on worker:797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :198
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.658391
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.384827
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 222 Norm Difference for worker 198 is 1.203773
INFO:root:FL Epoch: 222 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :456
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395170
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381680
INFO:root:FL Epoch: 222 Norm Difference for worker 456 is 1.174788
INFO:root:FL Epoch: 222 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :966
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377364
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202876
INFO:root:FL Epoch: 222 Norm Difference for worker 966 is 1.137573
INFO:root:FL Epoch: 222 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :100
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.361566
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.667775
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 222 Norm Difference for worker 100 is 1.17821
INFO:root:FL Epoch: 222 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :371
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578068
INFO:root:Worker: 371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277760
INFO:root:FL Epoch: 222 Norm Difference for worker 371 is 1.186747
INFO:root:FL Epoch: 222 Done on worker:371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :847
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572430
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491930
INFO:root:FL Epoch: 222 Norm Difference for worker 847 is 1.129266
INFO:root:FL Epoch: 222 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :1564
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 1564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540487
INFO:root:Worker: 1564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320775
INFO:root:FL Epoch: 222 Norm Difference for worker 1564 is 1.154644
INFO:root:FL Epoch: 222 Done on worker:1564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 222 Training on worker :804
INFO:root:FL Epoch: 222 Using Learning rate : 0.03212326118486735 
INFO:root:FL Epoch: 222 Normal Training
INFO:root:Worker: 804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.777842
INFO:root:Worker: 804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638035
INFO:root:FL Epoch: 222 Norm Difference for worker 804 is 1.268578
INFO:root:FL Epoch: 222 Done on worker:804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 847
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 222 Ends   ===================
INFO:root:Epoch:222 Global Model Test Loss:0.5338924457045162 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:222 Global Model Backdoor Test Loss:0.36716460684935254                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 223 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 223 Workers Selected : [693, 900, 1891, 914, 1339, 1170, 1747, 1173, 1100, 1280]
INFO:root:FL Epoch: 223 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 223 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 223 Training on worker :693
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.278353
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390039
INFO:root:FL Epoch: 223 Norm Difference for worker 693 is 0.983577
INFO:root:FL Epoch: 223 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :900
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486330
INFO:root:Worker: 900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413564
INFO:root:FL Epoch: 223 Norm Difference for worker 900 is 1.14937
INFO:root:FL Epoch: 223 Done on worker:900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1891
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698523
INFO:root:Worker: 1891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562157
INFO:root:FL Epoch: 223 Norm Difference for worker 1891 is 1.067665
INFO:root:FL Epoch: 223 Done on worker:1891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :914
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551719
INFO:root:Worker: 914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505320
INFO:root:FL Epoch: 223 Norm Difference for worker 914 is 1.137473
INFO:root:FL Epoch: 223 Done on worker:914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1339
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1339 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676854
INFO:root:Worker: 1339 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543537
INFO:root:FL Epoch: 223 Norm Difference for worker 1339 is 1.067534
INFO:root:FL Epoch: 223 Done on worker:1339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1170
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1170 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657160
INFO:root:Worker: 1170 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574526
INFO:root:FL Epoch: 223 Norm Difference for worker 1170 is 1.233513
INFO:root:FL Epoch: 223 Done on worker:1170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1747
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597959
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365748
INFO:root:FL Epoch: 223 Norm Difference for worker 1747 is 1.114421
INFO:root:FL Epoch: 223 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1173
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1173 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554989
INFO:root:Worker: 1173 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350822
INFO:root:FL Epoch: 223 Norm Difference for worker 1173 is 1.027029
INFO:root:FL Epoch: 223 Done on worker:1173
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1100
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1100 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714875
INFO:root:Worker: 1100 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574720
INFO:root:FL Epoch: 223 Norm Difference for worker 1100 is 1.18128
INFO:root:FL Epoch: 223 Done on worker:1100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 223 Training on worker :1280
INFO:root:FL Epoch: 223 Using Learning rate : 0.032059014662497616 
INFO:root:FL Epoch: 223 Normal Training
INFO:root:Worker: 1280 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610968
INFO:root:Worker: 1280 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516331
INFO:root:FL Epoch: 223 Norm Difference for worker 1280 is 1.08596
INFO:root:FL Epoch: 223 Done on worker:1280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 693
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 223 Ends   ===================
INFO:root:Epoch:223 Global Model Test Loss:0.5583371257080751 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:223 Global Model Backdoor Test Loss:0.40600892901420593                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 224 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 224 Workers Selected : [121, 432, 1521, 472, 447, 591, 1014, 127, 151, 1304]
INFO:root:FL Epoch: 224 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 224 Num points on workers: [201 200 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 224 Training on worker :121
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 121 Train Epoch: 0 [0/201 (0%)]	Loss: 0.403116
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 121 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428558
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 224 Norm Difference for worker 121 is 1.341867
INFO:root:FL Epoch: 224 Done on worker:121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :432
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.838949
INFO:root:Worker: 432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499703
INFO:root:FL Epoch: 224 Norm Difference for worker 432 is 1.105712
INFO:root:FL Epoch: 224 Done on worker:432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1521
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304797
INFO:root:Worker: 1521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365313
INFO:root:FL Epoch: 224 Norm Difference for worker 1521 is 1.180657
INFO:root:FL Epoch: 224 Done on worker:1521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :472
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491670
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411938
INFO:root:FL Epoch: 224 Norm Difference for worker 472 is 1.297983
INFO:root:FL Epoch: 224 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :447
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439107
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.796170
INFO:root:FL Epoch: 224 Norm Difference for worker 447 is 1.390718
INFO:root:FL Epoch: 224 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :591
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.800092
INFO:root:Worker: 591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465624
INFO:root:FL Epoch: 224 Norm Difference for worker 591 is 1.433174
INFO:root:FL Epoch: 224 Done on worker:591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1014
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639710
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481400
INFO:root:FL Epoch: 224 Norm Difference for worker 1014 is 1.323854
INFO:root:FL Epoch: 224 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :127
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 127 Train Epoch: 0 [0/201 (0%)]	Loss: 0.717134
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 127 Train Epoch: 1 [0/201 (0%)]	Loss: 0.737332
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 224 Norm Difference for worker 127 is 1.248062
INFO:root:FL Epoch: 224 Done on worker:127
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :151
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.638573
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.643114
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 224 Norm Difference for worker 151 is 1.279426
INFO:root:FL Epoch: 224 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 224 Training on worker :1304
INFO:root:FL Epoch: 224 Using Learning rate : 0.03199489663317262 
INFO:root:FL Epoch: 224 Normal Training
INFO:root:Worker: 1304 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412933
INFO:root:Worker: 1304 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556341
INFO:root:FL Epoch: 224 Norm Difference for worker 1304 is 1.191051
INFO:root:FL Epoch: 224 Done on worker:1304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 432
INFO:root:Norm of Aggregated Model: 5154.99072265625
INFO:root:Aggregating After Defense
INFO:root:================FL round 224 Ends   ===================
INFO:root:Epoch:224 Global Model Test Loss:0.5711903659736409 and Test Accuracy:70.29411764705883 
INFO:root:Epoch:224 Global Model Backdoor Test Loss:0.4830217311779658                             and Backdoor Test Accuracy:79.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 225 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 225 Workers Selected : [969, 9, 1523, 1343, 1486, 451, 775, 353, 1539, 1452]
INFO:root:FL Epoch: 225 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 225 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 225 Training on worker :969
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 969 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627536
INFO:root:Worker: 969 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663147
INFO:root:FL Epoch: 225 Norm Difference for worker 969 is 1.239754
INFO:root:FL Epoch: 225 Done on worker:969
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :9
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.743383
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.632096
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 225 Norm Difference for worker 9 is 1.254833
INFO:root:FL Epoch: 225 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1523
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.829089
INFO:root:Worker: 1523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343499
INFO:root:FL Epoch: 225 Norm Difference for worker 1523 is 1.22412
INFO:root:FL Epoch: 225 Done on worker:1523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1343
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.936275
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310851
INFO:root:FL Epoch: 225 Norm Difference for worker 1343 is 1.180515
INFO:root:FL Epoch: 225 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1486
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.903244
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351822
INFO:root:FL Epoch: 225 Norm Difference for worker 1486 is 1.176016
INFO:root:FL Epoch: 225 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :451
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581553
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490624
INFO:root:FL Epoch: 225 Norm Difference for worker 451 is 1.294361
INFO:root:FL Epoch: 225 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :775
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468522
INFO:root:Worker: 775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622771
INFO:root:FL Epoch: 225 Norm Difference for worker 775 is 1.251158
INFO:root:FL Epoch: 225 Done on worker:775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :353
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596591
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431987
INFO:root:FL Epoch: 225 Norm Difference for worker 353 is 1.206803
INFO:root:FL Epoch: 225 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1539
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635449
INFO:root:Worker: 1539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580857
INFO:root:FL Epoch: 225 Norm Difference for worker 1539 is 1.273124
INFO:root:FL Epoch: 225 Done on worker:1539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 225 Training on worker :1452
INFO:root:FL Epoch: 225 Using Learning rate : 0.03193090683990628 
INFO:root:FL Epoch: 225 Normal Training
INFO:root:Worker: 1452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501136
INFO:root:Worker: 1452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336464
INFO:root:FL Epoch: 225 Norm Difference for worker 1452 is 1.347431
INFO:root:FL Epoch: 225 Done on worker:1452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1343
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 225 Ends   ===================
INFO:root:Epoch:225 Global Model Test Loss:0.5110915706438177 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:225 Global Model Backdoor Test Loss:0.426520769794782                             and Backdoor Test Accuracy:81.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 226 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 226 Workers Selected : [1485, 555, 1594, 643, 1912, 754, 1378, 1133, 549, 1650]
INFO:root:FL Epoch: 226 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 226 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 226 Training on worker :1485
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315580
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421017
INFO:root:FL Epoch: 226 Norm Difference for worker 1485 is 1.094595
INFO:root:FL Epoch: 226 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :555
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403683
INFO:root:Worker: 555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255857
INFO:root:FL Epoch: 226 Norm Difference for worker 555 is 1.059007
INFO:root:FL Epoch: 226 Done on worker:555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1594
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643034
INFO:root:Worker: 1594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429410
INFO:root:FL Epoch: 226 Norm Difference for worker 1594 is 1.027646
INFO:root:FL Epoch: 226 Done on worker:1594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :643
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529334
INFO:root:Worker: 643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543139
INFO:root:FL Epoch: 226 Norm Difference for worker 643 is 1.121206
INFO:root:FL Epoch: 226 Done on worker:643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1912
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625006
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485220
INFO:root:FL Epoch: 226 Norm Difference for worker 1912 is 1.052873
INFO:root:FL Epoch: 226 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :754
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650397
INFO:root:Worker: 754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428231
INFO:root:FL Epoch: 226 Norm Difference for worker 754 is 1.109639
INFO:root:FL Epoch: 226 Done on worker:754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1378
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705879
INFO:root:Worker: 1378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406788
INFO:root:FL Epoch: 226 Norm Difference for worker 1378 is 1.122442
INFO:root:FL Epoch: 226 Done on worker:1378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1133
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1133 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414776
INFO:root:Worker: 1133 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474541
INFO:root:FL Epoch: 226 Norm Difference for worker 1133 is 1.149568
INFO:root:FL Epoch: 226 Done on worker:1133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :549
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442517
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498634
INFO:root:FL Epoch: 226 Norm Difference for worker 549 is 1.067437
INFO:root:FL Epoch: 226 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 226 Training on worker :1650
INFO:root:FL Epoch: 226 Using Learning rate : 0.03186704502622646 
INFO:root:FL Epoch: 226 Normal Training
INFO:root:Worker: 1650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631800
INFO:root:Worker: 1650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427476
INFO:root:FL Epoch: 226 Norm Difference for worker 1650 is 1.161235
INFO:root:FL Epoch: 226 Done on worker:1650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1594
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 226 Ends   ===================
INFO:root:Epoch:226 Global Model Test Loss:0.48975987118833203 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:226 Global Model Backdoor Test Loss:0.4107027103503545                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 227 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 227 Workers Selected : [648, 1867, 874, 93, 920, 1013, 990, 1773, 1689, 32]
INFO:root:FL Epoch: 227 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 227 Num points on workers: [200 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 227 Training on worker :648
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433723
INFO:root:Worker: 648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440737
INFO:root:FL Epoch: 227 Norm Difference for worker 648 is 1.027546
INFO:root:FL Epoch: 227 Done on worker:648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1867
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422553
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379029
INFO:root:FL Epoch: 227 Norm Difference for worker 1867 is 0.994126
INFO:root:FL Epoch: 227 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :874
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608905
INFO:root:Worker: 874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415553
INFO:root:FL Epoch: 227 Norm Difference for worker 874 is 1.095342
INFO:root:FL Epoch: 227 Done on worker:874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :93
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 93 Train Epoch: 0 [0/201 (0%)]	Loss: 0.302495
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 93 Train Epoch: 1 [0/201 (0%)]	Loss: 0.472534
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 93 is 1.010857
INFO:root:FL Epoch: 227 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :920
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474656
INFO:root:Worker: 920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.766573
INFO:root:FL Epoch: 227 Norm Difference for worker 920 is 1.076653
INFO:root:FL Epoch: 227 Done on worker:920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1013
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.883755
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694254
INFO:root:FL Epoch: 227 Norm Difference for worker 1013 is 0.985706
INFO:root:FL Epoch: 227 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :990
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 990 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600654
INFO:root:Worker: 990 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388400
INFO:root:FL Epoch: 227 Norm Difference for worker 990 is 1.020712
INFO:root:FL Epoch: 227 Done on worker:990
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1773
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650045
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463788
INFO:root:FL Epoch: 227 Norm Difference for worker 1773 is 0.982219
INFO:root:FL Epoch: 227 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :1689
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 1689 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630227
INFO:root:Worker: 1689 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546236
INFO:root:FL Epoch: 227 Norm Difference for worker 1689 is 1.055255
INFO:root:FL Epoch: 227 Done on worker:1689
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 227 Training on worker :32
INFO:root:FL Epoch: 227 Using Learning rate : 0.03180331093617401 
INFO:root:FL Epoch: 227 Normal Training
INFO:root:Worker: 32 Train Epoch: 0 [0/201 (0%)]	Loss: 0.567908
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 32 Train Epoch: 1 [0/201 (0%)]	Loss: 0.344445
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 227 Norm Difference for worker 32 is 1.029948
INFO:root:FL Epoch: 227 Done on worker:32
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1013
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 227 Ends   ===================
INFO:root:Epoch:227 Global Model Test Loss:0.49579675232662873 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:227 Global Model Backdoor Test Loss:0.4259031414985657                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 228 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 228 Workers Selected : [955, 1887, 1204, 1791, 1059, 1428, 634, 1557, 1872, 1924]
INFO:root:FL Epoch: 228 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 228 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 228 Training on worker :955
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 955 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368471
INFO:root:Worker: 955 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415463
INFO:root:FL Epoch: 228 Norm Difference for worker 955 is 0.937226
INFO:root:FL Epoch: 228 Done on worker:955
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1887
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567906
INFO:root:Worker: 1887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394049
INFO:root:FL Epoch: 228 Norm Difference for worker 1887 is 0.864662
INFO:root:FL Epoch: 228 Done on worker:1887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1204
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1204 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506652
INFO:root:Worker: 1204 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582949
INFO:root:FL Epoch: 228 Norm Difference for worker 1204 is 0.9346
INFO:root:FL Epoch: 228 Done on worker:1204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1791
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420101
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323724
INFO:root:FL Epoch: 228 Norm Difference for worker 1791 is 0.917443
INFO:root:FL Epoch: 228 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1059
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1059 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545909
INFO:root:Worker: 1059 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405600
INFO:root:FL Epoch: 228 Norm Difference for worker 1059 is 0.983277
INFO:root:FL Epoch: 228 Done on worker:1059
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1428
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545430
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439777
INFO:root:FL Epoch: 228 Norm Difference for worker 1428 is 0.9003
INFO:root:FL Epoch: 228 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :634
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415885
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565465
INFO:root:FL Epoch: 228 Norm Difference for worker 634 is 0.907555
INFO:root:FL Epoch: 228 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1557
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1557 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606704
INFO:root:Worker: 1557 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447545
INFO:root:FL Epoch: 228 Norm Difference for worker 1557 is 0.897931
INFO:root:FL Epoch: 228 Done on worker:1557
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1872
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445517
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400158
INFO:root:FL Epoch: 228 Norm Difference for worker 1872 is 0.890076
INFO:root:FL Epoch: 228 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 228 Training on worker :1924
INFO:root:FL Epoch: 228 Using Learning rate : 0.03173970431430166 
INFO:root:FL Epoch: 228 Normal Training
INFO:root:Worker: 1924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661663
INFO:root:Worker: 1924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457462
INFO:root:FL Epoch: 228 Norm Difference for worker 1924 is 0.915956
INFO:root:FL Epoch: 228 Done on worker:1924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1887
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 228 Ends   ===================
INFO:root:Epoch:228 Global Model Test Loss:0.5249878150575301 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:228 Global Model Backdoor Test Loss:0.5555026978254318                             and Backdoor Test Accuracy:73.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 229 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 229 Workers Selected : [671, 1129, 39, 772, 577, 1248, 637, 639, 299, 1080]
INFO:root:FL Epoch: 229 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 229 Num points on workers: [200 200 201 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 229 Training on worker :671
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607911
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425279
INFO:root:FL Epoch: 229 Norm Difference for worker 671 is 0.95372
INFO:root:FL Epoch: 229 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1129
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1129 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455412
INFO:root:Worker: 1129 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508123
INFO:root:FL Epoch: 229 Norm Difference for worker 1129 is 0.989976
INFO:root:FL Epoch: 229 Done on worker:1129
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :39
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 39 Train Epoch: 0 [0/201 (0%)]	Loss: 0.855154
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 39 Train Epoch: 1 [0/201 (0%)]	Loss: 0.480178
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 229 Norm Difference for worker 39 is 0.985332
INFO:root:FL Epoch: 229 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :772
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666512
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523344
INFO:root:FL Epoch: 229 Norm Difference for worker 772 is 1.013701
INFO:root:FL Epoch: 229 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :577
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559647
INFO:root:Worker: 577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511199
INFO:root:FL Epoch: 229 Norm Difference for worker 577 is 0.937508
INFO:root:FL Epoch: 229 Done on worker:577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1248
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521042
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455633
INFO:root:FL Epoch: 229 Norm Difference for worker 1248 is 0.958679
INFO:root:FL Epoch: 229 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :637
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389049
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362103
INFO:root:FL Epoch: 229 Norm Difference for worker 637 is 1.021098
INFO:root:FL Epoch: 229 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :639
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554689
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472891
INFO:root:FL Epoch: 229 Norm Difference for worker 639 is 0.867851
INFO:root:FL Epoch: 229 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :299
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 299 Train Epoch: 0 [0/201 (0%)]	Loss: 0.716156
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 299 Train Epoch: 1 [0/201 (0%)]	Loss: 0.607821
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 229 Norm Difference for worker 299 is 0.934007
INFO:root:FL Epoch: 229 Done on worker:299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 229 Training on worker :1080
INFO:root:FL Epoch: 229 Using Learning rate : 0.03167622490567306 
INFO:root:FL Epoch: 229 Normal Training
INFO:root:Worker: 1080 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354786
INFO:root:Worker: 1080 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586471
INFO:root:FL Epoch: 229 Norm Difference for worker 1080 is 0.948115
INFO:root:FL Epoch: 229 Done on worker:1080
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 639
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 229 Ends   ===================
INFO:root:Epoch:229 Global Model Test Loss:0.491014969699523 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:229 Global Model Backdoor Test Loss:0.47755465904871625                             and Backdoor Test Accuracy:79.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 230 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 230 Workers Selected : [873, 775, 828, 1248, 996, 1499, 76, 1770, 747, 595]
INFO:root:FL Epoch: 230 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 230 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 230 Training on worker :873
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427874
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479085
INFO:root:FL Epoch: 230 Norm Difference for worker 873 is 1.099487
INFO:root:FL Epoch: 230 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :775
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603881
INFO:root:Worker: 775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401800
INFO:root:FL Epoch: 230 Norm Difference for worker 775 is 1.11058
INFO:root:FL Epoch: 230 Done on worker:775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :828
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516579
INFO:root:Worker: 828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590239
INFO:root:FL Epoch: 230 Norm Difference for worker 828 is 1.198545
INFO:root:FL Epoch: 230 Done on worker:828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1248
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1248 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478649
INFO:root:Worker: 1248 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517680
INFO:root:FL Epoch: 230 Norm Difference for worker 1248 is 1.083884
INFO:root:FL Epoch: 230 Done on worker:1248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :996
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632527
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470476
INFO:root:FL Epoch: 230 Norm Difference for worker 996 is 1.077548
INFO:root:FL Epoch: 230 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1499
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452541
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335929
INFO:root:FL Epoch: 230 Norm Difference for worker 1499 is 1.083955
INFO:root:FL Epoch: 230 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :76
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.589640
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.715724
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 230 Norm Difference for worker 76 is 1.125396
INFO:root:FL Epoch: 230 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :1770
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.930610
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485712
INFO:root:FL Epoch: 230 Norm Difference for worker 1770 is 1.102088
INFO:root:FL Epoch: 230 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :747
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748476
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554624
INFO:root:FL Epoch: 230 Norm Difference for worker 747 is 1.185362
INFO:root:FL Epoch: 230 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 230 Training on worker :595
INFO:root:FL Epoch: 230 Using Learning rate : 0.03161287245586172 
INFO:root:FL Epoch: 230 Normal Training
INFO:root:Worker: 595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565957
INFO:root:Worker: 595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545945
INFO:root:FL Epoch: 230 Norm Difference for worker 595 is 1.05328
INFO:root:FL Epoch: 230 Done on worker:595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 595
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 230 Ends   ===================
INFO:root:Epoch:230 Global Model Test Loss:0.48556220356155844 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:230 Global Model Backdoor Test Loss:0.3997625907262166                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 231 Begins ===================
INFO:root:FL Epoch: 231 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 231 Workers Selected : [0, 983, 1374, 129, 320, 1346, 124, 1736, 1616, 1905]
INFO:root:FL Epoch: 231 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 231 Num points on workers: [200 200 200 201 201 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 231 Training on worker :0
INFO:root:FL Epoch: 231 Using Learning rate : 0.006309929342189997 
INFO:root:FL Epoch: 231 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412654
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421076
INFO:root:FL Epoch: 231 Worker: 0 Backdoor Test Loss: 0.32112180689970654 Backdoor Test Accuracy: 90.0
INFO:root:FL Epoch: 231 Worker: 0 Backdoor Train Loss: 0.2996972739696503 Backdoor Train Accuracy: 91.0
INFO:root:FL Epoch: 231 Norm Difference for worker 0 is 0.220015
INFO:root:FL Epoch: 231 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :983
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492529
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501035
INFO:root:FL Epoch: 231 Norm Difference for worker 983 is 1.006582
INFO:root:FL Epoch: 231 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1374
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614257
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588064
INFO:root:FL Epoch: 231 Norm Difference for worker 1374 is 0.898384
INFO:root:FL Epoch: 231 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :129
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 129 Train Epoch: 0 [0/201 (0%)]	Loss: 0.475560
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 129 Train Epoch: 1 [0/201 (0%)]	Loss: 0.453754
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 231 Norm Difference for worker 129 is 0.972713
INFO:root:FL Epoch: 231 Done on worker:129
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :320
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.461001
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.459678
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 231 Norm Difference for worker 320 is 1.01221
INFO:root:FL Epoch: 231 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1346
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491389
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415012
INFO:root:FL Epoch: 231 Norm Difference for worker 1346 is 0.895718
INFO:root:FL Epoch: 231 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :124
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.762355
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.468653
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 231 Norm Difference for worker 124 is 0.964247
INFO:root:FL Epoch: 231 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1736
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763216
INFO:root:Worker: 1736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391285
INFO:root:FL Epoch: 231 Norm Difference for worker 1736 is 0.950731
INFO:root:FL Epoch: 231 Done on worker:1736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1616
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458841
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557413
INFO:root:FL Epoch: 231 Norm Difference for worker 1616 is 0.958707
INFO:root:FL Epoch: 231 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 231 Training on worker :1905
INFO:root:FL Epoch: 231 Using Learning rate : 0.03154964671094999 
INFO:root:FL Epoch: 231 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.331735
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350742
INFO:root:FL Epoch: 231 Norm Difference for worker 1905 is 0.870477
INFO:root:FL Epoch: 231 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 231 Ends   ===================
INFO:root:Epoch:231 Global Model Test Loss:0.4808049237026888 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:231 Global Model Backdoor Test Loss:0.32112180689970654                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 232 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 232 Workers Selected : [1343, 469, 1642, 1238, 1114, 788, 936, 377, 528, 36]
INFO:root:FL Epoch: 232 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 232 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 232 Training on worker :1343
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415265
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447185
INFO:root:FL Epoch: 232 Norm Difference for worker 1343 is 0.898986
INFO:root:FL Epoch: 232 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :469
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496055
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572958
INFO:root:FL Epoch: 232 Norm Difference for worker 469 is 0.97644
INFO:root:FL Epoch: 232 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1642
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626382
INFO:root:Worker: 1642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421050
INFO:root:FL Epoch: 232 Norm Difference for worker 1642 is 1.045096
INFO:root:FL Epoch: 232 Done on worker:1642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1238
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591587
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566628
INFO:root:FL Epoch: 232 Norm Difference for worker 1238 is 1.027246
INFO:root:FL Epoch: 232 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :1114
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541812
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617003
INFO:root:FL Epoch: 232 Norm Difference for worker 1114 is 1.119894
INFO:root:FL Epoch: 232 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :788
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426542
INFO:root:Worker: 788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498375
INFO:root:FL Epoch: 232 Norm Difference for worker 788 is 1.03086
INFO:root:FL Epoch: 232 Done on worker:788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :936
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686909
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526742
INFO:root:FL Epoch: 232 Norm Difference for worker 936 is 1.033462
INFO:root:FL Epoch: 232 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :377
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736793
INFO:root:Worker: 377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509360
INFO:root:FL Epoch: 232 Norm Difference for worker 377 is 1.061356
INFO:root:FL Epoch: 232 Done on worker:377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :528
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645437
INFO:root:Worker: 528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403962
INFO:root:FL Epoch: 232 Norm Difference for worker 528 is 1.109884
INFO:root:FL Epoch: 232 Done on worker:528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 232 Training on worker :36
INFO:root:FL Epoch: 232 Using Learning rate : 0.03148654741752809 
INFO:root:FL Epoch: 232 Normal Training
INFO:root:Worker: 36 Train Epoch: 0 [0/201 (0%)]	Loss: 0.358754
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 36 Train Epoch: 1 [0/201 (0%)]	Loss: 0.547202
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 232 Norm Difference for worker 36 is 1.069271
INFO:root:FL Epoch: 232 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1343
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 232 Ends   ===================
INFO:root:Epoch:232 Global Model Test Loss:0.48417843790615306 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:232 Global Model Backdoor Test Loss:0.3240039423108101                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 233 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 233 Workers Selected : [778, 1186, 81, 1407, 1252, 174, 1613, 698, 583, 220]
INFO:root:FL Epoch: 233 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 233 Num points on workers: [200 200 201 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 233 Training on worker :778
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579669
INFO:root:Worker: 778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560897
INFO:root:FL Epoch: 233 Norm Difference for worker 778 is 1.320347
INFO:root:FL Epoch: 233 Done on worker:778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1186
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660182
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432729
INFO:root:FL Epoch: 233 Norm Difference for worker 1186 is 1.15877
INFO:root:FL Epoch: 233 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :81
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.854835
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.500475
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 233 Norm Difference for worker 81 is 1.2252
INFO:root:FL Epoch: 233 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1407
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408785
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358212
INFO:root:FL Epoch: 233 Norm Difference for worker 1407 is 1.242631
INFO:root:FL Epoch: 233 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1252
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1252 Train Epoch: 0 [0/200 (0%)]	Loss: 0.760802
INFO:root:Worker: 1252 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455737
INFO:root:FL Epoch: 233 Norm Difference for worker 1252 is 1.231773
INFO:root:FL Epoch: 233 Done on worker:1252
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :174
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 0.715908
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.495077
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 233 Norm Difference for worker 174 is 1.225405
INFO:root:FL Epoch: 233 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :1613
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613057
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315197
INFO:root:FL Epoch: 233 Norm Difference for worker 1613 is 1.182782
INFO:root:FL Epoch: 233 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :698
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486210
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392852
INFO:root:FL Epoch: 233 Norm Difference for worker 698 is 1.30842
INFO:root:FL Epoch: 233 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :583
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508026
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636599
INFO:root:FL Epoch: 233 Norm Difference for worker 583 is 1.217989
INFO:root:FL Epoch: 233 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 233 Training on worker :220
INFO:root:FL Epoch: 233 Using Learning rate : 0.031423574322693035 
INFO:root:FL Epoch: 233 Normal Training
INFO:root:Worker: 220 Train Epoch: 0 [0/201 (0%)]	Loss: 0.496557
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 220 Train Epoch: 1 [0/201 (0%)]	Loss: 0.696258
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 233 Norm Difference for worker 220 is 1.28236
INFO:root:FL Epoch: 233 Done on worker:220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1186
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 233 Ends   ===================
INFO:root:Epoch:233 Global Model Test Loss:0.5009928783949684 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:233 Global Model Backdoor Test Loss:0.3612719277540843                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 234 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 234 Workers Selected : [1156, 1523, 1918, 1420, 1146, 679, 124, 1799, 803, 836]
INFO:root:FL Epoch: 234 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 234 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 234 Training on worker :1156
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1156 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546026
INFO:root:Worker: 1156 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438768
INFO:root:FL Epoch: 234 Norm Difference for worker 1156 is 0.986242
INFO:root:FL Epoch: 234 Done on worker:1156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1523
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482466
INFO:root:Worker: 1523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.755786
INFO:root:FL Epoch: 234 Norm Difference for worker 1523 is 0.974666
INFO:root:FL Epoch: 234 Done on worker:1523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1918
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539959
INFO:root:Worker: 1918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376361
INFO:root:FL Epoch: 234 Norm Difference for worker 1918 is 0.955779
INFO:root:FL Epoch: 234 Done on worker:1918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1420
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645761
INFO:root:Worker: 1420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400351
INFO:root:FL Epoch: 234 Norm Difference for worker 1420 is 0.975326
INFO:root:FL Epoch: 234 Done on worker:1420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1146
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1146 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762283
INFO:root:Worker: 1146 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619521
INFO:root:FL Epoch: 234 Norm Difference for worker 1146 is 0.958883
INFO:root:FL Epoch: 234 Done on worker:1146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :679
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456767
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291014
INFO:root:FL Epoch: 234 Norm Difference for worker 679 is 1.002613
INFO:root:FL Epoch: 234 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :124
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 124 Train Epoch: 0 [0/201 (0%)]	Loss: 0.672155
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 124 Train Epoch: 1 [0/201 (0%)]	Loss: 0.565060
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 234 Norm Difference for worker 124 is 1.0035
INFO:root:FL Epoch: 234 Done on worker:124
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :1799
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 1799 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485264
INFO:root:Worker: 1799 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374287
INFO:root:FL Epoch: 234 Norm Difference for worker 1799 is 0.933231
INFO:root:FL Epoch: 234 Done on worker:1799
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :803
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476833
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618652
INFO:root:FL Epoch: 234 Norm Difference for worker 803 is 0.92153
INFO:root:FL Epoch: 234 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 234 Training on worker :836
INFO:root:FL Epoch: 234 Using Learning rate : 0.03136072717404764 
INFO:root:FL Epoch: 234 Normal Training
INFO:root:Worker: 836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666695
INFO:root:Worker: 836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568070
INFO:root:FL Epoch: 234 Norm Difference for worker 836 is 0.923759
INFO:root:FL Epoch: 234 Done on worker:836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 836
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 234 Ends   ===================
INFO:root:Epoch:234 Global Model Test Loss:0.5111652454909157 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:234 Global Model Backdoor Test Loss:0.31131688753763836                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 235 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 235 Workers Selected : [241, 775, 456, 1916, 28, 1890, 1777, 1368, 615, 1249]
INFO:root:FL Epoch: 235 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 235 Num points on workers: [201 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 235 Training on worker :241
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 241 Train Epoch: 0 [0/201 (0%)]	Loss: 0.948891
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 241 Train Epoch: 1 [0/201 (0%)]	Loss: 0.654000
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 235 Norm Difference for worker 241 is 1.082168
INFO:root:FL Epoch: 235 Done on worker:241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :775
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602485
INFO:root:Worker: 775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305798
INFO:root:FL Epoch: 235 Norm Difference for worker 775 is 1.035471
INFO:root:FL Epoch: 235 Done on worker:775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :456
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463006
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373747
INFO:root:FL Epoch: 235 Norm Difference for worker 456 is 0.99862
INFO:root:FL Epoch: 235 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1916
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510453
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485538
INFO:root:FL Epoch: 235 Norm Difference for worker 1916 is 0.992813
INFO:root:FL Epoch: 235 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :28
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.539241
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.461605
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 235 Norm Difference for worker 28 is 0.932941
INFO:root:FL Epoch: 235 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1890
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526862
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662902
INFO:root:FL Epoch: 235 Norm Difference for worker 1890 is 0.994636
INFO:root:FL Epoch: 235 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1777
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.889689
INFO:root:Worker: 1777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418759
INFO:root:FL Epoch: 235 Norm Difference for worker 1777 is 1.031205
INFO:root:FL Epoch: 235 Done on worker:1777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1368
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750599
INFO:root:Worker: 1368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558476
INFO:root:FL Epoch: 235 Norm Difference for worker 1368 is 1.011307
INFO:root:FL Epoch: 235 Done on worker:1368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :615
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 615 Train Epoch: 0 [0/200 (0%)]	Loss: 0.789324
INFO:root:Worker: 615 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511865
INFO:root:FL Epoch: 235 Norm Difference for worker 615 is 0.994919
INFO:root:FL Epoch: 235 Done on worker:615
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 235 Training on worker :1249
INFO:root:FL Epoch: 235 Using Learning rate : 0.031298005719699554 
INFO:root:FL Epoch: 235 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710859
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526381
INFO:root:FL Epoch: 235 Norm Difference for worker 1249 is 1.050013
INFO:root:FL Epoch: 235 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 28
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 235 Ends   ===================
INFO:root:Epoch:235 Global Model Test Loss:0.5258050105151009 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:235 Global Model Backdoor Test Loss:0.43406278391679126                             and Backdoor Test Accuracy:78.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 236 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 236 Workers Selected : [756, 291, 147, 1733, 178, 42, 3, 1153, 1239, 1698]
INFO:root:FL Epoch: 236 Fraction of points on each worker in this round: [0.09975062 0.10024938 0.10024938 0.09975062 0.10024938 0.10024938
 0.10024938 0.09975062 0.09975062 0.09975062]
INFO:root:FL Epoch: 236 Num points on workers: [200 201 201 200 201 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 236 Training on worker :756
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607311
INFO:root:Worker: 756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380301
INFO:root:FL Epoch: 236 Norm Difference for worker 756 is 0.954958
INFO:root:FL Epoch: 236 Done on worker:756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :291
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 291 Train Epoch: 0 [0/201 (0%)]	Loss: 0.626504
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 291 Train Epoch: 1 [0/201 (0%)]	Loss: 0.630455
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 291 is 0.94887
INFO:root:FL Epoch: 236 Done on worker:291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :147
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 147 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503992
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 147 Train Epoch: 1 [0/201 (0%)]	Loss: 0.546534
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 147 is 0.92738
INFO:root:FL Epoch: 236 Done on worker:147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1733
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567763
INFO:root:Worker: 1733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511226
INFO:root:FL Epoch: 236 Norm Difference for worker 1733 is 0.956527
INFO:root:FL Epoch: 236 Done on worker:1733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :178
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 178 Train Epoch: 0 [0/201 (0%)]	Loss: 0.535125
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 178 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505532
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 178 is 1.012302
INFO:root:FL Epoch: 236 Done on worker:178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :42
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.359835
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.815773
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 42 is 0.870693
INFO:root:FL Epoch: 236 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :3
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 3 Train Epoch: 0 [0/201 (0%)]	Loss: 0.640110
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 3 Train Epoch: 1 [0/201 (0%)]	Loss: 0.523140
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 236 Norm Difference for worker 3 is 0.986721
INFO:root:FL Epoch: 236 Done on worker:3
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1153
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1153 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705650
INFO:root:Worker: 1153 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336299
INFO:root:FL Epoch: 236 Norm Difference for worker 1153 is 0.97416
INFO:root:FL Epoch: 236 Done on worker:1153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1239
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470407
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618956
INFO:root:FL Epoch: 236 Norm Difference for worker 1239 is 0.978094
INFO:root:FL Epoch: 236 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 236 Training on worker :1698
INFO:root:FL Epoch: 236 Using Learning rate : 0.03123540970826015 
INFO:root:FL Epoch: 236 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511858
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353189
INFO:root:FL Epoch: 236 Norm Difference for worker 1698 is 0.973089
INFO:root:FL Epoch: 236 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 236 Ends   ===================
INFO:root:Epoch:236 Global Model Test Loss:0.5092319302699145 and Test Accuracy:75.0 
INFO:root:Epoch:236 Global Model Backdoor Test Loss:0.3332255457838376                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 237 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 237 Workers Selected : [1370, 1658, 708, 759, 918, 1219, 1148, 1159, 682, 546]
INFO:root:FL Epoch: 237 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 237 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 237 Training on worker :1370
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573645
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507912
INFO:root:FL Epoch: 237 Norm Difference for worker 1370 is 1.005692
INFO:root:FL Epoch: 237 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1658
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518592
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511775
INFO:root:FL Epoch: 237 Norm Difference for worker 1658 is 0.983428
INFO:root:FL Epoch: 237 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :708
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528651
INFO:root:Worker: 708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.329081
INFO:root:FL Epoch: 237 Norm Difference for worker 708 is 0.913598
INFO:root:FL Epoch: 237 Done on worker:708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :759
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 759 Train Epoch: 0 [0/200 (0%)]	Loss: 1.097481
INFO:root:Worker: 759 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546237
INFO:root:FL Epoch: 237 Norm Difference for worker 759 is 0.993087
INFO:root:FL Epoch: 237 Done on worker:759
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :918
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701169
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530938
INFO:root:FL Epoch: 237 Norm Difference for worker 918 is 1.007062
INFO:root:FL Epoch: 237 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1219
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686416
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586213
INFO:root:FL Epoch: 237 Norm Difference for worker 1219 is 1.023488
INFO:root:FL Epoch: 237 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1148
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464958
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583718
INFO:root:FL Epoch: 237 Norm Difference for worker 1148 is 1.012303
INFO:root:FL Epoch: 237 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :1159
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 1159 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637015
INFO:root:Worker: 1159 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346308
INFO:root:FL Epoch: 237 Norm Difference for worker 1159 is 0.947303
INFO:root:FL Epoch: 237 Done on worker:1159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :682
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766149
INFO:root:Worker: 682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579658
INFO:root:FL Epoch: 237 Norm Difference for worker 682 is 1.003251
INFO:root:FL Epoch: 237 Done on worker:682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 237 Training on worker :546
INFO:root:FL Epoch: 237 Using Learning rate : 0.031172938888843628 
INFO:root:FL Epoch: 237 Normal Training
INFO:root:Worker: 546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464864
INFO:root:Worker: 546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344209
INFO:root:FL Epoch: 237 Norm Difference for worker 546 is 0.958631
INFO:root:FL Epoch: 237 Done on worker:546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 708
INFO:root:Norm of Aggregated Model: 5154.9912109375
INFO:root:Aggregating After Defense
INFO:root:================FL round 237 Ends   ===================
INFO:root:Epoch:237 Global Model Test Loss:0.5223495083696702 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:237 Global Model Backdoor Test Loss:0.3406430358688037                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 238 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 238 Workers Selected : [234, 54, 1627, 925, 1099, 1451, 413, 99, 692, 632]
INFO:root:FL Epoch: 238 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 238 Num points on workers: [201 201 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 238 Training on worker :234
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 234 Train Epoch: 0 [0/201 (0%)]	Loss: 0.660876
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 234 Train Epoch: 1 [0/201 (0%)]	Loss: 0.470714
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 238 Norm Difference for worker 234 is 1.098001
INFO:root:FL Epoch: 238 Done on worker:234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :54
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 54 Train Epoch: 0 [0/201 (0%)]	Loss: 0.574028
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 54 Train Epoch: 1 [0/201 (0%)]	Loss: 0.452598
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 238 Norm Difference for worker 54 is 1.004585
INFO:root:FL Epoch: 238 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1627
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520833
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429804
INFO:root:FL Epoch: 238 Norm Difference for worker 1627 is 0.982249
INFO:root:FL Epoch: 238 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :925
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324342
INFO:root:Worker: 925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312782
INFO:root:FL Epoch: 238 Norm Difference for worker 925 is 0.830817
INFO:root:FL Epoch: 238 Done on worker:925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1099
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1099 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569238
INFO:root:Worker: 1099 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539162
INFO:root:FL Epoch: 238 Norm Difference for worker 1099 is 1.036775
INFO:root:FL Epoch: 238 Done on worker:1099
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :1451
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 1451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387485
INFO:root:Worker: 1451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432994
INFO:root:FL Epoch: 238 Norm Difference for worker 1451 is 1.00703
INFO:root:FL Epoch: 238 Done on worker:1451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :413
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467942
INFO:root:Worker: 413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472117
INFO:root:FL Epoch: 238 Norm Difference for worker 413 is 1.00329
INFO:root:FL Epoch: 238 Done on worker:413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :99
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 99 Train Epoch: 0 [0/201 (0%)]	Loss: 0.531479
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 99 Train Epoch: 1 [0/201 (0%)]	Loss: 0.370163
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 238 Norm Difference for worker 99 is 0.960267
INFO:root:FL Epoch: 238 Done on worker:99
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :692
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779017
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547783
INFO:root:FL Epoch: 238 Norm Difference for worker 692 is 1.014771
INFO:root:FL Epoch: 238 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 238 Training on worker :632
INFO:root:FL Epoch: 238 Using Learning rate : 0.031110593011065942 
INFO:root:FL Epoch: 238 Normal Training
INFO:root:Worker: 632 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505268
INFO:root:Worker: 632 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468918
INFO:root:FL Epoch: 238 Norm Difference for worker 632 is 0.96538
INFO:root:FL Epoch: 238 Done on worker:632
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 925
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 238 Ends   ===================
INFO:root:Epoch:238 Global Model Test Loss:0.5631263887181002 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:238 Global Model Backdoor Test Loss:0.4522370944420497                             and Backdoor Test Accuracy:78.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 239 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 239 Workers Selected : [1944, 1724, 1779, 803, 1839, 1224, 1020, 1562, 1284, 847]
INFO:root:FL Epoch: 239 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 239 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 239 Training on worker :1944
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759013
INFO:root:Worker: 1944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316978
INFO:root:FL Epoch: 239 Norm Difference for worker 1944 is 1.142046
INFO:root:FL Epoch: 239 Done on worker:1944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1724
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419076
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683561
INFO:root:FL Epoch: 239 Norm Difference for worker 1724 is 1.327374
INFO:root:FL Epoch: 239 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1779
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772740
INFO:root:Worker: 1779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448365
INFO:root:FL Epoch: 239 Norm Difference for worker 1779 is 1.281866
INFO:root:FL Epoch: 239 Done on worker:1779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :803
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410218
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527895
INFO:root:FL Epoch: 239 Norm Difference for worker 803 is 1.231786
INFO:root:FL Epoch: 239 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1839
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588025
INFO:root:Worker: 1839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423079
INFO:root:FL Epoch: 239 Norm Difference for worker 1839 is 1.259662
INFO:root:FL Epoch: 239 Done on worker:1839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1224
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1224 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702775
INFO:root:Worker: 1224 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326524
INFO:root:FL Epoch: 239 Norm Difference for worker 1224 is 1.248385
INFO:root:FL Epoch: 239 Done on worker:1224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1020
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1020 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718095
INFO:root:Worker: 1020 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301710
INFO:root:FL Epoch: 239 Norm Difference for worker 1020 is 1.229004
INFO:root:FL Epoch: 239 Done on worker:1020
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1562
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.817050
INFO:root:Worker: 1562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593358
INFO:root:FL Epoch: 239 Norm Difference for worker 1562 is 1.265667
INFO:root:FL Epoch: 239 Done on worker:1562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :1284
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 1284 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539247
INFO:root:Worker: 1284 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496968
INFO:root:FL Epoch: 239 Norm Difference for worker 1284 is 1.254403
INFO:root:FL Epoch: 239 Done on worker:1284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 239 Training on worker :847
INFO:root:FL Epoch: 239 Using Learning rate : 0.03104837182504381 
INFO:root:FL Epoch: 239 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411330
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362224
INFO:root:FL Epoch: 239 Norm Difference for worker 847 is 1.091254
INFO:root:FL Epoch: 239 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1944
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 239 Ends   ===================
INFO:root:Epoch:239 Global Model Test Loss:0.5282863098032334 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:239 Global Model Backdoor Test Loss:0.3751070449749629                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 240 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 240 Workers Selected : [1700, 1947, 227, 1223, 1724, 931, 941, 1328, 768, 1319]
INFO:root:FL Epoch: 240 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 240 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 240 Training on worker :1700
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502071
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519854
INFO:root:FL Epoch: 240 Norm Difference for worker 1700 is 1.055962
INFO:root:FL Epoch: 240 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1947
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608848
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543115
INFO:root:FL Epoch: 240 Norm Difference for worker 1947 is 1.014652
INFO:root:FL Epoch: 240 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :227
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.663876
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.339427
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 240 Norm Difference for worker 227 is 1.075209
INFO:root:FL Epoch: 240 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1223
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1223 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628152
INFO:root:Worker: 1223 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432340
INFO:root:FL Epoch: 240 Norm Difference for worker 1223 is 1.071566
INFO:root:FL Epoch: 240 Done on worker:1223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1724
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.917449
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400024
INFO:root:FL Epoch: 240 Norm Difference for worker 1724 is 1.148298
INFO:root:FL Epoch: 240 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :931
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392989
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471320
INFO:root:FL Epoch: 240 Norm Difference for worker 931 is 1.122192
INFO:root:FL Epoch: 240 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :941
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628888
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374693
INFO:root:FL Epoch: 240 Norm Difference for worker 941 is 1.001929
INFO:root:FL Epoch: 240 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1328
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1328 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606406
INFO:root:Worker: 1328 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382712
INFO:root:FL Epoch: 240 Norm Difference for worker 1328 is 1.020457
INFO:root:FL Epoch: 240 Done on worker:1328
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :768
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479135
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527018
INFO:root:FL Epoch: 240 Norm Difference for worker 768 is 1.0445
INFO:root:FL Epoch: 240 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 240 Training on worker :1319
INFO:root:FL Epoch: 240 Using Learning rate : 0.030986275081393722 
INFO:root:FL Epoch: 240 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698378
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520030
INFO:root:FL Epoch: 240 Norm Difference for worker 1319 is 1.134994
INFO:root:FL Epoch: 240 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 941
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 240 Ends   ===================
INFO:root:Epoch:240 Global Model Test Loss:0.5176877344355864 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:240 Global Model Backdoor Test Loss:0.40496950844923657                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 241 Begins ===================
INFO:root:FL Epoch: 241 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 241 Workers Selected : [0, 569, 14, 452, 1546, 1283, 1017, 977, 829, 1129]
INFO:root:FL Epoch: 241 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 241 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 241 Training on worker :0
INFO:root:FL Epoch: 241 Using Learning rate : 0.006184860506246187 
INFO:root:FL Epoch: 241 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.202831
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340647
INFO:root:FL Epoch: 241 Worker: 0 Backdoor Test Loss: 0.35088257988293964 Backdoor Test Accuracy: 85.0
INFO:root:FL Epoch: 241 Worker: 0 Backdoor Train Loss: 0.2869716718792915 Backdoor Train Accuracy: 90.5
INFO:root:FL Epoch: 241 Norm Difference for worker 0 is 0.199178
INFO:root:FL Epoch: 241 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :569
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456362
INFO:root:Worker: 569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383144
INFO:root:FL Epoch: 241 Norm Difference for worker 569 is 1.014329
INFO:root:FL Epoch: 241 Done on worker:569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :14
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.552005
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415182
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 241 Norm Difference for worker 14 is 0.971988
INFO:root:FL Epoch: 241 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :452
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420641
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341966
INFO:root:FL Epoch: 241 Norm Difference for worker 452 is 0.941301
INFO:root:FL Epoch: 241 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1546
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500690
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444199
INFO:root:FL Epoch: 241 Norm Difference for worker 1546 is 0.930533
INFO:root:FL Epoch: 241 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1283
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1283 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453926
INFO:root:Worker: 1283 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529501
INFO:root:FL Epoch: 241 Norm Difference for worker 1283 is 0.983204
INFO:root:FL Epoch: 241 Done on worker:1283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1017
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1017 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506260
INFO:root:Worker: 1017 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452372
INFO:root:FL Epoch: 241 Norm Difference for worker 1017 is 0.996323
INFO:root:FL Epoch: 241 Done on worker:1017
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :977
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393108
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544163
INFO:root:FL Epoch: 241 Norm Difference for worker 977 is 1.022199
INFO:root:FL Epoch: 241 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :829
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536551
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313010
INFO:root:FL Epoch: 241 Norm Difference for worker 829 is 0.995498
INFO:root:FL Epoch: 241 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 241 Training on worker :1129
INFO:root:FL Epoch: 241 Using Learning rate : 0.030924302531230935 
INFO:root:FL Epoch: 241 Normal Training
INFO:root:Worker: 1129 Train Epoch: 0 [0/200 (0%)]	Loss: 0.284863
INFO:root:Worker: 1129 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391107
INFO:root:FL Epoch: 241 Norm Difference for worker 1129 is 0.955162
INFO:root:FL Epoch: 241 Done on worker:1129
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 241 Ends   ===================
INFO:root:Epoch:241 Global Model Test Loss:0.5183354370734271 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:241 Global Model Backdoor Test Loss:0.35088257988293964                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 242 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 242 Workers Selected : [674, 306, 1588, 405, 739, 406, 450, 1851, 796, 1779]
INFO:root:FL Epoch: 242 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 242 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 242 Training on worker :674
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470374
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393004
INFO:root:FL Epoch: 242 Norm Difference for worker 674 is 1.106899
INFO:root:FL Epoch: 242 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :306
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.460700
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.504588
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 242 Norm Difference for worker 306 is 1.066487
INFO:root:FL Epoch: 242 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1588
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626139
INFO:root:Worker: 1588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507220
INFO:root:FL Epoch: 242 Norm Difference for worker 1588 is 1.032729
INFO:root:FL Epoch: 242 Done on worker:1588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :405
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447455
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386533
INFO:root:FL Epoch: 242 Norm Difference for worker 405 is 1.056985
INFO:root:FL Epoch: 242 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :739
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 739 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693543
INFO:root:Worker: 739 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524840
INFO:root:FL Epoch: 242 Norm Difference for worker 739 is 1.118609
INFO:root:FL Epoch: 242 Done on worker:739
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :406
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580293
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.789162
INFO:root:FL Epoch: 242 Norm Difference for worker 406 is 1.077622
INFO:root:FL Epoch: 242 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :450
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590759
INFO:root:Worker: 450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457462
INFO:root:FL Epoch: 242 Norm Difference for worker 450 is 0.964247
INFO:root:FL Epoch: 242 Done on worker:450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1851
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507312
INFO:root:Worker: 1851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478040
INFO:root:FL Epoch: 242 Norm Difference for worker 1851 is 1.050523
INFO:root:FL Epoch: 242 Done on worker:1851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :796
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564157
INFO:root:Worker: 796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526273
INFO:root:FL Epoch: 242 Norm Difference for worker 796 is 1.026711
INFO:root:FL Epoch: 242 Done on worker:796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 242 Training on worker :1779
INFO:root:FL Epoch: 242 Using Learning rate : 0.030862453926168473 
INFO:root:FL Epoch: 242 Normal Training
INFO:root:Worker: 1779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482121
INFO:root:Worker: 1779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483088
INFO:root:FL Epoch: 242 Norm Difference for worker 1779 is 1.113368
INFO:root:FL Epoch: 242 Done on worker:1779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 450
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 242 Ends   ===================
INFO:root:Epoch:242 Global Model Test Loss:0.5157090986476225 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:242 Global Model Backdoor Test Loss:0.3184071828921636                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 243 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 243 Workers Selected : [1257, 1407, 1052, 1647, 854, 1368, 872, 884, 1666, 1648]
INFO:root:FL Epoch: 243 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 243 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 243 Training on worker :1257
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1257 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414748
INFO:root:Worker: 1257 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444941
INFO:root:FL Epoch: 243 Norm Difference for worker 1257 is 1.015519
INFO:root:FL Epoch: 243 Done on worker:1257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1407
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733796
INFO:root:Worker: 1407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437266
INFO:root:FL Epoch: 243 Norm Difference for worker 1407 is 1.050897
INFO:root:FL Epoch: 243 Done on worker:1407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1052
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1052 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566324
INFO:root:Worker: 1052 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345053
INFO:root:FL Epoch: 243 Norm Difference for worker 1052 is 0.938617
INFO:root:FL Epoch: 243 Done on worker:1052
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1647
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563995
INFO:root:Worker: 1647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485601
INFO:root:FL Epoch: 243 Norm Difference for worker 1647 is 1.155242
INFO:root:FL Epoch: 243 Done on worker:1647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :854
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462924
INFO:root:Worker: 854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408541
INFO:root:FL Epoch: 243 Norm Difference for worker 854 is 1.064114
INFO:root:FL Epoch: 243 Done on worker:854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1368
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424175
INFO:root:Worker: 1368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424551
INFO:root:FL Epoch: 243 Norm Difference for worker 1368 is 1.030859
INFO:root:FL Epoch: 243 Done on worker:1368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :872
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.728240
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322505
INFO:root:FL Epoch: 243 Norm Difference for worker 872 is 0.994688
INFO:root:FL Epoch: 243 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :884
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 884 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444648
INFO:root:Worker: 884 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533559
INFO:root:FL Epoch: 243 Norm Difference for worker 884 is 1.025643
INFO:root:FL Epoch: 243 Done on worker:884
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1666
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.958960
INFO:root:Worker: 1666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593043
INFO:root:FL Epoch: 243 Norm Difference for worker 1666 is 1.037753
INFO:root:FL Epoch: 243 Done on worker:1666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 243 Training on worker :1648
INFO:root:FL Epoch: 243 Using Learning rate : 0.03080072901831614 
INFO:root:FL Epoch: 243 Normal Training
INFO:root:Worker: 1648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657340
INFO:root:Worker: 1648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503538
INFO:root:FL Epoch: 243 Norm Difference for worker 1648 is 1.010344
INFO:root:FL Epoch: 243 Done on worker:1648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1052
INFO:root:Norm of Aggregated Model: 5154.99169921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 243 Ends   ===================
INFO:root:Epoch:243 Global Model Test Loss:0.5113852129263037 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:243 Global Model Backdoor Test Loss:0.3188496381044388                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 244 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 244 Workers Selected : [1672, 1571, 249, 1770, 189, 364, 98, 658, 1513, 212]
INFO:root:FL Epoch: 244 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.1002994 0.0998004 0.1002994
 0.0998004 0.0998004 0.1002994]
INFO:root:FL Epoch: 244 Num points on workers: [200 200 201 200 201 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 244 Training on worker :1672
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568784
INFO:root:Worker: 1672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400759
INFO:root:FL Epoch: 244 Norm Difference for worker 1672 is 0.999814
INFO:root:FL Epoch: 244 Done on worker:1672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1571
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683251
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476448
INFO:root:FL Epoch: 244 Norm Difference for worker 1571 is 1.034337
INFO:root:FL Epoch: 244 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :249
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 249 Train Epoch: 0 [0/201 (0%)]	Loss: 0.423304
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 249 Train Epoch: 1 [0/201 (0%)]	Loss: 0.363028
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 249 is 0.997841
INFO:root:FL Epoch: 244 Done on worker:249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1770
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412306
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411382
INFO:root:FL Epoch: 244 Norm Difference for worker 1770 is 1.033125
INFO:root:FL Epoch: 244 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :189
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 189 Train Epoch: 0 [0/201 (0%)]	Loss: 0.397445
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 189 Train Epoch: 1 [0/201 (0%)]	Loss: 0.448327
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 189 is 0.992195
INFO:root:FL Epoch: 244 Done on worker:189
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :364
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469652
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299145
INFO:root:FL Epoch: 244 Norm Difference for worker 364 is 0.986912
INFO:root:FL Epoch: 244 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :98
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.726587
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.495101
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 98 is 1.038118
INFO:root:FL Epoch: 244 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :658
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710504
INFO:root:Worker: 658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670877
INFO:root:FL Epoch: 244 Norm Difference for worker 658 is 1.061749
INFO:root:FL Epoch: 244 Done on worker:658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :1513
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 1513 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441503
INFO:root:Worker: 1513 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346252
INFO:root:FL Epoch: 244 Norm Difference for worker 1513 is 1.000701
INFO:root:FL Epoch: 244 Done on worker:1513
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 244 Training on worker :212
INFO:root:FL Epoch: 244 Using Learning rate : 0.03073912756027951 
INFO:root:FL Epoch: 244 Normal Training
INFO:root:Worker: 212 Train Epoch: 0 [0/201 (0%)]	Loss: 0.643511
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 212 Train Epoch: 1 [0/201 (0%)]	Loss: 0.544852
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 244 Norm Difference for worker 212 is 1.01141
INFO:root:FL Epoch: 244 Done on worker:212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 249
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 244 Ends   ===================
INFO:root:Epoch:244 Global Model Test Loss:0.5103592083734625 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:244 Global Model Backdoor Test Loss:0.35845932612816495                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 245 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 245 Workers Selected : [1438, 1860, 361, 342, 752, 1125, 1028, 492, 1155, 639]
INFO:root:FL Epoch: 245 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 245 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 245 Training on worker :1438
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596109
INFO:root:Worker: 1438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404115
INFO:root:FL Epoch: 245 Norm Difference for worker 1438 is 1.02
INFO:root:FL Epoch: 245 Done on worker:1438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1860
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510106
INFO:root:Worker: 1860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291350
INFO:root:FL Epoch: 245 Norm Difference for worker 1860 is 0.969649
INFO:root:FL Epoch: 245 Done on worker:1860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :361
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.369573
INFO:root:Worker: 361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446038
INFO:root:FL Epoch: 245 Norm Difference for worker 361 is 1.035662
INFO:root:FL Epoch: 245 Done on worker:361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :342
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664281
INFO:root:Worker: 342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636154
INFO:root:FL Epoch: 245 Norm Difference for worker 342 is 1.038836
INFO:root:FL Epoch: 245 Done on worker:342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :752
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427814
INFO:root:Worker: 752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449384
INFO:root:FL Epoch: 245 Norm Difference for worker 752 is 0.975405
INFO:root:FL Epoch: 245 Done on worker:752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1125
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1125 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466712
INFO:root:Worker: 1125 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513207
INFO:root:FL Epoch: 245 Norm Difference for worker 1125 is 0.972385
INFO:root:FL Epoch: 245 Done on worker:1125
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1028
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1028 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645471
INFO:root:Worker: 1028 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527595
INFO:root:FL Epoch: 245 Norm Difference for worker 1028 is 0.945921
INFO:root:FL Epoch: 245 Done on worker:1028
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :492
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 492 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408299
INFO:root:Worker: 492 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462845
INFO:root:FL Epoch: 245 Norm Difference for worker 492 is 0.946291
INFO:root:FL Epoch: 245 Done on worker:492
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :1155
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 1155 Train Epoch: 0 [0/200 (0%)]	Loss: 0.831352
INFO:root:Worker: 1155 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699318
INFO:root:FL Epoch: 245 Norm Difference for worker 1155 is 1.0631
INFO:root:FL Epoch: 245 Done on worker:1155
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 245 Training on worker :639
INFO:root:FL Epoch: 245 Using Learning rate : 0.030677649305158945 
INFO:root:FL Epoch: 245 Normal Training
INFO:root:Worker: 639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434143
INFO:root:Worker: 639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444724
INFO:root:FL Epoch: 245 Norm Difference for worker 639 is 0.881755
INFO:root:FL Epoch: 245 Done on worker:639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 639
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 245 Ends   ===================
INFO:root:Epoch:245 Global Model Test Loss:0.5112620574586532 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:245 Global Model Backdoor Test Loss:0.36501728494962055                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 246 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 246 Workers Selected : [1696, 913, 1294, 1276, 986, 100, 1524, 139, 1848, 899]
INFO:root:FL Epoch: 246 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 246 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 246 Training on worker :1696
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405881
INFO:root:Worker: 1696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562948
INFO:root:FL Epoch: 246 Norm Difference for worker 1696 is 1.058726
INFO:root:FL Epoch: 246 Done on worker:1696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :913
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687390
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458485
INFO:root:FL Epoch: 246 Norm Difference for worker 913 is 1.315681
INFO:root:FL Epoch: 246 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1294
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595115
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337975
INFO:root:FL Epoch: 246 Norm Difference for worker 1294 is 1.26404
INFO:root:FL Epoch: 246 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1276
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1276 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622016
INFO:root:Worker: 1276 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492993
INFO:root:FL Epoch: 246 Norm Difference for worker 1276 is 1.262475
INFO:root:FL Epoch: 246 Done on worker:1276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :986
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514505
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600828
INFO:root:FL Epoch: 246 Norm Difference for worker 986 is 1.320564
INFO:root:FL Epoch: 246 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :100
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 100 Train Epoch: 0 [0/201 (0%)]	Loss: 0.606173
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 100 Train Epoch: 1 [0/201 (0%)]	Loss: 0.314542
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 246 Norm Difference for worker 100 is 1.192216
INFO:root:FL Epoch: 246 Done on worker:100
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1524
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487291
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539260
INFO:root:FL Epoch: 246 Norm Difference for worker 1524 is 1.200989
INFO:root:FL Epoch: 246 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :139
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 139 Train Epoch: 0 [0/201 (0%)]	Loss: 0.556661
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 139 Train Epoch: 1 [0/201 (0%)]	Loss: 0.501125
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 246 Norm Difference for worker 139 is 1.220567
INFO:root:FL Epoch: 246 Done on worker:139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :1848
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 1848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346117
INFO:root:Worker: 1848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369300
INFO:root:FL Epoch: 246 Norm Difference for worker 1848 is 1.082172
INFO:root:FL Epoch: 246 Done on worker:1848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 246 Training on worker :899
INFO:root:FL Epoch: 246 Using Learning rate : 0.03061629400654863 
INFO:root:FL Epoch: 246 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505643
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585995
INFO:root:FL Epoch: 246 Norm Difference for worker 899 is 1.250918
INFO:root:FL Epoch: 246 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1848
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 246 Ends   ===================
INFO:root:Epoch:246 Global Model Test Loss:0.5014147074783549 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:246 Global Model Backdoor Test Loss:0.4075801720221837                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 247 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 247 Workers Selected : [1365, 510, 1344, 1915, 1823, 1825, 1711, 692, 522, 1313]
INFO:root:FL Epoch: 247 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 247 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 247 Training on worker :1365
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347478
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607593
INFO:root:FL Epoch: 247 Norm Difference for worker 1365 is 1.097476
INFO:root:FL Epoch: 247 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :510
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682823
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464973
INFO:root:FL Epoch: 247 Norm Difference for worker 510 is 1.16946
INFO:root:FL Epoch: 247 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1344
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599939
INFO:root:Worker: 1344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441013
INFO:root:FL Epoch: 247 Norm Difference for worker 1344 is 1.026743
INFO:root:FL Epoch: 247 Done on worker:1344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1915
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514710
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402525
INFO:root:FL Epoch: 247 Norm Difference for worker 1915 is 1.102024
INFO:root:FL Epoch: 247 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1823
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696771
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350794
INFO:root:FL Epoch: 247 Norm Difference for worker 1823 is 1.179755
INFO:root:FL Epoch: 247 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1825
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629723
INFO:root:Worker: 1825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606290
INFO:root:FL Epoch: 247 Norm Difference for worker 1825 is 1.045391
INFO:root:FL Epoch: 247 Done on worker:1825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1711
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742961
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539856
INFO:root:FL Epoch: 247 Norm Difference for worker 1711 is 1.161351
INFO:root:FL Epoch: 247 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :692
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632852
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562302
INFO:root:FL Epoch: 247 Norm Difference for worker 692 is 1.021333
INFO:root:FL Epoch: 247 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :522
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 522 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507980
INFO:root:Worker: 522 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390734
INFO:root:FL Epoch: 247 Norm Difference for worker 522 is 1.065743
INFO:root:FL Epoch: 247 Done on worker:522
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 247 Training on worker :1313
INFO:root:FL Epoch: 247 Using Learning rate : 0.03055506141853553 
INFO:root:FL Epoch: 247 Normal Training
INFO:root:Worker: 1313 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592063
INFO:root:Worker: 1313 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303607
INFO:root:FL Epoch: 247 Norm Difference for worker 1313 is 1.073523
INFO:root:FL Epoch: 247 Done on worker:1313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1825
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 247 Ends   ===================
INFO:root:Epoch:247 Global Model Test Loss:0.4992414572659661 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:247 Global Model Backdoor Test Loss:0.33534133931001026                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 248 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 248 Workers Selected : [1316, 565, 899, 824, 1485, 1095, 1565, 153, 294, 210]
INFO:root:FL Epoch: 248 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.10034948]
INFO:root:FL Epoch: 248 Num points on workers: [200 200 200 200 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 248 Training on worker :1316
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715335
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372889
INFO:root:FL Epoch: 248 Norm Difference for worker 1316 is 0.968631
INFO:root:FL Epoch: 248 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :565
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392674
INFO:root:Worker: 565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371316
INFO:root:FL Epoch: 248 Norm Difference for worker 565 is 1.025613
INFO:root:FL Epoch: 248 Done on worker:565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :899
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602270
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478918
INFO:root:FL Epoch: 248 Norm Difference for worker 899 is 1.04862
INFO:root:FL Epoch: 248 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :824
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 824 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702853
INFO:root:Worker: 824 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525869
INFO:root:FL Epoch: 248 Norm Difference for worker 824 is 0.981535
INFO:root:FL Epoch: 248 Done on worker:824
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1485
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.875568
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475006
INFO:root:FL Epoch: 248 Norm Difference for worker 1485 is 1.000591
INFO:root:FL Epoch: 248 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1095
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1095 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557452
INFO:root:Worker: 1095 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430084
INFO:root:FL Epoch: 248 Norm Difference for worker 1095 is 1.018438
INFO:root:FL Epoch: 248 Done on worker:1095
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :1565
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 1565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579269
INFO:root:Worker: 1565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556347
INFO:root:FL Epoch: 248 Norm Difference for worker 1565 is 1.037539
INFO:root:FL Epoch: 248 Done on worker:1565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :153
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 153 Train Epoch: 0 [0/201 (0%)]	Loss: 0.531652
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 153 Train Epoch: 1 [0/201 (0%)]	Loss: 0.538165
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 248 Norm Difference for worker 153 is 1.027088
INFO:root:FL Epoch: 248 Done on worker:153
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :294
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 294 Train Epoch: 0 [0/201 (0%)]	Loss: 0.497614
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 294 Train Epoch: 1 [0/201 (0%)]	Loss: 0.429851
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 248 Norm Difference for worker 294 is 1.088395
INFO:root:FL Epoch: 248 Done on worker:294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 248 Training on worker :210
INFO:root:FL Epoch: 248 Using Learning rate : 0.030493951295698457 
INFO:root:FL Epoch: 248 Normal Training
INFO:root:Worker: 210 Train Epoch: 0 [0/201 (0%)]	Loss: 0.382670
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 210 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505568
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 248 Norm Difference for worker 210 is 1.038438
INFO:root:FL Epoch: 248 Done on worker:210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 824
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 248 Ends   ===================
INFO:root:Epoch:248 Global Model Test Loss:0.5074829091044033 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:248 Global Model Backdoor Test Loss:0.43124309678872425                             and Backdoor Test Accuracy:79.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 249 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 249 Workers Selected : [1763, 847, 1708, 194, 1749, 1546, 321, 1217, 1760, 1685]
INFO:root:FL Epoch: 249 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 249 Num points on workers: [200 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 249 Training on worker :1763
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445765
INFO:root:Worker: 1763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.733870
INFO:root:FL Epoch: 249 Norm Difference for worker 1763 is 0.94352
INFO:root:FL Epoch: 249 Done on worker:1763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :847
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 847 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542417
INFO:root:Worker: 847 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338219
INFO:root:FL Epoch: 249 Norm Difference for worker 847 is 0.862367
INFO:root:FL Epoch: 249 Done on worker:847
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1708
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472420
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450402
INFO:root:FL Epoch: 249 Norm Difference for worker 1708 is 0.909091
INFO:root:FL Epoch: 249 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :194
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 194 Train Epoch: 0 [0/201 (0%)]	Loss: 0.693196
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 194 Train Epoch: 1 [0/201 (0%)]	Loss: 0.602850
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 249 Norm Difference for worker 194 is 0.895392
INFO:root:FL Epoch: 249 Done on worker:194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1749
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1749 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456760
INFO:root:Worker: 1749 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438144
INFO:root:FL Epoch: 249 Norm Difference for worker 1749 is 0.84748
INFO:root:FL Epoch: 249 Done on worker:1749
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1546
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643653
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523512
INFO:root:FL Epoch: 249 Norm Difference for worker 1546 is 0.875394
INFO:root:FL Epoch: 249 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :321
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 321 Train Epoch: 0 [0/201 (0%)]	Loss: 0.655306
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 321 Train Epoch: 1 [0/201 (0%)]	Loss: 0.465745
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 249 Norm Difference for worker 321 is 0.953112
INFO:root:FL Epoch: 249 Done on worker:321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1217
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.889417
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384267
INFO:root:FL Epoch: 249 Norm Difference for worker 1217 is 0.95497
INFO:root:FL Epoch: 249 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1760
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433131
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.658389
INFO:root:FL Epoch: 249 Norm Difference for worker 1760 is 1.000237
INFO:root:FL Epoch: 249 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 249 Training on worker :1685
INFO:root:FL Epoch: 249 Using Learning rate : 0.03043296339310706 
INFO:root:FL Epoch: 249 Normal Training
INFO:root:Worker: 1685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.834171
INFO:root:Worker: 1685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671898
INFO:root:FL Epoch: 249 Norm Difference for worker 1685 is 0.916768
INFO:root:FL Epoch: 249 Done on worker:1685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1749
INFO:root:Norm of Aggregated Model: 5154.9921875
INFO:root:Aggregating After Defense
INFO:root:================FL round 249 Ends   ===================
INFO:root:Epoch:249 Global Model Test Loss:0.5200405857142281 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:249 Global Model Backdoor Test Loss:0.40242763857046765                             and Backdoor Test Accuracy:80.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 250 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 250 Workers Selected : [1336, 1168, 237, 585, 1629, 497, 690, 869, 451, 298]
INFO:root:FL Epoch: 250 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 250 Num points on workers: [200 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 250 Training on worker :1336
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1336 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558405
INFO:root:Worker: 1336 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533353
INFO:root:FL Epoch: 250 Norm Difference for worker 1336 is 0.93934
INFO:root:FL Epoch: 250 Done on worker:1336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1168
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1168 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348828
INFO:root:Worker: 1168 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444363
INFO:root:FL Epoch: 250 Norm Difference for worker 1168 is 0.83789
INFO:root:FL Epoch: 250 Done on worker:1168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :237
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 237 Train Epoch: 0 [0/201 (0%)]	Loss: 0.619051
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 237 Train Epoch: 1 [0/201 (0%)]	Loss: 0.338964
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 237 is 0.967007
INFO:root:FL Epoch: 250 Done on worker:237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :585
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444860
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.758005
INFO:root:FL Epoch: 250 Norm Difference for worker 585 is 0.925274
INFO:root:FL Epoch: 250 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :1629
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 1629 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554352
INFO:root:Worker: 1629 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384282
INFO:root:FL Epoch: 250 Norm Difference for worker 1629 is 0.995948
INFO:root:FL Epoch: 250 Done on worker:1629
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :497
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378985
INFO:root:Worker: 497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492908
INFO:root:FL Epoch: 250 Norm Difference for worker 497 is 0.8731
INFO:root:FL Epoch: 250 Done on worker:497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :690
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638273
INFO:root:Worker: 690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618358
INFO:root:FL Epoch: 250 Norm Difference for worker 690 is 0.903229
INFO:root:FL Epoch: 250 Done on worker:690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :869
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555411
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273504
INFO:root:FL Epoch: 250 Norm Difference for worker 869 is 0.889797
INFO:root:FL Epoch: 250 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :451
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 451 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377599
INFO:root:Worker: 451 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512060
INFO:root:FL Epoch: 250 Norm Difference for worker 451 is 0.919415
INFO:root:FL Epoch: 250 Done on worker:451
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 250 Training on worker :298
INFO:root:FL Epoch: 250 Using Learning rate : 0.030372097466320847 
INFO:root:FL Epoch: 250 Normal Training
INFO:root:Worker: 298 Train Epoch: 0 [0/201 (0%)]	Loss: 0.488698
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 298 Train Epoch: 1 [0/201 (0%)]	Loss: 0.616508
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 250 Norm Difference for worker 298 is 0.977152
INFO:root:FL Epoch: 250 Done on worker:298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 497
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 250 Ends   ===================
INFO:root:Epoch:250 Global Model Test Loss:0.5506985853700077 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:250 Global Model Backdoor Test Loss:0.6359329422314962                             and Backdoor Test Accuracy:71.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 251 Begins ===================
INFO:root:FL Epoch: 251 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 251 Workers Selected : [0, 386, 744, 637, 1587, 375, 1121, 480, 946, 169]
INFO:root:FL Epoch: 251 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 251 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 251 Training on worker :0
INFO:root:FL Epoch: 251 Using Learning rate : 0.0060622706542776406 
INFO:root:FL Epoch: 251 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327326
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333519
INFO:root:FL Epoch: 251 Worker: 0 Backdoor Test Loss: 0.3505297303199768 Backdoor Test Accuracy: 83.33333333333333
INFO:root:FL Epoch: 251 Worker: 0 Backdoor Train Loss: 0.26311261504888533 Backdoor Train Accuracy: 92.0
INFO:root:FL Epoch: 251 Norm Difference for worker 0 is 0.27272
INFO:root:FL Epoch: 251 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :386
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354092
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353313
INFO:root:FL Epoch: 251 Norm Difference for worker 386 is 0.994647
INFO:root:FL Epoch: 251 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :744
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415078
INFO:root:Worker: 744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.594773
INFO:root:FL Epoch: 251 Norm Difference for worker 744 is 1.082844
INFO:root:FL Epoch: 251 Done on worker:744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :637
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562841
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571830
INFO:root:FL Epoch: 251 Norm Difference for worker 637 is 1.025494
INFO:root:FL Epoch: 251 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1587
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582336
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519305
INFO:root:FL Epoch: 251 Norm Difference for worker 1587 is 1.003775
INFO:root:FL Epoch: 251 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :375
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411013
INFO:root:Worker: 375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547687
INFO:root:FL Epoch: 251 Norm Difference for worker 375 is 1.045376
INFO:root:FL Epoch: 251 Done on worker:375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :1121
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 1121 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668576
INFO:root:Worker: 1121 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497804
INFO:root:FL Epoch: 251 Norm Difference for worker 1121 is 1.041688
INFO:root:FL Epoch: 251 Done on worker:1121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :480
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.807644
INFO:root:Worker: 480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613615
INFO:root:FL Epoch: 251 Norm Difference for worker 480 is 1.065676
INFO:root:FL Epoch: 251 Done on worker:480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :946
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597756
INFO:root:Worker: 946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455060
INFO:root:FL Epoch: 251 Norm Difference for worker 946 is 1.065417
INFO:root:FL Epoch: 251 Done on worker:946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 251 Training on worker :169
INFO:root:FL Epoch: 251 Using Learning rate : 0.030311353271388203 
INFO:root:FL Epoch: 251 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.656783
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.506128
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 251 Norm Difference for worker 169 is 1.036239
INFO:root:FL Epoch: 251 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 251 Ends   ===================
INFO:root:Epoch:251 Global Model Test Loss:0.524763987344854 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:251 Global Model Backdoor Test Loss:0.3505297303199768                             and Backdoor Test Accuracy:83.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 252 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 252 Workers Selected : [655, 1448, 927, 1575, 317, 502, 255, 660, 481, 571]
INFO:root:FL Epoch: 252 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 252 Num points on workers: [200 200 200 200 201 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 252 Training on worker :655
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523038
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645268
INFO:root:FL Epoch: 252 Norm Difference for worker 655 is 1.077105
INFO:root:FL Epoch: 252 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1448
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511777
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501727
INFO:root:FL Epoch: 252 Norm Difference for worker 1448 is 1.106627
INFO:root:FL Epoch: 252 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :927
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323713
INFO:root:Worker: 927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264626
INFO:root:FL Epoch: 252 Norm Difference for worker 927 is 0.957203
INFO:root:FL Epoch: 252 Done on worker:927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :1575
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.795853
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604257
INFO:root:FL Epoch: 252 Norm Difference for worker 1575 is 1.038519
INFO:root:FL Epoch: 252 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :317
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 317 Train Epoch: 0 [0/201 (0%)]	Loss: 0.553727
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 317 Train Epoch: 1 [0/201 (0%)]	Loss: 0.514059
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 252 Norm Difference for worker 317 is 1.054579
INFO:root:FL Epoch: 252 Done on worker:317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :502
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 502 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476945
INFO:root:Worker: 502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481345
INFO:root:FL Epoch: 252 Norm Difference for worker 502 is 1.027842
INFO:root:FL Epoch: 252 Done on worker:502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :255
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 255 Train Epoch: 0 [0/201 (0%)]	Loss: 0.609489
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 255 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447507
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 252 Norm Difference for worker 255 is 1.033355
INFO:root:FL Epoch: 252 Done on worker:255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :660
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 660 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544262
INFO:root:Worker: 660 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426017
INFO:root:FL Epoch: 252 Norm Difference for worker 660 is 1.016092
INFO:root:FL Epoch: 252 Done on worker:660
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :481
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596816
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438861
INFO:root:FL Epoch: 252 Norm Difference for worker 481 is 1.128979
INFO:root:FL Epoch: 252 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 252 Training on worker :571
INFO:root:FL Epoch: 252 Using Learning rate : 0.03025073056484543 
INFO:root:FL Epoch: 252 Normal Training
INFO:root:Worker: 571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661453
INFO:root:Worker: 571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461034
INFO:root:FL Epoch: 252 Norm Difference for worker 571 is 1.061705
INFO:root:FL Epoch: 252 Done on worker:571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 927
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 252 Ends   ===================
INFO:root:Epoch:252 Global Model Test Loss:0.5182869048679576 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:252 Global Model Backdoor Test Loss:0.32063138981660205                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 253 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 253 Workers Selected : [156, 1365, 719, 1627, 308, 1875, 116, 1670, 112, 1663]
INFO:root:FL Epoch: 253 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 253 Num points on workers: [201 200 200 200 201 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 253 Training on worker :156
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 156 Train Epoch: 0 [0/201 (0%)]	Loss: 0.785157
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 156 Train Epoch: 1 [0/201 (0%)]	Loss: 0.510183
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 253 Norm Difference for worker 156 is 1.180677
INFO:root:FL Epoch: 253 Done on worker:156
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1365
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457544
INFO:root:Worker: 1365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335297
INFO:root:FL Epoch: 253 Norm Difference for worker 1365 is 1.046705
INFO:root:FL Epoch: 253 Done on worker:1365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :719
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 719 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489904
INFO:root:Worker: 719 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490085
INFO:root:FL Epoch: 253 Norm Difference for worker 719 is 1.137511
INFO:root:FL Epoch: 253 Done on worker:719
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1627
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631857
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306781
INFO:root:FL Epoch: 253 Norm Difference for worker 1627 is 0.992055
INFO:root:FL Epoch: 253 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :308
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.508265
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.416522
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 253 Norm Difference for worker 308 is 1.055371
INFO:root:FL Epoch: 253 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1875
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1875 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609373
INFO:root:Worker: 1875 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337680
INFO:root:FL Epoch: 253 Norm Difference for worker 1875 is 1.101368
INFO:root:FL Epoch: 253 Done on worker:1875
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :116
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.301681
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.434317
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 253 Norm Difference for worker 116 is 1.134125
INFO:root:FL Epoch: 253 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1670
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.290848
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409810
INFO:root:FL Epoch: 253 Norm Difference for worker 1670 is 0.970113
INFO:root:FL Epoch: 253 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :112
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 112 Train Epoch: 0 [0/201 (0%)]	Loss: 0.621461
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 112 Train Epoch: 1 [0/201 (0%)]	Loss: 0.437934
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 253 Norm Difference for worker 112 is 1.023656
INFO:root:FL Epoch: 253 Done on worker:112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 253 Training on worker :1663
INFO:root:FL Epoch: 253 Using Learning rate : 0.03019022910371574 
INFO:root:FL Epoch: 253 Normal Training
INFO:root:Worker: 1663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729785
INFO:root:Worker: 1663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512930
INFO:root:FL Epoch: 253 Norm Difference for worker 1663 is 0.943386
INFO:root:FL Epoch: 253 Done on worker:1663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1663
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 253 Ends   ===================
INFO:root:Epoch:253 Global Model Test Loss:0.5182762969942654 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:253 Global Model Backdoor Test Loss:0.32954757163921994                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 254 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 254 Workers Selected : [488, 46, 583, 80, 151, 1232, 1316, 820, 1752, 1208]
INFO:root:FL Epoch: 254 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 254 Num points on workers: [200 201 200 201 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 254 Training on worker :488
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415123
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534236
INFO:root:FL Epoch: 254 Norm Difference for worker 488 is 1.027491
INFO:root:FL Epoch: 254 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :46
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518580
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.277504
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 254 Norm Difference for worker 46 is 1.031008
INFO:root:FL Epoch: 254 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :583
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680976
INFO:root:Worker: 583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480469
INFO:root:FL Epoch: 254 Norm Difference for worker 583 is 1.094896
INFO:root:FL Epoch: 254 Done on worker:583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :80
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503906
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.409984
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 254 Norm Difference for worker 80 is 1.013087
INFO:root:FL Epoch: 254 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :151
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.532142
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.681434
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 254 Norm Difference for worker 151 is 1.076003
INFO:root:FL Epoch: 254 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1232
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1232 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546385
INFO:root:Worker: 1232 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546349
INFO:root:FL Epoch: 254 Norm Difference for worker 1232 is 1.081529
INFO:root:FL Epoch: 254 Done on worker:1232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1316
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1316 Train Epoch: 0 [0/200 (0%)]	Loss: 0.890236
INFO:root:Worker: 1316 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439324
INFO:root:FL Epoch: 254 Norm Difference for worker 1316 is 1.035718
INFO:root:FL Epoch: 254 Done on worker:1316
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :820
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638034
INFO:root:Worker: 820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532390
INFO:root:FL Epoch: 254 Norm Difference for worker 820 is 1.058959
INFO:root:FL Epoch: 254 Done on worker:820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1752
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508069
INFO:root:Worker: 1752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519570
INFO:root:FL Epoch: 254 Norm Difference for worker 1752 is 1.061277
INFO:root:FL Epoch: 254 Done on worker:1752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 254 Training on worker :1208
INFO:root:FL Epoch: 254 Using Learning rate : 0.030129848645508307 
INFO:root:FL Epoch: 254 Normal Training
INFO:root:Worker: 1208 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624827
INFO:root:Worker: 1208 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402581
INFO:root:FL Epoch: 254 Norm Difference for worker 1208 is 0.997624
INFO:root:FL Epoch: 254 Done on worker:1208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 80
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 254 Ends   ===================
INFO:root:Epoch:254 Global Model Test Loss:0.5055318422177258 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:254 Global Model Backdoor Test Loss:0.32123446464538574                             and Backdoor Test Accuracy:84.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 255 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 255 Workers Selected : [1729, 1674, 1530, 349, 693, 1398, 1038, 1463, 413, 889]
INFO:root:FL Epoch: 255 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 255 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 255 Training on worker :1729
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737106
INFO:root:Worker: 1729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578338
INFO:root:FL Epoch: 255 Norm Difference for worker 1729 is 1.056599
INFO:root:FL Epoch: 255 Done on worker:1729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1674
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437192
INFO:root:Worker: 1674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391245
INFO:root:FL Epoch: 255 Norm Difference for worker 1674 is 0.981901
INFO:root:FL Epoch: 255 Done on worker:1674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1530
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415205
INFO:root:Worker: 1530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429063
INFO:root:FL Epoch: 255 Norm Difference for worker 1530 is 1.108429
INFO:root:FL Epoch: 255 Done on worker:1530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :349
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394930
INFO:root:Worker: 349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435004
INFO:root:FL Epoch: 255 Norm Difference for worker 349 is 0.935087
INFO:root:FL Epoch: 255 Done on worker:349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :693
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457846
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408437
INFO:root:FL Epoch: 255 Norm Difference for worker 693 is 0.903426
INFO:root:FL Epoch: 255 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1398
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.890826
INFO:root:Worker: 1398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648240
INFO:root:FL Epoch: 255 Norm Difference for worker 1398 is 1.010006
INFO:root:FL Epoch: 255 Done on worker:1398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1038
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1038 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599751
INFO:root:Worker: 1038 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521908
INFO:root:FL Epoch: 255 Norm Difference for worker 1038 is 1.047201
INFO:root:FL Epoch: 255 Done on worker:1038
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :1463
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.917603
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468732
INFO:root:FL Epoch: 255 Norm Difference for worker 1463 is 1.092767
INFO:root:FL Epoch: 255 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :413
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482568
INFO:root:Worker: 413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305797
INFO:root:FL Epoch: 255 Norm Difference for worker 413 is 0.984951
INFO:root:FL Epoch: 255 Done on worker:413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 255 Training on worker :889
INFO:root:FL Epoch: 255 Using Learning rate : 0.03006958894821729 
INFO:root:FL Epoch: 255 Normal Training
INFO:root:Worker: 889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665682
INFO:root:Worker: 889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630641
INFO:root:FL Epoch: 255 Norm Difference for worker 889 is 1.063317
INFO:root:FL Epoch: 255 Done on worker:889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 693
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 255 Ends   ===================
INFO:root:Epoch:255 Global Model Test Loss:0.5134457752985113 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:255 Global Model Backdoor Test Loss:0.26259132474660873                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 256 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 256 Workers Selected : [1448, 856, 1876, 683, 924, 1238, 1840, 1324, 1696, 130]
INFO:root:FL Epoch: 256 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 256 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 256 Training on worker :1448
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1448 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693707
INFO:root:Worker: 1448 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649451
INFO:root:FL Epoch: 256 Norm Difference for worker 1448 is 1.258315
INFO:root:FL Epoch: 256 Done on worker:1448
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :856
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725408
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364725
INFO:root:FL Epoch: 256 Norm Difference for worker 856 is 1.4235
INFO:root:FL Epoch: 256 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1876
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1876 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433346
INFO:root:Worker: 1876 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457040
INFO:root:FL Epoch: 256 Norm Difference for worker 1876 is 1.327688
INFO:root:FL Epoch: 256 Done on worker:1876
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :683
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698936
INFO:root:Worker: 683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352099
INFO:root:FL Epoch: 256 Norm Difference for worker 683 is 1.255491
INFO:root:FL Epoch: 256 Done on worker:683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :924
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 924 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462668
INFO:root:Worker: 924 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404856
INFO:root:FL Epoch: 256 Norm Difference for worker 924 is 1.289442
INFO:root:FL Epoch: 256 Done on worker:924
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1238
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644247
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511716
INFO:root:FL Epoch: 256 Norm Difference for worker 1238 is 1.383887
INFO:root:FL Epoch: 256 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1840
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1840 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722544
INFO:root:Worker: 1840 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552140
INFO:root:FL Epoch: 256 Norm Difference for worker 1840 is 1.273602
INFO:root:FL Epoch: 256 Done on worker:1840
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1324
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437743
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410209
INFO:root:FL Epoch: 256 Norm Difference for worker 1324 is 1.233792
INFO:root:FL Epoch: 256 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :1696
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 1696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472176
INFO:root:Worker: 1696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361944
INFO:root:FL Epoch: 256 Norm Difference for worker 1696 is 1.028485
INFO:root:FL Epoch: 256 Done on worker:1696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 256 Training on worker :130
INFO:root:FL Epoch: 256 Using Learning rate : 0.030009449770320856 
INFO:root:FL Epoch: 256 Normal Training
INFO:root:Worker: 130 Train Epoch: 0 [0/201 (0%)]	Loss: 0.940622
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 130 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447807
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 256 Norm Difference for worker 130 is 1.242083
INFO:root:FL Epoch: 256 Done on worker:130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1696
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 256 Ends   ===================
INFO:root:Epoch:256 Global Model Test Loss:0.5196662948412054 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:256 Global Model Backdoor Test Loss:0.16886680449048677                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 257 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 257 Workers Selected : [865, 294, 1620, 716, 202, 1903, 1704, 813, 1440, 530]
INFO:root:FL Epoch: 257 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 257 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 257 Training on worker :865
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506200
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280533
INFO:root:FL Epoch: 257 Norm Difference for worker 865 is 1.331348
INFO:root:FL Epoch: 257 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :294
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 294 Train Epoch: 0 [0/201 (0%)]	Loss: 0.652392
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 294 Train Epoch: 1 [0/201 (0%)]	Loss: 0.496740
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 294 is 1.570875
INFO:root:FL Epoch: 257 Done on worker:294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :1620
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734558
INFO:root:Worker: 1620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419874
INFO:root:FL Epoch: 257 Norm Difference for worker 1620 is 1.388703
INFO:root:FL Epoch: 257 Done on worker:1620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :716
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.246659
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472861
INFO:root:FL Epoch: 257 Norm Difference for worker 716 is 1.242973
INFO:root:FL Epoch: 257 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :202
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 202 Train Epoch: 0 [0/201 (0%)]	Loss: 0.770966
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 202 Train Epoch: 1 [0/201 (0%)]	Loss: 0.478100
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 257 Norm Difference for worker 202 is 1.385973
INFO:root:FL Epoch: 257 Done on worker:202
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :1903
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733033
INFO:root:Worker: 1903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472411
INFO:root:FL Epoch: 257 Norm Difference for worker 1903 is 1.394483
INFO:root:FL Epoch: 257 Done on worker:1903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :1704
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414533
INFO:root:Worker: 1704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428669
INFO:root:FL Epoch: 257 Norm Difference for worker 1704 is 1.344317
INFO:root:FL Epoch: 257 Done on worker:1704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :813
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696880
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314289
INFO:root:FL Epoch: 257 Norm Difference for worker 813 is 1.298209
INFO:root:FL Epoch: 257 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :1440
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.861102
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388034
INFO:root:FL Epoch: 257 Norm Difference for worker 1440 is 1.389656
INFO:root:FL Epoch: 257 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 257 Training on worker :530
INFO:root:FL Epoch: 257 Using Learning rate : 0.029949430870780214 
INFO:root:FL Epoch: 257 Normal Training
INFO:root:Worker: 530 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487370
INFO:root:Worker: 530 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589156
INFO:root:FL Epoch: 257 Norm Difference for worker 530 is 1.454803
INFO:root:FL Epoch: 257 Done on worker:530
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 716
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 257 Ends   ===================
INFO:root:Epoch:257 Global Model Test Loss:0.509904624784694 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:257 Global Model Backdoor Test Loss:0.2874836375315984                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 258 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 258 Workers Selected : [221, 1400, 1245, 1917, 1319, 1804, 1380, 1045, 1514, 234]
INFO:root:FL Epoch: 258 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 258 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 258 Training on worker :221
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 221 Train Epoch: 0 [0/201 (0%)]	Loss: 0.719908
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 221 Train Epoch: 1 [0/201 (0%)]	Loss: 0.343169
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 258 Norm Difference for worker 221 is 1.019482
INFO:root:FL Epoch: 258 Done on worker:221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1400
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1400 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446902
INFO:root:Worker: 1400 Train Epoch: 1 [0/200 (0%)]	Loss: 0.609913
INFO:root:FL Epoch: 258 Norm Difference for worker 1400 is 1.186147
INFO:root:FL Epoch: 258 Done on worker:1400
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1245
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1245 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406387
INFO:root:Worker: 1245 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327726
INFO:root:FL Epoch: 258 Norm Difference for worker 1245 is 1.040797
INFO:root:FL Epoch: 258 Done on worker:1245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1917
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592765
INFO:root:Worker: 1917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559609
INFO:root:FL Epoch: 258 Norm Difference for worker 1917 is 1.072418
INFO:root:FL Epoch: 258 Done on worker:1917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1319
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.900416
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596700
INFO:root:FL Epoch: 258 Norm Difference for worker 1319 is 1.15758
INFO:root:FL Epoch: 258 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1804
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629167
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.379538
INFO:root:FL Epoch: 258 Norm Difference for worker 1804 is 1.192465
INFO:root:FL Epoch: 258 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1380
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339661
INFO:root:Worker: 1380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350390
INFO:root:FL Epoch: 258 Norm Difference for worker 1380 is 1.102521
INFO:root:FL Epoch: 258 Done on worker:1380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1045
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1045 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341412
INFO:root:Worker: 1045 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498549
INFO:root:FL Epoch: 258 Norm Difference for worker 1045 is 1.116308
INFO:root:FL Epoch: 258 Done on worker:1045
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :1514
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 1514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.820772
INFO:root:Worker: 1514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483858
INFO:root:FL Epoch: 258 Norm Difference for worker 1514 is 1.182392
INFO:root:FL Epoch: 258 Done on worker:1514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 258 Training on worker :234
INFO:root:FL Epoch: 258 Using Learning rate : 0.029889532009038655 
INFO:root:FL Epoch: 258 Normal Training
INFO:root:Worker: 234 Train Epoch: 0 [0/201 (0%)]	Loss: 0.426486
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 234 Train Epoch: 1 [0/201 (0%)]	Loss: 0.487810
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 258 Norm Difference for worker 234 is 1.215149
INFO:root:FL Epoch: 258 Done on worker:234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 221
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 258 Ends   ===================
INFO:root:Epoch:258 Global Model Test Loss:0.5176084760357352 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:258 Global Model Backdoor Test Loss:0.34978729983170825                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 259 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 259 Workers Selected : [1108, 1848, 224, 268, 1318, 537, 599, 745, 1046, 573]
INFO:root:FL Epoch: 259 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 259 Num points on workers: [200 200 201 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 259 Training on worker :1108
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653929
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666173
INFO:root:FL Epoch: 259 Norm Difference for worker 1108 is 1.02695
INFO:root:FL Epoch: 259 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1848
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440419
INFO:root:Worker: 1848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.194262
INFO:root:FL Epoch: 259 Norm Difference for worker 1848 is 0.877438
INFO:root:FL Epoch: 259 Done on worker:1848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :224
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 224 Train Epoch: 0 [0/201 (0%)]	Loss: 0.533033
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 224 Train Epoch: 1 [0/201 (0%)]	Loss: 0.545350
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 224 is 0.996341
INFO:root:FL Epoch: 259 Done on worker:224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :268
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 268 Train Epoch: 0 [0/201 (0%)]	Loss: 0.380091
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 268 Train Epoch: 1 [0/201 (0%)]	Loss: 0.372045
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 259 Norm Difference for worker 268 is 0.961464
INFO:root:FL Epoch: 259 Done on worker:268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1318
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723504
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446198
INFO:root:FL Epoch: 259 Norm Difference for worker 1318 is 1.090825
INFO:root:FL Epoch: 259 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :537
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721840
INFO:root:Worker: 537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494133
INFO:root:FL Epoch: 259 Norm Difference for worker 537 is 1.063953
INFO:root:FL Epoch: 259 Done on worker:537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :599
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327922
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.731172
INFO:root:FL Epoch: 259 Norm Difference for worker 599 is 1.01429
INFO:root:FL Epoch: 259 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :745
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526607
INFO:root:Worker: 745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.716160
INFO:root:FL Epoch: 259 Norm Difference for worker 745 is 1.105389
INFO:root:FL Epoch: 259 Done on worker:745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :1046
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 1046 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454102
INFO:root:Worker: 1046 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547067
INFO:root:FL Epoch: 259 Norm Difference for worker 1046 is 1.022974
INFO:root:FL Epoch: 259 Done on worker:1046
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 259 Training on worker :573
INFO:root:FL Epoch: 259 Using Learning rate : 0.029829752945020577 
INFO:root:FL Epoch: 259 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336318
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653709
INFO:root:FL Epoch: 259 Norm Difference for worker 573 is 1.035613
INFO:root:FL Epoch: 259 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1848
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 259 Ends   ===================
INFO:root:Epoch:259 Global Model Test Loss:0.5106676326078528 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:259 Global Model Backdoor Test Loss:0.24365694324175516                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 260 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 260 Workers Selected : [940, 564, 438, 42, 1141, 1106, 1742, 1477, 615, 373]
INFO:root:FL Epoch: 260 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 260 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 260 Training on worker :940
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.317164
INFO:root:Worker: 940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398483
INFO:root:FL Epoch: 260 Norm Difference for worker 940 is 1.179892
INFO:root:FL Epoch: 260 Done on worker:940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :564
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534603
INFO:root:Worker: 564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533764
INFO:root:FL Epoch: 260 Norm Difference for worker 564 is 1.237215
INFO:root:FL Epoch: 260 Done on worker:564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :438
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599385
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511877
INFO:root:FL Epoch: 260 Norm Difference for worker 438 is 1.260453
INFO:root:FL Epoch: 260 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :42
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.314426
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.251693
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 260 Norm Difference for worker 42 is 1.080692
INFO:root:FL Epoch: 260 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1141
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1141 Train Epoch: 0 [0/200 (0%)]	Loss: 0.838619
INFO:root:Worker: 1141 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378229
INFO:root:FL Epoch: 260 Norm Difference for worker 1141 is 1.15075
INFO:root:FL Epoch: 260 Done on worker:1141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1106
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1106 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585660
INFO:root:Worker: 1106 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441636
INFO:root:FL Epoch: 260 Norm Difference for worker 1106 is 1.264636
INFO:root:FL Epoch: 260 Done on worker:1106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1742
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611227
INFO:root:Worker: 1742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.716888
INFO:root:FL Epoch: 260 Norm Difference for worker 1742 is 1.324249
INFO:root:FL Epoch: 260 Done on worker:1742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :1477
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 1477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.255800
INFO:root:Worker: 1477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.793793
INFO:root:FL Epoch: 260 Norm Difference for worker 1477 is 1.316051
INFO:root:FL Epoch: 260 Done on worker:1477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :615
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 615 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646541
INFO:root:Worker: 615 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391142
INFO:root:FL Epoch: 260 Norm Difference for worker 615 is 1.264894
INFO:root:FL Epoch: 260 Done on worker:615
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 260 Training on worker :373
INFO:root:FL Epoch: 260 Using Learning rate : 0.029770093439130535 
INFO:root:FL Epoch: 260 Normal Training
INFO:root:Worker: 373 Train Epoch: 0 [0/200 (0%)]	Loss: 1.084651
INFO:root:Worker: 373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368079
INFO:root:FL Epoch: 260 Norm Difference for worker 373 is 1.233284
INFO:root:FL Epoch: 260 Done on worker:373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 260 Ends   ===================
INFO:root:Epoch:260 Global Model Test Loss:0.5211498842519873 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:260 Global Model Backdoor Test Loss:0.32159676651159924                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 261 Begins ===================
INFO:root:FL Epoch: 261 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 261 Workers Selected : [0, 525, 248, 1540, 939, 323, 1854, 320, 1038, 419]
INFO:root:FL Epoch: 261 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 261 Num points on workers: [200 200 201 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 261 Training on worker :0
INFO:root:FL Epoch: 261 Using Learning rate : 0.005942110650450455 
INFO:root:FL Epoch: 261 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.204601
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339709
INFO:root:FL Epoch: 261 Worker: 0 Backdoor Test Loss: 0.2691758871078491 Backdoor Test Accuracy: 86.66666666666667
INFO:root:FL Epoch: 261 Worker: 0 Backdoor Train Loss: 0.22545664012432098 Backdoor Train Accuracy: 92.5
INFO:root:FL Epoch: 261 Norm Difference for worker 0 is 0.200003
INFO:root:FL Epoch: 261 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :525
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688413
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633845
INFO:root:FL Epoch: 261 Norm Difference for worker 525 is 1.183692
INFO:root:FL Epoch: 261 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :248
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 248 Train Epoch: 0 [0/201 (0%)]	Loss: 0.689087
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 248 Train Epoch: 1 [0/201 (0%)]	Loss: 0.345760
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 261 Norm Difference for worker 248 is 1.104733
INFO:root:FL Epoch: 261 Done on worker:248
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1540
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396978
INFO:root:Worker: 1540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533084
INFO:root:FL Epoch: 261 Norm Difference for worker 1540 is 1.246081
INFO:root:FL Epoch: 261 Done on worker:1540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :939
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527159
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461173
INFO:root:FL Epoch: 261 Norm Difference for worker 939 is 1.178155
INFO:root:FL Epoch: 261 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :323
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 323 Train Epoch: 0 [0/201 (0%)]	Loss: 0.868743
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 323 Train Epoch: 1 [0/201 (0%)]	Loss: 0.506360
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 261 Norm Difference for worker 323 is 1.250289
INFO:root:FL Epoch: 261 Done on worker:323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1854
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701977
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337844
INFO:root:FL Epoch: 261 Norm Difference for worker 1854 is 1.202627
INFO:root:FL Epoch: 261 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :320
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.272385
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.560734
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 261 Norm Difference for worker 320 is 1.186254
INFO:root:FL Epoch: 261 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :1038
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 1038 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392491
INFO:root:Worker: 1038 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545130
INFO:root:FL Epoch: 261 Norm Difference for worker 1038 is 1.14464
INFO:root:FL Epoch: 261 Done on worker:1038
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 261 Training on worker :419
INFO:root:FL Epoch: 261 Using Learning rate : 0.029710553252252275 
INFO:root:FL Epoch: 261 Normal Training
INFO:root:Worker: 419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315782
INFO:root:Worker: 419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.137684
INFO:root:FL Epoch: 261 Norm Difference for worker 419 is 1.064714
INFO:root:FL Epoch: 261 Done on worker:419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 261 Ends   ===================
INFO:root:Epoch:261 Global Model Test Loss:0.5256327127709108 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:261 Global Model Backdoor Test Loss:0.2691758871078491                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 262 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 262 Workers Selected : [89, 236, 8, 769, 121, 128, 1886, 555, 1374, 1885]
INFO:root:FL Epoch: 262 Fraction of points on each worker in this round: [0.10024938 0.10024938 0.10024938 0.09975062 0.10024938 0.10024938
 0.09975062 0.09975062 0.09975062 0.09975062]
INFO:root:FL Epoch: 262 Num points on workers: [201 201 201 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 262 Training on worker :89
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 89 Train Epoch: 0 [0/201 (0%)]	Loss: 0.629830
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 89 Train Epoch: 1 [0/201 (0%)]	Loss: 0.467427
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 89 is 1.183921
INFO:root:FL Epoch: 262 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :236
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 236 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518042
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 236 Train Epoch: 1 [0/201 (0%)]	Loss: 0.725360
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 236 is 1.332616
INFO:root:FL Epoch: 262 Done on worker:236
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :8
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.443800
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.525053
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 8 is 1.10941
INFO:root:FL Epoch: 262 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :769
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.831292
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561702
INFO:root:FL Epoch: 262 Norm Difference for worker 769 is 1.254003
INFO:root:FL Epoch: 262 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :121
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 121 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518679
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 121 Train Epoch: 1 [0/201 (0%)]	Loss: 0.314769
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 121 is 1.22985
INFO:root:FL Epoch: 262 Done on worker:121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :128
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 128 Train Epoch: 0 [0/201 (0%)]	Loss: 0.654744
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 128 Train Epoch: 1 [0/201 (0%)]	Loss: 0.744093
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 262 Norm Difference for worker 128 is 1.254522
INFO:root:FL Epoch: 262 Done on worker:128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1886
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409898
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477623
INFO:root:FL Epoch: 262 Norm Difference for worker 1886 is 1.255742
INFO:root:FL Epoch: 262 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :555
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377349
INFO:root:Worker: 555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453675
INFO:root:FL Epoch: 262 Norm Difference for worker 555 is 1.278471
INFO:root:FL Epoch: 262 Done on worker:555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1374
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490376
INFO:root:Worker: 1374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656268
INFO:root:FL Epoch: 262 Norm Difference for worker 1374 is 1.115313
INFO:root:FL Epoch: 262 Done on worker:1374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 262 Training on worker :1885
INFO:root:FL Epoch: 262 Using Learning rate : 0.029651132145747768 
INFO:root:FL Epoch: 262 Normal Training
INFO:root:Worker: 1885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707229
INFO:root:Worker: 1885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390045
INFO:root:FL Epoch: 262 Norm Difference for worker 1885 is 1.222589
INFO:root:FL Epoch: 262 Done on worker:1885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 8
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 262 Ends   ===================
INFO:root:Epoch:262 Global Model Test Loss:0.5252141794737648 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:262 Global Model Backdoor Test Loss:0.22749394923448563                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 263 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 263 Workers Selected : [497, 1039, 1328, 1186, 18, 93, 1787, 1656, 1143, 1854]
INFO:root:FL Epoch: 263 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 263 Num points on workers: [200 200 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 263 Training on worker :497
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408803
INFO:root:Worker: 497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.296214
INFO:root:FL Epoch: 263 Norm Difference for worker 497 is 0.881827
INFO:root:FL Epoch: 263 Done on worker:497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1039
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1039 Train Epoch: 0 [0/200 (0%)]	Loss: 0.836605
INFO:root:Worker: 1039 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524241
INFO:root:FL Epoch: 263 Norm Difference for worker 1039 is 1.160651
INFO:root:FL Epoch: 263 Done on worker:1039
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1328
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1328 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733367
INFO:root:Worker: 1328 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504506
INFO:root:FL Epoch: 263 Norm Difference for worker 1328 is 1.101493
INFO:root:FL Epoch: 263 Done on worker:1328
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1186
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1186 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305167
INFO:root:Worker: 1186 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369492
INFO:root:FL Epoch: 263 Norm Difference for worker 1186 is 1.051142
INFO:root:FL Epoch: 263 Done on worker:1186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :18
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 18 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698942
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 18 Train Epoch: 1 [0/201 (0%)]	Loss: 0.326553
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 18 is 1.142658
INFO:root:FL Epoch: 263 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :93
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 93 Train Epoch: 0 [0/201 (0%)]	Loss: 0.396267
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 93 Train Epoch: 1 [0/201 (0%)]	Loss: 0.582213
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 263 Norm Difference for worker 93 is 1.148859
INFO:root:FL Epoch: 263 Done on worker:93
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1787
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319288
INFO:root:Worker: 1787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315895
INFO:root:FL Epoch: 263 Norm Difference for worker 1787 is 1.051185
INFO:root:FL Epoch: 263 Done on worker:1787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1656
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397098
INFO:root:Worker: 1656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460851
INFO:root:FL Epoch: 263 Norm Difference for worker 1656 is 1.118572
INFO:root:FL Epoch: 263 Done on worker:1656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1143
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1143 Train Epoch: 0 [0/200 (0%)]	Loss: 0.960296
INFO:root:Worker: 1143 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409037
INFO:root:FL Epoch: 263 Norm Difference for worker 1143 is 1.126335
INFO:root:FL Epoch: 263 Done on worker:1143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 263 Training on worker :1854
INFO:root:FL Epoch: 263 Using Learning rate : 0.029591829881456273 
INFO:root:FL Epoch: 263 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.285600
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.723754
INFO:root:FL Epoch: 263 Norm Difference for worker 1854 is 1.212906
INFO:root:FL Epoch: 263 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 497
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 263 Ends   ===================
INFO:root:Epoch:263 Global Model Test Loss:0.5601981562726638 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:263 Global Model Backdoor Test Loss:0.3247746576865514                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 264 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 264 Workers Selected : [1890, 1470, 1108, 83, 325, 172, 910, 329, 814, 1437]
INFO:root:FL Epoch: 264 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.1002994 0.1002994 0.1002994 0.0998004
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 264 Num points on workers: [200 200 200 201 201 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 264 Training on worker :1890
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549540
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394163
INFO:root:FL Epoch: 264 Norm Difference for worker 1890 is 1.203362
INFO:root:FL Epoch: 264 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1470
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692782
INFO:root:Worker: 1470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476469
INFO:root:FL Epoch: 264 Norm Difference for worker 1470 is 1.163769
INFO:root:FL Epoch: 264 Done on worker:1470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1108
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421568
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652604
INFO:root:FL Epoch: 264 Norm Difference for worker 1108 is 1.325392
INFO:root:FL Epoch: 264 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :83
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 83 Train Epoch: 0 [0/201 (0%)]	Loss: 0.855095
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 83 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488962
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 83 is 1.282878
INFO:root:FL Epoch: 264 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :325
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.447092
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.365643
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 325 is 1.299422
INFO:root:FL Epoch: 264 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :172
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 172 Train Epoch: 0 [0/201 (0%)]	Loss: 0.750778
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 172 Train Epoch: 1 [0/201 (0%)]	Loss: 0.236962
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 172 is 1.298015
INFO:root:FL Epoch: 264 Done on worker:172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :910
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600076
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.778279
INFO:root:FL Epoch: 264 Norm Difference for worker 910 is 1.256254
INFO:root:FL Epoch: 264 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :329
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 329 Train Epoch: 0 [0/201 (0%)]	Loss: 0.418252
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 329 Train Epoch: 1 [0/201 (0%)]	Loss: 0.357045
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 264 Norm Difference for worker 329 is 1.265139
INFO:root:FL Epoch: 264 Done on worker:329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :814
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412134
INFO:root:Worker: 814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441145
INFO:root:FL Epoch: 264 Norm Difference for worker 814 is 1.223113
INFO:root:FL Epoch: 264 Done on worker:814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 264 Training on worker :1437
INFO:root:FL Epoch: 264 Using Learning rate : 0.02953264622169336 
INFO:root:FL Epoch: 264 Normal Training
INFO:root:Worker: 1437 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736204
INFO:root:Worker: 1437 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550082
INFO:root:FL Epoch: 264 Norm Difference for worker 1437 is 1.330257
INFO:root:FL Epoch: 264 Done on worker:1437
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1890
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 264 Ends   ===================
INFO:root:Epoch:264 Global Model Test Loss:0.554362458341262 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:264 Global Model Backdoor Test Loss:0.32232247292995453                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 265 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 265 Workers Selected : [358, 1709, 1158, 860, 1731, 1161, 1725, 312, 938, 110]
INFO:root:FL Epoch: 265 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.1003996]
INFO:root:FL Epoch: 265 Num points on workers: [200 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 265 Training on worker :358
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586855
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621919
INFO:root:FL Epoch: 265 Norm Difference for worker 358 is 1.018278
INFO:root:FL Epoch: 265 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1709
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647104
INFO:root:Worker: 1709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582851
INFO:root:FL Epoch: 265 Norm Difference for worker 1709 is 1.036662
INFO:root:FL Epoch: 265 Done on worker:1709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1158
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1158 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543280
INFO:root:Worker: 1158 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636796
INFO:root:FL Epoch: 265 Norm Difference for worker 1158 is 1.000209
INFO:root:FL Epoch: 265 Done on worker:1158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :860
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.777198
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627337
INFO:root:FL Epoch: 265 Norm Difference for worker 860 is 1.093521
INFO:root:FL Epoch: 265 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1731
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428652
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392679
INFO:root:FL Epoch: 265 Norm Difference for worker 1731 is 0.968801
INFO:root:FL Epoch: 265 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1161
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1161 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676656
INFO:root:Worker: 1161 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405361
INFO:root:FL Epoch: 265 Norm Difference for worker 1161 is 1.005932
INFO:root:FL Epoch: 265 Done on worker:1161
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :1725
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505855
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490580
INFO:root:FL Epoch: 265 Norm Difference for worker 1725 is 1.066199
INFO:root:FL Epoch: 265 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :312
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.742007
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.458581
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 312 is 1.015112
INFO:root:FL Epoch: 265 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :938
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545662
INFO:root:Worker: 938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581197
INFO:root:FL Epoch: 265 Norm Difference for worker 938 is 1.026858
INFO:root:FL Epoch: 265 Done on worker:938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 265 Training on worker :110
INFO:root:FL Epoch: 265 Using Learning rate : 0.02947358092924998 
INFO:root:FL Epoch: 265 Normal Training
INFO:root:Worker: 110 Train Epoch: 0 [0/201 (0%)]	Loss: 0.456282
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 110 Train Epoch: 1 [0/201 (0%)]	Loss: 0.603675
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 265 Norm Difference for worker 110 is 0.992097
INFO:root:FL Epoch: 265 Done on worker:110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1731
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 265 Ends   ===================
INFO:root:Epoch:265 Global Model Test Loss:0.5291256501394159 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:265 Global Model Backdoor Test Loss:0.31442778805891675                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 266 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 266 Workers Selected : [303, 368, 1458, 1485, 59, 429, 806, 1733, 1770, 1494]
INFO:root:FL Epoch: 266 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 266 Num points on workers: [201 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 266 Training on worker :303
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 303 Train Epoch: 0 [0/201 (0%)]	Loss: 0.719160
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 303 Train Epoch: 1 [0/201 (0%)]	Loss: 0.699991
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 266 Norm Difference for worker 303 is 0.996834
INFO:root:FL Epoch: 266 Done on worker:303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :368
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769429
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359370
INFO:root:FL Epoch: 266 Norm Difference for worker 368 is 0.987503
INFO:root:FL Epoch: 266 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1458
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644407
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560861
INFO:root:FL Epoch: 266 Norm Difference for worker 1458 is 1.06599
INFO:root:FL Epoch: 266 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1485
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430657
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479229
INFO:root:FL Epoch: 266 Norm Difference for worker 1485 is 1.073322
INFO:root:FL Epoch: 266 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :59
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.691158
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.636694
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 266 Norm Difference for worker 59 is 1.072077
INFO:root:FL Epoch: 266 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :429
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568895
INFO:root:Worker: 429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347655
INFO:root:FL Epoch: 266 Norm Difference for worker 429 is 1.020978
INFO:root:FL Epoch: 266 Done on worker:429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :806
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.765323
INFO:root:Worker: 806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485522
INFO:root:FL Epoch: 266 Norm Difference for worker 806 is 1.072378
INFO:root:FL Epoch: 266 Done on worker:806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1733
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423204
INFO:root:Worker: 1733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.646023
INFO:root:FL Epoch: 266 Norm Difference for worker 1733 is 1.011707
INFO:root:FL Epoch: 266 Done on worker:1733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1770
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1770 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623214
INFO:root:Worker: 1770 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497344
INFO:root:FL Epoch: 266 Norm Difference for worker 1770 is 1.083327
INFO:root:FL Epoch: 266 Done on worker:1770
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 266 Training on worker :1494
INFO:root:FL Epoch: 266 Using Learning rate : 0.029414633767391476 
INFO:root:FL Epoch: 266 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367838
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361383
INFO:root:FL Epoch: 266 Norm Difference for worker 1494 is 0.984685
INFO:root:FL Epoch: 266 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 303
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 266 Ends   ===================
INFO:root:Epoch:266 Global Model Test Loss:0.5139669302631827 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:266 Global Model Backdoor Test Loss:0.31906816363334656                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 267 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 267 Workers Selected : [1242, 992, 1939, 1482, 179, 378, 369, 552, 1386, 14]
INFO:root:FL Epoch: 267 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 267 Num points on workers: [200 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 267 Training on worker :1242
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1242 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466250
INFO:root:Worker: 1242 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699372
INFO:root:FL Epoch: 267 Norm Difference for worker 1242 is 0.870437
INFO:root:FL Epoch: 267 Done on worker:1242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :992
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 992 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731962
INFO:root:Worker: 992 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363376
INFO:root:FL Epoch: 267 Norm Difference for worker 992 is 0.946615
INFO:root:FL Epoch: 267 Done on worker:992
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1939
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609314
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543455
INFO:root:FL Epoch: 267 Norm Difference for worker 1939 is 0.981724
INFO:root:FL Epoch: 267 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1482
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524846
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404246
INFO:root:FL Epoch: 267 Norm Difference for worker 1482 is 0.923729
INFO:root:FL Epoch: 267 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :179
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 179 Train Epoch: 0 [0/201 (0%)]	Loss: 0.643727
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 179 Train Epoch: 1 [0/201 (0%)]	Loss: 0.651678
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 267 Norm Difference for worker 179 is 0.988881
INFO:root:FL Epoch: 267 Done on worker:179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :378
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657795
INFO:root:Worker: 378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580403
INFO:root:FL Epoch: 267 Norm Difference for worker 378 is 0.896381
INFO:root:FL Epoch: 267 Done on worker:378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :369
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533673
INFO:root:Worker: 369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546251
INFO:root:FL Epoch: 267 Norm Difference for worker 369 is 0.949617
INFO:root:FL Epoch: 267 Done on worker:369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :552
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593410
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537833
INFO:root:FL Epoch: 267 Norm Difference for worker 552 is 0.939039
INFO:root:FL Epoch: 267 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :1386
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755065
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360908
INFO:root:FL Epoch: 267 Norm Difference for worker 1386 is 0.901377
INFO:root:FL Epoch: 267 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 267 Training on worker :14
INFO:root:FL Epoch: 267 Using Learning rate : 0.029355804499856693 
INFO:root:FL Epoch: 267 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.500123
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.418338
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 267 Norm Difference for worker 14 is 0.889476
INFO:root:FL Epoch: 267 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1242
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 267 Ends   ===================
INFO:root:Epoch:267 Global Model Test Loss:0.5130529035540188 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:267 Global Model Backdoor Test Loss:0.28969771911700565                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 268 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 268 Workers Selected : [439, 1573, 985, 1627, 936, 157, 1686, 820, 634, 411]
INFO:root:FL Epoch: 268 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 268 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 268 Training on worker :439
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600893
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504213
INFO:root:FL Epoch: 268 Norm Difference for worker 439 is 1.02883
INFO:root:FL Epoch: 268 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1573
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556948
INFO:root:Worker: 1573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.967156
INFO:root:FL Epoch: 268 Norm Difference for worker 1573 is 1.062899
INFO:root:FL Epoch: 268 Done on worker:1573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :985
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 985 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546539
INFO:root:Worker: 985 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403004
INFO:root:FL Epoch: 268 Norm Difference for worker 985 is 1.060259
INFO:root:FL Epoch: 268 Done on worker:985
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1627
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755826
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590780
INFO:root:FL Epoch: 268 Norm Difference for worker 1627 is 0.934932
INFO:root:FL Epoch: 268 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :936
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620502
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476205
INFO:root:FL Epoch: 268 Norm Difference for worker 936 is 0.979607
INFO:root:FL Epoch: 268 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :157
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 157 Train Epoch: 0 [0/201 (0%)]	Loss: 0.698695
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 157 Train Epoch: 1 [0/201 (0%)]	Loss: 0.477946
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 268 Norm Difference for worker 157 is 1.040693
INFO:root:FL Epoch: 268 Done on worker:157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :1686
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 1686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493022
INFO:root:Worker: 1686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408936
INFO:root:FL Epoch: 268 Norm Difference for worker 1686 is 1.005888
INFO:root:FL Epoch: 268 Done on worker:1686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :820
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544147
INFO:root:Worker: 820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458186
INFO:root:FL Epoch: 268 Norm Difference for worker 820 is 1.000507
INFO:root:FL Epoch: 268 Done on worker:820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :634
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576833
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463742
INFO:root:FL Epoch: 268 Norm Difference for worker 634 is 1.007376
INFO:root:FL Epoch: 268 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 268 Training on worker :411
INFO:root:FL Epoch: 268 Using Learning rate : 0.029297092890856982 
INFO:root:FL Epoch: 268 Normal Training
INFO:root:Worker: 411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618089
INFO:root:Worker: 411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597486
INFO:root:FL Epoch: 268 Norm Difference for worker 411 is 1.075862
INFO:root:FL Epoch: 268 Done on worker:411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1627
INFO:root:Norm of Aggregated Model: 5154.99267578125
INFO:root:Aggregating After Defense
INFO:root:================FL round 268 Ends   ===================
INFO:root:Epoch:268 Global Model Test Loss:0.5381595071624307 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:268 Global Model Backdoor Test Loss:0.3554062445958455                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 269 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 269 Workers Selected : [231, 600, 767, 1787, 1559, 174, 1415, 66, 1281, 498]
INFO:root:FL Epoch: 269 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 269 Num points on workers: [201 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 269 Training on worker :231
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 231 Train Epoch: 0 [0/201 (0%)]	Loss: 0.283871
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 231 Train Epoch: 1 [0/201 (0%)]	Loss: 0.298576
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 269 Norm Difference for worker 231 is 0.887428
INFO:root:FL Epoch: 269 Done on worker:231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :600
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406291
INFO:root:Worker: 600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374777
INFO:root:FL Epoch: 269 Norm Difference for worker 600 is 1.088548
INFO:root:FL Epoch: 269 Done on worker:600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :767
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802084
INFO:root:Worker: 767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.670249
INFO:root:FL Epoch: 269 Norm Difference for worker 767 is 1.089854
INFO:root:FL Epoch: 269 Done on worker:767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1787
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637518
INFO:root:Worker: 1787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566890
INFO:root:FL Epoch: 269 Norm Difference for worker 1787 is 1.019293
INFO:root:FL Epoch: 269 Done on worker:1787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1559
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571603
INFO:root:Worker: 1559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476825
INFO:root:FL Epoch: 269 Norm Difference for worker 1559 is 1.08361
INFO:root:FL Epoch: 269 Done on worker:1559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :174
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 174 Train Epoch: 0 [0/201 (0%)]	Loss: 0.610142
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 174 Train Epoch: 1 [0/201 (0%)]	Loss: 0.618833
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 269 Norm Difference for worker 174 is 1.11082
INFO:root:FL Epoch: 269 Done on worker:174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1415
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558931
INFO:root:Worker: 1415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491089
INFO:root:FL Epoch: 269 Norm Difference for worker 1415 is 1.180123
INFO:root:FL Epoch: 269 Done on worker:1415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :66
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 66 Train Epoch: 0 [0/201 (0%)]	Loss: 0.434913
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 66 Train Epoch: 1 [0/201 (0%)]	Loss: 0.448362
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 269 Norm Difference for worker 66 is 1.017727
INFO:root:FL Epoch: 269 Done on worker:66
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :1281
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 1281 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323856
INFO:root:Worker: 1281 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456230
INFO:root:FL Epoch: 269 Norm Difference for worker 1281 is 1.059205
INFO:root:FL Epoch: 269 Done on worker:1281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 269 Training on worker :498
INFO:root:FL Epoch: 269 Using Learning rate : 0.029238498705075264 
INFO:root:FL Epoch: 269 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691403
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377254
INFO:root:FL Epoch: 269 Norm Difference for worker 498 is 1.053667
INFO:root:FL Epoch: 269 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 231
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 269 Ends   ===================
INFO:root:Epoch:269 Global Model Test Loss:0.527293852146934 and Test Accuracy:75.0 
INFO:root:Epoch:269 Global Model Backdoor Test Loss:0.19800052046775818                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 270 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 270 Workers Selected : [1022, 484, 1546, 514, 1311, 1474, 1511, 1447, 740, 136]
INFO:root:FL Epoch: 270 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 270 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 270 Training on worker :1022
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389435
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.737510
INFO:root:FL Epoch: 270 Norm Difference for worker 1022 is 1.253389
INFO:root:FL Epoch: 270 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :484
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519090
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433169
INFO:root:FL Epoch: 270 Norm Difference for worker 484 is 1.305804
INFO:root:FL Epoch: 270 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1546
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438493
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466097
INFO:root:FL Epoch: 270 Norm Difference for worker 1546 is 1.250801
INFO:root:FL Epoch: 270 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :514
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386656
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263903
INFO:root:FL Epoch: 270 Norm Difference for worker 514 is 1.231771
INFO:root:FL Epoch: 270 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1311
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.781341
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542642
INFO:root:FL Epoch: 270 Norm Difference for worker 1311 is 1.396996
INFO:root:FL Epoch: 270 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1474
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639899
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.757509
INFO:root:FL Epoch: 270 Norm Difference for worker 1474 is 1.275357
INFO:root:FL Epoch: 270 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1511
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699317
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529983
INFO:root:FL Epoch: 270 Norm Difference for worker 1511 is 1.511713
INFO:root:FL Epoch: 270 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :1447
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 1447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.843591
INFO:root:Worker: 1447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352634
INFO:root:FL Epoch: 270 Norm Difference for worker 1447 is 1.31591
INFO:root:FL Epoch: 270 Done on worker:1447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :740
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420032
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429948
INFO:root:FL Epoch: 270 Norm Difference for worker 740 is 1.364092
INFO:root:FL Epoch: 270 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 270 Training on worker :136
INFO:root:FL Epoch: 270 Using Learning rate : 0.02918002170766511 
INFO:root:FL Epoch: 270 Normal Training
INFO:root:Worker: 136 Train Epoch: 0 [0/201 (0%)]	Loss: 0.671581
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 136 Train Epoch: 1 [0/201 (0%)]	Loss: 0.491637
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 270 Norm Difference for worker 136 is 1.224771
INFO:root:FL Epoch: 270 Done on worker:136
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 514
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 270 Ends   ===================
INFO:root:Epoch:270 Global Model Test Loss:0.5197599661700866 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:270 Global Model Backdoor Test Loss:0.2576748902599017                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 271 Begins ===================
INFO:root:FL Epoch: 271 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 271 Workers Selected : [0, 1525, 727, 38, 1481, 231, 1592, 523, 803, 1708]
INFO:root:FL Epoch: 271 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 271 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 271 Training on worker :0
INFO:root:FL Epoch: 271 Using Learning rate : 0.005824332332849957 
INFO:root:FL Epoch: 271 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445154
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.137011
INFO:root:FL Epoch: 271 Worker: 0 Backdoor Test Loss: 0.21818901350100836 Backdoor Test Accuracy: 90.0
INFO:root:FL Epoch: 271 Worker: 0 Backdoor Train Loss: 0.20209457129240035 Backdoor Train Accuracy: 92.0
INFO:root:FL Epoch: 271 Norm Difference for worker 0 is 0.188309
INFO:root:FL Epoch: 271 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1525
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702699
INFO:root:Worker: 1525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704940
INFO:root:FL Epoch: 271 Norm Difference for worker 1525 is 1.231798
INFO:root:FL Epoch: 271 Done on worker:1525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :727
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660408
INFO:root:Worker: 727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639152
INFO:root:FL Epoch: 271 Norm Difference for worker 727 is 1.289594
INFO:root:FL Epoch: 271 Done on worker:727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :38
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.435030
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.519758
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 38 is 1.1043
INFO:root:FL Epoch: 271 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1481
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642539
INFO:root:Worker: 1481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452819
INFO:root:FL Epoch: 271 Norm Difference for worker 1481 is 1.361872
INFO:root:FL Epoch: 271 Done on worker:1481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :231
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 231 Train Epoch: 0 [0/201 (0%)]	Loss: 0.113892
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 231 Train Epoch: 1 [0/201 (0%)]	Loss: 0.112574
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 271 Norm Difference for worker 231 is 0.729046
INFO:root:FL Epoch: 271 Done on worker:231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1592
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.818685
INFO:root:Worker: 1592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547530
INFO:root:FL Epoch: 271 Norm Difference for worker 1592 is 1.264304
INFO:root:FL Epoch: 271 Done on worker:1592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :523
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.883168
INFO:root:Worker: 523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331644
INFO:root:FL Epoch: 271 Norm Difference for worker 523 is 1.316165
INFO:root:FL Epoch: 271 Done on worker:523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :803
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.250724
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572882
INFO:root:FL Epoch: 271 Norm Difference for worker 803 is 1.264301
INFO:root:FL Epoch: 271 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 271 Training on worker :1708
INFO:root:FL Epoch: 271 Using Learning rate : 0.029121661664249784 
INFO:root:FL Epoch: 271 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490206
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341765
INFO:root:FL Epoch: 271 Norm Difference for worker 1708 is 1.182475
INFO:root:FL Epoch: 271 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 271 Ends   ===================
INFO:root:Epoch:271 Global Model Test Loss:0.5222423567491419 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:271 Global Model Backdoor Test Loss:0.21818901350100836                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 272 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 272 Workers Selected : [210, 1879, 1271, 837, 1009, 1713, 1030, 455, 1733, 909]
INFO:root:FL Epoch: 272 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 272 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 272 Training on worker :210
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 210 Train Epoch: 0 [0/201 (0%)]	Loss: 0.548467
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 210 Train Epoch: 1 [0/201 (0%)]	Loss: 0.464203
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 272 Norm Difference for worker 210 is 1.206059
INFO:root:FL Epoch: 272 Done on worker:210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1879
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.725237
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562631
INFO:root:FL Epoch: 272 Norm Difference for worker 1879 is 1.302247
INFO:root:FL Epoch: 272 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1271
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1271 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653550
INFO:root:Worker: 1271 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417074
INFO:root:FL Epoch: 272 Norm Difference for worker 1271 is 1.183028
INFO:root:FL Epoch: 272 Done on worker:1271
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :837
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.314428
INFO:root:Worker: 837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480485
INFO:root:FL Epoch: 272 Norm Difference for worker 837 is 1.284055
INFO:root:FL Epoch: 272 Done on worker:837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1009
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1009 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672135
INFO:root:Worker: 1009 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256135
INFO:root:FL Epoch: 272 Norm Difference for worker 1009 is 1.269262
INFO:root:FL Epoch: 272 Done on worker:1009
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1713
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613301
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451915
INFO:root:FL Epoch: 272 Norm Difference for worker 1713 is 1.279637
INFO:root:FL Epoch: 272 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1030
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1030 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751950
INFO:root:Worker: 1030 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244402
INFO:root:FL Epoch: 272 Norm Difference for worker 1030 is 1.361419
INFO:root:FL Epoch: 272 Done on worker:1030
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :455
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739716
INFO:root:Worker: 455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.317505
INFO:root:FL Epoch: 272 Norm Difference for worker 455 is 1.380554
INFO:root:FL Epoch: 272 Done on worker:455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :1733
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 1733 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439625
INFO:root:Worker: 1733 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582555
INFO:root:FL Epoch: 272 Norm Difference for worker 1733 is 1.217688
INFO:root:FL Epoch: 272 Done on worker:1733
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 272 Training on worker :909
INFO:root:FL Epoch: 272 Using Learning rate : 0.029063418340921285 
INFO:root:FL Epoch: 272 Normal Training
INFO:root:Worker: 909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775904
INFO:root:Worker: 909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663013
INFO:root:FL Epoch: 272 Norm Difference for worker 909 is 1.294599
INFO:root:FL Epoch: 272 Done on worker:909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1733
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 272 Ends   ===================
INFO:root:Epoch:272 Global Model Test Loss:0.5256852910799139 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:272 Global Model Backdoor Test Loss:0.25738799075285596                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 273 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 273 Workers Selected : [1347, 746, 242, 1693, 1007, 1377, 1190, 1081, 1284, 1947]
INFO:root:FL Epoch: 273 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 273 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 273 Training on worker :1347
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602570
INFO:root:Worker: 1347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371244
INFO:root:FL Epoch: 273 Norm Difference for worker 1347 is 1.077439
INFO:root:FL Epoch: 273 Done on worker:1347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :746
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 746 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548699
INFO:root:Worker: 746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332649
INFO:root:FL Epoch: 273 Norm Difference for worker 746 is 1.024658
INFO:root:FL Epoch: 273 Done on worker:746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :242
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.528480
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.486016
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 273 Norm Difference for worker 242 is 1.010144
INFO:root:FL Epoch: 273 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1693
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528860
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408629
INFO:root:FL Epoch: 273 Norm Difference for worker 1693 is 1.016919
INFO:root:FL Epoch: 273 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1007
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1007 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597058
INFO:root:Worker: 1007 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418270
INFO:root:FL Epoch: 273 Norm Difference for worker 1007 is 1.027405
INFO:root:FL Epoch: 273 Done on worker:1007
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1377
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543343
INFO:root:Worker: 1377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313815
INFO:root:FL Epoch: 273 Norm Difference for worker 1377 is 1.072342
INFO:root:FL Epoch: 273 Done on worker:1377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1190
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447063
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638800
INFO:root:FL Epoch: 273 Norm Difference for worker 1190 is 0.998392
INFO:root:FL Epoch: 273 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1081
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757718
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.842472
INFO:root:FL Epoch: 273 Norm Difference for worker 1081 is 1.129217
INFO:root:FL Epoch: 273 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1284
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1284 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528070
INFO:root:Worker: 1284 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534948
INFO:root:FL Epoch: 273 Norm Difference for worker 1284 is 1.002567
INFO:root:FL Epoch: 273 Done on worker:1284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 273 Training on worker :1947
INFO:root:FL Epoch: 273 Using Learning rate : 0.02900529150423944 
INFO:root:FL Epoch: 273 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435960
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368100
INFO:root:FL Epoch: 273 Norm Difference for worker 1947 is 1.028387
INFO:root:FL Epoch: 273 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1284
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 273 Ends   ===================
INFO:root:Epoch:273 Global Model Test Loss:0.5147630922934588 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:273 Global Model Backdoor Test Loss:0.24476078152656555                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 274 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 274 Workers Selected : [1826, 1048, 108, 460, 1181, 1105, 1022, 358, 1429, 1096]
INFO:root:FL Epoch: 274 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 274 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 274 Training on worker :1826
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396989
INFO:root:Worker: 1826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259000
INFO:root:FL Epoch: 274 Norm Difference for worker 1826 is 0.989355
INFO:root:FL Epoch: 274 Done on worker:1826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1048
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1048 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588792
INFO:root:Worker: 1048 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600667
INFO:root:FL Epoch: 274 Norm Difference for worker 1048 is 1.046686
INFO:root:FL Epoch: 274 Done on worker:1048
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :108
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 108 Train Epoch: 0 [0/201 (0%)]	Loss: 0.306421
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 108 Train Epoch: 1 [0/201 (0%)]	Loss: 0.334353
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 274 Norm Difference for worker 108 is 0.88128
INFO:root:FL Epoch: 274 Done on worker:108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :460
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.236674
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399126
INFO:root:FL Epoch: 274 Norm Difference for worker 460 is 1.046886
INFO:root:FL Epoch: 274 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1181
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1181 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538711
INFO:root:Worker: 1181 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373347
INFO:root:FL Epoch: 274 Norm Difference for worker 1181 is 0.98512
INFO:root:FL Epoch: 274 Done on worker:1181
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1105
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1105 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551217
INFO:root:Worker: 1105 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618198
INFO:root:FL Epoch: 274 Norm Difference for worker 1105 is 0.971787
INFO:root:FL Epoch: 274 Done on worker:1105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1022
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638613
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491289
INFO:root:FL Epoch: 274 Norm Difference for worker 1022 is 0.926451
INFO:root:FL Epoch: 274 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :358
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554924
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418579
INFO:root:FL Epoch: 274 Norm Difference for worker 358 is 0.976085
INFO:root:FL Epoch: 274 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1429
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391619
INFO:root:Worker: 1429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347344
INFO:root:FL Epoch: 274 Norm Difference for worker 1429 is 0.989857
INFO:root:FL Epoch: 274 Done on worker:1429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 274 Training on worker :1096
INFO:root:FL Epoch: 274 Using Learning rate : 0.028947280921230962 
INFO:root:FL Epoch: 274 Normal Training
INFO:root:Worker: 1096 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585565
INFO:root:Worker: 1096 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382167
INFO:root:FL Epoch: 274 Norm Difference for worker 1096 is 1.046224
INFO:root:FL Epoch: 274 Done on worker:1096
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 108
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 274 Ends   ===================
INFO:root:Epoch:274 Global Model Test Loss:0.525398899527157 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:274 Global Model Backdoor Test Loss:0.2525345707933108                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 275 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 275 Workers Selected : [820, 944, 1583, 1094, 1529, 1639, 1713, 24, 921, 368]
INFO:root:FL Epoch: 275 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 275 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 275 Training on worker :820
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500628
INFO:root:Worker: 820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541621
INFO:root:FL Epoch: 275 Norm Difference for worker 820 is 1.094729
INFO:root:FL Epoch: 275 Done on worker:820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :944
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478668
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326179
INFO:root:FL Epoch: 275 Norm Difference for worker 944 is 1.133514
INFO:root:FL Epoch: 275 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1583
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1583 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534023
INFO:root:Worker: 1583 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372616
INFO:root:FL Epoch: 275 Norm Difference for worker 1583 is 1.157594
INFO:root:FL Epoch: 275 Done on worker:1583
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1094
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1094 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502957
INFO:root:Worker: 1094 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320520
INFO:root:FL Epoch: 275 Norm Difference for worker 1094 is 1.069675
INFO:root:FL Epoch: 275 Done on worker:1094
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1529
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501722
INFO:root:Worker: 1529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493293
INFO:root:FL Epoch: 275 Norm Difference for worker 1529 is 1.177054
INFO:root:FL Epoch: 275 Done on worker:1529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1639
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377547
INFO:root:Worker: 1639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516777
INFO:root:FL Epoch: 275 Norm Difference for worker 1639 is 1.065849
INFO:root:FL Epoch: 275 Done on worker:1639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :1713
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743098
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434219
INFO:root:FL Epoch: 275 Norm Difference for worker 1713 is 1.119405
INFO:root:FL Epoch: 275 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :24
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.553384
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.482166
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 275 Norm Difference for worker 24 is 1.216498
INFO:root:FL Epoch: 275 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :921
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504146
INFO:root:Worker: 921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435486
INFO:root:FL Epoch: 275 Norm Difference for worker 921 is 1.167839
INFO:root:FL Epoch: 275 Done on worker:921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 275 Training on worker :368
INFO:root:FL Epoch: 275 Using Learning rate : 0.028889386359388498 
INFO:root:FL Epoch: 275 Normal Training
INFO:root:Worker: 368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531178
INFO:root:Worker: 368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601274
INFO:root:FL Epoch: 275 Norm Difference for worker 368 is 1.16058
INFO:root:FL Epoch: 275 Done on worker:368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 820
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 275 Ends   ===================
INFO:root:Epoch:275 Global Model Test Loss:0.5332477162866032 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:275 Global Model Backdoor Test Loss:0.2917834669351578                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 276 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 276 Workers Selected : [766, 693, 758, 1027, 1635, 166, 63, 585, 1260, 783]
INFO:root:FL Epoch: 276 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 276 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 276 Training on worker :766
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.407087
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254611
INFO:root:FL Epoch: 276 Norm Difference for worker 766 is 0.919454
INFO:root:FL Epoch: 276 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :693
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.292570
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266153
INFO:root:FL Epoch: 276 Norm Difference for worker 693 is 0.807143
INFO:root:FL Epoch: 276 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :758
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554873
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570087
INFO:root:FL Epoch: 276 Norm Difference for worker 758 is 0.995914
INFO:root:FL Epoch: 276 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1027
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1027 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553216
INFO:root:Worker: 1027 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413553
INFO:root:FL Epoch: 276 Norm Difference for worker 1027 is 0.959866
INFO:root:FL Epoch: 276 Done on worker:1027
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1635
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1635 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391930
INFO:root:Worker: 1635 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355412
INFO:root:FL Epoch: 276 Norm Difference for worker 1635 is 1.010792
INFO:root:FL Epoch: 276 Done on worker:1635
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :166
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 166 Train Epoch: 0 [0/201 (0%)]	Loss: 0.669642
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 166 Train Epoch: 1 [0/201 (0%)]	Loss: 0.517667
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 166 is 0.940296
INFO:root:FL Epoch: 276 Done on worker:166
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :63
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 63 Train Epoch: 0 [0/201 (0%)]	Loss: 0.472163
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 63 Train Epoch: 1 [0/201 (0%)]	Loss: 0.351702
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 276 Norm Difference for worker 63 is 0.962915
INFO:root:FL Epoch: 276 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :585
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688702
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512642
INFO:root:FL Epoch: 276 Norm Difference for worker 585 is 0.979199
INFO:root:FL Epoch: 276 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :1260
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701471
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404590
INFO:root:FL Epoch: 276 Norm Difference for worker 1260 is 1.019064
INFO:root:FL Epoch: 276 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 276 Training on worker :783
INFO:root:FL Epoch: 276 Using Learning rate : 0.028831607586669722 
INFO:root:FL Epoch: 276 Normal Training
INFO:root:Worker: 783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467787
INFO:root:Worker: 783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.607490
INFO:root:FL Epoch: 276 Norm Difference for worker 783 is 1.013818
INFO:root:FL Epoch: 276 Done on worker:783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 693
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 276 Ends   ===================
INFO:root:Epoch:276 Global Model Test Loss:0.5618205123087939 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:276 Global Model Backdoor Test Loss:0.23619682590166727                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 277 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 277 Workers Selected : [1739, 254, 1838, 242, 1882, 588, 1055, 1373, 500, 101]
INFO:root:FL Epoch: 277 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 277 Num points on workers: [200 201 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 277 Training on worker :1739
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1739 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507514
INFO:root:Worker: 1739 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431634
INFO:root:FL Epoch: 277 Norm Difference for worker 1739 is 1.308808
INFO:root:FL Epoch: 277 Done on worker:1739
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :254
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 254 Train Epoch: 0 [0/201 (0%)]	Loss: 0.554263
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 254 Train Epoch: 1 [0/201 (0%)]	Loss: 0.267151
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 254 is 1.179175
INFO:root:FL Epoch: 277 Done on worker:254
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1838
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539175
INFO:root:Worker: 1838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.767153
INFO:root:FL Epoch: 277 Norm Difference for worker 1838 is 1.264365
INFO:root:FL Epoch: 277 Done on worker:1838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :242
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 242 Train Epoch: 0 [0/201 (0%)]	Loss: 0.407622
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 242 Train Epoch: 1 [0/201 (0%)]	Loss: 0.564830
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 242 is 1.252055
INFO:root:FL Epoch: 277 Done on worker:242
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1882
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731203
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.817715
INFO:root:FL Epoch: 277 Norm Difference for worker 1882 is 1.454172
INFO:root:FL Epoch: 277 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :588
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709033
INFO:root:Worker: 588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384053
INFO:root:FL Epoch: 277 Norm Difference for worker 588 is 1.340936
INFO:root:FL Epoch: 277 Done on worker:588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1055
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1055 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330673
INFO:root:Worker: 1055 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597112
INFO:root:FL Epoch: 277 Norm Difference for worker 1055 is 1.387677
INFO:root:FL Epoch: 277 Done on worker:1055
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :1373
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 1373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532496
INFO:root:Worker: 1373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321791
INFO:root:FL Epoch: 277 Norm Difference for worker 1373 is 1.413295
INFO:root:FL Epoch: 277 Done on worker:1373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :500
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509333
INFO:root:Worker: 500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340213
INFO:root:FL Epoch: 277 Norm Difference for worker 500 is 1.325335
INFO:root:FL Epoch: 277 Done on worker:500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 277 Training on worker :101
INFO:root:FL Epoch: 277 Using Learning rate : 0.028773944371496385 
INFO:root:FL Epoch: 277 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.792894
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.613036
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 277 Norm Difference for worker 101 is 1.263126
INFO:root:FL Epoch: 277 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 242
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 277 Ends   ===================
INFO:root:Epoch:277 Global Model Test Loss:0.5157861902433283 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:277 Global Model Backdoor Test Loss:0.21100574731826782                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 278 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 278 Workers Selected : [127, 516, 1591, 858, 1179, 797, 1814, 1671, 118, 1526]
INFO:root:FL Epoch: 278 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 278 Num points on workers: [201 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 278 Training on worker :127
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 127 Train Epoch: 0 [0/201 (0%)]	Loss: 0.493468
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 127 Train Epoch: 1 [0/201 (0%)]	Loss: 0.697379
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 127 is 0.956101
INFO:root:FL Epoch: 278 Done on worker:127
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :516
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628122
INFO:root:Worker: 516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494854
INFO:root:FL Epoch: 278 Norm Difference for worker 516 is 1.032901
INFO:root:FL Epoch: 278 Done on worker:516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1591
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.486226
INFO:root:Worker: 1591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539808
INFO:root:FL Epoch: 278 Norm Difference for worker 1591 is 0.992813
INFO:root:FL Epoch: 278 Done on worker:1591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :858
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366119
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452506
INFO:root:FL Epoch: 278 Norm Difference for worker 858 is 0.978799
INFO:root:FL Epoch: 278 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1179
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1179 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391931
INFO:root:Worker: 1179 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439728
INFO:root:FL Epoch: 278 Norm Difference for worker 1179 is 1.033288
INFO:root:FL Epoch: 278 Done on worker:1179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :797
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782652
INFO:root:Worker: 797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626745
INFO:root:FL Epoch: 278 Norm Difference for worker 797 is 1.021917
INFO:root:FL Epoch: 278 Done on worker:797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1814
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1814 Train Epoch: 0 [0/200 (0%)]	Loss: 1.017656
INFO:root:Worker: 1814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454874
INFO:root:FL Epoch: 278 Norm Difference for worker 1814 is 0.986866
INFO:root:FL Epoch: 278 Done on worker:1814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1671
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649189
INFO:root:Worker: 1671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430715
INFO:root:FL Epoch: 278 Norm Difference for worker 1671 is 0.970542
INFO:root:FL Epoch: 278 Done on worker:1671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :118
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 118 Train Epoch: 0 [0/201 (0%)]	Loss: 0.785514
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 118 Train Epoch: 1 [0/201 (0%)]	Loss: 0.449590
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 278 Norm Difference for worker 118 is 0.948045
INFO:root:FL Epoch: 278 Done on worker:118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 278 Training on worker :1526
INFO:root:FL Epoch: 278 Using Learning rate : 0.028716396482753394 
INFO:root:FL Epoch: 278 Normal Training
INFO:root:Worker: 1526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506700
INFO:root:Worker: 1526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459725
INFO:root:FL Epoch: 278 Norm Difference for worker 1526 is 0.948599
INFO:root:FL Epoch: 278 Done on worker:1526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1526
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 278 Ends   ===================
INFO:root:Epoch:278 Global Model Test Loss:0.5138720782364116 and Test Accuracy:71.47058823529412 
INFO:root:Epoch:278 Global Model Backdoor Test Loss:0.24344433844089508                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 279 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 279 Workers Selected : [891, 1681, 975, 1421, 1659, 1795, 563, 1049, 120, 1456]
INFO:root:FL Epoch: 279 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 279 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 279 Training on worker :891
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 891 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387501
INFO:root:Worker: 891 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580510
INFO:root:FL Epoch: 279 Norm Difference for worker 891 is 0.946011
INFO:root:FL Epoch: 279 Done on worker:891
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1681
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433313
INFO:root:Worker: 1681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493700
INFO:root:FL Epoch: 279 Norm Difference for worker 1681 is 0.922924
INFO:root:FL Epoch: 279 Done on worker:1681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :975
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569824
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558614
INFO:root:FL Epoch: 279 Norm Difference for worker 975 is 0.974811
INFO:root:FL Epoch: 279 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1421
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324313
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496079
INFO:root:FL Epoch: 279 Norm Difference for worker 1421 is 0.902891
INFO:root:FL Epoch: 279 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1659
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539887
INFO:root:Worker: 1659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421258
INFO:root:FL Epoch: 279 Norm Difference for worker 1659 is 0.937813
INFO:root:FL Epoch: 279 Done on worker:1659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1795
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734136
INFO:root:Worker: 1795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457148
INFO:root:FL Epoch: 279 Norm Difference for worker 1795 is 0.916789
INFO:root:FL Epoch: 279 Done on worker:1795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :563
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541345
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425469
INFO:root:FL Epoch: 279 Norm Difference for worker 563 is 0.85489
INFO:root:FL Epoch: 279 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1049
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1049 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707764
INFO:root:Worker: 1049 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540478
INFO:root:FL Epoch: 279 Norm Difference for worker 1049 is 0.811375
INFO:root:FL Epoch: 279 Done on worker:1049
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :120
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 120 Train Epoch: 0 [0/201 (0%)]	Loss: 0.378545
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 120 Train Epoch: 1 [0/201 (0%)]	Loss: 0.663519
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 279 Norm Difference for worker 120 is 0.910941
INFO:root:FL Epoch: 279 Done on worker:120
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 279 Training on worker :1456
INFO:root:FL Epoch: 279 Using Learning rate : 0.028658963689787882 
INFO:root:FL Epoch: 279 Normal Training
INFO:root:Worker: 1456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657200
INFO:root:Worker: 1456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537203
INFO:root:FL Epoch: 279 Norm Difference for worker 1456 is 0.907517
INFO:root:FL Epoch: 279 Done on worker:1456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1049
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 279 Ends   ===================
INFO:root:Epoch:279 Global Model Test Loss:0.5079828167662901 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:279 Global Model Backdoor Test Loss:0.2705972542365392                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 280 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 280 Workers Selected : [881, 1575, 1932, 1349, 1004, 566, 1048, 1756, 373, 1745]
INFO:root:FL Epoch: 280 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 280 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 280 Training on worker :881
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481602
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279852
INFO:root:FL Epoch: 280 Norm Difference for worker 881 is 0.882402
INFO:root:FL Epoch: 280 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1575
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566758
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560913
INFO:root:FL Epoch: 280 Norm Difference for worker 1575 is 0.980923
INFO:root:FL Epoch: 280 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1932
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530496
INFO:root:Worker: 1932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544789
INFO:root:FL Epoch: 280 Norm Difference for worker 1932 is 0.864583
INFO:root:FL Epoch: 280 Done on worker:1932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1349
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483367
INFO:root:Worker: 1349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421427
INFO:root:FL Epoch: 280 Norm Difference for worker 1349 is 0.943285
INFO:root:FL Epoch: 280 Done on worker:1349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1004
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1004 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588074
INFO:root:Worker: 1004 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410381
INFO:root:FL Epoch: 280 Norm Difference for worker 1004 is 0.990981
INFO:root:FL Epoch: 280 Done on worker:1004
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :566
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606768
INFO:root:Worker: 566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454733
INFO:root:FL Epoch: 280 Norm Difference for worker 566 is 0.972846
INFO:root:FL Epoch: 280 Done on worker:566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1048
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1048 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406116
INFO:root:Worker: 1048 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605788
INFO:root:FL Epoch: 280 Norm Difference for worker 1048 is 1.027184
INFO:root:FL Epoch: 280 Done on worker:1048
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1756
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529674
INFO:root:Worker: 1756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423862
INFO:root:FL Epoch: 280 Norm Difference for worker 1756 is 0.942933
INFO:root:FL Epoch: 280 Done on worker:1756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :373
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414443
INFO:root:Worker: 373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468763
INFO:root:FL Epoch: 280 Norm Difference for worker 373 is 0.974377
INFO:root:FL Epoch: 280 Done on worker:373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 280 Training on worker :1745
INFO:root:FL Epoch: 280 Using Learning rate : 0.02860164576240831 
INFO:root:FL Epoch: 280 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565118
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404343
INFO:root:FL Epoch: 280 Norm Difference for worker 1745 is 0.920917
INFO:root:FL Epoch: 280 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 881
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 280 Ends   ===================
INFO:root:Epoch:280 Global Model Test Loss:0.5068851244800231 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:280 Global Model Backdoor Test Loss:0.15086336309711137                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 281 Begins ===================
INFO:root:FL Epoch: 281 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 281 Workers Selected : [0, 1663, 1823, 225, 1113, 1061, 810, 401, 1516, 106]
INFO:root:FL Epoch: 281 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 281 Num points on workers: [200 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 281 Training on worker :0
INFO:root:FL Epoch: 281 Using Learning rate : 0.005708888494176698 
INFO:root:FL Epoch: 281 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408899
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427692
INFO:root:FL Epoch: 281 Worker: 0 Backdoor Test Loss: 0.1486805814007918 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 281 Worker: 0 Backdoor Train Loss: 0.19141404181718827 Backdoor Train Accuracy: 94.0
INFO:root:FL Epoch: 281 Norm Difference for worker 0 is 0.20289
INFO:root:FL Epoch: 281 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1663
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367884
INFO:root:Worker: 1663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.166638
INFO:root:FL Epoch: 281 Norm Difference for worker 1663 is 1.045307
INFO:root:FL Epoch: 281 Done on worker:1663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1823
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.962505
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.273892
INFO:root:FL Epoch: 281 Norm Difference for worker 1823 is 1.333248
INFO:root:FL Epoch: 281 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :225
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 225 Train Epoch: 0 [0/201 (0%)]	Loss: 0.487922
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 225 Train Epoch: 1 [0/201 (0%)]	Loss: 0.325808
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 281 Norm Difference for worker 225 is 1.322091
INFO:root:FL Epoch: 281 Done on worker:225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1113
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1113 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734508
INFO:root:Worker: 1113 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586177
INFO:root:FL Epoch: 281 Norm Difference for worker 1113 is 1.314358
INFO:root:FL Epoch: 281 Done on worker:1113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1061
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550569
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323330
INFO:root:FL Epoch: 281 Norm Difference for worker 1061 is 1.247752
INFO:root:FL Epoch: 281 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :810
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.789472
INFO:root:Worker: 810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617750
INFO:root:FL Epoch: 281 Norm Difference for worker 810 is 1.412606
INFO:root:FL Epoch: 281 Done on worker:810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :401
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624730
INFO:root:Worker: 401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307846
INFO:root:FL Epoch: 281 Norm Difference for worker 401 is 1.143759
INFO:root:FL Epoch: 281 Done on worker:401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :1516
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639113
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461224
INFO:root:FL Epoch: 281 Norm Difference for worker 1516 is 1.230304
INFO:root:FL Epoch: 281 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 281 Training on worker :106
INFO:root:FL Epoch: 281 Using Learning rate : 0.02854444247088349 
INFO:root:FL Epoch: 281 Normal Training
INFO:root:Worker: 106 Train Epoch: 0 [0/201 (0%)]	Loss: 0.708211
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 106 Train Epoch: 1 [0/201 (0%)]	Loss: 0.449705
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 281 Norm Difference for worker 106 is 1.346238
INFO:root:FL Epoch: 281 Done on worker:106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.9931640625
INFO:root:Aggregating After Defense
INFO:root:================FL round 281 Ends   ===================
INFO:root:Epoch:281 Global Model Test Loss:0.5166954468278324 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:281 Global Model Backdoor Test Loss:0.1486805814007918                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 282 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 282 Workers Selected : [1039, 163, 1432, 1259, 139, 565, 741, 775, 1402, 1326]
INFO:root:FL Epoch: 282 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 282 Num points on workers: [200 201 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 282 Training on worker :1039
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1039 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648494
INFO:root:Worker: 1039 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592605
INFO:root:FL Epoch: 282 Norm Difference for worker 1039 is 1.395908
INFO:root:FL Epoch: 282 Done on worker:1039
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :163
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.911878
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.351741
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 163 is 1.279519
INFO:root:FL Epoch: 282 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1432
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.811633
INFO:root:Worker: 1432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581487
INFO:root:FL Epoch: 282 Norm Difference for worker 1432 is 1.334478
INFO:root:FL Epoch: 282 Done on worker:1432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1259
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1259 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343277
INFO:root:Worker: 1259 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287367
INFO:root:FL Epoch: 282 Norm Difference for worker 1259 is 1.262534
INFO:root:FL Epoch: 282 Done on worker:1259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :139
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 139 Train Epoch: 0 [0/201 (0%)]	Loss: 0.713975
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 139 Train Epoch: 1 [0/201 (0%)]	Loss: 0.364082
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 282 Norm Difference for worker 139 is 1.23377
INFO:root:FL Epoch: 282 Done on worker:139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :565
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504149
INFO:root:Worker: 565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531897
INFO:root:FL Epoch: 282 Norm Difference for worker 565 is 1.265686
INFO:root:FL Epoch: 282 Done on worker:565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :741
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 741 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802539
INFO:root:Worker: 741 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278275
INFO:root:FL Epoch: 282 Norm Difference for worker 741 is 1.308251
INFO:root:FL Epoch: 282 Done on worker:741
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :775
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471575
INFO:root:Worker: 775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422325
INFO:root:FL Epoch: 282 Norm Difference for worker 775 is 1.286382
INFO:root:FL Epoch: 282 Done on worker:775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1402
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1402 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518630
INFO:root:Worker: 1402 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487440
INFO:root:FL Epoch: 282 Norm Difference for worker 1402 is 1.334531
INFO:root:FL Epoch: 282 Done on worker:1402
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 282 Training on worker :1326
INFO:root:FL Epoch: 282 Using Learning rate : 0.028487353585941722 
INFO:root:FL Epoch: 282 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.826512
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654018
INFO:root:FL Epoch: 282 Norm Difference for worker 1326 is 1.399374
INFO:root:FL Epoch: 282 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1259
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 282 Ends   ===================
INFO:root:Epoch:282 Global Model Test Loss:0.4921283318715937 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:282 Global Model Backdoor Test Loss:0.23602362970511118                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 283 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 283 Workers Selected : [1792, 529, 394, 1564, 206, 472, 16, 309, 1415, 751]
INFO:root:FL Epoch: 283 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.10034948 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 283 Num points on workers: [200 200 200 200 201 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 283 Training on worker :1792
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.733351
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.659702
INFO:root:FL Epoch: 283 Norm Difference for worker 1792 is 0.956646
INFO:root:FL Epoch: 283 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :529
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680244
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463936
INFO:root:FL Epoch: 283 Norm Difference for worker 529 is 0.951012
INFO:root:FL Epoch: 283 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :394
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676435
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566043
INFO:root:FL Epoch: 283 Norm Difference for worker 394 is 1.002911
INFO:root:FL Epoch: 283 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1564
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1564 Train Epoch: 0 [0/200 (0%)]	Loss: 0.687869
INFO:root:Worker: 1564 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291629
INFO:root:FL Epoch: 283 Norm Difference for worker 1564 is 1.06283
INFO:root:FL Epoch: 283 Done on worker:1564
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :206
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.542750
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.578508
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 206 is 0.964497
INFO:root:FL Epoch: 283 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :472
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569516
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370960
INFO:root:FL Epoch: 283 Norm Difference for worker 472 is 1.04096
INFO:root:FL Epoch: 283 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :16
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 16 Train Epoch: 0 [0/201 (0%)]	Loss: 0.482896
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 16 Train Epoch: 1 [0/201 (0%)]	Loss: 0.334828
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 16 is 0.998309
INFO:root:FL Epoch: 283 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :309
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 309 Train Epoch: 0 [0/201 (0%)]	Loss: 0.533515
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 309 Train Epoch: 1 [0/201 (0%)]	Loss: 0.492723
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 283 Norm Difference for worker 309 is 1.059107
INFO:root:FL Epoch: 283 Done on worker:309
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :1415
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 1415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626131
INFO:root:Worker: 1415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469181
INFO:root:FL Epoch: 283 Norm Difference for worker 1415 is 1.034367
INFO:root:FL Epoch: 283 Done on worker:1415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 283 Training on worker :751
INFO:root:FL Epoch: 283 Using Learning rate : 0.02843037887876984 
INFO:root:FL Epoch: 283 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564834
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366135
INFO:root:FL Epoch: 283 Norm Difference for worker 751 is 0.986486
INFO:root:FL Epoch: 283 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 529
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 283 Ends   ===================
INFO:root:Epoch:283 Global Model Test Loss:0.4885542340138379 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:283 Global Model Backdoor Test Loss:0.1912893826762835                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 284 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 284 Workers Selected : [154, 357, 1624, 1590, 1428, 1904, 1235, 1178, 928, 1263]
INFO:root:FL Epoch: 284 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 284 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 284 Training on worker :154
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 154 Train Epoch: 0 [0/201 (0%)]	Loss: 0.711813
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 154 Train Epoch: 1 [0/201 (0%)]	Loss: 0.543028
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 284 Norm Difference for worker 154 is 1.018082
INFO:root:FL Epoch: 284 Done on worker:154
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :357
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653259
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368215
INFO:root:FL Epoch: 284 Norm Difference for worker 357 is 0.999817
INFO:root:FL Epoch: 284 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1624
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1624 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408372
INFO:root:Worker: 1624 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448371
INFO:root:FL Epoch: 284 Norm Difference for worker 1624 is 1.056456
INFO:root:FL Epoch: 284 Done on worker:1624
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1590
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606219
INFO:root:Worker: 1590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543948
INFO:root:FL Epoch: 284 Norm Difference for worker 1590 is 1.046275
INFO:root:FL Epoch: 284 Done on worker:1590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1428
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508565
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375118
INFO:root:FL Epoch: 284 Norm Difference for worker 1428 is 1.0638
INFO:root:FL Epoch: 284 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1904
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543426
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331695
INFO:root:FL Epoch: 284 Norm Difference for worker 1904 is 1.04052
INFO:root:FL Epoch: 284 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1235
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1235 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445207
INFO:root:Worker: 1235 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517967
INFO:root:FL Epoch: 284 Norm Difference for worker 1235 is 0.989793
INFO:root:FL Epoch: 284 Done on worker:1235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1178
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342049
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550785
INFO:root:FL Epoch: 284 Norm Difference for worker 1178 is 1.048503
INFO:root:FL Epoch: 284 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :928
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380889
INFO:root:Worker: 928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258094
INFO:root:FL Epoch: 284 Norm Difference for worker 928 is 1.007882
INFO:root:FL Epoch: 284 Done on worker:928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 284 Training on worker :1263
INFO:root:FL Epoch: 284 Using Learning rate : 0.028373518121012298 
INFO:root:FL Epoch: 284 Normal Training
INFO:root:Worker: 1263 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484036
INFO:root:Worker: 1263 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571976
INFO:root:FL Epoch: 284 Norm Difference for worker 1263 is 1.047005
INFO:root:FL Epoch: 284 Done on worker:1263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 928
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 284 Ends   ===================
INFO:root:Epoch:284 Global Model Test Loss:0.48341861367225647 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:284 Global Model Backdoor Test Loss:0.1857619434595108                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 285 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 285 Workers Selected : [324, 952, 1539, 1337, 416, 417, 1243, 1908, 1210, 1864]
INFO:root:FL Epoch: 285 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 285 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 285 Training on worker :324
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 324 Train Epoch: 0 [0/201 (0%)]	Loss: 0.588029
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 324 Train Epoch: 1 [0/201 (0%)]	Loss: 0.323897
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 285 Norm Difference for worker 324 is 0.865089
INFO:root:FL Epoch: 285 Done on worker:324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :952
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576464
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414559
INFO:root:FL Epoch: 285 Norm Difference for worker 952 is 1.024776
INFO:root:FL Epoch: 285 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1539
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1539 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393524
INFO:root:Worker: 1539 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485512
INFO:root:FL Epoch: 285 Norm Difference for worker 1539 is 0.953568
INFO:root:FL Epoch: 285 Done on worker:1539
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1337
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1337 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475702
INFO:root:Worker: 1337 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528028
INFO:root:FL Epoch: 285 Norm Difference for worker 1337 is 0.887291
INFO:root:FL Epoch: 285 Done on worker:1337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :416
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721989
INFO:root:Worker: 416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683524
INFO:root:FL Epoch: 285 Norm Difference for worker 416 is 0.9936
INFO:root:FL Epoch: 285 Done on worker:416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :417
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374248
INFO:root:Worker: 417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466367
INFO:root:FL Epoch: 285 Norm Difference for worker 417 is 0.976874
INFO:root:FL Epoch: 285 Done on worker:417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1243
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518000
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457548
INFO:root:FL Epoch: 285 Norm Difference for worker 1243 is 1.045948
INFO:root:FL Epoch: 285 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1908
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384233
INFO:root:Worker: 1908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395084
INFO:root:FL Epoch: 285 Norm Difference for worker 1908 is 1.009942
INFO:root:FL Epoch: 285 Done on worker:1908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1210
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1210 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513940
INFO:root:Worker: 1210 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557924
INFO:root:FL Epoch: 285 Norm Difference for worker 1210 is 0.999505
INFO:root:FL Epoch: 285 Done on worker:1210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 285 Training on worker :1864
INFO:root:FL Epoch: 285 Using Learning rate : 0.02831677108477028 
INFO:root:FL Epoch: 285 Normal Training
INFO:root:Worker: 1864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.631503
INFO:root:Worker: 1864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447230
INFO:root:FL Epoch: 285 Norm Difference for worker 1864 is 1.029134
INFO:root:FL Epoch: 285 Done on worker:1864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1337
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 285 Ends   ===================
INFO:root:Epoch:285 Global Model Test Loss:0.4886935887967839 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:285 Global Model Backdoor Test Loss:0.15937258178989092                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 286 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 286 Workers Selected : [1925, 383, 1915, 1745, 1387, 1705, 1843, 81, 1576, 1087]
INFO:root:FL Epoch: 286 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 286 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 286 Training on worker :1925
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567147
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562050
INFO:root:FL Epoch: 286 Norm Difference for worker 1925 is 1.018299
INFO:root:FL Epoch: 286 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :383
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 383 Train Epoch: 0 [0/200 (0%)]	Loss: 0.820625
INFO:root:Worker: 383 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482270
INFO:root:FL Epoch: 286 Norm Difference for worker 383 is 0.99904
INFO:root:FL Epoch: 286 Done on worker:383
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1915
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794614
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421728
INFO:root:FL Epoch: 286 Norm Difference for worker 1915 is 0.94671
INFO:root:FL Epoch: 286 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1745
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492160
INFO:root:Worker: 1745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465267
INFO:root:FL Epoch: 286 Norm Difference for worker 1745 is 0.92596
INFO:root:FL Epoch: 286 Done on worker:1745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1387
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1387 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582003
INFO:root:Worker: 1387 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312662
INFO:root:FL Epoch: 286 Norm Difference for worker 1387 is 0.978806
INFO:root:FL Epoch: 286 Done on worker:1387
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1705
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1705 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625697
INFO:root:Worker: 1705 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500557
INFO:root:FL Epoch: 286 Norm Difference for worker 1705 is 1.010639
INFO:root:FL Epoch: 286 Done on worker:1705
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1843
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.777770
INFO:root:Worker: 1843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381015
INFO:root:FL Epoch: 286 Norm Difference for worker 1843 is 0.917233
INFO:root:FL Epoch: 286 Done on worker:1843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :81
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 81 Train Epoch: 0 [0/201 (0%)]	Loss: 0.502013
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 81 Train Epoch: 1 [0/201 (0%)]	Loss: 0.480107
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 286 Norm Difference for worker 81 is 1.069034
INFO:root:FL Epoch: 286 Done on worker:81
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1576
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417730
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511568
INFO:root:FL Epoch: 286 Norm Difference for worker 1576 is 1.002966
INFO:root:FL Epoch: 286 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 286 Training on worker :1087
INFO:root:FL Epoch: 286 Using Learning rate : 0.028260137542600733 
INFO:root:FL Epoch: 286 Normal Training
INFO:root:Worker: 1087 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543258
INFO:root:Worker: 1087 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577765
INFO:root:FL Epoch: 286 Norm Difference for worker 1087 is 0.966203
INFO:root:FL Epoch: 286 Done on worker:1087
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1843
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 286 Ends   ===================
INFO:root:Epoch:286 Global Model Test Loss:0.48821810063193827 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:286 Global Model Backdoor Test Loss:0.22881351659695306                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 287 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 287 Workers Selected : [959, 776, 1302, 45, 1598, 659, 1114, 97, 249, 496]
INFO:root:FL Epoch: 287 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 287 Num points on workers: [200 200 200 201 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 287 Training on worker :959
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 959 Train Epoch: 0 [0/200 (0%)]	Loss: 0.811927
INFO:root:Worker: 959 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427913
INFO:root:FL Epoch: 287 Norm Difference for worker 959 is 0.972224
INFO:root:FL Epoch: 287 Done on worker:959
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :776
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511626
INFO:root:Worker: 776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432761
INFO:root:FL Epoch: 287 Norm Difference for worker 776 is 0.927869
INFO:root:FL Epoch: 287 Done on worker:776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :1302
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1302 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648197
INFO:root:Worker: 1302 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471999
INFO:root:FL Epoch: 287 Norm Difference for worker 1302 is 0.922359
INFO:root:FL Epoch: 287 Done on worker:1302
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :45
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 45 Train Epoch: 0 [0/201 (0%)]	Loss: 0.552170
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 45 Train Epoch: 1 [0/201 (0%)]	Loss: 0.534303
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 45 is 0.97606
INFO:root:FL Epoch: 287 Done on worker:45
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :1598
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475710
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534875
INFO:root:FL Epoch: 287 Norm Difference for worker 1598 is 0.889342
INFO:root:FL Epoch: 287 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :659
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576496
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.577644
INFO:root:FL Epoch: 287 Norm Difference for worker 659 is 0.944089
INFO:root:FL Epoch: 287 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :1114
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307888
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648684
INFO:root:FL Epoch: 287 Norm Difference for worker 1114 is 0.995056
INFO:root:FL Epoch: 287 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :97
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 97 Train Epoch: 0 [0/201 (0%)]	Loss: 0.436150
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 97 Train Epoch: 1 [0/201 (0%)]	Loss: 0.515292
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 97 is 1.008487
INFO:root:FL Epoch: 287 Done on worker:97
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :249
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 249 Train Epoch: 0 [0/201 (0%)]	Loss: 0.474166
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 249 Train Epoch: 1 [0/201 (0%)]	Loss: 0.326954
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 287 Norm Difference for worker 249 is 0.779972
INFO:root:FL Epoch: 287 Done on worker:249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 287 Training on worker :496
INFO:root:FL Epoch: 287 Using Learning rate : 0.028203617267515538 
INFO:root:FL Epoch: 287 Normal Training
INFO:root:Worker: 496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573077
INFO:root:Worker: 496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238725
INFO:root:FL Epoch: 287 Norm Difference for worker 496 is 0.831449
INFO:root:FL Epoch: 287 Done on worker:496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 249
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 287 Ends   ===================
INFO:root:Epoch:287 Global Model Test Loss:0.4988974718486561 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:287 Global Model Backdoor Test Loss:0.16972328598300615                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 288 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 288 Workers Selected : [379, 1801, 1144, 953, 744, 288, 1842, 1881, 1818, 859]
INFO:root:FL Epoch: 288 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 288 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 288 Training on worker :379
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456855
INFO:root:Worker: 379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625681
INFO:root:FL Epoch: 288 Norm Difference for worker 379 is 1.011814
INFO:root:FL Epoch: 288 Done on worker:379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1801
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460719
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567078
INFO:root:FL Epoch: 288 Norm Difference for worker 1801 is 1.008708
INFO:root:FL Epoch: 288 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1144
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1144 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449057
INFO:root:Worker: 1144 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470488
INFO:root:FL Epoch: 288 Norm Difference for worker 1144 is 1.045367
INFO:root:FL Epoch: 288 Done on worker:1144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :953
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 953 Train Epoch: 0 [0/200 (0%)]	Loss: 0.201850
INFO:root:Worker: 953 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371253
INFO:root:FL Epoch: 288 Norm Difference for worker 953 is 1.158708
INFO:root:FL Epoch: 288 Done on worker:953
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :744
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497072
INFO:root:Worker: 744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497514
INFO:root:FL Epoch: 288 Norm Difference for worker 744 is 1.097589
INFO:root:FL Epoch: 288 Done on worker:744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :288
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 288 Train Epoch: 0 [0/201 (0%)]	Loss: 0.407482
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 288 Train Epoch: 1 [0/201 (0%)]	Loss: 0.407866
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 288 Norm Difference for worker 288 is 1.067704
INFO:root:FL Epoch: 288 Done on worker:288
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1842
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1842 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564461
INFO:root:Worker: 1842 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429029
INFO:root:FL Epoch: 288 Norm Difference for worker 1842 is 1.019592
INFO:root:FL Epoch: 288 Done on worker:1842
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1881
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560945
INFO:root:Worker: 1881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588600
INFO:root:FL Epoch: 288 Norm Difference for worker 1881 is 1.024582
INFO:root:FL Epoch: 288 Done on worker:1881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :1818
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 1818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466864
INFO:root:Worker: 1818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282160
INFO:root:FL Epoch: 288 Norm Difference for worker 1818 is 1.086414
INFO:root:FL Epoch: 288 Done on worker:1818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 288 Training on worker :859
INFO:root:FL Epoch: 288 Using Learning rate : 0.028147210032980503 
INFO:root:FL Epoch: 288 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544151
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.588384
INFO:root:FL Epoch: 288 Norm Difference for worker 859 is 1.13539
INFO:root:FL Epoch: 288 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1842
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 288 Ends   ===================
INFO:root:Epoch:288 Global Model Test Loss:0.5047452993252698 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:288 Global Model Backdoor Test Loss:0.25747069468100864                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 289 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 289 Workers Selected : [800, 1234, 774, 874, 1885, 250, 829, 793, 877, 542]
INFO:root:FL Epoch: 289 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 289 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 289 Training on worker :800
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483366
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616583
INFO:root:FL Epoch: 289 Norm Difference for worker 800 is 0.895711
INFO:root:FL Epoch: 289 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1234
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705217
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356666
INFO:root:FL Epoch: 289 Norm Difference for worker 1234 is 0.91605
INFO:root:FL Epoch: 289 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :774
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 774 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607397
INFO:root:Worker: 774 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532834
INFO:root:FL Epoch: 289 Norm Difference for worker 774 is 0.873388
INFO:root:FL Epoch: 289 Done on worker:774
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :874
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377165
INFO:root:Worker: 874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682696
INFO:root:FL Epoch: 289 Norm Difference for worker 874 is 0.948328
INFO:root:FL Epoch: 289 Done on worker:874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :1885
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 1885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456454
INFO:root:Worker: 1885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614570
INFO:root:FL Epoch: 289 Norm Difference for worker 1885 is 0.901396
INFO:root:FL Epoch: 289 Done on worker:1885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :250
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.797272
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.433297
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 289 Norm Difference for worker 250 is 0.882781
INFO:root:FL Epoch: 289 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :829
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358005
INFO:root:Worker: 829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550915
INFO:root:FL Epoch: 289 Norm Difference for worker 829 is 0.917948
INFO:root:FL Epoch: 289 Done on worker:829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :793
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439098
INFO:root:Worker: 793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369127
INFO:root:FL Epoch: 289 Norm Difference for worker 793 is 0.876566
INFO:root:FL Epoch: 289 Done on worker:793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :877
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643277
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451158
INFO:root:FL Epoch: 289 Norm Difference for worker 877 is 0.892016
INFO:root:FL Epoch: 289 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 289 Training on worker :542
INFO:root:FL Epoch: 289 Using Learning rate : 0.028090915612914543 
INFO:root:FL Epoch: 289 Normal Training
INFO:root:Worker: 542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370801
INFO:root:Worker: 542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440512
INFO:root:FL Epoch: 289 Norm Difference for worker 542 is 0.843257
INFO:root:FL Epoch: 289 Done on worker:542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 542
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 289 Ends   ===================
INFO:root:Epoch:289 Global Model Test Loss:0.5066934999297646 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:289 Global Model Backdoor Test Loss:0.21868356813987097                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 290 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 290 Workers Selected : [1742, 592, 406, 145, 1148, 1176, 1558, 571, 1312, 1246]
INFO:root:FL Epoch: 290 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 290 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 290 Training on worker :1742
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.779211
INFO:root:Worker: 1742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537623
INFO:root:FL Epoch: 290 Norm Difference for worker 1742 is 1.002604
INFO:root:FL Epoch: 290 Done on worker:1742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :592
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544792
INFO:root:Worker: 592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470510
INFO:root:FL Epoch: 290 Norm Difference for worker 592 is 0.989824
INFO:root:FL Epoch: 290 Done on worker:592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :406
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.844256
INFO:root:Worker: 406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628790
INFO:root:FL Epoch: 290 Norm Difference for worker 406 is 0.987867
INFO:root:FL Epoch: 290 Done on worker:406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :145
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 145 Train Epoch: 0 [0/201 (0%)]	Loss: 0.841528
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 145 Train Epoch: 1 [0/201 (0%)]	Loss: 0.485730
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 290 Norm Difference for worker 145 is 0.891914
INFO:root:FL Epoch: 290 Done on worker:145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1148
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726443
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573883
INFO:root:FL Epoch: 290 Norm Difference for worker 1148 is 1.01133
INFO:root:FL Epoch: 290 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1176
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1176 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598827
INFO:root:Worker: 1176 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662643
INFO:root:FL Epoch: 290 Norm Difference for worker 1176 is 0.971969
INFO:root:FL Epoch: 290 Done on worker:1176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1558
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554956
INFO:root:Worker: 1558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643747
INFO:root:FL Epoch: 290 Norm Difference for worker 1558 is 0.951644
INFO:root:FL Epoch: 290 Done on worker:1558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :571
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720947
INFO:root:Worker: 571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348109
INFO:root:FL Epoch: 290 Norm Difference for worker 571 is 1.004174
INFO:root:FL Epoch: 290 Done on worker:571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1312
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415562
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532036
INFO:root:FL Epoch: 290 Norm Difference for worker 1312 is 0.972706
INFO:root:FL Epoch: 290 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 290 Training on worker :1246
INFO:root:FL Epoch: 290 Using Learning rate : 0.028034733781688716 
INFO:root:FL Epoch: 290 Normal Training
INFO:root:Worker: 1246 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796535
INFO:root:Worker: 1246 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307241
INFO:root:FL Epoch: 290 Norm Difference for worker 1246 is 0.956315
INFO:root:FL Epoch: 290 Done on worker:1246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 145
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 290 Ends   ===================
INFO:root:Epoch:290 Global Model Test Loss:0.4994121334132026 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:290 Global Model Backdoor Test Loss:0.21356398115555444                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 291 Begins ===================
INFO:root:FL Epoch: 291 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 291 Workers Selected : [0, 1344, 769, 284, 682, 98, 472, 1490, 650, 923]
INFO:root:FL Epoch: 291 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 291 Num points on workers: [200 200 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 291 Training on worker :0
INFO:root:FL Epoch: 291 Using Learning rate : 0.0055957328628250666 
INFO:root:FL Epoch: 291 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.167649
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199898
INFO:root:FL Epoch: 291 Worker: 0 Backdoor Test Loss: 0.2100654182334741 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 291 Worker: 0 Backdoor Train Loss: 0.23480346500873567 Backdoor Train Accuracy: 93.0
INFO:root:FL Epoch: 291 Norm Difference for worker 0 is 0.179768
INFO:root:FL Epoch: 291 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1344
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657960
INFO:root:Worker: 1344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529320
INFO:root:FL Epoch: 291 Norm Difference for worker 1344 is 0.953547
INFO:root:FL Epoch: 291 Done on worker:1344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :769
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.987823
INFO:root:Worker: 769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482440
INFO:root:FL Epoch: 291 Norm Difference for worker 769 is 1.002241
INFO:root:FL Epoch: 291 Done on worker:769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :284
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 284 Train Epoch: 0 [0/201 (0%)]	Loss: 0.868957
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 284 Train Epoch: 1 [0/201 (0%)]	Loss: 0.410052
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 291 Norm Difference for worker 284 is 1.014515
INFO:root:FL Epoch: 291 Done on worker:284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :682
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511982
INFO:root:Worker: 682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622263
INFO:root:FL Epoch: 291 Norm Difference for worker 682 is 1.047864
INFO:root:FL Epoch: 291 Done on worker:682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :98
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.705483
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.626653
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 291 Norm Difference for worker 98 is 1.014083
INFO:root:FL Epoch: 291 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :472
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448530
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458781
INFO:root:FL Epoch: 291 Norm Difference for worker 472 is 0.957341
INFO:root:FL Epoch: 291 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :1490
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 1490 Train Epoch: 0 [0/200 (0%)]	Loss: 0.957918
INFO:root:Worker: 1490 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641081
INFO:root:FL Epoch: 291 Norm Difference for worker 1490 is 0.913589
INFO:root:FL Epoch: 291 Done on worker:1490
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :650
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560259
INFO:root:Worker: 650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517485
INFO:root:FL Epoch: 291 Norm Difference for worker 650 is 0.999379
INFO:root:FL Epoch: 291 Done on worker:650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 291 Training on worker :923
INFO:root:FL Epoch: 291 Using Learning rate : 0.027978664314125337 
INFO:root:FL Epoch: 291 Normal Training
INFO:root:Worker: 923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494606
INFO:root:Worker: 923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570083
INFO:root:FL Epoch: 291 Norm Difference for worker 923 is 0.95055
INFO:root:FL Epoch: 291 Done on worker:923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 291 Ends   ===================
INFO:root:Epoch:291 Global Model Test Loss:0.5029621369698468 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:291 Global Model Backdoor Test Loss:0.2100654182334741                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 292 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 292 Workers Selected : [1279, 296, 1687, 1014, 591, 1609, 1825, 1680, 178, 1203]
INFO:root:FL Epoch: 292 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 292 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 292 Training on worker :1279
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1279 Train Epoch: 0 [0/200 (0%)]	Loss: 0.799340
INFO:root:Worker: 1279 Train Epoch: 1 [0/200 (0%)]	Loss: 0.757182
INFO:root:FL Epoch: 292 Norm Difference for worker 1279 is 0.935876
INFO:root:FL Epoch: 292 Done on worker:1279
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :296
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 296 Train Epoch: 0 [0/201 (0%)]	Loss: 0.342333
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 296 Train Epoch: 1 [0/201 (0%)]	Loss: 0.630976
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 292 Norm Difference for worker 296 is 1.031993
INFO:root:FL Epoch: 292 Done on worker:296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1687
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572083
INFO:root:Worker: 1687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546284
INFO:root:FL Epoch: 292 Norm Difference for worker 1687 is 1.138059
INFO:root:FL Epoch: 292 Done on worker:1687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1014
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675144
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599734
INFO:root:FL Epoch: 292 Norm Difference for worker 1014 is 1.047814
INFO:root:FL Epoch: 292 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :591
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775264
INFO:root:Worker: 591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561696
INFO:root:FL Epoch: 292 Norm Difference for worker 591 is 1.059489
INFO:root:FL Epoch: 292 Done on worker:591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1609
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522157
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441422
INFO:root:FL Epoch: 292 Norm Difference for worker 1609 is 1.017067
INFO:root:FL Epoch: 292 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1825
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556374
INFO:root:Worker: 1825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280262
INFO:root:FL Epoch: 292 Norm Difference for worker 1825 is 0.912659
INFO:root:FL Epoch: 292 Done on worker:1825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1680
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1680 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340740
INFO:root:Worker: 1680 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699502
INFO:root:FL Epoch: 292 Norm Difference for worker 1680 is 0.964634
INFO:root:FL Epoch: 292 Done on worker:1680
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :178
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 178 Train Epoch: 0 [0/201 (0%)]	Loss: 0.523878
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 178 Train Epoch: 1 [0/201 (0%)]	Loss: 0.455485
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 292 Norm Difference for worker 178 is 0.946775
INFO:root:FL Epoch: 292 Done on worker:178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 292 Training on worker :1203
INFO:root:FL Epoch: 292 Using Learning rate : 0.027922706985497082 
INFO:root:FL Epoch: 292 Normal Training
INFO:root:Worker: 1203 Train Epoch: 0 [0/200 (0%)]	Loss: 0.744575
INFO:root:Worker: 1203 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497108
INFO:root:FL Epoch: 292 Norm Difference for worker 1203 is 0.960634
INFO:root:FL Epoch: 292 Done on worker:1203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1279
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 292 Ends   ===================
INFO:root:Epoch:292 Global Model Test Loss:0.5067503802916583 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:292 Global Model Backdoor Test Loss:0.24277391781409582                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 293 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 293 Workers Selected : [1074, 695, 1683, 1234, 1128, 1570, 1012, 544, 1, 154]
INFO:root:FL Epoch: 293 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 293 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 293 Training on worker :1074
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1074 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599990
INFO:root:Worker: 1074 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492267
INFO:root:FL Epoch: 293 Norm Difference for worker 1074 is 0.884231
INFO:root:FL Epoch: 293 Done on worker:1074
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :695
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483891
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403404
INFO:root:FL Epoch: 293 Norm Difference for worker 695 is 0.903866
INFO:root:FL Epoch: 293 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1683
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1683 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605146
INFO:root:Worker: 1683 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611960
INFO:root:FL Epoch: 293 Norm Difference for worker 1683 is 0.882472
INFO:root:FL Epoch: 293 Done on worker:1683
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1234
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1234 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682335
INFO:root:Worker: 1234 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388205
INFO:root:FL Epoch: 293 Norm Difference for worker 1234 is 0.939498
INFO:root:FL Epoch: 293 Done on worker:1234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1128
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595935
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527953
INFO:root:FL Epoch: 293 Norm Difference for worker 1128 is 0.895645
INFO:root:FL Epoch: 293 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1570
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551937
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475551
INFO:root:FL Epoch: 293 Norm Difference for worker 1570 is 0.874654
INFO:root:FL Epoch: 293 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1012
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454075
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494619
INFO:root:FL Epoch: 293 Norm Difference for worker 1012 is 0.830512
INFO:root:FL Epoch: 293 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :544
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441966
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496518
INFO:root:FL Epoch: 293 Norm Difference for worker 544 is 0.919641
INFO:root:FL Epoch: 293 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :1
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 1 Train Epoch: 0 [0/201 (0%)]	Loss: 0.507106
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 1 Train Epoch: 1 [0/201 (0%)]	Loss: 0.359645
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 293 Norm Difference for worker 1 is 0.900169
INFO:root:FL Epoch: 293 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 293 Training on worker :154
INFO:root:FL Epoch: 293 Using Learning rate : 0.027866861571526094 
INFO:root:FL Epoch: 293 Normal Training
INFO:root:Worker: 154 Train Epoch: 0 [0/201 (0%)]	Loss: 0.373713
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 154 Train Epoch: 1 [0/201 (0%)]	Loss: 0.445160
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 293 Norm Difference for worker 154 is 0.888924
INFO:root:FL Epoch: 293 Done on worker:154
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1012
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 293 Ends   ===================
INFO:root:Epoch:293 Global Model Test Loss:0.5160741122329936 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:293 Global Model Backdoor Test Loss:0.1995074525475502                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 294 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 294 Workers Selected : [74, 1659, 512, 15, 469, 1732, 358, 1786, 1379, 727]
INFO:root:FL Epoch: 294 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 294 Num points on workers: [201 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 294 Training on worker :74
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.588618
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.331587
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 74 is 0.921252
INFO:root:FL Epoch: 294 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1659
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485028
INFO:root:Worker: 1659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519766
INFO:root:FL Epoch: 294 Norm Difference for worker 1659 is 0.981619
INFO:root:FL Epoch: 294 Done on worker:1659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :512
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584999
INFO:root:Worker: 512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498871
INFO:root:FL Epoch: 294 Norm Difference for worker 512 is 0.942446
INFO:root:FL Epoch: 294 Done on worker:512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :15
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.589393
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.345240
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 294 Norm Difference for worker 15 is 0.971458
INFO:root:FL Epoch: 294 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :469
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633175
INFO:root:Worker: 469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438418
INFO:root:FL Epoch: 294 Norm Difference for worker 469 is 0.922635
INFO:root:FL Epoch: 294 Done on worker:469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1732
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771329
INFO:root:Worker: 1732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355719
INFO:root:FL Epoch: 294 Norm Difference for worker 1732 is 0.888967
INFO:root:FL Epoch: 294 Done on worker:1732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :358
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621954
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417449
INFO:root:FL Epoch: 294 Norm Difference for worker 358 is 0.946428
INFO:root:FL Epoch: 294 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1786
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461082
INFO:root:Worker: 1786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513099
INFO:root:FL Epoch: 294 Norm Difference for worker 1786 is 0.963967
INFO:root:FL Epoch: 294 Done on worker:1786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :1379
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 1379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353237
INFO:root:Worker: 1379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571053
INFO:root:FL Epoch: 294 Norm Difference for worker 1379 is 0.958206
INFO:root:FL Epoch: 294 Done on worker:1379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 294 Training on worker :727
INFO:root:FL Epoch: 294 Using Learning rate : 0.02781112784838304 
INFO:root:FL Epoch: 294 Normal Training
INFO:root:Worker: 727 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588584
INFO:root:Worker: 727 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545846
INFO:root:FL Epoch: 294 Norm Difference for worker 727 is 0.9541
INFO:root:FL Epoch: 294 Done on worker:727
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1732
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 294 Ends   ===================
INFO:root:Epoch:294 Global Model Test Loss:0.5047775016111486 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:294 Global Model Backdoor Test Loss:0.25594598799943924                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 295 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 295 Workers Selected : [823, 1183, 877, 1508, 1112, 1340, 1040, 1818, 175, 1735]
INFO:root:FL Epoch: 295 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 295 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 295 Training on worker :823
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644523
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347315
INFO:root:FL Epoch: 295 Norm Difference for worker 823 is 0.861312
INFO:root:FL Epoch: 295 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1183
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1183 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528903
INFO:root:Worker: 1183 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497322
INFO:root:FL Epoch: 295 Norm Difference for worker 1183 is 0.836617
INFO:root:FL Epoch: 295 Done on worker:1183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :877
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677426
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378812
INFO:root:FL Epoch: 295 Norm Difference for worker 877 is 0.890649
INFO:root:FL Epoch: 295 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1508
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544877
INFO:root:Worker: 1508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283257
INFO:root:FL Epoch: 295 Norm Difference for worker 1508 is 0.893288
INFO:root:FL Epoch: 295 Done on worker:1508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1112
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1112 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447328
INFO:root:Worker: 1112 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438894
INFO:root:FL Epoch: 295 Norm Difference for worker 1112 is 0.857814
INFO:root:FL Epoch: 295 Done on worker:1112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1340
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600132
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656205
INFO:root:FL Epoch: 295 Norm Difference for worker 1340 is 0.909854
INFO:root:FL Epoch: 295 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1040
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695713
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538273
INFO:root:FL Epoch: 295 Norm Difference for worker 1040 is 0.9201
INFO:root:FL Epoch: 295 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1818
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624798
INFO:root:Worker: 1818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534711
INFO:root:FL Epoch: 295 Norm Difference for worker 1818 is 0.852196
INFO:root:FL Epoch: 295 Done on worker:1818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :175
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 175 Train Epoch: 0 [0/201 (0%)]	Loss: 0.682938
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 175 Train Epoch: 1 [0/201 (0%)]	Loss: 0.371186
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 295 Norm Difference for worker 175 is 0.856871
INFO:root:FL Epoch: 295 Done on worker:175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 295 Training on worker :1735
INFO:root:FL Epoch: 295 Using Learning rate : 0.02775550559268627 
INFO:root:FL Epoch: 295 Normal Training
INFO:root:Worker: 1735 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346399
INFO:root:Worker: 1735 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639882
INFO:root:FL Epoch: 295 Norm Difference for worker 1735 is 0.844858
INFO:root:FL Epoch: 295 Done on worker:1735
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1183
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 295 Ends   ===================
INFO:root:Epoch:295 Global Model Test Loss:0.49909399712786956 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:295 Global Model Backdoor Test Loss:0.19062475363413492                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 296 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 296 Workers Selected : [322, 1781, 504, 941, 1075, 1324, 1739, 635, 345, 1078]
INFO:root:FL Epoch: 296 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 296 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 296 Training on worker :322
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 322 Train Epoch: 0 [0/201 (0%)]	Loss: 0.298485
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 322 Train Epoch: 1 [0/201 (0%)]	Loss: 0.524357
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 296 Norm Difference for worker 322 is 1.002419
INFO:root:FL Epoch: 296 Done on worker:322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1781
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614245
INFO:root:Worker: 1781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601004
INFO:root:FL Epoch: 296 Norm Difference for worker 1781 is 1.043723
INFO:root:FL Epoch: 296 Done on worker:1781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :504
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662039
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600365
INFO:root:FL Epoch: 296 Norm Difference for worker 504 is 0.98629
INFO:root:FL Epoch: 296 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :941
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518404
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377517
INFO:root:FL Epoch: 296 Norm Difference for worker 941 is 0.92475
INFO:root:FL Epoch: 296 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1075
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488729
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501651
INFO:root:FL Epoch: 296 Norm Difference for worker 1075 is 0.991268
INFO:root:FL Epoch: 296 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1324
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1324 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452251
INFO:root:Worker: 1324 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579870
INFO:root:FL Epoch: 296 Norm Difference for worker 1324 is 0.976702
INFO:root:FL Epoch: 296 Done on worker:1324
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1739
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1739 Train Epoch: 0 [0/200 (0%)]	Loss: 0.848382
INFO:root:Worker: 1739 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389391
INFO:root:FL Epoch: 296 Norm Difference for worker 1739 is 0.908711
INFO:root:FL Epoch: 296 Done on worker:1739
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :635
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 635 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304402
INFO:root:Worker: 635 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229386
INFO:root:FL Epoch: 296 Norm Difference for worker 635 is 0.955873
INFO:root:FL Epoch: 296 Done on worker:635
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :345
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 345 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445151
INFO:root:Worker: 345 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396820
INFO:root:FL Epoch: 296 Norm Difference for worker 345 is 1.0074
INFO:root:FL Epoch: 296 Done on worker:345
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 296 Training on worker :1078
INFO:root:FL Epoch: 296 Using Learning rate : 0.027699994581500898 
INFO:root:FL Epoch: 296 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780948
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316275
INFO:root:FL Epoch: 296 Norm Difference for worker 1078 is 0.970013
INFO:root:FL Epoch: 296 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 941
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 296 Ends   ===================
INFO:root:Epoch:296 Global Model Test Loss:0.49036188686595245 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:296 Global Model Backdoor Test Loss:0.2650868718822797                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 297 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 297 Workers Selected : [205, 442, 1237, 1509, 1447, 597, 930, 353, 1481, 1860]
INFO:root:FL Epoch: 297 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 297 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 297 Training on worker :205
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.458680
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.752816
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 297 Norm Difference for worker 205 is 1.001894
INFO:root:FL Epoch: 297 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :442
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512979
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417014
INFO:root:FL Epoch: 297 Norm Difference for worker 442 is 0.996095
INFO:root:FL Epoch: 297 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1237
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1237 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551753
INFO:root:Worker: 1237 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534575
INFO:root:FL Epoch: 297 Norm Difference for worker 1237 is 1.052323
INFO:root:FL Epoch: 297 Done on worker:1237
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1509
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759662
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372332
INFO:root:FL Epoch: 297 Norm Difference for worker 1509 is 1.037476
INFO:root:FL Epoch: 297 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1447
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451888
INFO:root:Worker: 1447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494786
INFO:root:FL Epoch: 297 Norm Difference for worker 1447 is 0.922681
INFO:root:FL Epoch: 297 Done on worker:1447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :597
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 597 Train Epoch: 0 [0/200 (0%)]	Loss: 1.165663
INFO:root:Worker: 597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468605
INFO:root:FL Epoch: 297 Norm Difference for worker 597 is 0.978761
INFO:root:FL Epoch: 297 Done on worker:597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :930
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546395
INFO:root:Worker: 930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419435
INFO:root:FL Epoch: 297 Norm Difference for worker 930 is 0.941265
INFO:root:FL Epoch: 297 Done on worker:930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :353
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.927518
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395832
INFO:root:FL Epoch: 297 Norm Difference for worker 353 is 1.045199
INFO:root:FL Epoch: 297 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1481
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739008
INFO:root:Worker: 1481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352214
INFO:root:FL Epoch: 297 Norm Difference for worker 1481 is 1.140792
INFO:root:FL Epoch: 297 Done on worker:1481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 297 Training on worker :1860
INFO:root:FL Epoch: 297 Using Learning rate : 0.027644594592337896 
INFO:root:FL Epoch: 297 Normal Training
INFO:root:Worker: 1860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399347
INFO:root:Worker: 1860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339040
INFO:root:FL Epoch: 297 Norm Difference for worker 1860 is 0.994353
INFO:root:FL Epoch: 297 Done on worker:1860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1447
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 297 Ends   ===================
INFO:root:Epoch:297 Global Model Test Loss:0.4853283885647269 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:297 Global Model Backdoor Test Loss:0.2829989269375801                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 298 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 298 Workers Selected : [1712, 1764, 1271, 1654, 1377, 1790, 1843, 1512, 130, 1845]
INFO:root:FL Epoch: 298 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 298 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 298 Training on worker :1712
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459080
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586988
INFO:root:FL Epoch: 298 Norm Difference for worker 1712 is 0.890255
INFO:root:FL Epoch: 298 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1764
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515590
INFO:root:Worker: 1764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451697
INFO:root:FL Epoch: 298 Norm Difference for worker 1764 is 0.993849
INFO:root:FL Epoch: 298 Done on worker:1764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1271
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1271 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562262
INFO:root:Worker: 1271 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390430
INFO:root:FL Epoch: 298 Norm Difference for worker 1271 is 0.940961
INFO:root:FL Epoch: 298 Done on worker:1271
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1654
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441950
INFO:root:Worker: 1654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.723102
INFO:root:FL Epoch: 298 Norm Difference for worker 1654 is 0.914031
INFO:root:FL Epoch: 298 Done on worker:1654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1377
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487734
INFO:root:Worker: 1377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389016
INFO:root:FL Epoch: 298 Norm Difference for worker 1377 is 0.956935
INFO:root:FL Epoch: 298 Done on worker:1377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1790
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603955
INFO:root:Worker: 1790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546032
INFO:root:FL Epoch: 298 Norm Difference for worker 1790 is 0.844007
INFO:root:FL Epoch: 298 Done on worker:1790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1843
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.248228
INFO:root:Worker: 1843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380299
INFO:root:FL Epoch: 298 Norm Difference for worker 1843 is 0.782534
INFO:root:FL Epoch: 298 Done on worker:1843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1512
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484153
INFO:root:Worker: 1512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501789
INFO:root:FL Epoch: 298 Norm Difference for worker 1512 is 0.937476
INFO:root:FL Epoch: 298 Done on worker:1512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :130
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 130 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503337
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 130 Train Epoch: 1 [0/201 (0%)]	Loss: 0.480152
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 298 Norm Difference for worker 130 is 0.922615
INFO:root:FL Epoch: 298 Done on worker:130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 298 Training on worker :1845
INFO:root:FL Epoch: 298 Using Learning rate : 0.02758930540315322 
INFO:root:FL Epoch: 298 Normal Training
INFO:root:Worker: 1845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756610
INFO:root:Worker: 1845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.677724
INFO:root:FL Epoch: 298 Norm Difference for worker 1845 is 1.03156
INFO:root:FL Epoch: 298 Done on worker:1845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1843
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 298 Ends   ===================
INFO:root:Epoch:298 Global Model Test Loss:0.4856259928030126 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:298 Global Model Backdoor Test Loss:0.24377639591693878                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 299 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 299 Workers Selected : [1354, 1515, 1293, 1769, 1005, 1856, 1725, 1512, 1762, 1835]
INFO:root:FL Epoch: 299 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 299 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 299 Training on worker :1354
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568385
INFO:root:Worker: 1354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424527
INFO:root:FL Epoch: 299 Norm Difference for worker 1354 is 0.976994
INFO:root:FL Epoch: 299 Done on worker:1354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1515
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1515 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510975
INFO:root:Worker: 1515 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522542
INFO:root:FL Epoch: 299 Norm Difference for worker 1515 is 1.043443
INFO:root:FL Epoch: 299 Done on worker:1515
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1293
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1293 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559213
INFO:root:Worker: 1293 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494649
INFO:root:FL Epoch: 299 Norm Difference for worker 1293 is 0.964053
INFO:root:FL Epoch: 299 Done on worker:1293
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1769
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342830
INFO:root:Worker: 1769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650515
INFO:root:FL Epoch: 299 Norm Difference for worker 1769 is 0.995166
INFO:root:FL Epoch: 299 Done on worker:1769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1005
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1005 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503951
INFO:root:Worker: 1005 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457661
INFO:root:FL Epoch: 299 Norm Difference for worker 1005 is 1.055713
INFO:root:FL Epoch: 299 Done on worker:1005
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1856
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591355
INFO:root:Worker: 1856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495969
INFO:root:FL Epoch: 299 Norm Difference for worker 1856 is 1.008305
INFO:root:FL Epoch: 299 Done on worker:1856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1725
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559774
INFO:root:Worker: 1725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440930
INFO:root:FL Epoch: 299 Norm Difference for worker 1725 is 1.102847
INFO:root:FL Epoch: 299 Done on worker:1725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1512
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570793
INFO:root:Worker: 1512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345714
INFO:root:FL Epoch: 299 Norm Difference for worker 1512 is 1.004831
INFO:root:FL Epoch: 299 Done on worker:1512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1762
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1762 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499987
INFO:root:Worker: 1762 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515044
INFO:root:FL Epoch: 299 Norm Difference for worker 1762 is 0.907707
INFO:root:FL Epoch: 299 Done on worker:1762
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 299 Training on worker :1835
INFO:root:FL Epoch: 299 Using Learning rate : 0.027534126792346916 
INFO:root:FL Epoch: 299 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699207
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.654526
INFO:root:FL Epoch: 299 Norm Difference for worker 1835 is 1.104097
INFO:root:FL Epoch: 299 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1762
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 299 Ends   ===================
INFO:root:Epoch:299 Global Model Test Loss:0.4936130116967594 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:299 Global Model Backdoor Test Loss:0.23869217187166214                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 300 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 300 Workers Selected : [1702, 1886, 833, 865, 25, 1711, 558, 393, 1020, 893]
INFO:root:FL Epoch: 300 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 300 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 300 Training on worker :1702
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1702 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619725
INFO:root:Worker: 1702 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483882
INFO:root:FL Epoch: 300 Norm Difference for worker 1702 is 1.001166
INFO:root:FL Epoch: 300 Done on worker:1702
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1886
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559641
INFO:root:Worker: 1886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570284
INFO:root:FL Epoch: 300 Norm Difference for worker 1886 is 1.020938
INFO:root:FL Epoch: 300 Done on worker:1886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :833
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342414
INFO:root:Worker: 833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602262
INFO:root:FL Epoch: 300 Norm Difference for worker 833 is 0.949721
INFO:root:FL Epoch: 300 Done on worker:833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :865
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552954
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305624
INFO:root:FL Epoch: 300 Norm Difference for worker 865 is 0.954482
INFO:root:FL Epoch: 300 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :25
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.570374
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.362106
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 300 Norm Difference for worker 25 is 0.968184
INFO:root:FL Epoch: 300 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1711
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599042
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619951
INFO:root:FL Epoch: 300 Norm Difference for worker 1711 is 1.088861
INFO:root:FL Epoch: 300 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :558
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554457
INFO:root:Worker: 558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433976
INFO:root:FL Epoch: 300 Norm Difference for worker 558 is 1.022497
INFO:root:FL Epoch: 300 Done on worker:558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :393
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508226
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616489
INFO:root:FL Epoch: 300 Norm Difference for worker 393 is 1.029588
INFO:root:FL Epoch: 300 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :1020
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 1020 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389293
INFO:root:Worker: 1020 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413868
INFO:root:FL Epoch: 300 Norm Difference for worker 1020 is 0.965644
INFO:root:FL Epoch: 300 Done on worker:1020
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 300 Training on worker :893
INFO:root:FL Epoch: 300 Using Learning rate : 0.02747905853876222 
INFO:root:FL Epoch: 300 Normal Training
INFO:root:Worker: 893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414342
INFO:root:Worker: 893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546833
INFO:root:FL Epoch: 300 Norm Difference for worker 893 is 0.946902
INFO:root:FL Epoch: 300 Done on worker:893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 833
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 300 Ends   ===================
INFO:root:Epoch:300 Global Model Test Loss:0.5068793068913853 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:300 Global Model Backdoor Test Loss:0.2961474632223447                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 301 Begins ===================
INFO:root:FL Epoch: 301 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 301 Workers Selected : [0, 452, 323, 1197, 902, 1107, 244, 1947, 405, 1888]
INFO:root:FL Epoch: 301 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 301 Num points on workers: [200 200 201 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 301 Training on worker :0
INFO:root:FL Epoch: 301 Using Learning rate : 0.005484820084336939 
INFO:root:FL Epoch: 301 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337090
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.207322
INFO:root:FL Epoch: 301 Worker: 0 Backdoor Test Loss: 0.2321020613114039 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 301 Worker: 0 Backdoor Train Loss: 0.21826994121074678 Backdoor Train Accuracy: 94.0
INFO:root:FL Epoch: 301 Norm Difference for worker 0 is 0.192833
INFO:root:FL Epoch: 301 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :452
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518443
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434332
INFO:root:FL Epoch: 301 Norm Difference for worker 452 is 0.946333
INFO:root:FL Epoch: 301 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :323
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 323 Train Epoch: 0 [0/201 (0%)]	Loss: 0.477906
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 323 Train Epoch: 1 [0/201 (0%)]	Loss: 0.638824
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 301 Norm Difference for worker 323 is 1.069824
INFO:root:FL Epoch: 301 Done on worker:323
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1197
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1197 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599779
INFO:root:Worker: 1197 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541599
INFO:root:FL Epoch: 301 Norm Difference for worker 1197 is 1.115496
INFO:root:FL Epoch: 301 Done on worker:1197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :902
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.821133
INFO:root:Worker: 902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388583
INFO:root:FL Epoch: 301 Norm Difference for worker 902 is 1.027145
INFO:root:FL Epoch: 301 Done on worker:902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1107
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1107 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338219
INFO:root:Worker: 1107 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353170
INFO:root:FL Epoch: 301 Norm Difference for worker 1107 is 0.956313
INFO:root:FL Epoch: 301 Done on worker:1107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :244
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 244 Train Epoch: 0 [0/201 (0%)]	Loss: 0.600910
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 244 Train Epoch: 1 [0/201 (0%)]	Loss: 0.350646
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 301 Norm Difference for worker 244 is 0.935519
INFO:root:FL Epoch: 301 Done on worker:244
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1947
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1947 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628751
INFO:root:Worker: 1947 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451657
INFO:root:FL Epoch: 301 Norm Difference for worker 1947 is 0.993567
INFO:root:FL Epoch: 301 Done on worker:1947
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :405
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425303
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300019
INFO:root:FL Epoch: 301 Norm Difference for worker 405 is 1.022087
INFO:root:FL Epoch: 301 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 301 Training on worker :1888
INFO:root:FL Epoch: 301 Using Learning rate : 0.027424100421684694 
INFO:root:FL Epoch: 301 Normal Training
INFO:root:Worker: 1888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.938297
INFO:root:Worker: 1888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326581
INFO:root:FL Epoch: 301 Norm Difference for worker 1888 is 1.026342
INFO:root:FL Epoch: 301 Done on worker:1888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 301 Ends   ===================
INFO:root:Epoch:301 Global Model Test Loss:0.5099859588286456 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:301 Global Model Backdoor Test Loss:0.2321020613114039                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 302 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 302 Workers Selected : [494, 112, 1846, 296, 599, 622, 1555, 567, 1760, 122]
INFO:root:FL Epoch: 302 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 302 Num points on workers: [200 201 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 302 Training on worker :494
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386998
INFO:root:Worker: 494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336745
INFO:root:FL Epoch: 302 Norm Difference for worker 494 is 1.036835
INFO:root:FL Epoch: 302 Done on worker:494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :112
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 112 Train Epoch: 0 [0/201 (0%)]	Loss: 0.767649
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 112 Train Epoch: 1 [0/201 (0%)]	Loss: 0.341173
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 302 Norm Difference for worker 112 is 1.01087
INFO:root:FL Epoch: 302 Done on worker:112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1846
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437642
INFO:root:Worker: 1846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386080
INFO:root:FL Epoch: 302 Norm Difference for worker 1846 is 1.021166
INFO:root:FL Epoch: 302 Done on worker:1846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :296
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 296 Train Epoch: 0 [0/201 (0%)]	Loss: 0.463058
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 296 Train Epoch: 1 [0/201 (0%)]	Loss: 0.307396
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 302 Norm Difference for worker 296 is 1.075801
INFO:root:FL Epoch: 302 Done on worker:296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :599
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.604720
INFO:root:Worker: 599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565058
INFO:root:FL Epoch: 302 Norm Difference for worker 599 is 1.145983
INFO:root:FL Epoch: 302 Done on worker:599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :622
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677817
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592857
INFO:root:FL Epoch: 302 Norm Difference for worker 622 is 1.041954
INFO:root:FL Epoch: 302 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1555
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337576
INFO:root:Worker: 1555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546135
INFO:root:FL Epoch: 302 Norm Difference for worker 1555 is 1.042311
INFO:root:FL Epoch: 302 Done on worker:1555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :567
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549464
INFO:root:Worker: 567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481393
INFO:root:FL Epoch: 302 Norm Difference for worker 567 is 1.007239
INFO:root:FL Epoch: 302 Done on worker:567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :1760
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737816
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475890
INFO:root:FL Epoch: 302 Norm Difference for worker 1760 is 1.206576
INFO:root:FL Epoch: 302 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 302 Training on worker :122
INFO:root:FL Epoch: 302 Using Learning rate : 0.027369252220841328 
INFO:root:FL Epoch: 302 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.585693
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.285332
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 302 Norm Difference for worker 122 is 1.1287
INFO:root:FL Epoch: 302 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 112
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 302 Ends   ===================
INFO:root:Epoch:302 Global Model Test Loss:0.4892225055133595 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:302 Global Model Backdoor Test Loss:0.2994798794388771                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 303 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 303 Workers Selected : [369, 1361, 1486, 452, 1340, 1588, 1576, 949, 1333, 584]
INFO:root:FL Epoch: 303 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 303 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 303 Training on worker :369
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591797
INFO:root:Worker: 369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476941
INFO:root:FL Epoch: 303 Norm Difference for worker 369 is 0.973054
INFO:root:FL Epoch: 303 Done on worker:369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1361
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681683
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573858
INFO:root:FL Epoch: 303 Norm Difference for worker 1361 is 0.958075
INFO:root:FL Epoch: 303 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1486
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662719
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.569954
INFO:root:FL Epoch: 303 Norm Difference for worker 1486 is 0.926502
INFO:root:FL Epoch: 303 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :452
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488916
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405906
INFO:root:FL Epoch: 303 Norm Difference for worker 452 is 0.855098
INFO:root:FL Epoch: 303 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1340
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636227
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490626
INFO:root:FL Epoch: 303 Norm Difference for worker 1340 is 0.952939
INFO:root:FL Epoch: 303 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1588
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.448923
INFO:root:Worker: 1588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421782
INFO:root:FL Epoch: 303 Norm Difference for worker 1588 is 0.874072
INFO:root:FL Epoch: 303 Done on worker:1588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1576
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603203
INFO:root:Worker: 1576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478548
INFO:root:FL Epoch: 303 Norm Difference for worker 1576 is 0.931717
INFO:root:FL Epoch: 303 Done on worker:1576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :949
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.780315
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405506
INFO:root:FL Epoch: 303 Norm Difference for worker 949 is 0.893002
INFO:root:FL Epoch: 303 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :1333
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 1333 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678666
INFO:root:Worker: 1333 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570165
INFO:root:FL Epoch: 303 Norm Difference for worker 1333 is 0.906174
INFO:root:FL Epoch: 303 Done on worker:1333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 303 Training on worker :584
INFO:root:FL Epoch: 303 Using Learning rate : 0.027314513716399647 
INFO:root:FL Epoch: 303 Normal Training
INFO:root:Worker: 584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588208
INFO:root:Worker: 584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.777644
INFO:root:FL Epoch: 303 Norm Difference for worker 584 is 0.930169
INFO:root:FL Epoch: 303 Done on worker:584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1588
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 303 Ends   ===================
INFO:root:Epoch:303 Global Model Test Loss:0.5146579900208641 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:303 Global Model Backdoor Test Loss:0.3245114783445994                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 304 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 304 Workers Selected : [1500, 1588, 1036, 52, 873, 842, 19, 1375, 1256, 473]
INFO:root:FL Epoch: 304 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 304 Num points on workers: [200 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 304 Training on worker :1500
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626499
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.669641
INFO:root:FL Epoch: 304 Norm Difference for worker 1500 is 0.929236
INFO:root:FL Epoch: 304 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1588
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1588 Train Epoch: 0 [0/200 (0%)]	Loss: 0.439976
INFO:root:Worker: 1588 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320803
INFO:root:FL Epoch: 304 Norm Difference for worker 1588 is 0.743201
INFO:root:FL Epoch: 304 Done on worker:1588
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1036
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576324
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643362
INFO:root:FL Epoch: 304 Norm Difference for worker 1036 is 0.930157
INFO:root:FL Epoch: 304 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :52
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 52 Train Epoch: 0 [0/201 (0%)]	Loss: 0.608163
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 52 Train Epoch: 1 [0/201 (0%)]	Loss: 0.371014
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 304 Norm Difference for worker 52 is 0.916843
INFO:root:FL Epoch: 304 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :873
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594618
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415933
INFO:root:FL Epoch: 304 Norm Difference for worker 873 is 0.933298
INFO:root:FL Epoch: 304 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :842
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 842 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500981
INFO:root:Worker: 842 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533753
INFO:root:FL Epoch: 304 Norm Difference for worker 842 is 0.919155
INFO:root:FL Epoch: 304 Done on worker:842
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :19
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.440374
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.496785
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 304 Norm Difference for worker 19 is 0.964092
INFO:root:FL Epoch: 304 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1375
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663549
INFO:root:Worker: 1375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488571
INFO:root:FL Epoch: 304 Norm Difference for worker 1375 is 0.920933
INFO:root:FL Epoch: 304 Done on worker:1375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :1256
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 1256 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546760
INFO:root:Worker: 1256 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530979
INFO:root:FL Epoch: 304 Norm Difference for worker 1256 is 0.921347
INFO:root:FL Epoch: 304 Done on worker:1256
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 304 Training on worker :473
INFO:root:FL Epoch: 304 Using Learning rate : 0.027259884688966847 
INFO:root:FL Epoch: 304 Normal Training
INFO:root:Worker: 473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561589
INFO:root:Worker: 473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496788
INFO:root:FL Epoch: 304 Norm Difference for worker 473 is 0.948834
INFO:root:FL Epoch: 304 Done on worker:473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1588
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 304 Ends   ===================
INFO:root:Epoch:304 Global Model Test Loss:0.5516845636508044 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:304 Global Model Backdoor Test Loss:0.27243489151199657                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 305 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 305 Workers Selected : [182, 98, 196, 1528, 318, 1075, 206, 193, 1494, 982]
INFO:root:FL Epoch: 305 Fraction of points on each worker in this round: [0.1001994 0.1001994 0.1001994 0.0997009 0.1001994 0.0997009 0.1001994
 0.1001994 0.0997009 0.0997009]
INFO:root:FL Epoch: 305 Num points on workers: [201 201 201 200 201 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 305 Training on worker :182
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 182 Train Epoch: 0 [0/201 (0%)]	Loss: 0.753020
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 182 Train Epoch: 1 [0/201 (0%)]	Loss: 0.236614
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 305 Norm Difference for worker 182 is 1.165736
INFO:root:FL Epoch: 305 Done on worker:182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :98
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.669132
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.499458
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 305 Norm Difference for worker 98 is 1.146395
INFO:root:FL Epoch: 305 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :196
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.759539
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.573886
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 305 Norm Difference for worker 196 is 1.167293
INFO:root:FL Epoch: 305 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1528
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491307
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585668
INFO:root:FL Epoch: 305 Norm Difference for worker 1528 is 1.137209
INFO:root:FL Epoch: 305 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :318
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.714850
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.679477
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 305 Norm Difference for worker 318 is 1.065403
INFO:root:FL Epoch: 305 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1075
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.816666
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442694
INFO:root:FL Epoch: 305 Norm Difference for worker 1075 is 1.169572
INFO:root:FL Epoch: 305 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :206
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.458840
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.468060
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 305 Norm Difference for worker 206 is 1.118181
INFO:root:FL Epoch: 305 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :193
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 193 Train Epoch: 0 [0/201 (0%)]	Loss: 0.864632
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 193 Train Epoch: 1 [0/201 (0%)]	Loss: 0.671865
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 305 Norm Difference for worker 193 is 1.208955
INFO:root:FL Epoch: 305 Done on worker:193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :1494
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 1494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.256213
INFO:root:Worker: 1494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426237
INFO:root:FL Epoch: 305 Norm Difference for worker 1494 is 1.063063
INFO:root:FL Epoch: 305 Done on worker:1494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 305 Training on worker :982
INFO:root:FL Epoch: 305 Using Learning rate : 0.02720536491958891 
INFO:root:FL Epoch: 305 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.691931
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377253
INFO:root:FL Epoch: 305 Norm Difference for worker 982 is 1.165374
INFO:root:FL Epoch: 305 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1494
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 305 Ends   ===================
INFO:root:Epoch:305 Global Model Test Loss:0.5264867176027859 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:305 Global Model Backdoor Test Loss:0.2568646694223086                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 306 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 306 Workers Selected : [349, 1406, 534, 60, 1229, 892, 921, 836, 1428, 810]
INFO:root:FL Epoch: 306 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 306 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 306 Training on worker :349
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435122
INFO:root:Worker: 349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531618
INFO:root:FL Epoch: 306 Norm Difference for worker 349 is 1.026095
INFO:root:FL Epoch: 306 Done on worker:349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1406
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494736
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635516
INFO:root:FL Epoch: 306 Norm Difference for worker 1406 is 1.095821
INFO:root:FL Epoch: 306 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :534
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393168
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640906
INFO:root:FL Epoch: 306 Norm Difference for worker 534 is 1.124934
INFO:root:FL Epoch: 306 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :60
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 60 Train Epoch: 0 [0/201 (0%)]	Loss: 0.472220
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 60 Train Epoch: 1 [0/201 (0%)]	Loss: 0.438729
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 306 Norm Difference for worker 60 is 1.023143
INFO:root:FL Epoch: 306 Done on worker:60
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1229
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1229 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552755
INFO:root:Worker: 1229 Train Epoch: 1 [0/200 (0%)]	Loss: 0.785541
INFO:root:FL Epoch: 306 Norm Difference for worker 1229 is 1.116698
INFO:root:FL Epoch: 306 Done on worker:1229
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :892
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644217
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269322
INFO:root:FL Epoch: 306 Norm Difference for worker 892 is 0.952286
INFO:root:FL Epoch: 306 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :921
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516061
INFO:root:Worker: 921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425469
INFO:root:FL Epoch: 306 Norm Difference for worker 921 is 1.114445
INFO:root:FL Epoch: 306 Done on worker:921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :836
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458993
INFO:root:Worker: 836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309648
INFO:root:FL Epoch: 306 Norm Difference for worker 836 is 1.024118
INFO:root:FL Epoch: 306 Done on worker:836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :1428
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527222
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457409
INFO:root:FL Epoch: 306 Norm Difference for worker 1428 is 1.190779
INFO:root:FL Epoch: 306 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 306 Training on worker :810
INFO:root:FL Epoch: 306 Using Learning rate : 0.027150954189749735 
INFO:root:FL Epoch: 306 Normal Training
INFO:root:Worker: 810 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693931
INFO:root:Worker: 810 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530092
INFO:root:FL Epoch: 306 Norm Difference for worker 810 is 1.171052
INFO:root:FL Epoch: 306 Done on worker:810
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 892
INFO:root:Norm of Aggregated Model: 5154.99365234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 306 Ends   ===================
INFO:root:Epoch:306 Global Model Test Loss:0.5332454407916349 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:306 Global Model Backdoor Test Loss:0.28848249465227127                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 307 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 307 Workers Selected : [975, 759, 552, 1893, 144, 1194, 1904, 1014, 1462, 1036]
INFO:root:FL Epoch: 307 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 307 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 307 Training on worker :975
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576709
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367328
INFO:root:FL Epoch: 307 Norm Difference for worker 975 is 1.008327
INFO:root:FL Epoch: 307 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :759
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 759 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635682
INFO:root:Worker: 759 Train Epoch: 1 [0/200 (0%)]	Loss: 0.567705
INFO:root:FL Epoch: 307 Norm Difference for worker 759 is 1.030283
INFO:root:FL Epoch: 307 Done on worker:759
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :552
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.721550
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690664
INFO:root:FL Epoch: 307 Norm Difference for worker 552 is 1.061944
INFO:root:FL Epoch: 307 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1893
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600968
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378847
INFO:root:FL Epoch: 307 Norm Difference for worker 1893 is 1.054326
INFO:root:FL Epoch: 307 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :144
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.807575
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.332488
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 307 Norm Difference for worker 144 is 1.061395
INFO:root:FL Epoch: 307 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1194
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1194 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727650
INFO:root:Worker: 1194 Train Epoch: 1 [0/200 (0%)]	Loss: 0.771505
INFO:root:FL Epoch: 307 Norm Difference for worker 1194 is 1.003357
INFO:root:FL Epoch: 307 Done on worker:1194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1904
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543274
INFO:root:Worker: 1904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388870
INFO:root:FL Epoch: 307 Norm Difference for worker 1904 is 1.015853
INFO:root:FL Epoch: 307 Done on worker:1904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1014
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.699874
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550448
INFO:root:FL Epoch: 307 Norm Difference for worker 1014 is 1.061357
INFO:root:FL Epoch: 307 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1462
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609025
INFO:root:Worker: 1462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639969
INFO:root:FL Epoch: 307 Norm Difference for worker 1462 is 1.036095
INFO:root:FL Epoch: 307 Done on worker:1462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 307 Training on worker :1036
INFO:root:FL Epoch: 307 Using Learning rate : 0.02709665228137023 
INFO:root:FL Epoch: 307 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455055
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423694
INFO:root:FL Epoch: 307 Norm Difference for worker 1036 is 1.04742
INFO:root:FL Epoch: 307 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1194
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 307 Ends   ===================
INFO:root:Epoch:307 Global Model Test Loss:0.5354422769125771 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:307 Global Model Backdoor Test Loss:0.3269252727429072                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 308 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 308 Workers Selected : [1102, 352, 1587, 1069, 1440, 1142, 1182, 1854, 52, 859]
INFO:root:FL Epoch: 308 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 308 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 308 Training on worker :1102
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650289
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515755
INFO:root:FL Epoch: 308 Norm Difference for worker 1102 is 0.867289
INFO:root:FL Epoch: 308 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :352
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560054
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472477
INFO:root:FL Epoch: 308 Norm Difference for worker 352 is 0.869807
INFO:root:FL Epoch: 308 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1587
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565940
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411413
INFO:root:FL Epoch: 308 Norm Difference for worker 1587 is 0.816551
INFO:root:FL Epoch: 308 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1069
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1069 Train Epoch: 0 [0/200 (0%)]	Loss: 0.747594
INFO:root:Worker: 1069 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630536
INFO:root:FL Epoch: 308 Norm Difference for worker 1069 is 0.831948
INFO:root:FL Epoch: 308 Done on worker:1069
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1440
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585558
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538551
INFO:root:FL Epoch: 308 Norm Difference for worker 1440 is 0.884569
INFO:root:FL Epoch: 308 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1142
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464227
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471361
INFO:root:FL Epoch: 308 Norm Difference for worker 1142 is 0.844199
INFO:root:FL Epoch: 308 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1182
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455558
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489045
INFO:root:FL Epoch: 308 Norm Difference for worker 1182 is 0.834089
INFO:root:FL Epoch: 308 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :1854
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516083
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.836846
INFO:root:FL Epoch: 308 Norm Difference for worker 1854 is 0.928622
INFO:root:FL Epoch: 308 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :52
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 52 Train Epoch: 0 [0/201 (0%)]	Loss: 0.502593
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 52 Train Epoch: 1 [0/201 (0%)]	Loss: 0.741945
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 308 Norm Difference for worker 52 is 0.852148
INFO:root:FL Epoch: 308 Done on worker:52
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 308 Training on worker :859
INFO:root:FL Epoch: 308 Using Learning rate : 0.027042458976807494 
INFO:root:FL Epoch: 308 Normal Training
INFO:root:Worker: 859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516073
INFO:root:Worker: 859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461350
INFO:root:FL Epoch: 308 Norm Difference for worker 859 is 0.913875
INFO:root:FL Epoch: 308 Done on worker:859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1587
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 308 Ends   ===================
INFO:root:Epoch:308 Global Model Test Loss:0.5489125654977911 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:308 Global Model Backdoor Test Loss:0.4330122768878937                             and Backdoor Test Accuracy:78.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 309 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 309 Workers Selected : [478, 1024, 1666, 504, 967, 915, 1573, 1421, 422, 411]
INFO:root:FL Epoch: 309 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 309 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 309 Training on worker :478
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758855
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419640
INFO:root:FL Epoch: 309 Norm Difference for worker 478 is 0.886625
INFO:root:FL Epoch: 309 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1024
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.888549
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506559
INFO:root:FL Epoch: 309 Norm Difference for worker 1024 is 0.825669
INFO:root:FL Epoch: 309 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1666
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587089
INFO:root:Worker: 1666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614237
INFO:root:FL Epoch: 309 Norm Difference for worker 1666 is 0.888894
INFO:root:FL Epoch: 309 Done on worker:1666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :504
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450047
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.495247
INFO:root:FL Epoch: 309 Norm Difference for worker 504 is 0.864786
INFO:root:FL Epoch: 309 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :967
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 967 Train Epoch: 0 [0/200 (0%)]	Loss: 0.301648
INFO:root:Worker: 967 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310766
INFO:root:FL Epoch: 309 Norm Difference for worker 967 is 0.868636
INFO:root:FL Epoch: 309 Done on worker:967
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :915
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711471
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401921
INFO:root:FL Epoch: 309 Norm Difference for worker 915 is 0.914096
INFO:root:FL Epoch: 309 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1573
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599599
INFO:root:Worker: 1573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401198
INFO:root:FL Epoch: 309 Norm Difference for worker 1573 is 0.896894
INFO:root:FL Epoch: 309 Done on worker:1573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :1421
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 1421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485221
INFO:root:Worker: 1421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409926
INFO:root:FL Epoch: 309 Norm Difference for worker 1421 is 0.808614
INFO:root:FL Epoch: 309 Done on worker:1421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :422
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772889
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638876
INFO:root:FL Epoch: 309 Norm Difference for worker 422 is 0.878643
INFO:root:FL Epoch: 309 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 309 Training on worker :411
INFO:root:FL Epoch: 309 Using Learning rate : 0.026988374058853876 
INFO:root:FL Epoch: 309 Normal Training
INFO:root:Worker: 411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570974
INFO:root:Worker: 411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375631
INFO:root:FL Epoch: 309 Norm Difference for worker 411 is 0.876859
INFO:root:FL Epoch: 309 Done on worker:411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1024
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 309 Ends   ===================
INFO:root:Epoch:309 Global Model Test Loss:0.5390539397211636 and Test Accuracy:70.88235294117646 
INFO:root:Epoch:309 Global Model Backdoor Test Loss:0.37643564244111377                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 310 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 310 Workers Selected : [439, 1393, 1417, 1177, 757, 265, 532, 1180, 767, 1107]
INFO:root:FL Epoch: 310 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 310 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 310 Training on worker :439
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664266
INFO:root:Worker: 439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484772
INFO:root:FL Epoch: 310 Norm Difference for worker 439 is 0.72372
INFO:root:FL Epoch: 310 Done on worker:439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1393
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559041
INFO:root:Worker: 1393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548494
INFO:root:FL Epoch: 310 Norm Difference for worker 1393 is 0.755422
INFO:root:FL Epoch: 310 Done on worker:1393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1417
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458531
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570771
INFO:root:FL Epoch: 310 Norm Difference for worker 1417 is 0.750137
INFO:root:FL Epoch: 310 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1177
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1177 Train Epoch: 0 [0/200 (0%)]	Loss: 0.813127
INFO:root:Worker: 1177 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540883
INFO:root:FL Epoch: 310 Norm Difference for worker 1177 is 0.834343
INFO:root:FL Epoch: 310 Done on worker:1177
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :757
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757901
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684794
INFO:root:FL Epoch: 310 Norm Difference for worker 757 is 0.805651
INFO:root:FL Epoch: 310 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :265
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 265 Train Epoch: 0 [0/201 (0%)]	Loss: 0.495850
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 265 Train Epoch: 1 [0/201 (0%)]	Loss: 0.359706
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 310 Norm Difference for worker 265 is 0.791205
INFO:root:FL Epoch: 310 Done on worker:265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :532
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613811
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427282
INFO:root:FL Epoch: 310 Norm Difference for worker 532 is 0.81034
INFO:root:FL Epoch: 310 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1180
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724329
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586795
INFO:root:FL Epoch: 310 Norm Difference for worker 1180 is 0.754287
INFO:root:FL Epoch: 310 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :767
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 767 Train Epoch: 0 [0/200 (0%)]	Loss: 0.832887
INFO:root:Worker: 767 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505319
INFO:root:FL Epoch: 310 Norm Difference for worker 767 is 0.79568
INFO:root:FL Epoch: 310 Done on worker:767
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 310 Training on worker :1107
INFO:root:FL Epoch: 310 Using Learning rate : 0.02693439731073617 
INFO:root:FL Epoch: 310 Normal Training
INFO:root:Worker: 1107 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578253
INFO:root:Worker: 1107 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547651
INFO:root:FL Epoch: 310 Norm Difference for worker 1107 is 0.862922
INFO:root:FL Epoch: 310 Done on worker:1107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1393
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 310 Ends   ===================
INFO:root:Epoch:310 Global Model Test Loss:0.530686790452284 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:310 Global Model Backdoor Test Loss:0.37145369748274487                             and Backdoor Test Accuracy:85.0 
INFO:root:=======================================================
INFO:root:================FL round 311 Begins ===================
INFO:root:FL Epoch: 311 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 311 Workers Selected : [0, 258, 1148, 1057, 1821, 1666, 1311, 1342, 1580, 208]
INFO:root:FL Epoch: 311 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 311 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 311 Training on worker :0
INFO:root:FL Epoch: 311 Using Learning rate : 0.00537610570322294 
INFO:root:FL Epoch: 311 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342184
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325511
INFO:root:FL Epoch: 311 Worker: 0 Backdoor Test Loss: 0.3061649700005849 Backdoor Test Accuracy: 88.33333333333333
INFO:root:FL Epoch: 311 Worker: 0 Backdoor Train Loss: 0.26059757769107816 Backdoor Train Accuracy: 93.0
INFO:root:FL Epoch: 311 Norm Difference for worker 0 is 0.199797
INFO:root:FL Epoch: 311 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :258
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.768415
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.519162
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 311 Norm Difference for worker 258 is 0.854376
INFO:root:FL Epoch: 311 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1148
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1148 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577873
INFO:root:Worker: 1148 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606779
INFO:root:FL Epoch: 311 Norm Difference for worker 1148 is 0.84276
INFO:root:FL Epoch: 311 Done on worker:1148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1057
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1057 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616972
INFO:root:Worker: 1057 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390516
INFO:root:FL Epoch: 311 Norm Difference for worker 1057 is 0.779988
INFO:root:FL Epoch: 311 Done on worker:1057
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1821
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659083
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441551
INFO:root:FL Epoch: 311 Norm Difference for worker 1821 is 0.850819
INFO:root:FL Epoch: 311 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1666
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579435
INFO:root:Worker: 1666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492310
INFO:root:FL Epoch: 311 Norm Difference for worker 1666 is 0.810892
INFO:root:FL Epoch: 311 Done on worker:1666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1311
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1311 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578749
INFO:root:Worker: 1311 Train Epoch: 1 [0/200 (0%)]	Loss: 0.841021
INFO:root:FL Epoch: 311 Norm Difference for worker 1311 is 0.815645
INFO:root:FL Epoch: 311 Done on worker:1311
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1342
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.365949
INFO:root:Worker: 1342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320627
INFO:root:FL Epoch: 311 Norm Difference for worker 1342 is 0.833944
INFO:root:FL Epoch: 311 Done on worker:1342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :1580
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 1580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391306
INFO:root:Worker: 1580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418817
INFO:root:FL Epoch: 311 Norm Difference for worker 1580 is 0.79619
INFO:root:FL Epoch: 311 Done on worker:1580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 311 Training on worker :208
INFO:root:FL Epoch: 311 Using Learning rate : 0.0268805285161147 
INFO:root:FL Epoch: 311 Normal Training
INFO:root:Worker: 208 Train Epoch: 0 [0/201 (0%)]	Loss: 0.408726
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 208 Train Epoch: 1 [0/201 (0%)]	Loss: 0.452219
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 311 Norm Difference for worker 208 is 0.845044
INFO:root:FL Epoch: 311 Done on worker:208
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 311 Ends   ===================
INFO:root:Epoch:311 Global Model Test Loss:0.5264761851114386 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:311 Global Model Backdoor Test Loss:0.3061649700005849                             and Backdoor Test Accuracy:88.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 312 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 312 Workers Selected : [1405, 1711, 1582, 1040, 1687, 1441, 247, 144, 809, 1510]
INFO:root:FL Epoch: 312 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 312 Num points on workers: [200 200 200 200 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 312 Training on worker :1405
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504609
INFO:root:Worker: 1405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557467
INFO:root:FL Epoch: 312 Norm Difference for worker 1405 is 0.916065
INFO:root:FL Epoch: 312 Done on worker:1405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1711
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446133
INFO:root:Worker: 1711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423706
INFO:root:FL Epoch: 312 Norm Difference for worker 1711 is 0.936676
INFO:root:FL Epoch: 312 Done on worker:1711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1582
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1582 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441499
INFO:root:Worker: 1582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679022
INFO:root:FL Epoch: 312 Norm Difference for worker 1582 is 0.916677
INFO:root:FL Epoch: 312 Done on worker:1582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1040
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537721
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478391
INFO:root:FL Epoch: 312 Norm Difference for worker 1040 is 0.921034
INFO:root:FL Epoch: 312 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1687
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1687 Train Epoch: 0 [0/200 (0%)]	Loss: 0.854240
INFO:root:Worker: 1687 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655490
INFO:root:FL Epoch: 312 Norm Difference for worker 1687 is 0.991747
INFO:root:FL Epoch: 312 Done on worker:1687
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1441
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618301
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411224
INFO:root:FL Epoch: 312 Norm Difference for worker 1441 is 0.899047
INFO:root:FL Epoch: 312 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :247
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.773032
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.418233
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 312 Norm Difference for worker 247 is 0.908024
INFO:root:FL Epoch: 312 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :144
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.633133
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.333051
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 312 Norm Difference for worker 144 is 0.887872
INFO:root:FL Epoch: 312 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :809
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359027
INFO:root:Worker: 809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674043
INFO:root:FL Epoch: 312 Norm Difference for worker 809 is 0.876483
INFO:root:FL Epoch: 312 Done on worker:809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 312 Training on worker :1510
INFO:root:FL Epoch: 312 Using Learning rate : 0.026826767459082468 
INFO:root:FL Epoch: 312 Normal Training
INFO:root:Worker: 1510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573278
INFO:root:Worker: 1510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431493
INFO:root:FL Epoch: 312 Norm Difference for worker 1510 is 0.869383
INFO:root:FL Epoch: 312 Done on worker:1510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1405
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 312 Ends   ===================
INFO:root:Epoch:312 Global Model Test Loss:0.5228635493446799 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:312 Global Model Backdoor Test Loss:0.35909287134806317                             and Backdoor Test Accuracy:85.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 313 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 313 Workers Selected : [1463, 1864, 1780, 1381, 250, 821, 1375, 1434, 704, 808]
INFO:root:FL Epoch: 313 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 313 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 313 Training on worker :1463
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560701
INFO:root:Worker: 1463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521904
INFO:root:FL Epoch: 313 Norm Difference for worker 1463 is 0.901938
INFO:root:FL Epoch: 313 Done on worker:1463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1864
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565778
INFO:root:Worker: 1864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595358
INFO:root:FL Epoch: 313 Norm Difference for worker 1864 is 0.798832
INFO:root:FL Epoch: 313 Done on worker:1864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1780
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748998
INFO:root:Worker: 1780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407633
INFO:root:FL Epoch: 313 Norm Difference for worker 1780 is 0.874053
INFO:root:FL Epoch: 313 Done on worker:1780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1381
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649976
INFO:root:Worker: 1381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485393
INFO:root:FL Epoch: 313 Norm Difference for worker 1381 is 0.791103
INFO:root:FL Epoch: 313 Done on worker:1381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :250
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.415096
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.588074
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 313 Norm Difference for worker 250 is 0.854083
INFO:root:FL Epoch: 313 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :821
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768880
INFO:root:Worker: 821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458213
INFO:root:FL Epoch: 313 Norm Difference for worker 821 is 0.840623
INFO:root:FL Epoch: 313 Done on worker:821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1375
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1375 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574823
INFO:root:Worker: 1375 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371660
INFO:root:FL Epoch: 313 Norm Difference for worker 1375 is 0.853072
INFO:root:FL Epoch: 313 Done on worker:1375
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :1434
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 1434 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533432
INFO:root:Worker: 1434 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334047
INFO:root:FL Epoch: 313 Norm Difference for worker 1434 is 0.853415
INFO:root:FL Epoch: 313 Done on worker:1434
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :704
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559228
INFO:root:Worker: 704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599301
INFO:root:FL Epoch: 313 Norm Difference for worker 704 is 0.842734
INFO:root:FL Epoch: 313 Done on worker:704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 313 Training on worker :808
INFO:root:FL Epoch: 313 Using Learning rate : 0.026773113924164305 
INFO:root:FL Epoch: 313 Normal Training
INFO:root:Worker: 808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531568
INFO:root:Worker: 808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385879
INFO:root:FL Epoch: 313 Norm Difference for worker 808 is 0.852604
INFO:root:FL Epoch: 313 Done on worker:808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1381
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 313 Ends   ===================
INFO:root:Epoch:313 Global Model Test Loss:0.5194206185200635 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:313 Global Model Backdoor Test Loss:0.28495900084575015                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 314 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 314 Workers Selected : [299, 261, 696, 773, 508, 6, 405, 238, 1762, 1469]
INFO:root:FL Epoch: 314 Fraction of points on each worker in this round: [0.1002994 0.1002994 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 314 Num points on workers: [201 201 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 314 Training on worker :299
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 299 Train Epoch: 0 [0/201 (0%)]	Loss: 0.522670
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 299 Train Epoch: 1 [0/201 (0%)]	Loss: 0.386768
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 314 Norm Difference for worker 299 is 0.829222
INFO:root:FL Epoch: 314 Done on worker:299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :261
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.640682
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446458
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 314 Norm Difference for worker 261 is 0.770562
INFO:root:FL Epoch: 314 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :696
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619708
INFO:root:Worker: 696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573795
INFO:root:FL Epoch: 314 Norm Difference for worker 696 is 0.836287
INFO:root:FL Epoch: 314 Done on worker:696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :773
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578396
INFO:root:Worker: 773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.242704
INFO:root:FL Epoch: 314 Norm Difference for worker 773 is 0.865058
INFO:root:FL Epoch: 314 Done on worker:773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :508
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.751406
INFO:root:Worker: 508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.559175
INFO:root:FL Epoch: 314 Norm Difference for worker 508 is 0.805683
INFO:root:FL Epoch: 314 Done on worker:508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :6
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 6 Train Epoch: 0 [0/201 (0%)]	Loss: 0.461385
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 6 Train Epoch: 1 [0/201 (0%)]	Loss: 0.400217
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 314 Norm Difference for worker 6 is 0.775132
INFO:root:FL Epoch: 314 Done on worker:6
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :405
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455185
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551244
INFO:root:FL Epoch: 314 Norm Difference for worker 405 is 0.824899
INFO:root:FL Epoch: 314 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :238
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 238 Train Epoch: 0 [0/201 (0%)]	Loss: 0.448320
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 238 Train Epoch: 1 [0/201 (0%)]	Loss: 0.628219
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 314 Norm Difference for worker 238 is 0.754391
INFO:root:FL Epoch: 314 Done on worker:238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1762
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1762 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350567
INFO:root:Worker: 1762 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335631
INFO:root:FL Epoch: 314 Norm Difference for worker 1762 is 0.779605
INFO:root:FL Epoch: 314 Done on worker:1762
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 314 Training on worker :1469
INFO:root:FL Epoch: 314 Using Learning rate : 0.026719567696315977 
INFO:root:FL Epoch: 314 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437581
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443827
INFO:root:FL Epoch: 314 Norm Difference for worker 1469 is 0.75269
INFO:root:FL Epoch: 314 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1762
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 314 Ends   ===================
INFO:root:Epoch:314 Global Model Test Loss:0.531554202823078 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:314 Global Model Backdoor Test Loss:0.29171545555194217                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 315 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 315 Workers Selected : [245, 112, 198, 1475, 433, 874, 1523, 549, 378, 1453]
INFO:root:FL Epoch: 315 Fraction of points on each worker in this round: [0.10034948 0.10034948 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 315 Num points on workers: [201 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 315 Training on worker :245
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 245 Train Epoch: 0 [0/201 (0%)]	Loss: 0.538511
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 245 Train Epoch: 1 [0/201 (0%)]	Loss: 0.520287
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 315 Norm Difference for worker 245 is 1.094342
INFO:root:FL Epoch: 315 Done on worker:245
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :112
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 112 Train Epoch: 0 [0/201 (0%)]	Loss: 0.488247
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 112 Train Epoch: 1 [0/201 (0%)]	Loss: 0.451398
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 315 Norm Difference for worker 112 is 0.820585
INFO:root:FL Epoch: 315 Done on worker:112
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :198
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 198 Train Epoch: 0 [0/201 (0%)]	Loss: 0.592804
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 198 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381431
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 315 Norm Difference for worker 198 is 0.94913
INFO:root:FL Epoch: 315 Done on worker:198
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1475
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326536
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432398
INFO:root:FL Epoch: 315 Norm Difference for worker 1475 is 1.032646
INFO:root:FL Epoch: 315 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :433
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 433 Train Epoch: 0 [0/200 (0%)]	Loss: 0.829256
INFO:root:Worker: 433 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404410
INFO:root:FL Epoch: 315 Norm Difference for worker 433 is 0.997132
INFO:root:FL Epoch: 315 Done on worker:433
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :874
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549579
INFO:root:Worker: 874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417512
INFO:root:FL Epoch: 315 Norm Difference for worker 874 is 1.041959
INFO:root:FL Epoch: 315 Done on worker:874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1523
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499043
INFO:root:Worker: 1523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557680
INFO:root:FL Epoch: 315 Norm Difference for worker 1523 is 1.034354
INFO:root:FL Epoch: 315 Done on worker:1523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :549
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 549 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597168
INFO:root:Worker: 549 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372635
INFO:root:FL Epoch: 315 Norm Difference for worker 549 is 1.019544
INFO:root:FL Epoch: 315 Done on worker:549
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :378
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370524
INFO:root:Worker: 378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524326
INFO:root:FL Epoch: 315 Norm Difference for worker 378 is 1.026632
INFO:root:FL Epoch: 315 Done on worker:378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 315 Training on worker :1453
INFO:root:FL Epoch: 315 Using Learning rate : 0.026666128560923343 
INFO:root:FL Epoch: 315 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609469
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491606
INFO:root:FL Epoch: 315 Norm Difference for worker 1453 is 1.080649
INFO:root:FL Epoch: 315 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 112
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 315 Ends   ===================
INFO:root:Epoch:315 Global Model Test Loss:0.5085057142902824 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:315 Global Model Backdoor Test Loss:0.24561731393138567                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 316 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 316 Workers Selected : [1380, 1360, 631, 1340, 926, 471, 1347, 1284, 1067, 1890]
INFO:root:FL Epoch: 316 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 316 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 316 Training on worker :1380
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634478
INFO:root:Worker: 1380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525084
INFO:root:FL Epoch: 316 Norm Difference for worker 1380 is 1.112065
INFO:root:FL Epoch: 316 Done on worker:1380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1360
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616210
INFO:root:Worker: 1360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422756
INFO:root:FL Epoch: 316 Norm Difference for worker 1360 is 1.112668
INFO:root:FL Epoch: 316 Done on worker:1360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :631
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532669
INFO:root:Worker: 631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636631
INFO:root:FL Epoch: 316 Norm Difference for worker 631 is 1.146237
INFO:root:FL Epoch: 316 Done on worker:631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1340
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612061
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536123
INFO:root:FL Epoch: 316 Norm Difference for worker 1340 is 1.180398
INFO:root:FL Epoch: 316 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :926
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.782931
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671492
INFO:root:FL Epoch: 316 Norm Difference for worker 926 is 1.076221
INFO:root:FL Epoch: 316 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :471
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 471 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370761
INFO:root:Worker: 471 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326663
INFO:root:FL Epoch: 316 Norm Difference for worker 471 is 1.112421
INFO:root:FL Epoch: 316 Done on worker:471
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1347
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578263
INFO:root:Worker: 1347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472646
INFO:root:FL Epoch: 316 Norm Difference for worker 1347 is 1.174466
INFO:root:FL Epoch: 316 Done on worker:1347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1284
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1284 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424233
INFO:root:Worker: 1284 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449065
INFO:root:FL Epoch: 316 Norm Difference for worker 1284 is 0.8625
INFO:root:FL Epoch: 316 Done on worker:1284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1067
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1067 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601661
INFO:root:Worker: 1067 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476112
INFO:root:FL Epoch: 316 Norm Difference for worker 1067 is 1.000839
INFO:root:FL Epoch: 316 Done on worker:1067
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 316 Training on worker :1890
INFO:root:FL Epoch: 316 Using Learning rate : 0.026612796303801495 
INFO:root:FL Epoch: 316 Normal Training
INFO:root:Worker: 1890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.304060
INFO:root:Worker: 1890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.314836
INFO:root:FL Epoch: 316 Norm Difference for worker 1890 is 0.979475
INFO:root:FL Epoch: 316 Done on worker:1890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1284
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 316 Ends   ===================
INFO:root:Epoch:316 Global Model Test Loss:0.5270120764479918 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:316 Global Model Backdoor Test Loss:0.22184055671095848                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 317 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 317 Workers Selected : [1862, 1295, 88, 1516, 325, 519, 1068, 1073, 1119, 545]
INFO:root:FL Epoch: 317 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 317 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 317 Training on worker :1862
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560984
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409503
INFO:root:FL Epoch: 317 Norm Difference for worker 1862 is 1.111513
INFO:root:FL Epoch: 317 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :1295
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444558
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463336
INFO:root:FL Epoch: 317 Norm Difference for worker 1295 is 1.146996
INFO:root:FL Epoch: 317 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :88
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 88 Train Epoch: 0 [0/201 (0%)]	Loss: 0.269910
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 88 Train Epoch: 1 [0/201 (0%)]	Loss: 0.657247
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 88 is 1.190893
INFO:root:FL Epoch: 317 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :1516
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1516 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605183
INFO:root:Worker: 1516 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537608
INFO:root:FL Epoch: 317 Norm Difference for worker 1516 is 1.245584
INFO:root:FL Epoch: 317 Done on worker:1516
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :325
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.462258
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431589
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 317 Norm Difference for worker 325 is 1.17297
INFO:root:FL Epoch: 317 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :519
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.567339
INFO:root:Worker: 519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463609
INFO:root:FL Epoch: 317 Norm Difference for worker 519 is 1.181607
INFO:root:FL Epoch: 317 Done on worker:519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :1068
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1068 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600091
INFO:root:Worker: 1068 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268092
INFO:root:FL Epoch: 317 Norm Difference for worker 1068 is 1.089732
INFO:root:FL Epoch: 317 Done on worker:1068
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :1073
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1073 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701724
INFO:root:Worker: 1073 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417552
INFO:root:FL Epoch: 317 Norm Difference for worker 1073 is 1.2926
INFO:root:FL Epoch: 317 Done on worker:1073
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :1119
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 1119 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679502
INFO:root:Worker: 1119 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315611
INFO:root:FL Epoch: 317 Norm Difference for worker 1119 is 1.109495
INFO:root:FL Epoch: 317 Done on worker:1119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 317 Training on worker :545
INFO:root:FL Epoch: 317 Using Learning rate : 0.026559570711193893 
INFO:root:FL Epoch: 317 Normal Training
INFO:root:Worker: 545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.264896
INFO:root:Worker: 545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302059
INFO:root:FL Epoch: 317 Norm Difference for worker 545 is 1.209097
INFO:root:FL Epoch: 317 Done on worker:545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1862
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 317 Ends   ===================
INFO:root:Epoch:317 Global Model Test Loss:0.5101544506409589 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:317 Global Model Backdoor Test Loss:0.23472832888364792                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 318 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 318 Workers Selected : [904, 1273, 977, 941, 1371, 1843, 1658, 1452, 1548, 1782]
INFO:root:FL Epoch: 318 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 318 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 318 Training on worker :904
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.855000
INFO:root:Worker: 904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404111
INFO:root:FL Epoch: 318 Norm Difference for worker 904 is 0.970702
INFO:root:FL Epoch: 318 Done on worker:904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1273
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1273 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576673
INFO:root:Worker: 1273 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375131
INFO:root:FL Epoch: 318 Norm Difference for worker 1273 is 1.046102
INFO:root:FL Epoch: 318 Done on worker:1273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :977
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 977 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425058
INFO:root:Worker: 977 Train Epoch: 1 [0/200 (0%)]	Loss: 0.387999
INFO:root:FL Epoch: 318 Norm Difference for worker 977 is 1.020359
INFO:root:FL Epoch: 318 Done on worker:977
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :941
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367292
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.238088
INFO:root:FL Epoch: 318 Norm Difference for worker 941 is 0.779885
INFO:root:FL Epoch: 318 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1371
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547298
INFO:root:Worker: 1371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570586
INFO:root:FL Epoch: 318 Norm Difference for worker 1371 is 1.131423
INFO:root:FL Epoch: 318 Done on worker:1371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1843
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328375
INFO:root:Worker: 1843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270830
INFO:root:FL Epoch: 318 Norm Difference for worker 1843 is 0.845766
INFO:root:FL Epoch: 318 Done on worker:1843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1658
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1658 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465719
INFO:root:Worker: 1658 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459365
INFO:root:FL Epoch: 318 Norm Difference for worker 1658 is 0.983244
INFO:root:FL Epoch: 318 Done on worker:1658
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1452
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643907
INFO:root:Worker: 1452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343647
INFO:root:FL Epoch: 318 Norm Difference for worker 1452 is 1.010805
INFO:root:FL Epoch: 318 Done on worker:1452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1548
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1548 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511822
INFO:root:Worker: 1548 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358171
INFO:root:FL Epoch: 318 Norm Difference for worker 1548 is 0.978378
INFO:root:FL Epoch: 318 Done on worker:1548
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 318 Training on worker :1782
INFO:root:FL Epoch: 318 Using Learning rate : 0.026506451569771508 
INFO:root:FL Epoch: 318 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.737791
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444419
INFO:root:FL Epoch: 318 Norm Difference for worker 1782 is 1.042232
INFO:root:FL Epoch: 318 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 941
INFO:root:Norm of Aggregated Model: 5154.994140625
INFO:root:Aggregating After Defense
INFO:root:================FL round 318 Ends   ===================
INFO:root:Epoch:318 Global Model Test Loss:0.5238562594441807 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:318 Global Model Backdoor Test Loss:0.22150942434867224                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 319 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 319 Workers Selected : [1769, 121, 1308, 1169, 1861, 1877, 460, 746, 274, 833]
INFO:root:FL Epoch: 319 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 319 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 319 Training on worker :1769
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343519
INFO:root:Worker: 1769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.708771
INFO:root:FL Epoch: 319 Norm Difference for worker 1769 is 1.155843
INFO:root:FL Epoch: 319 Done on worker:1769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :121
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 121 Train Epoch: 0 [0/201 (0%)]	Loss: 0.654689
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 121 Train Epoch: 1 [0/201 (0%)]	Loss: 0.379910
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 319 Norm Difference for worker 121 is 1.274243
INFO:root:FL Epoch: 319 Done on worker:121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1308
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557259
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522095
INFO:root:FL Epoch: 319 Norm Difference for worker 1308 is 1.161366
INFO:root:FL Epoch: 319 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1169
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1169 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577935
INFO:root:Worker: 1169 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348874
INFO:root:FL Epoch: 319 Norm Difference for worker 1169 is 1.155199
INFO:root:FL Epoch: 319 Done on worker:1169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1861
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530511
INFO:root:Worker: 1861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398758
INFO:root:FL Epoch: 319 Norm Difference for worker 1861 is 1.13488
INFO:root:FL Epoch: 319 Done on worker:1861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :1877
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 1877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562514
INFO:root:Worker: 1877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375835
INFO:root:FL Epoch: 319 Norm Difference for worker 1877 is 1.1262
INFO:root:FL Epoch: 319 Done on worker:1877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :460
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398585
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638390
INFO:root:FL Epoch: 319 Norm Difference for worker 460 is 1.205916
INFO:root:FL Epoch: 319 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :746
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 746 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590778
INFO:root:Worker: 746 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333881
INFO:root:FL Epoch: 319 Norm Difference for worker 746 is 1.158118
INFO:root:FL Epoch: 319 Done on worker:746
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :274
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.514929
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.492200
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 319 Norm Difference for worker 274 is 1.212085
INFO:root:FL Epoch: 319 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 319 Training on worker :833
INFO:root:FL Epoch: 319 Using Learning rate : 0.026453438666631964 
INFO:root:FL Epoch: 319 Normal Training
INFO:root:Worker: 833 Train Epoch: 0 [0/200 (0%)]	Loss: 0.262543
INFO:root:Worker: 833 Train Epoch: 1 [0/200 (0%)]	Loss: 0.262733
INFO:root:FL Epoch: 319 Norm Difference for worker 833 is 0.964986
INFO:root:FL Epoch: 319 Done on worker:833
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 833
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 319 Ends   ===================
INFO:root:Epoch:319 Global Model Test Loss:0.5368453281767228 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:319 Global Model Backdoor Test Loss:0.24833124751845995                             and Backdoor Test Accuracy:90.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 320 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 320 Workers Selected : [222, 563, 1511, 1051, 666, 485, 1931, 809, 906, 1379]
INFO:root:FL Epoch: 320 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 320 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 320 Training on worker :222
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.390260
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.193422
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 320 Norm Difference for worker 222 is 0.901594
INFO:root:FL Epoch: 320 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :563
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620222
INFO:root:Worker: 563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454335
INFO:root:FL Epoch: 320 Norm Difference for worker 563 is 1.243085
INFO:root:FL Epoch: 320 Done on worker:563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1511
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595914
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.627944
INFO:root:FL Epoch: 320 Norm Difference for worker 1511 is 1.354101
INFO:root:FL Epoch: 320 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1051
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1051 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657183
INFO:root:Worker: 1051 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488897
INFO:root:FL Epoch: 320 Norm Difference for worker 1051 is 1.140254
INFO:root:FL Epoch: 320 Done on worker:1051
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :666
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601952
INFO:root:Worker: 666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663182
INFO:root:FL Epoch: 320 Norm Difference for worker 666 is 1.235119
INFO:root:FL Epoch: 320 Done on worker:666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :485
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515951
INFO:root:Worker: 485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538036
INFO:root:FL Epoch: 320 Norm Difference for worker 485 is 1.137834
INFO:root:FL Epoch: 320 Done on worker:485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1931
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.881700
INFO:root:Worker: 1931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548900
INFO:root:FL Epoch: 320 Norm Difference for worker 1931 is 1.282714
INFO:root:FL Epoch: 320 Done on worker:1931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :809
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342364
INFO:root:Worker: 809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707337
INFO:root:FL Epoch: 320 Norm Difference for worker 809 is 1.144193
INFO:root:FL Epoch: 320 Done on worker:809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :906
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374660
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319560
INFO:root:FL Epoch: 320 Norm Difference for worker 906 is 1.143431
INFO:root:FL Epoch: 320 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 320 Training on worker :1379
INFO:root:FL Epoch: 320 Using Learning rate : 0.0264005317892987 
INFO:root:FL Epoch: 320 Normal Training
INFO:root:Worker: 1379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436387
INFO:root:Worker: 1379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524096
INFO:root:FL Epoch: 320 Norm Difference for worker 1379 is 1.196229
INFO:root:FL Epoch: 320 Done on worker:1379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 222
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 320 Ends   ===================
INFO:root:Epoch:320 Global Model Test Loss:0.5672814512954039 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:320 Global Model Backdoor Test Loss:0.185163755590717                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 321 Begins ===================
INFO:root:FL Epoch: 321 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 321 Workers Selected : [0, 1754, 1419, 1495, 1748, 1560, 1339, 416, 1820, 591]
INFO:root:FL Epoch: 321 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 321 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 321 Training on worker :0
INFO:root:FL Epoch: 321 Using Learning rate : 0.005269546145144021 
INFO:root:FL Epoch: 321 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.174589
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263734
INFO:root:FL Epoch: 321 Worker: 0 Backdoor Test Loss: 0.1818699911236763 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 321 Worker: 0 Backdoor Train Loss: 0.16645586267113685 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 321 Norm Difference for worker 0 is 0.189703
INFO:root:FL Epoch: 321 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1754
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581870
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327044
INFO:root:FL Epoch: 321 Norm Difference for worker 1754 is 1.306562
INFO:root:FL Epoch: 321 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1419
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525765
INFO:root:Worker: 1419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605141
INFO:root:FL Epoch: 321 Norm Difference for worker 1419 is 1.192623
INFO:root:FL Epoch: 321 Done on worker:1419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1495
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459300
INFO:root:Worker: 1495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522506
INFO:root:FL Epoch: 321 Norm Difference for worker 1495 is 1.348321
INFO:root:FL Epoch: 321 Done on worker:1495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1748
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1748 Train Epoch: 0 [0/200 (0%)]	Loss: 0.815808
INFO:root:Worker: 1748 Train Epoch: 1 [0/200 (0%)]	Loss: 0.866590
INFO:root:FL Epoch: 321 Norm Difference for worker 1748 is 1.402954
INFO:root:FL Epoch: 321 Done on worker:1748
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1560
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511195
INFO:root:Worker: 1560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.205715
INFO:root:FL Epoch: 321 Norm Difference for worker 1560 is 1.281231
INFO:root:FL Epoch: 321 Done on worker:1560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1339
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1339 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756820
INFO:root:Worker: 1339 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513493
INFO:root:FL Epoch: 321 Norm Difference for worker 1339 is 1.216514
INFO:root:FL Epoch: 321 Done on worker:1339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :416
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 416 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492301
INFO:root:Worker: 416 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292740
INFO:root:FL Epoch: 321 Norm Difference for worker 416 is 1.391976
INFO:root:FL Epoch: 321 Done on worker:416
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :1820
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 1820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.904610
INFO:root:Worker: 1820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454692
INFO:root:FL Epoch: 321 Norm Difference for worker 1820 is 1.415013
INFO:root:FL Epoch: 321 Done on worker:1820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 321 Training on worker :591
INFO:root:FL Epoch: 321 Using Learning rate : 0.026347730725720105 
INFO:root:FL Epoch: 321 Normal Training
INFO:root:Worker: 591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.682190
INFO:root:Worker: 591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604477
INFO:root:FL Epoch: 321 Norm Difference for worker 591 is 1.490917
INFO:root:FL Epoch: 321 Done on worker:591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 321 Ends   ===================
INFO:root:Epoch:321 Global Model Test Loss:0.5850079655647278 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:321 Global Model Backdoor Test Loss:0.1818699911236763                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 322 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 322 Workers Selected : [1326, 1294, 1901, 842, 1146, 1613, 1805, 1032, 1278, 933]
INFO:root:FL Epoch: 322 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 322 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 322 Training on worker :1326
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544740
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.887085
INFO:root:FL Epoch: 322 Norm Difference for worker 1326 is 1.435517
INFO:root:FL Epoch: 322 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1294
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336947
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548055
INFO:root:FL Epoch: 322 Norm Difference for worker 1294 is 1.424866
INFO:root:FL Epoch: 322 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1901
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1901 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585073
INFO:root:Worker: 1901 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288891
INFO:root:FL Epoch: 322 Norm Difference for worker 1901 is 1.256012
INFO:root:FL Epoch: 322 Done on worker:1901
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :842
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 842 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490746
INFO:root:Worker: 842 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457712
INFO:root:FL Epoch: 322 Norm Difference for worker 842 is 1.346469
INFO:root:FL Epoch: 322 Done on worker:842
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1146
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1146 Train Epoch: 0 [0/200 (0%)]	Loss: 0.763924
INFO:root:Worker: 1146 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469021
INFO:root:FL Epoch: 322 Norm Difference for worker 1146 is 1.435037
INFO:root:FL Epoch: 322 Done on worker:1146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1613
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.248188
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405858
INFO:root:FL Epoch: 322 Norm Difference for worker 1613 is 1.314478
INFO:root:FL Epoch: 322 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1805
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471697
INFO:root:Worker: 1805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367013
INFO:root:FL Epoch: 322 Norm Difference for worker 1805 is 1.403401
INFO:root:FL Epoch: 322 Done on worker:1805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1032
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1032 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447502
INFO:root:Worker: 1032 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522996
INFO:root:FL Epoch: 322 Norm Difference for worker 1032 is 1.267117
INFO:root:FL Epoch: 322 Done on worker:1032
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :1278
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 1278 Train Epoch: 0 [0/200 (0%)]	Loss: 0.316829
INFO:root:Worker: 1278 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460287
INFO:root:FL Epoch: 322 Norm Difference for worker 1278 is 1.42594
INFO:root:FL Epoch: 322 Done on worker:1278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 322 Training on worker :933
INFO:root:FL Epoch: 322 Using Learning rate : 0.026295035264268664 
INFO:root:FL Epoch: 322 Normal Training
INFO:root:Worker: 933 Train Epoch: 0 [0/200 (0%)]	Loss: 0.273940
INFO:root:Worker: 933 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614880
INFO:root:FL Epoch: 322 Norm Difference for worker 933 is 1.351141
INFO:root:FL Epoch: 322 Done on worker:933
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1901
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 322 Ends   ===================
INFO:root:Epoch:322 Global Model Test Loss:0.5292080903754515 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:322 Global Model Backdoor Test Loss:0.21348625918229422                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 323 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 323 Workers Selected : [1775, 759, 1390, 1240, 1853, 37, 562, 1659, 960, 332]
INFO:root:FL Epoch: 323 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 323 Num points on workers: [200 200 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 323 Training on worker :1775
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.775485
INFO:root:Worker: 1775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400964
INFO:root:FL Epoch: 323 Norm Difference for worker 1775 is 1.03505
INFO:root:FL Epoch: 323 Done on worker:1775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :759
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 759 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337921
INFO:root:Worker: 759 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465000
INFO:root:FL Epoch: 323 Norm Difference for worker 759 is 1.110616
INFO:root:FL Epoch: 323 Done on worker:759
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1390
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.609336
INFO:root:Worker: 1390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.696975
INFO:root:FL Epoch: 323 Norm Difference for worker 1390 is 1.149267
INFO:root:FL Epoch: 323 Done on worker:1390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1240
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1240 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558143
INFO:root:Worker: 1240 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552913
INFO:root:FL Epoch: 323 Norm Difference for worker 1240 is 1.108253
INFO:root:FL Epoch: 323 Done on worker:1240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1853
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.935387
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349791
INFO:root:FL Epoch: 323 Norm Difference for worker 1853 is 1.185028
INFO:root:FL Epoch: 323 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :37
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 37 Train Epoch: 0 [0/201 (0%)]	Loss: 0.783661
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 37 Train Epoch: 1 [0/201 (0%)]	Loss: 0.627363
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 323 Norm Difference for worker 37 is 1.062344
INFO:root:FL Epoch: 323 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :562
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446401
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418873
INFO:root:FL Epoch: 323 Norm Difference for worker 562 is 1.177589
INFO:root:FL Epoch: 323 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :1659
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 1659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440978
INFO:root:Worker: 1659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561836
INFO:root:FL Epoch: 323 Norm Difference for worker 1659 is 1.087993
INFO:root:FL Epoch: 323 Done on worker:1659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :960
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 960 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581221
INFO:root:Worker: 960 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542014
INFO:root:FL Epoch: 323 Norm Difference for worker 960 is 1.078794
INFO:root:FL Epoch: 323 Done on worker:960
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 323 Training on worker :332
INFO:root:FL Epoch: 323 Using Learning rate : 0.026242445193740124 
INFO:root:FL Epoch: 323 Normal Training
INFO:root:Worker: 332 Train Epoch: 0 [0/201 (0%)]	Loss: 0.806578
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 332 Train Epoch: 1 [0/201 (0%)]	Loss: 0.808963
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 323 Norm Difference for worker 332 is 1.052191
INFO:root:FL Epoch: 323 Done on worker:332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 37
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 323 Ends   ===================
INFO:root:Epoch:323 Global Model Test Loss:0.5287289549322689 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:323 Global Model Backdoor Test Loss:0.38320624083280563                             and Backdoor Test Accuracy:80.0 
INFO:root:=======================================================
INFO:root:================FL round 324 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 324 Workers Selected : [1697, 720, 523, 692, 1330, 1142, 1537, 1698, 1461, 874]
INFO:root:FL Epoch: 324 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 324 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 324 Training on worker :1697
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478047
INFO:root:Worker: 1697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571027
INFO:root:FL Epoch: 324 Norm Difference for worker 1697 is 0.996108
INFO:root:FL Epoch: 324 Done on worker:1697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :720
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 720 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566062
INFO:root:Worker: 720 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370153
INFO:root:FL Epoch: 324 Norm Difference for worker 720 is 0.902338
INFO:root:FL Epoch: 324 Done on worker:720
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :523
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614316
INFO:root:Worker: 523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515913
INFO:root:FL Epoch: 324 Norm Difference for worker 523 is 0.970289
INFO:root:FL Epoch: 324 Done on worker:523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :692
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476996
INFO:root:Worker: 692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532052
INFO:root:FL Epoch: 324 Norm Difference for worker 692 is 0.943333
INFO:root:FL Epoch: 324 Done on worker:692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1330
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1330 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670317
INFO:root:Worker: 1330 Train Epoch: 1 [0/200 (0%)]	Loss: 0.728472
INFO:root:FL Epoch: 324 Norm Difference for worker 1330 is 1.005038
INFO:root:FL Epoch: 324 Done on worker:1330
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1142
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.265915
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484076
INFO:root:FL Epoch: 324 Norm Difference for worker 1142 is 0.899597
INFO:root:FL Epoch: 324 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1537
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628640
INFO:root:Worker: 1537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621609
INFO:root:FL Epoch: 324 Norm Difference for worker 1537 is 1.017672
INFO:root:FL Epoch: 324 Done on worker:1537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1698
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757965
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565695
INFO:root:FL Epoch: 324 Norm Difference for worker 1698 is 0.959118
INFO:root:FL Epoch: 324 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :1461
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 1461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354596
INFO:root:Worker: 1461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579419
INFO:root:FL Epoch: 324 Norm Difference for worker 1461 is 0.912889
INFO:root:FL Epoch: 324 Done on worker:1461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 324 Training on worker :874
INFO:root:FL Epoch: 324 Using Learning rate : 0.026189960303352647 
INFO:root:FL Epoch: 324 Normal Training
INFO:root:Worker: 874 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500626
INFO:root:Worker: 874 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414093
INFO:root:FL Epoch: 324 Norm Difference for worker 874 is 0.936337
INFO:root:FL Epoch: 324 Done on worker:874
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 720
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 324 Ends   ===================
INFO:root:Epoch:324 Global Model Test Loss:0.5093740400146035 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:324 Global Model Backdoor Test Loss:0.3230552052458127                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 325 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 325 Workers Selected : [941, 1930, 414, 346, 1787, 241, 601, 1620, 387, 1357]
INFO:root:FL Epoch: 325 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 325 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 325 Training on worker :941
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.296083
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196923
INFO:root:FL Epoch: 325 Norm Difference for worker 941 is 0.702231
INFO:root:FL Epoch: 325 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1930
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771955
INFO:root:Worker: 1930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562641
INFO:root:FL Epoch: 325 Norm Difference for worker 1930 is 0.950656
INFO:root:FL Epoch: 325 Done on worker:1930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :414
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667015
INFO:root:Worker: 414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368670
INFO:root:FL Epoch: 325 Norm Difference for worker 414 is 0.869611
INFO:root:FL Epoch: 325 Done on worker:414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :346
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481579
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337085
INFO:root:FL Epoch: 325 Norm Difference for worker 346 is 0.946561
INFO:root:FL Epoch: 325 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1787
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1787 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345936
INFO:root:Worker: 1787 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430362
INFO:root:FL Epoch: 325 Norm Difference for worker 1787 is 0.843775
INFO:root:FL Epoch: 325 Done on worker:1787
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :241
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 241 Train Epoch: 0 [0/201 (0%)]	Loss: 0.599151
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 241 Train Epoch: 1 [0/201 (0%)]	Loss: 0.447191
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 325 Norm Difference for worker 241 is 0.937654
INFO:root:FL Epoch: 325 Done on worker:241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :601
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538767
INFO:root:Worker: 601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340846
INFO:root:FL Epoch: 325 Norm Difference for worker 601 is 0.888094
INFO:root:FL Epoch: 325 Done on worker:601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1620
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.638542
INFO:root:Worker: 1620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457089
INFO:root:FL Epoch: 325 Norm Difference for worker 1620 is 0.923178
INFO:root:FL Epoch: 325 Done on worker:1620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :387
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 387 Train Epoch: 0 [0/200 (0%)]	Loss: 0.821507
INFO:root:Worker: 387 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464971
INFO:root:FL Epoch: 325 Norm Difference for worker 387 is 0.915478
INFO:root:FL Epoch: 325 Done on worker:387
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 325 Training on worker :1357
INFO:root:FL Epoch: 325 Using Learning rate : 0.02613758038274594 
INFO:root:FL Epoch: 325 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600460
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584348
INFO:root:FL Epoch: 325 Norm Difference for worker 1357 is 0.899904
INFO:root:FL Epoch: 325 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 941
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 325 Ends   ===================
INFO:root:Epoch:325 Global Model Test Loss:0.5270365985000834 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:325 Global Model Backdoor Test Loss:0.22090371325612068                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 326 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 326 Workers Selected : [722, 1203, 83, 1024, 1092, 1766, 813, 408, 427, 1604]
INFO:root:FL Epoch: 326 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 326 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 326 Training on worker :722
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570706
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307743
INFO:root:FL Epoch: 326 Norm Difference for worker 722 is 1.1546
INFO:root:FL Epoch: 326 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1203
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1203 Train Epoch: 0 [0/200 (0%)]	Loss: 1.123001
INFO:root:Worker: 1203 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513371
INFO:root:FL Epoch: 326 Norm Difference for worker 1203 is 1.309699
INFO:root:FL Epoch: 326 Done on worker:1203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :83
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 83 Train Epoch: 0 [0/201 (0%)]	Loss: 0.701651
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 83 Train Epoch: 1 [0/201 (0%)]	Loss: 0.643137
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 326 Norm Difference for worker 83 is 1.268307
INFO:root:FL Epoch: 326 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1024
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1024 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315707
INFO:root:Worker: 1024 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422574
INFO:root:FL Epoch: 326 Norm Difference for worker 1024 is 1.065644
INFO:root:FL Epoch: 326 Done on worker:1024
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1092
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.769845
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554285
INFO:root:FL Epoch: 326 Norm Difference for worker 1092 is 1.214687
INFO:root:FL Epoch: 326 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1766
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766390
INFO:root:Worker: 1766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478663
INFO:root:FL Epoch: 326 Norm Difference for worker 1766 is 1.242826
INFO:root:FL Epoch: 326 Done on worker:1766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :813
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545053
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444954
INFO:root:FL Epoch: 326 Norm Difference for worker 813 is 1.149118
INFO:root:FL Epoch: 326 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :408
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377506
INFO:root:Worker: 408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320907
INFO:root:FL Epoch: 326 Norm Difference for worker 408 is 1.0862
INFO:root:FL Epoch: 326 Done on worker:408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :427
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.291533
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513120
INFO:root:FL Epoch: 326 Norm Difference for worker 427 is 1.067909
INFO:root:FL Epoch: 326 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 326 Training on worker :1604
INFO:root:FL Epoch: 326 Using Learning rate : 0.02608530522198045 
INFO:root:FL Epoch: 326 Normal Training
INFO:root:Worker: 1604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549016
INFO:root:Worker: 1604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632963
INFO:root:FL Epoch: 326 Norm Difference for worker 1604 is 1.13922
INFO:root:FL Epoch: 326 Done on worker:1604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1024
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 326 Ends   ===================
INFO:root:Epoch:326 Global Model Test Loss:0.5203943007132587 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:326 Global Model Backdoor Test Loss:0.25102249532938004                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 327 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 327 Workers Selected : [1818, 1141, 520, 1844, 1272, 386, 1731, 1616, 813, 1415]
INFO:root:FL Epoch: 327 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 327 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 327 Training on worker :1818
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662902
INFO:root:Worker: 1818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.879267
INFO:root:FL Epoch: 327 Norm Difference for worker 1818 is 1.004579
INFO:root:FL Epoch: 327 Done on worker:1818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1141
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1141 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518124
INFO:root:Worker: 1141 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315043
INFO:root:FL Epoch: 327 Norm Difference for worker 1141 is 0.983945
INFO:root:FL Epoch: 327 Done on worker:1141
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :520
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.416490
INFO:root:Worker: 520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.732443
INFO:root:FL Epoch: 327 Norm Difference for worker 520 is 0.982971
INFO:root:FL Epoch: 327 Done on worker:520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1844
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508274
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423382
INFO:root:FL Epoch: 327 Norm Difference for worker 1844 is 0.949393
INFO:root:FL Epoch: 327 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1272
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1272 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636564
INFO:root:Worker: 1272 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558236
INFO:root:FL Epoch: 327 Norm Difference for worker 1272 is 1.053299
INFO:root:FL Epoch: 327 Done on worker:1272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :386
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589981
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656026
INFO:root:FL Epoch: 327 Norm Difference for worker 386 is 0.985052
INFO:root:FL Epoch: 327 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1731
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.279107
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307775
INFO:root:FL Epoch: 327 Norm Difference for worker 1731 is 0.85667
INFO:root:FL Epoch: 327 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1616
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519326
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518513
INFO:root:FL Epoch: 327 Norm Difference for worker 1616 is 0.998696
INFO:root:FL Epoch: 327 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :813
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 813 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409040
INFO:root:Worker: 813 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251828
INFO:root:FL Epoch: 327 Norm Difference for worker 813 is 0.933936
INFO:root:FL Epoch: 327 Done on worker:813
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 327 Training on worker :1415
INFO:root:FL Epoch: 327 Using Learning rate : 0.026033134611536488 
INFO:root:FL Epoch: 327 Normal Training
INFO:root:Worker: 1415 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670614
INFO:root:Worker: 1415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603828
INFO:root:FL Epoch: 327 Norm Difference for worker 1415 is 1.02463
INFO:root:FL Epoch: 327 Done on worker:1415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1731
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 327 Ends   ===================
INFO:root:Epoch:327 Global Model Test Loss:0.545419387957629 and Test Accuracy:73.23529411764706 
INFO:root:Epoch:327 Global Model Backdoor Test Loss:0.27464430903395015                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 328 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 328 Workers Selected : [169, 1079, 1061, 809, 926, 790, 1222, 667, 1097, 1487]
INFO:root:FL Epoch: 328 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 328 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 328 Training on worker :169
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.418866
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.443035
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 328 Norm Difference for worker 169 is 1.215438
INFO:root:FL Epoch: 328 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1079
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1079 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509802
INFO:root:Worker: 1079 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484749
INFO:root:FL Epoch: 328 Norm Difference for worker 1079 is 1.098591
INFO:root:FL Epoch: 328 Done on worker:1079
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1061
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1061 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607320
INFO:root:Worker: 1061 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554247
INFO:root:FL Epoch: 328 Norm Difference for worker 1061 is 1.121147
INFO:root:FL Epoch: 328 Done on worker:1061
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :809
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 809 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617305
INFO:root:Worker: 809 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315856
INFO:root:FL Epoch: 328 Norm Difference for worker 809 is 1.058012
INFO:root:FL Epoch: 328 Done on worker:809
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :926
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343453
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335756
INFO:root:FL Epoch: 328 Norm Difference for worker 926 is 0.988534
INFO:root:FL Epoch: 328 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :790
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.729164
INFO:root:Worker: 790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320484
INFO:root:FL Epoch: 328 Norm Difference for worker 790 is 1.151224
INFO:root:FL Epoch: 328 Done on worker:790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1222
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1222 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351427
INFO:root:Worker: 1222 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443009
INFO:root:FL Epoch: 328 Norm Difference for worker 1222 is 1.195929
INFO:root:FL Epoch: 328 Done on worker:1222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :667
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384116
INFO:root:Worker: 667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524907
INFO:root:FL Epoch: 328 Norm Difference for worker 667 is 1.010923
INFO:root:FL Epoch: 328 Done on worker:667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1097
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1097 Train Epoch: 0 [0/200 (0%)]	Loss: 0.868733
INFO:root:Worker: 1097 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605276
INFO:root:FL Epoch: 328 Norm Difference for worker 1097 is 1.199434
INFO:root:FL Epoch: 328 Done on worker:1097
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 328 Training on worker :1487
INFO:root:FL Epoch: 328 Using Learning rate : 0.025981068342313413 
INFO:root:FL Epoch: 328 Normal Training
INFO:root:Worker: 1487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418831
INFO:root:Worker: 1487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356295
INFO:root:FL Epoch: 328 Norm Difference for worker 1487 is 1.260746
INFO:root:FL Epoch: 328 Done on worker:1487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 667
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 328 Ends   ===================
INFO:root:Epoch:328 Global Model Test Loss:0.5312930888989392 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:328 Global Model Backdoor Test Loss:0.21109755709767342                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 329 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 329 Workers Selected : [213, 1424, 1749, 1383, 1652, 475, 566, 866, 756, 257]
INFO:root:FL Epoch: 329 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 329 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 329 Training on worker :213
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.736483
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.242281
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 329 Norm Difference for worker 213 is 1.147991
INFO:root:FL Epoch: 329 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1424
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709441
INFO:root:Worker: 1424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401330
INFO:root:FL Epoch: 329 Norm Difference for worker 1424 is 1.182626
INFO:root:FL Epoch: 329 Done on worker:1424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1749
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1749 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621936
INFO:root:Worker: 1749 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351174
INFO:root:FL Epoch: 329 Norm Difference for worker 1749 is 1.038259
INFO:root:FL Epoch: 329 Done on worker:1749
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1383
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1383 Train Epoch: 0 [0/200 (0%)]	Loss: 0.241677
INFO:root:Worker: 1383 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395036
INFO:root:FL Epoch: 329 Norm Difference for worker 1383 is 1.043883
INFO:root:FL Epoch: 329 Done on worker:1383
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :1652
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588551
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460057
INFO:root:FL Epoch: 329 Norm Difference for worker 1652 is 1.134771
INFO:root:FL Epoch: 329 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :475
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645992
INFO:root:Worker: 475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420670
INFO:root:FL Epoch: 329 Norm Difference for worker 475 is 1.16111
INFO:root:FL Epoch: 329 Done on worker:475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :566
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 566 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452104
INFO:root:Worker: 566 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656309
INFO:root:FL Epoch: 329 Norm Difference for worker 566 is 1.095886
INFO:root:FL Epoch: 329 Done on worker:566
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :866
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580211
INFO:root:Worker: 866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637130
INFO:root:FL Epoch: 329 Norm Difference for worker 866 is 1.167763
INFO:root:FL Epoch: 329 Done on worker:866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :756
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.620566
INFO:root:Worker: 756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.756073
INFO:root:FL Epoch: 329 Norm Difference for worker 756 is 1.151131
INFO:root:FL Epoch: 329 Done on worker:756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 329 Training on worker :257
INFO:root:FL Epoch: 329 Using Learning rate : 0.025929106205628785 
INFO:root:FL Epoch: 329 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.751540
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.522700
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 329 Norm Difference for worker 257 is 1.276693
INFO:root:FL Epoch: 329 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1383
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 329 Ends   ===================
INFO:root:Epoch:329 Global Model Test Loss:0.5139939048710991 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:329 Global Model Backdoor Test Loss:0.300338014960289                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 330 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 330 Workers Selected : [633, 742, 983, 1756, 877, 64, 1684, 992, 265, 1663]
INFO:root:FL Epoch: 330 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 330 Num points on workers: [200 200 200 200 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 330 Training on worker :633
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.260864
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386899
INFO:root:FL Epoch: 330 Norm Difference for worker 633 is 0.93301
INFO:root:FL Epoch: 330 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :742
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 742 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452706
INFO:root:Worker: 742 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384931
INFO:root:FL Epoch: 330 Norm Difference for worker 742 is 0.959978
INFO:root:FL Epoch: 330 Done on worker:742
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :983
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437674
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485306
INFO:root:FL Epoch: 330 Norm Difference for worker 983 is 1.0635
INFO:root:FL Epoch: 330 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1756
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1756 Train Epoch: 0 [0/200 (0%)]	Loss: 0.349550
INFO:root:Worker: 1756 Train Epoch: 1 [0/200 (0%)]	Loss: 0.347378
INFO:root:FL Epoch: 330 Norm Difference for worker 1756 is 0.964935
INFO:root:FL Epoch: 330 Done on worker:1756
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :877
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473273
INFO:root:Worker: 877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392070
INFO:root:FL Epoch: 330 Norm Difference for worker 877 is 0.99323
INFO:root:FL Epoch: 330 Done on worker:877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :64
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 64 Train Epoch: 0 [0/201 (0%)]	Loss: 0.798216
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 64 Train Epoch: 1 [0/201 (0%)]	Loss: 0.379452
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 64 is 0.933338
INFO:root:FL Epoch: 330 Done on worker:64
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1684
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637306
INFO:root:Worker: 1684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644566
INFO:root:FL Epoch: 330 Norm Difference for worker 1684 is 1.009684
INFO:root:FL Epoch: 330 Done on worker:1684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :992
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 992 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474406
INFO:root:Worker: 992 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404263
INFO:root:FL Epoch: 330 Norm Difference for worker 992 is 0.963221
INFO:root:FL Epoch: 330 Done on worker:992
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :265
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 265 Train Epoch: 0 [0/201 (0%)]	Loss: 0.658493
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 265 Train Epoch: 1 [0/201 (0%)]	Loss: 0.603406
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 330 Norm Difference for worker 265 is 1.04459
INFO:root:FL Epoch: 330 Done on worker:265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 330 Training on worker :1663
INFO:root:FL Epoch: 330 Using Learning rate : 0.025877247993217528 
INFO:root:FL Epoch: 330 Normal Training
INFO:root:Worker: 1663 Train Epoch: 0 [0/200 (0%)]	Loss: 0.318107
INFO:root:Worker: 1663 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330866
INFO:root:FL Epoch: 330 Norm Difference for worker 1663 is 0.90105
INFO:root:FL Epoch: 330 Done on worker:1663
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1663
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 330 Ends   ===================
INFO:root:Epoch:330 Global Model Test Loss:0.5274868554928723 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:330 Global Model Backdoor Test Loss:0.2337944321334362                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 331 Begins ===================
INFO:root:FL Epoch: 331 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 331 Workers Selected : [0, 625, 1217, 608, 1174, 1869, 217, 838, 894, 927]
INFO:root:FL Epoch: 331 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 331 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 331 Training on worker :0
INFO:root:FL Epoch: 331 Using Learning rate : 0.005165098699446219 
INFO:root:FL Epoch: 331 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.241737
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.230441
INFO:root:FL Epoch: 331 Worker: 0 Backdoor Test Loss: 0.22293663521607718 Backdoor Test Accuracy: 91.66666666666667
INFO:root:FL Epoch: 331 Worker: 0 Backdoor Train Loss: 0.17114998176693916 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 331 Norm Difference for worker 0 is 0.178061
INFO:root:FL Epoch: 331 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :625
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 625 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490148
INFO:root:Worker: 625 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285171
INFO:root:FL Epoch: 331 Norm Difference for worker 625 is 1.009356
INFO:root:FL Epoch: 331 Done on worker:625
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :1217
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.323877
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618374
INFO:root:FL Epoch: 331 Norm Difference for worker 1217 is 1.083374
INFO:root:FL Epoch: 331 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :608
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734099
INFO:root:Worker: 608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525157
INFO:root:FL Epoch: 331 Norm Difference for worker 608 is 1.042357
INFO:root:FL Epoch: 331 Done on worker:608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :1174
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587076
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496094
INFO:root:FL Epoch: 331 Norm Difference for worker 1174 is 1.11662
INFO:root:FL Epoch: 331 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :1869
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523040
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484545
INFO:root:FL Epoch: 331 Norm Difference for worker 1869 is 1.061311
INFO:root:FL Epoch: 331 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :217
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 217 Train Epoch: 0 [0/201 (0%)]	Loss: 0.666683
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 217 Train Epoch: 1 [0/201 (0%)]	Loss: 0.598771
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 331 Norm Difference for worker 217 is 1.040857
INFO:root:FL Epoch: 331 Done on worker:217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :838
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662814
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419631
INFO:root:FL Epoch: 331 Norm Difference for worker 838 is 1.17901
INFO:root:FL Epoch: 331 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :894
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 894 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433592
INFO:root:Worker: 894 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431396
INFO:root:FL Epoch: 331 Norm Difference for worker 894 is 1.068447
INFO:root:FL Epoch: 331 Done on worker:894
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 331 Training on worker :927
INFO:root:FL Epoch: 331 Using Learning rate : 0.025825493497231095 
INFO:root:FL Epoch: 331 Normal Training
INFO:root:Worker: 927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.274944
INFO:root:Worker: 927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393972
INFO:root:FL Epoch: 331 Norm Difference for worker 927 is 0.854225
INFO:root:FL Epoch: 331 Done on worker:927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 331 Ends   ===================
INFO:root:Epoch:331 Global Model Test Loss:0.5367248636834762 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:331 Global Model Backdoor Test Loss:0.22293663521607718                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 332 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 332 Workers Selected : [1081, 372, 412, 396, 1269, 1299, 1452, 257, 224, 481]
INFO:root:FL Epoch: 332 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.1003996 0.0999001]
INFO:root:FL Epoch: 332 Num points on workers: [200 200 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 332 Training on worker :1081
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 1.020918
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562837
INFO:root:FL Epoch: 332 Norm Difference for worker 1081 is 1.252476
INFO:root:FL Epoch: 332 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :372
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 372 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382787
INFO:root:Worker: 372 Train Epoch: 1 [0/200 (0%)]	Loss: 0.464292
INFO:root:FL Epoch: 332 Norm Difference for worker 372 is 1.084018
INFO:root:FL Epoch: 332 Done on worker:372
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :412
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 412 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764697
INFO:root:Worker: 412 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358806
INFO:root:FL Epoch: 332 Norm Difference for worker 412 is 1.104819
INFO:root:FL Epoch: 332 Done on worker:412
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :396
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372414
INFO:root:Worker: 396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586116
INFO:root:FL Epoch: 332 Norm Difference for worker 396 is 1.070871
INFO:root:FL Epoch: 332 Done on worker:396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1269
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1269 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577505
INFO:root:Worker: 1269 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397562
INFO:root:FL Epoch: 332 Norm Difference for worker 1269 is 1.096458
INFO:root:FL Epoch: 332 Done on worker:1269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1299
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1299 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576071
INFO:root:Worker: 1299 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491001
INFO:root:FL Epoch: 332 Norm Difference for worker 1299 is 1.082067
INFO:root:FL Epoch: 332 Done on worker:1299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :1452
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 1452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.790383
INFO:root:Worker: 1452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399843
INFO:root:FL Epoch: 332 Norm Difference for worker 1452 is 1.101081
INFO:root:FL Epoch: 332 Done on worker:1452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :257
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.726267
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.174125
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 332 Norm Difference for worker 257 is 1.159716
INFO:root:FL Epoch: 332 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :224
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 224 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503224
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 224 Train Epoch: 1 [0/201 (0%)]	Loss: 0.548237
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 332 Norm Difference for worker 224 is 1.090521
INFO:root:FL Epoch: 332 Done on worker:224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 332 Training on worker :481
INFO:root:FL Epoch: 332 Using Learning rate : 0.02577384251023663 
INFO:root:FL Epoch: 332 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594299
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255776
INFO:root:FL Epoch: 332 Norm Difference for worker 481 is 1.215306
INFO:root:FL Epoch: 332 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 224
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 332 Ends   ===================
INFO:root:Epoch:332 Global Model Test Loss:0.5254427790641785 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:332 Global Model Backdoor Test Loss:0.2931946540872256                             and Backdoor Test Accuracy:86.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 333 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 333 Workers Selected : [1613, 1671, 364, 1527, 203, 743, 1945, 1672, 463, 17]
INFO:root:FL Epoch: 333 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 333 Num points on workers: [200 200 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 333 Training on worker :1613
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527005
INFO:root:Worker: 1613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506162
INFO:root:FL Epoch: 333 Norm Difference for worker 1613 is 0.983684
INFO:root:FL Epoch: 333 Done on worker:1613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1671
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.825791
INFO:root:Worker: 1671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457935
INFO:root:FL Epoch: 333 Norm Difference for worker 1671 is 0.922354
INFO:root:FL Epoch: 333 Done on worker:1671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :364
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467166
INFO:root:Worker: 364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337983
INFO:root:FL Epoch: 333 Norm Difference for worker 364 is 0.964946
INFO:root:FL Epoch: 333 Done on worker:364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1527
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.208563
INFO:root:Worker: 1527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521773
INFO:root:FL Epoch: 333 Norm Difference for worker 1527 is 0.945875
INFO:root:FL Epoch: 333 Done on worker:1527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :203
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.591459
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.557230
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 333 Norm Difference for worker 203 is 0.970688
INFO:root:FL Epoch: 333 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :743
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526235
INFO:root:Worker: 743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565885
INFO:root:FL Epoch: 333 Norm Difference for worker 743 is 0.933351
INFO:root:FL Epoch: 333 Done on worker:743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1945
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338428
INFO:root:Worker: 1945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327492
INFO:root:FL Epoch: 333 Norm Difference for worker 1945 is 0.897659
INFO:root:FL Epoch: 333 Done on worker:1945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :1672
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 1672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415322
INFO:root:Worker: 1672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434839
INFO:root:FL Epoch: 333 Norm Difference for worker 1672 is 0.904761
INFO:root:FL Epoch: 333 Done on worker:1672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :463
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398143
INFO:root:Worker: 463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523708
INFO:root:FL Epoch: 333 Norm Difference for worker 463 is 0.968115
INFO:root:FL Epoch: 333 Done on worker:463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 333 Training on worker :17
INFO:root:FL Epoch: 333 Using Learning rate : 0.02572229482521616 
INFO:root:FL Epoch: 333 Normal Training
INFO:root:Worker: 17 Train Epoch: 0 [0/201 (0%)]	Loss: 0.740160
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 17 Train Epoch: 1 [0/201 (0%)]	Loss: 0.664967
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 333 Norm Difference for worker 17 is 1.059011
INFO:root:FL Epoch: 333 Done on worker:17
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1945
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 333 Ends   ===================
INFO:root:Epoch:333 Global Model Test Loss:0.5149374884717605 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:333 Global Model Backdoor Test Loss:0.21584554761648178                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 334 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 334 Workers Selected : [1294, 1807, 327, 1440, 144, 568, 1478, 916, 1157, 89]
INFO:root:FL Epoch: 334 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 334 Num points on workers: [200 200 201 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 334 Training on worker :1294
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1294 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648539
INFO:root:Worker: 1294 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515514
INFO:root:FL Epoch: 334 Norm Difference for worker 1294 is 1.052255
INFO:root:FL Epoch: 334 Done on worker:1294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1807
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579965
INFO:root:Worker: 1807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358805
INFO:root:FL Epoch: 334 Norm Difference for worker 1807 is 0.986411
INFO:root:FL Epoch: 334 Done on worker:1807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :327
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.721504
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.636259
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 327 is 1.026411
INFO:root:FL Epoch: 334 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1440
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455899
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506436
INFO:root:FL Epoch: 334 Norm Difference for worker 1440 is 1.083958
INFO:root:FL Epoch: 334 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :144
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.828554
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.562310
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 144 is 1.060946
INFO:root:FL Epoch: 334 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :568
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 568 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437741
INFO:root:Worker: 568 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473244
INFO:root:FL Epoch: 334 Norm Difference for worker 568 is 1.01908
INFO:root:FL Epoch: 334 Done on worker:568
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1478
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552333
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332373
INFO:root:FL Epoch: 334 Norm Difference for worker 1478 is 0.850503
INFO:root:FL Epoch: 334 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :916
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441386
INFO:root:Worker: 916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404592
INFO:root:FL Epoch: 334 Norm Difference for worker 916 is 1.053789
INFO:root:FL Epoch: 334 Done on worker:916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :1157
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 1157 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534341
INFO:root:Worker: 1157 Train Epoch: 1 [0/200 (0%)]	Loss: 0.717295
INFO:root:FL Epoch: 334 Norm Difference for worker 1157 is 1.037175
INFO:root:FL Epoch: 334 Done on worker:1157
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 334 Training on worker :89
INFO:root:FL Epoch: 334 Using Learning rate : 0.025670850235565725 
INFO:root:FL Epoch: 334 Normal Training
INFO:root:Worker: 89 Train Epoch: 0 [0/201 (0%)]	Loss: 0.263311
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 89 Train Epoch: 1 [0/201 (0%)]	Loss: 0.247238
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 334 Norm Difference for worker 89 is 0.972802
INFO:root:FL Epoch: 334 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1478
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 334 Ends   ===================
INFO:root:Epoch:334 Global Model Test Loss:0.5345072246649686 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:334 Global Model Backdoor Test Loss:0.2304573431611061                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 335 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 335 Workers Selected : [554, 1180, 1075, 704, 24, 1380, 481, 1545, 117, 457]
INFO:root:FL Epoch: 335 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 335 Num points on workers: [200 200 200 200 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 335 Training on worker :554
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377824
INFO:root:Worker: 554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366556
INFO:root:FL Epoch: 335 Norm Difference for worker 554 is 1.089684
INFO:root:FL Epoch: 335 Done on worker:554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :1180
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1180 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677463
INFO:root:Worker: 1180 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521048
INFO:root:FL Epoch: 335 Norm Difference for worker 1180 is 1.145731
INFO:root:FL Epoch: 335 Done on worker:1180
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :1075
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707187
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294633
INFO:root:FL Epoch: 335 Norm Difference for worker 1075 is 1.114799
INFO:root:FL Epoch: 335 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :704
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491319
INFO:root:Worker: 704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390247
INFO:root:FL Epoch: 335 Norm Difference for worker 704 is 1.080293
INFO:root:FL Epoch: 335 Done on worker:704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :24
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 24 Train Epoch: 0 [0/201 (0%)]	Loss: 0.725503
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 24 Train Epoch: 1 [0/201 (0%)]	Loss: 0.280475
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 24 is 1.134009
INFO:root:FL Epoch: 335 Done on worker:24
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :1380
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738494
INFO:root:Worker: 1380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450698
INFO:root:FL Epoch: 335 Norm Difference for worker 1380 is 1.088995
INFO:root:FL Epoch: 335 Done on worker:1380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :481
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472074
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430441
INFO:root:FL Epoch: 335 Norm Difference for worker 481 is 1.210258
INFO:root:FL Epoch: 335 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :1545
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 1545 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530758
INFO:root:Worker: 1545 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456065
INFO:root:FL Epoch: 335 Norm Difference for worker 1545 is 1.128558
INFO:root:FL Epoch: 335 Done on worker:1545
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :117
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.518421
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.423974
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 335 Norm Difference for worker 117 is 1.038925
INFO:root:FL Epoch: 335 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 335 Training on worker :457
INFO:root:FL Epoch: 335 Using Learning rate : 0.025619508535094593 
INFO:root:FL Epoch: 335 Normal Training
INFO:root:Worker: 457 Train Epoch: 0 [0/200 (0%)]	Loss: 0.921706
INFO:root:Worker: 457 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380699
INFO:root:FL Epoch: 335 Norm Difference for worker 457 is 1.113366
INFO:root:FL Epoch: 335 Done on worker:457
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 117
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 335 Ends   ===================
INFO:root:Epoch:335 Global Model Test Loss:0.531660200918422 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:335 Global Model Backdoor Test Loss:0.2451902280251185                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 336 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 336 Workers Selected : [119, 79, 1547, 347, 736, 735, 1907, 1480, 551, 1541]
INFO:root:FL Epoch: 336 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 336 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 336 Training on worker :119
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.580247
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.454980
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 336 Norm Difference for worker 119 is 0.965713
INFO:root:FL Epoch: 336 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :79
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 79 Train Epoch: 0 [0/201 (0%)]	Loss: 0.745306
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 79 Train Epoch: 1 [0/201 (0%)]	Loss: 0.267506
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 336 Norm Difference for worker 79 is 1.028509
INFO:root:FL Epoch: 336 Done on worker:79
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :1547
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 1547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630813
INFO:root:Worker: 1547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412798
INFO:root:FL Epoch: 336 Norm Difference for worker 1547 is 1.058758
INFO:root:FL Epoch: 336 Done on worker:1547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :347
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.528862
INFO:root:Worker: 347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506514
INFO:root:FL Epoch: 336 Norm Difference for worker 347 is 1.103474
INFO:root:FL Epoch: 336 Done on worker:347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :736
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562938
INFO:root:Worker: 736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620431
INFO:root:FL Epoch: 336 Norm Difference for worker 736 is 1.007403
INFO:root:FL Epoch: 336 Done on worker:736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :735
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 735 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802246
INFO:root:Worker: 735 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504070
INFO:root:FL Epoch: 336 Norm Difference for worker 735 is 1.084548
INFO:root:FL Epoch: 336 Done on worker:735
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :1907
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529488
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453501
INFO:root:FL Epoch: 336 Norm Difference for worker 1907 is 1.088876
INFO:root:FL Epoch: 336 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :1480
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 1480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363159
INFO:root:Worker: 1480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560770
INFO:root:FL Epoch: 336 Norm Difference for worker 1480 is 1.050674
INFO:root:FL Epoch: 336 Done on worker:1480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :551
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427419
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340368
INFO:root:FL Epoch: 336 Norm Difference for worker 551 is 0.929208
INFO:root:FL Epoch: 336 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 336 Training on worker :1541
INFO:root:FL Epoch: 336 Using Learning rate : 0.025568269518024406 
INFO:root:FL Epoch: 336 Normal Training
INFO:root:Worker: 1541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605521
INFO:root:Worker: 1541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390164
INFO:root:FL Epoch: 336 Norm Difference for worker 1541 is 1.030003
INFO:root:FL Epoch: 336 Done on worker:1541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 551
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 336 Ends   ===================
INFO:root:Epoch:336 Global Model Test Loss:0.5270328644443961 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:336 Global Model Backdoor Test Loss:0.25148674348990124                             and Backdoor Test Accuracy:89.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 337 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 337 Workers Selected : [761, 1296, 1458, 1881, 358, 1782, 82, 428, 640, 895]
INFO:root:FL Epoch: 337 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 337 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 337 Training on worker :761
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345051
INFO:root:Worker: 761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.258250
INFO:root:FL Epoch: 337 Norm Difference for worker 761 is 0.984894
INFO:root:FL Epoch: 337 Done on worker:761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1296
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1296 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572718
INFO:root:Worker: 1296 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366295
INFO:root:FL Epoch: 337 Norm Difference for worker 1296 is 0.979763
INFO:root:FL Epoch: 337 Done on worker:1296
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1458
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745373
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510528
INFO:root:FL Epoch: 337 Norm Difference for worker 1458 is 1.043783
INFO:root:FL Epoch: 337 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1881
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.307681
INFO:root:Worker: 1881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352297
INFO:root:FL Epoch: 337 Norm Difference for worker 1881 is 0.941211
INFO:root:FL Epoch: 337 Done on worker:1881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :358
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630485
INFO:root:Worker: 358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265432
INFO:root:FL Epoch: 337 Norm Difference for worker 358 is 0.940492
INFO:root:FL Epoch: 337 Done on worker:358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :1782
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 1782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494806
INFO:root:Worker: 1782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360068
INFO:root:FL Epoch: 337 Norm Difference for worker 1782 is 1.089582
INFO:root:FL Epoch: 337 Done on worker:1782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :82
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 82 Train Epoch: 0 [0/201 (0%)]	Loss: 0.562743
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 82 Train Epoch: 1 [0/201 (0%)]	Loss: 0.393910
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 337 Norm Difference for worker 82 is 0.998541
INFO:root:FL Epoch: 337 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :428
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485197
INFO:root:Worker: 428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.601541
INFO:root:FL Epoch: 337 Norm Difference for worker 428 is 1.042387
INFO:root:FL Epoch: 337 Done on worker:428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :640
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720155
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428639
INFO:root:FL Epoch: 337 Norm Difference for worker 640 is 1.00444
INFO:root:FL Epoch: 337 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 337 Training on worker :895
INFO:root:FL Epoch: 337 Using Learning rate : 0.025517132978988357 
INFO:root:FL Epoch: 337 Normal Training
INFO:root:Worker: 895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590366
INFO:root:Worker: 895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456510
INFO:root:FL Epoch: 337 Norm Difference for worker 895 is 1.078264
INFO:root:FL Epoch: 337 Done on worker:895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1881
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 337 Ends   ===================
INFO:root:Epoch:337 Global Model Test Loss:0.4984879178159377 and Test Accuracy:75.0 
INFO:root:Epoch:337 Global Model Backdoor Test Loss:0.21193510045607886                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 338 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 338 Workers Selected : [1314, 308, 1783, 1570, 1542, 121, 1931, 717, 1378, 322]
INFO:root:FL Epoch: 338 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 338 Num points on workers: [200 201 200 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 338 Training on worker :1314
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1314 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601460
INFO:root:Worker: 1314 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500027
INFO:root:FL Epoch: 338 Norm Difference for worker 1314 is 1.061176
INFO:root:FL Epoch: 338 Done on worker:1314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :308
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 308 Train Epoch: 0 [0/201 (0%)]	Loss: 0.357507
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 308 Train Epoch: 1 [0/201 (0%)]	Loss: 0.639032
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 338 Norm Difference for worker 308 is 0.903041
INFO:root:FL Epoch: 338 Done on worker:308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1783
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350774
INFO:root:Worker: 1783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381670
INFO:root:FL Epoch: 338 Norm Difference for worker 1783 is 1.00955
INFO:root:FL Epoch: 338 Done on worker:1783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1570
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1570 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464784
INFO:root:Worker: 1570 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582822
INFO:root:FL Epoch: 338 Norm Difference for worker 1570 is 0.973938
INFO:root:FL Epoch: 338 Done on worker:1570
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1542
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1542 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517024
INFO:root:Worker: 1542 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480655
INFO:root:FL Epoch: 338 Norm Difference for worker 1542 is 0.990883
INFO:root:FL Epoch: 338 Done on worker:1542
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :121
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 121 Train Epoch: 0 [0/201 (0%)]	Loss: 0.664080
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 121 Train Epoch: 1 [0/201 (0%)]	Loss: 0.582531
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 338 Norm Difference for worker 121 is 1.074099
INFO:root:FL Epoch: 338 Done on worker:121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1931
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628537
INFO:root:Worker: 1931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521753
INFO:root:FL Epoch: 338 Norm Difference for worker 1931 is 1.074153
INFO:root:FL Epoch: 338 Done on worker:1931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :717
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 717 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731672
INFO:root:Worker: 717 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563895
INFO:root:FL Epoch: 338 Norm Difference for worker 717 is 0.945601
INFO:root:FL Epoch: 338 Done on worker:717
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :1378
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 1378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.872210
INFO:root:Worker: 1378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328295
INFO:root:FL Epoch: 338 Norm Difference for worker 1378 is 0.990775
INFO:root:FL Epoch: 338 Done on worker:1378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 338 Training on worker :322
INFO:root:FL Epoch: 338 Using Learning rate : 0.025466098713030377 
INFO:root:FL Epoch: 338 Normal Training
INFO:root:Worker: 322 Train Epoch: 0 [0/201 (0%)]	Loss: 0.369052
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 322 Train Epoch: 1 [0/201 (0%)]	Loss: 0.352478
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 338 Norm Difference for worker 322 is 0.947093
INFO:root:FL Epoch: 338 Done on worker:322
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 308
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 338 Ends   ===================
INFO:root:Epoch:338 Global Model Test Loss:0.49880146279054527 and Test Accuracy:75.0 
INFO:root:Epoch:338 Global Model Backdoor Test Loss:0.3038914278149605                             and Backdoor Test Accuracy:90.0 
INFO:root:=======================================================
INFO:root:================FL round 339 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 339 Workers Selected : [303, 578, 617, 926, 272, 1458, 1703, 271, 1865, 1793]
INFO:root:FL Epoch: 339 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 339 Num points on workers: [201 200 200 200 201 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 339 Training on worker :303
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 303 Train Epoch: 0 [0/201 (0%)]	Loss: 0.583529
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 303 Train Epoch: 1 [0/201 (0%)]	Loss: 0.396464
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 339 Norm Difference for worker 303 is 0.800183
INFO:root:FL Epoch: 339 Done on worker:303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :578
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474940
INFO:root:Worker: 578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.308654
INFO:root:FL Epoch: 339 Norm Difference for worker 578 is 0.788666
INFO:root:FL Epoch: 339 Done on worker:578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :617
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 617 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563745
INFO:root:Worker: 617 Train Epoch: 1 [0/200 (0%)]	Loss: 0.395412
INFO:root:FL Epoch: 339 Norm Difference for worker 617 is 0.857195
INFO:root:FL Epoch: 339 Done on worker:617
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :926
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.381544
INFO:root:Worker: 926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475942
INFO:root:FL Epoch: 339 Norm Difference for worker 926 is 0.807395
INFO:root:FL Epoch: 339 Done on worker:926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :272
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.589151
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.590684
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 339 Norm Difference for worker 272 is 0.830354
INFO:root:FL Epoch: 339 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1458
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666528
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452082
INFO:root:FL Epoch: 339 Norm Difference for worker 1458 is 0.853039
INFO:root:FL Epoch: 339 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1703
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457412
INFO:root:Worker: 1703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509875
INFO:root:FL Epoch: 339 Norm Difference for worker 1703 is 0.846681
INFO:root:FL Epoch: 339 Done on worker:1703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :271
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 271 Train Epoch: 0 [0/201 (0%)]	Loss: 0.445350
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 271 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505947
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 339 Norm Difference for worker 271 is 0.847397
INFO:root:FL Epoch: 339 Done on worker:271
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1865
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571316
INFO:root:Worker: 1865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.800720
INFO:root:FL Epoch: 339 Norm Difference for worker 1865 is 0.860617
INFO:root:FL Epoch: 339 Done on worker:1865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 339 Training on worker :1793
INFO:root:FL Epoch: 339 Using Learning rate : 0.025415166515604316 
INFO:root:FL Epoch: 339 Normal Training
INFO:root:Worker: 1793 Train Epoch: 0 [0/200 (0%)]	Loss: 0.591382
INFO:root:Worker: 1793 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523460
INFO:root:FL Epoch: 339 Norm Difference for worker 1793 is 0.871511
INFO:root:FL Epoch: 339 Done on worker:1793
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 578
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 339 Ends   ===================
INFO:root:Epoch:339 Global Model Test Loss:0.5103231054895064 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:339 Global Model Backdoor Test Loss:0.2730076536536217                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 340 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 340 Workers Selected : [31, 654, 62, 505, 1214, 914, 1563, 766, 839, 904]
INFO:root:FL Epoch: 340 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 340 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 340 Training on worker :31
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 31 Train Epoch: 0 [0/201 (0%)]	Loss: 0.674095
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 31 Train Epoch: 1 [0/201 (0%)]	Loss: 0.420411
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 31 is 0.922396
INFO:root:FL Epoch: 340 Done on worker:31
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :654
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738651
INFO:root:Worker: 654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587145
INFO:root:FL Epoch: 340 Norm Difference for worker 654 is 0.940124
INFO:root:FL Epoch: 340 Done on worker:654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :62
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.452899
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.476626
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 340 Norm Difference for worker 62 is 0.965771
INFO:root:FL Epoch: 340 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :505
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408938
INFO:root:Worker: 505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.743092
INFO:root:FL Epoch: 340 Norm Difference for worker 505 is 0.937859
INFO:root:FL Epoch: 340 Done on worker:505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1214
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1214 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644003
INFO:root:Worker: 1214 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497314
INFO:root:FL Epoch: 340 Norm Difference for worker 1214 is 0.903788
INFO:root:FL Epoch: 340 Done on worker:1214
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :914
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613297
INFO:root:Worker: 914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637276
INFO:root:FL Epoch: 340 Norm Difference for worker 914 is 1.000076
INFO:root:FL Epoch: 340 Done on worker:914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :1563
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 1563 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475395
INFO:root:Worker: 1563 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356920
INFO:root:FL Epoch: 340 Norm Difference for worker 1563 is 1.064533
INFO:root:FL Epoch: 340 Done on worker:1563
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :766
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577277
INFO:root:Worker: 766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427461
INFO:root:FL Epoch: 340 Norm Difference for worker 766 is 0.871292
INFO:root:FL Epoch: 340 Done on worker:766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :839
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.710406
INFO:root:Worker: 839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597140
INFO:root:FL Epoch: 340 Norm Difference for worker 839 is 0.956356
INFO:root:FL Epoch: 340 Done on worker:839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 340 Training on worker :904
INFO:root:FL Epoch: 340 Using Learning rate : 0.02536433618257311 
INFO:root:FL Epoch: 340 Normal Training
INFO:root:Worker: 904 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577212
INFO:root:Worker: 904 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394375
INFO:root:FL Epoch: 340 Norm Difference for worker 904 is 0.890647
INFO:root:FL Epoch: 340 Done on worker:904
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 766
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 340 Ends   ===================
INFO:root:Epoch:340 Global Model Test Loss:0.4935038878637202 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:340 Global Model Backdoor Test Loss:0.2002013884484768                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 341 Begins ===================
INFO:root:FL Epoch: 341 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 341 Workers Selected : [0, 1190, 1470, 1335, 667, 919, 1303, 1291, 1446, 1601]
INFO:root:FL Epoch: 341 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 341 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 341 Training on worker :0
INFO:root:FL Epoch: 341 Using Learning rate : 0.005062721502041593 
INFO:root:FL Epoch: 341 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.227592
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236623
INFO:root:FL Epoch: 341 Worker: 0 Backdoor Test Loss: 0.1919174219171206 Backdoor Test Accuracy: 93.33333333333333
INFO:root:FL Epoch: 341 Worker: 0 Backdoor Train Loss: 0.1642393484711647 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 341 Norm Difference for worker 0 is 0.168508
INFO:root:FL Epoch: 341 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1190
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1190 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589315
INFO:root:Worker: 1190 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418034
INFO:root:FL Epoch: 341 Norm Difference for worker 1190 is 0.949926
INFO:root:FL Epoch: 341 Done on worker:1190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1470
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308715
INFO:root:Worker: 1470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621646
INFO:root:FL Epoch: 341 Norm Difference for worker 1470 is 0.997477
INFO:root:FL Epoch: 341 Done on worker:1470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1335
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395630
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344869
INFO:root:FL Epoch: 341 Norm Difference for worker 1335 is 0.944928
INFO:root:FL Epoch: 341 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :667
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538548
INFO:root:Worker: 667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.127857
INFO:root:FL Epoch: 341 Norm Difference for worker 667 is 0.759215
INFO:root:FL Epoch: 341 Done on worker:667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :919
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783601
INFO:root:Worker: 919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.733217
INFO:root:FL Epoch: 341 Norm Difference for worker 919 is 1.044018
INFO:root:FL Epoch: 341 Done on worker:919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1303
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685749
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.672532
INFO:root:FL Epoch: 341 Norm Difference for worker 1303 is 1.014379
INFO:root:FL Epoch: 341 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1291
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1291 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615438
INFO:root:Worker: 1291 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519067
INFO:root:FL Epoch: 341 Norm Difference for worker 1291 is 0.996448
INFO:root:FL Epoch: 341 Done on worker:1291
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1446
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651396
INFO:root:Worker: 1446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320408
INFO:root:FL Epoch: 341 Norm Difference for worker 1446 is 0.980751
INFO:root:FL Epoch: 341 Done on worker:1446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 341 Training on worker :1601
INFO:root:FL Epoch: 341 Using Learning rate : 0.025313607510207965 
INFO:root:FL Epoch: 341 Normal Training
INFO:root:Worker: 1601 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639202
INFO:root:Worker: 1601 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484597
INFO:root:FL Epoch: 341 Norm Difference for worker 1601 is 1.035028
INFO:root:FL Epoch: 341 Done on worker:1601
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 341 Ends   ===================
INFO:root:Epoch:341 Global Model Test Loss:0.50699343400843 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:341 Global Model Backdoor Test Loss:0.1919174219171206                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 342 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 342 Workers Selected : [1251, 40, 1030, 298, 486, 1634, 230, 1478, 1444, 422]
INFO:root:FL Epoch: 342 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 342 Num points on workers: [200 201 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 342 Training on worker :1251
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565166
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404575
INFO:root:FL Epoch: 342 Norm Difference for worker 1251 is 1.098359
INFO:root:FL Epoch: 342 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :40
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 40 Train Epoch: 0 [0/201 (0%)]	Loss: 0.749960
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 40 Train Epoch: 1 [0/201 (0%)]	Loss: 0.373333
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 342 Norm Difference for worker 40 is 1.034135
INFO:root:FL Epoch: 342 Done on worker:40
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1030
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1030 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617149
INFO:root:Worker: 1030 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580597
INFO:root:FL Epoch: 342 Norm Difference for worker 1030 is 1.179453
INFO:root:FL Epoch: 342 Done on worker:1030
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :298
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 298 Train Epoch: 0 [0/201 (0%)]	Loss: 0.489729
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 298 Train Epoch: 1 [0/201 (0%)]	Loss: 0.359094
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 342 Norm Difference for worker 298 is 1.015479
INFO:root:FL Epoch: 342 Done on worker:298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :486
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473758
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598845
INFO:root:FL Epoch: 342 Norm Difference for worker 486 is 1.037334
INFO:root:FL Epoch: 342 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1634
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726919
INFO:root:Worker: 1634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.271300
INFO:root:FL Epoch: 342 Norm Difference for worker 1634 is 1.138106
INFO:root:FL Epoch: 342 Done on worker:1634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :230
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 230 Train Epoch: 0 [0/201 (0%)]	Loss: 0.586686
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 230 Train Epoch: 1 [0/201 (0%)]	Loss: 0.571950
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 342 Norm Difference for worker 230 is 1.096608
INFO:root:FL Epoch: 342 Done on worker:230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1478
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327552
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.107841
INFO:root:FL Epoch: 342 Norm Difference for worker 1478 is 0.734962
INFO:root:FL Epoch: 342 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :1444
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 1444 Train Epoch: 0 [0/200 (0%)]	Loss: 1.018521
INFO:root:Worker: 1444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565966
INFO:root:FL Epoch: 342 Norm Difference for worker 1444 is 1.06174
INFO:root:FL Epoch: 342 Done on worker:1444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 342 Training on worker :422
INFO:root:FL Epoch: 342 Using Learning rate : 0.02526298029518755 
INFO:root:FL Epoch: 342 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.351921
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381279
INFO:root:FL Epoch: 342 Norm Difference for worker 422 is 1.097774
INFO:root:FL Epoch: 342 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1478
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 342 Ends   ===================
INFO:root:Epoch:342 Global Model Test Loss:0.5726414989022648 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:342 Global Model Backdoor Test Loss:0.22751542925834656                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 343 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 343 Workers Selected : [216, 527, 1913, 531, 1700, 1415, 723, 1642, 573, 880]
INFO:root:FL Epoch: 343 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 343 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 343 Training on worker :216
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 216 Train Epoch: 0 [0/201 (0%)]	Loss: 0.683257
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 216 Train Epoch: 1 [0/201 (0%)]	Loss: 0.241553
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 343 Norm Difference for worker 216 is 1.198569
INFO:root:FL Epoch: 343 Done on worker:216
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :527
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683199
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436009
INFO:root:FL Epoch: 343 Norm Difference for worker 527 is 1.248699
INFO:root:FL Epoch: 343 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1913
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.913206
INFO:root:Worker: 1913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545214
INFO:root:FL Epoch: 343 Norm Difference for worker 1913 is 1.362432
INFO:root:FL Epoch: 343 Done on worker:1913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :531
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 531 Train Epoch: 0 [0/200 (0%)]	Loss: 1.082869
INFO:root:Worker: 531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.784881
INFO:root:FL Epoch: 343 Norm Difference for worker 531 is 1.413464
INFO:root:FL Epoch: 343 Done on worker:531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1700
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794723
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.416606
INFO:root:FL Epoch: 343 Norm Difference for worker 1700 is 1.222919
INFO:root:FL Epoch: 343 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1415
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1415 Train Epoch: 0 [0/200 (0%)]	Loss: 1.202767
INFO:root:Worker: 1415 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510357
INFO:root:FL Epoch: 343 Norm Difference for worker 1415 is 1.429514
INFO:root:FL Epoch: 343 Done on worker:1415
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :723
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 723 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361854
INFO:root:Worker: 723 Train Epoch: 1 [0/200 (0%)]	Loss: 0.275703
INFO:root:FL Epoch: 343 Norm Difference for worker 723 is 1.1182
INFO:root:FL Epoch: 343 Done on worker:723
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :1642
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 1642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783637
INFO:root:Worker: 1642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420376
INFO:root:FL Epoch: 343 Norm Difference for worker 1642 is 1.31667
INFO:root:FL Epoch: 343 Done on worker:1642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :573
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.836995
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360457
INFO:root:FL Epoch: 343 Norm Difference for worker 573 is 1.192307
INFO:root:FL Epoch: 343 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 343 Training on worker :880
INFO:root:FL Epoch: 343 Using Learning rate : 0.025212454334597175 
INFO:root:FL Epoch: 343 Normal Training
INFO:root:Worker: 880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641905
INFO:root:Worker: 880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661282
INFO:root:FL Epoch: 343 Norm Difference for worker 880 is 1.255953
INFO:root:FL Epoch: 343 Done on worker:880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 723
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 343 Ends   ===================
INFO:root:Epoch:343 Global Model Test Loss:0.5290274900548598 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:343 Global Model Backdoor Test Loss:0.20949101572235426                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 344 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 344 Workers Selected : [1483, 726, 1413, 747, 640, 1022, 1574, 701, 1906, 939]
INFO:root:FL Epoch: 344 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 344 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 344 Training on worker :1483
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590515
INFO:root:Worker: 1483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372388
INFO:root:FL Epoch: 344 Norm Difference for worker 1483 is 1.084094
INFO:root:FL Epoch: 344 Done on worker:1483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :726
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424678
INFO:root:Worker: 726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263760
INFO:root:FL Epoch: 344 Norm Difference for worker 726 is 1.13677
INFO:root:FL Epoch: 344 Done on worker:726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1413
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649380
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482549
INFO:root:FL Epoch: 344 Norm Difference for worker 1413 is 1.041351
INFO:root:FL Epoch: 344 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :747
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654327
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222208
INFO:root:FL Epoch: 344 Norm Difference for worker 747 is 1.165662
INFO:root:FL Epoch: 344 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :640
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569387
INFO:root:Worker: 640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441275
INFO:root:FL Epoch: 344 Norm Difference for worker 640 is 1.065657
INFO:root:FL Epoch: 344 Done on worker:640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1022
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1022 Train Epoch: 0 [0/200 (0%)]	Loss: 0.325260
INFO:root:Worker: 1022 Train Epoch: 1 [0/200 (0%)]	Loss: 0.278944
INFO:root:FL Epoch: 344 Norm Difference for worker 1022 is 0.947176
INFO:root:FL Epoch: 344 Done on worker:1022
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1574
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736861
INFO:root:Worker: 1574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406843
INFO:root:FL Epoch: 344 Norm Difference for worker 1574 is 1.173445
INFO:root:FL Epoch: 344 Done on worker:1574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :701
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484598
INFO:root:Worker: 701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392191
INFO:root:FL Epoch: 344 Norm Difference for worker 701 is 1.050586
INFO:root:FL Epoch: 344 Done on worker:701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :1906
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468922
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.750513
INFO:root:FL Epoch: 344 Norm Difference for worker 1906 is 0.973534
INFO:root:FL Epoch: 344 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 344 Training on worker :939
INFO:root:FL Epoch: 344 Using Learning rate : 0.02516202942592798 
INFO:root:FL Epoch: 344 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.734421
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476162
INFO:root:FL Epoch: 344 Norm Difference for worker 939 is 1.091468
INFO:root:FL Epoch: 344 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1906
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 344 Ends   ===================
INFO:root:Epoch:344 Global Model Test Loss:0.513307206770953 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:344 Global Model Backdoor Test Loss:0.2045143904785315                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 345 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 345 Workers Selected : [117, 1855, 224, 1011, 1219, 370, 1174, 1873, 1310, 826]
INFO:root:FL Epoch: 345 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 345 Num points on workers: [201 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 345 Training on worker :117
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 117 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517256
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 117 Train Epoch: 1 [0/201 (0%)]	Loss: 0.224999
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 345 Norm Difference for worker 117 is 0.858265
INFO:root:FL Epoch: 345 Done on worker:117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1855
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1855 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429503
INFO:root:Worker: 1855 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413174
INFO:root:FL Epoch: 345 Norm Difference for worker 1855 is 1.031328
INFO:root:FL Epoch: 345 Done on worker:1855
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :224
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 224 Train Epoch: 0 [0/201 (0%)]	Loss: 0.129526
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 224 Train Epoch: 1 [0/201 (0%)]	Loss: 0.370138
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 345 Norm Difference for worker 224 is 0.830761
INFO:root:FL Epoch: 345 Done on worker:224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1011
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1011 Train Epoch: 0 [0/200 (0%)]	Loss: 0.698720
INFO:root:Worker: 1011 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333139
INFO:root:FL Epoch: 345 Norm Difference for worker 1011 is 1.095839
INFO:root:FL Epoch: 345 Done on worker:1011
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1219
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1219 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366820
INFO:root:Worker: 1219 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346635
INFO:root:FL Epoch: 345 Norm Difference for worker 1219 is 0.996806
INFO:root:FL Epoch: 345 Done on worker:1219
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :370
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426623
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433138
INFO:root:FL Epoch: 345 Norm Difference for worker 370 is 0.952328
INFO:root:FL Epoch: 345 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1174
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611414
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343041
INFO:root:FL Epoch: 345 Norm Difference for worker 1174 is 1.174364
INFO:root:FL Epoch: 345 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1873
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435906
INFO:root:Worker: 1873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490373
INFO:root:FL Epoch: 345 Norm Difference for worker 1873 is 1.116573
INFO:root:FL Epoch: 345 Done on worker:1873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :1310
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 1310 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629302
INFO:root:Worker: 1310 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578710
INFO:root:FL Epoch: 345 Norm Difference for worker 1310 is 1.089042
INFO:root:FL Epoch: 345 Done on worker:1310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 345 Training on worker :826
INFO:root:FL Epoch: 345 Using Learning rate : 0.02511170536707612 
INFO:root:FL Epoch: 345 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.624361
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412300
INFO:root:FL Epoch: 345 Norm Difference for worker 826 is 1.127118
INFO:root:FL Epoch: 345 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 224
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 345 Ends   ===================
INFO:root:Epoch:345 Global Model Test Loss:0.5265584886074066 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:345 Global Model Backdoor Test Loss:0.1684422567486763                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 346 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 346 Workers Selected : [919, 1880, 1336, 1458, 1596, 14, 1839, 1906, 1033, 1406]
INFO:root:FL Epoch: 346 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 346 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 346 Training on worker :919
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 919 Train Epoch: 0 [0/200 (0%)]	Loss: 0.987672
INFO:root:Worker: 919 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369689
INFO:root:FL Epoch: 346 Norm Difference for worker 919 is 1.246947
INFO:root:FL Epoch: 346 Done on worker:919
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1880
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518442
INFO:root:Worker: 1880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592587
INFO:root:FL Epoch: 346 Norm Difference for worker 1880 is 1.167069
INFO:root:FL Epoch: 346 Done on worker:1880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1336
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1336 Train Epoch: 0 [0/200 (0%)]	Loss: 0.573149
INFO:root:Worker: 1336 Train Epoch: 1 [0/200 (0%)]	Loss: 0.716868
INFO:root:FL Epoch: 346 Norm Difference for worker 1336 is 1.239457
INFO:root:FL Epoch: 346 Done on worker:1336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1458
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1458 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611003
INFO:root:Worker: 1458 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452699
INFO:root:FL Epoch: 346 Norm Difference for worker 1458 is 1.270136
INFO:root:FL Epoch: 346 Done on worker:1458
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1596
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 1.064554
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413153
INFO:root:FL Epoch: 346 Norm Difference for worker 1596 is 1.146783
INFO:root:FL Epoch: 346 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :14
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.404462
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.330512
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 346 Norm Difference for worker 14 is 1.163966
INFO:root:FL Epoch: 346 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1839
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496870
INFO:root:Worker: 1839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256815
INFO:root:FL Epoch: 346 Norm Difference for worker 1839 is 1.225109
INFO:root:FL Epoch: 346 Done on worker:1839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1906
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.334801
INFO:root:Worker: 1906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.199326
INFO:root:FL Epoch: 346 Norm Difference for worker 1906 is 0.815692
INFO:root:FL Epoch: 346 Done on worker:1906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1033
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1033 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547150
INFO:root:Worker: 1033 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382943
INFO:root:FL Epoch: 346 Norm Difference for worker 1033 is 1.080232
INFO:root:FL Epoch: 346 Done on worker:1033
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 346 Training on worker :1406
INFO:root:FL Epoch: 346 Using Learning rate : 0.02506148195634197 
INFO:root:FL Epoch: 346 Normal Training
INFO:root:Worker: 1406 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453054
INFO:root:Worker: 1406 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682783
INFO:root:FL Epoch: 346 Norm Difference for worker 1406 is 1.173637
INFO:root:FL Epoch: 346 Done on worker:1406
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1906
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 346 Ends   ===================
INFO:root:Epoch:346 Global Model Test Loss:0.5476427534047295 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:346 Global Model Backdoor Test Loss:0.16673589621980986                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 347 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 347 Workers Selected : [1713, 1915, 16, 982, 122, 1379, 906, 1273, 1926, 710]
INFO:root:FL Epoch: 347 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 347 Num points on workers: [200 200 201 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 347 Training on worker :1713
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376054
INFO:root:Worker: 1713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254791
INFO:root:FL Epoch: 347 Norm Difference for worker 1713 is 1.356239
INFO:root:FL Epoch: 347 Done on worker:1713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1915
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.998188
INFO:root:Worker: 1915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244686
INFO:root:FL Epoch: 347 Norm Difference for worker 1915 is 1.376143
INFO:root:FL Epoch: 347 Done on worker:1915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :16
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 16 Train Epoch: 0 [0/201 (0%)]	Loss: 0.574814
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 16 Train Epoch: 1 [0/201 (0%)]	Loss: 0.595406
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 347 Norm Difference for worker 16 is 1.331482
INFO:root:FL Epoch: 347 Done on worker:16
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :982
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627944
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574435
INFO:root:FL Epoch: 347 Norm Difference for worker 982 is 1.386405
INFO:root:FL Epoch: 347 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :122
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.560720
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.553108
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 347 Norm Difference for worker 122 is 1.387893
INFO:root:FL Epoch: 347 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1379
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.972743
INFO:root:Worker: 1379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189020
INFO:root:FL Epoch: 347 Norm Difference for worker 1379 is 1.378403
INFO:root:FL Epoch: 347 Done on worker:1379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :906
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670833
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426523
INFO:root:FL Epoch: 347 Norm Difference for worker 906 is 1.362314
INFO:root:FL Epoch: 347 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1273
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1273 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525250
INFO:root:Worker: 1273 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580135
INFO:root:FL Epoch: 347 Norm Difference for worker 1273 is 1.435345
INFO:root:FL Epoch: 347 Done on worker:1273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :1926
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 1926 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564714
INFO:root:Worker: 1926 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396350
INFO:root:FL Epoch: 347 Norm Difference for worker 1926 is 1.244642
INFO:root:FL Epoch: 347 Done on worker:1926
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 347 Training on worker :710
INFO:root:FL Epoch: 347 Using Learning rate : 0.025011358992429285 
INFO:root:FL Epoch: 347 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444237
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328530
INFO:root:FL Epoch: 347 Norm Difference for worker 710 is 1.272886
INFO:root:FL Epoch: 347 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 710
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 347 Ends   ===================
INFO:root:Epoch:347 Global Model Test Loss:0.5409779408398796 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:347 Global Model Backdoor Test Loss:0.15685575579603514                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 348 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 348 Workers Selected : [1897, 1068, 418, 886, 380, 476, 349, 1509, 1150, 808]
INFO:root:FL Epoch: 348 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 348 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 348 Training on worker :1897
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569836
INFO:root:Worker: 1897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553845
INFO:root:FL Epoch: 348 Norm Difference for worker 1897 is 1.107485
INFO:root:FL Epoch: 348 Done on worker:1897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1068
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1068 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413921
INFO:root:Worker: 1068 Train Epoch: 1 [0/200 (0%)]	Loss: 0.294552
INFO:root:FL Epoch: 348 Norm Difference for worker 1068 is 1.026479
INFO:root:FL Epoch: 348 Done on worker:1068
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :418
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489338
INFO:root:Worker: 418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426037
INFO:root:FL Epoch: 348 Norm Difference for worker 418 is 1.232035
INFO:root:FL Epoch: 348 Done on worker:418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :886
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 886 Train Epoch: 0 [0/200 (0%)]	Loss: 0.842294
INFO:root:Worker: 886 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585092
INFO:root:FL Epoch: 348 Norm Difference for worker 886 is 1.131242
INFO:root:FL Epoch: 348 Done on worker:886
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :380
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447682
INFO:root:Worker: 380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496337
INFO:root:FL Epoch: 348 Norm Difference for worker 380 is 1.18859
INFO:root:FL Epoch: 348 Done on worker:380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :476
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409200
INFO:root:Worker: 476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267469
INFO:root:FL Epoch: 348 Norm Difference for worker 476 is 1.033705
INFO:root:FL Epoch: 348 Done on worker:476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :349
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 349 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560545
INFO:root:Worker: 349 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415318
INFO:root:FL Epoch: 348 Norm Difference for worker 349 is 1.042563
INFO:root:FL Epoch: 348 Done on worker:349
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1509
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.701764
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.704191
INFO:root:FL Epoch: 348 Norm Difference for worker 1509 is 1.102046
INFO:root:FL Epoch: 348 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :1150
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 1150 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391245
INFO:root:Worker: 1150 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246588
INFO:root:FL Epoch: 348 Norm Difference for worker 1150 is 1.07097
INFO:root:FL Epoch: 348 Done on worker:1150
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 348 Training on worker :808
INFO:root:FL Epoch: 348 Using Learning rate : 0.024961336274444426 
INFO:root:FL Epoch: 348 Normal Training
INFO:root:Worker: 808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479003
INFO:root:Worker: 808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334917
INFO:root:FL Epoch: 348 Norm Difference for worker 808 is 1.104955
INFO:root:FL Epoch: 348 Done on worker:808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 476
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 348 Ends   ===================
INFO:root:Epoch:348 Global Model Test Loss:0.537884408936781 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:348 Global Model Backdoor Test Loss:0.26437417914470035                             and Backdoor Test Accuracy:87.5 
INFO:root:=======================================================
INFO:root:================FL round 349 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 349 Workers Selected : [889, 1269, 1717, 264, 1747, 1771, 1579, 1357, 535, 495]
INFO:root:FL Epoch: 349 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 349 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 349 Training on worker :889
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465188
INFO:root:Worker: 889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587512
INFO:root:FL Epoch: 349 Norm Difference for worker 889 is 0.960523
INFO:root:FL Epoch: 349 Done on worker:889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1269
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1269 Train Epoch: 0 [0/200 (0%)]	Loss: 0.722151
INFO:root:Worker: 1269 Train Epoch: 1 [0/200 (0%)]	Loss: 0.243249
INFO:root:FL Epoch: 349 Norm Difference for worker 1269 is 0.920214
INFO:root:FL Epoch: 349 Done on worker:1269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1717
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1717 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445996
INFO:root:Worker: 1717 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545706
INFO:root:FL Epoch: 349 Norm Difference for worker 1717 is 0.962651
INFO:root:FL Epoch: 349 Done on worker:1717
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :264
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 264 Train Epoch: 0 [0/201 (0%)]	Loss: 0.337439
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 264 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446892
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 349 Norm Difference for worker 264 is 0.956644
INFO:root:FL Epoch: 349 Done on worker:264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1747
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512820
INFO:root:Worker: 1747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513088
INFO:root:FL Epoch: 349 Norm Difference for worker 1747 is 0.948422
INFO:root:FL Epoch: 349 Done on worker:1747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1771
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1771 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556821
INFO:root:Worker: 1771 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363847
INFO:root:FL Epoch: 349 Norm Difference for worker 1771 is 0.90137
INFO:root:FL Epoch: 349 Done on worker:1771
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1579
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.878414
INFO:root:Worker: 1579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.778308
INFO:root:FL Epoch: 349 Norm Difference for worker 1579 is 0.963562
INFO:root:FL Epoch: 349 Done on worker:1579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :1357
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 1357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639628
INFO:root:Worker: 1357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449471
INFO:root:FL Epoch: 349 Norm Difference for worker 1357 is 0.920391
INFO:root:FL Epoch: 349 Done on worker:1357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :535
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 535 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434262
INFO:root:Worker: 535 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579104
INFO:root:FL Epoch: 349 Norm Difference for worker 535 is 0.895861
INFO:root:FL Epoch: 349 Done on worker:535
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 349 Training on worker :495
INFO:root:FL Epoch: 349 Using Learning rate : 0.02491141360189554 
INFO:root:FL Epoch: 349 Normal Training
INFO:root:Worker: 495 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522807
INFO:root:Worker: 495 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371708
INFO:root:FL Epoch: 349 Norm Difference for worker 495 is 0.940537
INFO:root:FL Epoch: 349 Done on worker:495
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 535
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 349 Ends   ===================
INFO:root:Epoch:349 Global Model Test Loss:0.5319642564829659 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:349 Global Model Backdoor Test Loss:0.20910783608754477                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 350 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 350 Workers Selected : [1292, 911, 1506, 333, 1879, 704, 1284, 264, 89, 318]
INFO:root:FL Epoch: 350 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.0998004
 0.1002994 0.1002994 0.1002994]
INFO:root:FL Epoch: 350 Num points on workers: [200 200 200 201 200 200 200 201 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 350 Training on worker :1292
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1292 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570165
INFO:root:Worker: 1292 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544687
INFO:root:FL Epoch: 350 Norm Difference for worker 1292 is 0.965775
INFO:root:FL Epoch: 350 Done on worker:1292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :911
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611460
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535813
INFO:root:FL Epoch: 350 Norm Difference for worker 911 is 0.931655
INFO:root:FL Epoch: 350 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1506
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409172
INFO:root:Worker: 1506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361334
INFO:root:FL Epoch: 350 Norm Difference for worker 1506 is 0.870378
INFO:root:FL Epoch: 350 Done on worker:1506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :333
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.592991
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.591412
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 333 is 0.918287
INFO:root:FL Epoch: 350 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1879
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801857
INFO:root:Worker: 1879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.626818
INFO:root:FL Epoch: 350 Norm Difference for worker 1879 is 0.899848
INFO:root:FL Epoch: 350 Done on worker:1879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :704
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.329450
INFO:root:Worker: 704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263795
INFO:root:FL Epoch: 350 Norm Difference for worker 704 is 0.897959
INFO:root:FL Epoch: 350 Done on worker:704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :1284
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 1284 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374591
INFO:root:Worker: 1284 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249214
INFO:root:FL Epoch: 350 Norm Difference for worker 1284 is 0.775548
INFO:root:FL Epoch: 350 Done on worker:1284
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :264
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 264 Train Epoch: 0 [0/201 (0%)]	Loss: 0.564473
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 264 Train Epoch: 1 [0/201 (0%)]	Loss: 0.571169
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 264 is 0.916764
INFO:root:FL Epoch: 350 Done on worker:264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :89
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 89 Train Epoch: 0 [0/201 (0%)]	Loss: 0.430027
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 89 Train Epoch: 1 [0/201 (0%)]	Loss: 0.467696
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 89 is 0.897158
INFO:root:FL Epoch: 350 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 350 Training on worker :318
INFO:root:FL Epoch: 350 Using Learning rate : 0.024861590774691748 
INFO:root:FL Epoch: 350 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.552053
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.439283
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 350 Norm Difference for worker 318 is 0.852429
INFO:root:FL Epoch: 350 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1284
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 350 Ends   ===================
INFO:root:Epoch:350 Global Model Test Loss:0.5497557959135841 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:350 Global Model Backdoor Test Loss:0.162302286674579                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 351 Begins ===================
INFO:root:FL Epoch: 351 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 351 Workers Selected : [0, 1364, 1922, 70, 1700, 674, 104, 454, 485, 657]
INFO:root:FL Epoch: 351 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 351 Num points on workers: [200 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 351 Training on worker :0
INFO:root:FL Epoch: 351 Using Learning rate : 0.004962373518628473 
INFO:root:FL Epoch: 351 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.260292
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.200411
INFO:root:FL Epoch: 351 Worker: 0 Backdoor Test Loss: 0.1323792946835359 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 351 Worker: 0 Backdoor Train Loss: 0.16256313025951385 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 351 Norm Difference for worker 0 is 0.168565
INFO:root:FL Epoch: 351 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1364
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.746670
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357998
INFO:root:FL Epoch: 351 Norm Difference for worker 1364 is 1.080709
INFO:root:FL Epoch: 351 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1922
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364888
INFO:root:Worker: 1922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414904
INFO:root:FL Epoch: 351 Norm Difference for worker 1922 is 1.035942
INFO:root:FL Epoch: 351 Done on worker:1922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :70
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503446
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.520812
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 351 Norm Difference for worker 70 is 0.923469
INFO:root:FL Epoch: 351 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :1700
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394915
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442727
INFO:root:FL Epoch: 351 Norm Difference for worker 1700 is 1.01443
INFO:root:FL Epoch: 351 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :674
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 674 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632991
INFO:root:Worker: 674 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455183
INFO:root:FL Epoch: 351 Norm Difference for worker 674 is 1.091139
INFO:root:FL Epoch: 351 Done on worker:674
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :104
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.882396
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.670137
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 351 Norm Difference for worker 104 is 1.127947
INFO:root:FL Epoch: 351 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :454
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 454 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426290
INFO:root:Worker: 454 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307557
INFO:root:FL Epoch: 351 Norm Difference for worker 454 is 1.009154
INFO:root:FL Epoch: 351 Done on worker:454
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :485
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466266
INFO:root:Worker: 485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544389
INFO:root:FL Epoch: 351 Norm Difference for worker 485 is 1.013744
INFO:root:FL Epoch: 351 Done on worker:485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 351 Training on worker :657
INFO:root:FL Epoch: 351 Using Learning rate : 0.024811867593142363 
INFO:root:FL Epoch: 351 Normal Training
INFO:root:Worker: 657 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712067
INFO:root:Worker: 657 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420923
INFO:root:FL Epoch: 351 Norm Difference for worker 657 is 1.096141
INFO:root:FL Epoch: 351 Done on worker:657
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 351 Ends   ===================
INFO:root:Epoch:351 Global Model Test Loss:0.5566550808794358 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:351 Global Model Backdoor Test Loss:0.1323792946835359                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 352 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 352 Workers Selected : [397, 865, 1474, 1134, 1508, 438, 1832, 263, 8, 764]
INFO:root:FL Epoch: 352 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.1003996 0.0999001]
INFO:root:FL Epoch: 352 Num points on workers: [200 200 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 352 Training on worker :397
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515822
INFO:root:Worker: 397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503868
INFO:root:FL Epoch: 352 Norm Difference for worker 397 is 1.144985
INFO:root:FL Epoch: 352 Done on worker:397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :865
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720653
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449142
INFO:root:FL Epoch: 352 Norm Difference for worker 865 is 1.104124
INFO:root:FL Epoch: 352 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1474
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669700
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491374
INFO:root:FL Epoch: 352 Norm Difference for worker 1474 is 1.173006
INFO:root:FL Epoch: 352 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1134
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1134 Train Epoch: 0 [0/200 (0%)]	Loss: 0.759727
INFO:root:Worker: 1134 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382055
INFO:root:FL Epoch: 352 Norm Difference for worker 1134 is 1.142715
INFO:root:FL Epoch: 352 Done on worker:1134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1508
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.257611
INFO:root:Worker: 1508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352555
INFO:root:FL Epoch: 352 Norm Difference for worker 1508 is 1.073041
INFO:root:FL Epoch: 352 Done on worker:1508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :438
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 438 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504246
INFO:root:Worker: 438 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502222
INFO:root:FL Epoch: 352 Norm Difference for worker 438 is 1.149093
INFO:root:FL Epoch: 352 Done on worker:438
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :1832
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 1832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500346
INFO:root:Worker: 1832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473682
INFO:root:FL Epoch: 352 Norm Difference for worker 1832 is 1.295135
INFO:root:FL Epoch: 352 Done on worker:1832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :263
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 263 Train Epoch: 0 [0/201 (0%)]	Loss: 0.589970
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 263 Train Epoch: 1 [0/201 (0%)]	Loss: 0.544365
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 352 Norm Difference for worker 263 is 1.188705
INFO:root:FL Epoch: 352 Done on worker:263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :8
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 8 Train Epoch: 0 [0/201 (0%)]	Loss: 0.572943
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 8 Train Epoch: 1 [0/201 (0%)]	Loss: 0.416428
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 352 Norm Difference for worker 8 is 0.950327
INFO:root:FL Epoch: 352 Done on worker:8
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 352 Training on worker :764
INFO:root:FL Epoch: 352 Using Learning rate : 0.024762243857956077 
INFO:root:FL Epoch: 352 Normal Training
INFO:root:Worker: 764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644532
INFO:root:Worker: 764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.586799
INFO:root:FL Epoch: 352 Norm Difference for worker 764 is 1.100234
INFO:root:FL Epoch: 352 Done on worker:764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 8
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 352 Ends   ===================
INFO:root:Epoch:352 Global Model Test Loss:0.549170089118621 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:352 Global Model Backdoor Test Loss:0.11333509410421054                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 353 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 353 Workers Selected : [1882, 521, 441, 440, 68, 1428, 1147, 1439, 512, 582]
INFO:root:FL Epoch: 353 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 353 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 353 Training on worker :1882
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445197
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.196479
INFO:root:FL Epoch: 353 Norm Difference for worker 1882 is 1.080046
INFO:root:FL Epoch: 353 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :521
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.613307
INFO:root:Worker: 521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497193
INFO:root:FL Epoch: 353 Norm Difference for worker 521 is 1.114458
INFO:root:FL Epoch: 353 Done on worker:521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :441
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681827
INFO:root:Worker: 441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.703473
INFO:root:FL Epoch: 353 Norm Difference for worker 441 is 1.301685
INFO:root:FL Epoch: 353 Done on worker:441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :440
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.889344
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447306
INFO:root:FL Epoch: 353 Norm Difference for worker 440 is 1.435046
INFO:root:FL Epoch: 353 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :68
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 68 Train Epoch: 0 [0/201 (0%)]	Loss: 0.634373
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 68 Train Epoch: 1 [0/201 (0%)]	Loss: 0.509350
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 353 Norm Difference for worker 68 is 1.092784
INFO:root:FL Epoch: 353 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1428
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667826
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.699242
INFO:root:FL Epoch: 353 Norm Difference for worker 1428 is 1.173329
INFO:root:FL Epoch: 353 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1147
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1147 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568429
INFO:root:Worker: 1147 Train Epoch: 1 [0/200 (0%)]	Loss: 0.484204
INFO:root:FL Epoch: 353 Norm Difference for worker 1147 is 1.165809
INFO:root:FL Epoch: 353 Done on worker:1147
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :1439
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545944
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444144
INFO:root:FL Epoch: 353 Norm Difference for worker 1439 is 1.102529
INFO:root:FL Epoch: 353 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :512
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.917543
INFO:root:Worker: 512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327196
INFO:root:FL Epoch: 353 Norm Difference for worker 512 is 1.087695
INFO:root:FL Epoch: 353 Done on worker:512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 353 Training on worker :582
INFO:root:FL Epoch: 353 Using Learning rate : 0.024712719370240166 
INFO:root:FL Epoch: 353 Normal Training
INFO:root:Worker: 582 Train Epoch: 0 [0/200 (0%)]	Loss: 1.252879
INFO:root:Worker: 582 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573542
INFO:root:FL Epoch: 353 Norm Difference for worker 582 is 1.206984
INFO:root:FL Epoch: 353 Done on worker:582
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1882
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 353 Ends   ===================
INFO:root:Epoch:353 Global Model Test Loss:0.5545142748776604 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:353 Global Model Backdoor Test Loss:0.12421845644712448                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 354 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 354 Workers Selected : [993, 910, 1137, 861, 750, 544, 1019, 1898, 337, 285]
INFO:root:FL Epoch: 354 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 354 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 354 Training on worker :993
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 993 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429320
INFO:root:Worker: 993 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298956
INFO:root:FL Epoch: 354 Norm Difference for worker 993 is 0.912104
INFO:root:FL Epoch: 354 Done on worker:993
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :910
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419177
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.737987
INFO:root:FL Epoch: 354 Norm Difference for worker 910 is 0.977446
INFO:root:FL Epoch: 354 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1137
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686478
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605219
INFO:root:FL Epoch: 354 Norm Difference for worker 1137 is 1.045843
INFO:root:FL Epoch: 354 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :861
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 861 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686311
INFO:root:Worker: 861 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538561
INFO:root:FL Epoch: 354 Norm Difference for worker 861 is 1.016479
INFO:root:FL Epoch: 354 Done on worker:861
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :750
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.316832
INFO:root:Worker: 750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.573486
INFO:root:FL Epoch: 354 Norm Difference for worker 750 is 1.02916
INFO:root:FL Epoch: 354 Done on worker:750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :544
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425512
INFO:root:Worker: 544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599332
INFO:root:FL Epoch: 354 Norm Difference for worker 544 is 0.976108
INFO:root:FL Epoch: 354 Done on worker:544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1019
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1019 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558292
INFO:root:Worker: 1019 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488214
INFO:root:FL Epoch: 354 Norm Difference for worker 1019 is 0.942809
INFO:root:FL Epoch: 354 Done on worker:1019
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :1898
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 1898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526433
INFO:root:Worker: 1898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.236342
INFO:root:FL Epoch: 354 Norm Difference for worker 1898 is 0.939212
INFO:root:FL Epoch: 354 Done on worker:1898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :337
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.464559
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.552911
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 337 is 0.989507
INFO:root:FL Epoch: 354 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 354 Training on worker :285
INFO:root:FL Epoch: 354 Using Learning rate : 0.024663293931499686 
INFO:root:FL Epoch: 354 Normal Training
INFO:root:Worker: 285 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596097
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 285 Train Epoch: 1 [0/201 (0%)]	Loss: 0.388010
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 354 Norm Difference for worker 285 is 0.928738
INFO:root:FL Epoch: 354 Done on worker:285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 285
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 354 Ends   ===================
INFO:root:Epoch:354 Global Model Test Loss:0.5548421547693365 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:354 Global Model Backdoor Test Loss:0.20695371677478155                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 355 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 355 Workers Selected : [1247, 175, 532, 460, 1013, 1020, 1517, 1536, 59, 736]
INFO:root:FL Epoch: 355 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 355 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 355 Training on worker :1247
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653666
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327481
INFO:root:FL Epoch: 355 Norm Difference for worker 1247 is 0.867248
INFO:root:FL Epoch: 355 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :175
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 175 Train Epoch: 0 [0/201 (0%)]	Loss: 0.285199
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 175 Train Epoch: 1 [0/201 (0%)]	Loss: 0.351164
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 355 Norm Difference for worker 175 is 0.836707
INFO:root:FL Epoch: 355 Done on worker:175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :532
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619198
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420760
INFO:root:FL Epoch: 355 Norm Difference for worker 532 is 0.846655
INFO:root:FL Epoch: 355 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :460
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 460 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625935
INFO:root:Worker: 460 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516534
INFO:root:FL Epoch: 355 Norm Difference for worker 460 is 0.914978
INFO:root:FL Epoch: 355 Done on worker:460
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1013
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562207
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447518
INFO:root:FL Epoch: 355 Norm Difference for worker 1013 is 0.890795
INFO:root:FL Epoch: 355 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1020
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1020 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679865
INFO:root:Worker: 1020 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425960
INFO:root:FL Epoch: 355 Norm Difference for worker 1020 is 0.825859
INFO:root:FL Epoch: 355 Done on worker:1020
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1517
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400621
INFO:root:Worker: 1517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382016
INFO:root:FL Epoch: 355 Norm Difference for worker 1517 is 0.886428
INFO:root:FL Epoch: 355 Done on worker:1517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :1536
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574721
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437746
INFO:root:FL Epoch: 355 Norm Difference for worker 1536 is 0.872504
INFO:root:FL Epoch: 355 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :59
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.582012
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.456598
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 355 Norm Difference for worker 59 is 0.891403
INFO:root:FL Epoch: 355 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 355 Training on worker :736
INFO:root:FL Epoch: 355 Using Learning rate : 0.02461396734363669 
INFO:root:FL Epoch: 355 Normal Training
INFO:root:Worker: 736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.696842
INFO:root:Worker: 736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580330
INFO:root:FL Epoch: 355 Norm Difference for worker 736 is 0.913998
INFO:root:FL Epoch: 355 Done on worker:736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1020
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 355 Ends   ===================
INFO:root:Epoch:355 Global Model Test Loss:0.5500350664643681 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:355 Global Model Backdoor Test Loss:0.2517616848150889                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 356 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 356 Workers Selected : [61, 619, 1055, 301, 988, 1505, 1379, 620, 1903, 170]
INFO:root:FL Epoch: 356 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 356 Num points on workers: [201 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 356 Training on worker :61
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 61 Train Epoch: 0 [0/201 (0%)]	Loss: 0.720445
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 61 Train Epoch: 1 [0/201 (0%)]	Loss: 0.487099
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 61 is 0.82226
INFO:root:FL Epoch: 356 Done on worker:61
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :619
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337282
INFO:root:Worker: 619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529962
INFO:root:FL Epoch: 356 Norm Difference for worker 619 is 0.882073
INFO:root:FL Epoch: 356 Done on worker:619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1055
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1055 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426276
INFO:root:Worker: 1055 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410387
INFO:root:FL Epoch: 356 Norm Difference for worker 1055 is 0.891789
INFO:root:FL Epoch: 356 Done on worker:1055
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :301
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.797235
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.454053
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 301 is 0.901145
INFO:root:FL Epoch: 356 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :988
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 988 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735252
INFO:root:Worker: 988 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488921
INFO:root:FL Epoch: 356 Norm Difference for worker 988 is 0.83117
INFO:root:FL Epoch: 356 Done on worker:988
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1505
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566427
INFO:root:Worker: 1505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487350
INFO:root:FL Epoch: 356 Norm Difference for worker 1505 is 0.850549
INFO:root:FL Epoch: 356 Done on worker:1505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1379
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483794
INFO:root:Worker: 1379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471786
INFO:root:FL Epoch: 356 Norm Difference for worker 1379 is 0.904052
INFO:root:FL Epoch: 356 Done on worker:1379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :620
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433359
INFO:root:Worker: 620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602083
INFO:root:FL Epoch: 356 Norm Difference for worker 620 is 0.827526
INFO:root:FL Epoch: 356 Done on worker:620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :1903
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 1903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555308
INFO:root:Worker: 1903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.603508
INFO:root:FL Epoch: 356 Norm Difference for worker 1903 is 0.833725
INFO:root:FL Epoch: 356 Done on worker:1903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 356 Training on worker :170
INFO:root:FL Epoch: 356 Using Learning rate : 0.024564739408949415 
INFO:root:FL Epoch: 356 Normal Training
INFO:root:Worker: 170 Train Epoch: 0 [0/201 (0%)]	Loss: 0.410153
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 170 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505441
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 356 Norm Difference for worker 170 is 0.901169
INFO:root:FL Epoch: 356 Done on worker:170
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 620
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 356 Ends   ===================
INFO:root:Epoch:356 Global Model Test Loss:0.5502695493838367 and Test Accuracy:72.05882352941177 
INFO:root:Epoch:356 Global Model Backdoor Test Loss:0.1656196564435959                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 357 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 357 Workers Selected : [1312, 340, 1693, 945, 1644, 498, 1645, 1651, 423, 102]
INFO:root:FL Epoch: 357 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 357 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 357 Training on worker :1312
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519510
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683980
INFO:root:FL Epoch: 357 Norm Difference for worker 1312 is 0.895166
INFO:root:FL Epoch: 357 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :340
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525552
INFO:root:Worker: 340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429669
INFO:root:FL Epoch: 357 Norm Difference for worker 340 is 0.933412
INFO:root:FL Epoch: 357 Done on worker:340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1693
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659942
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496081
INFO:root:FL Epoch: 357 Norm Difference for worker 1693 is 0.839247
INFO:root:FL Epoch: 357 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :945
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 945 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499860
INFO:root:Worker: 945 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496350
INFO:root:FL Epoch: 357 Norm Difference for worker 945 is 0.87743
INFO:root:FL Epoch: 357 Done on worker:945
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1644
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492146
INFO:root:Worker: 1644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550262
INFO:root:FL Epoch: 357 Norm Difference for worker 1644 is 0.850341
INFO:root:FL Epoch: 357 Done on worker:1644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :498
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645588
INFO:root:Worker: 498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606093
INFO:root:FL Epoch: 357 Norm Difference for worker 498 is 0.89645
INFO:root:FL Epoch: 357 Done on worker:498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1645
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1645 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481312
INFO:root:Worker: 1645 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414226
INFO:root:FL Epoch: 357 Norm Difference for worker 1645 is 0.864143
INFO:root:FL Epoch: 357 Done on worker:1645
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :1651
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 1651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577150
INFO:root:Worker: 1651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.267441
INFO:root:FL Epoch: 357 Norm Difference for worker 1651 is 0.86447
INFO:root:FL Epoch: 357 Done on worker:1651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :423
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643020
INFO:root:Worker: 423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398377
INFO:root:FL Epoch: 357 Norm Difference for worker 423 is 0.881638
INFO:root:FL Epoch: 357 Done on worker:423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 357 Training on worker :102
INFO:root:FL Epoch: 357 Using Learning rate : 0.024515609930131514 
INFO:root:FL Epoch: 357 Normal Training
INFO:root:Worker: 102 Train Epoch: 0 [0/201 (0%)]	Loss: 0.531839
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 102 Train Epoch: 1 [0/201 (0%)]	Loss: 0.390637
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 357 Norm Difference for worker 102 is 0.827528
INFO:root:FL Epoch: 357 Done on worker:102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1651
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 357 Ends   ===================
INFO:root:Epoch:357 Global Model Test Loss:0.5726315677165985 and Test Accuracy:71.17647058823529 
INFO:root:Epoch:357 Global Model Backdoor Test Loss:0.28871692220369977                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 358 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 358 Workers Selected : [1698, 63, 1431, 1854, 447, 685, 30, 423, 529, 575]
INFO:root:FL Epoch: 358 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 358 Num points on workers: [200 201 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 358 Training on worker :1698
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432091
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502080
INFO:root:FL Epoch: 358 Norm Difference for worker 1698 is 0.929173
INFO:root:FL Epoch: 358 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :63
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 63 Train Epoch: 0 [0/201 (0%)]	Loss: 0.494486
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 63 Train Epoch: 1 [0/201 (0%)]	Loss: 0.371219
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 63 is 0.93988
INFO:root:FL Epoch: 358 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :1431
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.333574
INFO:root:Worker: 1431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.222319
INFO:root:FL Epoch: 358 Norm Difference for worker 1431 is 0.914398
INFO:root:FL Epoch: 358 Done on worker:1431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :1854
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 1854 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535860
INFO:root:Worker: 1854 Train Epoch: 1 [0/200 (0%)]	Loss: 0.618661
INFO:root:FL Epoch: 358 Norm Difference for worker 1854 is 0.972091
INFO:root:FL Epoch: 358 Done on worker:1854
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :447
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594047
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291619
INFO:root:FL Epoch: 358 Norm Difference for worker 447 is 0.895681
INFO:root:FL Epoch: 358 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :685
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.359159
INFO:root:Worker: 685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382122
INFO:root:FL Epoch: 358 Norm Difference for worker 685 is 0.928473
INFO:root:FL Epoch: 358 Done on worker:685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :30
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 30 Train Epoch: 0 [0/201 (0%)]	Loss: 0.652308
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 30 Train Epoch: 1 [0/201 (0%)]	Loss: 0.495254
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 358 Norm Difference for worker 30 is 0.912123
INFO:root:FL Epoch: 358 Done on worker:30
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :423
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683107
INFO:root:Worker: 423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479634
INFO:root:FL Epoch: 358 Norm Difference for worker 423 is 0.965336
INFO:root:FL Epoch: 358 Done on worker:423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :529
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 529 Train Epoch: 0 [0/200 (0%)]	Loss: 0.311498
INFO:root:Worker: 529 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510326
INFO:root:FL Epoch: 358 Norm Difference for worker 529 is 0.855481
INFO:root:FL Epoch: 358 Done on worker:529
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 358 Training on worker :575
INFO:root:FL Epoch: 358 Using Learning rate : 0.02446657871027125 
INFO:root:FL Epoch: 358 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606752
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448625
INFO:root:FL Epoch: 358 Norm Difference for worker 575 is 1.00371
INFO:root:FL Epoch: 358 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 447
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 358 Ends   ===================
INFO:root:Epoch:358 Global Model Test Loss:0.5448525916127598 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:358 Global Model Backdoor Test Loss:0.20881061007579169                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 359 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 359 Workers Selected : [707, 936, 532, 207, 1911, 110, 1469, 268, 1634, 482]
INFO:root:FL Epoch: 359 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 359 Num points on workers: [200 200 200 201 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 359 Training on worker :707
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.378221
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538188
INFO:root:FL Epoch: 359 Norm Difference for worker 707 is 0.84842
INFO:root:FL Epoch: 359 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :936
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596275
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632124
INFO:root:FL Epoch: 359 Norm Difference for worker 936 is 0.84978
INFO:root:FL Epoch: 359 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :532
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 532 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438850
INFO:root:Worker: 532 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434370
INFO:root:FL Epoch: 359 Norm Difference for worker 532 is 0.837918
INFO:root:FL Epoch: 359 Done on worker:532
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :207
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 207 Train Epoch: 0 [0/201 (0%)]	Loss: 0.748124
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 207 Train Epoch: 1 [0/201 (0%)]	Loss: 0.573705
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 359 Norm Difference for worker 207 is 0.883509
INFO:root:FL Epoch: 359 Done on worker:207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1911
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611239
INFO:root:Worker: 1911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551679
INFO:root:FL Epoch: 359 Norm Difference for worker 1911 is 0.921611
INFO:root:FL Epoch: 359 Done on worker:1911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :110
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 110 Train Epoch: 0 [0/201 (0%)]	Loss: 0.660883
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 110 Train Epoch: 1 [0/201 (0%)]	Loss: 0.327029
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 359 Norm Difference for worker 110 is 0.856261
INFO:root:FL Epoch: 359 Done on worker:110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1469
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1469 Train Epoch: 0 [0/200 (0%)]	Loss: 0.545711
INFO:root:Worker: 1469 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561475
INFO:root:FL Epoch: 359 Norm Difference for worker 1469 is 0.881557
INFO:root:FL Epoch: 359 Done on worker:1469
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :268
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 268 Train Epoch: 0 [0/201 (0%)]	Loss: 0.384477
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 268 Train Epoch: 1 [0/201 (0%)]	Loss: 0.462877
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 359 Norm Difference for worker 268 is 0.7846
INFO:root:FL Epoch: 359 Done on worker:268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :1634
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 1634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712810
INFO:root:Worker: 1634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514121
INFO:root:FL Epoch: 359 Norm Difference for worker 1634 is 0.87557
INFO:root:FL Epoch: 359 Done on worker:1634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 359 Training on worker :482
INFO:root:FL Epoch: 359 Using Learning rate : 0.02441764555285071 
INFO:root:FL Epoch: 359 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536074
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608386
INFO:root:FL Epoch: 359 Norm Difference for worker 482 is 0.837011
INFO:root:FL Epoch: 359 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 268
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 359 Ends   ===================
INFO:root:Epoch:359 Global Model Test Loss:0.5441143915933722 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:359 Global Model Backdoor Test Loss:0.20123246063788733                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 360 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 360 Workers Selected : [1837, 435, 1470, 1218, 1752, 864, 1518, 1489, 50, 1221]
INFO:root:FL Epoch: 360 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 360 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 360 Training on worker :1837
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498540
INFO:root:Worker: 1837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307184
INFO:root:FL Epoch: 360 Norm Difference for worker 1837 is 0.814917
INFO:root:FL Epoch: 360 Done on worker:1837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :435
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736705
INFO:root:Worker: 435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.663217
INFO:root:FL Epoch: 360 Norm Difference for worker 435 is 0.889511
INFO:root:FL Epoch: 360 Done on worker:435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1470
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1470 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572511
INFO:root:Worker: 1470 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458386
INFO:root:FL Epoch: 360 Norm Difference for worker 1470 is 0.820588
INFO:root:FL Epoch: 360 Done on worker:1470
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1218
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559165
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.666851
INFO:root:FL Epoch: 360 Norm Difference for worker 1218 is 0.893694
INFO:root:FL Epoch: 360 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1752
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1752 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697162
INFO:root:Worker: 1752 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582986
INFO:root:FL Epoch: 360 Norm Difference for worker 1752 is 0.838132
INFO:root:FL Epoch: 360 Done on worker:1752
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :864
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.339102
INFO:root:Worker: 864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489025
INFO:root:FL Epoch: 360 Norm Difference for worker 864 is 0.840997
INFO:root:FL Epoch: 360 Done on worker:864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1518
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523458
INFO:root:Worker: 1518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591554
INFO:root:FL Epoch: 360 Norm Difference for worker 1518 is 0.883285
INFO:root:FL Epoch: 360 Done on worker:1518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1489
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1489 Train Epoch: 0 [0/200 (0%)]	Loss: 0.705202
INFO:root:Worker: 1489 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444520
INFO:root:FL Epoch: 360 Norm Difference for worker 1489 is 0.919343
INFO:root:FL Epoch: 360 Done on worker:1489
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :50
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.777391
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.536529
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 360 Norm Difference for worker 50 is 0.856994
INFO:root:FL Epoch: 360 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 360 Training on worker :1221
INFO:root:FL Epoch: 360 Using Learning rate : 0.024368810261745005 
INFO:root:FL Epoch: 360 Normal Training
INFO:root:Worker: 1221 Train Epoch: 0 [0/200 (0%)]	Loss: 0.678944
INFO:root:Worker: 1221 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472048
INFO:root:FL Epoch: 360 Norm Difference for worker 1221 is 0.852746
INFO:root:FL Epoch: 360 Done on worker:1221
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1837
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 360 Ends   ===================
INFO:root:Epoch:360 Global Model Test Loss:0.5238689043942619 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:360 Global Model Backdoor Test Loss:0.2251669466495514                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 361 Begins ===================
INFO:root:FL Epoch: 361 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 361 Workers Selected : [0, 1595, 210, 1872, 983, 1359, 374, 1036, 1442, 190]
INFO:root:FL Epoch: 361 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 361 Num points on workers: [200 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 361 Training on worker :0
INFO:root:FL Epoch: 361 Using Learning rate : 0.004864014528244303 
INFO:root:FL Epoch: 361 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308680
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.177222
INFO:root:FL Epoch: 361 Worker: 0 Backdoor Test Loss: 0.16651769851644835 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 361 Worker: 0 Backdoor Train Loss: 0.19885145500302315 Backdoor Train Accuracy: 94.5
INFO:root:FL Epoch: 361 Norm Difference for worker 0 is 0.166285
INFO:root:FL Epoch: 361 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1595
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420883
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419837
INFO:root:FL Epoch: 361 Norm Difference for worker 1595 is 0.849365
INFO:root:FL Epoch: 361 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :210
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 210 Train Epoch: 0 [0/201 (0%)]	Loss: 0.516770
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 210 Train Epoch: 1 [0/201 (0%)]	Loss: 0.511940
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 361 Norm Difference for worker 210 is 0.867838
INFO:root:FL Epoch: 361 Done on worker:210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1872
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.356204
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297168
INFO:root:FL Epoch: 361 Norm Difference for worker 1872 is 0.81302
INFO:root:FL Epoch: 361 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :983
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 983 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677613
INFO:root:Worker: 983 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528655
INFO:root:FL Epoch: 361 Norm Difference for worker 983 is 0.888041
INFO:root:FL Epoch: 361 Done on worker:983
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1359
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548112
INFO:root:Worker: 1359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475146
INFO:root:FL Epoch: 361 Norm Difference for worker 1359 is 0.870761
INFO:root:FL Epoch: 361 Done on worker:1359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :374
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695811
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515359
INFO:root:FL Epoch: 361 Norm Difference for worker 374 is 0.879874
INFO:root:FL Epoch: 361 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1036
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1036 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492950
INFO:root:Worker: 1036 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540563
INFO:root:FL Epoch: 361 Norm Difference for worker 1036 is 0.867748
INFO:root:FL Epoch: 361 Done on worker:1036
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :1442
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 1442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542285
INFO:root:Worker: 1442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263843
INFO:root:FL Epoch: 361 Norm Difference for worker 1442 is 0.841754
INFO:root:FL Epoch: 361 Done on worker:1442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 361 Training on worker :190
INFO:root:FL Epoch: 361 Using Learning rate : 0.02432007264122152 
INFO:root:FL Epoch: 361 Normal Training
INFO:root:Worker: 190 Train Epoch: 0 [0/201 (0%)]	Loss: 0.498697
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 190 Train Epoch: 1 [0/201 (0%)]	Loss: 0.396127
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 361 Norm Difference for worker 190 is 0.894458
INFO:root:FL Epoch: 361 Done on worker:190
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 361 Ends   ===================
INFO:root:Epoch:361 Global Model Test Loss:0.5221790215548348 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:361 Global Model Backdoor Test Loss:0.16651769851644835                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 362 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 362 Workers Selected : [1281, 1934, 1337, 1508, 1916, 62, 700, 698, 1722, 534]
INFO:root:FL Epoch: 362 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 362 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 362 Training on worker :1281
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1281 Train Epoch: 0 [0/200 (0%)]	Loss: 0.650575
INFO:root:Worker: 1281 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491548
INFO:root:FL Epoch: 362 Norm Difference for worker 1281 is 0.926937
INFO:root:FL Epoch: 362 Done on worker:1281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1934
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.386461
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455248
INFO:root:FL Epoch: 362 Norm Difference for worker 1934 is 0.961399
INFO:root:FL Epoch: 362 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1337
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1337 Train Epoch: 0 [0/200 (0%)]	Loss: 0.411976
INFO:root:Worker: 1337 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440615
INFO:root:FL Epoch: 362 Norm Difference for worker 1337 is 0.827499
INFO:root:FL Epoch: 362 Done on worker:1337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1508
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418325
INFO:root:Worker: 1508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.214555
INFO:root:FL Epoch: 362 Norm Difference for worker 1508 is 0.881253
INFO:root:FL Epoch: 362 Done on worker:1508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1916
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720198
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507107
INFO:root:FL Epoch: 362 Norm Difference for worker 1916 is 0.847602
INFO:root:FL Epoch: 362 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :62
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.333575
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.654212
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 362 Norm Difference for worker 62 is 0.957235
INFO:root:FL Epoch: 362 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :700
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579162
INFO:root:Worker: 700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415662
INFO:root:FL Epoch: 362 Norm Difference for worker 700 is 0.949912
INFO:root:FL Epoch: 362 Done on worker:700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :698
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419616
INFO:root:Worker: 698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.310128
INFO:root:FL Epoch: 362 Norm Difference for worker 698 is 0.98932
INFO:root:FL Epoch: 362 Done on worker:698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :1722
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 1722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743830
INFO:root:Worker: 1722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598296
INFO:root:FL Epoch: 362 Norm Difference for worker 1722 is 0.927206
INFO:root:FL Epoch: 362 Done on worker:1722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 362 Training on worker :534
INFO:root:FL Epoch: 362 Using Learning rate : 0.024271432495939074 
INFO:root:FL Epoch: 362 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655334
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553943
INFO:root:FL Epoch: 362 Norm Difference for worker 534 is 0.973214
INFO:root:FL Epoch: 362 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1337
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 362 Ends   ===================
INFO:root:Epoch:362 Global Model Test Loss:0.5280937727759866 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:362 Global Model Backdoor Test Loss:0.10743972038229306                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 363 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 363 Workers Selected : [407, 369, 1247, 757, 1543, 1753, 164, 604, 711, 447]
INFO:root:FL Epoch: 363 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 363 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 363 Training on worker :407
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 407 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618296
INFO:root:Worker: 407 Train Epoch: 1 [0/200 (0%)]	Loss: 0.585938
INFO:root:FL Epoch: 363 Norm Difference for worker 407 is 0.939334
INFO:root:FL Epoch: 363 Done on worker:407
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :369
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336036
INFO:root:Worker: 369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.744943
INFO:root:FL Epoch: 363 Norm Difference for worker 369 is 1.095595
INFO:root:FL Epoch: 363 Done on worker:369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1247
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768284
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606029
INFO:root:FL Epoch: 363 Norm Difference for worker 1247 is 0.958948
INFO:root:FL Epoch: 363 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :757
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.525277
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309161
INFO:root:FL Epoch: 363 Norm Difference for worker 757 is 0.966505
INFO:root:FL Epoch: 363 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1543
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1543 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408612
INFO:root:Worker: 1543 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562670
INFO:root:FL Epoch: 363 Norm Difference for worker 1543 is 1.008381
INFO:root:FL Epoch: 363 Done on worker:1543
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :1753
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.586605
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553848
INFO:root:FL Epoch: 363 Norm Difference for worker 1753 is 0.84634
INFO:root:FL Epoch: 363 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :164
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 164 Train Epoch: 0 [0/201 (0%)]	Loss: 0.710126
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 164 Train Epoch: 1 [0/201 (0%)]	Loss: 0.459351
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 363 Norm Difference for worker 164 is 0.951628
INFO:root:FL Epoch: 363 Done on worker:164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :604
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482613
INFO:root:Worker: 604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614306
INFO:root:FL Epoch: 363 Norm Difference for worker 604 is 0.942744
INFO:root:FL Epoch: 363 Done on worker:604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :711
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 711 Train Epoch: 0 [0/200 (0%)]	Loss: 0.854874
INFO:root:Worker: 711 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468490
INFO:root:FL Epoch: 363 Norm Difference for worker 711 is 0.988132
INFO:root:FL Epoch: 363 Done on worker:711
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 363 Training on worker :447
INFO:root:FL Epoch: 363 Using Learning rate : 0.024222889630947195 
INFO:root:FL Epoch: 363 Normal Training
INFO:root:Worker: 447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481336
INFO:root:Worker: 447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.189304
INFO:root:FL Epoch: 363 Norm Difference for worker 447 is 0.857301
INFO:root:FL Epoch: 363 Done on worker:447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1753
INFO:root:Norm of Aggregated Model: 5154.99462890625
INFO:root:Aggregating After Defense
INFO:root:================FL round 363 Ends   ===================
INFO:root:Epoch:363 Global Model Test Loss:0.5379192618762746 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:363 Global Model Backdoor Test Loss:0.18799187491337457                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 364 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 364 Workers Selected : [1315, 846, 969, 581, 1164, 383, 805, 306, 69, 504]
INFO:root:FL Epoch: 364 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.1003996 0.0999001]
INFO:root:FL Epoch: 364 Num points on workers: [200 200 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 364 Training on worker :1315
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685826
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563611
INFO:root:FL Epoch: 364 Norm Difference for worker 1315 is 0.924828
INFO:root:FL Epoch: 364 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :846
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727642
INFO:root:Worker: 846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.543125
INFO:root:FL Epoch: 364 Norm Difference for worker 846 is 0.944995
INFO:root:FL Epoch: 364 Done on worker:846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :969
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 969 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328908
INFO:root:Worker: 969 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508955
INFO:root:FL Epoch: 364 Norm Difference for worker 969 is 0.869792
INFO:root:FL Epoch: 364 Done on worker:969
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :581
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615813
INFO:root:Worker: 581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643877
INFO:root:FL Epoch: 364 Norm Difference for worker 581 is 1.039977
INFO:root:FL Epoch: 364 Done on worker:581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :1164
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 1164 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348801
INFO:root:Worker: 1164 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358767
INFO:root:FL Epoch: 364 Norm Difference for worker 1164 is 0.979629
INFO:root:FL Epoch: 364 Done on worker:1164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :383
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 383 Train Epoch: 0 [0/200 (0%)]	Loss: 0.585183
INFO:root:Worker: 383 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644859
INFO:root:FL Epoch: 364 Norm Difference for worker 383 is 0.944352
INFO:root:FL Epoch: 364 Done on worker:383
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :805
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 805 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653318
INFO:root:Worker: 805 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625975
INFO:root:FL Epoch: 364 Norm Difference for worker 805 is 0.96499
INFO:root:FL Epoch: 364 Done on worker:805
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :306
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.694703
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.474178
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 306 is 0.920936
INFO:root:FL Epoch: 364 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :69
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 69 Train Epoch: 0 [0/201 (0%)]	Loss: 0.578097
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 69 Train Epoch: 1 [0/201 (0%)]	Loss: 0.446633
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 364 Norm Difference for worker 69 is 0.874882
INFO:root:FL Epoch: 364 Done on worker:69
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 364 Training on worker :504
INFO:root:FL Epoch: 364 Using Learning rate : 0.024174443851685302 
INFO:root:FL Epoch: 364 Normal Training
INFO:root:Worker: 504 Train Epoch: 0 [0/200 (0%)]	Loss: 0.592045
INFO:root:Worker: 504 Train Epoch: 1 [0/200 (0%)]	Loss: 0.538073
INFO:root:FL Epoch: 364 Norm Difference for worker 504 is 0.961987
INFO:root:FL Epoch: 364 Done on worker:504
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 969
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 364 Ends   ===================
INFO:root:Epoch:364 Global Model Test Loss:0.5212451131904826 and Test Accuracy:72.94117647058823 
INFO:root:Epoch:364 Global Model Backdoor Test Loss:0.21547881265481314                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 365 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 365 Workers Selected : [304, 1441, 1672, 1845, 363, 1622, 230, 1819, 1574, 1527]
INFO:root:FL Epoch: 365 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 365 Num points on workers: [201 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 365 Training on worker :304
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 304 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526617
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 304 Train Epoch: 1 [0/201 (0%)]	Loss: 0.469808
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 365 Norm Difference for worker 304 is 0.847797
INFO:root:FL Epoch: 365 Done on worker:304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1441
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.790780
INFO:root:Worker: 1441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.206985
INFO:root:FL Epoch: 365 Norm Difference for worker 1441 is 0.810889
INFO:root:FL Epoch: 365 Done on worker:1441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1672
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513199
INFO:root:Worker: 1672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455185
INFO:root:FL Epoch: 365 Norm Difference for worker 1672 is 0.845448
INFO:root:FL Epoch: 365 Done on worker:1672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1845
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.576673
INFO:root:Worker: 1845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.738167
INFO:root:FL Epoch: 365 Norm Difference for worker 1845 is 0.926239
INFO:root:FL Epoch: 365 Done on worker:1845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :363
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566043
INFO:root:Worker: 363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428971
INFO:root:FL Epoch: 365 Norm Difference for worker 363 is 0.904895
INFO:root:FL Epoch: 365 Done on worker:363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1622
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.403978
INFO:root:Worker: 1622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367424
INFO:root:FL Epoch: 365 Norm Difference for worker 1622 is 0.818875
INFO:root:FL Epoch: 365 Done on worker:1622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :230
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 230 Train Epoch: 0 [0/201 (0%)]	Loss: 0.570230
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 230 Train Epoch: 1 [0/201 (0%)]	Loss: 0.400857
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 365 Norm Difference for worker 230 is 0.839955
INFO:root:FL Epoch: 365 Done on worker:230
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1819
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1819 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337764
INFO:root:Worker: 1819 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546314
INFO:root:FL Epoch: 365 Norm Difference for worker 1819 is 0.800526
INFO:root:FL Epoch: 365 Done on worker:1819
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1574
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652171
INFO:root:Worker: 1574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581030
INFO:root:FL Epoch: 365 Norm Difference for worker 1574 is 0.870371
INFO:root:FL Epoch: 365 Done on worker:1574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 365 Training on worker :1527
INFO:root:FL Epoch: 365 Using Learning rate : 0.02412609496398193 
INFO:root:FL Epoch: 365 Normal Training
INFO:root:Worker: 1527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546257
INFO:root:Worker: 1527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429858
INFO:root:FL Epoch: 365 Norm Difference for worker 1527 is 0.827652
INFO:root:FL Epoch: 365 Done on worker:1527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1441
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 365 Ends   ===================
INFO:root:Epoch:365 Global Model Test Loss:0.5159215225892908 and Test Accuracy:75.0 
INFO:root:Epoch:365 Global Model Backdoor Test Loss:0.16357426096995673                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 366 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 366 Workers Selected : [1282, 547, 362, 88, 1215, 699, 1817, 721, 1505, 1392]
INFO:root:FL Epoch: 366 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 366 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 366 Training on worker :1282
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1282 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633440
INFO:root:Worker: 1282 Train Epoch: 1 [0/200 (0%)]	Loss: 0.681935
INFO:root:FL Epoch: 366 Norm Difference for worker 1282 is 0.96425
INFO:root:FL Epoch: 366 Done on worker:1282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :547
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794667
INFO:root:Worker: 547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367198
INFO:root:FL Epoch: 366 Norm Difference for worker 547 is 0.875465
INFO:root:FL Epoch: 366 Done on worker:547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :362
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 362 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477751
INFO:root:Worker: 362 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621830
INFO:root:FL Epoch: 366 Norm Difference for worker 362 is 0.84388
INFO:root:FL Epoch: 366 Done on worker:362
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :88
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 88 Train Epoch: 0 [0/201 (0%)]	Loss: 0.623399
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 88 Train Epoch: 1 [0/201 (0%)]	Loss: 0.537814
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 366 Norm Difference for worker 88 is 0.901633
INFO:root:FL Epoch: 366 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1215
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697247
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435022
INFO:root:FL Epoch: 366 Norm Difference for worker 1215 is 0.886192
INFO:root:FL Epoch: 366 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :699
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 699 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480299
INFO:root:Worker: 699 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265458
INFO:root:FL Epoch: 366 Norm Difference for worker 699 is 0.875955
INFO:root:FL Epoch: 366 Done on worker:699
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1817
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683317
INFO:root:Worker: 1817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534225
INFO:root:FL Epoch: 366 Norm Difference for worker 1817 is 0.955579
INFO:root:FL Epoch: 366 Done on worker:1817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :721
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583698
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.582451
INFO:root:FL Epoch: 366 Norm Difference for worker 721 is 0.930505
INFO:root:FL Epoch: 366 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1505
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424859
INFO:root:Worker: 1505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456213
INFO:root:FL Epoch: 366 Norm Difference for worker 1505 is 0.93678
INFO:root:FL Epoch: 366 Done on worker:1505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 366 Training on worker :1392
INFO:root:FL Epoch: 366 Using Learning rate : 0.024077842774053965 
INFO:root:FL Epoch: 366 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408630
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348769
INFO:root:FL Epoch: 366 Norm Difference for worker 1392 is 0.799022
INFO:root:FL Epoch: 366 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1392
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 366 Ends   ===================
INFO:root:Epoch:366 Global Model Test Loss:0.5289678941754734 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:366 Global Model Backdoor Test Loss:0.23317813873291016                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 367 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 367 Workers Selected : [28, 1297, 642, 482, 1006, 235, 1107, 1117, 1251, 1507]
INFO:root:FL Epoch: 367 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 367 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 367 Training on worker :28
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 28 Train Epoch: 0 [0/201 (0%)]	Loss: 0.345537
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 28 Train Epoch: 1 [0/201 (0%)]	Loss: 0.238829
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 367 Norm Difference for worker 28 is 0.728095
INFO:root:FL Epoch: 367 Done on worker:28
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1297
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1297 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641656
INFO:root:Worker: 1297 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507506
INFO:root:FL Epoch: 367 Norm Difference for worker 1297 is 0.949024
INFO:root:FL Epoch: 367 Done on worker:1297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :642
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 642 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410467
INFO:root:Worker: 642 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523878
INFO:root:FL Epoch: 367 Norm Difference for worker 642 is 0.867501
INFO:root:FL Epoch: 367 Done on worker:642
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :482
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.305968
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345246
INFO:root:FL Epoch: 367 Norm Difference for worker 482 is 0.848368
INFO:root:FL Epoch: 367 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1006
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1006 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510788
INFO:root:Worker: 1006 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534173
INFO:root:FL Epoch: 367 Norm Difference for worker 1006 is 0.898754
INFO:root:FL Epoch: 367 Done on worker:1006
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :235
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 235 Train Epoch: 0 [0/201 (0%)]	Loss: 0.442065
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 235 Train Epoch: 1 [0/201 (0%)]	Loss: 0.605796
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 367 Norm Difference for worker 235 is 0.932604
INFO:root:FL Epoch: 367 Done on worker:235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1107
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1107 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415888
INFO:root:Worker: 1107 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372838
INFO:root:FL Epoch: 367 Norm Difference for worker 1107 is 0.854469
INFO:root:FL Epoch: 367 Done on worker:1107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1117
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1117 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600214
INFO:root:Worker: 1117 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331146
INFO:root:FL Epoch: 367 Norm Difference for worker 1117 is 0.843144
INFO:root:FL Epoch: 367 Done on worker:1117
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1251
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1251 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414443
INFO:root:Worker: 1251 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409090
INFO:root:FL Epoch: 367 Norm Difference for worker 1251 is 0.894132
INFO:root:FL Epoch: 367 Done on worker:1251
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 367 Training on worker :1507
INFO:root:FL Epoch: 367 Using Learning rate : 0.02402968708850586 
INFO:root:FL Epoch: 367 Normal Training
INFO:root:Worker: 1507 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494851
INFO:root:Worker: 1507 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277683
INFO:root:FL Epoch: 367 Norm Difference for worker 1507 is 0.843431
INFO:root:FL Epoch: 367 Done on worker:1507
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 28
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 367 Ends   ===================
INFO:root:Epoch:367 Global Model Test Loss:0.5313175180379082 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:367 Global Model Backdoor Test Loss:0.22058538595835367                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 368 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 368 Workers Selected : [1439, 84, 559, 1478, 521, 480, 1137, 1277, 1078, 1907]
INFO:root:FL Epoch: 368 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 368 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 368 Training on worker :1439
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564335
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323967
INFO:root:FL Epoch: 368 Norm Difference for worker 1439 is 0.870209
INFO:root:FL Epoch: 368 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :84
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 84 Train Epoch: 0 [0/201 (0%)]	Loss: 0.470563
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 84 Train Epoch: 1 [0/201 (0%)]	Loss: 0.332565
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 368 Norm Difference for worker 84 is 0.867121
INFO:root:FL Epoch: 368 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :559
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522000
INFO:root:Worker: 559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467603
INFO:root:FL Epoch: 368 Norm Difference for worker 559 is 0.870832
INFO:root:FL Epoch: 368 Done on worker:559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1478
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.230313
INFO:root:Worker: 1478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343588
INFO:root:FL Epoch: 368 Norm Difference for worker 1478 is 0.67377
INFO:root:FL Epoch: 368 Done on worker:1478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :521
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474676
INFO:root:Worker: 521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.698368
INFO:root:FL Epoch: 368 Norm Difference for worker 521 is 0.905133
INFO:root:FL Epoch: 368 Done on worker:521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :480
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368713
INFO:root:Worker: 480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476971
INFO:root:FL Epoch: 368 Norm Difference for worker 480 is 0.87615
INFO:root:FL Epoch: 368 Done on worker:480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1137
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417239
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461231
INFO:root:FL Epoch: 368 Norm Difference for worker 1137 is 0.901173
INFO:root:FL Epoch: 368 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1277
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.706553
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346084
INFO:root:FL Epoch: 368 Norm Difference for worker 1277 is 0.870103
INFO:root:FL Epoch: 368 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1078
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689333
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636091
INFO:root:FL Epoch: 368 Norm Difference for worker 1078 is 0.901105
INFO:root:FL Epoch: 368 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 368 Training on worker :1907
INFO:root:FL Epoch: 368 Using Learning rate : 0.023981627714328848 
INFO:root:FL Epoch: 368 Normal Training
INFO:root:Worker: 1907 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393716
INFO:root:Worker: 1907 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431358
INFO:root:FL Epoch: 368 Norm Difference for worker 1907 is 0.863433
INFO:root:FL Epoch: 368 Done on worker:1907
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1478
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 368 Ends   ===================
INFO:root:Epoch:368 Global Model Test Loss:0.5473000477342045 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:368 Global Model Backdoor Test Loss:0.11846598361929257                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 369 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 369 Workers Selected : [1905, 1263, 518, 696, 1863, 463, 713, 486, 405, 745]
INFO:root:FL Epoch: 369 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 369 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 369 Training on worker :1905
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694933
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539157
INFO:root:FL Epoch: 369 Norm Difference for worker 1905 is 1.045209
INFO:root:FL Epoch: 369 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :1263
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1263 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542677
INFO:root:Worker: 1263 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315938
INFO:root:FL Epoch: 369 Norm Difference for worker 1263 is 1.181171
INFO:root:FL Epoch: 369 Done on worker:1263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :518
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 518 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560481
INFO:root:Worker: 518 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408375
INFO:root:FL Epoch: 369 Norm Difference for worker 518 is 1.255999
INFO:root:FL Epoch: 369 Done on worker:518
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :696
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766964
INFO:root:Worker: 696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.615093
INFO:root:FL Epoch: 369 Norm Difference for worker 696 is 1.190737
INFO:root:FL Epoch: 369 Done on worker:696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :1863
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 1863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.282843
INFO:root:Worker: 1863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247812
INFO:root:FL Epoch: 369 Norm Difference for worker 1863 is 1.05673
INFO:root:FL Epoch: 369 Done on worker:1863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :463
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.943730
INFO:root:Worker: 463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494023
INFO:root:FL Epoch: 369 Norm Difference for worker 463 is 1.182543
INFO:root:FL Epoch: 369 Done on worker:463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :713
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.770517
INFO:root:Worker: 713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691294
INFO:root:FL Epoch: 369 Norm Difference for worker 713 is 1.235557
INFO:root:FL Epoch: 369 Done on worker:713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :486
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.913151
INFO:root:Worker: 486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.313825
INFO:root:FL Epoch: 369 Norm Difference for worker 486 is 1.132901
INFO:root:FL Epoch: 369 Done on worker:486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :405
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 405 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404357
INFO:root:Worker: 405 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637425
INFO:root:FL Epoch: 369 Norm Difference for worker 405 is 1.019733
INFO:root:FL Epoch: 369 Done on worker:405
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 369 Training on worker :745
INFO:root:FL Epoch: 369 Using Learning rate : 0.02393366445890019 
INFO:root:FL Epoch: 369 Normal Training
INFO:root:Worker: 745 Train Epoch: 0 [0/200 (0%)]	Loss: 0.924871
INFO:root:Worker: 745 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550001
INFO:root:FL Epoch: 369 Norm Difference for worker 745 is 1.159576
INFO:root:FL Epoch: 369 Done on worker:745
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 405
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 369 Ends   ===================
INFO:root:Epoch:369 Global Model Test Loss:0.549709661918528 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:369 Global Model Backdoor Test Loss:0.18817760795354843                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 370 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 370 Workers Selected : [780, 927, 1453, 453, 1403, 497, 644, 892, 788, 851]
INFO:root:FL Epoch: 370 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 370 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 370 Training on worker :780
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 780 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589578
INFO:root:Worker: 780 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571229
INFO:root:FL Epoch: 370 Norm Difference for worker 780 is 1.077003
INFO:root:FL Epoch: 370 Done on worker:780
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :927
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.454130
INFO:root:Worker: 927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302510
INFO:root:FL Epoch: 370 Norm Difference for worker 927 is 0.837495
INFO:root:FL Epoch: 370 Done on worker:927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :1453
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.336554
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397483
INFO:root:FL Epoch: 370 Norm Difference for worker 1453 is 1.007163
INFO:root:FL Epoch: 370 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :453
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534577
INFO:root:Worker: 453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436179
INFO:root:FL Epoch: 370 Norm Difference for worker 453 is 0.993282
INFO:root:FL Epoch: 370 Done on worker:453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :1403
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449741
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481386
INFO:root:FL Epoch: 370 Norm Difference for worker 1403 is 1.029606
INFO:root:FL Epoch: 370 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :497
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.394299
INFO:root:Worker: 497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320370
INFO:root:FL Epoch: 370 Norm Difference for worker 497 is 0.790933
INFO:root:FL Epoch: 370 Done on worker:497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :644
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562770
INFO:root:Worker: 644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.512863
INFO:root:FL Epoch: 370 Norm Difference for worker 644 is 1.02507
INFO:root:FL Epoch: 370 Done on worker:644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :892
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.227912
INFO:root:Worker: 892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.172450
INFO:root:FL Epoch: 370 Norm Difference for worker 892 is 0.846147
INFO:root:FL Epoch: 370 Done on worker:892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :788
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568572
INFO:root:Worker: 788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422032
INFO:root:FL Epoch: 370 Norm Difference for worker 788 is 1.050843
INFO:root:FL Epoch: 370 Done on worker:788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 370 Training on worker :851
INFO:root:FL Epoch: 370 Using Learning rate : 0.02388579712998239 
INFO:root:FL Epoch: 370 Normal Training
INFO:root:Worker: 851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406137
INFO:root:Worker: 851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340697
INFO:root:FL Epoch: 370 Norm Difference for worker 851 is 0.919637
INFO:root:FL Epoch: 370 Done on worker:851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 497
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 370 Ends   ===================
INFO:root:Epoch:370 Global Model Test Loss:0.5914506719392889 and Test Accuracy:71.76470588235294 
INFO:root:Epoch:370 Global Model Backdoor Test Loss:0.2593703245123227                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 371 Begins ===================
INFO:root:FL Epoch: 371 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 371 Workers Selected : [0, 1101, 1238, 938, 270, 1297, 1135, 425, 547, 1827]
INFO:root:FL Epoch: 371 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 371 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 371 Training on worker :0
INFO:root:FL Epoch: 371 Using Learning rate : 0.0047676051071444845 
INFO:root:FL Epoch: 371 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.197608
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.157453
INFO:root:FL Epoch: 371 Worker: 0 Backdoor Test Loss: 0.18490072588125864 Backdoor Test Accuracy: 94.16666666666667
INFO:root:FL Epoch: 371 Worker: 0 Backdoor Train Loss: 0.153441409021616 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 371 Norm Difference for worker 0 is 0.160294
INFO:root:FL Epoch: 371 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1101
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1101 Train Epoch: 0 [0/200 (0%)]	Loss: 0.887764
INFO:root:Worker: 1101 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529911
INFO:root:FL Epoch: 371 Norm Difference for worker 1101 is 1.088854
INFO:root:FL Epoch: 371 Done on worker:1101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1238
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1238 Train Epoch: 0 [0/200 (0%)]	Loss: 0.895305
INFO:root:Worker: 1238 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431631
INFO:root:FL Epoch: 371 Norm Difference for worker 1238 is 1.103649
INFO:root:FL Epoch: 371 Done on worker:1238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :938
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.893386
INFO:root:Worker: 938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468982
INFO:root:FL Epoch: 371 Norm Difference for worker 938 is 1.106536
INFO:root:FL Epoch: 371 Done on worker:938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :270
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 270 Train Epoch: 0 [0/201 (0%)]	Loss: 0.622389
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 270 Train Epoch: 1 [0/201 (0%)]	Loss: 0.201197
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 371 Norm Difference for worker 270 is 1.003204
INFO:root:FL Epoch: 371 Done on worker:270
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1297
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1297 Train Epoch: 0 [0/200 (0%)]	Loss: 0.898256
INFO:root:Worker: 1297 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436040
INFO:root:FL Epoch: 371 Norm Difference for worker 1297 is 1.117087
INFO:root:FL Epoch: 371 Done on worker:1297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1135
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1135 Train Epoch: 0 [0/200 (0%)]	Loss: 0.849627
INFO:root:Worker: 1135 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475006
INFO:root:FL Epoch: 371 Norm Difference for worker 1135 is 1.104082
INFO:root:FL Epoch: 371 Done on worker:1135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :425
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581173
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366626
INFO:root:FL Epoch: 371 Norm Difference for worker 425 is 1.191098
INFO:root:FL Epoch: 371 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :547
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 547 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414980
INFO:root:Worker: 547 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539695
INFO:root:FL Epoch: 371 Norm Difference for worker 547 is 1.071358
INFO:root:FL Epoch: 371 Done on worker:547
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 371 Training on worker :1827
INFO:root:FL Epoch: 371 Using Learning rate : 0.023838025535722424 
INFO:root:FL Epoch: 371 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 1.046974
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.508435
INFO:root:FL Epoch: 371 Norm Difference for worker 1827 is 1.001921
INFO:root:FL Epoch: 371 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 371 Ends   ===================
INFO:root:Epoch:371 Global Model Test Loss:0.5674486721263212 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:371 Global Model Backdoor Test Loss:0.18490072588125864                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 372 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 372 Workers Selected : [1361, 1326, 693, 1881, 1858, 1072, 906, 1818, 732, 1528]
INFO:root:FL Epoch: 372 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 372 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 372 Training on worker :1361
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1361 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516518
INFO:root:Worker: 1361 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455680
INFO:root:FL Epoch: 372 Norm Difference for worker 1361 is 1.129566
INFO:root:FL Epoch: 372 Done on worker:1361
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1326
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1326 Train Epoch: 0 [0/200 (0%)]	Loss: 0.931328
INFO:root:Worker: 1326 Train Epoch: 1 [0/200 (0%)]	Loss: 0.877191
INFO:root:FL Epoch: 372 Norm Difference for worker 1326 is 1.216307
INFO:root:FL Epoch: 372 Done on worker:1326
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :693
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.237921
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265018
INFO:root:FL Epoch: 372 Norm Difference for worker 693 is 0.871726
INFO:root:FL Epoch: 372 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1881
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421807
INFO:root:Worker: 1881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349424
INFO:root:FL Epoch: 372 Norm Difference for worker 1881 is 0.934962
INFO:root:FL Epoch: 372 Done on worker:1881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1858
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.816829
INFO:root:Worker: 1858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537277
INFO:root:FL Epoch: 372 Norm Difference for worker 1858 is 1.168505
INFO:root:FL Epoch: 372 Done on worker:1858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1072
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1072 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598269
INFO:root:Worker: 1072 Train Epoch: 1 [0/200 (0%)]	Loss: 0.732672
INFO:root:FL Epoch: 372 Norm Difference for worker 1072 is 1.052956
INFO:root:FL Epoch: 372 Done on worker:1072
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :906
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 906 Train Epoch: 0 [0/200 (0%)]	Loss: 0.421485
INFO:root:Worker: 906 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465539
INFO:root:FL Epoch: 372 Norm Difference for worker 906 is 1.04293
INFO:root:FL Epoch: 372 Done on worker:906
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1818
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.850159
INFO:root:Worker: 1818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378341
INFO:root:FL Epoch: 372 Norm Difference for worker 1818 is 1.061028
INFO:root:FL Epoch: 372 Done on worker:1818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :732
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 732 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597325
INFO:root:Worker: 732 Train Epoch: 1 [0/200 (0%)]	Loss: 0.480509
INFO:root:FL Epoch: 372 Norm Difference for worker 732 is 1.158016
INFO:root:FL Epoch: 372 Done on worker:732
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 372 Training on worker :1528
INFO:root:FL Epoch: 372 Using Learning rate : 0.023790349484650978 
INFO:root:FL Epoch: 372 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580586
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429154
INFO:root:FL Epoch: 372 Norm Difference for worker 1528 is 1.097791
INFO:root:FL Epoch: 372 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 693
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 372 Ends   ===================
INFO:root:Epoch:372 Global Model Test Loss:0.556527456816505 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:372 Global Model Backdoor Test Loss:0.1825546696782112                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 373 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 373 Workers Selected : [551, 314, 848, 898, 211, 204, 914, 1880, 865, 1933]
INFO:root:FL Epoch: 373 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 373 Num points on workers: [200 201 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 373 Training on worker :551
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535991
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536229
INFO:root:FL Epoch: 373 Norm Difference for worker 551 is 0.836862
INFO:root:FL Epoch: 373 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :314
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 314 Train Epoch: 0 [0/201 (0%)]	Loss: 0.394872
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 314 Train Epoch: 1 [0/201 (0%)]	Loss: 0.314935
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 373 Norm Difference for worker 314 is 1.096817
INFO:root:FL Epoch: 373 Done on worker:314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :848
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688553
INFO:root:Worker: 848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281852
INFO:root:FL Epoch: 373 Norm Difference for worker 848 is 1.116424
INFO:root:FL Epoch: 373 Done on worker:848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :898
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 898 Train Epoch: 0 [0/200 (0%)]	Loss: 0.859562
INFO:root:Worker: 898 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411072
INFO:root:FL Epoch: 373 Norm Difference for worker 898 is 1.135693
INFO:root:FL Epoch: 373 Done on worker:898
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :211
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.597033
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.650059
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 373 Norm Difference for worker 211 is 1.112647
INFO:root:FL Epoch: 373 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :204
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.458088
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.471272
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 373 Norm Difference for worker 204 is 1.125729
INFO:root:FL Epoch: 373 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :914
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.771704
INFO:root:Worker: 914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292470
INFO:root:FL Epoch: 373 Norm Difference for worker 914 is 1.16223
INFO:root:FL Epoch: 373 Done on worker:914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1880
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615370
INFO:root:Worker: 1880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608411
INFO:root:FL Epoch: 373 Norm Difference for worker 1880 is 1.105728
INFO:root:FL Epoch: 373 Done on worker:1880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :865
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492352
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274544
INFO:root:FL Epoch: 373 Norm Difference for worker 865 is 1.023477
INFO:root:FL Epoch: 373 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 373 Training on worker :1933
INFO:root:FL Epoch: 373 Using Learning rate : 0.023742768785681677 
INFO:root:FL Epoch: 373 Normal Training
INFO:root:Worker: 1933 Train Epoch: 0 [0/200 (0%)]	Loss: 0.834493
INFO:root:Worker: 1933 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444430
INFO:root:FL Epoch: 373 Norm Difference for worker 1933 is 1.108354
INFO:root:FL Epoch: 373 Done on worker:1933
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 551
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 373 Ends   ===================
INFO:root:Epoch:373 Global Model Test Loss:0.5660684091203353 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:373 Global Model Backdoor Test Loss:0.19591721519827843                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 374 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 374 Workers Selected : [1359, 866, 1152, 1536, 772, 517, 722, 1277, 238, 560]
INFO:root:FL Epoch: 374 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 374 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 374 Training on worker :1359
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653443
INFO:root:Worker: 1359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269023
INFO:root:FL Epoch: 374 Norm Difference for worker 1359 is 1.103405
INFO:root:FL Epoch: 374 Done on worker:1359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :866
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670636
INFO:root:Worker: 866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685689
INFO:root:FL Epoch: 374 Norm Difference for worker 866 is 1.116902
INFO:root:FL Epoch: 374 Done on worker:866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1152
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1152 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476598
INFO:root:Worker: 1152 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360067
INFO:root:FL Epoch: 374 Norm Difference for worker 1152 is 1.03101
INFO:root:FL Epoch: 374 Done on worker:1152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1536
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656917
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307179
INFO:root:FL Epoch: 374 Norm Difference for worker 1536 is 1.08025
INFO:root:FL Epoch: 374 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :772
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393585
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489171
INFO:root:FL Epoch: 374 Norm Difference for worker 772 is 1.131659
INFO:root:FL Epoch: 374 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :517
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 517 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472819
INFO:root:Worker: 517 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527880
INFO:root:FL Epoch: 374 Norm Difference for worker 517 is 1.116283
INFO:root:FL Epoch: 374 Done on worker:517
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :722
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490122
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557839
INFO:root:FL Epoch: 374 Norm Difference for worker 722 is 1.050305
INFO:root:FL Epoch: 374 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :1277
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 1277 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353966
INFO:root:Worker: 1277 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290060
INFO:root:FL Epoch: 374 Norm Difference for worker 1277 is 1.06288
INFO:root:FL Epoch: 374 Done on worker:1277
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :238
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 238 Train Epoch: 0 [0/201 (0%)]	Loss: 0.746154
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 238 Train Epoch: 1 [0/201 (0%)]	Loss: 0.373447
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 374 Norm Difference for worker 238 is 1.080747
INFO:root:FL Epoch: 374 Done on worker:238
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 374 Training on worker :560
INFO:root:FL Epoch: 374 Using Learning rate : 0.023695283248110315 
INFO:root:FL Epoch: 374 Normal Training
INFO:root:Worker: 560 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490617
INFO:root:Worker: 560 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407966
INFO:root:FL Epoch: 374 Norm Difference for worker 560 is 1.053733
INFO:root:FL Epoch: 374 Done on worker:560
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 560
INFO:root:Norm of Aggregated Model: 5154.9951171875
INFO:root:Aggregating After Defense
INFO:root:================FL round 374 Ends   ===================
INFO:root:Epoch:374 Global Model Test Loss:0.5081208821605233 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:374 Global Model Backdoor Test Loss:0.18085821345448494                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 375 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 375 Workers Selected : [1377, 709, 1920, 196, 622, 1043, 1142, 1449, 647, 510]
INFO:root:FL Epoch: 375 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 375 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 375 Training on worker :1377
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1377 Train Epoch: 0 [0/200 (0%)]	Loss: 0.566747
INFO:root:Worker: 1377 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541609
INFO:root:FL Epoch: 375 Norm Difference for worker 1377 is 0.96687
INFO:root:FL Epoch: 375 Done on worker:1377
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :709
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.962659
INFO:root:Worker: 709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565680
INFO:root:FL Epoch: 375 Norm Difference for worker 709 is 0.940915
INFO:root:FL Epoch: 375 Done on worker:709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1920
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1920 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647337
INFO:root:Worker: 1920 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527202
INFO:root:FL Epoch: 375 Norm Difference for worker 1920 is 0.91025
INFO:root:FL Epoch: 375 Done on worker:1920
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :196
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.659015
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.529552
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 375 Norm Difference for worker 196 is 0.860041
INFO:root:FL Epoch: 375 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :622
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664266
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439345
INFO:root:FL Epoch: 375 Norm Difference for worker 622 is 0.888876
INFO:root:FL Epoch: 375 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1043
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1043 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595182
INFO:root:Worker: 1043 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409722
INFO:root:FL Epoch: 375 Norm Difference for worker 1043 is 0.917561
INFO:root:FL Epoch: 375 Done on worker:1043
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1142
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1142 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794918
INFO:root:Worker: 1142 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531962
INFO:root:FL Epoch: 375 Norm Difference for worker 1142 is 0.950191
INFO:root:FL Epoch: 375 Done on worker:1142
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :1449
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.468074
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386801
INFO:root:FL Epoch: 375 Norm Difference for worker 1449 is 0.914361
INFO:root:FL Epoch: 375 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :647
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774969
INFO:root:Worker: 647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557827
INFO:root:FL Epoch: 375 Norm Difference for worker 647 is 0.948151
INFO:root:FL Epoch: 375 Done on worker:647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 375 Training on worker :510
INFO:root:FL Epoch: 375 Using Learning rate : 0.023647892681614092 
INFO:root:FL Epoch: 375 Normal Training
INFO:root:Worker: 510 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490541
INFO:root:Worker: 510 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485473
INFO:root:FL Epoch: 375 Norm Difference for worker 510 is 0.949103
INFO:root:FL Epoch: 375 Done on worker:510
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 196
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 375 Ends   ===================
INFO:root:Epoch:375 Global Model Test Loss:0.5043850208030027 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:375 Global Model Backdoor Test Loss:0.15835142259796461                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 376 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 376 Workers Selected : [1210, 1922, 714, 158, 425, 1771, 1670, 1315, 357, 1550]
INFO:root:FL Epoch: 376 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 376 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 376 Training on worker :1210
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1210 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538613
INFO:root:Worker: 1210 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628586
INFO:root:FL Epoch: 376 Norm Difference for worker 1210 is 0.888653
INFO:root:FL Epoch: 376 Done on worker:1210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1922
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1922 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442757
INFO:root:Worker: 1922 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366083
INFO:root:FL Epoch: 376 Norm Difference for worker 1922 is 0.84862
INFO:root:FL Epoch: 376 Done on worker:1922
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :714
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 714 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408638
INFO:root:Worker: 714 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553211
INFO:root:FL Epoch: 376 Norm Difference for worker 714 is 0.906014
INFO:root:FL Epoch: 376 Done on worker:714
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :158
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 158 Train Epoch: 0 [0/201 (0%)]	Loss: 0.775902
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 158 Train Epoch: 1 [0/201 (0%)]	Loss: 0.649941
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 376 Norm Difference for worker 158 is 0.930955
INFO:root:FL Epoch: 376 Done on worker:158
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :425
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577110
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492641
INFO:root:FL Epoch: 376 Norm Difference for worker 425 is 0.909009
INFO:root:FL Epoch: 376 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1771
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1771 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674056
INFO:root:Worker: 1771 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680012
INFO:root:FL Epoch: 376 Norm Difference for worker 1771 is 0.88961
INFO:root:FL Epoch: 376 Done on worker:1771
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1670
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783837
INFO:root:Worker: 1670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447090
INFO:root:FL Epoch: 376 Norm Difference for worker 1670 is 0.899958
INFO:root:FL Epoch: 376 Done on worker:1670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1315
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.340092
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501573
INFO:root:FL Epoch: 376 Norm Difference for worker 1315 is 0.867614
INFO:root:FL Epoch: 376 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :357
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402151
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407595
INFO:root:FL Epoch: 376 Norm Difference for worker 357 is 0.85615
INFO:root:FL Epoch: 376 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 376 Training on worker :1550
INFO:root:FL Epoch: 376 Using Learning rate : 0.023600596896250867 
INFO:root:FL Epoch: 376 Normal Training
INFO:root:Worker: 1550 Train Epoch: 0 [0/200 (0%)]	Loss: 0.286440
INFO:root:Worker: 1550 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468015
INFO:root:FL Epoch: 376 Norm Difference for worker 1550 is 0.841544
INFO:root:FL Epoch: 376 Done on worker:1550
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1922
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 376 Ends   ===================
INFO:root:Epoch:376 Global Model Test Loss:0.531046590384315 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:376 Global Model Backdoor Test Loss:0.22480681414405504                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 377 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 377 Workers Selected : [261, 1412, 1534, 1686, 1111, 211, 782, 1708, 931, 867]
INFO:root:FL Epoch: 377 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 377 Num points on workers: [201 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 377 Training on worker :261
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 261 Train Epoch: 0 [0/201 (0%)]	Loss: 0.644218
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 261 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488638
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 261 is 1.003511
INFO:root:FL Epoch: 377 Done on worker:261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1412
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1412 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488510
INFO:root:Worker: 1412 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276239
INFO:root:FL Epoch: 377 Norm Difference for worker 1412 is 1.022766
INFO:root:FL Epoch: 377 Done on worker:1412
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1534
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376042
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351944
INFO:root:FL Epoch: 377 Norm Difference for worker 1534 is 0.935419
INFO:root:FL Epoch: 377 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1686
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1686 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364629
INFO:root:Worker: 1686 Train Epoch: 1 [0/200 (0%)]	Loss: 0.370632
INFO:root:FL Epoch: 377 Norm Difference for worker 1686 is 0.960458
INFO:root:FL Epoch: 377 Done on worker:1686
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1111
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1111 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655968
INFO:root:Worker: 1111 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367927
INFO:root:FL Epoch: 377 Norm Difference for worker 1111 is 0.898899
INFO:root:FL Epoch: 377 Done on worker:1111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :211
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 211 Train Epoch: 0 [0/201 (0%)]	Loss: 0.540393
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 211 Train Epoch: 1 [0/201 (0%)]	Loss: 0.497572
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 377 Norm Difference for worker 211 is 0.966137
INFO:root:FL Epoch: 377 Done on worker:211
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :782
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794307
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420038
INFO:root:FL Epoch: 377 Norm Difference for worker 782 is 1.02956
INFO:root:FL Epoch: 377 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :1708
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 1708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444164
INFO:root:Worker: 1708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444019
INFO:root:FL Epoch: 377 Norm Difference for worker 1708 is 0.90415
INFO:root:FL Epoch: 377 Done on worker:1708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :931
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.279033
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541411
INFO:root:FL Epoch: 377 Norm Difference for worker 931 is 0.936366
INFO:root:FL Epoch: 377 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 377 Training on worker :867
INFO:root:FL Epoch: 377 Using Learning rate : 0.023553395702458364 
INFO:root:FL Epoch: 377 Normal Training
INFO:root:Worker: 867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772257
INFO:root:Worker: 867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287064
INFO:root:FL Epoch: 377 Norm Difference for worker 867 is 0.927588
INFO:root:FL Epoch: 377 Done on worker:867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1111
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 377 Ends   ===================
INFO:root:Epoch:377 Global Model Test Loss:0.49973288704367247 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:377 Global Model Backdoor Test Loss:0.19899753977855048                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 378 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 378 Workers Selected : [1609, 1341, 1364, 864, 597, 1265, 234, 1249, 105, 1453]
INFO:root:FL Epoch: 378 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 378 Num points on workers: [200 200 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 378 Training on worker :1609
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444779
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546539
INFO:root:FL Epoch: 378 Norm Difference for worker 1609 is 0.856788
INFO:root:FL Epoch: 378 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1341
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1341 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533166
INFO:root:Worker: 1341 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449764
INFO:root:FL Epoch: 378 Norm Difference for worker 1341 is 0.829995
INFO:root:FL Epoch: 378 Done on worker:1341
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1364
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543047
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336651
INFO:root:FL Epoch: 378 Norm Difference for worker 1364 is 0.840925
INFO:root:FL Epoch: 378 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :864
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500945
INFO:root:Worker: 864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455399
INFO:root:FL Epoch: 378 Norm Difference for worker 864 is 0.827048
INFO:root:FL Epoch: 378 Done on worker:864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :597
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536087
INFO:root:Worker: 597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505379
INFO:root:FL Epoch: 378 Norm Difference for worker 597 is 0.804731
INFO:root:FL Epoch: 378 Done on worker:597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1265
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309141
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489012
INFO:root:FL Epoch: 378 Norm Difference for worker 1265 is 0.776491
INFO:root:FL Epoch: 378 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :234
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 234 Train Epoch: 0 [0/201 (0%)]	Loss: 0.392850
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 234 Train Epoch: 1 [0/201 (0%)]	Loss: 0.554667
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 378 Norm Difference for worker 234 is 0.901104
INFO:root:FL Epoch: 378 Done on worker:234
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1249
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1249 Train Epoch: 0 [0/200 (0%)]	Loss: 0.871890
INFO:root:Worker: 1249 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436250
INFO:root:FL Epoch: 378 Norm Difference for worker 1249 is 0.944295
INFO:root:FL Epoch: 378 Done on worker:1249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :105
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.662862
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.531412
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 378 Norm Difference for worker 105 is 0.883091
INFO:root:FL Epoch: 378 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 378 Training on worker :1453
INFO:root:FL Epoch: 378 Using Learning rate : 0.023506288911053445 
INFO:root:FL Epoch: 378 Normal Training
INFO:root:Worker: 1453 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657169
INFO:root:Worker: 1453 Train Epoch: 1 [0/200 (0%)]	Loss: 0.420309
INFO:root:FL Epoch: 378 Norm Difference for worker 1453 is 0.835252
INFO:root:FL Epoch: 378 Done on worker:1453
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1265
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 378 Ends   ===================
INFO:root:Epoch:378 Global Model Test Loss:0.49590861622024984 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:378 Global Model Backdoor Test Loss:0.25223998228708905                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 379 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 379 Workers Selected : [1896, 1462, 896, 1014, 411, 744, 655, 1912, 1807, 25]
INFO:root:FL Epoch: 379 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 379 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 379 Training on worker :1896
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.399437
INFO:root:Worker: 1896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.624645
INFO:root:FL Epoch: 379 Norm Difference for worker 1896 is 0.833069
INFO:root:FL Epoch: 379 Done on worker:1896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :1462
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420736
INFO:root:Worker: 1462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648984
INFO:root:FL Epoch: 379 Norm Difference for worker 1462 is 0.860902
INFO:root:FL Epoch: 379 Done on worker:1462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :896
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575697
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456098
INFO:root:FL Epoch: 379 Norm Difference for worker 896 is 0.774167
INFO:root:FL Epoch: 379 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :1014
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1014 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466009
INFO:root:Worker: 1014 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501164
INFO:root:FL Epoch: 379 Norm Difference for worker 1014 is 0.78834
INFO:root:FL Epoch: 379 Done on worker:1014
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :411
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 411 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455211
INFO:root:Worker: 411 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545162
INFO:root:FL Epoch: 379 Norm Difference for worker 411 is 0.826418
INFO:root:FL Epoch: 379 Done on worker:411
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :744
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602888
INFO:root:Worker: 744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.595991
INFO:root:FL Epoch: 379 Norm Difference for worker 744 is 0.813389
INFO:root:FL Epoch: 379 Done on worker:744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :655
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472007
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442264
INFO:root:FL Epoch: 379 Norm Difference for worker 655 is 0.82182
INFO:root:FL Epoch: 379 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :1912
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492337
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349369
INFO:root:FL Epoch: 379 Norm Difference for worker 1912 is 0.8063
INFO:root:FL Epoch: 379 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :1807
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 1807 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529494
INFO:root:Worker: 1807 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517012
INFO:root:FL Epoch: 379 Norm Difference for worker 1807 is 0.764261
INFO:root:FL Epoch: 379 Done on worker:1807
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 379 Training on worker :25
INFO:root:FL Epoch: 379 Using Learning rate : 0.02345927633323134 
INFO:root:FL Epoch: 379 Normal Training
INFO:root:Worker: 25 Train Epoch: 0 [0/201 (0%)]	Loss: 0.355567
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 25 Train Epoch: 1 [0/201 (0%)]	Loss: 0.454885
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 379 Norm Difference for worker 25 is 0.723148
INFO:root:FL Epoch: 379 Done on worker:25
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 25
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 379 Ends   ===================
INFO:root:Epoch:379 Global Model Test Loss:0.5000074961606193 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:379 Global Model Backdoor Test Loss:0.1869390606880188                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 380 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 380 Workers Selected : [634, 1146, 1013, 1030, 609, 1932, 1268, 1882, 1892, 1182]
INFO:root:FL Epoch: 380 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 380 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 380 Training on worker :634
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.829911
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339357
INFO:root:FL Epoch: 380 Norm Difference for worker 634 is 0.84292
INFO:root:FL Epoch: 380 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1146
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1146 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402010
INFO:root:Worker: 1146 Train Epoch: 1 [0/200 (0%)]	Loss: 0.613576
INFO:root:FL Epoch: 380 Norm Difference for worker 1146 is 0.883217
INFO:root:FL Epoch: 380 Done on worker:1146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1013
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1013 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426533
INFO:root:Worker: 1013 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631677
INFO:root:FL Epoch: 380 Norm Difference for worker 1013 is 0.844049
INFO:root:FL Epoch: 380 Done on worker:1013
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1030
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1030 Train Epoch: 0 [0/200 (0%)]	Loss: 0.633960
INFO:root:Worker: 1030 Train Epoch: 1 [0/200 (0%)]	Loss: 0.684202
INFO:root:FL Epoch: 380 Norm Difference for worker 1030 is 0.969165
INFO:root:FL Epoch: 380 Done on worker:1030
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :609
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622441
INFO:root:Worker: 609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579989
INFO:root:FL Epoch: 380 Norm Difference for worker 609 is 0.869769
INFO:root:FL Epoch: 380 Done on worker:609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1932
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.414881
INFO:root:Worker: 1932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330738
INFO:root:FL Epoch: 380 Norm Difference for worker 1932 is 0.794352
INFO:root:FL Epoch: 380 Done on worker:1932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1268
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1268 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346211
INFO:root:Worker: 1268 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354232
INFO:root:FL Epoch: 380 Norm Difference for worker 1268 is 0.881152
INFO:root:FL Epoch: 380 Done on worker:1268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1882
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.250177
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246319
INFO:root:FL Epoch: 380 Norm Difference for worker 1882 is 0.759966
INFO:root:FL Epoch: 380 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1892
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1892 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552250
INFO:root:Worker: 1892 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369264
INFO:root:FL Epoch: 380 Norm Difference for worker 1892 is 0.884566
INFO:root:FL Epoch: 380 Done on worker:1892
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 380 Training on worker :1182
INFO:root:FL Epoch: 380 Using Learning rate : 0.02341235778056488 
INFO:root:FL Epoch: 380 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462867
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445183
INFO:root:FL Epoch: 380 Norm Difference for worker 1182 is 0.810615
INFO:root:FL Epoch: 380 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1932
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 380 Ends   ===================
INFO:root:Epoch:380 Global Model Test Loss:0.4917289807515986 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:380 Global Model Backdoor Test Loss:0.24196192622184753                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 381 Begins ===================
INFO:root:FL Epoch: 381 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 381 Workers Selected : [0, 1916, 1346, 50, 1946, 1820, 1554, 1848, 151, 286]
INFO:root:FL Epoch: 381 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 381 Num points on workers: [200 200 200 201 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 381 Training on worker :0
INFO:root:FL Epoch: 381 Using Learning rate : 0.00467310661300075 
INFO:root:FL Epoch: 381 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.220227
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.210257
INFO:root:FL Epoch: 381 Worker: 0 Backdoor Test Loss: 0.18273264666398367 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 381 Worker: 0 Backdoor Train Loss: 0.18988319262862205 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 381 Norm Difference for worker 0 is 0.15463
INFO:root:FL Epoch: 381 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1916
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.693948
INFO:root:Worker: 1916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440988
INFO:root:FL Epoch: 381 Norm Difference for worker 1916 is 0.77563
INFO:root:FL Epoch: 381 Done on worker:1916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1346
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603311
INFO:root:Worker: 1346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499827
INFO:root:FL Epoch: 381 Norm Difference for worker 1346 is 0.773574
INFO:root:FL Epoch: 381 Done on worker:1346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :50
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.439252
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.359001
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 381 Norm Difference for worker 50 is 0.856717
INFO:root:FL Epoch: 381 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1946
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.927718
INFO:root:Worker: 1946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270046
INFO:root:FL Epoch: 381 Norm Difference for worker 1946 is 0.754461
INFO:root:FL Epoch: 381 Done on worker:1946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1820
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575730
INFO:root:Worker: 1820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306353
INFO:root:FL Epoch: 381 Norm Difference for worker 1820 is 0.856817
INFO:root:FL Epoch: 381 Done on worker:1820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1554
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561200
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620484
INFO:root:FL Epoch: 381 Norm Difference for worker 1554 is 0.816724
INFO:root:FL Epoch: 381 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :1848
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 1848 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327740
INFO:root:Worker: 1848 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440025
INFO:root:FL Epoch: 381 Norm Difference for worker 1848 is 0.711288
INFO:root:FL Epoch: 381 Done on worker:1848
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :151
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.448338
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.529685
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 381 Norm Difference for worker 151 is 0.902799
INFO:root:FL Epoch: 381 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 381 Training on worker :286
INFO:root:FL Epoch: 381 Using Learning rate : 0.023365533065003746 
INFO:root:FL Epoch: 381 Normal Training
INFO:root:Worker: 286 Train Epoch: 0 [0/201 (0%)]	Loss: 0.368725
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 286 Train Epoch: 1 [0/201 (0%)]	Loss: 0.497431
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 381 Norm Difference for worker 286 is 0.776809
INFO:root:FL Epoch: 381 Done on worker:286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 381 Ends   ===================
INFO:root:Epoch:381 Global Model Test Loss:0.4895439954365001 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:381 Global Model Backdoor Test Loss:0.18273264666398367                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 382 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 382 Workers Selected : [484, 9, 1065, 1863, 450, 452, 634, 160, 7, 1146]
INFO:root:FL Epoch: 382 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 382 Num points on workers: [200 201 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 382 Training on worker :484
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495290
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556503
INFO:root:FL Epoch: 382 Norm Difference for worker 484 is 0.935997
INFO:root:FL Epoch: 382 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :9
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.526503
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.472891
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 382 Norm Difference for worker 9 is 0.839283
INFO:root:FL Epoch: 382 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1065
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476877
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528465
INFO:root:FL Epoch: 382 Norm Difference for worker 1065 is 0.920782
INFO:root:FL Epoch: 382 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1863
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401299
INFO:root:Worker: 1863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337457
INFO:root:FL Epoch: 382 Norm Difference for worker 1863 is 0.816304
INFO:root:FL Epoch: 382 Done on worker:1863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :450
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 450 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357976
INFO:root:Worker: 450 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539871
INFO:root:FL Epoch: 382 Norm Difference for worker 450 is 0.776563
INFO:root:FL Epoch: 382 Done on worker:450
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :452
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.358740
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491219
INFO:root:FL Epoch: 382 Norm Difference for worker 452 is 0.855107
INFO:root:FL Epoch: 382 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :634
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440481
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.241490
INFO:root:FL Epoch: 382 Norm Difference for worker 634 is 0.812809
INFO:root:FL Epoch: 382 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :160
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.683617
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.423237
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 382 Norm Difference for worker 160 is 0.892522
INFO:root:FL Epoch: 382 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :7
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 7 Train Epoch: 0 [0/201 (0%)]	Loss: 0.520092
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 7 Train Epoch: 1 [0/201 (0%)]	Loss: 0.439041
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 382 Norm Difference for worker 7 is 0.82645
INFO:root:FL Epoch: 382 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 382 Training on worker :1146
INFO:root:FL Epoch: 382 Using Learning rate : 0.02331880199887374 
INFO:root:FL Epoch: 382 Normal Training
INFO:root:Worker: 1146 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531917
INFO:root:Worker: 1146 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465113
INFO:root:FL Epoch: 382 Norm Difference for worker 1146 is 0.905914
INFO:root:FL Epoch: 382 Done on worker:1146
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 450
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 382 Ends   ===================
INFO:root:Epoch:382 Global Model Test Loss:0.49316609431715575 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:382 Global Model Backdoor Test Loss:0.1834458832939466                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 383 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 383 Workers Selected : [997, 747, 720, 1026, 1339, 1380, 541, 562, 1757, 1939]
INFO:root:FL Epoch: 383 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 383 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 383 Training on worker :997
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 997 Train Epoch: 0 [0/200 (0%)]	Loss: 0.312414
INFO:root:Worker: 997 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430824
INFO:root:FL Epoch: 383 Norm Difference for worker 997 is 0.840558
INFO:root:FL Epoch: 383 Done on worker:997
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :747
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 747 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502638
INFO:root:Worker: 747 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568031
INFO:root:FL Epoch: 383 Norm Difference for worker 747 is 0.893866
INFO:root:FL Epoch: 383 Done on worker:747
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :720
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 720 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409678
INFO:root:Worker: 720 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694741
INFO:root:FL Epoch: 383 Norm Difference for worker 720 is 0.769694
INFO:root:FL Epoch: 383 Done on worker:720
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1026
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1026 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564906
INFO:root:Worker: 1026 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514651
INFO:root:FL Epoch: 383 Norm Difference for worker 1026 is 0.872875
INFO:root:FL Epoch: 383 Done on worker:1026
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1339
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1339 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419523
INFO:root:Worker: 1339 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498381
INFO:root:FL Epoch: 383 Norm Difference for worker 1339 is 0.824255
INFO:root:FL Epoch: 383 Done on worker:1339
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1380
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1380 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580075
INFO:root:Worker: 1380 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462039
INFO:root:FL Epoch: 383 Norm Difference for worker 1380 is 0.854554
INFO:root:FL Epoch: 383 Done on worker:1380
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :541
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.330612
INFO:root:Worker: 541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426139
INFO:root:FL Epoch: 383 Norm Difference for worker 541 is 0.841924
INFO:root:FL Epoch: 383 Done on worker:541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :562
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605346
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259493
INFO:root:FL Epoch: 383 Norm Difference for worker 562 is 0.852912
INFO:root:FL Epoch: 383 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1757
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.413420
INFO:root:Worker: 1757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690987
INFO:root:FL Epoch: 383 Norm Difference for worker 1757 is 0.859752
INFO:root:FL Epoch: 383 Done on worker:1757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 383 Training on worker :1939
INFO:root:FL Epoch: 383 Using Learning rate : 0.02327216439487599 
INFO:root:FL Epoch: 383 Normal Training
INFO:root:Worker: 1939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538212
INFO:root:Worker: 1939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448501
INFO:root:FL Epoch: 383 Norm Difference for worker 1939 is 0.880553
INFO:root:FL Epoch: 383 Done on worker:1939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 720
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 383 Ends   ===================
INFO:root:Epoch:383 Global Model Test Loss:0.48747699576265674 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:383 Global Model Backdoor Test Loss:0.18569242457548776                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 384 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 384 Workers Selected : [534, 432, 19, 1595, 725, 1044, 591, 1579, 937, 820]
INFO:root:FL Epoch: 384 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 384 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 384 Training on worker :534
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788219
INFO:root:Worker: 534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505538
INFO:root:FL Epoch: 384 Norm Difference for worker 534 is 0.88
INFO:root:FL Epoch: 384 Done on worker:534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :432
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 432 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430375
INFO:root:Worker: 432 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432326
INFO:root:FL Epoch: 384 Norm Difference for worker 432 is 0.760764
INFO:root:FL Epoch: 384 Done on worker:432
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :19
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 19 Train Epoch: 0 [0/201 (0%)]	Loss: 0.706669
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 19 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505344
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 384 Norm Difference for worker 19 is 0.831173
INFO:root:FL Epoch: 384 Done on worker:19
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1595
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1595 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326203
INFO:root:Worker: 1595 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597341
INFO:root:FL Epoch: 384 Norm Difference for worker 1595 is 0.826224
INFO:root:FL Epoch: 384 Done on worker:1595
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :725
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 725 Train Epoch: 0 [0/200 (0%)]	Loss: 0.582436
INFO:root:Worker: 725 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338887
INFO:root:FL Epoch: 384 Norm Difference for worker 725 is 0.856634
INFO:root:FL Epoch: 384 Done on worker:725
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1044
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1044 Train Epoch: 0 [0/200 (0%)]	Loss: 0.367944
INFO:root:Worker: 1044 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354986
INFO:root:FL Epoch: 384 Norm Difference for worker 1044 is 0.791669
INFO:root:FL Epoch: 384 Done on worker:1044
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :591
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640746
INFO:root:Worker: 591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629683
INFO:root:FL Epoch: 384 Norm Difference for worker 591 is 0.892326
INFO:root:FL Epoch: 384 Done on worker:591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :1579
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 1579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.937893
INFO:root:Worker: 1579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465803
INFO:root:FL Epoch: 384 Norm Difference for worker 1579 is 0.922856
INFO:root:FL Epoch: 384 Done on worker:1579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :937
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492231
INFO:root:Worker: 937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260172
INFO:root:FL Epoch: 384 Norm Difference for worker 937 is 0.821057
INFO:root:FL Epoch: 384 Done on worker:937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 384 Training on worker :820
INFO:root:FL Epoch: 384 Using Learning rate : 0.02322562006608624 
INFO:root:FL Epoch: 384 Normal Training
INFO:root:Worker: 820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.891379
INFO:root:Worker: 820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486158
INFO:root:FL Epoch: 384 Norm Difference for worker 820 is 0.757185
INFO:root:FL Epoch: 384 Done on worker:820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 820
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 384 Ends   ===================
INFO:root:Epoch:384 Global Model Test Loss:0.49728112361010385 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:384 Global Model Backdoor Test Loss:0.16570643583933511                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 385 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 385 Workers Selected : [987, 27, 1596, 730, 1396, 1179, 722, 344, 1209, 107]
INFO:root:FL Epoch: 385 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 385 Num points on workers: [200 201 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 385 Training on worker :987
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 987 Train Epoch: 0 [0/200 (0%)]	Loss: 0.442729
INFO:root:Worker: 987 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298525
INFO:root:FL Epoch: 385 Norm Difference for worker 987 is 0.881434
INFO:root:FL Epoch: 385 Done on worker:987
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :27
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 27 Train Epoch: 0 [0/201 (0%)]	Loss: 0.563024
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 27 Train Epoch: 1 [0/201 (0%)]	Loss: 0.571516
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 385 Norm Difference for worker 27 is 0.855728
INFO:root:FL Epoch: 385 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1596
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412032
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400526
INFO:root:FL Epoch: 385 Norm Difference for worker 1596 is 0.83729
INFO:root:FL Epoch: 385 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :730
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692049
INFO:root:Worker: 730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346933
INFO:root:FL Epoch: 385 Norm Difference for worker 730 is 0.888996
INFO:root:FL Epoch: 385 Done on worker:730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1396
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1396 Train Epoch: 0 [0/200 (0%)]	Loss: 0.311584
INFO:root:Worker: 1396 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579333
INFO:root:FL Epoch: 385 Norm Difference for worker 1396 is 0.87663
INFO:root:FL Epoch: 385 Done on worker:1396
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1179
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1179 Train Epoch: 0 [0/200 (0%)]	Loss: 0.213706
INFO:root:Worker: 1179 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479072
INFO:root:FL Epoch: 385 Norm Difference for worker 1179 is 0.797465
INFO:root:FL Epoch: 385 Done on worker:1179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :722
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 722 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657099
INFO:root:Worker: 722 Train Epoch: 1 [0/200 (0%)]	Loss: 0.473798
INFO:root:FL Epoch: 385 Norm Difference for worker 722 is 0.863795
INFO:root:FL Epoch: 385 Done on worker:722
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :344
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549528
INFO:root:Worker: 344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.596373
INFO:root:FL Epoch: 385 Norm Difference for worker 344 is 0.919393
INFO:root:FL Epoch: 385 Done on worker:344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :1209
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 1209 Train Epoch: 0 [0/200 (0%)]	Loss: 0.793753
INFO:root:Worker: 1209 Train Epoch: 1 [0/200 (0%)]	Loss: 0.301247
INFO:root:FL Epoch: 385 Norm Difference for worker 1209 is 0.846471
INFO:root:FL Epoch: 385 Done on worker:1209
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 385 Training on worker :107
INFO:root:FL Epoch: 385 Using Learning rate : 0.02317916882595407 
INFO:root:FL Epoch: 385 Normal Training
INFO:root:Worker: 107 Train Epoch: 0 [0/201 (0%)]	Loss: 0.539645
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 107 Train Epoch: 1 [0/201 (0%)]	Loss: 0.593798
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 385 Norm Difference for worker 107 is 0.918097
INFO:root:FL Epoch: 385 Done on worker:107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1179
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 385 Ends   ===================
INFO:root:Epoch:385 Global Model Test Loss:0.4766773230889264 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:385 Global Model Backdoor Test Loss:0.12943512573838234                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 386 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 386 Workers Selected : [615, 820, 1215, 1018, 418, 897, 1602, 281, 1367, 176]
INFO:root:FL Epoch: 386 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.1003996]
INFO:root:FL Epoch: 386 Num points on workers: [200 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 386 Training on worker :615
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 615 Train Epoch: 0 [0/200 (0%)]	Loss: 0.388906
INFO:root:Worker: 615 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400091
INFO:root:FL Epoch: 386 Norm Difference for worker 615 is 0.878444
INFO:root:FL Epoch: 386 Done on worker:615
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :820
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 820 Train Epoch: 0 [0/200 (0%)]	Loss: 0.181670
INFO:root:Worker: 820 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377761
INFO:root:FL Epoch: 386 Norm Difference for worker 820 is 0.686095
INFO:root:FL Epoch: 386 Done on worker:820
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1215
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1215 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412725
INFO:root:Worker: 1215 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521377
INFO:root:FL Epoch: 386 Norm Difference for worker 1215 is 0.908348
INFO:root:FL Epoch: 386 Done on worker:1215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1018
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1018 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593541
INFO:root:Worker: 1018 Train Epoch: 1 [0/200 (0%)]	Loss: 0.316374
INFO:root:FL Epoch: 386 Norm Difference for worker 1018 is 0.966746
INFO:root:FL Epoch: 386 Done on worker:1018
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :418
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715318
INFO:root:Worker: 418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527840
INFO:root:FL Epoch: 386 Norm Difference for worker 418 is 0.980011
INFO:root:FL Epoch: 386 Done on worker:418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :897
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457307
INFO:root:Worker: 897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521018
INFO:root:FL Epoch: 386 Norm Difference for worker 897 is 0.911908
INFO:root:FL Epoch: 386 Done on worker:897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1602
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1602 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628031
INFO:root:Worker: 1602 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469007
INFO:root:FL Epoch: 386 Norm Difference for worker 1602 is 0.972651
INFO:root:FL Epoch: 386 Done on worker:1602
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :281
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 281 Train Epoch: 0 [0/201 (0%)]	Loss: 0.467148
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 281 Train Epoch: 1 [0/201 (0%)]	Loss: 0.489505
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 386 Norm Difference for worker 281 is 0.802424
INFO:root:FL Epoch: 386 Done on worker:281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :1367
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 1367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.580684
INFO:root:Worker: 1367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631074
INFO:root:FL Epoch: 386 Norm Difference for worker 1367 is 1.009663
INFO:root:FL Epoch: 386 Done on worker:1367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 386 Training on worker :176
INFO:root:FL Epoch: 386 Using Learning rate : 0.02313281048830216 
INFO:root:FL Epoch: 386 Normal Training
INFO:root:Worker: 176 Train Epoch: 0 [0/201 (0%)]	Loss: 0.417212
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 176 Train Epoch: 1 [0/201 (0%)]	Loss: 0.372880
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 386 Norm Difference for worker 176 is 0.902992
INFO:root:FL Epoch: 386 Done on worker:176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 820
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 386 Ends   ===================
INFO:root:Epoch:386 Global Model Test Loss:0.5133663389612647 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:386 Global Model Backdoor Test Loss:0.12724542245268822                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 387 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 387 Workers Selected : [964, 655, 838, 597, 481, 1791, 1480, 1352, 1062, 1614]
INFO:root:FL Epoch: 387 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 387 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 387 Training on worker :964
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 964 Train Epoch: 0 [0/200 (0%)]	Loss: 0.515359
INFO:root:Worker: 964 Train Epoch: 1 [0/200 (0%)]	Loss: 0.311457
INFO:root:FL Epoch: 387 Norm Difference for worker 964 is 1.081428
INFO:root:FL Epoch: 387 Done on worker:964
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :655
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.366000
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429854
INFO:root:FL Epoch: 387 Norm Difference for worker 655 is 1.009755
INFO:root:FL Epoch: 387 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :838
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509931
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436072
INFO:root:FL Epoch: 387 Norm Difference for worker 838 is 1.036917
INFO:root:FL Epoch: 387 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :597
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.326345
INFO:root:Worker: 597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.584227
INFO:root:FL Epoch: 387 Norm Difference for worker 597 is 0.987086
INFO:root:FL Epoch: 387 Done on worker:597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :481
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431450
INFO:root:Worker: 481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490498
INFO:root:FL Epoch: 387 Norm Difference for worker 481 is 1.049118
INFO:root:FL Epoch: 387 Done on worker:481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1791
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.648073
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.816681
INFO:root:FL Epoch: 387 Norm Difference for worker 1791 is 1.037432
INFO:root:FL Epoch: 387 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1480
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1480 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547731
INFO:root:Worker: 1480 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246928
INFO:root:FL Epoch: 387 Norm Difference for worker 1480 is 1.057605
INFO:root:FL Epoch: 387 Done on worker:1480
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1352
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640736
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413423
INFO:root:FL Epoch: 387 Norm Difference for worker 1352 is 1.110537
INFO:root:FL Epoch: 387 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1062
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1062 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602323
INFO:root:Worker: 1062 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497746
INFO:root:FL Epoch: 387 Norm Difference for worker 1062 is 1.067706
INFO:root:FL Epoch: 387 Done on worker:1062
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 387 Training on worker :1614
INFO:root:FL Epoch: 387 Using Learning rate : 0.023086544867325556 
INFO:root:FL Epoch: 387 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.718954
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478270
INFO:root:FL Epoch: 387 Norm Difference for worker 1614 is 1.139909
INFO:root:FL Epoch: 387 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 597
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 387 Ends   ===================
INFO:root:Epoch:387 Global Model Test Loss:0.5102148143684163 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:387 Global Model Backdoor Test Loss:0.19517923891544342                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 388 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 388 Workers Selected : [456, 226, 972, 422, 184, 42, 199, 707, 394, 473]
INFO:root:FL Epoch: 388 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.0998004 0.1002994 0.1002994 0.1002994
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 388 Num points on workers: [200 201 200 200 201 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 388 Training on worker :456
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360444
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285865
INFO:root:FL Epoch: 388 Norm Difference for worker 456 is 0.85277
INFO:root:FL Epoch: 388 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :226
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.462967
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.530023
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 388 Norm Difference for worker 226 is 0.910916
INFO:root:FL Epoch: 388 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :972
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 972 Train Epoch: 0 [0/200 (0%)]	Loss: 0.820170
INFO:root:Worker: 972 Train Epoch: 1 [0/200 (0%)]	Loss: 0.483779
INFO:root:FL Epoch: 388 Norm Difference for worker 972 is 0.892988
INFO:root:FL Epoch: 388 Done on worker:972
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :422
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481409
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636519
INFO:root:FL Epoch: 388 Norm Difference for worker 422 is 0.896032
INFO:root:FL Epoch: 388 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :184
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.472967
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.323625
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 388 Norm Difference for worker 184 is 0.827205
INFO:root:FL Epoch: 388 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :42
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 42 Train Epoch: 0 [0/201 (0%)]	Loss: 0.426877
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 42 Train Epoch: 1 [0/201 (0%)]	Loss: 0.191871
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 388 Norm Difference for worker 42 is 0.739765
INFO:root:FL Epoch: 388 Done on worker:42
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :199
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 199 Train Epoch: 0 [0/201 (0%)]	Loss: 0.343379
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 199 Train Epoch: 1 [0/201 (0%)]	Loss: 0.325714
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 388 Norm Difference for worker 199 is 0.911753
INFO:root:FL Epoch: 388 Done on worker:199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :707
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 707 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671621
INFO:root:Worker: 707 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410744
INFO:root:FL Epoch: 388 Norm Difference for worker 707 is 0.874192
INFO:root:FL Epoch: 388 Done on worker:707
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :394
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523217
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474970
INFO:root:FL Epoch: 388 Norm Difference for worker 394 is 0.943034
INFO:root:FL Epoch: 388 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 388 Training on worker :473
INFO:root:FL Epoch: 388 Using Learning rate : 0.023040371777590902 
INFO:root:FL Epoch: 388 Normal Training
INFO:root:Worker: 473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711937
INFO:root:Worker: 473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501059
INFO:root:FL Epoch: 388 Norm Difference for worker 473 is 0.913419
INFO:root:FL Epoch: 388 Done on worker:473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 42
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 388 Ends   ===================
INFO:root:Epoch:388 Global Model Test Loss:0.4944295181947596 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:388 Global Model Backdoor Test Loss:0.1320595989624659                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 389 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 389 Workers Selected : [936, 1280, 269, 403, 127, 999, 951, 1040, 255, 80]
INFO:root:FL Epoch: 389 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.1002994 0.0998004 0.0998004
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 389 Num points on workers: [200 200 201 200 201 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 389 Training on worker :936
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649195
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550383
INFO:root:FL Epoch: 389 Norm Difference for worker 936 is 0.976197
INFO:root:FL Epoch: 389 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1280
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1280 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656297
INFO:root:Worker: 1280 Train Epoch: 1 [0/200 (0%)]	Loss: 0.269619
INFO:root:FL Epoch: 389 Norm Difference for worker 1280 is 0.902168
INFO:root:FL Epoch: 389 Done on worker:1280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :269
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 269 Train Epoch: 0 [0/201 (0%)]	Loss: 0.553983
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 269 Train Epoch: 1 [0/201 (0%)]	Loss: 0.325793
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 389 Norm Difference for worker 269 is 0.914655
INFO:root:FL Epoch: 389 Done on worker:269
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :403
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629222
INFO:root:Worker: 403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525684
INFO:root:FL Epoch: 389 Norm Difference for worker 403 is 1.053173
INFO:root:FL Epoch: 389 Done on worker:403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :127
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 127 Train Epoch: 0 [0/201 (0%)]	Loss: 0.388419
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 127 Train Epoch: 1 [0/201 (0%)]	Loss: 0.477928
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 389 Norm Difference for worker 127 is 0.9086
INFO:root:FL Epoch: 389 Done on worker:127
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :999
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 999 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667594
INFO:root:Worker: 999 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482866
INFO:root:FL Epoch: 389 Norm Difference for worker 999 is 0.967602
INFO:root:FL Epoch: 389 Done on worker:999
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :951
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.787061
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419652
INFO:root:FL Epoch: 389 Norm Difference for worker 951 is 0.9534
INFO:root:FL Epoch: 389 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :1040
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.516789
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346834
INFO:root:FL Epoch: 389 Norm Difference for worker 1040 is 1.000514
INFO:root:FL Epoch: 389 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :255
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 255 Train Epoch: 0 [0/201 (0%)]	Loss: 0.479357
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 255 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415183
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 389 Norm Difference for worker 255 is 0.936401
INFO:root:FL Epoch: 389 Done on worker:255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 389 Training on worker :80
INFO:root:FL Epoch: 389 Using Learning rate : 0.022994291034035722 
INFO:root:FL Epoch: 389 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.309232
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.304045
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 389 Norm Difference for worker 80 is 0.807788
INFO:root:FL Epoch: 389 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 80
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 389 Ends   ===================
INFO:root:Epoch:389 Global Model Test Loss:0.5050358316477608 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:389 Global Model Backdoor Test Loss:0.14369055132071176                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 390 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 390 Workers Selected : [239, 423, 1867, 1044, 80, 1928, 7, 576, 231, 1578]
INFO:root:FL Epoch: 390 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 390 Num points on workers: [201 200 200 200 201 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 390 Training on worker :239
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 239 Train Epoch: 0 [0/201 (0%)]	Loss: 0.786815
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 239 Train Epoch: 1 [0/201 (0%)]	Loss: 0.611675
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 239 is 1.06537
INFO:root:FL Epoch: 390 Done on worker:239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :423
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 423 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537495
INFO:root:Worker: 423 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461511
INFO:root:FL Epoch: 390 Norm Difference for worker 423 is 1.01382
INFO:root:FL Epoch: 390 Done on worker:423
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1867
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.875955
INFO:root:Worker: 1867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628637
INFO:root:FL Epoch: 390 Norm Difference for worker 1867 is 0.919681
INFO:root:FL Epoch: 390 Done on worker:1867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1044
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1044 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534091
INFO:root:Worker: 1044 Train Epoch: 1 [0/200 (0%)]	Loss: 0.318961
INFO:root:FL Epoch: 390 Norm Difference for worker 1044 is 1.010504
INFO:root:FL Epoch: 390 Done on worker:1044
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :80
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 80 Train Epoch: 0 [0/201 (0%)]	Loss: 0.246716
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 80 Train Epoch: 1 [0/201 (0%)]	Loss: 0.179018
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 80 is 0.666884
INFO:root:FL Epoch: 390 Done on worker:80
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1928
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535131
INFO:root:Worker: 1928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378205
INFO:root:FL Epoch: 390 Norm Difference for worker 1928 is 1.010064
INFO:root:FL Epoch: 390 Done on worker:1928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :7
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 7 Train Epoch: 0 [0/201 (0%)]	Loss: 0.562921
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 7 Train Epoch: 1 [0/201 (0%)]	Loss: 0.624908
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 7 is 1.01262
INFO:root:FL Epoch: 390 Done on worker:7
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :576
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459487
INFO:root:Worker: 576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449351
INFO:root:FL Epoch: 390 Norm Difference for worker 576 is 0.97563
INFO:root:FL Epoch: 390 Done on worker:576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :231
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 231 Train Epoch: 0 [0/201 (0%)]	Loss: 0.224029
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 231 Train Epoch: 1 [0/201 (0%)]	Loss: 0.137984
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 390 Norm Difference for worker 231 is 0.725127
INFO:root:FL Epoch: 390 Done on worker:231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 390 Training on worker :1578
INFO:root:FL Epoch: 390 Using Learning rate : 0.02294830245196765 
INFO:root:FL Epoch: 390 Normal Training
INFO:root:Worker: 1578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460836
INFO:root:Worker: 1578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380919
INFO:root:FL Epoch: 390 Norm Difference for worker 1578 is 0.902534
INFO:root:FL Epoch: 390 Done on worker:1578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 80
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 390 Ends   ===================
INFO:root:Epoch:390 Global Model Test Loss:0.5329836133648368 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:390 Global Model Backdoor Test Loss:0.11290121885637443                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 391 Begins ===================
INFO:root:FL Epoch: 391 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 391 Workers Selected : [0, 1622, 1218, 1298, 1229, 1084, 1794, 37, 1835, 425]
INFO:root:FL Epoch: 391 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 391 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 391 Training on worker :0
INFO:root:FL Epoch: 391 Using Learning rate : 0.004580481169412743 
INFO:root:FL Epoch: 391 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.320818
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.135401
INFO:root:FL Epoch: 391 Worker: 0 Backdoor Test Loss: 0.1121852130939563 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 391 Worker: 0 Backdoor Train Loss: 0.13573054485023023 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 391 Norm Difference for worker 0 is 0.138703
INFO:root:FL Epoch: 391 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1622
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551516
INFO:root:Worker: 1622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354524
INFO:root:FL Epoch: 391 Norm Difference for worker 1622 is 1.092186
INFO:root:FL Epoch: 391 Done on worker:1622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1218
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348220
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281558
INFO:root:FL Epoch: 391 Norm Difference for worker 1218 is 1.124533
INFO:root:FL Epoch: 391 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1298
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1298 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445731
INFO:root:Worker: 1298 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403241
INFO:root:FL Epoch: 391 Norm Difference for worker 1298 is 1.153682
INFO:root:FL Epoch: 391 Done on worker:1298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1229
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1229 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485706
INFO:root:Worker: 1229 Train Epoch: 1 [0/200 (0%)]	Loss: 0.747690
INFO:root:FL Epoch: 391 Norm Difference for worker 1229 is 1.319767
INFO:root:FL Epoch: 391 Done on worker:1229
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1084
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.959995
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.305745
INFO:root:FL Epoch: 391 Norm Difference for worker 1084 is 1.208341
INFO:root:FL Epoch: 391 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1794
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1794 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550141
INFO:root:Worker: 1794 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354216
INFO:root:FL Epoch: 391 Norm Difference for worker 1794 is 1.25346
INFO:root:FL Epoch: 391 Done on worker:1794
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :37
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 37 Train Epoch: 0 [0/201 (0%)]	Loss: 0.670138
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 37 Train Epoch: 1 [0/201 (0%)]	Loss: 0.382951
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 391 Norm Difference for worker 37 is 1.05052
INFO:root:FL Epoch: 391 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :1835
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 1835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.496927
INFO:root:Worker: 1835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697386
INFO:root:FL Epoch: 391 Norm Difference for worker 1835 is 1.298387
INFO:root:FL Epoch: 391 Done on worker:1835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 391 Training on worker :425
INFO:root:FL Epoch: 391 Using Learning rate : 0.022902405847063715 
INFO:root:FL Epoch: 391 Normal Training
INFO:root:Worker: 425 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498383
INFO:root:Worker: 425 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629054
INFO:root:FL Epoch: 391 Norm Difference for worker 425 is 1.338186
INFO:root:FL Epoch: 391 Done on worker:425
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 391 Ends   ===================
INFO:root:Epoch:391 Global Model Test Loss:0.5474360795582042 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:391 Global Model Backdoor Test Loss:0.1121852130939563                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 392 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 392 Workers Selected : [1500, 1912, 868, 1439, 1905, 1231, 897, 851, 1693, 743]
INFO:root:FL Epoch: 392 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 392 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 392 Training on worker :1500
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 1.042055
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.811062
INFO:root:FL Epoch: 392 Norm Difference for worker 1500 is 1.273333
INFO:root:FL Epoch: 392 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1912
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1912 Train Epoch: 0 [0/200 (0%)]	Loss: 1.033329
INFO:root:Worker: 1912 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248044
INFO:root:FL Epoch: 392 Norm Difference for worker 1912 is 1.102517
INFO:root:FL Epoch: 392 Done on worker:1912
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :868
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457580
INFO:root:Worker: 868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680946
INFO:root:FL Epoch: 392 Norm Difference for worker 868 is 1.289529
INFO:root:FL Epoch: 392 Done on worker:868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1439
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1439 Train Epoch: 0 [0/200 (0%)]	Loss: 0.802245
INFO:root:Worker: 1439 Train Epoch: 1 [0/200 (0%)]	Loss: 0.388548
INFO:root:FL Epoch: 392 Norm Difference for worker 1439 is 1.260038
INFO:root:FL Epoch: 392 Done on worker:1439
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1905
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671669
INFO:root:Worker: 1905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400170
INFO:root:FL Epoch: 392 Norm Difference for worker 1905 is 1.189824
INFO:root:FL Epoch: 392 Done on worker:1905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1231
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1231 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458131
INFO:root:Worker: 1231 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532097
INFO:root:FL Epoch: 392 Norm Difference for worker 1231 is 1.210944
INFO:root:FL Epoch: 392 Done on worker:1231
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :897
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 897 Train Epoch: 0 [0/200 (0%)]	Loss: 0.727419
INFO:root:Worker: 897 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578989
INFO:root:FL Epoch: 392 Norm Difference for worker 897 is 1.271936
INFO:root:FL Epoch: 392 Done on worker:897
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :851
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427012
INFO:root:Worker: 851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493164
INFO:root:FL Epoch: 392 Norm Difference for worker 851 is 1.143691
INFO:root:FL Epoch: 392 Done on worker:851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :1693
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 1693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726580
INFO:root:Worker: 1693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406839
INFO:root:FL Epoch: 392 Norm Difference for worker 1693 is 1.237535
INFO:root:FL Epoch: 392 Done on worker:1693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 392 Training on worker :743
INFO:root:FL Epoch: 392 Using Learning rate : 0.022856601035369586 
INFO:root:FL Epoch: 392 Normal Training
INFO:root:Worker: 743 Train Epoch: 0 [0/200 (0%)]	Loss: 0.360261
INFO:root:Worker: 743 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376607
INFO:root:FL Epoch: 392 Norm Difference for worker 743 is 1.208521
INFO:root:FL Epoch: 392 Done on worker:743
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1912
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 392 Ends   ===================
INFO:root:Epoch:392 Global Model Test Loss:0.5365139596602496 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:392 Global Model Backdoor Test Loss:0.13626758133371672                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 393 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 393 Workers Selected : [962, 386, 1281, 1108, 312, 118, 1635, 1562, 152, 581]
INFO:root:FL Epoch: 393 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 393 Num points on workers: [200 200 200 200 201 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 393 Training on worker :962
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 962 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355406
INFO:root:Worker: 962 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514932
INFO:root:FL Epoch: 393 Norm Difference for worker 962 is 1.098293
INFO:root:FL Epoch: 393 Done on worker:962
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :386
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.649682
INFO:root:Worker: 386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427512
INFO:root:FL Epoch: 393 Norm Difference for worker 386 is 1.010729
INFO:root:FL Epoch: 393 Done on worker:386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1281
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1281 Train Epoch: 0 [0/200 (0%)]	Loss: 0.419364
INFO:root:Worker: 1281 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284093
INFO:root:FL Epoch: 393 Norm Difference for worker 1281 is 1.015905
INFO:root:FL Epoch: 393 Done on worker:1281
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1108
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601270
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496741
INFO:root:FL Epoch: 393 Norm Difference for worker 1108 is 1.204137
INFO:root:FL Epoch: 393 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :312
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.501605
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.806803
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 312 is 1.133448
INFO:root:FL Epoch: 393 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :118
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 118 Train Epoch: 0 [0/201 (0%)]	Loss: 0.434333
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 118 Train Epoch: 1 [0/201 (0%)]	Loss: 0.638122
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 118 is 1.063029
INFO:root:FL Epoch: 393 Done on worker:118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1635
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1635 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509109
INFO:root:Worker: 1635 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466521
INFO:root:FL Epoch: 393 Norm Difference for worker 1635 is 0.974945
INFO:root:FL Epoch: 393 Done on worker:1635
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :1562
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 1562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614923
INFO:root:Worker: 1562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383977
INFO:root:FL Epoch: 393 Norm Difference for worker 1562 is 1.051488
INFO:root:FL Epoch: 393 Done on worker:1562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :152
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 152 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685896
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 152 Train Epoch: 1 [0/201 (0%)]	Loss: 0.521880
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 393 Norm Difference for worker 152 is 1.013893
INFO:root:FL Epoch: 393 Done on worker:152
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 393 Training on worker :581
INFO:root:FL Epoch: 393 Using Learning rate : 0.02281088783329885 
INFO:root:FL Epoch: 393 Normal Training
INFO:root:Worker: 581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.912772
INFO:root:Worker: 581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636091
INFO:root:FL Epoch: 393 Norm Difference for worker 581 is 1.234692
INFO:root:FL Epoch: 393 Done on worker:581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 152
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 393 Ends   ===================
INFO:root:Epoch:393 Global Model Test Loss:0.5115935381721047 and Test Accuracy:75.0 
INFO:root:Epoch:393 Global Model Backdoor Test Loss:0.20171732952197394                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 394 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 394 Workers Selected : [1584, 1111, 826, 1561, 1704, 978, 1928, 888, 456, 744]
INFO:root:FL Epoch: 394 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 394 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 394 Training on worker :1584
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543142
INFO:root:Worker: 1584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547864
INFO:root:FL Epoch: 394 Norm Difference for worker 1584 is 0.942912
INFO:root:FL Epoch: 394 Done on worker:1584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1111
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1111 Train Epoch: 0 [0/200 (0%)]	Loss: 0.377418
INFO:root:Worker: 1111 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529198
INFO:root:FL Epoch: 394 Norm Difference for worker 1111 is 0.782316
INFO:root:FL Epoch: 394 Done on worker:1111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :826
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 826 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639872
INFO:root:Worker: 826 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482861
INFO:root:FL Epoch: 394 Norm Difference for worker 826 is 0.956562
INFO:root:FL Epoch: 394 Done on worker:826
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1561
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700964
INFO:root:Worker: 1561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514283
INFO:root:FL Epoch: 394 Norm Difference for worker 1561 is 0.959739
INFO:root:FL Epoch: 394 Done on worker:1561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1704
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505017
INFO:root:Worker: 1704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545741
INFO:root:FL Epoch: 394 Norm Difference for worker 1704 is 0.877016
INFO:root:FL Epoch: 394 Done on worker:1704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :978
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 978 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402287
INFO:root:Worker: 978 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527583
INFO:root:FL Epoch: 394 Norm Difference for worker 978 is 0.94139
INFO:root:FL Epoch: 394 Done on worker:978
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :1928
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 1928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581965
INFO:root:Worker: 1928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456484
INFO:root:FL Epoch: 394 Norm Difference for worker 1928 is 0.950947
INFO:root:FL Epoch: 394 Done on worker:1928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :888
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 888 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618310
INFO:root:Worker: 888 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651862
INFO:root:FL Epoch: 394 Norm Difference for worker 888 is 0.995806
INFO:root:FL Epoch: 394 Done on worker:888
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :456
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 456 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450559
INFO:root:Worker: 456 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481041
INFO:root:FL Epoch: 394 Norm Difference for worker 456 is 0.873311
INFO:root:FL Epoch: 394 Done on worker:456
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 394 Training on worker :744
INFO:root:FL Epoch: 394 Using Learning rate : 0.022765266057632252 
INFO:root:FL Epoch: 394 Normal Training
INFO:root:Worker: 744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660007
INFO:root:Worker: 744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264781
INFO:root:FL Epoch: 394 Norm Difference for worker 744 is 0.907269
INFO:root:FL Epoch: 394 Done on worker:744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1111
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 394 Ends   ===================
INFO:root:Epoch:394 Global Model Test Loss:0.5104617634240318 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:394 Global Model Backdoor Test Loss:0.20595565189917883                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 395 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 395 Workers Selected : [108, 1534, 1228, 1830, 525, 151, 1175, 335, 596, 472]
INFO:root:FL Epoch: 395 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 395 Num points on workers: [201 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 395 Training on worker :108
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 108 Train Epoch: 0 [0/201 (0%)]	Loss: 0.631532
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 108 Train Epoch: 1 [0/201 (0%)]	Loss: 0.251246
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 108 is 0.789072
INFO:root:FL Epoch: 395 Done on worker:108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1534
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1534 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548881
INFO:root:Worker: 1534 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493794
INFO:root:FL Epoch: 395 Norm Difference for worker 1534 is 0.926093
INFO:root:FL Epoch: 395 Done on worker:1534
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1228
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1228 Train Epoch: 0 [0/200 (0%)]	Loss: 0.680837
INFO:root:Worker: 1228 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268886
INFO:root:FL Epoch: 395 Norm Difference for worker 1228 is 0.924552
INFO:root:FL Epoch: 395 Done on worker:1228
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1830
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1830 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526877
INFO:root:Worker: 1830 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337630
INFO:root:FL Epoch: 395 Norm Difference for worker 1830 is 0.915224
INFO:root:FL Epoch: 395 Done on worker:1830
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :525
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 525 Train Epoch: 0 [0/200 (0%)]	Loss: 0.657589
INFO:root:Worker: 525 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359190
INFO:root:FL Epoch: 395 Norm Difference for worker 525 is 0.886225
INFO:root:FL Epoch: 395 Done on worker:525
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :151
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.759019
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.725905
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 151 is 0.939759
INFO:root:FL Epoch: 395 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :1175
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514099
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557927
INFO:root:FL Epoch: 395 Norm Difference for worker 1175 is 0.941553
INFO:root:FL Epoch: 395 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :335
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.451529
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.839141
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 395 Norm Difference for worker 335 is 0.938762
INFO:root:FL Epoch: 395 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :596
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501059
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518661
INFO:root:FL Epoch: 395 Norm Difference for worker 596 is 0.968025
INFO:root:FL Epoch: 395 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 395 Training on worker :472
INFO:root:FL Epoch: 395 Using Learning rate : 0.022719735525516985 
INFO:root:FL Epoch: 395 Normal Training
INFO:root:Worker: 472 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408655
INFO:root:Worker: 472 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468221
INFO:root:FL Epoch: 395 Norm Difference for worker 472 is 0.938472
INFO:root:FL Epoch: 395 Done on worker:472
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 108
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 395 Ends   ===================
INFO:root:Epoch:395 Global Model Test Loss:0.5067159095231224 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:395 Global Model Backdoor Test Loss:0.175650575508674                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 396 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 396 Workers Selected : [682, 70, 1609, 1332, 1343, 1481, 1167, 41, 294, 1440]
INFO:root:FL Epoch: 396 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.09985022 0.10034948 0.10034948 0.09985022]
INFO:root:FL Epoch: 396 Num points on workers: [200 201 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 396 Training on worker :682
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597217
INFO:root:Worker: 682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515505
INFO:root:FL Epoch: 396 Norm Difference for worker 682 is 1.051874
INFO:root:FL Epoch: 396 Done on worker:682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :70
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 70 Train Epoch: 0 [0/201 (0%)]	Loss: 0.254602
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 70 Train Epoch: 1 [0/201 (0%)]	Loss: 0.261633
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 70 is 0.856456
INFO:root:FL Epoch: 396 Done on worker:70
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1609
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1609 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619007
INFO:root:Worker: 1609 Train Epoch: 1 [0/200 (0%)]	Loss: 0.451252
INFO:root:FL Epoch: 396 Norm Difference for worker 1609 is 0.961922
INFO:root:FL Epoch: 396 Done on worker:1609
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1332
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473072
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.637460
INFO:root:FL Epoch: 396 Norm Difference for worker 1332 is 1.039889
INFO:root:FL Epoch: 396 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1343
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.219622
INFO:root:Worker: 1343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315818
INFO:root:FL Epoch: 396 Norm Difference for worker 1343 is 0.840023
INFO:root:FL Epoch: 396 Done on worker:1343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1481
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1481 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488019
INFO:root:Worker: 1481 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506869
INFO:root:FL Epoch: 396 Norm Difference for worker 1481 is 1.10041
INFO:root:FL Epoch: 396 Done on worker:1481
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1167
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1167 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635660
INFO:root:Worker: 1167 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359228
INFO:root:FL Epoch: 396 Norm Difference for worker 1167 is 0.947424
INFO:root:FL Epoch: 396 Done on worker:1167
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :41
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 41 Train Epoch: 0 [0/201 (0%)]	Loss: 0.196204
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 41 Train Epoch: 1 [0/201 (0%)]	Loss: 0.499809
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 41 is 0.917427
INFO:root:FL Epoch: 396 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :294
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 294 Train Epoch: 0 [0/201 (0%)]	Loss: 0.493642
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 294 Train Epoch: 1 [0/201 (0%)]	Loss: 0.597307
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 396 Norm Difference for worker 294 is 1.088889
INFO:root:FL Epoch: 396 Done on worker:294
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 396 Training on worker :1440
INFO:root:FL Epoch: 396 Using Learning rate : 0.022674296054465953 
INFO:root:FL Epoch: 396 Normal Training
INFO:root:Worker: 1440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.405707
INFO:root:Worker: 1440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.390252
INFO:root:FL Epoch: 396 Norm Difference for worker 1440 is 0.99213
INFO:root:FL Epoch: 396 Done on worker:1440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1343
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 396 Ends   ===================
INFO:root:Epoch:396 Global Model Test Loss:0.5116189911085016 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:396 Global Model Backdoor Test Loss:0.1577774981657664                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 397 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 397 Workers Selected : [1864, 514, 1464, 183, 1401, 1929, 1232, 1394, 1398, 126]
INFO:root:FL Epoch: 397 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 397 Num points on workers: [200 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 397 Training on worker :1864
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467064
INFO:root:Worker: 1864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.756642
INFO:root:FL Epoch: 397 Norm Difference for worker 1864 is 1.064805
INFO:root:FL Epoch: 397 Done on worker:1864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :514
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 514 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679898
INFO:root:Worker: 514 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323210
INFO:root:FL Epoch: 397 Norm Difference for worker 514 is 0.911925
INFO:root:FL Epoch: 397 Done on worker:514
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1464
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.901854
INFO:root:Worker: 1464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474015
INFO:root:FL Epoch: 397 Norm Difference for worker 1464 is 1.005906
INFO:root:FL Epoch: 397 Done on worker:1464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :183
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 183 Train Epoch: 0 [0/201 (0%)]	Loss: 0.387189
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 183 Train Epoch: 1 [0/201 (0%)]	Loss: 0.615468
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 397 Norm Difference for worker 183 is 1.131522
INFO:root:FL Epoch: 397 Done on worker:183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1401
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1401 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712078
INFO:root:Worker: 1401 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566757
INFO:root:FL Epoch: 397 Norm Difference for worker 1401 is 1.104716
INFO:root:FL Epoch: 397 Done on worker:1401
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1929
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758482
INFO:root:Worker: 1929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625637
INFO:root:FL Epoch: 397 Norm Difference for worker 1929 is 0.968344
INFO:root:FL Epoch: 397 Done on worker:1929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1232
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1232 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562632
INFO:root:Worker: 1232 Train Epoch: 1 [0/200 (0%)]	Loss: 0.235655
INFO:root:FL Epoch: 397 Norm Difference for worker 1232 is 1.073337
INFO:root:FL Epoch: 397 Done on worker:1232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1394
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.939745
INFO:root:Worker: 1394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592642
INFO:root:FL Epoch: 397 Norm Difference for worker 1394 is 1.180493
INFO:root:FL Epoch: 397 Done on worker:1394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :1398
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 1398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.344717
INFO:root:Worker: 1398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549437
INFO:root:FL Epoch: 397 Norm Difference for worker 1398 is 1.032135
INFO:root:FL Epoch: 397 Done on worker:1398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 397 Training on worker :126
INFO:root:FL Epoch: 397 Using Learning rate : 0.02262894746235702 
INFO:root:FL Epoch: 397 Normal Training
INFO:root:Worker: 126 Train Epoch: 0 [0/201 (0%)]	Loss: 0.562531
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 126 Train Epoch: 1 [0/201 (0%)]	Loss: 0.367155
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 397 Norm Difference for worker 126 is 1.077448
INFO:root:FL Epoch: 397 Done on worker:126
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 514
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 397 Ends   ===================
INFO:root:Epoch:397 Global Model Test Loss:0.48496150444535646 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:397 Global Model Backdoor Test Loss:0.15064009899894396                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 398 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 398 Workers Selected : [318, 1303, 852, 1580, 1758, 1461, 449, 1243, 1430, 671]
INFO:root:FL Epoch: 398 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 398 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 398 Training on worker :318
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.866159
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.413435
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 398 Norm Difference for worker 318 is 0.943248
INFO:root:FL Epoch: 398 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1303
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665011
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307602
INFO:root:FL Epoch: 398 Norm Difference for worker 1303 is 0.972843
INFO:root:FL Epoch: 398 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :852
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.932131
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493325
INFO:root:FL Epoch: 398 Norm Difference for worker 852 is 1.028413
INFO:root:FL Epoch: 398 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1580
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1580 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368982
INFO:root:Worker: 1580 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468178
INFO:root:FL Epoch: 398 Norm Difference for worker 1580 is 0.958211
INFO:root:FL Epoch: 398 Done on worker:1580
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1758
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.235457
INFO:root:Worker: 1758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.592557
INFO:root:FL Epoch: 398 Norm Difference for worker 1758 is 0.932259
INFO:root:FL Epoch: 398 Done on worker:1758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1461
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483378
INFO:root:Worker: 1461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.270580
INFO:root:FL Epoch: 398 Norm Difference for worker 1461 is 0.975809
INFO:root:FL Epoch: 398 Done on worker:1461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :449
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511276
INFO:root:Worker: 449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.619530
INFO:root:FL Epoch: 398 Norm Difference for worker 449 is 1.022394
INFO:root:FL Epoch: 398 Done on worker:449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1243
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1243 Train Epoch: 0 [0/200 (0%)]	Loss: 0.635742
INFO:root:Worker: 1243 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540512
INFO:root:FL Epoch: 398 Norm Difference for worker 1243 is 1.08928
INFO:root:FL Epoch: 398 Done on worker:1243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :1430
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 1430 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425887
INFO:root:Worker: 1430 Train Epoch: 1 [0/200 (0%)]	Loss: 0.502733
INFO:root:FL Epoch: 398 Norm Difference for worker 1430 is 1.046857
INFO:root:FL Epoch: 398 Done on worker:1430
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 398 Training on worker :671
INFO:root:FL Epoch: 398 Using Learning rate : 0.022583689567432307 
INFO:root:FL Epoch: 398 Normal Training
INFO:root:Worker: 671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558113
INFO:root:Worker: 671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425705
INFO:root:FL Epoch: 398 Norm Difference for worker 671 is 0.976124
INFO:root:FL Epoch: 398 Done on worker:671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 318
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 398 Ends   ===================
INFO:root:Epoch:398 Global Model Test Loss:0.5208354592323303 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:398 Global Model Backdoor Test Loss:0.2249032681186994                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 399 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 399 Workers Selected : [1183, 1761, 1858, 716, 579, 1097, 1371, 54, 928, 38]
INFO:root:FL Epoch: 399 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.0999001 0.1003996]
INFO:root:FL Epoch: 399 Num points on workers: [200 200 200 200 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 399 Training on worker :1183
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1183 Train Epoch: 0 [0/200 (0%)]	Loss: 0.215793
INFO:root:Worker: 1183 Train Epoch: 1 [0/200 (0%)]	Loss: 0.334835
INFO:root:FL Epoch: 399 Norm Difference for worker 1183 is 0.869149
INFO:root:FL Epoch: 399 Done on worker:1183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1761
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514423
INFO:root:Worker: 1761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265965
INFO:root:FL Epoch: 399 Norm Difference for worker 1761 is 0.971064
INFO:root:FL Epoch: 399 Done on worker:1761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1858
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630154
INFO:root:Worker: 1858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.563848
INFO:root:FL Epoch: 399 Norm Difference for worker 1858 is 0.975748
INFO:root:FL Epoch: 399 Done on worker:1858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :716
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.275994
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263348
INFO:root:FL Epoch: 399 Norm Difference for worker 716 is 0.787055
INFO:root:FL Epoch: 399 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :579
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716847
INFO:root:Worker: 579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489546
INFO:root:FL Epoch: 399 Norm Difference for worker 579 is 0.958771
INFO:root:FL Epoch: 399 Done on worker:579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1097
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1097 Train Epoch: 0 [0/200 (0%)]	Loss: 0.611211
INFO:root:Worker: 1097 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342742
INFO:root:FL Epoch: 399 Norm Difference for worker 1097 is 0.941064
INFO:root:FL Epoch: 399 Done on worker:1097
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :1371
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 1371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686098
INFO:root:Worker: 1371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.707447
INFO:root:FL Epoch: 399 Norm Difference for worker 1371 is 1.000389
INFO:root:FL Epoch: 399 Done on worker:1371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :54
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 54 Train Epoch: 0 [0/201 (0%)]	Loss: 0.455773
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 54 Train Epoch: 1 [0/201 (0%)]	Loss: 0.426228
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 399 Norm Difference for worker 54 is 0.938281
INFO:root:FL Epoch: 399 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :928
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441319
INFO:root:Worker: 928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.250134
INFO:root:FL Epoch: 399 Norm Difference for worker 928 is 0.797676
INFO:root:FL Epoch: 399 Done on worker:928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 399 Training on worker :38
INFO:root:FL Epoch: 399 Using Learning rate : 0.022538522188297442 
INFO:root:FL Epoch: 399 Normal Training
INFO:root:Worker: 38 Train Epoch: 0 [0/201 (0%)]	Loss: 0.679619
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 38 Train Epoch: 1 [0/201 (0%)]	Loss: 0.301424
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 399 Norm Difference for worker 38 is 0.875505
INFO:root:FL Epoch: 399 Done on worker:38
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 716
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 399 Ends   ===================
INFO:root:Epoch:399 Global Model Test Loss:0.4925478994846344 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:399 Global Model Backdoor Test Loss:0.13070968041817346                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 400 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 400 Workers Selected : [1143, 1839, 1845, 336, 83, 285, 171, 455, 113, 297]
INFO:root:FL Epoch: 400 Fraction of points on each worker in this round: [0.0997009 0.0997009 0.0997009 0.1001994 0.1001994 0.1001994 0.1001994
 0.0997009 0.1001994 0.1001994]
INFO:root:FL Epoch: 400 Num points on workers: [200 200 200 201 201 201 201 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 400 Training on worker :1143
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1143 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656578
INFO:root:Worker: 1143 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546741
INFO:root:FL Epoch: 400 Norm Difference for worker 1143 is 0.977942
INFO:root:FL Epoch: 400 Done on worker:1143
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1839
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.740923
INFO:root:Worker: 1839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427803
INFO:root:FL Epoch: 400 Norm Difference for worker 1839 is 0.982597
INFO:root:FL Epoch: 400 Done on worker:1839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :1845
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 1845 Train Epoch: 0 [0/200 (0%)]	Loss: 0.873553
INFO:root:Worker: 1845 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574887
INFO:root:FL Epoch: 400 Norm Difference for worker 1845 is 1.133096
INFO:root:FL Epoch: 400 Done on worker:1845
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :336
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 336 Train Epoch: 0 [0/201 (0%)]	Loss: 0.321584
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 336 Train Epoch: 1 [0/201 (0%)]	Loss: 0.502081
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 400 Norm Difference for worker 336 is 0.860467
INFO:root:FL Epoch: 400 Done on worker:336
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :83
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 83 Train Epoch: 0 [0/201 (0%)]	Loss: 0.438706
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 83 Train Epoch: 1 [0/201 (0%)]	Loss: 0.641641
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 400 Norm Difference for worker 83 is 0.996629
INFO:root:FL Epoch: 400 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :285
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 285 Train Epoch: 0 [0/201 (0%)]	Loss: 0.310648
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 285 Train Epoch: 1 [0/201 (0%)]	Loss: 0.317001
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 400 Norm Difference for worker 285 is 0.862228
INFO:root:FL Epoch: 400 Done on worker:285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :171
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 171 Train Epoch: 0 [0/201 (0%)]	Loss: 0.546334
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 171 Train Epoch: 1 [0/201 (0%)]	Loss: 0.594591
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 400 Norm Difference for worker 171 is 0.901705
INFO:root:FL Epoch: 400 Done on worker:171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :455
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430125
INFO:root:Worker: 455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367191
INFO:root:FL Epoch: 400 Norm Difference for worker 455 is 1.04893
INFO:root:FL Epoch: 400 Done on worker:455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :113
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 113 Train Epoch: 0 [0/201 (0%)]	Loss: 0.610889
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 113 Train Epoch: 1 [0/201 (0%)]	Loss: 0.484261
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 400 Norm Difference for worker 113 is 0.865907
INFO:root:FL Epoch: 400 Done on worker:113
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 400 Training on worker :297
INFO:root:FL Epoch: 400 Using Learning rate : 0.022493445143920848 
INFO:root:FL Epoch: 400 Normal Training
INFO:root:Worker: 297 Train Epoch: 0 [0/201 (0%)]	Loss: 0.506166
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 297 Train Epoch: 1 [0/201 (0%)]	Loss: 0.516962
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 400 Norm Difference for worker 297 is 0.961779
INFO:root:FL Epoch: 400 Done on worker:297
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 113
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 400 Ends   ===================
INFO:root:Epoch:400 Global Model Test Loss:0.4891978449681226 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:400 Global Model Backdoor Test Loss:0.20034299045801163                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 401 Begins ===================
INFO:root:FL Epoch: 401 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 401 Workers Selected : [0, 398, 864, 1499, 482, 122, 576, 1862, 463, 637]
INFO:root:FL Epoch: 401 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 401 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 401 Training on worker :0
INFO:root:FL Epoch: 401 Using Learning rate : 0.004489691650726601 
INFO:root:FL Epoch: 401 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427886
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418959
INFO:root:FL Epoch: 401 Worker: 0 Backdoor Test Loss: 0.16016270592808723 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 401 Worker: 0 Backdoor Train Loss: 0.18596562519669532 Backdoor Train Accuracy: 93.5
INFO:root:FL Epoch: 401 Norm Difference for worker 0 is 0.147728
INFO:root:FL Epoch: 401 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :398
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 398 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651310
INFO:root:Worker: 398 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514143
INFO:root:FL Epoch: 401 Norm Difference for worker 398 is 0.959865
INFO:root:FL Epoch: 401 Done on worker:398
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :864
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 864 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495457
INFO:root:Worker: 864 Train Epoch: 1 [0/200 (0%)]	Loss: 0.261760
INFO:root:FL Epoch: 401 Norm Difference for worker 864 is 0.846896
INFO:root:FL Epoch: 401 Done on worker:864
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1499
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563936
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.325995
INFO:root:FL Epoch: 401 Norm Difference for worker 1499 is 0.915218
INFO:root:FL Epoch: 401 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :482
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.839363
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635655
INFO:root:FL Epoch: 401 Norm Difference for worker 482 is 0.896301
INFO:root:FL Epoch: 401 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :122
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.478745
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.356214
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 401 Norm Difference for worker 122 is 0.852397
INFO:root:FL Epoch: 401 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :576
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 576 Train Epoch: 0 [0/200 (0%)]	Loss: 0.543351
INFO:root:Worker: 576 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472267
INFO:root:FL Epoch: 401 Norm Difference for worker 576 is 0.902111
INFO:root:FL Epoch: 401 Done on worker:576
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :1862
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 1862 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400451
INFO:root:Worker: 1862 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337965
INFO:root:FL Epoch: 401 Norm Difference for worker 1862 is 0.773633
INFO:root:FL Epoch: 401 Done on worker:1862
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :463
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.689946
INFO:root:Worker: 463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631669
INFO:root:FL Epoch: 401 Norm Difference for worker 463 is 0.892518
INFO:root:FL Epoch: 401 Done on worker:463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 401 Training on worker :637
INFO:root:FL Epoch: 401 Using Learning rate : 0.022448458253633004 
INFO:root:FL Epoch: 401 Normal Training
INFO:root:Worker: 637 Train Epoch: 0 [0/200 (0%)]	Loss: 0.800489
INFO:root:Worker: 637 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441853
INFO:root:FL Epoch: 401 Norm Difference for worker 637 is 0.974787
INFO:root:FL Epoch: 401 Done on worker:637
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 401 Ends   ===================
INFO:root:Epoch:401 Global Model Test Loss:0.49288438698824716 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:401 Global Model Backdoor Test Loss:0.16016270592808723                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 402 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 402 Workers Selected : [1565, 1941, 1371, 721, 312, 1282, 905, 1509, 778, 1914]
INFO:root:FL Epoch: 402 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 402 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 402 Training on worker :1565
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536790
INFO:root:Worker: 1565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418116
INFO:root:FL Epoch: 402 Norm Difference for worker 1565 is 0.97209
INFO:root:FL Epoch: 402 Done on worker:1565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1941
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.877714
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482705
INFO:root:FL Epoch: 402 Norm Difference for worker 1941 is 0.853542
INFO:root:FL Epoch: 402 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1371
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598157
INFO:root:Worker: 1371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412201
INFO:root:FL Epoch: 402 Norm Difference for worker 1371 is 0.982311
INFO:root:FL Epoch: 402 Done on worker:1371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :721
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452372
INFO:root:Worker: 721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540109
INFO:root:FL Epoch: 402 Norm Difference for worker 721 is 1.039088
INFO:root:FL Epoch: 402 Done on worker:721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :312
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 312 Train Epoch: 0 [0/201 (0%)]	Loss: 0.431187
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 312 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431204
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 402 Norm Difference for worker 312 is 0.9515
INFO:root:FL Epoch: 402 Done on worker:312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1282
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1282 Train Epoch: 0 [0/200 (0%)]	Loss: 0.277973
INFO:root:Worker: 1282 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640671
INFO:root:FL Epoch: 402 Norm Difference for worker 1282 is 0.946761
INFO:root:FL Epoch: 402 Done on worker:1282
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :905
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602068
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.515850
INFO:root:FL Epoch: 402 Norm Difference for worker 905 is 0.919632
INFO:root:FL Epoch: 402 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1509
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1509 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552019
INFO:root:Worker: 1509 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357419
INFO:root:FL Epoch: 402 Norm Difference for worker 1509 is 0.979705
INFO:root:FL Epoch: 402 Done on worker:1509
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :778
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 778 Train Epoch: 0 [0/200 (0%)]	Loss: 0.617774
INFO:root:Worker: 778 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298822
INFO:root:FL Epoch: 402 Norm Difference for worker 778 is 0.993338
INFO:root:FL Epoch: 402 Done on worker:778
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 402 Training on worker :1914
INFO:root:FL Epoch: 402 Using Learning rate : 0.02240356133712574 
INFO:root:FL Epoch: 402 Normal Training
INFO:root:Worker: 1914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.660488
INFO:root:Worker: 1914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.732369
INFO:root:FL Epoch: 402 Norm Difference for worker 1914 is 0.8686
INFO:root:FL Epoch: 402 Done on worker:1914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1914
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 402 Ends   ===================
INFO:root:Epoch:402 Global Model Test Loss:0.4810248034841874 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:402 Global Model Backdoor Test Loss:0.1629579539100329                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 403 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 403 Workers Selected : [835, 868, 1159, 1591, 133, 1829, 1825, 860, 656, 627]
INFO:root:FL Epoch: 403 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 403 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 403 Training on worker :835
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 835 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514252
INFO:root:Worker: 835 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641159
INFO:root:FL Epoch: 403 Norm Difference for worker 835 is 0.865988
INFO:root:FL Epoch: 403 Done on worker:835
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :868
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447419
INFO:root:Worker: 868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.548155
INFO:root:FL Epoch: 403 Norm Difference for worker 868 is 0.864667
INFO:root:FL Epoch: 403 Done on worker:868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1159
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1159 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503978
INFO:root:Worker: 1159 Train Epoch: 1 [0/200 (0%)]	Loss: 0.690338
INFO:root:FL Epoch: 403 Norm Difference for worker 1159 is 0.837765
INFO:root:FL Epoch: 403 Done on worker:1159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1591
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1591 Train Epoch: 0 [0/200 (0%)]	Loss: 0.524581
INFO:root:Worker: 1591 Train Epoch: 1 [0/200 (0%)]	Loss: 0.683001
INFO:root:FL Epoch: 403 Norm Difference for worker 1591 is 0.872766
INFO:root:FL Epoch: 403 Done on worker:1591
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :133
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 133 Train Epoch: 0 [0/201 (0%)]	Loss: 0.564253
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 133 Train Epoch: 1 [0/201 (0%)]	Loss: 0.429126
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 403 Norm Difference for worker 133 is 0.846657
INFO:root:FL Epoch: 403 Done on worker:133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1829
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.499166
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415312
INFO:root:FL Epoch: 403 Norm Difference for worker 1829 is 0.805838
INFO:root:FL Epoch: 403 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :1825
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 1825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501531
INFO:root:Worker: 1825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407240
INFO:root:FL Epoch: 403 Norm Difference for worker 1825 is 0.807002
INFO:root:FL Epoch: 403 Done on worker:1825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :860
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561142
INFO:root:Worker: 860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602978
INFO:root:FL Epoch: 403 Norm Difference for worker 860 is 0.914802
INFO:root:FL Epoch: 403 Done on worker:860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :656
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 656 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406021
INFO:root:Worker: 656 Train Epoch: 1 [0/200 (0%)]	Loss: 0.758871
INFO:root:FL Epoch: 403 Norm Difference for worker 656 is 0.926902
INFO:root:FL Epoch: 403 Done on worker:656
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 403 Training on worker :627
INFO:root:FL Epoch: 403 Using Learning rate : 0.02235875421445149 
INFO:root:FL Epoch: 403 Normal Training
INFO:root:Worker: 627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485497
INFO:root:Worker: 627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556566
INFO:root:FL Epoch: 403 Norm Difference for worker 627 is 0.807011
INFO:root:FL Epoch: 403 Done on worker:627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1829
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 403 Ends   ===================
INFO:root:Epoch:403 Global Model Test Loss:0.498086401644875 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:403 Global Model Backdoor Test Loss:0.13867242261767387                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 404 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 404 Workers Selected : [1274, 921, 960, 1317, 1064, 1260, 1220, 659, 390, 760]
INFO:root:FL Epoch: 404 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 404 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 404 Training on worker :1274
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.826975
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712474
INFO:root:FL Epoch: 404 Norm Difference for worker 1274 is 0.774468
INFO:root:FL Epoch: 404 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :921
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 921 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546993
INFO:root:Worker: 921 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518680
INFO:root:FL Epoch: 404 Norm Difference for worker 921 is 0.875281
INFO:root:FL Epoch: 404 Done on worker:921
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :960
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 960 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593334
INFO:root:Worker: 960 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580106
INFO:root:FL Epoch: 404 Norm Difference for worker 960 is 0.835511
INFO:root:FL Epoch: 404 Done on worker:960
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1317
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1317 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514367
INFO:root:Worker: 1317 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375800
INFO:root:FL Epoch: 404 Norm Difference for worker 1317 is 0.843733
INFO:root:FL Epoch: 404 Done on worker:1317
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1064
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1064 Train Epoch: 0 [0/200 (0%)]	Loss: 0.795337
INFO:root:Worker: 1064 Train Epoch: 1 [0/200 (0%)]	Loss: 0.631138
INFO:root:FL Epoch: 404 Norm Difference for worker 1064 is 0.881838
INFO:root:FL Epoch: 404 Done on worker:1064
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1260
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1260 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625046
INFO:root:Worker: 1260 Train Epoch: 1 [0/200 (0%)]	Loss: 0.818139
INFO:root:FL Epoch: 404 Norm Difference for worker 1260 is 0.80806
INFO:root:FL Epoch: 404 Done on worker:1260
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :1220
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321546
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351778
INFO:root:FL Epoch: 404 Norm Difference for worker 1220 is 0.773099
INFO:root:FL Epoch: 404 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :659
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 659 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434182
INFO:root:Worker: 659 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415925
INFO:root:FL Epoch: 404 Norm Difference for worker 659 is 0.860376
INFO:root:FL Epoch: 404 Done on worker:659
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :390
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.767526
INFO:root:Worker: 390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489402
INFO:root:FL Epoch: 404 Norm Difference for worker 390 is 0.908388
INFO:root:FL Epoch: 404 Done on worker:390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 404 Training on worker :760
INFO:root:FL Epoch: 404 Using Learning rate : 0.022314036706022583 
INFO:root:FL Epoch: 404 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.984877
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645542
INFO:root:FL Epoch: 404 Norm Difference for worker 760 is 0.824561
INFO:root:FL Epoch: 404 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1220
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 404 Ends   ===================
INFO:root:Epoch:404 Global Model Test Loss:0.49527837248409495 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:404 Global Model Backdoor Test Loss:0.19476373493671417                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 405 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 405 Workers Selected : [581, 1003, 427, 206, 1872, 351, 1199, 1701, 39, 333]
INFO:root:FL Epoch: 405 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.10034948]
INFO:root:FL Epoch: 405 Num points on workers: [200 200 200 201 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 405 Training on worker :581
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 581 Train Epoch: 0 [0/200 (0%)]	Loss: 0.900349
INFO:root:Worker: 581 Train Epoch: 1 [0/200 (0%)]	Loss: 0.633233
INFO:root:FL Epoch: 405 Norm Difference for worker 581 is 0.877316
INFO:root:FL Epoch: 405 Done on worker:581
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1003
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.640347
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384286
INFO:root:FL Epoch: 405 Norm Difference for worker 1003 is 0.74696
INFO:root:FL Epoch: 405 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :427
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404863
INFO:root:Worker: 427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466781
INFO:root:FL Epoch: 405 Norm Difference for worker 427 is 0.750617
INFO:root:FL Epoch: 405 Done on worker:427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :206
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.478895
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.627516
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 405 Norm Difference for worker 206 is 0.767635
INFO:root:FL Epoch: 405 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1872
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1872 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435429
INFO:root:Worker: 1872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.423121
INFO:root:FL Epoch: 405 Norm Difference for worker 1872 is 0.725692
INFO:root:FL Epoch: 405 Done on worker:1872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :351
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.437791
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554675
INFO:root:FL Epoch: 405 Norm Difference for worker 351 is 0.761987
INFO:root:FL Epoch: 405 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1199
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1199 Train Epoch: 0 [0/200 (0%)]	Loss: 0.612880
INFO:root:Worker: 1199 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490099
INFO:root:FL Epoch: 405 Norm Difference for worker 1199 is 0.792942
INFO:root:FL Epoch: 405 Done on worker:1199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :1701
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 1701 Train Epoch: 0 [0/200 (0%)]	Loss: 0.534014
INFO:root:Worker: 1701 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598390
INFO:root:FL Epoch: 405 Norm Difference for worker 1701 is 0.760677
INFO:root:FL Epoch: 405 Done on worker:1701
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :39
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 39 Train Epoch: 0 [0/201 (0%)]	Loss: 0.489707
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 39 Train Epoch: 1 [0/201 (0%)]	Loss: 0.555752
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 405 Norm Difference for worker 39 is 0.784024
INFO:root:FL Epoch: 405 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 405 Training on worker :333
INFO:root:FL Epoch: 405 Using Learning rate : 0.022269408632610538 
INFO:root:FL Epoch: 405 Normal Training
INFO:root:Worker: 333 Train Epoch: 0 [0/201 (0%)]	Loss: 0.363381
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 333 Train Epoch: 1 [0/201 (0%)]	Loss: 0.690628
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 405 Norm Difference for worker 333 is 0.782888
INFO:root:FL Epoch: 405 Done on worker:333
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1872
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 405 Ends   ===================
INFO:root:Epoch:405 Global Model Test Loss:0.4886285610058728 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:405 Global Model Backdoor Test Loss:0.15207303067048392                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 406 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 406 Workers Selected : [1627, 931, 290, 1587, 1055, 1594, 763, 1486, 697, 26]
INFO:root:FL Epoch: 406 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 406 Num points on workers: [200 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 406 Training on worker :1627
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.246201
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.488451
INFO:root:FL Epoch: 406 Norm Difference for worker 1627 is 0.714851
INFO:root:FL Epoch: 406 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :931
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490090
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454974
INFO:root:FL Epoch: 406 Norm Difference for worker 931 is 0.863496
INFO:root:FL Epoch: 406 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :290
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.444225
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.440563
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 406 Norm Difference for worker 290 is 0.91314
INFO:root:FL Epoch: 406 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1587
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480407
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616408
INFO:root:FL Epoch: 406 Norm Difference for worker 1587 is 0.801776
INFO:root:FL Epoch: 406 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1055
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1055 Train Epoch: 0 [0/200 (0%)]	Loss: 0.295710
INFO:root:Worker: 1055 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590665
INFO:root:FL Epoch: 406 Norm Difference for worker 1055 is 0.8557
INFO:root:FL Epoch: 406 Done on worker:1055
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1594
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1594 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380840
INFO:root:Worker: 1594 Train Epoch: 1 [0/200 (0%)]	Loss: 0.185714
INFO:root:FL Epoch: 406 Norm Difference for worker 1594 is 0.744176
INFO:root:FL Epoch: 406 Done on worker:1594
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :763
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.578139
INFO:root:Worker: 763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432070
INFO:root:FL Epoch: 406 Norm Difference for worker 763 is 0.818626
INFO:root:FL Epoch: 406 Done on worker:763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :1486
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 1486 Train Epoch: 0 [0/200 (0%)]	Loss: 0.602863
INFO:root:Worker: 1486 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564924
INFO:root:FL Epoch: 406 Norm Difference for worker 1486 is 0.860359
INFO:root:FL Epoch: 406 Done on worker:1486
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :697
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.895158
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343448
INFO:root:FL Epoch: 406 Norm Difference for worker 697 is 0.889626
INFO:root:FL Epoch: 406 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 406 Training on worker :26
INFO:root:FL Epoch: 406 Using Learning rate : 0.022224869815345317 
INFO:root:FL Epoch: 406 Normal Training
INFO:root:Worker: 26 Train Epoch: 0 [0/201 (0%)]	Loss: 0.864632
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 26 Train Epoch: 1 [0/201 (0%)]	Loss: 0.572696
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 406 Norm Difference for worker 26 is 0.878819
INFO:root:FL Epoch: 406 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1627
INFO:root:Norm of Aggregated Model: 5154.99560546875
INFO:root:Aggregating After Defense
INFO:root:================FL round 406 Ends   ===================
INFO:root:Epoch:406 Global Model Test Loss:0.508420903893078 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:406 Global Model Backdoor Test Loss:0.16000081350406012                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 407 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 407 Workers Selected : [512, 1791, 1106, 280, 206, 865, 327, 944, 1276, 734]
INFO:root:FL Epoch: 407 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.09985022 0.10034948 0.10034948 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 407 Num points on workers: [200 200 200 201 201 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 407 Training on worker :512
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 512 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668726
INFO:root:Worker: 512 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374824
INFO:root:FL Epoch: 407 Norm Difference for worker 512 is 0.876653
INFO:root:FL Epoch: 407 Done on worker:512
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1791
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627341
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315295
INFO:root:FL Epoch: 407 Norm Difference for worker 1791 is 0.887526
INFO:root:FL Epoch: 407 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1106
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1106 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375468
INFO:root:Worker: 1106 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504651
INFO:root:FL Epoch: 407 Norm Difference for worker 1106 is 0.854527
INFO:root:FL Epoch: 407 Done on worker:1106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :280
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 280 Train Epoch: 0 [0/201 (0%)]	Loss: 0.619202
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 280 Train Epoch: 1 [0/201 (0%)]	Loss: 0.313378
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 407 Norm Difference for worker 280 is 0.840277
INFO:root:FL Epoch: 407 Done on worker:280
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :206
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 206 Train Epoch: 0 [0/201 (0%)]	Loss: 0.628950
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 206 Train Epoch: 1 [0/201 (0%)]	Loss: 0.677047
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 407 Norm Difference for worker 206 is 0.863835
INFO:root:FL Epoch: 407 Done on worker:206
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :865
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.625722
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439520
INFO:root:FL Epoch: 407 Norm Difference for worker 865 is 0.813135
INFO:root:FL Epoch: 407 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :327
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 327 Train Epoch: 0 [0/201 (0%)]	Loss: 0.659608
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 327 Train Epoch: 1 [0/201 (0%)]	Loss: 0.452539
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 407 Norm Difference for worker 327 is 0.965804
INFO:root:FL Epoch: 407 Done on worker:327
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :944
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762707
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443391
INFO:root:FL Epoch: 407 Norm Difference for worker 944 is 0.906583
INFO:root:FL Epoch: 407 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :1276
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 1276 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321832
INFO:root:Worker: 1276 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431532
INFO:root:FL Epoch: 407 Norm Difference for worker 1276 is 0.904519
INFO:root:FL Epoch: 407 Done on worker:1276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 407 Training on worker :734
INFO:root:FL Epoch: 407 Using Learning rate : 0.02218042007571463 
INFO:root:FL Epoch: 407 Normal Training
INFO:root:Worker: 734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481772
INFO:root:Worker: 734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528602
INFO:root:FL Epoch: 407 Norm Difference for worker 734 is 0.880315
INFO:root:FL Epoch: 407 Done on worker:734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 865
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 407 Ends   ===================
INFO:root:Epoch:407 Global Model Test Loss:0.5140911393305835 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:407 Global Model Backdoor Test Loss:0.15420398861169815                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 408 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 408 Workers Selected : [224, 1524, 1192, 1063, 247, 222, 508, 1901, 1626, 1902]
INFO:root:FL Epoch: 408 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.10034948 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 408 Num points on workers: [201 200 200 200 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 408 Training on worker :224
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 224 Train Epoch: 0 [0/201 (0%)]	Loss: 0.579987
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 224 Train Epoch: 1 [0/201 (0%)]	Loss: 0.261317
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 408 Norm Difference for worker 224 is 0.702645
INFO:root:FL Epoch: 408 Done on worker:224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1524
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.897413
INFO:root:Worker: 1524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419646
INFO:root:FL Epoch: 408 Norm Difference for worker 1524 is 0.921309
INFO:root:FL Epoch: 408 Done on worker:1524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1192
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1192 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480157
INFO:root:Worker: 1192 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366967
INFO:root:FL Epoch: 408 Norm Difference for worker 1192 is 0.925204
INFO:root:FL Epoch: 408 Done on worker:1192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1063
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1063 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404807
INFO:root:Worker: 1063 Train Epoch: 1 [0/200 (0%)]	Loss: 0.622912
INFO:root:FL Epoch: 408 Norm Difference for worker 1063 is 0.909507
INFO:root:FL Epoch: 408 Done on worker:1063
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :247
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 247 Train Epoch: 0 [0/201 (0%)]	Loss: 0.425451
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 247 Train Epoch: 1 [0/201 (0%)]	Loss: 0.494648
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 408 Norm Difference for worker 247 is 0.911983
INFO:root:FL Epoch: 408 Done on worker:247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :222
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.441152
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.271845
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 408 Norm Difference for worker 222 is 0.734179
INFO:root:FL Epoch: 408 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :508
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342608
INFO:root:Worker: 508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422468
INFO:root:FL Epoch: 408 Norm Difference for worker 508 is 0.813264
INFO:root:FL Epoch: 408 Done on worker:508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1901
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1901 Train Epoch: 0 [0/200 (0%)]	Loss: 0.225702
INFO:root:Worker: 1901 Train Epoch: 1 [0/200 (0%)]	Loss: 0.341286
INFO:root:FL Epoch: 408 Norm Difference for worker 1901 is 0.749675
INFO:root:FL Epoch: 408 Done on worker:1901
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1626
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1626 Train Epoch: 0 [0/200 (0%)]	Loss: 0.401311
INFO:root:Worker: 1626 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643103
INFO:root:FL Epoch: 408 Norm Difference for worker 1626 is 0.917598
INFO:root:FL Epoch: 408 Done on worker:1626
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 408 Training on worker :1902
INFO:root:FL Epoch: 408 Using Learning rate : 0.022136059235563197 
INFO:root:FL Epoch: 408 Normal Training
INFO:root:Worker: 1902 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512173
INFO:root:Worker: 1902 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470123
INFO:root:FL Epoch: 408 Norm Difference for worker 1902 is 0.891594
INFO:root:FL Epoch: 408 Done on worker:1902
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 224
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 408 Ends   ===================
INFO:root:Epoch:408 Global Model Test Loss:0.5758672286482418 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:408 Global Model Backdoor Test Loss:0.163166473309199                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 409 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 409 Workers Selected : [1757, 928, 1760, 442, 1721, 138, 788, 155, 1700, 1731]
INFO:root:FL Epoch: 409 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 409 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 409 Training on worker :1757
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1757 Train Epoch: 0 [0/200 (0%)]	Loss: 1.083357
INFO:root:Worker: 1757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557079
INFO:root:FL Epoch: 409 Norm Difference for worker 1757 is 1.118389
INFO:root:FL Epoch: 409 Done on worker:1757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :928
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 928 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463712
INFO:root:Worker: 928 Train Epoch: 1 [0/200 (0%)]	Loss: 0.295771
INFO:root:FL Epoch: 409 Norm Difference for worker 928 is 0.949188
INFO:root:FL Epoch: 409 Done on worker:928
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1760
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.850510
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.648090
INFO:root:FL Epoch: 409 Norm Difference for worker 1760 is 1.187802
INFO:root:FL Epoch: 409 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :442
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 442 Train Epoch: 0 [0/200 (0%)]	Loss: 0.820409
INFO:root:Worker: 442 Train Epoch: 1 [0/200 (0%)]	Loss: 0.320314
INFO:root:FL Epoch: 409 Norm Difference for worker 442 is 1.022098
INFO:root:FL Epoch: 409 Done on worker:442
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1721
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1721 Train Epoch: 0 [0/200 (0%)]	Loss: 0.927328
INFO:root:Worker: 1721 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372055
INFO:root:FL Epoch: 409 Norm Difference for worker 1721 is 0.976259
INFO:root:FL Epoch: 409 Done on worker:1721
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :138
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 138 Train Epoch: 0 [0/201 (0%)]	Loss: 0.423866
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 138 Train Epoch: 1 [0/201 (0%)]	Loss: 0.814839
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 409 Norm Difference for worker 138 is 1.041708
INFO:root:FL Epoch: 409 Done on worker:138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :788
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634139
INFO:root:Worker: 788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397643
INFO:root:FL Epoch: 409 Norm Difference for worker 788 is 0.986294
INFO:root:FL Epoch: 409 Done on worker:788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :155
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 155 Train Epoch: 0 [0/201 (0%)]	Loss: 0.628685
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 155 Train Epoch: 1 [0/201 (0%)]	Loss: 0.516170
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 409 Norm Difference for worker 155 is 1.201248
INFO:root:FL Epoch: 409 Done on worker:155
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1700
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1700 Train Epoch: 0 [0/200 (0%)]	Loss: 0.627584
INFO:root:Worker: 1700 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406063
INFO:root:FL Epoch: 409 Norm Difference for worker 1700 is 1.054984
INFO:root:FL Epoch: 409 Done on worker:1700
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 409 Training on worker :1731
INFO:root:FL Epoch: 409 Using Learning rate : 0.022091787117092074 
INFO:root:FL Epoch: 409 Normal Training
INFO:root:Worker: 1731 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561364
INFO:root:Worker: 1731 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223737
INFO:root:FL Epoch: 409 Norm Difference for worker 1731 is 0.821028
INFO:root:FL Epoch: 409 Done on worker:1731
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1731
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 409 Ends   ===================
INFO:root:Epoch:409 Global Model Test Loss:0.507976249736898 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:409 Global Model Backdoor Test Loss:0.1024126186966896                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 410 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 410 Workers Selected : [782, 654, 1696, 484, 1175, 39, 1764, 949, 1359, 1155]
INFO:root:FL Epoch: 410 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 410 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 410 Training on worker :782
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.942024
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438346
INFO:root:FL Epoch: 410 Norm Difference for worker 782 is 1.207682
INFO:root:FL Epoch: 410 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :654
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 654 Train Epoch: 0 [0/200 (0%)]	Loss: 0.389254
INFO:root:Worker: 654 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498855
INFO:root:FL Epoch: 410 Norm Difference for worker 654 is 1.102796
INFO:root:FL Epoch: 410 Done on worker:654
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1696
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1696 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498884
INFO:root:Worker: 1696 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354632
INFO:root:FL Epoch: 410 Norm Difference for worker 1696 is 0.96337
INFO:root:FL Epoch: 410 Done on worker:1696
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :484
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670926
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445213
INFO:root:FL Epoch: 410 Norm Difference for worker 484 is 1.080586
INFO:root:FL Epoch: 410 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1175
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1175 Train Epoch: 0 [0/200 (0%)]	Loss: 0.848440
INFO:root:Worker: 1175 Train Epoch: 1 [0/200 (0%)]	Loss: 0.378473
INFO:root:FL Epoch: 410 Norm Difference for worker 1175 is 1.170814
INFO:root:FL Epoch: 410 Done on worker:1175
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :39
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 39 Train Epoch: 0 [0/201 (0%)]	Loss: 0.512464
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 39 Train Epoch: 1 [0/201 (0%)]	Loss: 0.540531
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 410 Norm Difference for worker 39 is 1.131529
INFO:root:FL Epoch: 410 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1764
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.825348
INFO:root:Worker: 1764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469392
INFO:root:FL Epoch: 410 Norm Difference for worker 1764 is 1.260318
INFO:root:FL Epoch: 410 Done on worker:1764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :949
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 949 Train Epoch: 0 [0/200 (0%)]	Loss: 0.457397
INFO:root:Worker: 949 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389857
INFO:root:FL Epoch: 410 Norm Difference for worker 949 is 1.052366
INFO:root:FL Epoch: 410 Done on worker:949
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1359
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1359 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694872
INFO:root:Worker: 1359 Train Epoch: 1 [0/200 (0%)]	Loss: 0.229421
INFO:root:FL Epoch: 410 Norm Difference for worker 1359 is 1.135829
INFO:root:FL Epoch: 410 Done on worker:1359
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 410 Training on worker :1155
INFO:root:FL Epoch: 410 Using Learning rate : 0.022047603542857886 
INFO:root:FL Epoch: 410 Normal Training
INFO:root:Worker: 1155 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574888
INFO:root:Worker: 1155 Train Epoch: 1 [0/200 (0%)]	Loss: 0.549126
INFO:root:FL Epoch: 410 Norm Difference for worker 1155 is 1.078124
INFO:root:FL Epoch: 410 Done on worker:1155
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1696
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 410 Ends   ===================
INFO:root:Epoch:410 Global Model Test Loss:0.5359343342921313 and Test Accuracy:75.0 
INFO:root:Epoch:410 Global Model Backdoor Test Loss:0.08882132234672706                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 411 Begins ===================
INFO:root:FL Epoch: 411 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 411 Workers Selected : [0, 299, 493, 1364, 332, 365, 502, 1554, 1015, 82]
INFO:root:FL Epoch: 411 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.10034948 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 411 Num points on workers: [200 201 200 200 201 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 411 Training on worker :0
INFO:root:FL Epoch: 411 Using Learning rate : 0.004400701667154434 
INFO:root:FL Epoch: 411 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.107685
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.292275
INFO:root:FL Epoch: 411 Worker: 0 Backdoor Test Loss: 0.0785500667989254 Backdoor Test Accuracy: 99.16666666666667
INFO:root:FL Epoch: 411 Worker: 0 Backdoor Train Loss: 0.12681352347135544 Backdoor Train Accuracy: 95.5
INFO:root:FL Epoch: 411 Norm Difference for worker 0 is 0.128566
INFO:root:FL Epoch: 411 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :299
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 299 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517886
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 299 Train Epoch: 1 [0/201 (0%)]	Loss: 0.484216
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 411 Norm Difference for worker 299 is 1.035033
INFO:root:FL Epoch: 411 Done on worker:299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :493
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 493 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431933
INFO:root:Worker: 493 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315360
INFO:root:FL Epoch: 411 Norm Difference for worker 493 is 1.124442
INFO:root:FL Epoch: 411 Done on worker:493
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1364
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1364 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535294
INFO:root:Worker: 1364 Train Epoch: 1 [0/200 (0%)]	Loss: 0.306116
INFO:root:FL Epoch: 411 Norm Difference for worker 1364 is 1.011801
INFO:root:FL Epoch: 411 Done on worker:1364
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :332
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 332 Train Epoch: 0 [0/201 (0%)]	Loss: 0.899337
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 332 Train Epoch: 1 [0/201 (0%)]	Loss: 0.565701
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 411 Norm Difference for worker 332 is 1.192525
INFO:root:FL Epoch: 411 Done on worker:332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :365
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 365 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555748
INFO:root:Worker: 365 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401869
INFO:root:FL Epoch: 411 Norm Difference for worker 365 is 1.011449
INFO:root:FL Epoch: 411 Done on worker:365
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :502
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 502 Train Epoch: 0 [0/200 (0%)]	Loss: 1.052816
INFO:root:Worker: 502 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223589
INFO:root:FL Epoch: 411 Norm Difference for worker 502 is 1.101715
INFO:root:FL Epoch: 411 Done on worker:502
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1554
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473607
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330099
INFO:root:FL Epoch: 411 Norm Difference for worker 1554 is 1.038803
INFO:root:FL Epoch: 411 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :1015
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 1015 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474214
INFO:root:Worker: 1015 Train Epoch: 1 [0/200 (0%)]	Loss: 0.223892
INFO:root:FL Epoch: 411 Norm Difference for worker 1015 is 1.061036
INFO:root:FL Epoch: 411 Done on worker:1015
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 411 Training on worker :82
INFO:root:FL Epoch: 411 Using Learning rate : 0.022003508335772172 
INFO:root:FL Epoch: 411 Normal Training
INFO:root:Worker: 82 Train Epoch: 0 [0/201 (0%)]	Loss: 0.493799
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 82 Train Epoch: 1 [0/201 (0%)]	Loss: 0.467157
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 411 Norm Difference for worker 82 is 1.101552
INFO:root:FL Epoch: 411 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 411 Ends   ===================
INFO:root:Epoch:411 Global Model Test Loss:0.5396170756396126 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:411 Global Model Backdoor Test Loss:0.0785500667989254                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 412 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 412 Workers Selected : [1352, 1314, 144, 111, 148, 201, 776, 1712, 1925, 483]
INFO:root:FL Epoch: 412 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.1002994 0.1002994 0.1002994 0.0998004
 0.0998004 0.0998004 0.0998004]
INFO:root:FL Epoch: 412 Num points on workers: [200 200 201 201 201 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 412 Training on worker :1352
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.857776
INFO:root:Worker: 1352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.364219
INFO:root:FL Epoch: 412 Norm Difference for worker 1352 is 1.231138
INFO:root:FL Epoch: 412 Done on worker:1352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1314
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1314 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488285
INFO:root:Worker: 1314 Train Epoch: 1 [0/200 (0%)]	Loss: 0.358501
INFO:root:FL Epoch: 412 Norm Difference for worker 1314 is 1.227643
INFO:root:FL Epoch: 412 Done on worker:1314
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :144
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.383225
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.363411
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 412 Norm Difference for worker 144 is 1.159729
INFO:root:FL Epoch: 412 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :111
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 111 Train Epoch: 0 [0/201 (0%)]	Loss: 0.410549
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 111 Train Epoch: 1 [0/201 (0%)]	Loss: 0.762969
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 412 Norm Difference for worker 111 is 1.140192
INFO:root:FL Epoch: 412 Done on worker:111
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :148
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 148 Train Epoch: 0 [0/201 (0%)]	Loss: 0.937396
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 148 Train Epoch: 1 [0/201 (0%)]	Loss: 0.463275
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 412 Norm Difference for worker 148 is 1.160463
INFO:root:FL Epoch: 412 Done on worker:148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :201
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 201 Train Epoch: 0 [0/201 (0%)]	Loss: 0.716234
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 201 Train Epoch: 1 [0/201 (0%)]	Loss: 0.680979
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 412 Norm Difference for worker 201 is 1.356164
INFO:root:FL Epoch: 412 Done on worker:201
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :776
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.929999
INFO:root:Worker: 776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.192089
INFO:root:FL Epoch: 412 Norm Difference for worker 776 is 1.008573
INFO:root:FL Epoch: 412 Done on worker:776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1712
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530595
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333051
INFO:root:FL Epoch: 412 Norm Difference for worker 1712 is 1.095651
INFO:root:FL Epoch: 412 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :1925
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 1925 Train Epoch: 0 [0/200 (0%)]	Loss: 0.808197
INFO:root:Worker: 1925 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638253
INFO:root:FL Epoch: 412 Norm Difference for worker 1925 is 1.266998
INFO:root:FL Epoch: 412 Done on worker:1925
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 412 Training on worker :483
INFO:root:FL Epoch: 412 Using Learning rate : 0.021959501319100627 
INFO:root:FL Epoch: 412 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450770
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255847
INFO:root:FL Epoch: 412 Norm Difference for worker 483 is 1.460074
INFO:root:FL Epoch: 412 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 776
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 412 Ends   ===================
INFO:root:Epoch:412 Global Model Test Loss:0.5194811365183662 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:412 Global Model Backdoor Test Loss:0.10894189899166425                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 413 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 413 Workers Selected : [101, 1814, 521, 1303, 109, 666, 1597, 1619, 622, 1781]
INFO:root:FL Epoch: 413 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 413 Num points on workers: [201 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 413 Training on worker :101
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 101 Train Epoch: 0 [0/201 (0%)]	Loss: 0.766250
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 101 Train Epoch: 1 [0/201 (0%)]	Loss: 0.389727
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 413 Norm Difference for worker 101 is 0.955786
INFO:root:FL Epoch: 413 Done on worker:101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1814
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1814 Train Epoch: 0 [0/200 (0%)]	Loss: 1.037150
INFO:root:Worker: 1814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568654
INFO:root:FL Epoch: 413 Norm Difference for worker 1814 is 1.044975
INFO:root:FL Epoch: 413 Done on worker:1814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :521
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.859406
INFO:root:Worker: 521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516183
INFO:root:FL Epoch: 413 Norm Difference for worker 521 is 0.973756
INFO:root:FL Epoch: 413 Done on worker:521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1303
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1303 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440853
INFO:root:Worker: 1303 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304029
INFO:root:FL Epoch: 413 Norm Difference for worker 1303 is 0.877087
INFO:root:FL Epoch: 413 Done on worker:1303
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :109
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 109 Train Epoch: 0 [0/201 (0%)]	Loss: 0.856931
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 109 Train Epoch: 1 [0/201 (0%)]	Loss: 0.487062
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 413 Norm Difference for worker 109 is 1.035202
INFO:root:FL Epoch: 413 Done on worker:109
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :666
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539128
INFO:root:Worker: 666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309363
INFO:root:FL Epoch: 413 Norm Difference for worker 666 is 0.952624
INFO:root:FL Epoch: 413 Done on worker:666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1597
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521611
INFO:root:Worker: 1597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400468
INFO:root:FL Epoch: 413 Norm Difference for worker 1597 is 1.014018
INFO:root:FL Epoch: 413 Done on worker:1597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1619
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.857777
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432545
INFO:root:FL Epoch: 413 Norm Difference for worker 1619 is 0.984286
INFO:root:FL Epoch: 413 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :622
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622721
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493521
INFO:root:FL Epoch: 413 Norm Difference for worker 622 is 0.986464
INFO:root:FL Epoch: 413 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 413 Training on worker :1781
INFO:root:FL Epoch: 413 Using Learning rate : 0.02191558231646243 
INFO:root:FL Epoch: 413 Normal Training
INFO:root:Worker: 1781 Train Epoch: 0 [0/200 (0%)]	Loss: 0.823680
INFO:root:Worker: 1781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692505
INFO:root:FL Epoch: 413 Norm Difference for worker 1781 is 1.117401
INFO:root:FL Epoch: 413 Done on worker:1781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1303
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 413 Ends   ===================
INFO:root:Epoch:413 Global Model Test Loss:0.5224898720488829 and Test Accuracy:75.0 
INFO:root:Epoch:413 Global Model Backdoor Test Loss:0.14088530093431473                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 414 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 414 Workers Selected : [596, 1541, 713, 428, 1692, 376, 370, 41, 690, 939]
INFO:root:FL Epoch: 414 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 414 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 414 Training on worker :596
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.672006
INFO:root:Worker: 596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431718
INFO:root:FL Epoch: 414 Norm Difference for worker 596 is 0.998326
INFO:root:FL Epoch: 414 Done on worker:596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1541
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426888
INFO:root:Worker: 1541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344063
INFO:root:FL Epoch: 414 Norm Difference for worker 1541 is 0.966406
INFO:root:FL Epoch: 414 Done on worker:1541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :713
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.656943
INFO:root:Worker: 713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650602
INFO:root:FL Epoch: 414 Norm Difference for worker 713 is 0.91617
INFO:root:FL Epoch: 414 Done on worker:713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :428
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374386
INFO:root:Worker: 428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280574
INFO:root:FL Epoch: 414 Norm Difference for worker 428 is 0.910379
INFO:root:FL Epoch: 414 Done on worker:428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :1692
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 1692 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597756
INFO:root:Worker: 1692 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344329
INFO:root:FL Epoch: 414 Norm Difference for worker 1692 is 1.035936
INFO:root:FL Epoch: 414 Done on worker:1692
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :376
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 376 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597551
INFO:root:Worker: 376 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531165
INFO:root:FL Epoch: 414 Norm Difference for worker 376 is 1.004879
INFO:root:FL Epoch: 414 Done on worker:376
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :370
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392439
INFO:root:Worker: 370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446407
INFO:root:FL Epoch: 414 Norm Difference for worker 370 is 0.855279
INFO:root:FL Epoch: 414 Done on worker:370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :41
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 41 Train Epoch: 0 [0/201 (0%)]	Loss: 0.504732
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 41 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431565
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 414 Norm Difference for worker 41 is 0.842216
INFO:root:FL Epoch: 414 Done on worker:41
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :690
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.406980
INFO:root:Worker: 690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539669
INFO:root:FL Epoch: 414 Norm Difference for worker 690 is 0.928969
INFO:root:FL Epoch: 414 Done on worker:690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 414 Training on worker :939
INFO:root:FL Epoch: 414 Using Learning rate : 0.021871751151829502 
INFO:root:FL Epoch: 414 Normal Training
INFO:root:Worker: 939 Train Epoch: 0 [0/200 (0%)]	Loss: 0.764542
INFO:root:Worker: 939 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384411
INFO:root:FL Epoch: 414 Norm Difference for worker 939 is 0.990756
INFO:root:FL Epoch: 414 Done on worker:939
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 41
INFO:root:Norm of Aggregated Model: 5154.99609375
INFO:root:Aggregating After Defense
INFO:root:================FL round 414 Ends   ===================
INFO:root:Epoch:414 Global Model Test Loss:0.5202555323348326 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:414 Global Model Backdoor Test Loss:0.16299212723970413                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 415 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 415 Workers Selected : [1363, 1863, 50, 176, 1648, 446, 1076, 148, 592, 224]
INFO:root:FL Epoch: 415 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.1002994 0.0998004 0.0998004 0.0998004
 0.1002994 0.0998004 0.1002994]
INFO:root:FL Epoch: 415 Num points on workers: [200 200 201 201 200 200 200 201 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 415 Training on worker :1363
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1363 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619400
INFO:root:Worker: 1363 Train Epoch: 1 [0/200 (0%)]	Loss: 0.537714
INFO:root:FL Epoch: 415 Norm Difference for worker 1363 is 0.939845
INFO:root:FL Epoch: 415 Done on worker:1363
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1863
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447886
INFO:root:Worker: 1863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.377757
INFO:root:FL Epoch: 415 Norm Difference for worker 1863 is 0.753842
INFO:root:FL Epoch: 415 Done on worker:1863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :50
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 50 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611184
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 50 Train Epoch: 1 [0/201 (0%)]	Loss: 0.482620
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 415 Norm Difference for worker 50 is 0.886124
INFO:root:FL Epoch: 415 Done on worker:50
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :176
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 176 Train Epoch: 0 [0/201 (0%)]	Loss: 0.822649
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 176 Train Epoch: 1 [0/201 (0%)]	Loss: 0.552776
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 415 Norm Difference for worker 176 is 0.830475
INFO:root:FL Epoch: 415 Done on worker:176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1648
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1648 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415043
INFO:root:Worker: 1648 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556892
INFO:root:FL Epoch: 415 Norm Difference for worker 1648 is 0.815233
INFO:root:FL Epoch: 415 Done on worker:1648
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :446
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 446 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396091
INFO:root:Worker: 446 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259658
INFO:root:FL Epoch: 415 Norm Difference for worker 446 is 0.851269
INFO:root:FL Epoch: 415 Done on worker:446
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :1076
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 1076 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364518
INFO:root:Worker: 1076 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496473
INFO:root:FL Epoch: 415 Norm Difference for worker 1076 is 0.814116
INFO:root:FL Epoch: 415 Done on worker:1076
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :148
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 148 Train Epoch: 0 [0/201 (0%)]	Loss: 0.744768
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 148 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431852
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 415 Norm Difference for worker 148 is 0.879171
INFO:root:FL Epoch: 415 Done on worker:148
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :592
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492561
INFO:root:Worker: 592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604659
INFO:root:FL Epoch: 415 Norm Difference for worker 592 is 0.843701
INFO:root:FL Epoch: 415 Done on worker:592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 415 Training on worker :224
INFO:root:FL Epoch: 415 Using Learning rate : 0.021828007649525843 
INFO:root:FL Epoch: 415 Normal Training
INFO:root:Worker: 224 Train Epoch: 0 [0/201 (0%)]	Loss: 0.334255
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 224 Train Epoch: 1 [0/201 (0%)]	Loss: 0.190194
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 415 Norm Difference for worker 224 is 0.557885
INFO:root:FL Epoch: 415 Done on worker:224
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 224
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 415 Ends   ===================
INFO:root:Epoch:415 Global Model Test Loss:0.5771636612275067 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:415 Global Model Backdoor Test Loss:0.12035876015822093                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 416 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 416 Workers Selected : [966, 784, 1822, 306, 1540, 1348, 482, 508, 649, 676]
INFO:root:FL Epoch: 416 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 416 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 416 Training on worker :966
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 966 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438573
INFO:root:Worker: 966 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470405
INFO:root:FL Epoch: 416 Norm Difference for worker 966 is 1.056784
INFO:root:FL Epoch: 416 Done on worker:966
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :784
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666677
INFO:root:Worker: 784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499552
INFO:root:FL Epoch: 416 Norm Difference for worker 784 is 1.087681
INFO:root:FL Epoch: 416 Done on worker:784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1822
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695044
INFO:root:Worker: 1822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443145
INFO:root:FL Epoch: 416 Norm Difference for worker 1822 is 1.154349
INFO:root:FL Epoch: 416 Done on worker:1822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :306
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 306 Train Epoch: 0 [0/201 (0%)]	Loss: 0.215368
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 306 Train Epoch: 1 [0/201 (0%)]	Loss: 0.763588
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 416 Norm Difference for worker 306 is 1.017564
INFO:root:FL Epoch: 416 Done on worker:306
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1540
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1540 Train Epoch: 0 [0/200 (0%)]	Loss: 0.738813
INFO:root:Worker: 1540 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344441
INFO:root:FL Epoch: 416 Norm Difference for worker 1540 is 1.159828
INFO:root:FL Epoch: 416 Done on worker:1540
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :1348
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 1348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357900
INFO:root:Worker: 1348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.132921
INFO:root:FL Epoch: 416 Norm Difference for worker 1348 is 0.914627
INFO:root:FL Epoch: 416 Done on worker:1348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :482
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600476
INFO:root:Worker: 482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593547
INFO:root:FL Epoch: 416 Norm Difference for worker 482 is 1.13284
INFO:root:FL Epoch: 416 Done on worker:482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :508
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 508 Train Epoch: 0 [0/200 (0%)]	Loss: 0.840540
INFO:root:Worker: 508 Train Epoch: 1 [0/200 (0%)]	Loss: 0.348274
INFO:root:FL Epoch: 416 Norm Difference for worker 508 is 1.042937
INFO:root:FL Epoch: 416 Done on worker:508
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :649
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.230441
INFO:root:Worker: 649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.231012
INFO:root:FL Epoch: 416 Norm Difference for worker 649 is 1.078426
INFO:root:FL Epoch: 416 Done on worker:649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 416 Training on worker :676
INFO:root:FL Epoch: 416 Using Learning rate : 0.02178435163422679 
INFO:root:FL Epoch: 416 Normal Training
INFO:root:Worker: 676 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755885
INFO:root:Worker: 676 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541770
INFO:root:FL Epoch: 416 Norm Difference for worker 676 is 1.166232
INFO:root:FL Epoch: 416 Done on worker:676
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1348
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 416 Ends   ===================
INFO:root:Epoch:416 Global Model Test Loss:0.5309531758813297 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:416 Global Model Backdoor Test Loss:0.11075046534339587                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 417 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 417 Workers Selected : [1528, 1726, 1802, 27, 473, 1866, 351, 879, 1853, 286]
INFO:root:FL Epoch: 417 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 417 Num points on workers: [200 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 417 Training on worker :1528
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1528 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474615
INFO:root:Worker: 1528 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452836
INFO:root:FL Epoch: 417 Norm Difference for worker 1528 is 0.912181
INFO:root:FL Epoch: 417 Done on worker:1528
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1726
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395628
INFO:root:Worker: 1726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.837104
INFO:root:FL Epoch: 417 Norm Difference for worker 1726 is 1.030897
INFO:root:FL Epoch: 417 Done on worker:1726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1802
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669385
INFO:root:Worker: 1802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.632044
INFO:root:FL Epoch: 417 Norm Difference for worker 1802 is 1.059705
INFO:root:FL Epoch: 417 Done on worker:1802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :27
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 27 Train Epoch: 0 [0/201 (0%)]	Loss: 0.669038
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 27 Train Epoch: 1 [0/201 (0%)]	Loss: 0.379040
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 417 Norm Difference for worker 27 is 1.051663
INFO:root:FL Epoch: 417 Done on worker:27
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :473
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 473 Train Epoch: 0 [0/200 (0%)]	Loss: 0.786297
INFO:root:Worker: 473 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307287
INFO:root:FL Epoch: 417 Norm Difference for worker 473 is 1.017964
INFO:root:FL Epoch: 417 Done on worker:473
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1866
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526046
INFO:root:Worker: 1866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.280614
INFO:root:FL Epoch: 417 Norm Difference for worker 1866 is 1.034439
INFO:root:FL Epoch: 417 Done on worker:1866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :351
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 351 Train Epoch: 0 [0/200 (0%)]	Loss: 0.350399
INFO:root:Worker: 351 Train Epoch: 1 [0/200 (0%)]	Loss: 0.709020
INFO:root:FL Epoch: 417 Norm Difference for worker 351 is 1.044492
INFO:root:FL Epoch: 417 Done on worker:351
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :879
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 879 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387203
INFO:root:Worker: 879 Train Epoch: 1 [0/200 (0%)]	Loss: 0.272883
INFO:root:FL Epoch: 417 Norm Difference for worker 879 is 1.001655
INFO:root:FL Epoch: 417 Done on worker:879
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :1853
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562708
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562724
INFO:root:FL Epoch: 417 Norm Difference for worker 1853 is 1.186803
INFO:root:FL Epoch: 417 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 417 Training on worker :286
INFO:root:FL Epoch: 417 Using Learning rate : 0.02174078293095834 
INFO:root:FL Epoch: 417 Normal Training
INFO:root:Worker: 286 Train Epoch: 0 [0/201 (0%)]	Loss: 0.616455
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 286 Train Epoch: 1 [0/201 (0%)]	Loss: 0.392716
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 417 Norm Difference for worker 286 is 0.956649
INFO:root:FL Epoch: 417 Done on worker:286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1528
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 417 Ends   ===================
INFO:root:Epoch:417 Global Model Test Loss:0.5085688811891219 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:417 Global Model Backdoor Test Loss:0.15716946994264921                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 418 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 418 Workers Selected : [729, 929, 608, 664, 832, 1012, 669, 246, 1585, 1875]
INFO:root:FL Epoch: 418 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 418 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 418 Training on worker :729
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.444378
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425269
INFO:root:FL Epoch: 418 Norm Difference for worker 729 is 0.979441
INFO:root:FL Epoch: 418 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :929
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332948
INFO:root:Worker: 929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450091
INFO:root:FL Epoch: 418 Norm Difference for worker 929 is 0.88786
INFO:root:FL Epoch: 418 Done on worker:929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :608
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.466760
INFO:root:Worker: 608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491918
INFO:root:FL Epoch: 418 Norm Difference for worker 608 is 0.99062
INFO:root:FL Epoch: 418 Done on worker:608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :664
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.474016
INFO:root:Worker: 664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.542045
INFO:root:FL Epoch: 418 Norm Difference for worker 664 is 0.981833
INFO:root:FL Epoch: 418 Done on worker:664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :832
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694583
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.509303
INFO:root:FL Epoch: 418 Norm Difference for worker 832 is 1.102492
INFO:root:FL Epoch: 418 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1012
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.259852
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562375
INFO:root:FL Epoch: 418 Norm Difference for worker 1012 is 0.832011
INFO:root:FL Epoch: 418 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :669
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.595004
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.414178
INFO:root:FL Epoch: 418 Norm Difference for worker 669 is 0.983484
INFO:root:FL Epoch: 418 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :246
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 246 Train Epoch: 0 [0/201 (0%)]	Loss: 0.989553
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 246 Train Epoch: 1 [0/201 (0%)]	Loss: 0.709634
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 418 Norm Difference for worker 246 is 0.88147
INFO:root:FL Epoch: 418 Done on worker:246
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1585
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731995
INFO:root:Worker: 1585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.527335
INFO:root:FL Epoch: 418 Norm Difference for worker 1585 is 0.921255
INFO:root:FL Epoch: 418 Done on worker:1585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 418 Training on worker :1875
INFO:root:FL Epoch: 418 Using Learning rate : 0.02169730136509642 
INFO:root:FL Epoch: 418 Normal Training
INFO:root:Worker: 1875 Train Epoch: 0 [0/200 (0%)]	Loss: 0.327893
INFO:root:Worker: 1875 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343605
INFO:root:FL Epoch: 418 Norm Difference for worker 1875 is 0.931323
INFO:root:FL Epoch: 418 Done on worker:1875
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1012
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 418 Ends   ===================
INFO:root:Epoch:418 Global Model Test Loss:0.5137230280567618 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:418 Global Model Backdoor Test Loss:0.16668176154295603                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 419 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 419 Workers Selected : [1590, 808, 465, 713, 649, 1672, 255, 915, 1914, 738]
INFO:root:FL Epoch: 419 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 419 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 419 Training on worker :1590
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.608797
INFO:root:Worker: 1590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546484
INFO:root:FL Epoch: 419 Norm Difference for worker 1590 is 0.922066
INFO:root:FL Epoch: 419 Done on worker:1590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :808
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.666227
INFO:root:Worker: 808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326895
INFO:root:FL Epoch: 419 Norm Difference for worker 808 is 0.935482
INFO:root:FL Epoch: 419 Done on worker:808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :465
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 465 Train Epoch: 0 [0/200 (0%)]	Loss: 0.332406
INFO:root:Worker: 465 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372567
INFO:root:FL Epoch: 419 Norm Difference for worker 465 is 0.860668
INFO:root:FL Epoch: 419 Done on worker:465
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :713
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 713 Train Epoch: 0 [0/200 (0%)]	Loss: 0.731013
INFO:root:Worker: 713 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551038
INFO:root:FL Epoch: 419 Norm Difference for worker 713 is 0.915506
INFO:root:FL Epoch: 419 Done on worker:713
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :649
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702589
INFO:root:Worker: 649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411078
INFO:root:FL Epoch: 419 Norm Difference for worker 649 is 0.875492
INFO:root:FL Epoch: 419 Done on worker:649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1672
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462620
INFO:root:Worker: 1672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319444
INFO:root:FL Epoch: 419 Norm Difference for worker 1672 is 0.815361
INFO:root:FL Epoch: 419 Done on worker:1672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :255
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 255 Train Epoch: 0 [0/201 (0%)]	Loss: 0.668196
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 255 Train Epoch: 1 [0/201 (0%)]	Loss: 0.474139
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 419 Norm Difference for worker 255 is 0.888984
INFO:root:FL Epoch: 419 Done on worker:255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :915
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 915 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616880
INFO:root:Worker: 915 Train Epoch: 1 [0/200 (0%)]	Loss: 0.820310
INFO:root:FL Epoch: 419 Norm Difference for worker 915 is 0.922957
INFO:root:FL Epoch: 419 Done on worker:915
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :1914
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 1914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.254818
INFO:root:Worker: 1914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350151
INFO:root:FL Epoch: 419 Norm Difference for worker 1914 is 0.742231
INFO:root:FL Epoch: 419 Done on worker:1914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 419 Training on worker :738
INFO:root:FL Epoch: 419 Using Learning rate : 0.021653906762366226 
INFO:root:FL Epoch: 419 Normal Training
INFO:root:Worker: 738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.536384
INFO:root:Worker: 738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477720
INFO:root:FL Epoch: 419 Norm Difference for worker 738 is 0.843678
INFO:root:FL Epoch: 419 Done on worker:738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 8, which is global user: 1914
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 419 Ends   ===================
INFO:root:Epoch:419 Global Model Test Loss:0.5430650816244238 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:419 Global Model Backdoor Test Loss:0.16536878297726312                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 420 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 420 Workers Selected : [1275, 1798, 84, 1896, 575, 250, 1853, 193, 37, 1851]
INFO:root:FL Epoch: 420 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.1002994 0.0998004
 0.1002994 0.1002994 0.0998004]
INFO:root:FL Epoch: 420 Num points on workers: [200 200 201 200 200 201 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 420 Training on worker :1275
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1275 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395840
INFO:root:Worker: 1275 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361091
INFO:root:FL Epoch: 420 Norm Difference for worker 1275 is 0.976183
INFO:root:FL Epoch: 420 Done on worker:1275
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1798
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.858026
INFO:root:Worker: 1798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580105
INFO:root:FL Epoch: 420 Norm Difference for worker 1798 is 1.08331
INFO:root:FL Epoch: 420 Done on worker:1798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :84
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 84 Train Epoch: 0 [0/201 (0%)]	Loss: 0.503534
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 84 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436218
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 420 Norm Difference for worker 84 is 0.921326
INFO:root:FL Epoch: 420 Done on worker:84
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1896
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.828298
INFO:root:Worker: 1896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.291739
INFO:root:FL Epoch: 420 Norm Difference for worker 1896 is 0.96388
INFO:root:FL Epoch: 420 Done on worker:1896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :575
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373829
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640771
INFO:root:FL Epoch: 420 Norm Difference for worker 575 is 1.020795
INFO:root:FL Epoch: 420 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :250
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 250 Train Epoch: 0 [0/201 (0%)]	Loss: 0.573908
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 250 Train Epoch: 1 [0/201 (0%)]	Loss: 0.650816
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 420 Norm Difference for worker 250 is 0.98643
INFO:root:FL Epoch: 420 Done on worker:250
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1853
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1853 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577470
INFO:root:Worker: 1853 Train Epoch: 1 [0/200 (0%)]	Loss: 0.529310
INFO:root:FL Epoch: 420 Norm Difference for worker 1853 is 1.083422
INFO:root:FL Epoch: 420 Done on worker:1853
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :193
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 193 Train Epoch: 0 [0/201 (0%)]	Loss: 0.764587
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 193 Train Epoch: 1 [0/201 (0%)]	Loss: 0.824873
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 420 Norm Difference for worker 193 is 1.048497
INFO:root:FL Epoch: 420 Done on worker:193
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :37
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 37 Train Epoch: 0 [0/201 (0%)]	Loss: 0.575046
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 37 Train Epoch: 1 [0/201 (0%)]	Loss: 0.614240
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 420 Norm Difference for worker 37 is 0.984309
INFO:root:FL Epoch: 420 Done on worker:37
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 420 Training on worker :1851
INFO:root:FL Epoch: 420 Using Learning rate : 0.021610598948841497 
INFO:root:FL Epoch: 420 Normal Training
INFO:root:Worker: 1851 Train Epoch: 0 [0/200 (0%)]	Loss: 0.485801
INFO:root:Worker: 1851 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327594
INFO:root:FL Epoch: 420 Norm Difference for worker 1851 is 0.984222
INFO:root:FL Epoch: 420 Done on worker:1851
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 250
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 420 Ends   ===================
INFO:root:Epoch:420 Global Model Test Loss:0.5097534358501434 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:420 Global Model Backdoor Test Loss:0.1295541375875473                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 421 Begins ===================
INFO:root:FL Epoch: 421 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 421 Workers Selected : [0, 337, 750, 121, 1435, 259, 1694, 850, 952, 772]
INFO:root:FL Epoch: 421 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 421 Num points on workers: [200 201 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 421 Training on worker :0
INFO:root:FL Epoch: 421 Using Learning rate : 0.004313475550188762 
INFO:root:FL Epoch: 421 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.335611
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319264
INFO:root:FL Epoch: 421 Worker: 0 Backdoor Test Loss: 0.13225618253151575 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 421 Worker: 0 Backdoor Train Loss: 0.1876488745212555 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 421 Norm Difference for worker 0 is 0.194132
INFO:root:FL Epoch: 421 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :337
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.672604
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.677688
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 421 Norm Difference for worker 337 is 0.871239
INFO:root:FL Epoch: 421 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :750
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.754422
INFO:root:Worker: 750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.368853
INFO:root:FL Epoch: 421 Norm Difference for worker 750 is 0.864019
INFO:root:FL Epoch: 421 Done on worker:750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :121
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 121 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596275
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 121 Train Epoch: 1 [0/201 (0%)]	Loss: 0.768509
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 421 Norm Difference for worker 121 is 0.89216
INFO:root:FL Epoch: 421 Done on worker:121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1435
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683859
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.396829
INFO:root:FL Epoch: 421 Norm Difference for worker 1435 is 0.875988
INFO:root:FL Epoch: 421 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :259
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 259 Train Epoch: 0 [0/201 (0%)]	Loss: 0.505113
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 259 Train Epoch: 1 [0/201 (0%)]	Loss: 0.530552
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 421 Norm Difference for worker 259 is 0.766133
INFO:root:FL Epoch: 421 Done on worker:259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :1694
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 1694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.453092
INFO:root:Worker: 1694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.562825
INFO:root:FL Epoch: 421 Norm Difference for worker 1694 is 0.857838
INFO:root:FL Epoch: 421 Done on worker:1694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :850
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542353
INFO:root:Worker: 850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500547
INFO:root:FL Epoch: 421 Norm Difference for worker 850 is 0.915658
INFO:root:FL Epoch: 421 Done on worker:850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :952
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.669030
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524480
INFO:root:FL Epoch: 421 Norm Difference for worker 952 is 0.957807
INFO:root:FL Epoch: 421 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 421 Training on worker :772
INFO:root:FL Epoch: 421 Using Learning rate : 0.021567377750943813 
INFO:root:FL Epoch: 421 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542872
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286407
INFO:root:FL Epoch: 421 Norm Difference for worker 772 is 0.885669
INFO:root:FL Epoch: 421 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 421 Ends   ===================
INFO:root:Epoch:421 Global Model Test Loss:0.49536510074839873 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:421 Global Model Backdoor Test Loss:0.13225618253151575                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 422 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 422 Workers Selected : [1404, 104, 1596, 57, 1825, 160, 1053, 899, 1777, 1220]
INFO:root:FL Epoch: 422 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 422 Num points on workers: [200 201 200 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 422 Training on worker :1404
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1404 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548419
INFO:root:Worker: 1404 Train Epoch: 1 [0/200 (0%)]	Loss: 0.796154
INFO:root:FL Epoch: 422 Norm Difference for worker 1404 is 0.833504
INFO:root:FL Epoch: 422 Done on worker:1404
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :104
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 104 Train Epoch: 0 [0/201 (0%)]	Loss: 0.824352
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 104 Train Epoch: 1 [0/201 (0%)]	Loss: 0.407133
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 422 Norm Difference for worker 104 is 0.9262
INFO:root:FL Epoch: 422 Done on worker:104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1596
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1596 Train Epoch: 0 [0/200 (0%)]	Loss: 0.954195
INFO:root:Worker: 1596 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430389
INFO:root:FL Epoch: 422 Norm Difference for worker 1596 is 0.86169
INFO:root:FL Epoch: 422 Done on worker:1596
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :57
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 57 Train Epoch: 0 [0/201 (0%)]	Loss: 0.497955
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 57 Train Epoch: 1 [0/201 (0%)]	Loss: 0.315194
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 422 Norm Difference for worker 57 is 0.83085
INFO:root:FL Epoch: 422 Done on worker:57
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1825
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.451122
INFO:root:Worker: 1825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419241
INFO:root:FL Epoch: 422 Norm Difference for worker 1825 is 0.781584
INFO:root:FL Epoch: 422 Done on worker:1825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :160
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.572090
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.469419
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 422 Norm Difference for worker 160 is 0.862174
INFO:root:FL Epoch: 422 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1053
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1053 Train Epoch: 0 [0/200 (0%)]	Loss: 0.290133
INFO:root:Worker: 1053 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456252
INFO:root:FL Epoch: 422 Norm Difference for worker 1053 is 0.833524
INFO:root:FL Epoch: 422 Done on worker:1053
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :899
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484091
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530577
INFO:root:FL Epoch: 422 Norm Difference for worker 899 is 0.847574
INFO:root:FL Epoch: 422 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1777
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542372
INFO:root:Worker: 1777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365971
INFO:root:FL Epoch: 422 Norm Difference for worker 1777 is 0.906091
INFO:root:FL Epoch: 422 Done on worker:1777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 422 Training on worker :1220
INFO:root:FL Epoch: 422 Using Learning rate : 0.021524242995441922 
INFO:root:FL Epoch: 422 Normal Training
INFO:root:Worker: 1220 Train Epoch: 0 [0/200 (0%)]	Loss: 0.198747
INFO:root:Worker: 1220 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391636
INFO:root:FL Epoch: 422 Norm Difference for worker 1220 is 0.775857
INFO:root:FL Epoch: 422 Done on worker:1220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1220
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 422 Ends   ===================
INFO:root:Epoch:422 Global Model Test Loss:0.5180910142029033 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:422 Global Model Backdoor Test Loss:0.16116507848103842                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 423 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 423 Workers Selected : [204, 1418, 1551, 372, 1555, 1108, 379, 1155, 287, 865]
INFO:root:FL Epoch: 423 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 423 Num points on workers: [201 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 423 Training on worker :204
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.553287
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.634143
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 423 Norm Difference for worker 204 is 0.907537
INFO:root:FL Epoch: 423 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1418
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.831933
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679491
INFO:root:FL Epoch: 423 Norm Difference for worker 1418 is 0.883195
INFO:root:FL Epoch: 423 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1551
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417586
INFO:root:Worker: 1551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.765011
INFO:root:FL Epoch: 423 Norm Difference for worker 1551 is 0.858085
INFO:root:FL Epoch: 423 Done on worker:1551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :372
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 372 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418402
INFO:root:Worker: 372 Train Epoch: 1 [0/200 (0%)]	Loss: 0.448522
INFO:root:FL Epoch: 423 Norm Difference for worker 372 is 0.881116
INFO:root:FL Epoch: 423 Done on worker:372
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1555
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1555 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519623
INFO:root:Worker: 1555 Train Epoch: 1 [0/200 (0%)]	Loss: 0.833268
INFO:root:FL Epoch: 423 Norm Difference for worker 1555 is 0.919706
INFO:root:FL Epoch: 423 Done on worker:1555
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1108
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1108 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427348
INFO:root:Worker: 1108 Train Epoch: 1 [0/200 (0%)]	Loss: 0.822057
INFO:root:FL Epoch: 423 Norm Difference for worker 1108 is 0.925678
INFO:root:FL Epoch: 423 Done on worker:1108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :379
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 379 Train Epoch: 0 [0/200 (0%)]	Loss: 0.418378
INFO:root:Worker: 379 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398055
INFO:root:FL Epoch: 423 Norm Difference for worker 379 is 0.944951
INFO:root:FL Epoch: 423 Done on worker:379
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :1155
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 1155 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685163
INFO:root:Worker: 1155 Train Epoch: 1 [0/200 (0%)]	Loss: 0.641435
INFO:root:FL Epoch: 423 Norm Difference for worker 1155 is 0.926259
INFO:root:FL Epoch: 423 Done on worker:1155
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :287
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 287 Train Epoch: 0 [0/201 (0%)]	Loss: 0.575835
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 287 Train Epoch: 1 [0/201 (0%)]	Loss: 0.578295
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 423 Norm Difference for worker 287 is 0.916547
INFO:root:FL Epoch: 423 Done on worker:287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 423 Training on worker :865
INFO:root:FL Epoch: 423 Using Learning rate : 0.02148119450945104 
INFO:root:FL Epoch: 423 Normal Training
INFO:root:Worker: 865 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456849
INFO:root:Worker: 865 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328668
INFO:root:FL Epoch: 423 Norm Difference for worker 865 is 0.771905
INFO:root:FL Epoch: 423 Done on worker:865
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 865
INFO:root:Norm of Aggregated Model: 5154.9970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 423 Ends   ===================
INFO:root:Epoch:423 Global Model Test Loss:0.5334020064157599 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:423 Global Model Backdoor Test Loss:0.11030370369553566                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 424 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 424 Workers Selected : [232, 1589, 1893, 195, 1839, 551, 116, 119, 1098, 1075]
INFO:root:FL Epoch: 424 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.1002994
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 424 Num points on workers: [201 200 200 201 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 424 Training on worker :232
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 232 Train Epoch: 0 [0/201 (0%)]	Loss: 0.546589
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 232 Train Epoch: 1 [0/201 (0%)]	Loss: 0.598180
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 232 is 1.053716
INFO:root:FL Epoch: 424 Done on worker:232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1589
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.458733
INFO:root:Worker: 1589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309196
INFO:root:FL Epoch: 424 Norm Difference for worker 1589 is 0.98152
INFO:root:FL Epoch: 424 Done on worker:1589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1893
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1893 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502667
INFO:root:Worker: 1893 Train Epoch: 1 [0/200 (0%)]	Loss: 0.303781
INFO:root:FL Epoch: 424 Norm Difference for worker 1893 is 1.097506
INFO:root:FL Epoch: 424 Done on worker:1893
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :195
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.476668
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.399352
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 195 is 0.983705
INFO:root:FL Epoch: 424 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1839
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1839 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533566
INFO:root:Worker: 1839 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449755
INFO:root:FL Epoch: 424 Norm Difference for worker 1839 is 1.04623
INFO:root:FL Epoch: 424 Done on worker:1839
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :551
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400710
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.147939
INFO:root:FL Epoch: 424 Norm Difference for worker 551 is 0.751395
INFO:root:FL Epoch: 424 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :116
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 116 Train Epoch: 0 [0/201 (0%)]	Loss: 0.609335
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 116 Train Epoch: 1 [0/201 (0%)]	Loss: 0.579391
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 116 is 1.023742
INFO:root:FL Epoch: 424 Done on worker:116
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :119
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 119 Train Epoch: 0 [0/201 (0%)]	Loss: 0.216787
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 119 Train Epoch: 1 [0/201 (0%)]	Loss: 0.218116
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 424 Norm Difference for worker 119 is 1.078648
INFO:root:FL Epoch: 424 Done on worker:119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1098
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1098 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552423
INFO:root:Worker: 1098 Train Epoch: 1 [0/200 (0%)]	Loss: 0.755285
INFO:root:FL Epoch: 424 Norm Difference for worker 1098 is 0.99517
INFO:root:FL Epoch: 424 Done on worker:1098
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 424 Training on worker :1075
INFO:root:FL Epoch: 424 Using Learning rate : 0.021438232120432138 
INFO:root:FL Epoch: 424 Normal Training
INFO:root:Worker: 1075 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587248
INFO:root:Worker: 1075 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290718
INFO:root:FL Epoch: 424 Norm Difference for worker 1075 is 0.905954
INFO:root:FL Epoch: 424 Done on worker:1075
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 551
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 424 Ends   ===================
INFO:root:Epoch:424 Global Model Test Loss:0.575412557405584 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:424 Global Model Backdoor Test Loss:0.1529147612551848                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 425 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 425 Workers Selected : [1857, 621, 1846, 388, 1882, 1236, 1388, 292, 764, 1941]
INFO:root:FL Epoch: 425 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 425 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 425 Training on worker :1857
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1857 Train Epoch: 0 [0/200 (0%)]	Loss: 1.022690
INFO:root:Worker: 1857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.498768
INFO:root:FL Epoch: 425 Norm Difference for worker 1857 is 1.142425
INFO:root:FL Epoch: 425 Done on worker:1857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :621
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697211
INFO:root:Worker: 621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404256
INFO:root:FL Epoch: 425 Norm Difference for worker 621 is 1.118675
INFO:root:FL Epoch: 425 Done on worker:621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1846
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1846 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510827
INFO:root:Worker: 1846 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457847
INFO:root:FL Epoch: 425 Norm Difference for worker 1846 is 1.033366
INFO:root:FL Epoch: 425 Done on worker:1846
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :388
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436519
INFO:root:Worker: 388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.510306
INFO:root:FL Epoch: 425 Norm Difference for worker 388 is 1.097999
INFO:root:FL Epoch: 425 Done on worker:388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1882
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461315
INFO:root:Worker: 1882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384928
INFO:root:FL Epoch: 425 Norm Difference for worker 1882 is 0.94668
INFO:root:FL Epoch: 425 Done on worker:1882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1236
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1236 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309767
INFO:root:Worker: 1236 Train Epoch: 1 [0/200 (0%)]	Loss: 0.257685
INFO:root:FL Epoch: 425 Norm Difference for worker 1236 is 1.017602
INFO:root:FL Epoch: 425 Done on worker:1236
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1388
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.397084
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665521
INFO:root:FL Epoch: 425 Norm Difference for worker 1388 is 1.046847
INFO:root:FL Epoch: 425 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :292
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 292 Train Epoch: 0 [0/201 (0%)]	Loss: 0.387764
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 292 Train Epoch: 1 [0/201 (0%)]	Loss: 0.256865
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 425 Norm Difference for worker 292 is 1.11563
INFO:root:FL Epoch: 425 Done on worker:292
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :764
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 764 Train Epoch: 0 [0/200 (0%)]	Loss: 0.668857
INFO:root:Worker: 764 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274127
INFO:root:FL Epoch: 425 Norm Difference for worker 764 is 1.049838
INFO:root:FL Epoch: 425 Done on worker:764
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 425 Training on worker :1941
INFO:root:FL Epoch: 425 Using Learning rate : 0.021395355656191273 
INFO:root:FL Epoch: 425 Normal Training
INFO:root:Worker: 1941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.757101
INFO:root:Worker: 1941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404262
INFO:root:FL Epoch: 425 Norm Difference for worker 1941 is 0.977743
INFO:root:FL Epoch: 425 Done on worker:1941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1882
INFO:root:Norm of Aggregated Model: 5154.9970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 425 Ends   ===================
INFO:root:Epoch:425 Global Model Test Loss:0.5396750201197231 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:425 Global Model Backdoor Test Loss:0.11188616541524728                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 426 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 426 Workers Selected : [1079, 159, 779, 1132, 1832, 1003, 299, 1684, 63, 759]
INFO:root:FL Epoch: 426 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.09985022 0.09985022 0.09985022
 0.10034948 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 426 Num points on workers: [200 201 200 200 200 200 201 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 426 Training on worker :1079
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1079 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529373
INFO:root:Worker: 1079 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283976
INFO:root:FL Epoch: 426 Norm Difference for worker 1079 is 0.983732
INFO:root:FL Epoch: 426 Done on worker:1079
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :159
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.664639
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.548283
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 426 Norm Difference for worker 159 is 1.047022
INFO:root:FL Epoch: 426 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :779
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530744
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432416
INFO:root:FL Epoch: 426 Norm Difference for worker 779 is 1.098057
INFO:root:FL Epoch: 426 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :1132
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1132 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380721
INFO:root:Worker: 1132 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503637
INFO:root:FL Epoch: 426 Norm Difference for worker 1132 is 0.906004
INFO:root:FL Epoch: 426 Done on worker:1132
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :1832
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.993955
INFO:root:Worker: 1832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.764059
INFO:root:FL Epoch: 426 Norm Difference for worker 1832 is 1.080546
INFO:root:FL Epoch: 426 Done on worker:1832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :1003
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1003 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579783
INFO:root:Worker: 1003 Train Epoch: 1 [0/200 (0%)]	Loss: 0.511881
INFO:root:FL Epoch: 426 Norm Difference for worker 1003 is 0.955095
INFO:root:FL Epoch: 426 Done on worker:1003
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :299
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 299 Train Epoch: 0 [0/201 (0%)]	Loss: 0.692814
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 299 Train Epoch: 1 [0/201 (0%)]	Loss: 0.448480
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 426 Norm Difference for worker 299 is 0.98051
INFO:root:FL Epoch: 426 Done on worker:299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :1684
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 1684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.838344
INFO:root:Worker: 1684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550233
INFO:root:FL Epoch: 426 Norm Difference for worker 1684 is 1.055439
INFO:root:FL Epoch: 426 Done on worker:1684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :63
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 63 Train Epoch: 0 [0/201 (0%)]	Loss: 0.461788
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 63 Train Epoch: 1 [0/201 (0%)]	Loss: 0.357990
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 426 Norm Difference for worker 63 is 0.993943
INFO:root:FL Epoch: 426 Done on worker:63
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 426 Training on worker :759
INFO:root:FL Epoch: 426 Using Learning rate : 0.02135256494487889 
INFO:root:FL Epoch: 426 Normal Training
INFO:root:Worker: 759 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549816
INFO:root:Worker: 759 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474596
INFO:root:FL Epoch: 426 Norm Difference for worker 759 is 1.009975
INFO:root:FL Epoch: 426 Done on worker:759
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1132
INFO:root:Norm of Aggregated Model: 5154.99658203125
INFO:root:Aggregating After Defense
INFO:root:================FL round 426 Ends   ===================
INFO:root:Epoch:426 Global Model Test Loss:0.564600837581298 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:426 Global Model Backdoor Test Loss:0.18646962692340216                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 427 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 427 Workers Selected : [1137, 1200, 204, 301, 1744, 55, 1386, 1730, 15, 1910]
INFO:root:FL Epoch: 427 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.1002994 0.0998004 0.1002994 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 427 Num points on workers: [200 200 201 201 200 201 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 427 Training on worker :1137
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1137 Train Epoch: 0 [0/200 (0%)]	Loss: 0.847644
INFO:root:Worker: 1137 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579793
INFO:root:FL Epoch: 427 Norm Difference for worker 1137 is 1.015394
INFO:root:FL Epoch: 427 Done on worker:1137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1200
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1200 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605055
INFO:root:Worker: 1200 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418376
INFO:root:FL Epoch: 427 Norm Difference for worker 1200 is 0.837181
INFO:root:FL Epoch: 427 Done on worker:1200
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :204
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 204 Train Epoch: 0 [0/201 (0%)]	Loss: 0.423627
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 204 Train Epoch: 1 [0/201 (0%)]	Loss: 0.449532
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 427 Norm Difference for worker 204 is 0.897716
INFO:root:FL Epoch: 427 Done on worker:204
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :301
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 301 Train Epoch: 0 [0/201 (0%)]	Loss: 0.704059
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 301 Train Epoch: 1 [0/201 (0%)]	Loss: 0.513721
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 427 Norm Difference for worker 301 is 0.982442
INFO:root:FL Epoch: 427 Done on worker:301
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1744
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1744 Train Epoch: 0 [0/200 (0%)]	Loss: 0.651113
INFO:root:Worker: 1744 Train Epoch: 1 [0/200 (0%)]	Loss: 0.244170
INFO:root:FL Epoch: 427 Norm Difference for worker 1744 is 0.87911
INFO:root:FL Epoch: 427 Done on worker:1744
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :55
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 55 Train Epoch: 0 [0/201 (0%)]	Loss: 0.435521
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 55 Train Epoch: 1 [0/201 (0%)]	Loss: 0.581512
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 427 Norm Difference for worker 55 is 0.856608
INFO:root:FL Epoch: 427 Done on worker:55
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1386
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601157
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445874
INFO:root:FL Epoch: 427 Norm Difference for worker 1386 is 0.870641
INFO:root:FL Epoch: 427 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1730
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1730 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686360
INFO:root:Worker: 1730 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557663
INFO:root:FL Epoch: 427 Norm Difference for worker 1730 is 0.913788
INFO:root:FL Epoch: 427 Done on worker:1730
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :15
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 15 Train Epoch: 0 [0/201 (0%)]	Loss: 0.525295
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 15 Train Epoch: 1 [0/201 (0%)]	Loss: 0.369360
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 427 Norm Difference for worker 15 is 0.89426
INFO:root:FL Epoch: 427 Done on worker:15
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 427 Training on worker :1910
INFO:root:FL Epoch: 427 Using Learning rate : 0.021309859814989132 
INFO:root:FL Epoch: 427 Normal Training
INFO:root:Worker: 1910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600489
INFO:root:Worker: 1910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.608081
INFO:root:FL Epoch: 427 Norm Difference for worker 1910 is 0.871917
INFO:root:FL Epoch: 427 Done on worker:1910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1200
INFO:root:Norm of Aggregated Model: 5154.9970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 427 Ends   ===================
INFO:root:Epoch:427 Global Model Test Loss:0.5217706263065338 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:427 Global Model Backdoor Test Loss:0.15086657057205835                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 428 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 428 Workers Selected : [1194, 220, 287, 1078, 1247, 1042, 1099, 1332, 1554, 391]
INFO:root:FL Epoch: 428 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 428 Num points on workers: [200 201 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 428 Training on worker :1194
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1194 Train Epoch: 0 [0/200 (0%)]	Loss: 0.410071
INFO:root:Worker: 1194 Train Epoch: 1 [0/200 (0%)]	Loss: 0.837332
INFO:root:FL Epoch: 428 Norm Difference for worker 1194 is 0.798596
INFO:root:FL Epoch: 428 Done on worker:1194
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :220
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 220 Train Epoch: 0 [0/201 (0%)]	Loss: 0.662479
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 220 Train Epoch: 1 [0/201 (0%)]	Loss: 0.712279
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 428 Norm Difference for worker 220 is 0.81883
INFO:root:FL Epoch: 428 Done on worker:220
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :287
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 287 Train Epoch: 0 [0/201 (0%)]	Loss: 0.370548
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 287 Train Epoch: 1 [0/201 (0%)]	Loss: 0.658481
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 428 Norm Difference for worker 287 is 0.863653
INFO:root:FL Epoch: 428 Done on worker:287
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1078
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1078 Train Epoch: 0 [0/200 (0%)]	Loss: 0.821106
INFO:root:Worker: 1078 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568412
INFO:root:FL Epoch: 428 Norm Difference for worker 1078 is 0.8037
INFO:root:FL Epoch: 428 Done on worker:1078
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1247
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.288122
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516499
INFO:root:FL Epoch: 428 Norm Difference for worker 1247 is 0.909151
INFO:root:FL Epoch: 428 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1042
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1042 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606259
INFO:root:Worker: 1042 Train Epoch: 1 [0/200 (0%)]	Loss: 0.643977
INFO:root:FL Epoch: 428 Norm Difference for worker 1042 is 0.906798
INFO:root:FL Epoch: 428 Done on worker:1042
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1099
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1099 Train Epoch: 0 [0/200 (0%)]	Loss: 0.679863
INFO:root:Worker: 1099 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565677
INFO:root:FL Epoch: 428 Norm Difference for worker 1099 is 0.874041
INFO:root:FL Epoch: 428 Done on worker:1099
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1332
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654745
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479932
INFO:root:FL Epoch: 428 Norm Difference for worker 1332 is 0.885724
INFO:root:FL Epoch: 428 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :1554
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508939
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.568711
INFO:root:FL Epoch: 428 Norm Difference for worker 1554 is 0.793779
INFO:root:FL Epoch: 428 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 428 Training on worker :391
INFO:root:FL Epoch: 428 Using Learning rate : 0.021267240095359154 
INFO:root:FL Epoch: 428 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575057
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.673250
INFO:root:FL Epoch: 428 Norm Difference for worker 391 is 0.898575
INFO:root:FL Epoch: 428 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1078
INFO:root:Norm of Aggregated Model: 5154.9970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 428 Ends   ===================
INFO:root:Epoch:428 Global Model Test Loss:0.5204483726445366 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:428 Global Model Backdoor Test Loss:0.1849422243734201                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 429 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 429 Workers Selected : [952, 527, 1429, 276, 1682, 440, 160, 1859, 726, 1934]
INFO:root:FL Epoch: 429 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 429 Num points on workers: [200 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 429 Training on worker :952
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553938
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.474932
INFO:root:FL Epoch: 429 Norm Difference for worker 952 is 0.76742
INFO:root:FL Epoch: 429 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :527
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 527 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472466
INFO:root:Worker: 527 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530680
INFO:root:FL Epoch: 429 Norm Difference for worker 527 is 0.773759
INFO:root:FL Epoch: 429 Done on worker:527
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1429
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512265
INFO:root:Worker: 1429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256257
INFO:root:FL Epoch: 429 Norm Difference for worker 1429 is 0.738553
INFO:root:FL Epoch: 429 Done on worker:1429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :276
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 276 Train Epoch: 0 [0/201 (0%)]	Loss: 0.607276
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 276 Train Epoch: 1 [0/201 (0%)]	Loss: 0.415584
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 429 Norm Difference for worker 276 is 0.834993
INFO:root:FL Epoch: 429 Done on worker:276
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1682
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395163
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688201
INFO:root:FL Epoch: 429 Norm Difference for worker 1682 is 0.79767
INFO:root:FL Epoch: 429 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :440
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684338
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439143
INFO:root:FL Epoch: 429 Norm Difference for worker 440 is 0.779883
INFO:root:FL Epoch: 429 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :160
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 160 Train Epoch: 0 [0/201 (0%)]	Loss: 0.835115
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 160 Train Epoch: 1 [0/201 (0%)]	Loss: 0.575469
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 429 Norm Difference for worker 160 is 0.82961
INFO:root:FL Epoch: 429 Done on worker:160
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1859
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506575
INFO:root:Worker: 1859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630808
INFO:root:FL Epoch: 429 Norm Difference for worker 1859 is 0.779907
INFO:root:FL Epoch: 429 Done on worker:1859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :726
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 726 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383570
INFO:root:Worker: 726 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399302
INFO:root:FL Epoch: 429 Norm Difference for worker 726 is 0.835056
INFO:root:FL Epoch: 429 Done on worker:726
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 429 Training on worker :1934
INFO:root:FL Epoch: 429 Using Learning rate : 0.021224705615168437 
INFO:root:FL Epoch: 429 Normal Training
INFO:root:Worker: 1934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629946
INFO:root:Worker: 1934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461942
INFO:root:FL Epoch: 429 Norm Difference for worker 1934 is 0.838131
INFO:root:FL Epoch: 429 Done on worker:1934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1429
INFO:root:Norm of Aggregated Model: 5154.9970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 429 Ends   ===================
INFO:root:Epoch:429 Global Model Test Loss:0.5222857489305384 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:429 Global Model Backdoor Test Loss:0.12493121127287547                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 430 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 430 Workers Selected : [818, 199, 1608, 1016, 974, 394, 1885, 873, 169, 613]
INFO:root:FL Epoch: 430 Fraction of points on each worker in this round: [0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 430 Num points on workers: [200 201 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 430 Training on worker :818
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 818 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398472
INFO:root:Worker: 818 Train Epoch: 1 [0/200 (0%)]	Loss: 0.579044
INFO:root:FL Epoch: 430 Norm Difference for worker 818 is 0.896704
INFO:root:FL Epoch: 430 Done on worker:818
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :199
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 199 Train Epoch: 0 [0/201 (0%)]	Loss: 0.839252
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 199 Train Epoch: 1 [0/201 (0%)]	Loss: 0.577890
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 430 Norm Difference for worker 199 is 0.94332
INFO:root:FL Epoch: 430 Done on worker:199
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1608
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1608 Train Epoch: 0 [0/200 (0%)]	Loss: 0.303182
INFO:root:Worker: 1608 Train Epoch: 1 [0/200 (0%)]	Loss: 0.645151
INFO:root:FL Epoch: 430 Norm Difference for worker 1608 is 0.909378
INFO:root:FL Epoch: 430 Done on worker:1608
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1016
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1016 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623213
INFO:root:Worker: 1016 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491589
INFO:root:FL Epoch: 430 Norm Difference for worker 1016 is 0.893025
INFO:root:FL Epoch: 430 Done on worker:1016
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :974
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 974 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589289
INFO:root:Worker: 974 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415296
INFO:root:FL Epoch: 430 Norm Difference for worker 974 is 0.795625
INFO:root:FL Epoch: 430 Done on worker:974
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :394
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 394 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577030
INFO:root:Worker: 394 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544325
INFO:root:FL Epoch: 430 Norm Difference for worker 394 is 0.940087
INFO:root:FL Epoch: 430 Done on worker:394
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :1885
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 1885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544123
INFO:root:Worker: 1885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.561406
INFO:root:FL Epoch: 430 Norm Difference for worker 1885 is 0.890406
INFO:root:FL Epoch: 430 Done on worker:1885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :873
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 873 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540926
INFO:root:Worker: 873 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337838
INFO:root:FL Epoch: 430 Norm Difference for worker 873 is 0.892602
INFO:root:FL Epoch: 430 Done on worker:873
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :169
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 169 Train Epoch: 0 [0/201 (0%)]	Loss: 0.887297
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 169 Train Epoch: 1 [0/201 (0%)]	Loss: 0.392816
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 430 Norm Difference for worker 169 is 0.888575
INFO:root:FL Epoch: 430 Done on worker:169
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 430 Training on worker :613
INFO:root:FL Epoch: 430 Using Learning rate : 0.0211822562039381 
INFO:root:FL Epoch: 430 Normal Training
INFO:root:Worker: 613 Train Epoch: 0 [0/200 (0%)]	Loss: 0.501379
INFO:root:Worker: 613 Train Epoch: 1 [0/200 (0%)]	Loss: 0.369263
INFO:root:FL Epoch: 430 Norm Difference for worker 613 is 0.925726
INFO:root:FL Epoch: 430 Done on worker:613
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 974
INFO:root:Norm of Aggregated Model: 5154.9970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 430 Ends   ===================
INFO:root:Epoch:430 Global Model Test Loss:0.523316402645672 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:430 Global Model Backdoor Test Loss:0.19181441267331442                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 431 Begins ===================
INFO:root:FL Epoch: 431 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 431 Workers Selected : [0, 1247, 1081, 1909, 356, 1724, 930, 1056, 989, 267]
INFO:root:FL Epoch: 431 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 431 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 431 Training on worker :0
INFO:root:FL Epoch: 431 Using Learning rate : 0.004227978338306044 
INFO:root:FL Epoch: 431 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.324166
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.184654
INFO:root:FL Epoch: 431 Worker: 0 Backdoor Test Loss: 0.14948191245396933 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 431 Worker: 0 Backdoor Train Loss: 0.16864759102463722 Backdoor Train Accuracy: 97.0
INFO:root:FL Epoch: 431 Norm Difference for worker 0 is 0.135258
INFO:root:FL Epoch: 431 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1247
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1247 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796221
INFO:root:Worker: 1247 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575036
INFO:root:FL Epoch: 431 Norm Difference for worker 1247 is 0.776064
INFO:root:FL Epoch: 431 Done on worker:1247
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1081
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.837314
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494822
INFO:root:FL Epoch: 431 Norm Difference for worker 1081 is 0.86761
INFO:root:FL Epoch: 431 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1909
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1909 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493593
INFO:root:Worker: 1909 Train Epoch: 1 [0/200 (0%)]	Loss: 0.740565
INFO:root:FL Epoch: 431 Norm Difference for worker 1909 is 0.850528
INFO:root:FL Epoch: 431 Done on worker:1909
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :356
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 356 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803913
INFO:root:Worker: 356 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427356
INFO:root:FL Epoch: 431 Norm Difference for worker 356 is 0.88086
INFO:root:FL Epoch: 431 Done on worker:356
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1724
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.484805
INFO:root:Worker: 1724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523701
INFO:root:FL Epoch: 431 Norm Difference for worker 1724 is 0.824857
INFO:root:FL Epoch: 431 Done on worker:1724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :930
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 930 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685698
INFO:root:Worker: 930 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266798
INFO:root:FL Epoch: 431 Norm Difference for worker 930 is 0.827339
INFO:root:FL Epoch: 431 Done on worker:930
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :1056
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 1056 Train Epoch: 0 [0/200 (0%)]	Loss: 0.535924
INFO:root:Worker: 1056 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503905
INFO:root:FL Epoch: 431 Norm Difference for worker 1056 is 0.800956
INFO:root:FL Epoch: 431 Done on worker:1056
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :989
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 989 Train Epoch: 0 [0/200 (0%)]	Loss: 0.557472
INFO:root:Worker: 989 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470226
INFO:root:FL Epoch: 431 Norm Difference for worker 989 is 0.800804
INFO:root:FL Epoch: 431 Done on worker:989
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 431 Training on worker :267
INFO:root:FL Epoch: 431 Using Learning rate : 0.021139891691530223 
INFO:root:FL Epoch: 431 Normal Training
INFO:root:Worker: 267 Train Epoch: 0 [0/201 (0%)]	Loss: 0.620011
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 267 Train Epoch: 1 [0/201 (0%)]	Loss: 0.449000
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 431 Norm Difference for worker 267 is 0.861819
INFO:root:FL Epoch: 431 Done on worker:267
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.9970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 431 Ends   ===================
INFO:root:Epoch:431 Global Model Test Loss:0.5251904305289773 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:431 Global Model Backdoor Test Loss:0.14948191245396933                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 432 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 432 Workers Selected : [441, 203, 390, 315, 1475, 825, 1493, 1133, 337, 749]
INFO:root:FL Epoch: 432 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.10034948 0.09985022]
INFO:root:FL Epoch: 432 Num points on workers: [200 201 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 432 Training on worker :441
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 441 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615410
INFO:root:Worker: 441 Train Epoch: 1 [0/200 (0%)]	Loss: 0.818285
INFO:root:FL Epoch: 432 Norm Difference for worker 441 is 1.022556
INFO:root:FL Epoch: 432 Done on worker:441
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :203
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 203 Train Epoch: 0 [0/201 (0%)]	Loss: 0.560272
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 203 Train Epoch: 1 [0/201 (0%)]	Loss: 0.429005
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 432 Norm Difference for worker 203 is 0.87016
INFO:root:FL Epoch: 432 Done on worker:203
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :390
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 390 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550986
INFO:root:Worker: 390 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614705
INFO:root:FL Epoch: 432 Norm Difference for worker 390 is 0.941109
INFO:root:FL Epoch: 432 Done on worker:390
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :315
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 315 Train Epoch: 0 [0/201 (0%)]	Loss: 0.364312
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 315 Train Epoch: 1 [0/201 (0%)]	Loss: 0.643858
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 432 Norm Difference for worker 315 is 0.841272
INFO:root:FL Epoch: 432 Done on worker:315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1475
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.902256
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.611637
INFO:root:FL Epoch: 432 Norm Difference for worker 1475 is 0.922643
INFO:root:FL Epoch: 432 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :825
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 825 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506340
INFO:root:Worker: 825 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255357
INFO:root:FL Epoch: 432 Norm Difference for worker 825 is 0.812122
INFO:root:FL Epoch: 432 Done on worker:825
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1493
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1493 Train Epoch: 0 [0/200 (0%)]	Loss: 0.309792
INFO:root:Worker: 1493 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427086
INFO:root:FL Epoch: 432 Norm Difference for worker 1493 is 0.913753
INFO:root:FL Epoch: 432 Done on worker:1493
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :1133
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 1133 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588905
INFO:root:Worker: 1133 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501720
INFO:root:FL Epoch: 432 Norm Difference for worker 1133 is 0.928699
INFO:root:FL Epoch: 432 Done on worker:1133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :337
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 337 Train Epoch: 0 [0/201 (0%)]	Loss: 0.794276
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 337 Train Epoch: 1 [0/201 (0%)]	Loss: 0.342716
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 432 Norm Difference for worker 337 is 0.856412
INFO:root:FL Epoch: 432 Done on worker:337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 432 Training on worker :749
INFO:root:FL Epoch: 432 Using Learning rate : 0.021097611908147164 
INFO:root:FL Epoch: 432 Normal Training
INFO:root:Worker: 749 Train Epoch: 0 [0/200 (0%)]	Loss: 0.541567
INFO:root:Worker: 749 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528693
INFO:root:FL Epoch: 432 Norm Difference for worker 749 is 0.810439
INFO:root:FL Epoch: 432 Done on worker:749
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 749
INFO:root:Norm of Aggregated Model: 5154.9970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 432 Ends   ===================
INFO:root:Epoch:432 Global Model Test Loss:0.5139649755814496 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:432 Global Model Backdoor Test Loss:0.14280778045455614                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 433 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 433 Workers Selected : [1875, 506, 1304, 1537, 1355, 88, 1253, 1850, 1005, 878]
INFO:root:FL Epoch: 433 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 433 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 433 Training on worker :1875
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1875 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376908
INFO:root:Worker: 1875 Train Epoch: 1 [0/200 (0%)]	Loss: 0.469155
INFO:root:FL Epoch: 433 Norm Difference for worker 1875 is 0.799579
INFO:root:FL Epoch: 433 Done on worker:1875
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :506
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 506 Train Epoch: 0 [0/200 (0%)]	Loss: 0.583808
INFO:root:Worker: 506 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445985
INFO:root:FL Epoch: 433 Norm Difference for worker 506 is 0.861709
INFO:root:FL Epoch: 433 Done on worker:506
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1304
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1304 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460813
INFO:root:Worker: 1304 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417292
INFO:root:FL Epoch: 433 Norm Difference for worker 1304 is 0.774572
INFO:root:FL Epoch: 433 Done on worker:1304
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1537
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1537 Train Epoch: 0 [0/200 (0%)]	Loss: 0.899020
INFO:root:Worker: 1537 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408471
INFO:root:FL Epoch: 433 Norm Difference for worker 1537 is 0.880923
INFO:root:FL Epoch: 433 Done on worker:1537
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1355
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1355 Train Epoch: 0 [0/200 (0%)]	Loss: 0.700356
INFO:root:Worker: 1355 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454050
INFO:root:FL Epoch: 433 Norm Difference for worker 1355 is 0.838454
INFO:root:FL Epoch: 433 Done on worker:1355
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :88
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 88 Train Epoch: 0 [0/201 (0%)]	Loss: 0.562726
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 88 Train Epoch: 1 [0/201 (0%)]	Loss: 0.448096
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 433 Norm Difference for worker 88 is 0.799227
INFO:root:FL Epoch: 433 Done on worker:88
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1253
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1253 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615468
INFO:root:Worker: 1253 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695688
INFO:root:FL Epoch: 433 Norm Difference for worker 1253 is 0.851835
INFO:root:FL Epoch: 433 Done on worker:1253
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1850
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1850 Train Epoch: 0 [0/200 (0%)]	Loss: 0.409686
INFO:root:Worker: 1850 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380762
INFO:root:FL Epoch: 433 Norm Difference for worker 1850 is 0.749
INFO:root:FL Epoch: 433 Done on worker:1850
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :1005
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 1005 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736917
INFO:root:Worker: 1005 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523683
INFO:root:FL Epoch: 433 Norm Difference for worker 1005 is 0.837099
INFO:root:FL Epoch: 433 Done on worker:1005
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 433 Training on worker :878
INFO:root:FL Epoch: 433 Using Learning rate : 0.021055416684330867 
INFO:root:FL Epoch: 433 Normal Training
INFO:root:Worker: 878 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637832
INFO:root:Worker: 878 Train Epoch: 1 [0/200 (0%)]	Loss: 0.411084
INFO:root:FL Epoch: 433 Norm Difference for worker 878 is 0.800668
INFO:root:FL Epoch: 433 Done on worker:878
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 88
INFO:root:Norm of Aggregated Model: 5154.9970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 433 Ends   ===================
INFO:root:Epoch:433 Global Model Test Loss:0.5046149422140682 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:433 Global Model Backdoor Test Loss:0.1931113675236702                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 434 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 434 Workers Selected : [92, 1520, 428, 1786, 1561, 1381, 1927, 775, 1443, 105]
INFO:root:FL Epoch: 434 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 434 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 434 Training on worker :92
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.404748
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.636929
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 92 is 0.71002
INFO:root:FL Epoch: 434 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1520
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372470
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.501952
INFO:root:FL Epoch: 434 Norm Difference for worker 1520 is 0.716248
INFO:root:FL Epoch: 434 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :428
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532629
INFO:root:Worker: 428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491199
INFO:root:FL Epoch: 434 Norm Difference for worker 428 is 0.681649
INFO:root:FL Epoch: 434 Done on worker:428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1786
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1786 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387586
INFO:root:Worker: 1786 Train Epoch: 1 [0/200 (0%)]	Loss: 0.337295
INFO:root:FL Epoch: 434 Norm Difference for worker 1786 is 0.646929
INFO:root:FL Epoch: 434 Done on worker:1786
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1561
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628373
INFO:root:Worker: 1561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.781876
INFO:root:FL Epoch: 434 Norm Difference for worker 1561 is 0.735467
INFO:root:FL Epoch: 434 Done on worker:1561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1381
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559839
INFO:root:Worker: 1381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612919
INFO:root:FL Epoch: 434 Norm Difference for worker 1381 is 0.684196
INFO:root:FL Epoch: 434 Done on worker:1381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1927
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1927 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593123
INFO:root:Worker: 1927 Train Epoch: 1 [0/200 (0%)]	Loss: 0.560998
INFO:root:FL Epoch: 434 Norm Difference for worker 1927 is 0.65727
INFO:root:FL Epoch: 434 Done on worker:1927
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :775
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641267
INFO:root:Worker: 775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578348
INFO:root:FL Epoch: 434 Norm Difference for worker 775 is 0.696356
INFO:root:FL Epoch: 434 Done on worker:775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :1443
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 1443 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766143
INFO:root:Worker: 1443 Train Epoch: 1 [0/200 (0%)]	Loss: 0.466003
INFO:root:FL Epoch: 434 Norm Difference for worker 1443 is 0.705979
INFO:root:FL Epoch: 434 Done on worker:1443
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 434 Training on worker :105
INFO:root:FL Epoch: 434 Using Learning rate : 0.021013305850962206 
INFO:root:FL Epoch: 434 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.520530
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.418119
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 434 Norm Difference for worker 105 is 0.676128
INFO:root:FL Epoch: 434 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1786
INFO:root:Norm of Aggregated Model: 5154.9970703125
INFO:root:Aggregating After Defense
INFO:root:================FL round 434 Ends   ===================
INFO:root:Epoch:434 Global Model Test Loss:0.5130526581231285 and Test Accuracy:75.0 
INFO:root:Epoch:434 Global Model Backdoor Test Loss:0.20486288021008173                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 435 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 435 Workers Selected : [1773, 788, 1274, 837, 951, 1315, 455, 881, 1413, 344]
INFO:root:FL Epoch: 435 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 435 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 435 Training on worker :1773
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605355
INFO:root:Worker: 1773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.717667
INFO:root:FL Epoch: 435 Norm Difference for worker 1773 is 0.775951
INFO:root:FL Epoch: 435 Done on worker:1773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :788
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661879
INFO:root:Worker: 788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315402
INFO:root:FL Epoch: 435 Norm Difference for worker 788 is 0.684078
INFO:root:FL Epoch: 435 Done on worker:788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1274
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1274 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641520
INFO:root:Worker: 1274 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447991
INFO:root:FL Epoch: 435 Norm Difference for worker 1274 is 0.885655
INFO:root:FL Epoch: 435 Done on worker:1274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :837
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 837 Train Epoch: 0 [0/200 (0%)]	Loss: 0.393497
INFO:root:Worker: 837 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408618
INFO:root:FL Epoch: 435 Norm Difference for worker 837 is 0.765488
INFO:root:FL Epoch: 435 Done on worker:837
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :951
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 951 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607981
INFO:root:Worker: 951 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452592
INFO:root:FL Epoch: 435 Norm Difference for worker 951 is 0.807733
INFO:root:FL Epoch: 435 Done on worker:951
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1315
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363681
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581403
INFO:root:FL Epoch: 435 Norm Difference for worker 1315 is 0.807361
INFO:root:FL Epoch: 435 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :455
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.942217
INFO:root:Worker: 455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531860
INFO:root:FL Epoch: 435 Norm Difference for worker 455 is 0.783157
INFO:root:FL Epoch: 435 Done on worker:455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :881
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 881 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465892
INFO:root:Worker: 881 Train Epoch: 1 [0/200 (0%)]	Loss: 0.251763
INFO:root:FL Epoch: 435 Norm Difference for worker 881 is 0.675668
INFO:root:FL Epoch: 435 Done on worker:881
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :1413
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 1413 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547141
INFO:root:Worker: 1413 Train Epoch: 1 [0/200 (0%)]	Loss: 0.572757
INFO:root:FL Epoch: 435 Norm Difference for worker 1413 is 0.77201
INFO:root:FL Epoch: 435 Done on worker:1413
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 435 Training on worker :344
INFO:root:FL Epoch: 435 Using Learning rate : 0.020971279239260284 
INFO:root:FL Epoch: 435 Normal Training
INFO:root:Worker: 344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473205
INFO:root:Worker: 344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638450
INFO:root:FL Epoch: 435 Norm Difference for worker 344 is 0.82865
INFO:root:FL Epoch: 435 Done on worker:344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 881
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 435 Ends   ===================
INFO:root:Epoch:435 Global Model Test Loss:0.5235336124897003 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:435 Global Model Backdoor Test Loss:0.08923792280256748                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 436 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 436 Workers Selected : [36, 1797, 819, 1868, 1615, 1923, 1712, 1616, 1738, 255]
INFO:root:FL Epoch: 436 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 436 Num points on workers: [201 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 436 Training on worker :36
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 36 Train Epoch: 0 [0/201 (0%)]	Loss: 0.686524
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 36 Train Epoch: 1 [0/201 (0%)]	Loss: 0.272684
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 36 is 0.882128
INFO:root:FL Epoch: 436 Done on worker:36
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1797
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1797 Train Epoch: 0 [0/200 (0%)]	Loss: 1.156685
INFO:root:Worker: 1797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574684
INFO:root:FL Epoch: 436 Norm Difference for worker 1797 is 1.050288
INFO:root:FL Epoch: 436 Done on worker:1797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :819
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 819 Train Epoch: 0 [0/200 (0%)]	Loss: 0.827574
INFO:root:Worker: 819 Train Epoch: 1 [0/200 (0%)]	Loss: 0.844103
INFO:root:FL Epoch: 436 Norm Difference for worker 819 is 1.010248
INFO:root:FL Epoch: 436 Done on worker:819
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1868
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523972
INFO:root:Worker: 1868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620695
INFO:root:FL Epoch: 436 Norm Difference for worker 1868 is 1.099284
INFO:root:FL Epoch: 436 Done on worker:1868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1615
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1615 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703425
INFO:root:Worker: 1615 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356343
INFO:root:FL Epoch: 436 Norm Difference for worker 1615 is 0.973204
INFO:root:FL Epoch: 436 Done on worker:1615
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1923
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1923 Train Epoch: 0 [0/200 (0%)]	Loss: 0.500408
INFO:root:Worker: 1923 Train Epoch: 1 [0/200 (0%)]	Loss: 0.356644
INFO:root:FL Epoch: 436 Norm Difference for worker 1923 is 1.005032
INFO:root:FL Epoch: 436 Done on worker:1923
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1712
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1712 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723583
INFO:root:Worker: 1712 Train Epoch: 1 [0/200 (0%)]	Loss: 0.725727
INFO:root:FL Epoch: 436 Norm Difference for worker 1712 is 1.059582
INFO:root:FL Epoch: 436 Done on worker:1712
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1616
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1616 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564371
INFO:root:Worker: 1616 Train Epoch: 1 [0/200 (0%)]	Loss: 0.505921
INFO:root:FL Epoch: 436 Norm Difference for worker 1616 is 0.983839
INFO:root:FL Epoch: 436 Done on worker:1616
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :1738
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 1738 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597617
INFO:root:Worker: 1738 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422595
INFO:root:FL Epoch: 436 Norm Difference for worker 1738 is 0.957552
INFO:root:FL Epoch: 436 Done on worker:1738
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 436 Training on worker :255
INFO:root:FL Epoch: 436 Using Learning rate : 0.02092933668078176 
INFO:root:FL Epoch: 436 Normal Training
INFO:root:Worker: 255 Train Epoch: 0 [0/201 (0%)]	Loss: 0.445013
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 255 Train Epoch: 1 [0/201 (0%)]	Loss: 0.494737
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 436 Norm Difference for worker 255 is 1.002481
INFO:root:FL Epoch: 436 Done on worker:255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 36
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 436 Ends   ===================
INFO:root:Epoch:436 Global Model Test Loss:0.5014453092042137 and Test Accuracy:75.0 
INFO:root:Epoch:436 Global Model Backdoor Test Loss:0.12318454558650653                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 437 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 437 Workers Selected : [1643, 944, 1798, 836, 1340, 239, 1135, 889, 562, 1554]
INFO:root:FL Epoch: 437 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 437 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 437 Training on worker :1643
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.944583
INFO:root:Worker: 1643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446770
INFO:root:FL Epoch: 437 Norm Difference for worker 1643 is 0.795011
INFO:root:FL Epoch: 437 Done on worker:1643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :944
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 944 Train Epoch: 0 [0/200 (0%)]	Loss: 0.792108
INFO:root:Worker: 944 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331777
INFO:root:FL Epoch: 437 Norm Difference for worker 944 is 0.865628
INFO:root:FL Epoch: 437 Done on worker:944
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1798
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671009
INFO:root:Worker: 1798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526174
INFO:root:FL Epoch: 437 Norm Difference for worker 1798 is 0.821626
INFO:root:FL Epoch: 437 Done on worker:1798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :836
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 836 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555400
INFO:root:Worker: 836 Train Epoch: 1 [0/200 (0%)]	Loss: 0.399690
INFO:root:FL Epoch: 437 Norm Difference for worker 836 is 0.78284
INFO:root:FL Epoch: 437 Done on worker:836
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1340
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1340 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548499
INFO:root:Worker: 1340 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490144
INFO:root:FL Epoch: 437 Norm Difference for worker 1340 is 0.888299
INFO:root:FL Epoch: 437 Done on worker:1340
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :239
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 239 Train Epoch: 0 [0/201 (0%)]	Loss: 0.723090
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 239 Train Epoch: 1 [0/201 (0%)]	Loss: 0.604521
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 437 Norm Difference for worker 239 is 1.002225
INFO:root:FL Epoch: 437 Done on worker:239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1135
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1135 Train Epoch: 0 [0/200 (0%)]	Loss: 0.511811
INFO:root:Worker: 1135 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531994
INFO:root:FL Epoch: 437 Norm Difference for worker 1135 is 0.830681
INFO:root:FL Epoch: 437 Done on worker:1135
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :889
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.443302
INFO:root:Worker: 889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.357131
INFO:root:FL Epoch: 437 Norm Difference for worker 889 is 0.872226
INFO:root:FL Epoch: 437 Done on worker:889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :562
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 562 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422602
INFO:root:Worker: 562 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419687
INFO:root:FL Epoch: 437 Norm Difference for worker 562 is 0.852533
INFO:root:FL Epoch: 437 Done on worker:562
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 437 Training on worker :1554
INFO:root:FL Epoch: 437 Using Learning rate : 0.020887478007420197 
INFO:root:FL Epoch: 437 Normal Training
INFO:root:Worker: 1554 Train Epoch: 0 [0/200 (0%)]	Loss: 0.247251
INFO:root:Worker: 1554 Train Epoch: 1 [0/200 (0%)]	Loss: 0.602419
INFO:root:FL Epoch: 437 Norm Difference for worker 1554 is 0.744241
INFO:root:FL Epoch: 437 Done on worker:1554
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1554
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 437 Ends   ===================
INFO:root:Epoch:437 Global Model Test Loss:0.5010319702765521 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:437 Global Model Backdoor Test Loss:0.12677598372101784                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 438 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 438 Workers Selected : [1114, 768, 1104, 1611, 1520, 325, 986, 1578, 381, 636]
INFO:root:FL Epoch: 438 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 438 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 438 Training on worker :1114
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1114 Train Epoch: 0 [0/200 (0%)]	Loss: 0.562755
INFO:root:Worker: 1114 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578159
INFO:root:FL Epoch: 438 Norm Difference for worker 1114 is 0.927836
INFO:root:FL Epoch: 438 Done on worker:1114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :768
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518795
INFO:root:Worker: 768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493644
INFO:root:FL Epoch: 438 Norm Difference for worker 768 is 0.749707
INFO:root:FL Epoch: 438 Done on worker:768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1104
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1104 Train Epoch: 0 [0/200 (0%)]	Loss: 0.950560
INFO:root:Worker: 1104 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571803
INFO:root:FL Epoch: 438 Norm Difference for worker 1104 is 0.805508
INFO:root:FL Epoch: 438 Done on worker:1104
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1611
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.623729
INFO:root:Worker: 1611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463397
INFO:root:FL Epoch: 438 Norm Difference for worker 1611 is 0.828377
INFO:root:FL Epoch: 438 Done on worker:1611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1520
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1520 Train Epoch: 0 [0/200 (0%)]	Loss: 0.337496
INFO:root:Worker: 1520 Train Epoch: 1 [0/200 (0%)]	Loss: 0.419280
INFO:root:FL Epoch: 438 Norm Difference for worker 1520 is 0.809103
INFO:root:FL Epoch: 438 Done on worker:1520
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :325
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576505
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.174236
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 438 Norm Difference for worker 325 is 0.831619
INFO:root:FL Epoch: 438 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :986
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 986 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471418
INFO:root:Worker: 986 Train Epoch: 1 [0/200 (0%)]	Loss: 0.516034
INFO:root:FL Epoch: 438 Norm Difference for worker 986 is 0.824162
INFO:root:FL Epoch: 438 Done on worker:986
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :1578
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 1578 Train Epoch: 0 [0/200 (0%)]	Loss: 0.530340
INFO:root:Worker: 1578 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384432
INFO:root:FL Epoch: 438 Norm Difference for worker 1578 is 0.678888
INFO:root:FL Epoch: 438 Done on worker:1578
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :381
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 381 Train Epoch: 0 [0/200 (0%)]	Loss: 0.469583
INFO:root:Worker: 381 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425767
INFO:root:FL Epoch: 438 Norm Difference for worker 381 is 0.789854
INFO:root:FL Epoch: 438 Done on worker:381
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 438 Training on worker :636
INFO:root:FL Epoch: 438 Using Learning rate : 0.02084570305140536 
INFO:root:FL Epoch: 438 Normal Training
INFO:root:Worker: 636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755545
INFO:root:Worker: 636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492368
INFO:root:FL Epoch: 438 Norm Difference for worker 636 is 0.850798
INFO:root:FL Epoch: 438 Done on worker:636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1578
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 438 Ends   ===================
INFO:root:Epoch:438 Global Model Test Loss:0.5044302589753095 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:438 Global Model Backdoor Test Loss:0.16118303686380386                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 439 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 439 Workers Selected : [776, 5, 750, 784, 1827, 668, 913, 1618, 1698, 644]
INFO:root:FL Epoch: 439 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 439 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 439 Training on worker :776
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.712522
INFO:root:Worker: 776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381728
INFO:root:FL Epoch: 439 Norm Difference for worker 776 is 0.742272
INFO:root:FL Epoch: 439 Done on worker:776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :5
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 5 Train Epoch: 0 [0/201 (0%)]	Loss: 0.286029
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 5 Train Epoch: 1 [0/201 (0%)]	Loss: 0.464413
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 439 Norm Difference for worker 5 is 0.858738
INFO:root:FL Epoch: 439 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :750
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 750 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697677
INFO:root:Worker: 750 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471494
INFO:root:FL Epoch: 439 Norm Difference for worker 750 is 0.974117
INFO:root:FL Epoch: 439 Done on worker:750
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :784
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 784 Train Epoch: 0 [0/200 (0%)]	Loss: 0.275737
INFO:root:Worker: 784 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467601
INFO:root:FL Epoch: 439 Norm Difference for worker 784 is 0.864862
INFO:root:FL Epoch: 439 Done on worker:784
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :1827
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 1827 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424600
INFO:root:Worker: 1827 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381221
INFO:root:FL Epoch: 439 Norm Difference for worker 1827 is 0.808808
INFO:root:FL Epoch: 439 Done on worker:1827
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :668
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 668 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553168
INFO:root:Worker: 668 Train Epoch: 1 [0/200 (0%)]	Loss: 0.727630
INFO:root:FL Epoch: 439 Norm Difference for worker 668 is 0.912951
INFO:root:FL Epoch: 439 Done on worker:668
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :913
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 913 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577851
INFO:root:Worker: 913 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437072
INFO:root:FL Epoch: 439 Norm Difference for worker 913 is 0.864456
INFO:root:FL Epoch: 439 Done on worker:913
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :1618
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 1618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.552575
INFO:root:Worker: 1618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.534620
INFO:root:FL Epoch: 439 Norm Difference for worker 1618 is 0.835741
INFO:root:FL Epoch: 439 Done on worker:1618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :1698
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 1698 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688676
INFO:root:Worker: 1698 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351131
INFO:root:FL Epoch: 439 Norm Difference for worker 1698 is 0.831071
INFO:root:FL Epoch: 439 Done on worker:1698
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 439 Training on worker :644
INFO:root:FL Epoch: 439 Using Learning rate : 0.020804011645302545 
INFO:root:FL Epoch: 439 Normal Training
INFO:root:Worker: 644 Train Epoch: 0 [0/200 (0%)]	Loss: 0.522089
INFO:root:Worker: 644 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434300
INFO:root:FL Epoch: 439 Norm Difference for worker 644 is 0.810885
INFO:root:FL Epoch: 439 Done on worker:644
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 776
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 439 Ends   ===================
INFO:root:Epoch:439 Global Model Test Loss:0.5039496553294799 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:439 Global Model Backdoor Test Loss:0.11875309298435847                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 440 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 440 Workers Selected : [1567, 592, 68, 283, 675, 223, 1164, 896, 1877, 796]
INFO:root:FL Epoch: 440 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 440 Num points on workers: [200 200 201 201 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 440 Training on worker :1567
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1567 Train Epoch: 0 [0/200 (0%)]	Loss: 0.854555
INFO:root:Worker: 1567 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409999
INFO:root:FL Epoch: 440 Norm Difference for worker 1567 is 0.880514
INFO:root:FL Epoch: 440 Done on worker:1567
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :592
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 592 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766670
INFO:root:Worker: 592 Train Epoch: 1 [0/200 (0%)]	Loss: 0.437320
INFO:root:FL Epoch: 440 Norm Difference for worker 592 is 0.987776
INFO:root:FL Epoch: 440 Done on worker:592
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :68
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 68 Train Epoch: 0 [0/201 (0%)]	Loss: 0.383217
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 68 Train Epoch: 1 [0/201 (0%)]	Loss: 0.591906
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 440 Norm Difference for worker 68 is 0.995036
INFO:root:FL Epoch: 440 Done on worker:68
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :283
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 283 Train Epoch: 0 [0/201 (0%)]	Loss: 0.859035
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 283 Train Epoch: 1 [0/201 (0%)]	Loss: 0.492752
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 440 Norm Difference for worker 283 is 0.825478
INFO:root:FL Epoch: 440 Done on worker:283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :675
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 675 Train Epoch: 0 [0/200 (0%)]	Loss: 0.589662
INFO:root:Worker: 675 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587806
INFO:root:FL Epoch: 440 Norm Difference for worker 675 is 1.122391
INFO:root:FL Epoch: 440 Done on worker:675
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :223
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 223 Train Epoch: 0 [0/201 (0%)]	Loss: 0.607663
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 223 Train Epoch: 1 [0/201 (0%)]	Loss: 0.414080
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 440 Norm Difference for worker 223 is 0.992888
INFO:root:FL Epoch: 440 Done on worker:223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1164
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1164 Train Epoch: 0 [0/200 (0%)]	Loss: 1.061910
INFO:root:Worker: 1164 Train Epoch: 1 [0/200 (0%)]	Loss: 0.749760
INFO:root:FL Epoch: 440 Norm Difference for worker 1164 is 0.938891
INFO:root:FL Epoch: 440 Done on worker:1164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :896
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 896 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579687
INFO:root:Worker: 896 Train Epoch: 1 [0/200 (0%)]	Loss: 0.232962
INFO:root:FL Epoch: 440 Norm Difference for worker 896 is 0.90583
INFO:root:FL Epoch: 440 Done on worker:896
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :1877
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 1877 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569219
INFO:root:Worker: 1877 Train Epoch: 1 [0/200 (0%)]	Loss: 0.351635
INFO:root:FL Epoch: 440 Norm Difference for worker 1877 is 0.8907
INFO:root:FL Epoch: 440 Done on worker:1877
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 440 Training on worker :796
INFO:root:FL Epoch: 440 Using Learning rate : 0.02076240362201194 
INFO:root:FL Epoch: 440 Normal Training
INFO:root:Worker: 796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707189
INFO:root:Worker: 796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403541
INFO:root:FL Epoch: 440 Norm Difference for worker 796 is 0.928522
INFO:root:FL Epoch: 440 Done on worker:796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 283
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 440 Ends   ===================
INFO:root:Epoch:440 Global Model Test Loss:0.4967365019461688 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:440 Global Model Backdoor Test Loss:0.18612363437811533                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 441 Begins ===================
INFO:root:FL Epoch: 441 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 441 Workers Selected : [0, 1720, 697, 1047, 955, 483, 842, 163, 299, 1402]
INFO:root:FL Epoch: 441 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.1003996 0.1003996 0.0999001]
INFO:root:FL Epoch: 441 Num points on workers: [200 200 200 200 200 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 441 Training on worker :0
INFO:root:FL Epoch: 441 Using Learning rate : 0.004144175762953584 
INFO:root:FL Epoch: 441 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.223481
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330251
INFO:root:FL Epoch: 441 Worker: 0 Backdoor Test Loss: 0.1602251653869947 Backdoor Test Accuracy: 97.5
INFO:root:FL Epoch: 441 Worker: 0 Backdoor Train Loss: 0.18985699862241745 Backdoor Train Accuracy: 95.0
INFO:root:FL Epoch: 441 Norm Difference for worker 0 is 0.144143
INFO:root:FL Epoch: 441 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1720
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1720 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538593
INFO:root:Worker: 1720 Train Epoch: 1 [0/200 (0%)]	Loss: 0.746714
INFO:root:FL Epoch: 441 Norm Difference for worker 1720 is 0.742029
INFO:root:FL Epoch: 441 Done on worker:1720
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :697
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 697 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549721
INFO:root:Worker: 697 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458944
INFO:root:FL Epoch: 441 Norm Difference for worker 697 is 0.809603
INFO:root:FL Epoch: 441 Done on worker:697
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1047
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1047 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492942
INFO:root:Worker: 1047 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695843
INFO:root:FL Epoch: 441 Norm Difference for worker 1047 is 0.733661
INFO:root:FL Epoch: 441 Done on worker:1047
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :955
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 955 Train Epoch: 0 [0/200 (0%)]	Loss: 0.387812
INFO:root:Worker: 955 Train Epoch: 1 [0/200 (0%)]	Loss: 0.735306
INFO:root:FL Epoch: 441 Norm Difference for worker 955 is 0.713275
INFO:root:FL Epoch: 441 Done on worker:955
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :483
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 483 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488916
INFO:root:Worker: 483 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540415
INFO:root:FL Epoch: 441 Norm Difference for worker 483 is 0.756705
INFO:root:FL Epoch: 441 Done on worker:483
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :842
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 842 Train Epoch: 0 [0/200 (0%)]	Loss: 0.603155
INFO:root:Worker: 842 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471747
INFO:root:FL Epoch: 441 Norm Difference for worker 842 is 0.746788
INFO:root:FL Epoch: 441 Done on worker:842
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :163
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.660506
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.471478
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 441 Norm Difference for worker 163 is 0.720768
INFO:root:FL Epoch: 441 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :299
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 299 Train Epoch: 0 [0/201 (0%)]	Loss: 0.534152
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 299 Train Epoch: 1 [0/201 (0%)]	Loss: 0.467744
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 441 Norm Difference for worker 299 is 0.730197
INFO:root:FL Epoch: 441 Done on worker:299
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 441 Training on worker :1402
INFO:root:FL Epoch: 441 Using Learning rate : 0.020720878814767918 
INFO:root:FL Epoch: 441 Normal Training
INFO:root:Worker: 1402 Train Epoch: 0 [0/200 (0%)]	Loss: 0.774411
INFO:root:Worker: 1402 Train Epoch: 1 [0/200 (0%)]	Loss: 0.686834
INFO:root:FL Epoch: 441 Norm Difference for worker 1402 is 0.742444
INFO:root:FL Epoch: 441 Done on worker:1402
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 441 Ends   ===================
INFO:root:Epoch:441 Global Model Test Loss:0.5007102244040545 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:441 Global Model Backdoor Test Loss:0.1602251653869947                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 442 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 442 Workers Selected : [1371, 934, 332, 26, 1403, 1138, 328, 192, 1223, 600]
INFO:root:FL Epoch: 442 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.1002994 0.0998004 0.0998004 0.1002994
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 442 Num points on workers: [200 200 201 201 200 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 442 Training on worker :1371
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.902558
INFO:root:Worker: 1371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712464
INFO:root:FL Epoch: 442 Norm Difference for worker 1371 is 0.818719
INFO:root:FL Epoch: 442 Done on worker:1371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :934
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 934 Train Epoch: 0 [0/200 (0%)]	Loss: 0.398052
INFO:root:Worker: 934 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550529
INFO:root:FL Epoch: 442 Norm Difference for worker 934 is 0.846529
INFO:root:FL Epoch: 442 Done on worker:934
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :332
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 332 Train Epoch: 0 [0/201 (0%)]	Loss: 0.838959
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 332 Train Epoch: 1 [0/201 (0%)]	Loss: 0.655355
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 442 Norm Difference for worker 332 is 0.837452
INFO:root:FL Epoch: 442 Done on worker:332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :26
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 26 Train Epoch: 0 [0/201 (0%)]	Loss: 0.426854
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 26 Train Epoch: 1 [0/201 (0%)]	Loss: 0.388601
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 442 Norm Difference for worker 26 is 0.801998
INFO:root:FL Epoch: 442 Done on worker:26
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1403
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472679
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556461
INFO:root:FL Epoch: 442 Norm Difference for worker 1403 is 0.817344
INFO:root:FL Epoch: 442 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1138
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1138 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572882
INFO:root:Worker: 1138 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371053
INFO:root:FL Epoch: 442 Norm Difference for worker 1138 is 0.871075
INFO:root:FL Epoch: 442 Done on worker:1138
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :328
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 328 Train Epoch: 0 [0/201 (0%)]	Loss: 0.480225
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 328 Train Epoch: 1 [0/201 (0%)]	Loss: 0.500853
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 442 Norm Difference for worker 328 is 0.79627
INFO:root:FL Epoch: 442 Done on worker:328
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :192
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 192 Train Epoch: 0 [0/201 (0%)]	Loss: 0.403277
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 192 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450715
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 442 Norm Difference for worker 192 is 0.764514
INFO:root:FL Epoch: 442 Done on worker:192
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :1223
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 1223 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659736
INFO:root:Worker: 1223 Train Epoch: 1 [0/200 (0%)]	Loss: 0.776222
INFO:root:FL Epoch: 442 Norm Difference for worker 1223 is 0.905382
INFO:root:FL Epoch: 442 Done on worker:1223
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 442 Training on worker :600
INFO:root:FL Epoch: 442 Using Learning rate : 0.020679437057138383 
INFO:root:FL Epoch: 442 Normal Training
INFO:root:Worker: 600 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548817
INFO:root:Worker: 600 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454818
INFO:root:FL Epoch: 442 Norm Difference for worker 600 is 0.786409
INFO:root:FL Epoch: 442 Done on worker:600
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 328
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 442 Ends   ===================
INFO:root:Epoch:442 Global Model Test Loss:0.4977468234651229 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:442 Global Model Backdoor Test Loss:0.19212290892998377                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 443 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 443 Workers Selected : [1408, 318, 1168, 59, 463, 911, 1605, 1418, 890, 118]
INFO:root:FL Epoch: 443 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 443 Num points on workers: [200 201 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 443 Training on worker :1408
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1408 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531757
INFO:root:Worker: 1408 Train Epoch: 1 [0/200 (0%)]	Loss: 0.712677
INFO:root:FL Epoch: 443 Norm Difference for worker 1408 is 0.758961
INFO:root:FL Epoch: 443 Done on worker:1408
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :318
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 318 Train Epoch: 0 [0/201 (0%)]	Loss: 0.454790
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 318 Train Epoch: 1 [0/201 (0%)]	Loss: 0.219408
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 318 is 0.689022
INFO:root:FL Epoch: 443 Done on worker:318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1168
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1168 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476327
INFO:root:Worker: 1168 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354558
INFO:root:FL Epoch: 443 Norm Difference for worker 1168 is 0.920502
INFO:root:FL Epoch: 443 Done on worker:1168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :59
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 59 Train Epoch: 0 [0/201 (0%)]	Loss: 0.493022
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 59 Train Epoch: 1 [0/201 (0%)]	Loss: 0.758866
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 59 is 0.729322
INFO:root:FL Epoch: 443 Done on worker:59
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :463
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 463 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667166
INFO:root:Worker: 463 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506570
INFO:root:FL Epoch: 443 Norm Difference for worker 463 is 0.705339
INFO:root:FL Epoch: 443 Done on worker:463
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :911
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 911 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445938
INFO:root:Worker: 911 Train Epoch: 1 [0/200 (0%)]	Loss: 0.523455
INFO:root:FL Epoch: 443 Norm Difference for worker 911 is 0.71566
INFO:root:FL Epoch: 443 Done on worker:911
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1605
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1605 Train Epoch: 0 [0/200 (0%)]	Loss: 0.502308
INFO:root:Worker: 1605 Train Epoch: 1 [0/200 (0%)]	Loss: 0.528610
INFO:root:FL Epoch: 443 Norm Difference for worker 1605 is 0.745279
INFO:root:FL Epoch: 443 Done on worker:1605
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :1418
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 1418 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404772
INFO:root:Worker: 1418 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621313
INFO:root:FL Epoch: 443 Norm Difference for worker 1418 is 0.722134
INFO:root:FL Epoch: 443 Done on worker:1418
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :890
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 890 Train Epoch: 0 [0/200 (0%)]	Loss: 0.581027
INFO:root:Worker: 890 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415768
INFO:root:FL Epoch: 443 Norm Difference for worker 890 is 0.730502
INFO:root:FL Epoch: 443 Done on worker:890
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 443 Training on worker :118
INFO:root:FL Epoch: 443 Using Learning rate : 0.020638078183024103 
INFO:root:FL Epoch: 443 Normal Training
INFO:root:Worker: 118 Train Epoch: 0 [0/201 (0%)]	Loss: 0.440177
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 118 Train Epoch: 1 [0/201 (0%)]	Loss: 0.623105
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 443 Norm Difference for worker 118 is 0.722309
INFO:root:FL Epoch: 443 Done on worker:118
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 318
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 443 Ends   ===================
INFO:root:Epoch:443 Global Model Test Loss:0.5304508331943961 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:443 Global Model Backdoor Test Loss:0.20755280926823616                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 444 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 444 Workers Selected : [872, 1863, 1130, 1487, 1106, 1544, 1475, 800, 521, 1145]
INFO:root:FL Epoch: 444 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 444 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 444 Training on worker :872
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 872 Train Epoch: 0 [0/200 (0%)]	Loss: 1.113541
INFO:root:Worker: 872 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604251
INFO:root:FL Epoch: 444 Norm Difference for worker 872 is 0.871097
INFO:root:FL Epoch: 444 Done on worker:872
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1863
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.236837
INFO:root:Worker: 1863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.418552
INFO:root:FL Epoch: 444 Norm Difference for worker 1863 is 0.735269
INFO:root:FL Epoch: 444 Done on worker:1863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1130
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1130 Train Epoch: 0 [0/200 (0%)]	Loss: 0.622097
INFO:root:Worker: 1130 Train Epoch: 1 [0/200 (0%)]	Loss: 0.725081
INFO:root:FL Epoch: 444 Norm Difference for worker 1130 is 0.980587
INFO:root:FL Epoch: 444 Done on worker:1130
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1487
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509259
INFO:root:Worker: 1487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.439200
INFO:root:FL Epoch: 444 Norm Difference for worker 1487 is 0.844262
INFO:root:FL Epoch: 444 Done on worker:1487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1106
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1106 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694065
INFO:root:Worker: 1106 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688196
INFO:root:FL Epoch: 444 Norm Difference for worker 1106 is 0.781128
INFO:root:FL Epoch: 444 Done on worker:1106
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1544
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1544 Train Epoch: 0 [0/200 (0%)]	Loss: 0.724316
INFO:root:Worker: 1544 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440010
INFO:root:FL Epoch: 444 Norm Difference for worker 1544 is 0.866782
INFO:root:FL Epoch: 444 Done on worker:1544
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1475
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1475 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463658
INFO:root:Worker: 1475 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541261
INFO:root:FL Epoch: 444 Norm Difference for worker 1475 is 0.812924
INFO:root:FL Epoch: 444 Done on worker:1475
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :800
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 800 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459995
INFO:root:Worker: 800 Train Epoch: 1 [0/200 (0%)]	Loss: 0.443031
INFO:root:FL Epoch: 444 Norm Difference for worker 800 is 0.859072
INFO:root:FL Epoch: 444 Done on worker:800
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :521
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575595
INFO:root:Worker: 521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459846
INFO:root:FL Epoch: 444 Norm Difference for worker 521 is 0.864828
INFO:root:FL Epoch: 444 Done on worker:521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 444 Training on worker :1145
INFO:root:FL Epoch: 444 Using Learning rate : 0.02059680202665806 
INFO:root:FL Epoch: 444 Normal Training
INFO:root:Worker: 1145 Train Epoch: 0 [0/200 (0%)]	Loss: 0.692841
INFO:root:Worker: 1145 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520859
INFO:root:FL Epoch: 444 Norm Difference for worker 1145 is 0.819363
INFO:root:FL Epoch: 444 Done on worker:1145
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1863
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 444 Ends   ===================
INFO:root:Epoch:444 Global Model Test Loss:0.5202836955294889 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:444 Global Model Backdoor Test Loss:0.1832479623456796                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 445 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 445 Workers Selected : [681, 856, 144, 972, 1914, 137, 931, 1370, 12, 163]
INFO:root:FL Epoch: 445 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.1002994 0.0998004 0.0998004 0.1002994 0.0998004
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 445 Num points on workers: [200 200 201 200 200 201 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 445 Training on worker :681
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.507639
INFO:root:Worker: 681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446501
INFO:root:FL Epoch: 445 Norm Difference for worker 681 is 0.792224
INFO:root:FL Epoch: 445 Done on worker:681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :856
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.785258
INFO:root:Worker: 856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.688270
INFO:root:FL Epoch: 445 Norm Difference for worker 856 is 0.975366
INFO:root:FL Epoch: 445 Done on worker:856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :144
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 144 Train Epoch: 0 [0/201 (0%)]	Loss: 0.401203
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 144 Train Epoch: 1 [0/201 (0%)]	Loss: 0.396058
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 445 Norm Difference for worker 144 is 0.859338
INFO:root:FL Epoch: 445 Done on worker:144
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :972
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 972 Train Epoch: 0 [0/200 (0%)]	Loss: 0.646364
INFO:root:Worker: 972 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557873
INFO:root:FL Epoch: 445 Norm Difference for worker 972 is 0.778465
INFO:root:FL Epoch: 445 Done on worker:972
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1914
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1914 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420022
INFO:root:Worker: 1914 Train Epoch: 1 [0/200 (0%)]	Loss: 0.283556
INFO:root:FL Epoch: 445 Norm Difference for worker 1914 is 0.648978
INFO:root:FL Epoch: 445 Done on worker:1914
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :137
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 137 Train Epoch: 0 [0/201 (0%)]	Loss: 0.805899
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 137 Train Epoch: 1 [0/201 (0%)]	Loss: 0.369464
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 445 Norm Difference for worker 137 is 0.826879
INFO:root:FL Epoch: 445 Done on worker:137
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :931
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 931 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645407
INFO:root:Worker: 931 Train Epoch: 1 [0/200 (0%)]	Loss: 0.566518
INFO:root:FL Epoch: 445 Norm Difference for worker 931 is 0.921754
INFO:root:FL Epoch: 445 Done on worker:931
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :1370
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 1370 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321892
INFO:root:Worker: 1370 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651440
INFO:root:FL Epoch: 445 Norm Difference for worker 1370 is 0.765657
INFO:root:FL Epoch: 445 Done on worker:1370
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :12
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 12 Train Epoch: 0 [0/201 (0%)]	Loss: 0.449004
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 12 Train Epoch: 1 [0/201 (0%)]	Loss: 0.475789
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 445 Norm Difference for worker 12 is 0.893461
INFO:root:FL Epoch: 445 Done on worker:12
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 445 Training on worker :163
INFO:root:FL Epoch: 445 Using Learning rate : 0.020555608422604742 
INFO:root:FL Epoch: 445 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.655432
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.432571
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 445 Norm Difference for worker 163 is 0.763352
INFO:root:FL Epoch: 445 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1914
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 445 Ends   ===================
INFO:root:Epoch:445 Global Model Test Loss:0.530433607452056 and Test Accuracy:74.70588235294117 
INFO:root:Epoch:445 Global Model Backdoor Test Loss:0.13849875579277673                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 446 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 446 Workers Selected : [708, 92, 1859, 85, 159, 1467, 1766, 1320, 95, 1795]
INFO:root:FL Epoch: 446 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.1002994 0.1002994 0.0998004 0.0998004
 0.0998004 0.1002994 0.0998004]
INFO:root:FL Epoch: 446 Num points on workers: [200 201 200 201 201 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 446 Training on worker :708
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 708 Train Epoch: 0 [0/200 (0%)]	Loss: 0.173510
INFO:root:Worker: 708 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300021
INFO:root:FL Epoch: 446 Norm Difference for worker 708 is 0.825369
INFO:root:FL Epoch: 446 Done on worker:708
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :92
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.611583
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.389249
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 92 is 0.954203
INFO:root:FL Epoch: 446 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1859
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1859 Train Epoch: 0 [0/200 (0%)]	Loss: 0.750329
INFO:root:Worker: 1859 Train Epoch: 1 [0/200 (0%)]	Loss: 0.457003
INFO:root:FL Epoch: 446 Norm Difference for worker 1859 is 0.914877
INFO:root:FL Epoch: 446 Done on worker:1859
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :85
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 85 Train Epoch: 0 [0/201 (0%)]	Loss: 0.884008
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 85 Train Epoch: 1 [0/201 (0%)]	Loss: 0.534834
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 85 is 0.957705
INFO:root:FL Epoch: 446 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :159
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 159 Train Epoch: 0 [0/201 (0%)]	Loss: 0.622165
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 159 Train Epoch: 1 [0/201 (0%)]	Loss: 0.452415
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 159 is 0.915705
INFO:root:FL Epoch: 446 Done on worker:159
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1467
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1467 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664225
INFO:root:Worker: 1467 Train Epoch: 1 [0/200 (0%)]	Loss: 0.393982
INFO:root:FL Epoch: 446 Norm Difference for worker 1467 is 0.958833
INFO:root:FL Epoch: 446 Done on worker:1467
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1766
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1766 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472110
INFO:root:Worker: 1766 Train Epoch: 1 [0/200 (0%)]	Loss: 0.649954
INFO:root:FL Epoch: 446 Norm Difference for worker 1766 is 1.043612
INFO:root:FL Epoch: 446 Done on worker:1766
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1320
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1320 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395098
INFO:root:Worker: 1320 Train Epoch: 1 [0/200 (0%)]	Loss: 0.376434
INFO:root:FL Epoch: 446 Norm Difference for worker 1320 is 0.91215
INFO:root:FL Epoch: 446 Done on worker:1320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :95
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 95 Train Epoch: 0 [0/201 (0%)]	Loss: 0.825595
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 95 Train Epoch: 1 [0/201 (0%)]	Loss: 0.598545
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 446 Norm Difference for worker 95 is 0.970203
INFO:root:FL Epoch: 446 Done on worker:95
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 446 Training on worker :1795
INFO:root:FL Epoch: 446 Using Learning rate : 0.02051449720575953 
INFO:root:FL Epoch: 446 Normal Training
INFO:root:Worker: 1795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.424820
INFO:root:Worker: 1795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546729
INFO:root:FL Epoch: 446 Norm Difference for worker 1795 is 1.259455
INFO:root:FL Epoch: 446 Done on worker:1795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 708
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 446 Ends   ===================
INFO:root:Epoch:446 Global Model Test Loss:0.5340559184551239 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:446 Global Model Backdoor Test Loss:0.1494396577278773                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 447 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 447 Workers Selected : [11, 1368, 1040, 1102, 357, 740, 378, 952, 1754, 822]
INFO:root:FL Epoch: 447 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 447 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 447 Training on worker :11
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 11 Train Epoch: 0 [0/201 (0%)]	Loss: 0.676495
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 11 Train Epoch: 1 [0/201 (0%)]	Loss: 0.469094
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 447 Norm Difference for worker 11 is 0.920736
INFO:root:FL Epoch: 447 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1368
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1368 Train Epoch: 0 [0/200 (0%)]	Loss: 0.548091
INFO:root:Worker: 1368 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328325
INFO:root:FL Epoch: 447 Norm Difference for worker 1368 is 0.878074
INFO:root:FL Epoch: 447 Done on worker:1368
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1040
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1040 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440630
INFO:root:Worker: 1040 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482772
INFO:root:FL Epoch: 447 Norm Difference for worker 1040 is 0.936319
INFO:root:FL Epoch: 447 Done on worker:1040
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1102
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1102 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723476
INFO:root:Worker: 1102 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385826
INFO:root:FL Epoch: 447 Norm Difference for worker 1102 is 0.920924
INFO:root:FL Epoch: 447 Done on worker:1102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :357
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 357 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584529
INFO:root:Worker: 357 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266534
INFO:root:FL Epoch: 447 Norm Difference for worker 357 is 0.80726
INFO:root:FL Epoch: 447 Done on worker:357
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :740
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.361670
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571323
INFO:root:FL Epoch: 447 Norm Difference for worker 740 is 0.985746
INFO:root:FL Epoch: 447 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :378
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574378
INFO:root:Worker: 378 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547053
INFO:root:FL Epoch: 447 Norm Difference for worker 378 is 0.901051
INFO:root:FL Epoch: 447 Done on worker:378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :952
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 952 Train Epoch: 0 [0/200 (0%)]	Loss: 0.652001
INFO:root:Worker: 952 Train Epoch: 1 [0/200 (0%)]	Loss: 0.551789
INFO:root:FL Epoch: 447 Norm Difference for worker 952 is 0.985664
INFO:root:FL Epoch: 447 Done on worker:952
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :1754
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 1754 Train Epoch: 0 [0/200 (0%)]	Loss: 0.655668
INFO:root:Worker: 1754 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606071
INFO:root:FL Epoch: 447 Norm Difference for worker 1754 is 0.948351
INFO:root:FL Epoch: 447 Done on worker:1754
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 447 Training on worker :822
INFO:root:FL Epoch: 447 Using Learning rate : 0.020473468211348014 
INFO:root:FL Epoch: 447 Normal Training
INFO:root:Worker: 822 Train Epoch: 0 [0/200 (0%)]	Loss: 0.262951
INFO:root:Worker: 822 Train Epoch: 1 [0/200 (0%)]	Loss: 0.268860
INFO:root:FL Epoch: 447 Norm Difference for worker 822 is 0.957169
INFO:root:FL Epoch: 447 Done on worker:822
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 357
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 447 Ends   ===================
INFO:root:Epoch:447 Global Model Test Loss:0.5397593291366801 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:447 Global Model Backdoor Test Loss:0.15124727537234625                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 448 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 448 Workers Selected : [790, 164, 186, 1255, 1783, 688, 685, 761, 268, 85]
INFO:root:FL Epoch: 448 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.1002994 0.0998004 0.0998004 0.0998004 0.0998004
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 448 Num points on workers: [200 201 201 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 448 Training on worker :790
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 790 Train Epoch: 0 [0/200 (0%)]	Loss: 0.794468
INFO:root:Worker: 790 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372439
INFO:root:FL Epoch: 448 Norm Difference for worker 790 is 1.009319
INFO:root:FL Epoch: 448 Done on worker:790
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :164
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 164 Train Epoch: 0 [0/201 (0%)]	Loss: 0.529089
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 164 Train Epoch: 1 [0/201 (0%)]	Loss: 0.458818
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 448 Norm Difference for worker 164 is 0.971099
INFO:root:FL Epoch: 448 Done on worker:164
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :186
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 186 Train Epoch: 0 [0/201 (0%)]	Loss: 0.384028
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 186 Train Epoch: 1 [0/201 (0%)]	Loss: 0.315472
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 448 Norm Difference for worker 186 is 0.917971
INFO:root:FL Epoch: 448 Done on worker:186
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1255
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1255 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538264
INFO:root:Worker: 1255 Train Epoch: 1 [0/200 (0%)]	Loss: 0.693659
INFO:root:FL Epoch: 448 Norm Difference for worker 1255 is 1.022739
INFO:root:FL Epoch: 448 Done on worker:1255
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :1783
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 1783 Train Epoch: 0 [0/200 (0%)]	Loss: 0.767014
INFO:root:Worker: 1783 Train Epoch: 1 [0/200 (0%)]	Loss: 0.426402
INFO:root:FL Epoch: 448 Norm Difference for worker 1783 is 1.062926
INFO:root:FL Epoch: 448 Done on worker:1783
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :688
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.571984
INFO:root:Worker: 688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.875625
INFO:root:FL Epoch: 448 Norm Difference for worker 688 is 0.920354
INFO:root:FL Epoch: 448 Done on worker:688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :685
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.703560
INFO:root:Worker: 685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340097
INFO:root:FL Epoch: 448 Norm Difference for worker 685 is 0.954843
INFO:root:FL Epoch: 448 Done on worker:685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :761
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 761 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526611
INFO:root:Worker: 761 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535596
INFO:root:FL Epoch: 448 Norm Difference for worker 761 is 0.994849
INFO:root:FL Epoch: 448 Done on worker:761
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :268
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 268 Train Epoch: 0 [0/201 (0%)]	Loss: 0.538339
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 268 Train Epoch: 1 [0/201 (0%)]	Loss: 0.497661
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 448 Norm Difference for worker 268 is 0.939035
INFO:root:FL Epoch: 448 Done on worker:268
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 448 Training on worker :85
INFO:root:FL Epoch: 448 Using Learning rate : 0.020432521274925314 
INFO:root:FL Epoch: 448 Normal Training
INFO:root:Worker: 85 Train Epoch: 0 [0/201 (0%)]	Loss: 0.495698
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 85 Train Epoch: 1 [0/201 (0%)]	Loss: 0.550101
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 448 Norm Difference for worker 85 is 0.975648
INFO:root:FL Epoch: 448 Done on worker:85
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 688
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 448 Ends   ===================
INFO:root:Epoch:448 Global Model Test Loss:0.5285140065585866 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:448 Global Model Backdoor Test Loss:0.21141005555788675                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 449 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 449 Workers Selected : [628, 110, 1720, 75, 1619, 857, 631, 298, 961, 695]
INFO:root:FL Epoch: 449 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.10034948 0.09985022 0.09985022]
INFO:root:FL Epoch: 449 Num points on workers: [200 201 200 201 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 449 Training on worker :628
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 628 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353317
INFO:root:Worker: 628 Train Epoch: 1 [0/200 (0%)]	Loss: 0.514103
INFO:root:FL Epoch: 449 Norm Difference for worker 628 is 0.772039
INFO:root:FL Epoch: 449 Done on worker:628
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :110
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 110 Train Epoch: 0 [0/201 (0%)]	Loss: 0.393164
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 110 Train Epoch: 1 [0/201 (0%)]	Loss: 0.428728
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 449 Norm Difference for worker 110 is 0.761402
INFO:root:FL Epoch: 449 Done on worker:110
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1720
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1720 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684180
INFO:root:Worker: 1720 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590250
INFO:root:FL Epoch: 449 Norm Difference for worker 1720 is 0.728083
INFO:root:FL Epoch: 449 Done on worker:1720
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :75
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 75 Train Epoch: 0 [0/201 (0%)]	Loss: 0.351025
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 75 Train Epoch: 1 [0/201 (0%)]	Loss: 0.401925
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 449 Norm Difference for worker 75 is 0.769621
INFO:root:FL Epoch: 449 Done on worker:75
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :1619
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 1619 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753486
INFO:root:Worker: 1619 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431386
INFO:root:FL Epoch: 449 Norm Difference for worker 1619 is 0.860741
INFO:root:FL Epoch: 449 Done on worker:1619
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :857
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.761735
INFO:root:Worker: 857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.530635
INFO:root:FL Epoch: 449 Norm Difference for worker 857 is 0.878463
INFO:root:FL Epoch: 449 Done on worker:857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :631
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 631 Train Epoch: 0 [0/200 (0%)]	Loss: 0.579570
INFO:root:Worker: 631 Train Epoch: 1 [0/200 (0%)]	Loss: 0.638282
INFO:root:FL Epoch: 449 Norm Difference for worker 631 is 0.832045
INFO:root:FL Epoch: 449 Done on worker:631
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :298
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 298 Train Epoch: 0 [0/201 (0%)]	Loss: 0.643304
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 298 Train Epoch: 1 [0/201 (0%)]	Loss: 0.490466
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 449 Norm Difference for worker 298 is 0.777724
INFO:root:FL Epoch: 449 Done on worker:298
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :961
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 961 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478306
INFO:root:Worker: 961 Train Epoch: 1 [0/200 (0%)]	Loss: 0.336289
INFO:root:FL Epoch: 449 Norm Difference for worker 961 is 0.824488
INFO:root:FL Epoch: 449 Done on worker:961
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 449 Training on worker :695
INFO:root:FL Epoch: 449 Using Learning rate : 0.020391656232375464 
INFO:root:FL Epoch: 449 Normal Training
INFO:root:Worker: 695 Train Epoch: 0 [0/200 (0%)]	Loss: 0.665598
INFO:root:Worker: 695 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522425
INFO:root:FL Epoch: 449 Norm Difference for worker 695 is 0.835081
INFO:root:FL Epoch: 449 Done on worker:695
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 1720
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 449 Ends   ===================
INFO:root:Epoch:449 Global Model Test Loss:0.5128235799424788 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:449 Global Model Backdoor Test Loss:0.23857094595829645                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 450 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 450 Workers Selected : [461, 526, 1499, 14, 716, 880, 374, 1844, 1498, 290]
INFO:root:FL Epoch: 450 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 450 Num points on workers: [200 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 450 Training on worker :461
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 461 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677839
INFO:root:Worker: 461 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500646
INFO:root:FL Epoch: 450 Norm Difference for worker 461 is 0.700847
INFO:root:FL Epoch: 450 Done on worker:461
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :526
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.519548
INFO:root:Worker: 526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460443
INFO:root:FL Epoch: 450 Norm Difference for worker 526 is 0.729853
INFO:root:FL Epoch: 450 Done on worker:526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1499
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1499 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568342
INFO:root:Worker: 1499 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494233
INFO:root:FL Epoch: 450 Norm Difference for worker 1499 is 0.77385
INFO:root:FL Epoch: 450 Done on worker:1499
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :14
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.668855
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.421888
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 14 is 0.706821
INFO:root:FL Epoch: 450 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :716
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 716 Train Epoch: 0 [0/200 (0%)]	Loss: 0.483145
INFO:root:Worker: 716 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359343
INFO:root:FL Epoch: 450 Norm Difference for worker 716 is 0.613196
INFO:root:FL Epoch: 450 Done on worker:716
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :880
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 880 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392906
INFO:root:Worker: 880 Train Epoch: 1 [0/200 (0%)]	Loss: 0.497095
INFO:root:FL Epoch: 450 Norm Difference for worker 880 is 0.71366
INFO:root:FL Epoch: 450 Done on worker:880
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :374
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 374 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503593
INFO:root:Worker: 374 Train Epoch: 1 [0/200 (0%)]	Loss: 0.373274
INFO:root:FL Epoch: 450 Norm Difference for worker 374 is 0.712912
INFO:root:FL Epoch: 450 Done on worker:374
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1844
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1844 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342898
INFO:root:Worker: 1844 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494006
INFO:root:FL Epoch: 450 Norm Difference for worker 1844 is 0.711666
INFO:root:FL Epoch: 450 Done on worker:1844
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :1498
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 1498 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546212
INFO:root:Worker: 1498 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485968
INFO:root:FL Epoch: 450 Norm Difference for worker 1498 is 0.696114
INFO:root:FL Epoch: 450 Done on worker:1498
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 450 Training on worker :290
INFO:root:FL Epoch: 450 Using Learning rate : 0.020350872919910713 
INFO:root:FL Epoch: 450 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.550668
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.577555
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 450 Norm Difference for worker 290 is 0.765513
INFO:root:FL Epoch: 450 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 716
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 450 Ends   ===================
INFO:root:Epoch:450 Global Model Test Loss:0.5060542856945711 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:450 Global Model Backdoor Test Loss:0.1803175856669744                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 451 Begins ===================
INFO:root:FL Epoch: 451 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 451 Workers Selected : [0, 445, 1690, 352, 1806, 1449, 1574, 1455, 575, 1729]
INFO:root:FL Epoch: 451 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 451 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 451 Training on worker :0
INFO:root:FL Epoch: 451 Using Learning rate : 0.0040620342348141785 
INFO:root:FL Epoch: 451 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.222375
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.276493
INFO:root:FL Epoch: 451 Worker: 0 Backdoor Test Loss: 0.15544753273328146 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 451 Worker: 0 Backdoor Train Loss: 0.17130414620041848 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 451 Norm Difference for worker 0 is 0.126579
INFO:root:FL Epoch: 451 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :445
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 445 Train Epoch: 0 [0/200 (0%)]	Loss: 0.797301
INFO:root:Worker: 445 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531260
INFO:root:FL Epoch: 451 Norm Difference for worker 445 is 0.75084
INFO:root:FL Epoch: 451 Done on worker:445
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1690
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1690 Train Epoch: 0 [0/200 (0%)]	Loss: 0.610027
INFO:root:Worker: 1690 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330105
INFO:root:FL Epoch: 451 Norm Difference for worker 1690 is 0.788698
INFO:root:FL Epoch: 451 Done on worker:1690
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :352
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 352 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544014
INFO:root:Worker: 352 Train Epoch: 1 [0/200 (0%)]	Loss: 0.639726
INFO:root:FL Epoch: 451 Norm Difference for worker 352 is 0.838563
INFO:root:FL Epoch: 451 Done on worker:352
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1806
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1806 Train Epoch: 0 [0/200 (0%)]	Loss: 0.601324
INFO:root:Worker: 1806 Train Epoch: 1 [0/200 (0%)]	Loss: 0.650164
INFO:root:FL Epoch: 451 Norm Difference for worker 1806 is 0.772957
INFO:root:FL Epoch: 451 Done on worker:1806
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1449
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1449 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420572
INFO:root:Worker: 1449 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522924
INFO:root:FL Epoch: 451 Norm Difference for worker 1449 is 0.868311
INFO:root:FL Epoch: 451 Done on worker:1449
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1574
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473044
INFO:root:Worker: 1574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471861
INFO:root:FL Epoch: 451 Norm Difference for worker 1574 is 0.848366
INFO:root:FL Epoch: 451 Done on worker:1574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1455
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1455 Train Epoch: 0 [0/200 (0%)]	Loss: 0.686030
INFO:root:Worker: 1455 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546523
INFO:root:FL Epoch: 451 Norm Difference for worker 1455 is 0.783329
INFO:root:FL Epoch: 451 Done on worker:1455
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :575
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.822378
INFO:root:Worker: 575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302423
INFO:root:FL Epoch: 451 Norm Difference for worker 575 is 0.849358
INFO:root:FL Epoch: 451 Done on worker:575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 451 Training on worker :1729
INFO:root:FL Epoch: 451 Using Learning rate : 0.020310171174070895 
INFO:root:FL Epoch: 451 Normal Training
INFO:root:Worker: 1729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768914
INFO:root:Worker: 1729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.790524
INFO:root:FL Epoch: 451 Norm Difference for worker 1729 is 0.806628
INFO:root:FL Epoch: 451 Done on worker:1729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 451 Ends   ===================
INFO:root:Epoch:451 Global Model Test Loss:0.5100711619152742 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:451 Global Model Backdoor Test Loss:0.15544753273328146                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 452 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 452 Workers Selected : [122, 18, 1917, 474, 589, 354, 1575, 1640, 1804, 1779]
INFO:root:FL Epoch: 452 Fraction of points on each worker in this round: [0.1003996 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 452 Num points on workers: [201 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 452 Training on worker :122
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 122 Train Epoch: 0 [0/201 (0%)]	Loss: 0.480023
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 122 Train Epoch: 1 [0/201 (0%)]	Loss: 0.412641
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 122 is 0.899346
INFO:root:FL Epoch: 452 Done on worker:122
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :18
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 18 Train Epoch: 0 [0/201 (0%)]	Loss: 0.481309
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 18 Train Epoch: 1 [0/201 (0%)]	Loss: 0.324216
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 452 Norm Difference for worker 18 is 0.847314
INFO:root:FL Epoch: 452 Done on worker:18
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1917
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1917 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487496
INFO:root:Worker: 1917 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385730
INFO:root:FL Epoch: 452 Norm Difference for worker 1917 is 0.875892
INFO:root:FL Epoch: 452 Done on worker:1917
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :474
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628943
INFO:root:Worker: 474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.172355
INFO:root:FL Epoch: 452 Norm Difference for worker 474 is 0.872623
INFO:root:FL Epoch: 452 Done on worker:474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :589
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 589 Train Epoch: 0 [0/200 (0%)]	Loss: 0.422331
INFO:root:Worker: 589 Train Epoch: 1 [0/200 (0%)]	Loss: 0.629176
INFO:root:FL Epoch: 452 Norm Difference for worker 589 is 0.892804
INFO:root:FL Epoch: 452 Done on worker:589
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :354
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.735484
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472271
INFO:root:FL Epoch: 452 Norm Difference for worker 354 is 0.92794
INFO:root:FL Epoch: 452 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1575
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1575 Train Epoch: 0 [0/200 (0%)]	Loss: 0.475910
INFO:root:Worker: 1575 Train Epoch: 1 [0/200 (0%)]	Loss: 0.375230
INFO:root:FL Epoch: 452 Norm Difference for worker 1575 is 0.857206
INFO:root:FL Epoch: 452 Done on worker:1575
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1640
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1640 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801775
INFO:root:Worker: 1640 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519670
INFO:root:FL Epoch: 452 Norm Difference for worker 1640 is 0.880949
INFO:root:FL Epoch: 452 Done on worker:1640
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1804
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1804 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542851
INFO:root:Worker: 1804 Train Epoch: 1 [0/200 (0%)]	Loss: 0.540836
INFO:root:FL Epoch: 452 Norm Difference for worker 1804 is 0.924312
INFO:root:FL Epoch: 452 Done on worker:1804
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 452 Training on worker :1779
INFO:root:FL Epoch: 452 Using Learning rate : 0.02026955083172275 
INFO:root:FL Epoch: 452 Normal Training
INFO:root:Worker: 1779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.341155
INFO:root:Worker: 1779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.366820
INFO:root:FL Epoch: 452 Norm Difference for worker 1779 is 0.822579
INFO:root:FL Epoch: 452 Done on worker:1779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 18
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 452 Ends   ===================
INFO:root:Epoch:452 Global Model Test Loss:0.5014831897090463 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:452 Global Model Backdoor Test Loss:0.17774726326266924                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 453 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 453 Workers Selected : [569, 1664, 225, 1559, 1638, 597, 649, 1666, 462, 11]
INFO:root:FL Epoch: 453 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 453 Num points on workers: [200 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 453 Training on worker :569
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.839521
INFO:root:Worker: 569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363090
INFO:root:FL Epoch: 453 Norm Difference for worker 569 is 0.77874
INFO:root:FL Epoch: 453 Done on worker:569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1664
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1664 Train Epoch: 0 [0/200 (0%)]	Loss: 0.753231
INFO:root:Worker: 1664 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259742
INFO:root:FL Epoch: 453 Norm Difference for worker 1664 is 0.76009
INFO:root:FL Epoch: 453 Done on worker:1664
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :225
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 225 Train Epoch: 0 [0/201 (0%)]	Loss: 0.483824
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 225 Train Epoch: 1 [0/201 (0%)]	Loss: 0.313789
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 453 Norm Difference for worker 225 is 0.823865
INFO:root:FL Epoch: 453 Done on worker:225
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1559
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1559 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641172
INFO:root:Worker: 1559 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435994
INFO:root:FL Epoch: 453 Norm Difference for worker 1559 is 0.804668
INFO:root:FL Epoch: 453 Done on worker:1559
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1638
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1638 Train Epoch: 0 [0/200 (0%)]	Loss: 0.395445
INFO:root:Worker: 1638 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455739
INFO:root:FL Epoch: 453 Norm Difference for worker 1638 is 0.758965
INFO:root:FL Epoch: 453 Done on worker:1638
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :597
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 597 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382657
INFO:root:Worker: 597 Train Epoch: 1 [0/200 (0%)]	Loss: 0.255318
INFO:root:FL Epoch: 453 Norm Difference for worker 597 is 0.720732
INFO:root:FL Epoch: 453 Done on worker:597
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :649
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 649 Train Epoch: 0 [0/200 (0%)]	Loss: 0.412459
INFO:root:Worker: 649 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557975
INFO:root:FL Epoch: 453 Norm Difference for worker 649 is 0.786183
INFO:root:FL Epoch: 453 Done on worker:649
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :1666
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 1666 Train Epoch: 0 [0/200 (0%)]	Loss: 0.217060
INFO:root:Worker: 1666 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531037
INFO:root:FL Epoch: 453 Norm Difference for worker 1666 is 0.79769
INFO:root:FL Epoch: 453 Done on worker:1666
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :462
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 462 Train Epoch: 0 [0/200 (0%)]	Loss: 0.426642
INFO:root:Worker: 462 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431320
INFO:root:FL Epoch: 453 Norm Difference for worker 462 is 0.781011
INFO:root:FL Epoch: 453 Done on worker:462
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 453 Training on worker :11
INFO:root:FL Epoch: 453 Using Learning rate : 0.020229011730059306 
INFO:root:FL Epoch: 453 Normal Training
INFO:root:Worker: 11 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587264
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 11 Train Epoch: 1 [0/201 (0%)]	Loss: 0.583650
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 453 Norm Difference for worker 11 is 0.752805
INFO:root:FL Epoch: 453 Done on worker:11
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 597
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 453 Ends   ===================
INFO:root:Epoch:453 Global Model Test Loss:0.49742473574245677 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:453 Global Model Backdoor Test Loss:0.16257493197917938                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 454 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 454 Workers Selected : [384, 1139, 728, 1239, 1172, 240, 1795, 92, 1477, 1261]
INFO:root:FL Epoch: 454 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.0999001
 0.1003996 0.0999001 0.0999001]
INFO:root:FL Epoch: 454 Num points on workers: [200 200 200 200 200 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 454 Training on worker :384
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 384 Train Epoch: 0 [0/200 (0%)]	Loss: 0.238839
INFO:root:Worker: 384 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435466
INFO:root:FL Epoch: 454 Norm Difference for worker 384 is 0.741444
INFO:root:FL Epoch: 454 Done on worker:384
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1139
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1139 Train Epoch: 0 [0/200 (0%)]	Loss: 0.288832
INFO:root:Worker: 1139 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413173
INFO:root:FL Epoch: 454 Norm Difference for worker 1139 is 0.808931
INFO:root:FL Epoch: 454 Done on worker:1139
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :728
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 728 Train Epoch: 0 [0/200 (0%)]	Loss: 0.527909
INFO:root:Worker: 728 Train Epoch: 1 [0/200 (0%)]	Loss: 0.620385
INFO:root:FL Epoch: 454 Norm Difference for worker 728 is 0.817762
INFO:root:FL Epoch: 454 Done on worker:728
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1239
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1239 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417296
INFO:root:Worker: 1239 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412990
INFO:root:FL Epoch: 454 Norm Difference for worker 1239 is 0.842463
INFO:root:FL Epoch: 454 Done on worker:1239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1172
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1172 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662383
INFO:root:Worker: 1172 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533324
INFO:root:FL Epoch: 454 Norm Difference for worker 1172 is 0.861021
INFO:root:FL Epoch: 454 Done on worker:1172
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :240
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 240 Train Epoch: 0 [0/201 (0%)]	Loss: 0.855497
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 240 Train Epoch: 1 [0/201 (0%)]	Loss: 0.826982
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 240 is 0.828226
INFO:root:FL Epoch: 454 Done on worker:240
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1795
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1795 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512837
INFO:root:Worker: 1795 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513328
INFO:root:FL Epoch: 454 Norm Difference for worker 1795 is 0.802109
INFO:root:FL Epoch: 454 Done on worker:1795
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :92
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 92 Train Epoch: 0 [0/201 (0%)]	Loss: 0.513699
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 92 Train Epoch: 1 [0/201 (0%)]	Loss: 0.553616
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 454 Norm Difference for worker 92 is 0.818568
INFO:root:FL Epoch: 454 Done on worker:92
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1477
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1477 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575299
INFO:root:Worker: 1477 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435865
INFO:root:FL Epoch: 454 Norm Difference for worker 1477 is 0.776714
INFO:root:FL Epoch: 454 Done on worker:1477
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 454 Training on worker :1261
INFO:root:FL Epoch: 454 Using Learning rate : 0.020188553706599187 
INFO:root:FL Epoch: 454 Normal Training
INFO:root:Worker: 1261 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441902
INFO:root:Worker: 1261 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413292
INFO:root:FL Epoch: 454 Norm Difference for worker 1261 is 0.784181
INFO:root:FL Epoch: 454 Done on worker:1261
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 384
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 454 Ends   ===================
INFO:root:Epoch:454 Global Model Test Loss:0.4950331905308892 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:454 Global Model Backdoor Test Loss:0.1442634661992391                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 455 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 455 Workers Selected : [1937, 655, 965, 838, 1218, 1353, 1429, 108, 488, 1012]
INFO:root:FL Epoch: 455 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 455 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 455 Training on worker :1937
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.506077
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.628367
INFO:root:FL Epoch: 455 Norm Difference for worker 1937 is 0.90012
INFO:root:FL Epoch: 455 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :655
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 655 Train Epoch: 0 [0/200 (0%)]	Loss: 0.452820
INFO:root:Worker: 655 Train Epoch: 1 [0/200 (0%)]	Loss: 0.380857
INFO:root:FL Epoch: 455 Norm Difference for worker 655 is 0.814962
INFO:root:FL Epoch: 455 Done on worker:655
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :965
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 965 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561595
INFO:root:Worker: 965 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372513
INFO:root:FL Epoch: 455 Norm Difference for worker 965 is 0.755382
INFO:root:FL Epoch: 455 Done on worker:965
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :838
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 838 Train Epoch: 0 [0/200 (0%)]	Loss: 0.636631
INFO:root:Worker: 838 Train Epoch: 1 [0/200 (0%)]	Loss: 0.636817
INFO:root:FL Epoch: 455 Norm Difference for worker 838 is 0.831133
INFO:root:FL Epoch: 455 Done on worker:838
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1218
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1218 Train Epoch: 0 [0/200 (0%)]	Loss: 0.766298
INFO:root:Worker: 1218 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445607
INFO:root:FL Epoch: 455 Norm Difference for worker 1218 is 0.810141
INFO:root:FL Epoch: 455 Done on worker:1218
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1353
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.229550
INFO:root:Worker: 1353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.630534
INFO:root:FL Epoch: 455 Norm Difference for worker 1353 is 0.742479
INFO:root:FL Epoch: 455 Done on worker:1353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1429
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1429 Train Epoch: 0 [0/200 (0%)]	Loss: 0.248644
INFO:root:Worker: 1429 Train Epoch: 1 [0/200 (0%)]	Loss: 0.312862
INFO:root:FL Epoch: 455 Norm Difference for worker 1429 is 0.657268
INFO:root:FL Epoch: 455 Done on worker:1429
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :108
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 108 Train Epoch: 0 [0/201 (0%)]	Loss: 0.632267
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 108 Train Epoch: 1 [0/201 (0%)]	Loss: 0.322403
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 455 Norm Difference for worker 108 is 0.69742
INFO:root:FL Epoch: 455 Done on worker:108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :488
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 488 Train Epoch: 0 [0/200 (0%)]	Loss: 0.736337
INFO:root:Worker: 488 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521299
INFO:root:FL Epoch: 455 Norm Difference for worker 488 is 0.76798
INFO:root:FL Epoch: 455 Done on worker:488
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 455 Training on worker :1012
INFO:root:FL Epoch: 455 Using Learning rate : 0.02014817659918599 
INFO:root:FL Epoch: 455 Normal Training
INFO:root:Worker: 1012 Train Epoch: 0 [0/200 (0%)]	Loss: 0.329796
INFO:root:Worker: 1012 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297988
INFO:root:FL Epoch: 455 Norm Difference for worker 1012 is 0.685507
INFO:root:FL Epoch: 455 Done on worker:1012
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 108
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 455 Ends   ===================
INFO:root:Epoch:455 Global Model Test Loss:0.4991311799077427 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:455 Global Model Backdoor Test Loss:0.16528439770142236                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 456 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 456 Workers Selected : [929, 1347, 1497, 239, 1485, 1482, 971, 1332, 325, 606]
INFO:root:FL Epoch: 456 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 456 Num points on workers: [200 200 200 201 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 456 Training on worker :929
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 929 Train Epoch: 0 [0/200 (0%)]	Loss: 0.551049
INFO:root:Worker: 929 Train Epoch: 1 [0/200 (0%)]	Loss: 0.553414
INFO:root:FL Epoch: 456 Norm Difference for worker 929 is 0.838471
INFO:root:FL Epoch: 456 Done on worker:929
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1347
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.505882
INFO:root:Worker: 1347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.477389
INFO:root:FL Epoch: 456 Norm Difference for worker 1347 is 0.874682
INFO:root:FL Epoch: 456 Done on worker:1347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1497
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1497 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550156
INFO:root:Worker: 1497 Train Epoch: 1 [0/200 (0%)]	Loss: 0.606574
INFO:root:FL Epoch: 456 Norm Difference for worker 1497 is 0.846222
INFO:root:FL Epoch: 456 Done on worker:1497
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :239
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 239 Train Epoch: 0 [0/201 (0%)]	Loss: 0.776054
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 239 Train Epoch: 1 [0/201 (0%)]	Loss: 0.444378
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 456 Norm Difference for worker 239 is 0.958342
INFO:root:FL Epoch: 456 Done on worker:239
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1485
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1485 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517766
INFO:root:Worker: 1485 Train Epoch: 1 [0/200 (0%)]	Loss: 0.422708
INFO:root:FL Epoch: 456 Norm Difference for worker 1485 is 0.781586
INFO:root:FL Epoch: 456 Done on worker:1485
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1482
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1482 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670895
INFO:root:Worker: 1482 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682467
INFO:root:FL Epoch: 456 Norm Difference for worker 1482 is 0.802338
INFO:root:FL Epoch: 456 Done on worker:1482
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :971
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 971 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768757
INFO:root:Worker: 971 Train Epoch: 1 [0/200 (0%)]	Loss: 0.535533
INFO:root:FL Epoch: 456 Norm Difference for worker 971 is 0.833921
INFO:root:FL Epoch: 456 Done on worker:971
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :1332
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487891
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.697999
INFO:root:FL Epoch: 456 Norm Difference for worker 1332 is 0.856465
INFO:root:FL Epoch: 456 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :325
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 325 Train Epoch: 0 [0/201 (0%)]	Loss: 0.413129
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 325 Train Epoch: 1 [0/201 (0%)]	Loss: 0.423617
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 456 Norm Difference for worker 325 is 0.809955
INFO:root:FL Epoch: 456 Done on worker:325
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 456 Training on worker :606
INFO:root:FL Epoch: 456 Using Learning rate : 0.020107880245987617 
INFO:root:FL Epoch: 456 Normal Training
INFO:root:Worker: 606 Train Epoch: 0 [0/200 (0%)]	Loss: 0.224016
INFO:root:Worker: 606 Train Epoch: 1 [0/200 (0%)]	Loss: 0.695459
INFO:root:FL Epoch: 456 Norm Difference for worker 606 is 0.787525
INFO:root:FL Epoch: 456 Done on worker:606
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1485
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 456 Ends   ===================
INFO:root:Epoch:456 Global Model Test Loss:0.4882081466562608 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:456 Global Model Backdoor Test Loss:0.1753627210855484                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 457 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 457 Workers Selected : [670, 1171, 102, 1739, 618, 360, 817, 1523, 1373, 1487]
INFO:root:FL Epoch: 457 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 457 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 457 Training on worker :670
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 670 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441534
INFO:root:Worker: 670 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475619
INFO:root:FL Epoch: 457 Norm Difference for worker 670 is 0.788837
INFO:root:FL Epoch: 457 Done on worker:670
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :1171
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 1171 Train Epoch: 0 [0/200 (0%)]	Loss: 0.643536
INFO:root:Worker: 1171 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385664
INFO:root:FL Epoch: 457 Norm Difference for worker 1171 is 0.691974
INFO:root:FL Epoch: 457 Done on worker:1171
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :102
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 102 Train Epoch: 0 [0/201 (0%)]	Loss: 0.602098
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 102 Train Epoch: 1 [0/201 (0%)]	Loss: 0.505314
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 457 Norm Difference for worker 102 is 0.780208
INFO:root:FL Epoch: 457 Done on worker:102
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :1739
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 1739 Train Epoch: 0 [0/200 (0%)]	Loss: 0.383126
INFO:root:Worker: 1739 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558790
INFO:root:FL Epoch: 457 Norm Difference for worker 1739 is 0.723927
INFO:root:FL Epoch: 457 Done on worker:1739
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :618
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 618 Train Epoch: 0 [0/200 (0%)]	Loss: 0.645725
INFO:root:Worker: 618 Train Epoch: 1 [0/200 (0%)]	Loss: 0.246668
INFO:root:FL Epoch: 457 Norm Difference for worker 618 is 0.747135
INFO:root:FL Epoch: 457 Done on worker:618
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :360
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.685241
INFO:root:Worker: 360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.617331
INFO:root:FL Epoch: 457 Norm Difference for worker 360 is 0.769457
INFO:root:FL Epoch: 457 Done on worker:360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :817
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 817 Train Epoch: 0 [0/200 (0%)]	Loss: 0.588195
INFO:root:Worker: 817 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425171
INFO:root:FL Epoch: 457 Norm Difference for worker 817 is 0.78286
INFO:root:FL Epoch: 457 Done on worker:817
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :1523
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 1523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.709053
INFO:root:Worker: 1523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478477
INFO:root:FL Epoch: 457 Norm Difference for worker 1523 is 0.751924
INFO:root:FL Epoch: 457 Done on worker:1523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :1373
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 1373 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523924
INFO:root:Worker: 1373 Train Epoch: 1 [0/200 (0%)]	Loss: 0.434570
INFO:root:FL Epoch: 457 Norm Difference for worker 1373 is 0.820552
INFO:root:FL Epoch: 457 Done on worker:1373
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 457 Training on worker :1487
INFO:root:FL Epoch: 457 Using Learning rate : 0.020067664485495643 
INFO:root:FL Epoch: 457 Normal Training
INFO:root:Worker: 1487 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684250
INFO:root:Worker: 1487 Train Epoch: 1 [0/200 (0%)]	Loss: 0.285108
INFO:root:FL Epoch: 457 Norm Difference for worker 1487 is 0.743774
INFO:root:FL Epoch: 457 Done on worker:1487
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1171
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 457 Ends   ===================
INFO:root:Epoch:457 Global Model Test Loss:0.504426170797909 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:457 Global Model Backdoor Test Loss:0.18503918374578157                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 458 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 458 Workers Selected : [1765, 320, 1569, 353, 1834, 1889, 1668, 1295, 1521, 693]
INFO:root:FL Epoch: 458 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 458 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 458 Training on worker :1765
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1765 Train Epoch: 0 [0/200 (0%)]	Loss: 0.310476
INFO:root:Worker: 1765 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552534
INFO:root:FL Epoch: 458 Norm Difference for worker 1765 is 0.759118
INFO:root:FL Epoch: 458 Done on worker:1765
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :320
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 320 Train Epoch: 0 [0/201 (0%)]	Loss: 0.458694
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 320 Train Epoch: 1 [0/201 (0%)]	Loss: 0.568697
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 458 Norm Difference for worker 320 is 0.776723
INFO:root:FL Epoch: 458 Done on worker:320
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1569
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.809643
INFO:root:Worker: 1569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.574209
INFO:root:FL Epoch: 458 Norm Difference for worker 1569 is 0.774822
INFO:root:FL Epoch: 458 Done on worker:1569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :353
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.690114
INFO:root:Worker: 353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.425459
INFO:root:FL Epoch: 458 Norm Difference for worker 353 is 0.755206
INFO:root:FL Epoch: 458 Done on worker:353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1834
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.449296
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355862
INFO:root:FL Epoch: 458 Norm Difference for worker 1834 is 0.757223
INFO:root:FL Epoch: 458 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1889
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1889 Train Epoch: 0 [0/200 (0%)]	Loss: 0.618914
INFO:root:Worker: 1889 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371666
INFO:root:FL Epoch: 458 Norm Difference for worker 1889 is 0.774133
INFO:root:FL Epoch: 458 Done on worker:1889
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1668
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1668 Train Epoch: 0 [0/200 (0%)]	Loss: 0.546848
INFO:root:Worker: 1668 Train Epoch: 1 [0/200 (0%)]	Loss: 0.793700
INFO:root:FL Epoch: 458 Norm Difference for worker 1668 is 0.794769
INFO:root:FL Epoch: 458 Done on worker:1668
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1295
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1295 Train Epoch: 0 [0/200 (0%)]	Loss: 0.532047
INFO:root:Worker: 1295 Train Epoch: 1 [0/200 (0%)]	Loss: 0.558638
INFO:root:FL Epoch: 458 Norm Difference for worker 1295 is 0.738583
INFO:root:FL Epoch: 458 Done on worker:1295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :1521
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 1521 Train Epoch: 0 [0/200 (0%)]	Loss: 0.427512
INFO:root:Worker: 1521 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415435
INFO:root:FL Epoch: 458 Norm Difference for worker 1521 is 0.750388
INFO:root:FL Epoch: 458 Done on worker:1521
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 458 Training on worker :693
INFO:root:FL Epoch: 458 Using Learning rate : 0.02002752915652465 
INFO:root:FL Epoch: 458 Normal Training
INFO:root:Worker: 693 Train Epoch: 0 [0/200 (0%)]	Loss: 0.317473
INFO:root:Worker: 693 Train Epoch: 1 [0/200 (0%)]	Loss: 0.287191
INFO:root:FL Epoch: 458 Norm Difference for worker 693 is 0.613011
INFO:root:FL Epoch: 458 Done on worker:693
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 693
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 458 Ends   ===================
INFO:root:Epoch:458 Global Model Test Loss:0.554715987514047 and Test Accuracy:72.6470588235294 
INFO:root:Epoch:458 Global Model Backdoor Test Loss:0.17443499093254408                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 459 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 459 Workers Selected : [184, 858, 249, 574, 1523, 1811, 1546, 1823, 1121, 108]
INFO:root:FL Epoch: 459 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.10034948 0.09985022 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 459 Num points on workers: [201 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 459 Training on worker :184
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 184 Train Epoch: 0 [0/201 (0%)]	Loss: 0.658381
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 184 Train Epoch: 1 [0/201 (0%)]	Loss: 0.488723
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 459 Norm Difference for worker 184 is 0.810311
INFO:root:FL Epoch: 459 Done on worker:184
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :858
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762600
INFO:root:Worker: 858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.349659
INFO:root:FL Epoch: 459 Norm Difference for worker 858 is 0.901227
INFO:root:FL Epoch: 459 Done on worker:858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :249
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 249 Train Epoch: 0 [0/201 (0%)]	Loss: 0.661065
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 249 Train Epoch: 1 [0/201 (0%)]	Loss: 0.321577
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 459 Norm Difference for worker 249 is 0.806154
INFO:root:FL Epoch: 459 Done on worker:249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :574
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 574 Train Epoch: 0 [0/200 (0%)]	Loss: 0.473439
INFO:root:Worker: 574 Train Epoch: 1 [0/200 (0%)]	Loss: 0.391411
INFO:root:FL Epoch: 459 Norm Difference for worker 574 is 0.834508
INFO:root:FL Epoch: 459 Done on worker:574
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1523
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1523 Train Epoch: 0 [0/200 (0%)]	Loss: 0.677963
INFO:root:Worker: 1523 Train Epoch: 1 [0/200 (0%)]	Loss: 0.694978
INFO:root:FL Epoch: 459 Norm Difference for worker 1523 is 0.870823
INFO:root:FL Epoch: 459 Done on worker:1523
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1811
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1811 Train Epoch: 0 [0/200 (0%)]	Loss: 0.683285
INFO:root:Worker: 1811 Train Epoch: 1 [0/200 (0%)]	Loss: 0.556992
INFO:root:FL Epoch: 459 Norm Difference for worker 1811 is 0.892214
INFO:root:FL Epoch: 459 Done on worker:1811
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1546
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1546 Train Epoch: 0 [0/200 (0%)]	Loss: 0.308669
INFO:root:Worker: 1546 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452292
INFO:root:FL Epoch: 459 Norm Difference for worker 1546 is 0.865621
INFO:root:FL Epoch: 459 Done on worker:1546
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1823
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549234
INFO:root:Worker: 1823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.656340
INFO:root:FL Epoch: 459 Norm Difference for worker 1823 is 1.051942
INFO:root:FL Epoch: 459 Done on worker:1823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :1121
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 1121 Train Epoch: 0 [0/200 (0%)]	Loss: 0.910608
INFO:root:Worker: 1121 Train Epoch: 1 [0/200 (0%)]	Loss: 0.578020
INFO:root:FL Epoch: 459 Norm Difference for worker 1121 is 0.92897
INFO:root:FL Epoch: 459 Done on worker:1121
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 459 Training on worker :108
INFO:root:FL Epoch: 459 Using Learning rate : 0.0199874740982116 
INFO:root:FL Epoch: 459 Normal Training
INFO:root:Worker: 108 Train Epoch: 0 [0/201 (0%)]	Loss: 0.406372
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 108 Train Epoch: 1 [0/201 (0%)]	Loss: 0.264189
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 459 Norm Difference for worker 108 is 0.587553
INFO:root:FL Epoch: 459 Done on worker:108
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 108
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 459 Ends   ===================
INFO:root:Epoch:459 Global Model Test Loss:0.5297833032467786 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:459 Global Model Backdoor Test Loss:0.11379196929434936                             and Backdoor Test Accuracy:98.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 460 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 460 Workers Selected : [1672, 779, 871, 464, 709, 1801, 1386, 869, 1777, 1611]
INFO:root:FL Epoch: 460 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 460 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 460 Training on worker :1672
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1672 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436245
INFO:root:Worker: 1672 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345081
INFO:root:FL Epoch: 460 Norm Difference for worker 1672 is 0.859093
INFO:root:FL Epoch: 460 Done on worker:1672
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :779
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.837558
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449263
INFO:root:FL Epoch: 460 Norm Difference for worker 779 is 1.032104
INFO:root:FL Epoch: 460 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :871
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 871 Train Epoch: 0 [0/200 (0%)]	Loss: 0.790539
INFO:root:Worker: 871 Train Epoch: 1 [0/200 (0%)]	Loss: 0.274391
INFO:root:FL Epoch: 460 Norm Difference for worker 871 is 0.999479
INFO:root:FL Epoch: 460 Done on worker:871
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :464
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450350
INFO:root:Worker: 464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352001
INFO:root:FL Epoch: 460 Norm Difference for worker 464 is 0.910192
INFO:root:FL Epoch: 460 Done on worker:464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :709
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 709 Train Epoch: 0 [0/200 (0%)]	Loss: 0.805810
INFO:root:Worker: 709 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403497
INFO:root:FL Epoch: 460 Norm Difference for worker 709 is 1.074663
INFO:root:FL Epoch: 460 Done on worker:709
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1801
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498625
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.202077
INFO:root:FL Epoch: 460 Norm Difference for worker 1801 is 0.978281
INFO:root:FL Epoch: 460 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1386
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1386 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372990
INFO:root:Worker: 1386 Train Epoch: 1 [0/200 (0%)]	Loss: 0.363309
INFO:root:FL Epoch: 460 Norm Difference for worker 1386 is 0.928497
INFO:root:FL Epoch: 460 Done on worker:1386
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :869
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.765663
INFO:root:Worker: 869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.409297
INFO:root:FL Epoch: 460 Norm Difference for worker 869 is 0.920401
INFO:root:FL Epoch: 460 Done on worker:869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1777
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1777 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343138
INFO:root:Worker: 1777 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680601
INFO:root:FL Epoch: 460 Norm Difference for worker 1777 is 1.030799
INFO:root:FL Epoch: 460 Done on worker:1777
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 460 Training on worker :1611
INFO:root:FL Epoch: 460 Using Learning rate : 0.019947499150015178 
INFO:root:FL Epoch: 460 Normal Training
INFO:root:Worker: 1611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.599476
INFO:root:Worker: 1611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367348
INFO:root:FL Epoch: 460 Norm Difference for worker 1611 is 1.049955
INFO:root:FL Epoch: 460 Done on worker:1611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1672
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 460 Ends   ===================
INFO:root:Epoch:460 Global Model Test Loss:0.5519046844804988 and Test Accuracy:75.0 
INFO:root:Epoch:460 Global Model Backdoor Test Loss:0.14867624888817468                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 461 Begins ===================
INFO:root:FL Epoch: 461 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 461 Workers Selected : [0, 72, 346, 623, 1155, 1091, 367, 843, 344, 679]
INFO:root:FL Epoch: 461 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 461 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 461 Training on worker :0
INFO:root:FL Epoch: 461 Using Learning rate : 0.003981520830343029 
INFO:root:FL Epoch: 461 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.130554
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.139397
INFO:root:FL Epoch: 461 Worker: 0 Backdoor Test Loss: 0.14176840335130692 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 461 Worker: 0 Backdoor Train Loss: 0.1332862615585327 Backdoor Train Accuracy: 98.0
INFO:root:FL Epoch: 461 Norm Difference for worker 0 is 0.109194
INFO:root:FL Epoch: 461 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :72
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 72 Train Epoch: 0 [0/201 (0%)]	Loss: 0.508756
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 72 Train Epoch: 1 [0/201 (0%)]	Loss: 0.389339
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 461 Norm Difference for worker 72 is 0.889158
INFO:root:FL Epoch: 461 Done on worker:72
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :346
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659409
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372019
INFO:root:FL Epoch: 461 Norm Difference for worker 346 is 1.040791
INFO:root:FL Epoch: 461 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :623
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 623 Train Epoch: 0 [0/200 (0%)]	Loss: 0.291457
INFO:root:Worker: 623 Train Epoch: 1 [0/200 (0%)]	Loss: 0.614102
INFO:root:FL Epoch: 461 Norm Difference for worker 623 is 1.059525
INFO:root:FL Epoch: 461 Done on worker:623
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1155
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1155 Train Epoch: 0 [0/200 (0%)]	Loss: 0.298492
INFO:root:Worker: 1155 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445541
INFO:root:FL Epoch: 461 Norm Difference for worker 1155 is 1.007711
INFO:root:FL Epoch: 461 Done on worker:1155
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :1091
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 1091 Train Epoch: 0 [0/200 (0%)]	Loss: 0.404197
INFO:root:Worker: 1091 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536650
INFO:root:FL Epoch: 461 Norm Difference for worker 1091 is 0.986689
INFO:root:FL Epoch: 461 Done on worker:1091
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :367
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743145
INFO:root:Worker: 367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450327
INFO:root:FL Epoch: 461 Norm Difference for worker 367 is 0.993727
INFO:root:FL Epoch: 461 Done on worker:367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :843
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 843 Train Epoch: 0 [0/200 (0%)]	Loss: 0.920988
INFO:root:Worker: 843 Train Epoch: 1 [0/200 (0%)]	Loss: 0.782920
INFO:root:FL Epoch: 461 Norm Difference for worker 843 is 1.023508
INFO:root:FL Epoch: 461 Done on worker:843
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :344
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 344 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708465
INFO:root:Worker: 344 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521840
INFO:root:FL Epoch: 461 Norm Difference for worker 344 is 1.037097
INFO:root:FL Epoch: 461 Done on worker:344
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 461 Training on worker :679
INFO:root:FL Epoch: 461 Using Learning rate : 0.01990760415171515 
INFO:root:FL Epoch: 461 Normal Training
INFO:root:Worker: 679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.572047
INFO:root:Worker: 679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.266895
INFO:root:FL Epoch: 461 Norm Difference for worker 679 is 0.989951
INFO:root:FL Epoch: 461 Done on worker:679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 461 Ends   ===================
INFO:root:Epoch:461 Global Model Test Loss:0.5694792033994899 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:461 Global Model Backdoor Test Loss:0.14176840335130692                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 462 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 462 Workers Selected : [90, 1207, 1431, 541, 283, 210, 967, 257, 1647, 933]
INFO:root:FL Epoch: 462 Fraction of points on each worker in this round: [0.1002994 0.0998004 0.0998004 0.0998004 0.1002994 0.1002994 0.0998004
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 462 Num points on workers: [201 200 200 200 201 201 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 462 Training on worker :90
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 90 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587232
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 90 Train Epoch: 1 [0/201 (0%)]	Loss: 0.490678
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 462 Norm Difference for worker 90 is 0.97281
INFO:root:FL Epoch: 462 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1207
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1207 Train Epoch: 0 [0/200 (0%)]	Loss: 0.720789
INFO:root:Worker: 1207 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640036
INFO:root:FL Epoch: 462 Norm Difference for worker 1207 is 1.0457
INFO:root:FL Epoch: 462 Done on worker:1207
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1431
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1431 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558541
INFO:root:Worker: 1431 Train Epoch: 1 [0/200 (0%)]	Loss: 0.326814
INFO:root:FL Epoch: 462 Norm Difference for worker 1431 is 0.971898
INFO:root:FL Epoch: 462 Done on worker:1431
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :541
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 541 Train Epoch: 0 [0/200 (0%)]	Loss: 0.402450
INFO:root:Worker: 541 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374464
INFO:root:FL Epoch: 462 Norm Difference for worker 541 is 0.949106
INFO:root:FL Epoch: 462 Done on worker:541
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :283
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 283 Train Epoch: 0 [0/201 (0%)]	Loss: 0.474435
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 283 Train Epoch: 1 [0/201 (0%)]	Loss: 0.375072
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 462 Norm Difference for worker 283 is 0.843926
INFO:root:FL Epoch: 462 Done on worker:283
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :210
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 210 Train Epoch: 0 [0/201 (0%)]	Loss: 0.548650
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 210 Train Epoch: 1 [0/201 (0%)]	Loss: 0.347019
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 462 Norm Difference for worker 210 is 1.054527
INFO:root:FL Epoch: 462 Done on worker:210
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :967
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 967 Train Epoch: 0 [0/200 (0%)]	Loss: 0.380552
INFO:root:Worker: 967 Train Epoch: 1 [0/200 (0%)]	Loss: 0.352307
INFO:root:FL Epoch: 462 Norm Difference for worker 967 is 0.958254
INFO:root:FL Epoch: 462 Done on worker:967
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :257
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 257 Train Epoch: 0 [0/201 (0%)]	Loss: 0.715514
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 257 Train Epoch: 1 [0/201 (0%)]	Loss: 0.454831
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 462 Norm Difference for worker 257 is 1.044027
INFO:root:FL Epoch: 462 Done on worker:257
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :1647
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 1647 Train Epoch: 0 [0/200 (0%)]	Loss: 0.629295
INFO:root:Worker: 1647 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547142
INFO:root:FL Epoch: 462 Norm Difference for worker 1647 is 1.105132
INFO:root:FL Epoch: 462 Done on worker:1647
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 462 Training on worker :933
INFO:root:FL Epoch: 462 Using Learning rate : 0.019867788943411718 
INFO:root:FL Epoch: 462 Normal Training
INFO:root:Worker: 933 Train Epoch: 0 [0/200 (0%)]	Loss: 0.986682
INFO:root:Worker: 933 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359192
INFO:root:FL Epoch: 462 Norm Difference for worker 933 is 1.037998
INFO:root:FL Epoch: 462 Done on worker:933
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 283
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 462 Ends   ===================
INFO:root:Epoch:462 Global Model Test Loss:0.5222479683511397 and Test Accuracy:77.94117647058823 
INFO:root:Epoch:462 Global Model Backdoor Test Loss:0.13275108858942986                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 463 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 463 Workers Selected : [791, 811, 755, 870, 1026, 1538, 1829, 1858, 1, 76]
INFO:root:FL Epoch: 463 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.1003996]
INFO:root:FL Epoch: 463 Num points on workers: [200 200 200 200 200 200 200 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 463 Training on worker :791
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373916
INFO:root:Worker: 791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354820
INFO:root:FL Epoch: 463 Norm Difference for worker 791 is 0.918968
INFO:root:FL Epoch: 463 Done on worker:791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :811
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 811 Train Epoch: 0 [0/200 (0%)]	Loss: 0.570100
INFO:root:Worker: 811 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589278
INFO:root:FL Epoch: 463 Norm Difference for worker 811 is 0.986998
INFO:root:FL Epoch: 463 Done on worker:811
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :755
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 755 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450383
INFO:root:Worker: 755 Train Epoch: 1 [0/200 (0%)]	Loss: 0.309146
INFO:root:FL Epoch: 463 Norm Difference for worker 755 is 0.902104
INFO:root:FL Epoch: 463 Done on worker:755
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :870
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 870 Train Epoch: 0 [0/200 (0%)]	Loss: 0.480871
INFO:root:Worker: 870 Train Epoch: 1 [0/200 (0%)]	Loss: 0.401114
INFO:root:FL Epoch: 463 Norm Difference for worker 870 is 0.980127
INFO:root:FL Epoch: 463 Done on worker:870
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1026
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1026 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438599
INFO:root:Worker: 1026 Train Epoch: 1 [0/200 (0%)]	Loss: 0.446129
INFO:root:FL Epoch: 463 Norm Difference for worker 1026 is 0.929644
INFO:root:FL Epoch: 463 Done on worker:1026
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1538
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1538 Train Epoch: 0 [0/200 (0%)]	Loss: 0.697618
INFO:root:Worker: 1538 Train Epoch: 1 [0/200 (0%)]	Loss: 0.838266
INFO:root:FL Epoch: 463 Norm Difference for worker 1538 is 1.003539
INFO:root:FL Epoch: 463 Done on worker:1538
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1829
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1829 Train Epoch: 0 [0/200 (0%)]	Loss: 0.492234
INFO:root:Worker: 1829 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521662
INFO:root:FL Epoch: 463 Norm Difference for worker 1829 is 0.842992
INFO:root:FL Epoch: 463 Done on worker:1829
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1858
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1858 Train Epoch: 0 [0/200 (0%)]	Loss: 0.628962
INFO:root:Worker: 1858 Train Epoch: 1 [0/200 (0%)]	Loss: 0.381282
INFO:root:FL Epoch: 463 Norm Difference for worker 1858 is 1.003158
INFO:root:FL Epoch: 463 Done on worker:1858
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :1
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 1 Train Epoch: 0 [0/201 (0%)]	Loss: 0.811881
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 1 Train Epoch: 1 [0/201 (0%)]	Loss: 0.436561
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 1 is 0.928879
INFO:root:FL Epoch: 463 Done on worker:1
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 463 Training on worker :76
INFO:root:FL Epoch: 463 Using Learning rate : 0.019828053365524893 
INFO:root:FL Epoch: 463 Normal Training
INFO:root:Worker: 76 Train Epoch: 0 [0/201 (0%)]	Loss: 0.645591
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 76 Train Epoch: 1 [0/201 (0%)]	Loss: 0.633457
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 463 Norm Difference for worker 76 is 0.919665
INFO:root:FL Epoch: 463 Done on worker:76
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1829
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 463 Ends   ===================
INFO:root:Epoch:463 Global Model Test Loss:0.5194723465863396 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:463 Global Model Backdoor Test Loss:0.10995783843100071                             and Backdoor Test Accuracy:99.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 464 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 464 Workers Selected : [1263, 524, 1310, 74, 1636, 533, 710, 1099, 1908, 758]
INFO:root:FL Epoch: 464 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 464 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 464 Training on worker :1263
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1263 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488259
INFO:root:Worker: 1263 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651913
INFO:root:FL Epoch: 464 Norm Difference for worker 1263 is 0.956154
INFO:root:FL Epoch: 464 Done on worker:1263
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :524
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 524 Train Epoch: 0 [0/200 (0%)]	Loss: 0.762095
INFO:root:Worker: 524 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394418
INFO:root:FL Epoch: 464 Norm Difference for worker 524 is 0.847253
INFO:root:FL Epoch: 464 Done on worker:524
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1310
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1310 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450866
INFO:root:Worker: 1310 Train Epoch: 1 [0/200 (0%)]	Loss: 0.281849
INFO:root:FL Epoch: 464 Norm Difference for worker 1310 is 0.879818
INFO:root:FL Epoch: 464 Done on worker:1310
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :74
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 74 Train Epoch: 0 [0/201 (0%)]	Loss: 0.476526
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 74 Train Epoch: 1 [0/201 (0%)]	Loss: 0.544963
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 464 Norm Difference for worker 74 is 0.944739
INFO:root:FL Epoch: 464 Done on worker:74
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1636
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1636 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621702
INFO:root:Worker: 1636 Train Epoch: 1 [0/200 (0%)]	Loss: 0.652476
INFO:root:FL Epoch: 464 Norm Difference for worker 1636 is 0.992493
INFO:root:FL Epoch: 464 Done on worker:1636
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :533
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 533 Train Epoch: 0 [0/200 (0%)]	Loss: 0.717249
INFO:root:Worker: 533 Train Epoch: 1 [0/200 (0%)]	Loss: 0.625850
INFO:root:FL Epoch: 464 Norm Difference for worker 533 is 0.949367
INFO:root:FL Epoch: 464 Done on worker:533
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :710
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357665
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.328217
INFO:root:FL Epoch: 464 Norm Difference for worker 710 is 0.784104
INFO:root:FL Epoch: 464 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1099
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1099 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634295
INFO:root:Worker: 1099 Train Epoch: 1 [0/200 (0%)]	Loss: 0.754289
INFO:root:FL Epoch: 464 Norm Difference for worker 1099 is 0.913431
INFO:root:FL Epoch: 464 Done on worker:1099
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :1908
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 1908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.658220
INFO:root:Worker: 1908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359995
INFO:root:FL Epoch: 464 Norm Difference for worker 1908 is 0.882894
INFO:root:FL Epoch: 464 Done on worker:1908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 464 Training on worker :758
INFO:root:FL Epoch: 464 Using Learning rate : 0.019788397258793843 
INFO:root:FL Epoch: 464 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.430350
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355941
INFO:root:FL Epoch: 464 Norm Difference for worker 758 is 0.927413
INFO:root:FL Epoch: 464 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 710
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 464 Ends   ===================
INFO:root:Epoch:464 Global Model Test Loss:0.5248084699406343 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:464 Global Model Backdoor Test Loss:0.11892908749481042                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 465 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 465 Workers Selected : [899, 259, 1772, 1791, 684, 1688, 1734, 1399, 1682, 863]
INFO:root:FL Epoch: 465 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 465 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 465 Training on worker :899
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 899 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597507
INFO:root:Worker: 899 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384268
INFO:root:FL Epoch: 465 Norm Difference for worker 899 is 0.881588
INFO:root:FL Epoch: 465 Done on worker:899
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :259
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 259 Train Epoch: 0 [0/201 (0%)]	Loss: 0.587879
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 259 Train Epoch: 1 [0/201 (0%)]	Loss: 0.202421
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 465 Norm Difference for worker 259 is 0.876407
INFO:root:FL Epoch: 465 Done on worker:259
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1772
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.758907
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.410841
INFO:root:FL Epoch: 465 Norm Difference for worker 1772 is 0.976365
INFO:root:FL Epoch: 465 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1791
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1791 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714100
INFO:root:Worker: 1791 Train Epoch: 1 [0/200 (0%)]	Loss: 0.445350
INFO:root:FL Epoch: 465 Norm Difference for worker 1791 is 0.968209
INFO:root:FL Epoch: 465 Done on worker:1791
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :684
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 684 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346502
INFO:root:Worker: 684 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282319
INFO:root:FL Epoch: 465 Norm Difference for worker 684 is 0.899828
INFO:root:FL Epoch: 465 Done on worker:684
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1688
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1688 Train Epoch: 0 [0/200 (0%)]	Loss: 0.481684
INFO:root:Worker: 1688 Train Epoch: 1 [0/200 (0%)]	Loss: 0.260346
INFO:root:FL Epoch: 465 Norm Difference for worker 1688 is 0.92716
INFO:root:FL Epoch: 465 Done on worker:1688
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1734
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1734 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544520
INFO:root:Worker: 1734 Train Epoch: 1 [0/200 (0%)]	Loss: 0.424211
INFO:root:FL Epoch: 465 Norm Difference for worker 1734 is 0.930372
INFO:root:FL Epoch: 465 Done on worker:1734
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1399
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1399 Train Epoch: 0 [0/200 (0%)]	Loss: 0.681650
INFO:root:Worker: 1399 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421114
INFO:root:FL Epoch: 465 Norm Difference for worker 1399 is 1.001291
INFO:root:FL Epoch: 465 Done on worker:1399
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :1682
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 1682 Train Epoch: 0 [0/200 (0%)]	Loss: 0.514509
INFO:root:Worker: 1682 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355627
INFO:root:FL Epoch: 465 Norm Difference for worker 1682 is 0.869577
INFO:root:FL Epoch: 465 Done on worker:1682
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 465 Training on worker :863
INFO:root:FL Epoch: 465 Using Learning rate : 0.019748820464276257 
INFO:root:FL Epoch: 465 Normal Training
INFO:root:Worker: 863 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688747
INFO:root:Worker: 863 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463733
INFO:root:FL Epoch: 465 Norm Difference for worker 863 is 0.942141
INFO:root:FL Epoch: 465 Done on worker:863
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 259
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 465 Ends   ===================
INFO:root:Epoch:465 Global Model Test Loss:0.5095173979506773 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:465 Global Model Backdoor Test Loss:0.17725263411800066                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 466 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 466 Workers Selected : [1903, 1500, 1590, 918, 1410, 476, 1621, 622, 1084, 1753]
INFO:root:FL Epoch: 466 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 466 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 466 Training on worker :1903
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.531471
INFO:root:Worker: 1903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.304190
INFO:root:FL Epoch: 466 Norm Difference for worker 1903 is 0.854572
INFO:root:FL Epoch: 466 Done on worker:1903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1500
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 0.803956
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444825
INFO:root:FL Epoch: 466 Norm Difference for worker 1500 is 0.809703
INFO:root:FL Epoch: 466 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1590
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1590 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417555
INFO:root:Worker: 1590 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476204
INFO:root:FL Epoch: 466 Norm Difference for worker 1590 is 0.813366
INFO:root:FL Epoch: 466 Done on worker:1590
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :918
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 918 Train Epoch: 0 [0/200 (0%)]	Loss: 0.695127
INFO:root:Worker: 918 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327122
INFO:root:FL Epoch: 466 Norm Difference for worker 918 is 0.881192
INFO:root:FL Epoch: 466 Done on worker:918
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1410
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.497228
INFO:root:Worker: 1410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.315694
INFO:root:FL Epoch: 466 Norm Difference for worker 1410 is 0.811997
INFO:root:FL Epoch: 466 Done on worker:1410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :476
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.565929
INFO:root:Worker: 476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.612507
INFO:root:FL Epoch: 466 Norm Difference for worker 476 is 0.781401
INFO:root:FL Epoch: 466 Done on worker:476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1621
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1621 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641071
INFO:root:Worker: 1621 Train Epoch: 1 [0/200 (0%)]	Loss: 0.460022
INFO:root:FL Epoch: 466 Norm Difference for worker 1621 is 0.832424
INFO:root:FL Epoch: 466 Done on worker:1621
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :622
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607764
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520305
INFO:root:FL Epoch: 466 Norm Difference for worker 622 is 0.793257
INFO:root:FL Epoch: 466 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1084
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1084 Train Epoch: 0 [0/200 (0%)]	Loss: 0.670656
INFO:root:Worker: 1084 Train Epoch: 1 [0/200 (0%)]	Loss: 0.665481
INFO:root:FL Epoch: 466 Norm Difference for worker 1084 is 0.831899
INFO:root:FL Epoch: 466 Done on worker:1084
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 466 Training on worker :1753
INFO:root:FL Epoch: 466 Using Learning rate : 0.019709322823347704 
INFO:root:FL Epoch: 466 Normal Training
INFO:root:Worker: 1753 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415946
INFO:root:Worker: 1753 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345692
INFO:root:FL Epoch: 466 Norm Difference for worker 1753 is 0.692227
INFO:root:FL Epoch: 466 Done on worker:1753
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 1753
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 466 Ends   ===================
INFO:root:Epoch:466 Global Model Test Loss:0.5202436377020443 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:466 Global Model Backdoor Test Loss:0.18459453185399374                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 467 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 467 Workers Selected : [1168, 39, 868, 89, 1403, 561, 196, 1650, 1312, 885]
INFO:root:FL Epoch: 467 Fraction of points on each worker in this round: [0.09985022 0.10034948 0.09985022 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 467 Num points on workers: [200 201 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 467 Training on worker :1168
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1168 Train Epoch: 0 [0/200 (0%)]	Loss: 0.354968
INFO:root:Worker: 1168 Train Epoch: 1 [0/200 (0%)]	Loss: 0.289189
INFO:root:FL Epoch: 467 Norm Difference for worker 1168 is 0.787851
INFO:root:FL Epoch: 467 Done on worker:1168
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :39
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 39 Train Epoch: 0 [0/201 (0%)]	Loss: 0.470358
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 39 Train Epoch: 1 [0/201 (0%)]	Loss: 0.547233
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 467 Norm Difference for worker 39 is 0.90126
INFO:root:FL Epoch: 467 Done on worker:39
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :868
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 868 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568719
INFO:root:Worker: 868 Train Epoch: 1 [0/200 (0%)]	Loss: 0.642042
INFO:root:FL Epoch: 467 Norm Difference for worker 868 is 0.883126
INFO:root:FL Epoch: 467 Done on worker:868
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :89
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 89 Train Epoch: 0 [0/201 (0%)]	Loss: 0.399030
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 89 Train Epoch: 1 [0/201 (0%)]	Loss: 0.307121
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 467 Norm Difference for worker 89 is 0.886652
INFO:root:FL Epoch: 467 Done on worker:89
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1403
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1403 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450120
INFO:root:Worker: 1403 Train Epoch: 1 [0/200 (0%)]	Loss: 0.421653
INFO:root:FL Epoch: 467 Norm Difference for worker 1403 is 0.834181
INFO:root:FL Epoch: 467 Done on worker:1403
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :561
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.675832
INFO:root:Worker: 561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.403628
INFO:root:FL Epoch: 467 Norm Difference for worker 561 is 0.973456
INFO:root:FL Epoch: 467 Done on worker:561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :196
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 196 Train Epoch: 0 [0/201 (0%)]	Loss: 0.563795
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 196 Train Epoch: 1 [0/201 (0%)]	Loss: 0.162528
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 467 Norm Difference for worker 196 is 0.803406
INFO:root:FL Epoch: 467 Done on worker:196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1650
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1650 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743301
INFO:root:Worker: 1650 Train Epoch: 1 [0/200 (0%)]	Loss: 0.755297
INFO:root:FL Epoch: 467 Norm Difference for worker 1650 is 0.912073
INFO:root:FL Epoch: 467 Done on worker:1650
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :1312
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 1312 Train Epoch: 0 [0/200 (0%)]	Loss: 0.488672
INFO:root:Worker: 1312 Train Epoch: 1 [0/200 (0%)]	Loss: 0.674767
INFO:root:FL Epoch: 467 Norm Difference for worker 1312 is 0.843856
INFO:root:FL Epoch: 467 Done on worker:1312
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 467 Training on worker :885
INFO:root:FL Epoch: 467 Using Learning rate : 0.01966990417770101 
INFO:root:FL Epoch: 467 Normal Training
INFO:root:Worker: 885 Train Epoch: 0 [0/200 (0%)]	Loss: 0.723938
INFO:root:Worker: 885 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332368
INFO:root:FL Epoch: 467 Norm Difference for worker 885 is 0.831689
INFO:root:FL Epoch: 467 Done on worker:885
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1168
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 467 Ends   ===================
INFO:root:Epoch:467 Global Model Test Loss:0.5126258117311141 and Test Accuracy:77.6470588235294 
INFO:root:Epoch:467 Global Model Backdoor Test Loss:0.14041557535529137                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 468 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 468 Workers Selected : [1671, 814, 1769, 758, 1318, 1134, 290, 1178, 1679, 331]
INFO:root:FL Epoch: 468 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 468 Num points on workers: [200 200 200 200 200 200 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 468 Training on worker :1671
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470297
INFO:root:Worker: 1671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513769
INFO:root:FL Epoch: 468 Norm Difference for worker 1671 is 0.832552
INFO:root:FL Epoch: 468 Done on worker:1671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :814
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446007
INFO:root:Worker: 814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249177
INFO:root:FL Epoch: 468 Norm Difference for worker 814 is 0.783955
INFO:root:FL Epoch: 468 Done on worker:814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1769
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1769 Train Epoch: 0 [0/200 (0%)]	Loss: 0.446847
INFO:root:Worker: 1769 Train Epoch: 1 [0/200 (0%)]	Loss: 0.284947
INFO:root:FL Epoch: 468 Norm Difference for worker 1769 is 0.790526
INFO:root:FL Epoch: 468 Done on worker:1769
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :758
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 758 Train Epoch: 0 [0/200 (0%)]	Loss: 0.526977
INFO:root:Worker: 758 Train Epoch: 1 [0/200 (0%)]	Loss: 0.590567
INFO:root:FL Epoch: 468 Norm Difference for worker 758 is 0.812231
INFO:root:FL Epoch: 468 Done on worker:758
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1318
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1318 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493821
INFO:root:Worker: 1318 Train Epoch: 1 [0/200 (0%)]	Loss: 0.598391
INFO:root:FL Epoch: 468 Norm Difference for worker 1318 is 0.872535
INFO:root:FL Epoch: 468 Done on worker:1318
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1134
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1134 Train Epoch: 0 [0/200 (0%)]	Loss: 0.772913
INFO:root:Worker: 1134 Train Epoch: 1 [0/200 (0%)]	Loss: 0.449904
INFO:root:FL Epoch: 468 Norm Difference for worker 1134 is 0.906596
INFO:root:FL Epoch: 468 Done on worker:1134
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :290
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 290 Train Epoch: 0 [0/201 (0%)]	Loss: 0.897511
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 290 Train Epoch: 1 [0/201 (0%)]	Loss: 0.566904
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 468 Norm Difference for worker 290 is 0.867723
INFO:root:FL Epoch: 468 Done on worker:290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1178
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1178 Train Epoch: 0 [0/200 (0%)]	Loss: 0.632397
INFO:root:Worker: 1178 Train Epoch: 1 [0/200 (0%)]	Loss: 0.248525
INFO:root:FL Epoch: 468 Norm Difference for worker 1178 is 0.79603
INFO:root:FL Epoch: 468 Done on worker:1178
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :1679
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 0.537687
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.680461
INFO:root:FL Epoch: 468 Norm Difference for worker 1679 is 0.887453
INFO:root:FL Epoch: 468 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 468 Training on worker :331
INFO:root:FL Epoch: 468 Using Learning rate : 0.019630564369345606 
INFO:root:FL Epoch: 468 Normal Training
INFO:root:Worker: 331 Train Epoch: 0 [0/201 (0%)]	Loss: 0.508971
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 331 Train Epoch: 1 [0/201 (0%)]	Loss: 0.698215
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 468 Norm Difference for worker 331 is 0.854813
INFO:root:FL Epoch: 468 Done on worker:331
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 814
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 468 Ends   ===================
INFO:root:Epoch:468 Global Model Test Loss:0.512249602990992 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:468 Global Model Backdoor Test Loss:0.21765749529004097                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 469 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 469 Workers Selected : [1435, 459, 105, 1070, 1940, 1531, 1505, 343, 997, 710]
INFO:root:FL Epoch: 469 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.10044978 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 469 Num points on workers: [200 200 201 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 469 Training on worker :1435
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353862
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293559
INFO:root:FL Epoch: 469 Norm Difference for worker 1435 is 0.739997
INFO:root:FL Epoch: 469 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :459
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.787970
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.331876
INFO:root:FL Epoch: 469 Norm Difference for worker 459 is 0.737039
INFO:root:FL Epoch: 469 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :105
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 105 Train Epoch: 0 [0/201 (0%)]	Loss: 0.596919
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 105 Train Epoch: 1 [0/201 (0%)]	Loss: 0.450114
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 469 Norm Difference for worker 105 is 0.849941
INFO:root:FL Epoch: 469 Done on worker:105
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1070
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1070 Train Epoch: 0 [0/200 (0%)]	Loss: 0.539275
INFO:root:Worker: 1070 Train Epoch: 1 [0/200 (0%)]	Loss: 0.324556
INFO:root:FL Epoch: 469 Norm Difference for worker 1070 is 0.79821
INFO:root:FL Epoch: 469 Done on worker:1070
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1940
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1940 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508308
INFO:root:Worker: 1940 Train Epoch: 1 [0/200 (0%)]	Loss: 0.513925
INFO:root:FL Epoch: 469 Norm Difference for worker 1940 is 0.797607
INFO:root:FL Epoch: 469 Done on worker:1940
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1531
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1531 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555276
INFO:root:Worker: 1531 Train Epoch: 1 [0/200 (0%)]	Loss: 0.587370
INFO:root:FL Epoch: 469 Norm Difference for worker 1531 is 0.817998
INFO:root:FL Epoch: 469 Done on worker:1531
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :1505
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 1505 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756593
INFO:root:Worker: 1505 Train Epoch: 1 [0/200 (0%)]	Loss: 0.846695
INFO:root:FL Epoch: 469 Norm Difference for worker 1505 is 0.78946
INFO:root:FL Epoch: 469 Done on worker:1505
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :343
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425383
INFO:root:Worker: 343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.339544
INFO:root:FL Epoch: 469 Norm Difference for worker 343 is 0.803797
INFO:root:FL Epoch: 469 Done on worker:343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :997
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 997 Train Epoch: 0 [0/200 (0%)]	Loss: 0.634178
INFO:root:Worker: 997 Train Epoch: 1 [0/200 (0%)]	Loss: 0.565876
INFO:root:FL Epoch: 469 Norm Difference for worker 997 is 0.795268
INFO:root:FL Epoch: 469 Done on worker:997
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 469 Training on worker :710
INFO:root:FL Epoch: 469 Using Learning rate : 0.019591303240606914 
INFO:root:FL Epoch: 469 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.232096
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.147212
INFO:root:FL Epoch: 469 Norm Difference for worker 710 is 0.633295
INFO:root:FL Epoch: 469 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 710
INFO:root:Norm of Aggregated Model: 5154.99755859375
INFO:root:Aggregating After Defense
INFO:root:================FL round 469 Ends   ===================
INFO:root:Epoch:469 Global Model Test Loss:0.5199714022524217 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:469 Global Model Backdoor Test Loss:0.12275207166870435                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 470 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 470 Workers Selected : [1627, 737, 478, 572, 634, 1360, 1093, 1792, 1392, 1593]
INFO:root:FL Epoch: 470 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 470 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 470 Training on worker :1627
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1627 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605754
INFO:root:Worker: 1627 Train Epoch: 1 [0/200 (0%)]	Loss: 0.188982
INFO:root:FL Epoch: 470 Norm Difference for worker 1627 is 0.766959
INFO:root:FL Epoch: 470 Done on worker:1627
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :737
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 737 Train Epoch: 0 [0/200 (0%)]	Loss: 0.345443
INFO:root:Worker: 737 Train Epoch: 1 [0/200 (0%)]	Loss: 0.545752
INFO:root:FL Epoch: 470 Norm Difference for worker 737 is 0.930513
INFO:root:FL Epoch: 470 Done on worker:737
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :478
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 478 Train Epoch: 0 [0/200 (0%)]	Loss: 0.935997
INFO:root:Worker: 478 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482810
INFO:root:FL Epoch: 470 Norm Difference for worker 478 is 0.99569
INFO:root:FL Epoch: 470 Done on worker:478
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :572
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319259
INFO:root:Worker: 572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.195237
INFO:root:FL Epoch: 470 Norm Difference for worker 572 is 0.869065
INFO:root:FL Epoch: 470 Done on worker:572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :634
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 634 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630921
INFO:root:Worker: 634 Train Epoch: 1 [0/200 (0%)]	Loss: 0.372637
INFO:root:FL Epoch: 470 Norm Difference for worker 634 is 0.957737
INFO:root:FL Epoch: 470 Done on worker:634
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1360
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.313600
INFO:root:Worker: 1360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.494033
INFO:root:FL Epoch: 470 Norm Difference for worker 1360 is 1.040887
INFO:root:FL Epoch: 470 Done on worker:1360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1093
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1093 Train Epoch: 0 [0/200 (0%)]	Loss: 0.796964
INFO:root:Worker: 1093 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589092
INFO:root:FL Epoch: 470 Norm Difference for worker 1093 is 1.004007
INFO:root:FL Epoch: 470 Done on worker:1093
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1792
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1792 Train Epoch: 0 [0/200 (0%)]	Loss: 0.433795
INFO:root:Worker: 1792 Train Epoch: 1 [0/200 (0%)]	Loss: 0.773171
INFO:root:FL Epoch: 470 Norm Difference for worker 1792 is 0.991067
INFO:root:FL Epoch: 470 Done on worker:1792
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1392
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1392 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517191
INFO:root:Worker: 1392 Train Epoch: 1 [0/200 (0%)]	Loss: 0.159992
INFO:root:FL Epoch: 470 Norm Difference for worker 1392 is 0.813443
INFO:root:FL Epoch: 470 Done on worker:1392
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 470 Training on worker :1593
INFO:root:FL Epoch: 470 Using Learning rate : 0.019552120634125703 
INFO:root:FL Epoch: 470 Normal Training
INFO:root:Worker: 1593 Train Epoch: 0 [0/200 (0%)]	Loss: 0.667710
INFO:root:Worker: 1593 Train Epoch: 1 [0/200 (0%)]	Loss: 0.746162
INFO:root:FL Epoch: 470 Norm Difference for worker 1593 is 0.901047
INFO:root:FL Epoch: 470 Done on worker:1593
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1627
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 470 Ends   ===================
INFO:root:Epoch:470 Global Model Test Loss:0.5614300755893483 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:470 Global Model Backdoor Test Loss:0.1881837584078312                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 471 Begins ===================
INFO:root:FL Epoch: 471 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 471 Workers Selected : [0, 1064, 996, 1781, 1358, 1371, 264, 782, 724, 1679]
INFO:root:FL Epoch: 471 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.10044978 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 471 Num points on workers: [200 200 200 200 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 471 Training on worker :0
INFO:root:FL Epoch: 471 Using Learning rate : 0.00390260327857149 
INFO:root:FL Epoch: 471 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.202133
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.149076
INFO:root:FL Epoch: 471 Worker: 0 Backdoor Test Loss: 0.16029367285470167 Backdoor Test Accuracy: 95.83333333333333
INFO:root:FL Epoch: 471 Worker: 0 Backdoor Train Loss: 0.12912598326802255 Backdoor Train Accuracy: 96.5
INFO:root:FL Epoch: 471 Norm Difference for worker 0 is 0.113417
INFO:root:FL Epoch: 471 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1064
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1064 Train Epoch: 0 [0/200 (0%)]	Loss: 0.647612
INFO:root:Worker: 1064 Train Epoch: 1 [0/200 (0%)]	Loss: 0.723752
INFO:root:FL Epoch: 471 Norm Difference for worker 1064 is 1.018222
INFO:root:FL Epoch: 471 Done on worker:1064
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :996
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 996 Train Epoch: 0 [0/200 (0%)]	Loss: 0.286728
INFO:root:Worker: 996 Train Epoch: 1 [0/200 (0%)]	Loss: 0.321163
INFO:root:FL Epoch: 471 Norm Difference for worker 996 is 0.892812
INFO:root:FL Epoch: 471 Done on worker:996
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1781
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1781 Train Epoch: 0 [0/200 (0%)]	Loss: 1.009160
INFO:root:Worker: 1781 Train Epoch: 1 [0/200 (0%)]	Loss: 0.413179
INFO:root:FL Epoch: 471 Norm Difference for worker 1781 is 1.103589
INFO:root:FL Epoch: 471 Done on worker:1781
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1358
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1358 Train Epoch: 0 [0/200 (0%)]	Loss: 0.428318
INFO:root:Worker: 1358 Train Epoch: 1 [0/200 (0%)]	Loss: 0.249738
INFO:root:FL Epoch: 471 Norm Difference for worker 1358 is 0.96749
INFO:root:FL Epoch: 471 Done on worker:1358
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1371
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1371 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654253
INFO:root:Worker: 1371 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431838
INFO:root:FL Epoch: 471 Norm Difference for worker 1371 is 1.022359
INFO:root:FL Epoch: 471 Done on worker:1371
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :264
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 264 Train Epoch: 0 [0/201 (0%)]	Loss: 1.057561
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 264 Train Epoch: 1 [0/201 (0%)]	Loss: 0.548062
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 471 Norm Difference for worker 264 is 1.004383
INFO:root:FL Epoch: 471 Done on worker:264
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :782
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 782 Train Epoch: 0 [0/200 (0%)]	Loss: 0.574353
INFO:root:Worker: 782 Train Epoch: 1 [0/200 (0%)]	Loss: 0.716891
INFO:root:FL Epoch: 471 Norm Difference for worker 782 is 1.177065
INFO:root:FL Epoch: 471 Done on worker:782
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :724
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 724 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517701
INFO:root:Worker: 724 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655749
INFO:root:FL Epoch: 471 Norm Difference for worker 724 is 1.007569
INFO:root:FL Epoch: 471 Done on worker:724
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 471 Training on worker :1679
INFO:root:FL Epoch: 471 Using Learning rate : 0.01951301639285745 
INFO:root:FL Epoch: 471 Normal Training
INFO:root:Worker: 1679 Train Epoch: 0 [0/200 (0%)]	Loss: 1.071480
INFO:root:Worker: 1679 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431318
INFO:root:FL Epoch: 471 Norm Difference for worker 1679 is 1.037239
INFO:root:FL Epoch: 471 Done on worker:1679
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 471 Ends   ===================
INFO:root:Epoch:471 Global Model Test Loss:0.5631184683126562 and Test Accuracy:75.29411764705883 
INFO:root:Epoch:471 Global Model Backdoor Test Loss:0.16029367285470167                             and Backdoor Test Accuracy:95.83333333333333 
INFO:root:=======================================================
INFO:root:================FL round 472 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 472 Workers Selected : [385, 572, 1760, 90, 338, 953, 94, 285, 1328, 941]
INFO:root:FL Epoch: 472 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.1002994 0.1002994 0.0998004 0.1002994
 0.1002994 0.0998004 0.0998004]
INFO:root:FL Epoch: 472 Num points on workers: [200 200 200 201 201 200 201 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 472 Training on worker :385
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 385 Train Epoch: 0 [0/200 (0%)]	Loss: 0.642991
INFO:root:Worker: 385 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427308
INFO:root:FL Epoch: 472 Norm Difference for worker 385 is 0.864684
INFO:root:FL Epoch: 472 Done on worker:385
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :572
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510920
INFO:root:Worker: 572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532961
INFO:root:FL Epoch: 472 Norm Difference for worker 572 is 0.957864
INFO:root:FL Epoch: 472 Done on worker:572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1760
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.630257
INFO:root:Worker: 1760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.277276
INFO:root:FL Epoch: 472 Norm Difference for worker 1760 is 1.096478
INFO:root:FL Epoch: 472 Done on worker:1760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :90
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 90 Train Epoch: 0 [0/201 (0%)]	Loss: 0.553902
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 90 Train Epoch: 1 [0/201 (0%)]	Loss: 0.637856
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 472 Norm Difference for worker 90 is 0.99595
INFO:root:FL Epoch: 472 Done on worker:90
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :338
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 338 Train Epoch: 0 [0/201 (0%)]	Loss: 0.545561
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 338 Train Epoch: 1 [0/201 (0%)]	Loss: 0.385302
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 472 Norm Difference for worker 338 is 0.988468
INFO:root:FL Epoch: 472 Done on worker:338
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :953
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 953 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598670
INFO:root:Worker: 953 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433483
INFO:root:FL Epoch: 472 Norm Difference for worker 953 is 0.91833
INFO:root:FL Epoch: 472 Done on worker:953
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :94
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 94 Train Epoch: 0 [0/201 (0%)]	Loss: 0.403379
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 94 Train Epoch: 1 [0/201 (0%)]	Loss: 0.358479
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 472 Norm Difference for worker 94 is 1.054787
INFO:root:FL Epoch: 472 Done on worker:94
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :285
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 285 Train Epoch: 0 [0/201 (0%)]	Loss: 0.519055
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 285 Train Epoch: 1 [0/201 (0%)]	Loss: 0.351599
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 472 Norm Difference for worker 285 is 0.910732
INFO:root:FL Epoch: 472 Done on worker:285
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :1328
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 1328 Train Epoch: 0 [0/200 (0%)]	Loss: 0.795966
INFO:root:Worker: 1328 Train Epoch: 1 [0/200 (0%)]	Loss: 0.392996
INFO:root:FL Epoch: 472 Norm Difference for worker 1328 is 0.961748
INFO:root:FL Epoch: 472 Done on worker:1328
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 472 Training on worker :941
INFO:root:FL Epoch: 472 Using Learning rate : 0.019473990360071733 
INFO:root:FL Epoch: 472 Normal Training
INFO:root:Worker: 941 Train Epoch: 0 [0/200 (0%)]	Loss: 0.251340
INFO:root:Worker: 941 Train Epoch: 1 [0/200 (0%)]	Loss: 0.589648
INFO:root:FL Epoch: 472 Norm Difference for worker 941 is 0.709402
INFO:root:FL Epoch: 472 Done on worker:941
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 941
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 472 Ends   ===================
INFO:root:Epoch:472 Global Model Test Loss:0.5391724004464991 and Test Accuracy:79.11764705882354 
INFO:root:Epoch:472 Global Model Backdoor Test Loss:0.11159930316110452                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 473 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 473 Workers Selected : [718, 551, 1808, 1286, 1420, 936, 1681, 1500, 933, 982]
INFO:root:FL Epoch: 473 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 473 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 473 Training on worker :718
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.182071
INFO:root:Worker: 718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441037
INFO:root:FL Epoch: 473 Norm Difference for worker 718 is 0.971598
INFO:root:FL Epoch: 473 Done on worker:718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :551
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 551 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425821
INFO:root:Worker: 551 Train Epoch: 1 [0/200 (0%)]	Loss: 0.259598
INFO:root:FL Epoch: 473 Norm Difference for worker 551 is 0.673193
INFO:root:FL Epoch: 473 Done on worker:551
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1808
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1808 Train Epoch: 0 [0/200 (0%)]	Loss: 0.756457
INFO:root:Worker: 1808 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452739
INFO:root:FL Epoch: 473 Norm Difference for worker 1808 is 1.103044
INFO:root:FL Epoch: 473 Done on worker:1808
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1286
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1286 Train Epoch: 0 [0/200 (0%)]	Loss: 0.943779
INFO:root:Worker: 1286 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546365
INFO:root:FL Epoch: 473 Norm Difference for worker 1286 is 1.145171
INFO:root:FL Epoch: 473 Done on worker:1286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1420
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1420 Train Epoch: 0 [0/200 (0%)]	Loss: 0.885287
INFO:root:Worker: 1420 Train Epoch: 1 [0/200 (0%)]	Loss: 0.796903
INFO:root:FL Epoch: 473 Norm Difference for worker 1420 is 1.14943
INFO:root:FL Epoch: 473 Done on worker:1420
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :936
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 936 Train Epoch: 0 [0/200 (0%)]	Loss: 0.472152
INFO:root:Worker: 936 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682771
INFO:root:FL Epoch: 473 Norm Difference for worker 936 is 1.047772
INFO:root:FL Epoch: 473 Done on worker:936
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1681
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1681 Train Epoch: 0 [0/200 (0%)]	Loss: 0.434916
INFO:root:Worker: 1681 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547000
INFO:root:FL Epoch: 473 Norm Difference for worker 1681 is 0.997742
INFO:root:FL Epoch: 473 Done on worker:1681
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :1500
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 1500 Train Epoch: 0 [0/200 (0%)]	Loss: 1.037742
INFO:root:Worker: 1500 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493960
INFO:root:FL Epoch: 473 Norm Difference for worker 1500 is 1.031011
INFO:root:FL Epoch: 473 Done on worker:1500
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :933
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 933 Train Epoch: 0 [0/200 (0%)]	Loss: 0.986228
INFO:root:Worker: 933 Train Epoch: 1 [0/200 (0%)]	Loss: 0.682226
INFO:root:FL Epoch: 473 Norm Difference for worker 933 is 1.105682
INFO:root:FL Epoch: 473 Done on worker:933
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 473 Training on worker :982
INFO:root:FL Epoch: 473 Using Learning rate : 0.01943504237935159 
INFO:root:FL Epoch: 473 Normal Training
INFO:root:Worker: 982 Train Epoch: 0 [0/200 (0%)]	Loss: 0.254313
INFO:root:Worker: 982 Train Epoch: 1 [0/200 (0%)]	Loss: 0.479712
INFO:root:FL Epoch: 473 Norm Difference for worker 982 is 1.046203
INFO:root:FL Epoch: 473 Done on worker:982
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 551
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 473 Ends   ===================
INFO:root:Epoch:473 Global Model Test Loss:0.5960712888661552 and Test Accuracy:72.3529411764706 
INFO:root:Epoch:473 Global Model Backdoor Test Loss:0.1811797165622314                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 474 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 474 Workers Selected : [1342, 1579, 1101, 1265, 1832, 1639, 1227, 903, 213, 1652]
INFO:root:FL Epoch: 474 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.10044978 0.09995002]
INFO:root:FL Epoch: 474 Num points on workers: [200 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 474 Training on worker :1342
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1342 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593247
INFO:root:Worker: 1342 Train Epoch: 1 [0/200 (0%)]	Loss: 0.481656
INFO:root:FL Epoch: 474 Norm Difference for worker 1342 is 0.994826
INFO:root:FL Epoch: 474 Done on worker:1342
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1579
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417022
INFO:root:Worker: 1579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.490648
INFO:root:FL Epoch: 474 Norm Difference for worker 1579 is 1.208745
INFO:root:FL Epoch: 474 Done on worker:1579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1101
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1101 Train Epoch: 0 [0/200 (0%)]	Loss: 0.817634
INFO:root:Worker: 1101 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655662
INFO:root:FL Epoch: 474 Norm Difference for worker 1101 is 1.103303
INFO:root:FL Epoch: 474 Done on worker:1101
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1265
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1265 Train Epoch: 0 [0/200 (0%)]	Loss: 0.462365
INFO:root:Worker: 1265 Train Epoch: 1 [0/200 (0%)]	Loss: 0.441879
INFO:root:FL Epoch: 474 Norm Difference for worker 1265 is 1.105188
INFO:root:FL Epoch: 474 Done on worker:1265
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1832
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.382831
INFO:root:Worker: 1832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.519885
INFO:root:FL Epoch: 474 Norm Difference for worker 1832 is 1.206272
INFO:root:FL Epoch: 474 Done on worker:1832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1639
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1639 Train Epoch: 0 [0/200 (0%)]	Loss: 0.965654
INFO:root:Worker: 1639 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435424
INFO:root:FL Epoch: 474 Norm Difference for worker 1639 is 1.069132
INFO:root:FL Epoch: 474 Done on worker:1639
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1227
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1227 Train Epoch: 0 [0/200 (0%)]	Loss: 1.196918
INFO:root:Worker: 1227 Train Epoch: 1 [0/200 (0%)]	Loss: 0.635420
INFO:root:FL Epoch: 474 Norm Difference for worker 1227 is 1.12311
INFO:root:FL Epoch: 474 Done on worker:1227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :903
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 903 Train Epoch: 0 [0/200 (0%)]	Loss: 0.637975
INFO:root:Worker: 903 Train Epoch: 1 [0/200 (0%)]	Loss: 0.220094
INFO:root:FL Epoch: 474 Norm Difference for worker 903 is 1.125907
INFO:root:FL Epoch: 474 Done on worker:903
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :213
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.809636
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.670543
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 474 Norm Difference for worker 213 is 1.23842
INFO:root:FL Epoch: 474 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 474 Training on worker :1652
INFO:root:FL Epoch: 474 Using Learning rate : 0.019396172294592888 
INFO:root:FL Epoch: 474 Normal Training
INFO:root:Worker: 1652 Train Epoch: 0 [0/200 (0%)]	Loss: 0.639095
INFO:root:Worker: 1652 Train Epoch: 1 [0/200 (0%)]	Loss: 0.564666
INFO:root:FL Epoch: 474 Norm Difference for worker 1652 is 1.192941
INFO:root:FL Epoch: 474 Done on worker:1652
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 1342
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 474 Ends   ===================
INFO:root:Epoch:474 Global Model Test Loss:0.5149265825748444 and Test Accuracy:79.41176470588235 
INFO:root:Epoch:474 Global Model Backdoor Test Loss:0.11363386921584606                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 475 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 475 Workers Selected : [1856, 1625, 1673, 278, 1229, 718, 1577, 1561, 1212, 1801]
INFO:root:FL Epoch: 475 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.10044978 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 475 Num points on workers: [200 200 200 201 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 475 Training on worker :1856
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1856 Train Epoch: 0 [0/200 (0%)]	Loss: 0.390129
INFO:root:Worker: 1856 Train Epoch: 1 [0/200 (0%)]	Loss: 0.300060
INFO:root:FL Epoch: 475 Norm Difference for worker 1856 is 1.015199
INFO:root:FL Epoch: 475 Done on worker:1856
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1625
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1625 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671064
INFO:root:Worker: 1625 Train Epoch: 1 [0/200 (0%)]	Loss: 0.404497
INFO:root:FL Epoch: 475 Norm Difference for worker 1625 is 0.88441
INFO:root:FL Epoch: 475 Done on worker:1625
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1673
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1673 Train Epoch: 0 [0/200 (0%)]	Loss: 0.748259
INFO:root:Worker: 1673 Train Epoch: 1 [0/200 (0%)]	Loss: 0.476951
INFO:root:FL Epoch: 475 Norm Difference for worker 1673 is 1.020638
INFO:root:FL Epoch: 475 Done on worker:1673
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :278
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 278 Train Epoch: 0 [0/201 (0%)]	Loss: 0.416347
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 278 Train Epoch: 1 [0/201 (0%)]	Loss: 0.364171
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 475 Norm Difference for worker 278 is 1.089638
INFO:root:FL Epoch: 475 Done on worker:278
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1229
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1229 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554811
INFO:root:Worker: 1229 Train Epoch: 1 [0/200 (0%)]	Loss: 0.343004
INFO:root:FL Epoch: 475 Norm Difference for worker 1229 is 1.015588
INFO:root:FL Epoch: 475 Done on worker:1229
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :718
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 718 Train Epoch: 0 [0/200 (0%)]	Loss: 0.450652
INFO:root:Worker: 718 Train Epoch: 1 [0/200 (0%)]	Loss: 0.453567
INFO:root:FL Epoch: 475 Norm Difference for worker 718 is 0.895389
INFO:root:FL Epoch: 475 Done on worker:718
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1577
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1577 Train Epoch: 0 [0/200 (0%)]	Loss: 0.783148
INFO:root:Worker: 1577 Train Epoch: 1 [0/200 (0%)]	Loss: 0.581243
INFO:root:FL Epoch: 475 Norm Difference for worker 1577 is 1.044869
INFO:root:FL Epoch: 475 Done on worker:1577
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1561
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1561 Train Epoch: 0 [0/200 (0%)]	Loss: 0.930615
INFO:root:Worker: 1561 Train Epoch: 1 [0/200 (0%)]	Loss: 0.288637
INFO:root:FL Epoch: 475 Norm Difference for worker 1561 is 0.982809
INFO:root:FL Epoch: 475 Done on worker:1561
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1212
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465291
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.322353
INFO:root:FL Epoch: 475 Norm Difference for worker 1212 is 0.904188
INFO:root:FL Epoch: 475 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 475 Training on worker :1801
INFO:root:FL Epoch: 475 Using Learning rate : 0.0193573799500037 
INFO:root:FL Epoch: 475 Normal Training
INFO:root:Worker: 1801 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429852
INFO:root:Worker: 1801 Train Epoch: 1 [0/200 (0%)]	Loss: 0.591978
INFO:root:FL Epoch: 475 Norm Difference for worker 1801 is 1.019985
INFO:root:FL Epoch: 475 Done on worker:1801
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1625
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 475 Ends   ===================
INFO:root:Epoch:475 Global Model Test Loss:0.5156273894450244 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:475 Global Model Backdoor Test Loss:0.13246169686317444                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 476 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 476 Workers Selected : [585, 1417, 1081, 1937, 1571, 179, 1932, 354, 779, 1387]
INFO:root:FL Epoch: 476 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.10044978
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 476 Num points on workers: [200 200 200 200 200 201 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 476 Training on worker :585
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 585 Train Epoch: 0 [0/200 (0%)]	Loss: 0.739222
INFO:root:Worker: 585 Train Epoch: 1 [0/200 (0%)]	Loss: 0.518755
INFO:root:FL Epoch: 476 Norm Difference for worker 585 is 0.889891
INFO:root:FL Epoch: 476 Done on worker:585
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1417
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1417 Train Epoch: 0 [0/200 (0%)]	Loss: 0.373679
INFO:root:Worker: 1417 Train Epoch: 1 [0/200 (0%)]	Loss: 0.655608
INFO:root:FL Epoch: 476 Norm Difference for worker 1417 is 0.864154
INFO:root:FL Epoch: 476 Done on worker:1417
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1081
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1081 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420254
INFO:root:Worker: 1081 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571483
INFO:root:FL Epoch: 476 Norm Difference for worker 1081 is 0.993697
INFO:root:FL Epoch: 476 Done on worker:1081
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1937
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.745045
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478217
INFO:root:FL Epoch: 476 Norm Difference for worker 1937 is 0.990132
INFO:root:FL Epoch: 476 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1571
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1571 Train Epoch: 0 [0/200 (0%)]	Loss: 0.626992
INFO:root:Worker: 1571 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482006
INFO:root:FL Epoch: 476 Norm Difference for worker 1571 is 0.843571
INFO:root:FL Epoch: 476 Done on worker:1571
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :179
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 179 Train Epoch: 0 [0/201 (0%)]	Loss: 0.640935
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 179 Train Epoch: 1 [0/201 (0%)]	Loss: 0.353192
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 476 Norm Difference for worker 179 is 0.956742
INFO:root:FL Epoch: 476 Done on worker:179
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1932
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1932 Train Epoch: 0 [0/200 (0%)]	Loss: 0.925287
INFO:root:Worker: 1932 Train Epoch: 1 [0/200 (0%)]	Loss: 0.486086
INFO:root:FL Epoch: 476 Norm Difference for worker 1932 is 0.834252
INFO:root:FL Epoch: 476 Done on worker:1932
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :354
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 354 Train Epoch: 0 [0/200 (0%)]	Loss: 0.714760
INFO:root:Worker: 354 Train Epoch: 1 [0/200 (0%)]	Loss: 0.692028
INFO:root:FL Epoch: 476 Norm Difference for worker 354 is 0.871085
INFO:root:FL Epoch: 476 Done on worker:354
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :779
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 779 Train Epoch: 0 [0/200 (0%)]	Loss: 0.285532
INFO:root:Worker: 779 Train Epoch: 1 [0/200 (0%)]	Loss: 0.753045
INFO:root:FL Epoch: 476 Norm Difference for worker 779 is 0.940154
INFO:root:FL Epoch: 476 Done on worker:779
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 476 Training on worker :1387
INFO:root:FL Epoch: 476 Using Learning rate : 0.019318665190103695 
INFO:root:FL Epoch: 476 Normal Training
INFO:root:Worker: 1387 Train Epoch: 0 [0/200 (0%)]	Loss: 0.471881
INFO:root:Worker: 1387 Train Epoch: 1 [0/200 (0%)]	Loss: 0.362414
INFO:root:FL Epoch: 476 Norm Difference for worker 1387 is 0.902934
INFO:root:FL Epoch: 476 Done on worker:1387
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 1932
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 476 Ends   ===================
INFO:root:Epoch:476 Global Model Test Loss:0.4948403607396519 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:476 Global Model Backdoor Test Loss:0.190092949817578                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 477 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 477 Workers Selected : [313, 901, 573, 677, 852, 1604, 1027, 760, 213, 704]
INFO:root:FL Epoch: 477 Fraction of points on each worker in this round: [0.1003996 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.1003996 0.0999001]
INFO:root:FL Epoch: 477 Num points on workers: [201 200 200 200 200 200 200 200 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 477 Training on worker :313
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 313 Train Epoch: 0 [0/201 (0%)]	Loss: 0.517639
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 313 Train Epoch: 1 [0/201 (0%)]	Loss: 0.509996
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 477 Norm Difference for worker 313 is 0.8628
INFO:root:FL Epoch: 477 Done on worker:313
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :901
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 901 Train Epoch: 0 [0/200 (0%)]	Loss: 0.218050
INFO:root:Worker: 901 Train Epoch: 1 [0/200 (0%)]	Loss: 0.290119
INFO:root:FL Epoch: 477 Norm Difference for worker 901 is 0.734617
INFO:root:FL Epoch: 477 Done on worker:901
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :573
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 573 Train Epoch: 0 [0/200 (0%)]	Loss: 0.338646
INFO:root:Worker: 573 Train Epoch: 1 [0/200 (0%)]	Loss: 0.330548
INFO:root:FL Epoch: 477 Norm Difference for worker 573 is 0.836033
INFO:root:FL Epoch: 477 Done on worker:573
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :677
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.663298
INFO:root:Worker: 677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400518
INFO:root:FL Epoch: 477 Norm Difference for worker 677 is 0.917289
INFO:root:FL Epoch: 477 Done on worker:677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :852
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 852 Train Epoch: 0 [0/200 (0%)]	Loss: 0.554612
INFO:root:Worker: 852 Train Epoch: 1 [0/200 (0%)]	Loss: 0.755476
INFO:root:FL Epoch: 477 Norm Difference for worker 852 is 0.908751
INFO:root:FL Epoch: 477 Done on worker:852
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1604
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1604 Train Epoch: 0 [0/200 (0%)]	Loss: 0.491994
INFO:root:Worker: 1604 Train Epoch: 1 [0/200 (0%)]	Loss: 0.547176
INFO:root:FL Epoch: 477 Norm Difference for worker 1604 is 0.93201
INFO:root:FL Epoch: 477 Done on worker:1604
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :1027
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 1027 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614432
INFO:root:Worker: 1027 Train Epoch: 1 [0/200 (0%)]	Loss: 0.360783
INFO:root:FL Epoch: 477 Norm Difference for worker 1027 is 0.84829
INFO:root:FL Epoch: 477 Done on worker:1027
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :760
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 760 Train Epoch: 0 [0/200 (0%)]	Loss: 0.415594
INFO:root:Worker: 760 Train Epoch: 1 [0/200 (0%)]	Loss: 0.400621
INFO:root:FL Epoch: 477 Norm Difference for worker 760 is 0.909723
INFO:root:FL Epoch: 477 Done on worker:760
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :213
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 213 Train Epoch: 0 [0/201 (0%)]	Loss: 0.602010
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 213 Train Epoch: 1 [0/201 (0%)]	Loss: 0.566923
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 477 Norm Difference for worker 213 is 0.94022
INFO:root:FL Epoch: 477 Done on worker:213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 477 Training on worker :704
INFO:root:FL Epoch: 477 Using Learning rate : 0.01928002785972349 
INFO:root:FL Epoch: 477 Normal Training
INFO:root:Worker: 704 Train Epoch: 0 [0/200 (0%)]	Loss: 0.438443
INFO:root:Worker: 704 Train Epoch: 1 [0/200 (0%)]	Loss: 0.429693
INFO:root:FL Epoch: 477 Norm Difference for worker 704 is 0.899806
INFO:root:FL Epoch: 477 Done on worker:704
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 901
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 477 Ends   ===================
INFO:root:Epoch:477 Global Model Test Loss:0.48385567524853873 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:477 Global Model Backdoor Test Loss:0.1997821107506752                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 478 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 478 Workers Selected : [426, 1821, 1938, 1092, 1558, 1814, 736, 345, 1335, 262]
INFO:root:FL Epoch: 478 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.10044978]
INFO:root:FL Epoch: 478 Num points on workers: [200 200 200 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 478 Training on worker :426
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 426 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347989
INFO:root:Worker: 426 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438102
INFO:root:FL Epoch: 478 Norm Difference for worker 426 is 0.759381
INFO:root:FL Epoch: 478 Done on worker:426
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1821
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1821 Train Epoch: 0 [0/200 (0%)]	Loss: 0.564546
INFO:root:Worker: 1821 Train Epoch: 1 [0/200 (0%)]	Loss: 0.447935
INFO:root:FL Epoch: 478 Norm Difference for worker 1821 is 0.836071
INFO:root:FL Epoch: 478 Done on worker:1821
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1938
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1938 Train Epoch: 0 [0/200 (0%)]	Loss: 0.328435
INFO:root:Worker: 1938 Train Epoch: 1 [0/200 (0%)]	Loss: 0.415376
INFO:root:FL Epoch: 478 Norm Difference for worker 1938 is 0.877483
INFO:root:FL Epoch: 478 Done on worker:1938
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1092
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1092 Train Epoch: 0 [0/200 (0%)]	Loss: 0.641165
INFO:root:Worker: 1092 Train Epoch: 1 [0/200 (0%)]	Loss: 0.468116
INFO:root:FL Epoch: 478 Norm Difference for worker 1092 is 0.836689
INFO:root:FL Epoch: 478 Done on worker:1092
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1558
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1558 Train Epoch: 0 [0/200 (0%)]	Loss: 0.517413
INFO:root:Worker: 1558 Train Epoch: 1 [0/200 (0%)]	Loss: 0.487433
INFO:root:FL Epoch: 478 Norm Difference for worker 1558 is 0.809903
INFO:root:FL Epoch: 478 Done on worker:1558
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1814
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1814 Train Epoch: 0 [0/200 (0%)]	Loss: 0.476546
INFO:root:Worker: 1814 Train Epoch: 1 [0/200 (0%)]	Loss: 0.763512
INFO:root:FL Epoch: 478 Norm Difference for worker 1814 is 0.869643
INFO:root:FL Epoch: 478 Done on worker:1814
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :736
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 736 Train Epoch: 0 [0/200 (0%)]	Loss: 0.512263
INFO:root:Worker: 736 Train Epoch: 1 [0/200 (0%)]	Loss: 0.546937
INFO:root:FL Epoch: 478 Norm Difference for worker 736 is 0.813733
INFO:root:FL Epoch: 478 Done on worker:736
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :345
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 345 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559974
INFO:root:Worker: 345 Train Epoch: 1 [0/200 (0%)]	Loss: 0.489266
INFO:root:FL Epoch: 478 Norm Difference for worker 345 is 0.803565
INFO:root:FL Epoch: 478 Done on worker:345
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :1335
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 1335 Train Epoch: 0 [0/200 (0%)]	Loss: 0.801984
INFO:root:Worker: 1335 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454156
INFO:root:FL Epoch: 478 Norm Difference for worker 1335 is 0.799399
INFO:root:FL Epoch: 478 Done on worker:1335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 478 Training on worker :262
INFO:root:FL Epoch: 478 Using Learning rate : 0.019241467804004042 
INFO:root:FL Epoch: 478 Normal Training
INFO:root:Worker: 262 Train Epoch: 0 [0/201 (0%)]	Loss: 0.216114
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 262 Train Epoch: 1 [0/201 (0%)]	Loss: 0.507870
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 478 Norm Difference for worker 262 is 0.770072
INFO:root:FL Epoch: 478 Done on worker:262
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 426
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 478 Ends   ===================
INFO:root:Epoch:478 Global Model Test Loss:0.4830086441601024 and Test Accuracy:78.82352941176471 
INFO:root:Epoch:478 Global Model Backdoor Test Loss:0.1604581711192926                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 479 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 479 Workers Selected : [694, 360, 176, 552, 556, 98, 519, 1428, 1788, 9]
INFO:root:FL Epoch: 479 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.09985022 0.09985022 0.10034948
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 479 Num points on workers: [200 200 201 200 200 201 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 479 Training on worker :694
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 694 Train Epoch: 0 [0/200 (0%)]	Loss: 0.440557
INFO:root:Worker: 694 Train Epoch: 1 [0/200 (0%)]	Loss: 0.353468
INFO:root:FL Epoch: 479 Norm Difference for worker 694 is 0.753721
INFO:root:FL Epoch: 479 Done on worker:694
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :360
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 360 Train Epoch: 0 [0/200 (0%)]	Loss: 0.370432
INFO:root:Worker: 360 Train Epoch: 1 [0/200 (0%)]	Loss: 0.247737
INFO:root:FL Epoch: 479 Norm Difference for worker 360 is 0.814776
INFO:root:FL Epoch: 479 Done on worker:360
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :176
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 176 Train Epoch: 0 [0/201 (0%)]	Loss: 0.495664
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 176 Train Epoch: 1 [0/201 (0%)]	Loss: 0.754740
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 479 Norm Difference for worker 176 is 0.843498
INFO:root:FL Epoch: 479 Done on worker:176
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :552
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.368288
INFO:root:Worker: 552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407595
INFO:root:FL Epoch: 479 Norm Difference for worker 552 is 0.880363
INFO:root:FL Epoch: 479 Done on worker:552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :556
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 556 Train Epoch: 0 [0/200 (0%)]	Loss: 0.550752
INFO:root:Worker: 556 Train Epoch: 1 [0/200 (0%)]	Loss: 0.365430
INFO:root:FL Epoch: 479 Norm Difference for worker 556 is 0.846441
INFO:root:FL Epoch: 479 Done on worker:556
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :98
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 98 Train Epoch: 0 [0/201 (0%)]	Loss: 0.441652
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 98 Train Epoch: 1 [0/201 (0%)]	Loss: 0.495116
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 479 Norm Difference for worker 98 is 0.856554
INFO:root:FL Epoch: 479 Done on worker:98
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :519
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 519 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348581
INFO:root:Worker: 519 Train Epoch: 1 [0/200 (0%)]	Loss: 0.524190
INFO:root:FL Epoch: 479 Norm Difference for worker 519 is 0.811853
INFO:root:FL Epoch: 479 Done on worker:519
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :1428
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1428 Train Epoch: 0 [0/200 (0%)]	Loss: 0.533416
INFO:root:Worker: 1428 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440669
INFO:root:FL Epoch: 479 Norm Difference for worker 1428 is 0.825442
INFO:root:FL Epoch: 479 Done on worker:1428
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :1788
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 1788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549450
INFO:root:Worker: 1788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.345546
INFO:root:FL Epoch: 479 Norm Difference for worker 1788 is 0.84881
INFO:root:FL Epoch: 479 Done on worker:1788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 479 Training on worker :9
INFO:root:FL Epoch: 479 Using Learning rate : 0.01920298486839603 
INFO:root:FL Epoch: 479 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.459930
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.304390
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 479 Norm Difference for worker 9 is 0.752253
INFO:root:FL Epoch: 479 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 694
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 479 Ends   ===================
INFO:root:Epoch:479 Global Model Test Loss:0.4850933604380664 and Test Accuracy:79.70588235294117 
INFO:root:Epoch:479 Global Model Backdoor Test Loss:0.23630288491646448                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 480 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 480 Workers Selected : [933, 345, 1128, 1315, 151, 1598, 83, 1389, 46, 249]
INFO:root:FL Epoch: 480 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.0998004 0.1002994
 0.0998004 0.1002994 0.1002994]
INFO:root:FL Epoch: 480 Num points on workers: [200 200 200 200 201 200 201 200 201 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 480 Training on worker :933
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 933 Train Epoch: 0 [0/200 (0%)]	Loss: 0.949922
INFO:root:Worker: 933 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361735
INFO:root:FL Epoch: 480 Norm Difference for worker 933 is 0.711671
INFO:root:FL Epoch: 480 Done on worker:933
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :345
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 345 Train Epoch: 0 [0/200 (0%)]	Loss: 0.498086
INFO:root:Worker: 345 Train Epoch: 1 [0/200 (0%)]	Loss: 0.676770
INFO:root:FL Epoch: 480 Norm Difference for worker 345 is 0.71015
INFO:root:FL Epoch: 480 Done on worker:345
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1128
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1128 Train Epoch: 0 [0/200 (0%)]	Loss: 0.425019
INFO:root:Worker: 1128 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408549
INFO:root:FL Epoch: 480 Norm Difference for worker 1128 is 0.769171
INFO:root:FL Epoch: 480 Done on worker:1128
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1315
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1315 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711040
INFO:root:Worker: 1315 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307292
INFO:root:FL Epoch: 480 Norm Difference for worker 1315 is 0.706403
INFO:root:FL Epoch: 480 Done on worker:1315
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :151
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 151 Train Epoch: 0 [0/201 (0%)]	Loss: 0.642313
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 151 Train Epoch: 1 [0/201 (0%)]	Loss: 0.420466
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 480 Norm Difference for worker 151 is 0.76717
INFO:root:FL Epoch: 480 Done on worker:151
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1598
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1598 Train Epoch: 0 [0/200 (0%)]	Loss: 0.429079
INFO:root:Worker: 1598 Train Epoch: 1 [0/200 (0%)]	Loss: 0.593476
INFO:root:FL Epoch: 480 Norm Difference for worker 1598 is 0.712115
INFO:root:FL Epoch: 480 Done on worker:1598
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :83
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 83 Train Epoch: 0 [0/201 (0%)]	Loss: 0.402151
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 83 Train Epoch: 1 [0/201 (0%)]	Loss: 0.564276
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 480 Norm Difference for worker 83 is 0.778739
INFO:root:FL Epoch: 480 Done on worker:83
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :1389
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 1389 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460217
INFO:root:Worker: 1389 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532446
INFO:root:FL Epoch: 480 Norm Difference for worker 1389 is 0.757454
INFO:root:FL Epoch: 480 Done on worker:1389
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :46
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.408044
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.243717
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 480 Norm Difference for worker 46 is 0.711913
INFO:root:FL Epoch: 480 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 480 Training on worker :249
INFO:root:FL Epoch: 480 Using Learning rate : 0.01916457889865924 
INFO:root:FL Epoch: 480 Normal Training
INFO:root:Worker: 249 Train Epoch: 0 [0/201 (0%)]	Loss: 0.355508
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 249 Train Epoch: 1 [0/201 (0%)]	Loss: 0.561053
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 480 Norm Difference for worker 249 is 0.672314
INFO:root:FL Epoch: 480 Done on worker:249
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 9, which is global user: 249
INFO:root:Norm of Aggregated Model: 5154.998046875
INFO:root:Aggregating After Defense
INFO:root:================FL round 480 Ends   ===================
INFO:root:Epoch:480 Global Model Test Loss:0.4892573461813085 and Test Accuracy:78.23529411764706 
INFO:root:Epoch:480 Global Model Backdoor Test Loss:0.21753273904323578                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 481 Begins ===================
INFO:root:FL Epoch: 481 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 481 Workers Selected : [0, 1185, 397, 494, 155, 710, 1653, 823, 685, 1943]
INFO:root:FL Epoch: 481 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 481 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 481 Training on worker :0
INFO:root:FL Epoch: 481 Using Learning rate : 0.003825249948172384 
INFO:root:FL Epoch: 481 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.201479
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.323203
INFO:root:FL Epoch: 481 Worker: 0 Backdoor Test Loss: 0.19343770667910576 Backdoor Test Accuracy: 92.5
INFO:root:FL Epoch: 481 Worker: 0 Backdoor Train Loss: 0.16283830851316453 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 481 Norm Difference for worker 0 is 0.119517
INFO:root:FL Epoch: 481 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :1185
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 1185 Train Epoch: 0 [0/200 (0%)]	Loss: 0.555884
INFO:root:Worker: 1185 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427582
INFO:root:FL Epoch: 481 Norm Difference for worker 1185 is 0.792356
INFO:root:FL Epoch: 481 Done on worker:1185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :397
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 397 Train Epoch: 0 [0/200 (0%)]	Loss: 0.596932
INFO:root:Worker: 397 Train Epoch: 1 [0/200 (0%)]	Loss: 0.503054
INFO:root:FL Epoch: 481 Norm Difference for worker 397 is 0.834923
INFO:root:FL Epoch: 481 Done on worker:397
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :494
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 494 Train Epoch: 0 [0/200 (0%)]	Loss: 0.482975
INFO:root:Worker: 494 Train Epoch: 1 [0/200 (0%)]	Loss: 0.307669
INFO:root:FL Epoch: 481 Norm Difference for worker 494 is 0.741812
INFO:root:FL Epoch: 481 Done on worker:494
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :155
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 155 Train Epoch: 0 [0/201 (0%)]	Loss: 0.781731
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 155 Train Epoch: 1 [0/201 (0%)]	Loss: 0.286502
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 481 Norm Difference for worker 155 is 0.831409
INFO:root:FL Epoch: 481 Done on worker:155
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :710
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.235759
INFO:root:Worker: 710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.240392
INFO:root:FL Epoch: 481 Norm Difference for worker 710 is 0.572337
INFO:root:FL Epoch: 481 Done on worker:710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :1653
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 1653 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423680
INFO:root:Worker: 1653 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507606
INFO:root:FL Epoch: 481 Norm Difference for worker 1653 is 0.783795
INFO:root:FL Epoch: 481 Done on worker:1653
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :823
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.616857
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.433733
INFO:root:FL Epoch: 481 Norm Difference for worker 823 is 0.741895
INFO:root:FL Epoch: 481 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :685
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 685 Train Epoch: 0 [0/200 (0%)]	Loss: 0.460414
INFO:root:Worker: 685 Train Epoch: 1 [0/200 (0%)]	Loss: 0.570623
INFO:root:FL Epoch: 481 Norm Difference for worker 685 is 0.76415
INFO:root:FL Epoch: 481 Done on worker:685
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 481 Training on worker :1943
INFO:root:FL Epoch: 481 Using Learning rate : 0.019126249740861922 
INFO:root:FL Epoch: 481 Normal Training
INFO:root:Worker: 1943 Train Epoch: 0 [0/200 (0%)]	Loss: 0.768758
INFO:root:Worker: 1943 Train Epoch: 1 [0/200 (0%)]	Loss: 0.407318
INFO:root:FL Epoch: 481 Norm Difference for worker 1943 is 0.787932
INFO:root:FL Epoch: 481 Done on worker:1943
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 481 Ends   ===================
INFO:root:Epoch:481 Global Model Test Loss:0.4938572434818043 and Test Accuracy:78.52941176470588 
INFO:root:Epoch:481 Global Model Backdoor Test Loss:0.19343770667910576                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 482 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 482 Workers Selected : [1010, 1065, 391, 811, 226, 346, 1935, 1319, 1332, 382]
INFO:root:FL Epoch: 482 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 482 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 482 Training on worker :1010
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1010 Train Epoch: 0 [0/200 (0%)]	Loss: 0.436201
INFO:root:Worker: 1010 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506870
INFO:root:FL Epoch: 482 Norm Difference for worker 1010 is 0.816656
INFO:root:FL Epoch: 482 Done on worker:1010
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1065
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1065 Train Epoch: 0 [0/200 (0%)]	Loss: 0.708876
INFO:root:Worker: 1065 Train Epoch: 1 [0/200 (0%)]	Loss: 0.554388
INFO:root:FL Epoch: 482 Norm Difference for worker 1065 is 0.820947
INFO:root:FL Epoch: 482 Done on worker:1065
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :391
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 391 Train Epoch: 0 [0/200 (0%)]	Loss: 0.920199
INFO:root:Worker: 391 Train Epoch: 1 [0/200 (0%)]	Loss: 0.787906
INFO:root:FL Epoch: 482 Norm Difference for worker 391 is 0.881895
INFO:root:FL Epoch: 482 Done on worker:391
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :811
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 811 Train Epoch: 0 [0/200 (0%)]	Loss: 0.302170
INFO:root:Worker: 811 Train Epoch: 1 [0/200 (0%)]	Loss: 0.467557
INFO:root:FL Epoch: 482 Norm Difference for worker 811 is 0.871699
INFO:root:FL Epoch: 482 Done on worker:811
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :226
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 226 Train Epoch: 0 [0/201 (0%)]	Loss: 0.726640
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 226 Train Epoch: 1 [0/201 (0%)]	Loss: 0.346575
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 482 Norm Difference for worker 226 is 0.867314
INFO:root:FL Epoch: 482 Done on worker:226
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :346
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 346 Train Epoch: 0 [0/200 (0%)]	Loss: 0.619254
INFO:root:Worker: 346 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338266
INFO:root:FL Epoch: 482 Norm Difference for worker 346 is 0.829486
INFO:root:FL Epoch: 482 Done on worker:346
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1935
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.447030
INFO:root:Worker: 1935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.254016
INFO:root:FL Epoch: 482 Norm Difference for worker 1935 is 0.818718
INFO:root:FL Epoch: 482 Done on worker:1935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1319
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1319 Train Epoch: 0 [0/200 (0%)]	Loss: 0.375580
INFO:root:Worker: 1319 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485097
INFO:root:FL Epoch: 482 Norm Difference for worker 1319 is 0.86895
INFO:root:FL Epoch: 482 Done on worker:1319
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :1332
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 1332 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560967
INFO:root:Worker: 1332 Train Epoch: 1 [0/200 (0%)]	Loss: 0.536206
INFO:root:FL Epoch: 482 Norm Difference for worker 1332 is 0.83253
INFO:root:FL Epoch: 482 Done on worker:1332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 482 Training on worker :382
INFO:root:FL Epoch: 482 Using Learning rate : 0.0190879972413802 
INFO:root:FL Epoch: 482 Normal Training
INFO:root:Worker: 382 Train Epoch: 0 [0/200 (0%)]	Loss: 0.594621
INFO:root:Worker: 382 Train Epoch: 1 [0/200 (0%)]	Loss: 0.634521
INFO:root:FL Epoch: 482 Norm Difference for worker 382 is 0.815862
INFO:root:FL Epoch: 482 Done on worker:382
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 1065
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 482 Ends   ===================
INFO:root:Epoch:482 Global Model Test Loss:0.5018054492333356 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:482 Global Model Backdoor Test Loss:0.20354309678077698                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 483 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 483 Workers Selected : [452, 484, 633, 1427, 23, 241, 9, 1768, 1185, 163]
INFO:root:FL Epoch: 483 Fraction of points on each worker in this round: [0.0998004 0.0998004 0.0998004 0.0998004 0.1002994 0.1002994 0.1002994
 0.0998004 0.0998004 0.1002994]
INFO:root:FL Epoch: 483 Num points on workers: [200 200 200 200 201 201 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 483 Training on worker :452
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 452 Train Epoch: 0 [0/200 (0%)]	Loss: 0.568848
INFO:root:Worker: 452 Train Epoch: 1 [0/200 (0%)]	Loss: 0.459997
INFO:root:FL Epoch: 483 Norm Difference for worker 452 is 0.70232
INFO:root:FL Epoch: 483 Done on worker:452
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :484
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 484 Train Epoch: 0 [0/200 (0%)]	Loss: 0.423808
INFO:root:Worker: 484 Train Epoch: 1 [0/200 (0%)]	Loss: 0.344715
INFO:root:FL Epoch: 483 Norm Difference for worker 484 is 0.758302
INFO:root:FL Epoch: 483 Done on worker:484
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :633
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478027
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383794
INFO:root:FL Epoch: 483 Norm Difference for worker 633 is 0.703683
INFO:root:FL Epoch: 483 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1427
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1427 Train Epoch: 0 [0/200 (0%)]	Loss: 0.715905
INFO:root:Worker: 1427 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482832
INFO:root:FL Epoch: 483 Norm Difference for worker 1427 is 0.747403
INFO:root:FL Epoch: 483 Done on worker:1427
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :23
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 23 Train Epoch: 0 [0/201 (0%)]	Loss: 0.482715
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 23 Train Epoch: 1 [0/201 (0%)]	Loss: 0.457651
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 483 Norm Difference for worker 23 is 0.79187
INFO:root:FL Epoch: 483 Done on worker:23
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :241
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 241 Train Epoch: 0 [0/201 (0%)]	Loss: 0.685473
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 241 Train Epoch: 1 [0/201 (0%)]	Loss: 0.566641
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 483 Norm Difference for worker 241 is 0.759919
INFO:root:FL Epoch: 483 Done on worker:241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :9
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 9 Train Epoch: 0 [0/201 (0%)]	Loss: 0.594614
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 9 Train Epoch: 1 [0/201 (0%)]	Loss: 0.435785
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 483 Norm Difference for worker 9 is 0.730503
INFO:root:FL Epoch: 483 Done on worker:9
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1768
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1768 Train Epoch: 0 [0/200 (0%)]	Loss: 0.346983
INFO:root:Worker: 1768 Train Epoch: 1 [0/200 (0%)]	Loss: 0.397633
INFO:root:FL Epoch: 483 Norm Difference for worker 1768 is 0.729995
INFO:root:FL Epoch: 483 Done on worker:1768
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :1185
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 1185 Train Epoch: 0 [0/200 (0%)]	Loss: 0.845437
INFO:root:Worker: 1185 Train Epoch: 1 [0/200 (0%)]	Loss: 0.475325
INFO:root:FL Epoch: 483 Norm Difference for worker 1185 is 0.755692
INFO:root:FL Epoch: 483 Done on worker:1185
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 483 Training on worker :163
INFO:root:FL Epoch: 483 Using Learning rate : 0.019049821246897438 
INFO:root:FL Epoch: 483 Normal Training
INFO:root:Worker: 163 Train Epoch: 0 [0/201 (0%)]	Loss: 0.565661
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 163 Train Epoch: 1 [0/201 (0%)]	Loss: 0.420107
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 483 Norm Difference for worker 163 is 0.728056
INFO:root:FL Epoch: 483 Done on worker:163
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 633
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 483 Ends   ===================
INFO:root:Epoch:483 Global Model Test Loss:0.5077737008824068 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:483 Global Model Backdoor Test Loss:0.23982989291350046                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 484 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 484 Workers Selected : [823, 802, 1074, 1367, 729, 215, 295, 440, 1212, 1828]
INFO:root:FL Epoch: 484 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.0999001 0.0999001 0.1003996 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 484 Num points on workers: [200 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 484 Training on worker :823
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 823 Train Epoch: 0 [0/200 (0%)]	Loss: 0.558592
INFO:root:Worker: 823 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522284
INFO:root:FL Epoch: 484 Norm Difference for worker 823 is 0.736226
INFO:root:FL Epoch: 484 Done on worker:823
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :802
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 802 Train Epoch: 0 [0/200 (0%)]	Loss: 0.707516
INFO:root:Worker: 802 Train Epoch: 1 [0/200 (0%)]	Loss: 0.444499
INFO:root:FL Epoch: 484 Norm Difference for worker 802 is 0.703146
INFO:root:FL Epoch: 484 Done on worker:802
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1074
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1074 Train Epoch: 0 [0/200 (0%)]	Loss: 0.584851
INFO:root:Worker: 1074 Train Epoch: 1 [0/200 (0%)]	Loss: 0.653202
INFO:root:FL Epoch: 484 Norm Difference for worker 1074 is 0.775505
INFO:root:FL Epoch: 484 Done on worker:1074
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1367
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1367 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577230
INFO:root:Worker: 1367 Train Epoch: 1 [0/200 (0%)]	Loss: 0.463020
INFO:root:FL Epoch: 484 Norm Difference for worker 1367 is 0.798737
INFO:root:FL Epoch: 484 Done on worker:1367
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :729
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 729 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587359
INFO:root:Worker: 729 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541509
INFO:root:FL Epoch: 484 Norm Difference for worker 729 is 0.711534
INFO:root:FL Epoch: 484 Done on worker:729
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :215
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 215 Train Epoch: 0 [0/201 (0%)]	Loss: 0.554839
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 215 Train Epoch: 1 [0/201 (0%)]	Loss: 0.487363
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 484 Norm Difference for worker 215 is 0.753577
INFO:root:FL Epoch: 484 Done on worker:215
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :295
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 295 Train Epoch: 0 [0/201 (0%)]	Loss: 0.568956
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 295 Train Epoch: 1 [0/201 (0%)]	Loss: 0.373913
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 484 Norm Difference for worker 295 is 0.668341
INFO:root:FL Epoch: 484 Done on worker:295
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :440
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 440 Train Epoch: 0 [0/200 (0%)]	Loss: 0.598353
INFO:root:Worker: 440 Train Epoch: 1 [0/200 (0%)]	Loss: 0.402958
INFO:root:FL Epoch: 484 Norm Difference for worker 440 is 0.735455
INFO:root:FL Epoch: 484 Done on worker:440
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1212
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1212 Train Epoch: 0 [0/200 (0%)]	Loss: 0.355492
INFO:root:Worker: 1212 Train Epoch: 1 [0/200 (0%)]	Loss: 0.478831
INFO:root:FL Epoch: 484 Norm Difference for worker 1212 is 0.690393
INFO:root:FL Epoch: 484 Done on worker:1212
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 484 Training on worker :1828
INFO:root:FL Epoch: 484 Using Learning rate : 0.019011721604403644 
INFO:root:FL Epoch: 484 Normal Training
INFO:root:Worker: 1828 Train Epoch: 0 [0/200 (0%)]	Loss: 0.503101
INFO:root:Worker: 1828 Train Epoch: 1 [0/200 (0%)]	Loss: 0.651076
INFO:root:FL Epoch: 484 Norm Difference for worker 1828 is 0.740945
INFO:root:FL Epoch: 484 Done on worker:1828
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 295
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 484 Ends   ===================
INFO:root:Epoch:484 Global Model Test Loss:0.5138880049481112 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:484 Global Model Backdoor Test Loss:0.251307154695193                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 485 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 485 Workers Selected : [1119, 667, 1860, 735, 48, 410, 1735, 1599, 1775, 1651]
INFO:root:FL Epoch: 485 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.10044978 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 485 Num points on workers: [200 200 200 200 201 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 485 Training on worker :1119
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1119 Train Epoch: 0 [0/200 (0%)]	Loss: 0.694292
INFO:root:Worker: 1119 Train Epoch: 1 [0/200 (0%)]	Loss: 0.264885
INFO:root:FL Epoch: 485 Norm Difference for worker 1119 is 0.67242
INFO:root:FL Epoch: 485 Done on worker:1119
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :667
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 667 Train Epoch: 0 [0/200 (0%)]	Loss: 0.587414
INFO:root:Worker: 667 Train Epoch: 1 [0/200 (0%)]	Loss: 0.297747
INFO:root:FL Epoch: 485 Norm Difference for worker 667 is 0.631132
INFO:root:FL Epoch: 485 Done on worker:667
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :1860
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1860 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435748
INFO:root:Worker: 1860 Train Epoch: 1 [0/200 (0%)]	Loss: 0.520542
INFO:root:FL Epoch: 485 Norm Difference for worker 1860 is 0.692642
INFO:root:FL Epoch: 485 Done on worker:1860
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :735
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 735 Train Epoch: 0 [0/200 (0%)]	Loss: 0.561599
INFO:root:Worker: 735 Train Epoch: 1 [0/200 (0%)]	Loss: 0.640128
INFO:root:FL Epoch: 485 Norm Difference for worker 735 is 0.764825
INFO:root:FL Epoch: 485 Done on worker:735
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :48
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 48 Train Epoch: 0 [0/201 (0%)]	Loss: 0.772846
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 48 Train Epoch: 1 [0/201 (0%)]	Loss: 0.439024
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 485 Norm Difference for worker 48 is 0.670956
INFO:root:FL Epoch: 485 Done on worker:48
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :410
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 410 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342779
INFO:root:Worker: 410 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454255
INFO:root:FL Epoch: 485 Norm Difference for worker 410 is 0.726903
INFO:root:FL Epoch: 485 Done on worker:410
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :1735
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1735 Train Epoch: 0 [0/200 (0%)]	Loss: 0.563772
INFO:root:Worker: 1735 Train Epoch: 1 [0/200 (0%)]	Loss: 0.504632
INFO:root:FL Epoch: 485 Norm Difference for worker 1735 is 0.669275
INFO:root:FL Epoch: 485 Done on worker:1735
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :1599
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1599 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508662
INFO:root:Worker: 1599 Train Epoch: 1 [0/200 (0%)]	Loss: 0.299684
INFO:root:FL Epoch: 485 Norm Difference for worker 1599 is 0.694638
INFO:root:FL Epoch: 485 Done on worker:1599
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :1775
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1775 Train Epoch: 0 [0/200 (0%)]	Loss: 0.556303
INFO:root:Worker: 1775 Train Epoch: 1 [0/200 (0%)]	Loss: 0.442370
INFO:root:FL Epoch: 485 Norm Difference for worker 1775 is 0.746912
INFO:root:FL Epoch: 485 Done on worker:1775
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 485 Training on worker :1651
INFO:root:FL Epoch: 485 Using Learning rate : 0.018973698161194832 
INFO:root:FL Epoch: 485 Normal Training
INFO:root:Worker: 1651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470549
INFO:root:Worker: 1651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.346086
INFO:root:FL Epoch: 485 Norm Difference for worker 1651 is 0.671527
INFO:root:FL Epoch: 485 Done on worker:1651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 667
INFO:root:Norm of Aggregated Model: 5154.9990234375
INFO:root:Aggregating After Defense
INFO:root:================FL round 485 Ends   ===================
INFO:root:Epoch:485 Global Model Test Loss:0.5121503910597633 and Test Accuracy:77.3529411764706 
INFO:root:Epoch:485 Global Model Backdoor Test Loss:0.1655671956638495                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 486 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 486 Workers Selected : [1321, 1579, 584, 205, 968, 1677, 183, 347, 1536, 1369]
INFO:root:FL Epoch: 486 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.1003996
 0.0999001 0.0999001 0.0999001]
INFO:root:FL Epoch: 486 Num points on workers: [200 200 200 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 486 Training on worker :1321
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1321 Train Epoch: 0 [0/200 (0%)]	Loss: 0.306529
INFO:root:Worker: 1321 Train Epoch: 1 [0/200 (0%)]	Loss: 0.435738
INFO:root:FL Epoch: 486 Norm Difference for worker 1321 is 0.805254
INFO:root:FL Epoch: 486 Done on worker:1321
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1579
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1579 Train Epoch: 0 [0/200 (0%)]	Loss: 0.903684
INFO:root:Worker: 1579 Train Epoch: 1 [0/200 (0%)]	Loss: 0.526673
INFO:root:FL Epoch: 486 Norm Difference for worker 1579 is 0.838168
INFO:root:FL Epoch: 486 Done on worker:1579
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :584
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.834085
INFO:root:Worker: 584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.458941
INFO:root:FL Epoch: 486 Norm Difference for worker 584 is 0.783525
INFO:root:FL Epoch: 486 Done on worker:584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :205
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 205 Train Epoch: 0 [0/201 (0%)]	Loss: 0.416509
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 205 Train Epoch: 1 [0/201 (0%)]	Loss: 0.377038
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 486 Norm Difference for worker 205 is 0.772233
INFO:root:FL Epoch: 486 Done on worker:205
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :968
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 968 Train Epoch: 0 [0/200 (0%)]	Loss: 0.547783
INFO:root:Worker: 968 Train Epoch: 1 [0/200 (0%)]	Loss: 0.405706
INFO:root:FL Epoch: 486 Norm Difference for worker 968 is 0.846272
INFO:root:FL Epoch: 486 Done on worker:968
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1677
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1677 Train Epoch: 0 [0/200 (0%)]	Loss: 0.521484
INFO:root:Worker: 1677 Train Epoch: 1 [0/200 (0%)]	Loss: 0.580468
INFO:root:FL Epoch: 486 Norm Difference for worker 1677 is 0.751522
INFO:root:FL Epoch: 486 Done on worker:1677
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :183
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 183 Train Epoch: 0 [0/201 (0%)]	Loss: 0.781491
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 183 Train Epoch: 1 [0/201 (0%)]	Loss: 0.430329
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 486 Norm Difference for worker 183 is 0.870888
INFO:root:FL Epoch: 486 Done on worker:183
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :347
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 347 Train Epoch: 0 [0/200 (0%)]	Loss: 0.494713
INFO:root:Worker: 347 Train Epoch: 1 [0/200 (0%)]	Loss: 0.531299
INFO:root:FL Epoch: 486 Norm Difference for worker 347 is 0.819508
INFO:root:FL Epoch: 486 Done on worker:347
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1536
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.464346
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.522322
INFO:root:FL Epoch: 486 Norm Difference for worker 1536 is 0.738789
INFO:root:FL Epoch: 486 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 486 Training on worker :1369
INFO:root:FL Epoch: 486 Using Learning rate : 0.018935750764872444 
INFO:root:FL Epoch: 486 Normal Training
INFO:root:Worker: 1369 Train Epoch: 0 [0/200 (0%)]	Loss: 0.978258
INFO:root:Worker: 1369 Train Epoch: 1 [0/200 (0%)]	Loss: 0.691062
INFO:root:FL Epoch: 486 Norm Difference for worker 1369 is 0.832522
INFO:root:FL Epoch: 486 Done on worker:1369
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1677
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 486 Ends   ===================
INFO:root:Epoch:486 Global Model Test Loss:0.5125718923176036 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:486 Global Model Backdoor Test Loss:0.21604805688063303                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 487 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 487 Workers Selected : [54, 1436, 796, 798, 424, 994, 1614, 1196, 1476, 916]
INFO:root:FL Epoch: 487 Fraction of points on each worker in this round: [0.10044978 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 487 Num points on workers: [201 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 487 Training on worker :54
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 54 Train Epoch: 0 [0/201 (0%)]	Loss: 0.264100
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 54 Train Epoch: 1 [0/201 (0%)]	Loss: 0.385566
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 487 Norm Difference for worker 54 is 0.705189
INFO:root:FL Epoch: 487 Done on worker:54
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1436
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1436 Train Epoch: 0 [0/200 (0%)]	Loss: 0.347445
INFO:root:Worker: 1436 Train Epoch: 1 [0/200 (0%)]	Loss: 0.282260
INFO:root:FL Epoch: 487 Norm Difference for worker 1436 is 0.695779
INFO:root:FL Epoch: 487 Done on worker:1436
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :796
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 796 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621424
INFO:root:Worker: 796 Train Epoch: 1 [0/200 (0%)]	Loss: 0.671052
INFO:root:FL Epoch: 487 Norm Difference for worker 796 is 0.710525
INFO:root:FL Epoch: 487 Done on worker:796
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :798
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 798 Train Epoch: 0 [0/200 (0%)]	Loss: 0.343404
INFO:root:Worker: 798 Train Epoch: 1 [0/200 (0%)]	Loss: 0.386647
INFO:root:FL Epoch: 487 Norm Difference for worker 798 is 0.687684
INFO:root:FL Epoch: 487 Done on worker:798
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :424
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 424 Train Epoch: 0 [0/200 (0%)]	Loss: 0.590928
INFO:root:Worker: 424 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408264
INFO:root:FL Epoch: 487 Norm Difference for worker 424 is 0.597321
INFO:root:FL Epoch: 487 Done on worker:424
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :994
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 994 Train Epoch: 0 [0/200 (0%)]	Loss: 0.654994
INFO:root:Worker: 994 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350091
INFO:root:FL Epoch: 487 Norm Difference for worker 994 is 0.697542
INFO:root:FL Epoch: 487 Done on worker:994
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1614
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1614 Train Epoch: 0 [0/200 (0%)]	Loss: 0.851610
INFO:root:Worker: 1614 Train Epoch: 1 [0/200 (0%)]	Loss: 0.575939
INFO:root:FL Epoch: 487 Norm Difference for worker 1614 is 0.947731
INFO:root:FL Epoch: 487 Done on worker:1614
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1196
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1196 Train Epoch: 0 [0/200 (0%)]	Loss: 0.523445
INFO:root:Worker: 1196 Train Epoch: 1 [0/200 (0%)]	Loss: 0.471692
INFO:root:FL Epoch: 487 Norm Difference for worker 1196 is 0.705426
INFO:root:FL Epoch: 487 Done on worker:1196
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :1476
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 1476 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508861
INFO:root:Worker: 1476 Train Epoch: 1 [0/200 (0%)]	Loss: 0.342476
INFO:root:FL Epoch: 487 Norm Difference for worker 1476 is 0.693108
INFO:root:FL Epoch: 487 Done on worker:1476
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 487 Training on worker :916
INFO:root:FL Epoch: 487 Using Learning rate : 0.0188978792633427 
INFO:root:FL Epoch: 487 Normal Training
INFO:root:Worker: 916 Train Epoch: 0 [0/200 (0%)]	Loss: 0.513941
INFO:root:Worker: 916 Train Epoch: 1 [0/200 (0%)]	Loss: 0.600942
INFO:root:FL Epoch: 487 Norm Difference for worker 916 is 0.740742
INFO:root:FL Epoch: 487 Done on worker:916
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 424
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 487 Ends   ===================
INFO:root:Epoch:487 Global Model Test Loss:0.516563694266712 and Test Accuracy:76.47058823529412 
INFO:root:Epoch:487 Global Model Backdoor Test Loss:0.20648680130640665                             and Backdoor Test Accuracy:95.0 
INFO:root:=======================================================
INFO:root:================FL round 488 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 488 Workers Selected : [751, 1857, 984, 1603, 1511, 1895, 1788, 1671, 960, 948]
INFO:root:FL Epoch: 488 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 488 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 488 Training on worker :751
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 751 Train Epoch: 0 [0/200 (0%)]	Loss: 0.353994
INFO:root:Worker: 751 Train Epoch: 1 [0/200 (0%)]	Loss: 0.431805
INFO:root:FL Epoch: 488 Norm Difference for worker 751 is 0.7114
INFO:root:FL Epoch: 488 Done on worker:751
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1857
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1857 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508988
INFO:root:Worker: 1857 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327647
INFO:root:FL Epoch: 488 Norm Difference for worker 1857 is 0.749764
INFO:root:FL Epoch: 488 Done on worker:1857
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :984
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 984 Train Epoch: 0 [0/200 (0%)]	Loss: 0.743272
INFO:root:Worker: 984 Train Epoch: 1 [0/200 (0%)]	Loss: 0.332384
INFO:root:FL Epoch: 488 Norm Difference for worker 984 is 0.714652
INFO:root:FL Epoch: 488 Done on worker:984
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1603
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1603 Train Epoch: 0 [0/200 (0%)]	Loss: 0.319740
INFO:root:Worker: 1603 Train Epoch: 1 [0/200 (0%)]	Loss: 0.621798
INFO:root:FL Epoch: 488 Norm Difference for worker 1603 is 0.683004
INFO:root:FL Epoch: 488 Done on worker:1603
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1511
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1511 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607542
INFO:root:Worker: 1511 Train Epoch: 1 [0/200 (0%)]	Loss: 0.685692
INFO:root:FL Epoch: 488 Norm Difference for worker 1511 is 0.807751
INFO:root:FL Epoch: 488 Done on worker:1511
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1895
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1895 Train Epoch: 0 [0/200 (0%)]	Loss: 0.432873
INFO:root:Worker: 1895 Train Epoch: 1 [0/200 (0%)]	Loss: 0.355069
INFO:root:FL Epoch: 488 Norm Difference for worker 1895 is 0.755157
INFO:root:FL Epoch: 488 Done on worker:1895
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1788
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1788 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520255
INFO:root:Worker: 1788 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398614
INFO:root:FL Epoch: 488 Norm Difference for worker 1788 is 0.721506
INFO:root:FL Epoch: 488 Done on worker:1788
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :1671
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 1671 Train Epoch: 0 [0/200 (0%)]	Loss: 0.529955
INFO:root:Worker: 1671 Train Epoch: 1 [0/200 (0%)]	Loss: 0.350995
INFO:root:FL Epoch: 488 Norm Difference for worker 1671 is 0.725796
INFO:root:FL Epoch: 488 Done on worker:1671
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :960
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 960 Train Epoch: 0 [0/200 (0%)]	Loss: 0.400683
INFO:root:Worker: 960 Train Epoch: 1 [0/200 (0%)]	Loss: 0.552376
INFO:root:FL Epoch: 488 Norm Difference for worker 960 is 0.726944
INFO:root:FL Epoch: 488 Done on worker:960
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 488 Training on worker :948
INFO:root:FL Epoch: 488 Using Learning rate : 0.018860083504816015 
INFO:root:FL Epoch: 488 Normal Training
INFO:root:Worker: 948 Train Epoch: 0 [0/200 (0%)]	Loss: 0.445231
INFO:root:Worker: 948 Train Epoch: 1 [0/200 (0%)]	Loss: 0.616950
INFO:root:FL Epoch: 488 Norm Difference for worker 948 is 0.748318
INFO:root:FL Epoch: 488 Done on worker:948
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1603
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 488 Ends   ===================
INFO:root:Epoch:488 Global Model Test Loss:0.5107874116476845 and Test Accuracy:75.58823529411765 
INFO:root:Epoch:488 Global Model Backdoor Test Loss:0.18807766338189444                             and Backdoor Test Accuracy:97.5 
INFO:root:=======================================================
INFO:root:================FL round 489 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 489 Workers Selected : [1133, 227, 1033, 1308, 1419, 1937, 1772, 910, 1572, 1900]
INFO:root:FL Epoch: 489 Fraction of points on each worker in this round: [0.09995002 0.10044978 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.09995002 0.09995002 0.09995002]
INFO:root:FL Epoch: 489 Num points on workers: [200 201 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 489 Training on worker :1133
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1133 Train Epoch: 0 [0/200 (0%)]	Loss: 0.459951
INFO:root:Worker: 1133 Train Epoch: 1 [0/200 (0%)]	Loss: 0.298768
INFO:root:FL Epoch: 489 Norm Difference for worker 1133 is 0.752557
INFO:root:FL Epoch: 489 Done on worker:1133
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :227
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 227 Train Epoch: 0 [0/201 (0%)]	Loss: 0.769244
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 227 Train Epoch: 1 [0/201 (0%)]	Loss: 0.292810
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 489 Norm Difference for worker 227 is 0.718076
INFO:root:FL Epoch: 489 Done on worker:227
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1033
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1033 Train Epoch: 0 [0/200 (0%)]	Loss: 0.607728
INFO:root:Worker: 1033 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408170
INFO:root:FL Epoch: 489 Norm Difference for worker 1033 is 0.638529
INFO:root:FL Epoch: 489 Done on worker:1033
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1308
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1308 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600435
INFO:root:Worker: 1308 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438895
INFO:root:FL Epoch: 489 Norm Difference for worker 1308 is 0.74518
INFO:root:FL Epoch: 489 Done on worker:1308
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1419
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1419 Train Epoch: 0 [0/200 (0%)]	Loss: 0.357787
INFO:root:Worker: 1419 Train Epoch: 1 [0/200 (0%)]	Loss: 0.472618
INFO:root:FL Epoch: 489 Norm Difference for worker 1419 is 0.666914
INFO:root:FL Epoch: 489 Done on worker:1419
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1937
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1937 Train Epoch: 0 [0/200 (0%)]	Loss: 0.600627
INFO:root:Worker: 1937 Train Epoch: 1 [0/200 (0%)]	Loss: 0.517900
INFO:root:FL Epoch: 489 Norm Difference for worker 1937 is 0.795287
INFO:root:FL Epoch: 489 Done on worker:1937
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1772
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.615189
INFO:root:Worker: 1772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.925008
INFO:root:FL Epoch: 489 Norm Difference for worker 1772 is 0.734601
INFO:root:FL Epoch: 489 Done on worker:1772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :910
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 910 Train Epoch: 0 [0/200 (0%)]	Loss: 0.538674
INFO:root:Worker: 910 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417323
INFO:root:FL Epoch: 489 Norm Difference for worker 910 is 0.782869
INFO:root:FL Epoch: 489 Done on worker:910
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1572
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1572 Train Epoch: 0 [0/200 (0%)]	Loss: 0.348924
INFO:root:Worker: 1572 Train Epoch: 1 [0/200 (0%)]	Loss: 0.286379
INFO:root:FL Epoch: 489 Norm Difference for worker 1572 is 0.727021
INFO:root:FL Epoch: 489 Done on worker:1572
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 489 Training on worker :1900
INFO:root:FL Epoch: 489 Using Learning rate : 0.018822363337806382 
INFO:root:FL Epoch: 489 Normal Training
INFO:root:Worker: 1900 Train Epoch: 0 [0/200 (0%)]	Loss: 0.504255
INFO:root:Worker: 1900 Train Epoch: 1 [0/200 (0%)]	Loss: 0.772136
INFO:root:FL Epoch: 489 Norm Difference for worker 1900 is 0.712764
INFO:root:FL Epoch: 489 Done on worker:1900
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 1419
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 489 Ends   ===================
INFO:root:Epoch:489 Global Model Test Loss:0.5207801215788898 and Test Accuracy:73.82352941176471 
INFO:root:Epoch:489 Global Model Backdoor Test Loss:0.28399765988190967                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 490 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 490 Workers Selected : [258, 882, 1565, 274, 1834, 1337, 1073, 832, 1536, 222]
INFO:root:FL Epoch: 490 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.10034948 0.09985022 0.09985022
 0.09985022 0.09985022 0.09985022 0.10034948]
INFO:root:FL Epoch: 490 Num points on workers: [201 200 200 201 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 490 Training on worker :258
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.721370
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.528068
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 490 Norm Difference for worker 258 is 0.748083
INFO:root:FL Epoch: 490 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :882
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 882 Train Epoch: 0 [0/200 (0%)]	Loss: 0.776158
INFO:root:Worker: 882 Train Epoch: 1 [0/200 (0%)]	Loss: 0.461898
INFO:root:FL Epoch: 490 Norm Difference for worker 882 is 0.692863
INFO:root:FL Epoch: 490 Done on worker:882
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1565
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1565 Train Epoch: 0 [0/200 (0%)]	Loss: 0.659002
INFO:root:Worker: 1565 Train Epoch: 1 [0/200 (0%)]	Loss: 0.533131
INFO:root:FL Epoch: 490 Norm Difference for worker 1565 is 0.765334
INFO:root:FL Epoch: 490 Done on worker:1565
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :274
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 274 Train Epoch: 0 [0/201 (0%)]	Loss: 0.585334
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 274 Train Epoch: 1 [0/201 (0%)]	Loss: 0.568743
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 490 Norm Difference for worker 274 is 0.657073
INFO:root:FL Epoch: 490 Done on worker:274
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1834
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1834 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560232
INFO:root:Worker: 1834 Train Epoch: 1 [0/200 (0%)]	Loss: 0.604825
INFO:root:FL Epoch: 490 Norm Difference for worker 1834 is 0.734872
INFO:root:FL Epoch: 490 Done on worker:1834
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1337
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1337 Train Epoch: 0 [0/200 (0%)]	Loss: 0.376881
INFO:root:Worker: 1337 Train Epoch: 1 [0/200 (0%)]	Loss: 0.265821
INFO:root:FL Epoch: 490 Norm Difference for worker 1337 is 0.679806
INFO:root:FL Epoch: 490 Done on worker:1337
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1073
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1073 Train Epoch: 0 [0/200 (0%)]	Loss: 0.495063
INFO:root:Worker: 1073 Train Epoch: 1 [0/200 (0%)]	Loss: 0.790594
INFO:root:FL Epoch: 490 Norm Difference for worker 1073 is 0.773704
INFO:root:FL Epoch: 490 Done on worker:1073
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :832
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 832 Train Epoch: 0 [0/200 (0%)]	Loss: 0.455174
INFO:root:Worker: 832 Train Epoch: 1 [0/200 (0%)]	Loss: 0.438364
INFO:root:FL Epoch: 490 Norm Difference for worker 832 is 0.688476
INFO:root:FL Epoch: 490 Done on worker:832
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :1536
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417810
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.361741
INFO:root:FL Epoch: 490 Norm Difference for worker 1536 is 0.651403
INFO:root:FL Epoch: 490 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 490 Training on worker :222
INFO:root:FL Epoch: 490 Using Learning rate : 0.01878471861113077 
INFO:root:FL Epoch: 490 Normal Training
INFO:root:Worker: 222 Train Epoch: 0 [0/201 (0%)]	Loss: 0.379346
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 222 Train Epoch: 1 [0/201 (0%)]	Loss: 0.293905
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 490 Norm Difference for worker 222 is 0.659684
INFO:root:FL Epoch: 490 Done on worker:222
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 5, which is global user: 1337
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 490 Ends   ===================
INFO:root:Epoch:490 Global Model Test Loss:0.52206091670429 and Test Accuracy:75.0 
INFO:root:Epoch:490 Global Model Backdoor Test Loss:0.15383480737606683                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 491 Begins ===================
INFO:root:FL Epoch: 491 *** This is Attack Epoch *** 
INFO:root:[True, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 491 Workers Selected : [0, 875, 272, 1662, 622, 633, 757, 1217, 1388, 82]
INFO:root:FL Epoch: 491 Fraction of points on each worker in this round: [0.0999001 0.0999001 0.1003996 0.0999001 0.0999001 0.0999001 0.0999001
 0.0999001 0.0999001 0.1003996]
INFO:root:FL Epoch: 491 Num points on workers: [200 200 201 200 200 200 200 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 491 Training on worker :0
INFO:root:FL Epoch: 491 Using Learning rate : 0.003749429834781701 
INFO:root:FL Epoch: 491 Training Attacker with blackbox Method 
INFO:root:Worker: 0 Train Epoch: 0 [0/200 (0%)]	Loss: 0.315808
INFO:root:Worker: 0 Train Epoch: 1 [0/200 (0%)]	Loss: 0.186004
INFO:root:FL Epoch: 491 Worker: 0 Backdoor Test Loss: 0.15846230338017145 Backdoor Test Accuracy: 96.66666666666667
INFO:root:FL Epoch: 491 Worker: 0 Backdoor Train Loss: 0.16116929352283477 Backdoor Train Accuracy: 96.0
INFO:root:FL Epoch: 491 Norm Difference for worker 0 is 0.142305
INFO:root:FL Epoch: 491 Done on worker:0
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :875
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 875 Train Epoch: 0 [0/200 (0%)]	Loss: 0.661560
INFO:root:Worker: 875 Train Epoch: 1 [0/200 (0%)]	Loss: 0.371703
INFO:root:FL Epoch: 491 Norm Difference for worker 875 is 0.824558
INFO:root:FL Epoch: 491 Done on worker:875
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :272
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 272 Train Epoch: 0 [0/201 (0%)]	Loss: 0.245629
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 272 Train Epoch: 1 [0/201 (0%)]	Loss: 0.626065
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 491 Norm Difference for worker 272 is 0.762324
INFO:root:FL Epoch: 491 Done on worker:272
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1662
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1662 Train Epoch: 0 [0/200 (0%)]	Loss: 0.420772
INFO:root:Worker: 1662 Train Epoch: 1 [0/200 (0%)]	Loss: 0.382318
INFO:root:FL Epoch: 491 Norm Difference for worker 1662 is 0.847375
INFO:root:FL Epoch: 491 Done on worker:1662
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :622
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 622 Train Epoch: 0 [0/200 (0%)]	Loss: 0.417851
INFO:root:Worker: 622 Train Epoch: 1 [0/200 (0%)]	Loss: 0.496336
INFO:root:FL Epoch: 491 Norm Difference for worker 622 is 0.782952
INFO:root:FL Epoch: 491 Done on worker:622
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :633
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.518798
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.398505
INFO:root:FL Epoch: 491 Norm Difference for worker 633 is 0.673476
INFO:root:FL Epoch: 491 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :757
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 757 Train Epoch: 0 [0/200 (0%)]	Loss: 0.540143
INFO:root:Worker: 757 Train Epoch: 1 [0/200 (0%)]	Loss: 0.583509
INFO:root:FL Epoch: 491 Norm Difference for worker 757 is 0.807713
INFO:root:FL Epoch: 491 Done on worker:757
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1217
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1217 Train Epoch: 0 [0/200 (0%)]	Loss: 0.560929
INFO:root:Worker: 1217 Train Epoch: 1 [0/200 (0%)]	Loss: 0.454240
INFO:root:FL Epoch: 491 Norm Difference for worker 1217 is 0.748462
INFO:root:FL Epoch: 491 Done on worker:1217
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :1388
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 1388 Train Epoch: 0 [0/200 (0%)]	Loss: 0.653091
INFO:root:Worker: 1388 Train Epoch: 1 [0/200 (0%)]	Loss: 0.340384
INFO:root:FL Epoch: 491 Norm Difference for worker 1388 is 0.766789
INFO:root:FL Epoch: 491 Done on worker:1388
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 491 Training on worker :82
INFO:root:FL Epoch: 491 Using Learning rate : 0.018747149173908507 
INFO:root:FL Epoch: 491 Normal Training
INFO:root:Worker: 82 Train Epoch: 0 [0/201 (0%)]	Loss: 0.614111
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 82 Train Epoch: 1 [0/201 (0%)]	Loss: 0.277658
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 491 Norm Difference for worker 82 is 0.791313
INFO:root:FL Epoch: 491 Done on worker:82
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 0, which is global user: 0
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 491 Ends   ===================
INFO:root:Epoch:491 Global Model Test Loss:0.5131301774698145 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:491 Global Model Backdoor Test Loss:0.15846230338017145                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 492 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 492 Workers Selected : [262, 797, 849, 1131, 703, 14, 243, 1435, 1552, 908]
INFO:root:FL Epoch: 492 Fraction of points on each worker in this round: [0.10034948 0.09985022 0.09985022 0.09985022 0.09985022 0.10034948
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 492 Num points on workers: [201 200 200 200 200 201 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 492 Training on worker :262
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 262 Train Epoch: 0 [0/201 (0%)]	Loss: 0.398521
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 262 Train Epoch: 1 [0/201 (0%)]	Loss: 0.483096
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 262 is 0.776671
INFO:root:FL Epoch: 492 Done on worker:262
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :797
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 797 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509060
INFO:root:Worker: 797 Train Epoch: 1 [0/200 (0%)]	Loss: 0.384204
INFO:root:FL Epoch: 492 Norm Difference for worker 797 is 0.828654
INFO:root:FL Epoch: 492 Done on worker:797
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :849
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 849 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569638
INFO:root:Worker: 849 Train Epoch: 1 [0/200 (0%)]	Loss: 0.412442
INFO:root:FL Epoch: 492 Norm Difference for worker 849 is 0.761446
INFO:root:FL Epoch: 492 Done on worker:849
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1131
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1131 Train Epoch: 0 [0/200 (0%)]	Loss: 0.664972
INFO:root:Worker: 1131 Train Epoch: 1 [0/200 (0%)]	Loss: 0.327554
INFO:root:FL Epoch: 492 Norm Difference for worker 1131 is 0.855352
INFO:root:FL Epoch: 492 Done on worker:1131
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :703
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 703 Train Epoch: 0 [0/200 (0%)]	Loss: 0.621260
INFO:root:Worker: 703 Train Epoch: 1 [0/200 (0%)]	Loss: 0.279878
INFO:root:FL Epoch: 492 Norm Difference for worker 703 is 0.841458
INFO:root:FL Epoch: 492 Done on worker:703
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :14
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 14 Train Epoch: 0 [0/201 (0%)]	Loss: 0.384901
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 14 Train Epoch: 1 [0/201 (0%)]	Loss: 0.533172
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 14 is 0.75593
INFO:root:FL Epoch: 492 Done on worker:14
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :243
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 243 Train Epoch: 0 [0/201 (0%)]	Loss: 0.509834
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 243 Train Epoch: 1 [0/201 (0%)]	Loss: 0.464171
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 492 Norm Difference for worker 243 is 0.813057
INFO:root:FL Epoch: 492 Done on worker:243
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1435
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1435 Train Epoch: 0 [0/200 (0%)]	Loss: 0.676992
INFO:root:Worker: 1435 Train Epoch: 1 [0/200 (0%)]	Loss: 0.256376
INFO:root:FL Epoch: 492 Norm Difference for worker 1435 is 0.722664
INFO:root:FL Epoch: 492 Done on worker:1435
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :1552
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 1552 Train Epoch: 0 [0/200 (0%)]	Loss: 0.467869
INFO:root:Worker: 1552 Train Epoch: 1 [0/200 (0%)]	Loss: 0.383021
INFO:root:FL Epoch: 492 Norm Difference for worker 1552 is 0.7898
INFO:root:FL Epoch: 492 Done on worker:1552
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 492 Training on worker :908
INFO:root:FL Epoch: 492 Using Learning rate : 0.018709654875560693 
INFO:root:FL Epoch: 492 Normal Training
INFO:root:Worker: 908 Train Epoch: 0 [0/200 (0%)]	Loss: 0.597396
INFO:root:Worker: 908 Train Epoch: 1 [0/200 (0%)]	Loss: 0.456710
INFO:root:FL Epoch: 492 Norm Difference for worker 908 is 0.746678
INFO:root:FL Epoch: 492 Done on worker:908
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 1435
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 492 Ends   ===================
INFO:root:Epoch:492 Global Model Test Loss:0.5086837375865263 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:492 Global Model Backdoor Test Loss:0.1962156929075718                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 493 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 493 Workers Selected : [195, 1174, 1447, 1474, 114, 2, 335, 989, 1273, 5]
INFO:root:FL Epoch: 493 Fraction of points on each worker in this round: [0.10024938 0.09975062 0.09975062 0.09975062 0.10024938 0.10024938
 0.10024938 0.09975062 0.09975062 0.10024938]
INFO:root:FL Epoch: 493 Num points on workers: [201 200 200 200 201 201 201 200 200 201]
INFO:root:--------------------------
INFO:root:FL Epoch: 493 Training on worker :195
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 195 Train Epoch: 0 [0/201 (0%)]	Loss: 0.576675
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 195 Train Epoch: 1 [0/201 (0%)]	Loss: 0.464565
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 493 Norm Difference for worker 195 is 0.826464
INFO:root:FL Epoch: 493 Done on worker:195
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1174
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1174 Train Epoch: 0 [0/200 (0%)]	Loss: 0.510523
INFO:root:Worker: 1174 Train Epoch: 1 [0/200 (0%)]	Loss: 0.499838
INFO:root:FL Epoch: 493 Norm Difference for worker 1174 is 0.869642
INFO:root:FL Epoch: 493 Done on worker:1174
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1447
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1447 Train Epoch: 0 [0/200 (0%)]	Loss: 0.489438
INFO:root:Worker: 1447 Train Epoch: 1 [0/200 (0%)]	Loss: 0.333954
INFO:root:FL Epoch: 493 Norm Difference for worker 1447 is 0.728284
INFO:root:FL Epoch: 493 Done on worker:1447
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1474
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1474 Train Epoch: 0 [0/200 (0%)]	Loss: 0.577752
INFO:root:Worker: 1474 Train Epoch: 1 [0/200 (0%)]	Loss: 0.550930
INFO:root:FL Epoch: 493 Norm Difference for worker 1474 is 0.792826
INFO:root:FL Epoch: 493 Done on worker:1474
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :114
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 114 Train Epoch: 0 [0/201 (0%)]	Loss: 0.561602
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 114 Train Epoch: 1 [0/201 (0%)]	Loss: 0.765072
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 493 Norm Difference for worker 114 is 0.855741
INFO:root:FL Epoch: 493 Done on worker:114
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :2
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 2 Train Epoch: 0 [0/201 (0%)]	Loss: 0.475818
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 2 Train Epoch: 1 [0/201 (0%)]	Loss: 0.381018
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 493 Norm Difference for worker 2 is 0.725267
INFO:root:FL Epoch: 493 Done on worker:2
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :335
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 335 Train Epoch: 0 [0/201 (0%)]	Loss: 0.722839
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 335 Train Epoch: 1 [0/201 (0%)]	Loss: 0.577605
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 493 Norm Difference for worker 335 is 0.758239
INFO:root:FL Epoch: 493 Done on worker:335
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :989
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 989 Train Epoch: 0 [0/200 (0%)]	Loss: 0.742216
INFO:root:Worker: 989 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493055
INFO:root:FL Epoch: 493 Norm Difference for worker 989 is 0.757611
INFO:root:FL Epoch: 493 Done on worker:989
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :1273
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 1273 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716404
INFO:root:Worker: 1273 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576634
INFO:root:FL Epoch: 493 Norm Difference for worker 1273 is 0.807731
INFO:root:FL Epoch: 493 Done on worker:1273
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 493 Training on worker :5
INFO:root:FL Epoch: 493 Using Learning rate : 0.01867223556580957 
INFO:root:FL Epoch: 493 Normal Training
INFO:root:Worker: 5 Train Epoch: 0 [0/201 (0%)]	Loss: 0.375500
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 5 Train Epoch: 1 [0/201 (0%)]	Loss: 0.397148
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 493 Norm Difference for worker 5 is 0.807427
INFO:root:FL Epoch: 493 Done on worker:5
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 6, which is global user: 335
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 493 Ends   ===================
INFO:root:Epoch:493 Global Model Test Loss:0.5035766328082365 and Test Accuracy:77.05882352941177 
INFO:root:Epoch:493 Global Model Backdoor Test Loss:0.17801456525921822                             and Backdoor Test Accuracy:96.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 494 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 494 Workers Selected : [1188, 1083, 258, 62, 620, 989, 46, 776, 803, 1710]
INFO:root:FL Epoch: 494 Fraction of points on each worker in this round: [0.09985022 0.09985022 0.10034948 0.10034948 0.09985022 0.09985022
 0.10034948 0.09985022 0.09985022 0.09985022]
INFO:root:FL Epoch: 494 Num points on workers: [200 200 201 201 200 200 201 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 494 Training on worker :1188
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1188 Train Epoch: 0 [0/200 (0%)]	Loss: 0.716046
INFO:root:Worker: 1188 Train Epoch: 1 [0/200 (0%)]	Loss: 0.359376
INFO:root:FL Epoch: 494 Norm Difference for worker 1188 is 0.756006
INFO:root:FL Epoch: 494 Done on worker:1188
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1083
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1083 Train Epoch: 0 [0/200 (0%)]	Loss: 0.431868
INFO:root:Worker: 1083 Train Epoch: 1 [0/200 (0%)]	Loss: 0.428168
INFO:root:FL Epoch: 494 Norm Difference for worker 1083 is 0.833432
INFO:root:FL Epoch: 494 Done on worker:1083
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :258
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 258 Train Epoch: 0 [0/201 (0%)]	Loss: 0.616251
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 258 Train Epoch: 1 [0/201 (0%)]	Loss: 0.599005
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 258 is 0.800071
INFO:root:FL Epoch: 494 Done on worker:258
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :62
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 62 Train Epoch: 0 [0/201 (0%)]	Loss: 0.531694
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 62 Train Epoch: 1 [0/201 (0%)]	Loss: 0.370376
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 62 is 0.757888
INFO:root:FL Epoch: 494 Done on worker:62
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :620
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 620 Train Epoch: 0 [0/200 (0%)]	Loss: 0.342525
INFO:root:Worker: 620 Train Epoch: 1 [0/200 (0%)]	Loss: 0.293335
INFO:root:FL Epoch: 494 Norm Difference for worker 620 is 0.607623
INFO:root:FL Epoch: 494 Done on worker:620
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :989
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 989 Train Epoch: 0 [0/200 (0%)]	Loss: 0.702562
INFO:root:Worker: 989 Train Epoch: 1 [0/200 (0%)]	Loss: 0.485345
INFO:root:FL Epoch: 494 Norm Difference for worker 989 is 0.69731
INFO:root:FL Epoch: 494 Done on worker:989
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :46
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 46 Train Epoch: 0 [0/201 (0%)]	Loss: 0.449668
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 46 Train Epoch: 1 [0/201 (0%)]	Loss: 0.413571
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 494 Norm Difference for worker 46 is 0.739286
INFO:root:FL Epoch: 494 Done on worker:46
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :776
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 776 Train Epoch: 0 [0/200 (0%)]	Loss: 0.300071
INFO:root:Worker: 776 Train Epoch: 1 [0/200 (0%)]	Loss: 0.263096
INFO:root:FL Epoch: 494 Norm Difference for worker 776 is 0.671887
INFO:root:FL Epoch: 494 Done on worker:776
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :803
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.364556
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408994
INFO:root:FL Epoch: 494 Norm Difference for worker 803 is 0.735338
INFO:root:FL Epoch: 494 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 494 Training on worker :1710
INFO:root:FL Epoch: 494 Using Learning rate : 0.01863489109467795 
INFO:root:FL Epoch: 494 Normal Training
INFO:root:Worker: 1710 Train Epoch: 0 [0/200 (0%)]	Loss: 0.508326
INFO:root:Worker: 1710 Train Epoch: 1 [0/200 (0%)]	Loss: 0.436737
INFO:root:FL Epoch: 494 Norm Difference for worker 1710 is 0.714283
INFO:root:FL Epoch: 494 Done on worker:1710
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 776
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 494 Ends   ===================
INFO:root:Epoch:494 Global Model Test Loss:0.5189304106375751 and Test Accuracy:74.41176470588235 
INFO:root:Epoch:494 Global Model Backdoor Test Loss:0.19963059201836586                             and Backdoor Test Accuracy:94.16666666666667 
INFO:root:=======================================================
INFO:root:================FL round 495 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 495 Workers Selected : [1468, 459, 867, 584, 1079, 1611, 1935, 1353, 789, 422]
INFO:root:FL Epoch: 495 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 495 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 495 Training on worker :1468
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1468 Train Epoch: 0 [0/200 (0%)]	Loss: 0.688660
INFO:root:Worker: 1468 Train Epoch: 1 [0/200 (0%)]	Loss: 0.740629
INFO:root:FL Epoch: 495 Norm Difference for worker 1468 is 0.885589
INFO:root:FL Epoch: 495 Done on worker:1468
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :459
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 459 Train Epoch: 0 [0/200 (0%)]	Loss: 0.478714
INFO:root:Worker: 459 Train Epoch: 1 [0/200 (0%)]	Loss: 0.237037
INFO:root:FL Epoch: 495 Norm Difference for worker 459 is 0.718752
INFO:root:FL Epoch: 495 Done on worker:459
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :867
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 867 Train Epoch: 0 [0/200 (0%)]	Loss: 0.544550
INFO:root:Worker: 867 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338374
INFO:root:FL Epoch: 495 Norm Difference for worker 867 is 0.80436
INFO:root:FL Epoch: 495 Done on worker:867
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :584
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 584 Train Epoch: 0 [0/200 (0%)]	Loss: 0.614397
INFO:root:Worker: 584 Train Epoch: 1 [0/200 (0%)]	Loss: 0.374652
INFO:root:FL Epoch: 495 Norm Difference for worker 584 is 0.787155
INFO:root:FL Epoch: 495 Done on worker:584
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1079
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1079 Train Epoch: 0 [0/200 (0%)]	Loss: 0.606461
INFO:root:Worker: 1079 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521571
INFO:root:FL Epoch: 495 Norm Difference for worker 1079 is 0.82289
INFO:root:FL Epoch: 495 Done on worker:1079
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1611
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1611 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463700
INFO:root:Worker: 1611 Train Epoch: 1 [0/200 (0%)]	Loss: 0.491735
INFO:root:FL Epoch: 495 Norm Difference for worker 1611 is 0.803575
INFO:root:FL Epoch: 495 Done on worker:1611
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1935
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1935 Train Epoch: 0 [0/200 (0%)]	Loss: 0.788157
INFO:root:Worker: 1935 Train Epoch: 1 [0/200 (0%)]	Loss: 0.432152
INFO:root:FL Epoch: 495 Norm Difference for worker 1935 is 0.802775
INFO:root:FL Epoch: 495 Done on worker:1935
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :1353
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 1353 Train Epoch: 0 [0/200 (0%)]	Loss: 0.391901
INFO:root:Worker: 1353 Train Epoch: 1 [0/200 (0%)]	Loss: 0.417946
INFO:root:FL Epoch: 495 Norm Difference for worker 1353 is 0.764241
INFO:root:FL Epoch: 495 Done on worker:1353
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :789
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 789 Train Epoch: 0 [0/200 (0%)]	Loss: 0.671266
INFO:root:Worker: 789 Train Epoch: 1 [0/200 (0%)]	Loss: 0.539227
INFO:root:FL Epoch: 495 Norm Difference for worker 789 is 0.760905
INFO:root:FL Epoch: 495 Done on worker:789
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 495 Training on worker :422
INFO:root:FL Epoch: 495 Using Learning rate : 0.018597621312488596 
INFO:root:FL Epoch: 495 Normal Training
INFO:root:Worker: 422 Train Epoch: 0 [0/200 (0%)]	Loss: 0.232865
INFO:root:Worker: 422 Train Epoch: 1 [0/200 (0%)]	Loss: 0.544299
INFO:root:FL Epoch: 495 Norm Difference for worker 422 is 0.787396
INFO:root:FL Epoch: 495 Done on worker:422
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 1, which is global user: 459
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 495 Ends   ===================
INFO:root:Epoch:495 Global Model Test Loss:0.5043471473104814 and Test Accuracy:76.17647058823529 
INFO:root:Epoch:495 Global Model Backdoor Test Loss:0.22277584175268808                             and Backdoor Test Accuracy:92.5 
INFO:root:=======================================================
INFO:root:================FL round 496 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 496 Workers Selected : [651, 1213, 1587, 762, 1241, 343, 1496, 773, 1232, 414]
INFO:root:FL Epoch: 496 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 496 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 496 Training on worker :651
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 651 Train Epoch: 0 [0/200 (0%)]	Loss: 0.363383
INFO:root:Worker: 651 Train Epoch: 1 [0/200 (0%)]	Loss: 0.408455
INFO:root:FL Epoch: 496 Norm Difference for worker 651 is 0.709501
INFO:root:FL Epoch: 496 Done on worker:651
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1213
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1213 Train Epoch: 0 [0/200 (0%)]	Loss: 0.575067
INFO:root:Worker: 1213 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482898
INFO:root:FL Epoch: 496 Norm Difference for worker 1213 is 0.776663
INFO:root:FL Epoch: 496 Done on worker:1213
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1587
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1587 Train Epoch: 0 [0/200 (0%)]	Loss: 0.662516
INFO:root:Worker: 1587 Train Epoch: 1 [0/200 (0%)]	Loss: 0.385905
INFO:root:FL Epoch: 496 Norm Difference for worker 1587 is 0.697487
INFO:root:FL Epoch: 496 Done on worker:1587
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :762
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 762 Train Epoch: 0 [0/200 (0%)]	Loss: 0.441564
INFO:root:Worker: 762 Train Epoch: 1 [0/200 (0%)]	Loss: 0.571922
INFO:root:FL Epoch: 496 Norm Difference for worker 762 is 0.765646
INFO:root:FL Epoch: 496 Done on worker:762
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1241
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1241 Train Epoch: 0 [0/200 (0%)]	Loss: 0.726936
INFO:root:Worker: 1241 Train Epoch: 1 [0/200 (0%)]	Loss: 0.597550
INFO:root:FL Epoch: 496 Norm Difference for worker 1241 is 0.73297
INFO:root:FL Epoch: 496 Done on worker:1241
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :343
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 343 Train Epoch: 0 [0/200 (0%)]	Loss: 0.435730
INFO:root:Worker: 343 Train Epoch: 1 [0/200 (0%)]	Loss: 0.774512
INFO:root:FL Epoch: 496 Norm Difference for worker 343 is 0.730028
INFO:root:FL Epoch: 496 Done on worker:343
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1496
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1496 Train Epoch: 0 [0/200 (0%)]	Loss: 0.569437
INFO:root:Worker: 1496 Train Epoch: 1 [0/200 (0%)]	Loss: 0.532646
INFO:root:FL Epoch: 496 Norm Difference for worker 1496 is 0.720364
INFO:root:FL Epoch: 496 Done on worker:1496
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :773
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 773 Train Epoch: 0 [0/200 (0%)]	Loss: 0.470897
INFO:root:Worker: 773 Train Epoch: 1 [0/200 (0%)]	Loss: 0.465939
INFO:root:FL Epoch: 496 Norm Difference for worker 773 is 0.627524
INFO:root:FL Epoch: 496 Done on worker:773
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :1232
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 1232 Train Epoch: 0 [0/200 (0%)]	Loss: 0.852388
INFO:root:Worker: 1232 Train Epoch: 1 [0/200 (0%)]	Loss: 0.335442
INFO:root:FL Epoch: 496 Norm Difference for worker 1232 is 0.703484
INFO:root:FL Epoch: 496 Done on worker:1232
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 496 Training on worker :414
INFO:root:FL Epoch: 496 Using Learning rate : 0.018560426069863616 
INFO:root:FL Epoch: 496 Normal Training
INFO:root:Worker: 414 Train Epoch: 0 [0/200 (0%)]	Loss: 0.871241
INFO:root:Worker: 414 Train Epoch: 1 [0/200 (0%)]	Loss: 0.644246
INFO:root:FL Epoch: 496 Norm Difference for worker 414 is 0.757943
INFO:root:FL Epoch: 496 Done on worker:414
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 7, which is global user: 773
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 496 Ends   ===================
INFO:root:Epoch:496 Global Model Test Loss:0.5102133610669304 and Test Accuracy:74.11764705882354 
INFO:root:Epoch:496 Global Model Backdoor Test Loss:0.25626330077648163                             and Backdoor Test Accuracy:91.66666666666667 
INFO:root:=======================================================
INFO:root:================FL round 497 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 497 Workers Selected : [1051, 665, 633, 1771, 1763, 612, 1329, 421, 866, 1001]
INFO:root:FL Epoch: 497 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 497 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 497 Training on worker :1051
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1051 Train Epoch: 0 [0/200 (0%)]	Loss: 0.644458
INFO:root:Worker: 1051 Train Epoch: 1 [0/200 (0%)]	Loss: 0.427956
INFO:root:FL Epoch: 497 Norm Difference for worker 1051 is 0.667966
INFO:root:FL Epoch: 497 Done on worker:1051
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :665
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 665 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605173
INFO:root:Worker: 665 Train Epoch: 1 [0/200 (0%)]	Loss: 0.492911
INFO:root:FL Epoch: 497 Norm Difference for worker 665 is 0.639525
INFO:root:FL Epoch: 497 Done on worker:665
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :633
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 633 Train Epoch: 0 [0/200 (0%)]	Loss: 0.392688
INFO:root:Worker: 633 Train Epoch: 1 [0/200 (0%)]	Loss: 0.493052
INFO:root:FL Epoch: 497 Norm Difference for worker 633 is 0.599799
INFO:root:FL Epoch: 497 Done on worker:633
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :1771
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1771 Train Epoch: 0 [0/200 (0%)]	Loss: 0.520602
INFO:root:Worker: 1771 Train Epoch: 1 [0/200 (0%)]	Loss: 0.500832
INFO:root:FL Epoch: 497 Norm Difference for worker 1771 is 0.693522
INFO:root:FL Epoch: 497 Done on worker:1771
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :1763
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1763 Train Epoch: 0 [0/200 (0%)]	Loss: 0.674369
INFO:root:Worker: 1763 Train Epoch: 1 [0/200 (0%)]	Loss: 0.319654
INFO:root:FL Epoch: 497 Norm Difference for worker 1763 is 0.696553
INFO:root:FL Epoch: 497 Done on worker:1763
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :612
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 612 Train Epoch: 0 [0/200 (0%)]	Loss: 0.396323
INFO:root:Worker: 612 Train Epoch: 1 [0/200 (0%)]	Loss: 0.679259
INFO:root:FL Epoch: 497 Norm Difference for worker 612 is 0.715706
INFO:root:FL Epoch: 497 Done on worker:612
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :1329
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1329 Train Epoch: 0 [0/200 (0%)]	Loss: 0.479750
INFO:root:Worker: 1329 Train Epoch: 1 [0/200 (0%)]	Loss: 0.576898
INFO:root:FL Epoch: 497 Norm Difference for worker 1329 is 0.713274
INFO:root:FL Epoch: 497 Done on worker:1329
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :421
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 421 Train Epoch: 0 [0/200 (0%)]	Loss: 0.711082
INFO:root:Worker: 421 Train Epoch: 1 [0/200 (0%)]	Loss: 0.605977
INFO:root:FL Epoch: 497 Norm Difference for worker 421 is 0.825079
INFO:root:FL Epoch: 497 Done on worker:421
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :866
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 866 Train Epoch: 0 [0/200 (0%)]	Loss: 0.684581
INFO:root:Worker: 866 Train Epoch: 1 [0/200 (0%)]	Loss: 0.661157
INFO:root:FL Epoch: 497 Norm Difference for worker 866 is 0.728214
INFO:root:FL Epoch: 497 Done on worker:866
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 497 Training on worker :1001
INFO:root:FL Epoch: 497 Using Learning rate : 0.01852330521772389 
INFO:root:FL Epoch: 497 Normal Training
INFO:root:Worker: 1001 Train Epoch: 0 [0/200 (0%)]	Loss: 0.384725
INFO:root:Worker: 1001 Train Epoch: 1 [0/200 (0%)]	Loss: 0.599854
INFO:root:FL Epoch: 497 Norm Difference for worker 1001 is 0.720311
INFO:root:FL Epoch: 497 Done on worker:1001
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 633
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 497 Ends   ===================
INFO:root:Epoch:497 Global Model Test Loss:0.5048201890552745 and Test Accuracy:75.0 
INFO:root:Epoch:497 Global Model Backdoor Test Loss:0.2149934470653534                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 498 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 498 Workers Selected : [740, 1107, 772, 1526, 887, 905, 1182, 1235, 1464, 1946]
INFO:root:FL Epoch: 498 Fraction of points on each worker in this round: [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]
INFO:root:FL Epoch: 498 Num points on workers: [200 200 200 200 200 200 200 200 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 498 Training on worker :740
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 740 Train Epoch: 0 [0/200 (0%)]	Loss: 0.509680
INFO:root:Worker: 740 Train Epoch: 1 [0/200 (0%)]	Loss: 0.470126
INFO:root:FL Epoch: 498 Norm Difference for worker 740 is 0.755998
INFO:root:FL Epoch: 498 Done on worker:740
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1107
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1107 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408374
INFO:root:Worker: 1107 Train Epoch: 1 [0/200 (0%)]	Loss: 0.662317
INFO:root:FL Epoch: 498 Norm Difference for worker 1107 is 0.729059
INFO:root:FL Epoch: 498 Done on worker:1107
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :772
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 772 Train Epoch: 0 [0/200 (0%)]	Loss: 0.408440
INFO:root:Worker: 772 Train Epoch: 1 [0/200 (0%)]	Loss: 0.845420
INFO:root:FL Epoch: 498 Norm Difference for worker 772 is 0.826732
INFO:root:FL Epoch: 498 Done on worker:772
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1526
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1526 Train Epoch: 0 [0/200 (0%)]	Loss: 0.374006
INFO:root:Worker: 1526 Train Epoch: 1 [0/200 (0%)]	Loss: 0.430654
INFO:root:FL Epoch: 498 Norm Difference for worker 1526 is 0.6906
INFO:root:FL Epoch: 498 Done on worker:1526
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :887
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 887 Train Epoch: 0 [0/200 (0%)]	Loss: 0.456550
INFO:root:Worker: 887 Train Epoch: 1 [0/200 (0%)]	Loss: 0.406229
INFO:root:FL Epoch: 498 Norm Difference for worker 887 is 0.769383
INFO:root:FL Epoch: 498 Done on worker:887
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :905
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 905 Train Epoch: 0 [0/200 (0%)]	Loss: 0.461976
INFO:root:Worker: 905 Train Epoch: 1 [0/200 (0%)]	Loss: 0.541168
INFO:root:FL Epoch: 498 Norm Difference for worker 905 is 0.807675
INFO:root:FL Epoch: 498 Done on worker:905
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1182
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1182 Train Epoch: 0 [0/200 (0%)]	Loss: 0.559209
INFO:root:Worker: 1182 Train Epoch: 1 [0/200 (0%)]	Loss: 0.525326
INFO:root:FL Epoch: 498 Norm Difference for worker 1182 is 0.783699
INFO:root:FL Epoch: 498 Done on worker:1182
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1235
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1235 Train Epoch: 0 [0/200 (0%)]	Loss: 0.465330
INFO:root:Worker: 1235 Train Epoch: 1 [0/200 (0%)]	Loss: 0.521892
INFO:root:FL Epoch: 498 Norm Difference for worker 1235 is 0.760127
INFO:root:FL Epoch: 498 Done on worker:1235
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1464
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1464 Train Epoch: 0 [0/200 (0%)]	Loss: 0.605141
INFO:root:Worker: 1464 Train Epoch: 1 [0/200 (0%)]	Loss: 0.367743
INFO:root:FL Epoch: 498 Norm Difference for worker 1464 is 0.716996
INFO:root:FL Epoch: 498 Done on worker:1464
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 498 Training on worker :1946
INFO:root:FL Epoch: 498 Using Learning rate : 0.018486258607288444 
INFO:root:FL Epoch: 498 Normal Training
INFO:root:Worker: 1946 Train Epoch: 0 [0/200 (0%)]	Loss: 0.838366
INFO:root:Worker: 1946 Train Epoch: 1 [0/200 (0%)]	Loss: 0.452544
INFO:root:FL Epoch: 498 Norm Difference for worker 1946 is 0.722693
INFO:root:FL Epoch: 498 Done on worker:1946
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 3, which is global user: 1526
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 498 Ends   ===================
INFO:root:Epoch:498 Global Model Test Loss:0.5060325843446395 and Test Accuracy:73.52941176470588 
INFO:root:Epoch:498 Global Model Backdoor Test Loss:0.21448293328285217                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 499 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 499 Workers Selected : [803, 1154, 378, 444, 975, 669, 1010, 197, 1536, 569]
INFO:root:FL Epoch: 499 Fraction of points on each worker in this round: [0.09995002 0.09995002 0.09995002 0.09995002 0.09995002 0.09995002
 0.09995002 0.10044978 0.09995002 0.09995002]
INFO:root:FL Epoch: 499 Num points on workers: [200 200 200 200 200 200 200 201 200 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 499 Training on worker :803
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 803 Train Epoch: 0 [0/200 (0%)]	Loss: 0.542106
INFO:root:Worker: 803 Train Epoch: 1 [0/200 (0%)]	Loss: 0.302025
INFO:root:FL Epoch: 499 Norm Difference for worker 803 is 0.708335
INFO:root:FL Epoch: 499 Done on worker:803
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1154
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1154 Train Epoch: 0 [0/200 (0%)]	Loss: 0.593891
INFO:root:Worker: 1154 Train Epoch: 1 [0/200 (0%)]	Loss: 0.389928
INFO:root:FL Epoch: 499 Norm Difference for worker 1154 is 0.727558
INFO:root:FL Epoch: 499 Done on worker:1154
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :378
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 378 Train Epoch: 0 [0/200 (0%)]	Loss: 0.490557
INFO:root:Worker: 378 Train Epoch: 1 [0/200 (0%)]	Loss: 1.026319
INFO:root:FL Epoch: 499 Norm Difference for worker 378 is 0.714103
INFO:root:FL Epoch: 499 Done on worker:378
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :444
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 444 Train Epoch: 0 [0/200 (0%)]	Loss: 0.493104
INFO:root:Worker: 444 Train Epoch: 1 [0/200 (0%)]	Loss: 0.455995
INFO:root:FL Epoch: 499 Norm Difference for worker 444 is 0.713791
INFO:root:FL Epoch: 499 Done on worker:444
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :975
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 975 Train Epoch: 0 [0/200 (0%)]	Loss: 0.487307
INFO:root:Worker: 975 Train Epoch: 1 [0/200 (0%)]	Loss: 0.462307
INFO:root:FL Epoch: 499 Norm Difference for worker 975 is 0.777671
INFO:root:FL Epoch: 499 Done on worker:975
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :669
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 669 Train Epoch: 0 [0/200 (0%)]	Loss: 0.463566
INFO:root:Worker: 669 Train Epoch: 1 [0/200 (0%)]	Loss: 0.338119
INFO:root:FL Epoch: 499 Norm Difference for worker 669 is 0.763076
INFO:root:FL Epoch: 499 Done on worker:669
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1010
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1010 Train Epoch: 0 [0/200 (0%)]	Loss: 0.755167
INFO:root:Worker: 1010 Train Epoch: 1 [0/200 (0%)]	Loss: 0.660027
INFO:root:FL Epoch: 499 Norm Difference for worker 1010 is 0.730079
INFO:root:FL Epoch: 499 Done on worker:1010
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :197
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 197 Train Epoch: 0 [0/201 (0%)]	Loss: 0.590900
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 197 Train Epoch: 1 [0/201 (0%)]	Loss: 0.380011
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 499 Norm Difference for worker 197 is 0.718498
INFO:root:FL Epoch: 499 Done on worker:197
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :1536
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 1536 Train Epoch: 0 [0/200 (0%)]	Loss: 0.549975
INFO:root:Worker: 1536 Train Epoch: 1 [0/200 (0%)]	Loss: 0.354069
INFO:root:FL Epoch: 499 Norm Difference for worker 1536 is 0.716018
INFO:root:FL Epoch: 499 Done on worker:1536
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 499 Training on worker :569
INFO:root:FL Epoch: 499 Using Learning rate : 0.018449286090073864 
INFO:root:FL Epoch: 499 Normal Training
INFO:root:Worker: 569 Train Epoch: 0 [0/200 (0%)]	Loss: 0.900945
INFO:root:Worker: 569 Train Epoch: 1 [0/200 (0%)]	Loss: 0.506772
INFO:root:FL Epoch: 499 Norm Difference for worker 569 is 0.769762
INFO:root:FL Epoch: 499 Done on worker:569
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 2, which is global user: 378
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 499 Ends   ===================
INFO:root:Epoch:499 Global Model Test Loss:0.501142193289364 and Test Accuracy:75.88235294117646 
INFO:root:Epoch:499 Global Model Backdoor Test Loss:0.28195185710986453                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:================FL round 500 Begins ===================
INFO:root:[False, False, False, False, False, False, False, False, False, False]
INFO:root:FL Epoch: 500 Workers Selected : [1053, 332, 1290, 1643, 286, 348, 1869, 43, 49, 393]
INFO:root:FL Epoch: 500 Fraction of points on each worker in this round: [0.0998004 0.1002994 0.0998004 0.0998004 0.1002994 0.0998004 0.0998004
 0.1002994 0.1002994 0.0998004]
INFO:root:FL Epoch: 500 Num points on workers: [200 201 200 200 201 200 200 201 201 200]
INFO:root:--------------------------
INFO:root:FL Epoch: 500 Training on worker :1053
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1053 Train Epoch: 0 [0/200 (0%)]	Loss: 0.553981
INFO:root:Worker: 1053 Train Epoch: 1 [0/200 (0%)]	Loss: 0.394183
INFO:root:FL Epoch: 500 Norm Difference for worker 1053 is 0.599208
INFO:root:FL Epoch: 500 Done on worker:1053
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :332
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 332 Train Epoch: 0 [0/201 (0%)]	Loss: 0.808782
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 332 Train Epoch: 1 [0/201 (0%)]	Loss: 0.380660
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 500 Norm Difference for worker 332 is 0.663708
INFO:root:FL Epoch: 500 Done on worker:332
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1290
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1290 Train Epoch: 0 [0/200 (0%)]	Loss: 0.321610
INFO:root:Worker: 1290 Train Epoch: 1 [0/200 (0%)]	Loss: 0.507956
INFO:root:FL Epoch: 500 Norm Difference for worker 1290 is 0.604468
INFO:root:FL Epoch: 500 Done on worker:1290
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1643
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1643 Train Epoch: 0 [0/200 (0%)]	Loss: 0.837428
INFO:root:Worker: 1643 Train Epoch: 1 [0/200 (0%)]	Loss: 0.482214
INFO:root:FL Epoch: 500 Norm Difference for worker 1643 is 0.653856
INFO:root:FL Epoch: 500 Done on worker:1643
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :286
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 286 Train Epoch: 0 [0/201 (0%)]	Loss: 0.427474
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 286 Train Epoch: 1 [0/201 (0%)]	Loss: 0.431792
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 500 Norm Difference for worker 286 is 0.573398
INFO:root:FL Epoch: 500 Done on worker:286
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :348
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 348 Train Epoch: 0 [0/200 (0%)]	Loss: 0.477456
INFO:root:Worker: 348 Train Epoch: 1 [0/200 (0%)]	Loss: 0.440683
INFO:root:FL Epoch: 500 Norm Difference for worker 348 is 0.647962
INFO:root:FL Epoch: 500 Done on worker:348
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :1869
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 1869 Train Epoch: 0 [0/200 (0%)]	Loss: 0.372740
INFO:root:Worker: 1869 Train Epoch: 1 [0/200 (0%)]	Loss: 0.450240
INFO:root:FL Epoch: 500 Norm Difference for worker 1869 is 0.625588
INFO:root:FL Epoch: 500 Done on worker:1869
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :43
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 43 Train Epoch: 0 [0/201 (0%)]	Loss: 0.727998
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 43 Train Epoch: 1 [0/201 (0%)]	Loss: 0.639527
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 500 Norm Difference for worker 43 is 0.582763
INFO:root:FL Epoch: 500 Done on worker:43
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :49
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 49 Train Epoch: 0 [0/201 (0%)]	Loss: 0.650716
INFO:root:ignore batch due to small size = 1
INFO:root:Worker: 49 Train Epoch: 1 [0/201 (0%)]	Loss: 0.444832
INFO:root:ignore batch due to small size = 1
INFO:root:FL Epoch: 500 Norm Difference for worker 49 is 0.650881
INFO:root:FL Epoch: 500 Done on worker:49
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:FL Epoch: 500 Training on worker :393
INFO:root:FL Epoch: 500 Using Learning rate : 0.018412387517893716 
INFO:root:FL Epoch: 500 Normal Training
INFO:root:Worker: 393 Train Epoch: 0 [0/200 (0%)]	Loss: 0.245544
INFO:root:Worker: 393 Train Epoch: 1 [0/200 (0%)]	Loss: 0.557694
INFO:root:FL Epoch: 500 Norm Difference for worker 393 is 0.639449
INFO:root:FL Epoch: 500 Done on worker:393
INFO:root:--------------------------
INFO:root:Will aggregate after defense
INFO:root:@@@@ The chosen one is user: 4, which is global user: 286
INFO:root:Norm of Aggregated Model: 5154.99853515625
INFO:root:Aggregating After Defense
INFO:root:================FL round 500 Ends   ===================
INFO:root:Epoch:500 Global Model Test Loss:0.49874792730107026 and Test Accuracy:76.76470588235294 
INFO:root:Epoch:500 Global Model Backdoor Test Loss:0.22823914140462875                             and Backdoor Test Accuracy:93.33333333333333 
INFO:root:=======================================================
INFO:root:***** Done with FL Training, Saved the stats to file ./out/report/3c/stats.csv ******
